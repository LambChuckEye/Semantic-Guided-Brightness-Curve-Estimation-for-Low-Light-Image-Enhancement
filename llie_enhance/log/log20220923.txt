Namespace(gpu_id=0, img_path='/home/wsz/workspace/Data/LOLdataset/our485/low/', img_val_path='/home/wsz/workspace/Data/LOLdataset/eval15/low/', batch_size=4, lr=0.0001, weight_decay=0, pretrain_dir='/home/wsz/workspace/Illumination-Adaptive-Transformer/IAT_enhance/workdirs/snapshots_folder_lol_v1_patch_unet_weight_220922/best_Epoch.pth', num_epochs=200, display_iter=10, snapshots_folder='workdirs/snapshots_folder_lol_v1_whole_u2net_weight_220923')
Total examples: 485
Total examples: 15
the device is: cuda:0
######## Start IAT Training #########
the epoch is: 0
/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
Traceback (most recent call last):
  File "/home/wsz/workspace/Illumination-Adaptive-Transformer/IAT_enhance/train_lol_v1_whole.py", line 101, in <module>
    mul, add, enhance_img = model(low_img)
  File "/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wsz/workspace/Illumination-Adaptive-Transformer/IAT_enhance/model/IAT_local_U2Net.py", line 125, in forward
    img_high = self.u2net(img_low)
  File "/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wsz/workspace/Illumination-Adaptive-Transformer/IAT_enhance/model/u2net.py", line 508, in forward
    hx1d = self.stage1d(torch.cat((hx2dup,hx1),1))
  File "/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/wsz/workspace/Illumination-Adaptive-Transformer/IAT_enhance/model/u2net.py", line 106, in forward
    return hx1d + hxin
RuntimeError: CUDA out of memory. Tried to allocate 236.00 MiB (GPU 0; 23.70 GiB total capacity; 5.15 GiB already allocated; 197.81 MiB free; 5.28 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
