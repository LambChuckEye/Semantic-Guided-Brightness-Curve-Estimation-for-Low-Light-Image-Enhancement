Namespace(gpu_id=0, img_path='/home/wsz/workspace/Data/LOLdataset/our485_patch/low/', img_val_path='/home/wsz/workspace/Data/LOLdataset/eval15/low/', batch_size=4, lr=0.0002, weight_decay=0, pretrain_dir=None, num_epochs=200, display_iter=10, snapshots_folder='workdirs/snapshots_folder_lol_v1_patch_decom_all_1_20230220')
Total examples: 4850
Total examples: 15
the device is: cuda:0
######## Start IAT Training #########
the epoch is: 0
/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Loss at iteration 10 : 0.08414290845394135
Loss at iteration 20 : 0.08052878081798553
Loss at iteration 30 : 0.04237973317503929
Loss at iteration 40 : 0.03356510400772095
Loss at iteration 50 : 0.05621006712317467
Loss at iteration 60 : 0.045357853174209595
Loss at iteration 70 : 0.03184947371482849
Loss at iteration 80 : 0.03106561303138733
Loss at iteration 90 : 0.030315758660435677
Loss at iteration 100 : 0.027001164853572845
Loss at iteration 110 : 0.03293308615684509
Loss at iteration 120 : 0.034596607089042664
Loss at iteration 130 : 0.03924231976270676
Loss at iteration 140 : 0.03308067470788956
Loss at iteration 150 : 0.02306171879172325
Loss at iteration 160 : 0.03974517434835434
Loss at iteration 170 : 0.03062041476368904
Loss at iteration 180 : 0.039181239902973175
Loss at iteration 190 : 0.025575414299964905
Loss at iteration 200 : 0.031517188996076584
Loss at iteration 210 : 0.03399881348013878
Loss at iteration 220 : 0.03281894698739052
Loss at iteration 230 : 0.02912287414073944
Loss at iteration 240 : 0.04325830936431885
Loss at iteration 250 : 0.039608389139175415
Loss at iteration 260 : 0.043694522231817245
Loss at iteration 270 : 0.026335611939430237
Loss at iteration 280 : 0.03668777272105217
Loss at iteration 290 : 0.03153533488512039
Loss at iteration 300 : 0.037623483687639236
Loss at iteration 310 : 0.025594869628548622
Loss at iteration 320 : 0.042624469846487045
Loss at iteration 330 : 0.041979461908340454
Loss at iteration 340 : 0.03370049595832825
Loss at iteration 350 : 0.02056206949055195
Loss at iteration 360 : 0.02932835929095745
Loss at iteration 370 : 0.02781745046377182
Loss at iteration 380 : 0.02685883641242981
Loss at iteration 390 : 0.02811484783887863
Loss at iteration 400 : 0.03520870953798294
Loss at iteration 410 : 0.03834421932697296
Loss at iteration 420 : 0.022624937817454338
Loss at iteration 430 : 0.019438954070210457
Loss at iteration 440 : 0.032188549637794495
Loss at iteration 450 : 0.01975015550851822
Loss at iteration 460 : 0.019651401787996292
Loss at iteration 470 : 0.03543026000261307
Loss at iteration 480 : 0.03499861806631088
Loss at iteration 490 : 0.027391556650400162
Loss at iteration 500 : 0.02591477707028389
Loss at iteration 510 : 0.03922189772129059
Loss at iteration 520 : 0.03382500261068344
Loss at iteration 530 : 0.037094950675964355
Loss at iteration 540 : 0.03322077542543411
Loss at iteration 550 : 0.021698325872421265
Loss at iteration 560 : 0.027931876480579376
Loss at iteration 570 : 0.03828713297843933
Loss at iteration 580 : 0.016974519938230515
Loss at iteration 590 : 0.02120715007185936
Loss at iteration 600 : 0.020612666383385658
Loss at iteration 610 : 0.018069038167595863
Loss at iteration 620 : 0.03281400352716446
Loss at iteration 630 : 0.034696195274591446
Loss at iteration 640 : 0.023489434272050858
Loss at iteration 650 : 0.020155135542154312
Loss at iteration 660 : 0.032118961215019226
Loss at iteration 670 : 0.031800106167793274
Loss at iteration 680 : 0.028413034975528717
Loss at iteration 690 : 0.01736615225672722
Loss at iteration 700 : 0.02512214332818985
Loss at iteration 710 : 0.021095972508192062
Loss at iteration 720 : 0.024230070412158966
Loss at iteration 730 : 0.03874954581260681
Loss at iteration 740 : 0.025026720017194748
Loss at iteration 750 : 0.040542252361774445
Loss at iteration 760 : 0.03020469658076763
Loss at iteration 770 : 0.04665005952119827
Loss at iteration 780 : 0.029031451791524887
Loss at iteration 790 : 0.02770509384572506
Loss at iteration 800 : 0.026562629267573357
Loss at iteration 810 : 0.038539160043001175
Loss at iteration 820 : 0.031415991485118866
Loss at iteration 830 : 0.025717314332723618
Loss at iteration 840 : 0.042401984333992004
Loss at iteration 850 : 0.031217433512210846
Loss at iteration 860 : 0.022640042006969452
Loss at iteration 870 : 0.01702924445271492
Loss at iteration 880 : 0.027778973802924156
Loss at iteration 890 : 0.022059548646211624
Loss at iteration 900 : 0.02788986824452877
Loss at iteration 910 : 0.025739019736647606
Loss at iteration 920 : 0.02575785294175148
Loss at iteration 930 : 0.02257021889090538
Loss at iteration 940 : 0.02892899699509144
Loss at iteration 950 : 0.01882716827094555
Loss at iteration 960 : 0.021502584218978882
Loss at iteration 970 : 0.018086425960063934
Loss at iteration 980 : 0.01874152384698391
Loss at iteration 990 : 0.024501919746398926
Loss at iteration 1000 : 0.021581249311566353
Loss at iteration 1010 : 0.02428789995610714
Loss at iteration 1020 : 0.02678978070616722
Loss at iteration 1030 : 0.03683226555585861
Loss at iteration 1040 : 0.02304019220173359
Loss at iteration 1050 : 0.022821012884378433
Loss at iteration 1060 : 0.023140786215662956
Loss at iteration 1070 : 0.026709701865911484
Loss at iteration 1080 : 0.027781352400779724
Loss at iteration 1090 : 0.029477817937731743
Loss at iteration 1100 : 0.03413868322968483
Loss at iteration 1110 : 0.025147374719381332
Loss at iteration 1120 : 0.02934917062520981
Loss at iteration 1130 : 0.019313562661409378
Loss at iteration 1140 : 0.01717306673526764
Loss at iteration 1150 : 0.03560657054185867
Loss at iteration 1160 : 0.027111811563372612
Loss at iteration 1170 : 0.02044489234685898
Loss at iteration 1180 : 0.028848212212324142
Loss at iteration 1190 : 0.021181777119636536
Loss at iteration 1200 : 0.02122657746076584
Loss at iteration 1210 : 0.023011839017271996
The SSIM Value is: 0.6876653631528219
The PSNR Value is: 15.286478169759114
the highest SSIM value is: 15.286478169759114
the epoch is: 1
Loss at iteration 10 : 0.017273396253585815
Loss at iteration 20 : 0.022731002420186996
Loss at iteration 30 : 0.026988551020622253
Loss at iteration 40 : 0.02923760749399662
Loss at iteration 50 : 0.027398522943258286
Loss at iteration 60 : 0.023334627971053123
Loss at iteration 70 : 0.02255868911743164
Loss at iteration 80 : 0.024486903101205826
Loss at iteration 90 : 0.018822677433490753
Loss at iteration 100 : 0.032799575477838516
Loss at iteration 110 : 0.012104211375117302
Loss at iteration 120 : 0.01994994468986988
Loss at iteration 130 : 0.014643898233771324
Loss at iteration 140 : 0.025715190917253494
Loss at iteration 150 : 0.02336551994085312
Loss at iteration 160 : 0.01820392534136772
Loss at iteration 170 : 0.02734290435910225
Loss at iteration 180 : 0.018101273104548454
Loss at iteration 190 : 0.026154324412345886
Loss at iteration 200 : 0.020075714215636253
Loss at iteration 210 : 0.024616479873657227
Loss at iteration 220 : 0.013951817527413368
Loss at iteration 230 : 0.019961446523666382
Loss at iteration 240 : 0.023487918078899384
Loss at iteration 250 : 0.020559655502438545
Loss at iteration 260 : 0.026165440678596497
Loss at iteration 270 : 0.01740735024213791
Loss at iteration 280 : 0.026051338762044907
Loss at iteration 290 : 0.027976442128419876
Loss at iteration 300 : 0.02216876670718193
Loss at iteration 310 : 0.017511337995529175
Loss at iteration 320 : 0.018529826775193214
Loss at iteration 330 : 0.030721444636583328
Loss at iteration 340 : 0.021174537017941475
Loss at iteration 350 : 0.019544649869203568
Loss at iteration 360 : 0.022411581128835678
Loss at iteration 370 : 0.031180746853351593
Loss at iteration 380 : 0.01749877817928791
Loss at iteration 390 : 0.019345879554748535
Loss at iteration 400 : 0.027242669835686684
Loss at iteration 410 : 0.037583161145448685
Loss at iteration 420 : 0.029455406591296196
Loss at iteration 430 : 0.018685724586248398
Loss at iteration 440 : 0.014044009149074554
Loss at iteration 450 : 0.01852325350046158
Loss at iteration 460 : 0.03503620624542236
Loss at iteration 470 : 0.03195933625102043
Loss at iteration 480 : 0.039023175835609436
Loss at iteration 490 : 0.015458246693015099
Loss at iteration 500 : 0.024186236783862114
Loss at iteration 510 : 0.03359355032444
Loss at iteration 520 : 0.02090000919997692
Loss at iteration 530 : 0.023380793631076813
Loss at iteration 540 : 0.021820932626724243
Loss at iteration 550 : 0.01427161693572998
Loss at iteration 560 : 0.02319704182446003
Loss at iteration 570 : 0.014052565209567547
Loss at iteration 580 : 0.01803004741668701
Loss at iteration 590 : 0.02351420372724533
Loss at iteration 600 : 0.023951657116413116
Loss at iteration 610 : 0.01985260844230652
Loss at iteration 620 : 0.023646488785743713
Loss at iteration 630 : 0.0162599366158247
Loss at iteration 640 : 0.012709087692201138
Loss at iteration 650 : 0.03163851797580719
Loss at iteration 660 : 0.027374085038900375
Loss at iteration 670 : 0.020017804577946663
Loss at iteration 680 : 0.03090662695467472
Loss at iteration 690 : 0.026409968733787537
Loss at iteration 700 : 0.024378318339586258
Loss at iteration 710 : 0.023434167727828026
Loss at iteration 720 : 0.02702970989048481
Loss at iteration 730 : 0.02909669280052185
Loss at iteration 740 : 0.022590627893805504
Loss at iteration 750 : 0.028101075440645218
Loss at iteration 760 : 0.02333640307188034
Loss at iteration 770 : 0.017322948202490807
Loss at iteration 780 : 0.027565529569983482
Loss at iteration 790 : 0.024828888475894928
Loss at iteration 800 : 0.014599594287574291
Loss at iteration 810 : 0.03164781257510185
Loss at iteration 820 : 0.02652672678232193
Loss at iteration 830 : 0.015312155708670616
Loss at iteration 840 : 0.015279464423656464
Loss at iteration 850 : 0.029233772307634354
Loss at iteration 860 : 0.017261844128370285
Loss at iteration 870 : 0.020773764699697495
Loss at iteration 880 : 0.021385330706834793
Loss at iteration 890 : 0.016302453354001045
Loss at iteration 900 : 0.026479247957468033
Loss at iteration 910 : 0.01447678729891777
Loss at iteration 920 : 0.026827245950698853
Loss at iteration 930 : 0.019655758515000343
Loss at iteration 940 : 0.014724264852702618
Loss at iteration 950 : 0.018461115658283234
Loss at iteration 960 : 0.01915782317519188
Loss at iteration 970 : 0.03687535226345062
Loss at iteration 980 : 0.018909113481640816
Loss at iteration 990 : 0.02659340761601925
Loss at iteration 1000 : 0.024202240630984306
Loss at iteration 1010 : 0.022994089871644974
Loss at iteration 1020 : 0.02939770370721817
Loss at iteration 1030 : 0.03926968201994896
Loss at iteration 1040 : 0.029537705704569817
Loss at iteration 1050 : 0.01592547819018364
Loss at iteration 1060 : 0.02471519075334072
Loss at iteration 1070 : 0.015415159985423088
Loss at iteration 1080 : 0.027027282863855362
Loss at iteration 1090 : 0.013652917928993702
Loss at iteration 1100 : 0.021592292934656143
Loss at iteration 1110 : 0.024183563888072968
Loss at iteration 1120 : 0.026168853044509888
Loss at iteration 1130 : 0.015961356461048126
Loss at iteration 1140 : 0.018291685730218887
Loss at iteration 1150 : 0.010089620016515255
Loss at iteration 1160 : 0.021453790366649628
Loss at iteration 1170 : 0.016857407987117767
Loss at iteration 1180 : 0.022237839177250862
Loss at iteration 1190 : 0.017992055043578148
Loss at iteration 1200 : 0.017863474786281586
Loss at iteration 1210 : 0.018403802067041397
The SSIM Value is: 0.7150792558987935
The PSNR Value is: 16.254851468404134
the highest SSIM value is: 16.254851468404134
the epoch is: 2
Loss at iteration 10 : 0.017764350399374962
Loss at iteration 20 : 0.011758018285036087
Loss at iteration 30 : 0.019448351114988327
Loss at iteration 40 : 0.03040168806910515
Loss at iteration 50 : 0.03418416529893875
Loss at iteration 60 : 0.017470775172114372
Loss at iteration 70 : 0.024959806352853775
Loss at iteration 80 : 0.018694095313549042
Loss at iteration 90 : 0.009942689910531044
Loss at iteration 100 : 0.019456684589385986
Loss at iteration 110 : 0.01757807657122612
Loss at iteration 120 : 0.01859508641064167
Loss at iteration 130 : 0.02083396166563034
Loss at iteration 140 : 0.023314885795116425
Loss at iteration 150 : 0.014837394468486309
Loss at iteration 160 : 0.013910378329455853
Loss at iteration 170 : 0.023440256714820862
Loss at iteration 180 : 0.01930311694741249
Loss at iteration 190 : 0.031049877405166626
Loss at iteration 200 : 0.015095297247171402
Loss at iteration 210 : 0.020101934671401978
Loss at iteration 220 : 0.02470085769891739
Loss at iteration 230 : 0.01595395803451538
Loss at iteration 240 : 0.022859176620841026
Loss at iteration 250 : 0.024841755628585815
Loss at iteration 260 : 0.019684888422489166
Loss at iteration 270 : 0.017905425280332565
Loss at iteration 280 : 0.01715254969894886
Loss at iteration 290 : 0.01564437337219715
Loss at iteration 300 : 0.013363798148930073
Loss at iteration 310 : 0.021783044561743736
Loss at iteration 320 : 0.0283017847687006
Loss at iteration 330 : 0.01648826338350773
Loss at iteration 340 : 0.025115564465522766
Loss at iteration 350 : 0.030928142368793488
Loss at iteration 360 : 0.022186368703842163
Loss at iteration 370 : 0.013289429247379303
Loss at iteration 380 : 0.017967641353607178
Loss at iteration 390 : 0.015936361625790596
Loss at iteration 400 : 0.021921927109360695
Loss at iteration 410 : 0.015907196328043938
Loss at iteration 420 : 0.014308186247944832
Loss at iteration 430 : 0.01824093982577324
Loss at iteration 440 : 0.01128675788640976
Loss at iteration 450 : 0.023489464074373245
Loss at iteration 460 : 0.022926997393369675
Loss at iteration 470 : 0.018997706472873688
Loss at iteration 480 : 0.021522358059883118
Loss at iteration 490 : 0.019419586285948753
Loss at iteration 500 : 0.0183977410197258
Loss at iteration 510 : 0.02114611119031906
Loss at iteration 520 : 0.009656072594225407
Loss at iteration 530 : 0.017641231417655945
Loss at iteration 540 : 0.030788298696279526
Loss at iteration 550 : 0.03835185617208481
Loss at iteration 560 : 0.021826889365911484
Loss at iteration 570 : 0.02429799735546112
Loss at iteration 580 : 0.020956212654709816
Loss at iteration 590 : 0.02496141940355301
Loss at iteration 600 : 0.02647768147289753
Loss at iteration 610 : 0.01921655982732773
Loss at iteration 620 : 0.016440626233816147
Loss at iteration 630 : 0.025552604347467422
Loss at iteration 640 : 0.017268545925617218
Loss at iteration 650 : 0.02718926966190338
Loss at iteration 660 : 0.017988266423344612
Loss at iteration 670 : 0.020107798278331757
Loss at iteration 680 : 0.021953582763671875
Loss at iteration 690 : 0.018514379858970642
Loss at iteration 700 : 0.0196841973811388
Loss at iteration 710 : 0.017127953469753265
Loss at iteration 720 : 0.018505096435546875
Loss at iteration 730 : 0.03494871407747269
Loss at iteration 740 : 0.015119143761694431
Loss at iteration 750 : 0.01621592417359352
Loss at iteration 760 : 0.031498126685619354
Loss at iteration 770 : 0.020187396556138992
Loss at iteration 780 : 0.01726810820400715
Loss at iteration 790 : 0.022157149389386177
Loss at iteration 800 : 0.020265161991119385
Loss at iteration 810 : 0.013707167468965054
Loss at iteration 820 : 0.013905011117458344
Loss at iteration 830 : 0.019540444016456604
Loss at iteration 840 : 0.01552044041454792
Loss at iteration 850 : 0.01767110452055931
Loss at iteration 860 : 0.020090438425540924
Loss at iteration 870 : 0.019990909844636917
Loss at iteration 880 : 0.020862095057964325
Loss at iteration 890 : 0.012747676111757755
Loss at iteration 900 : 0.016568824648857117
Loss at iteration 910 : 0.01390860602259636
Loss at iteration 920 : 0.02195437066257
Loss at iteration 930 : 0.01894925907254219
Loss at iteration 940 : 0.014791421592235565
Loss at iteration 950 : 0.0255131758749485
Loss at iteration 960 : 0.014179267920553684
Loss at iteration 970 : 0.020934026688337326
Loss at iteration 980 : 0.02199232205748558
Loss at iteration 990 : 0.01032936666160822
Loss at iteration 1000 : 0.0155616020783782
Loss at iteration 1010 : 0.00885204691439867
Loss at iteration 1020 : 0.0131148686632514
Loss at iteration 1030 : 0.010963814333081245
Loss at iteration 1040 : 0.028687627986073494
Loss at iteration 1050 : 0.018747281283140182
Loss at iteration 1060 : 0.017979897558689117
Loss at iteration 1070 : 0.016064930707216263
Loss at iteration 1080 : 0.02290809154510498
Loss at iteration 1090 : 0.01966359093785286
Loss at iteration 1100 : 0.0216330885887146
Loss at iteration 1110 : 0.01839146949350834
Loss at iteration 1120 : 0.02067445032298565
Loss at iteration 1130 : 0.021599404513835907
Loss at iteration 1140 : 0.014075914397835732
Loss at iteration 1150 : 0.025054462254047394
Loss at iteration 1160 : 0.02338734269142151
Loss at iteration 1170 : 0.0222038421779871
Loss at iteration 1180 : 0.013806283473968506
Loss at iteration 1190 : 0.019728856161236763
Loss at iteration 1200 : 0.013977300375699997
Loss at iteration 1210 : 0.031240351498126984
The SSIM Value is: 0.7315580109755199
The PSNR Value is: 15.903089141845703
the epoch is: 3
Loss at iteration 10 : 0.03526880592107773
Loss at iteration 20 : 0.03284536302089691
Loss at iteration 30 : 0.025759894400835037
Loss at iteration 40 : 0.016851892694830894
Loss at iteration 50 : 0.01675829105079174
Loss at iteration 60 : 0.018079517409205437
Loss at iteration 70 : 0.025376908481121063
Loss at iteration 80 : 0.010547117330133915
Loss at iteration 90 : 0.02115936577320099
Loss at iteration 100 : 0.019058268517255783
Loss at iteration 110 : 0.01637023687362671
Loss at iteration 120 : 0.012106113135814667
Loss at iteration 130 : 0.011693427339196205
Loss at iteration 140 : 0.02288898639380932
Loss at iteration 150 : 0.015698403120040894
Loss at iteration 160 : 0.012395266443490982
Loss at iteration 170 : 0.02020920440554619
Loss at iteration 180 : 0.016598699614405632
Loss at iteration 190 : 0.021010860800743103
Loss at iteration 200 : 0.026056509464979172
Loss at iteration 210 : 0.023601366207003593
Loss at iteration 220 : 0.020347818732261658
Loss at iteration 230 : 0.01566450297832489
Loss at iteration 240 : 0.015803689137101173
Loss at iteration 250 : 0.011719303205609322
Loss at iteration 260 : 0.01423373818397522
Loss at iteration 270 : 0.020087359473109245
Loss at iteration 280 : 0.02333999052643776
Loss at iteration 290 : 0.014114066027104855
Loss at iteration 300 : 0.014373337849974632
Loss at iteration 310 : 0.02139773964881897
Loss at iteration 320 : 0.01832815259695053
Loss at iteration 330 : 0.014728846959769726
Loss at iteration 340 : 0.012760300189256668
Loss at iteration 350 : 0.015447158366441727
Loss at iteration 360 : 0.01824081689119339
Loss at iteration 370 : 0.010976574383676052
Loss at iteration 380 : 0.025326905772089958
Loss at iteration 390 : 0.01596849039196968
Loss at iteration 400 : 0.01471630297601223
Loss at iteration 410 : 0.018277136608958244
Loss at iteration 420 : 0.024717573076486588
Loss at iteration 430 : 0.03270525112748146
Loss at iteration 440 : 0.013994911685585976
Loss at iteration 450 : 0.015261072665452957
Loss at iteration 460 : 0.023987118154764175
Loss at iteration 470 : 0.015380721539258957
Loss at iteration 480 : 0.012727108784019947
Loss at iteration 490 : 0.018661456182599068
Loss at iteration 500 : 0.01735825464129448
Loss at iteration 510 : 0.02074214443564415
Loss at iteration 520 : 0.014761967584490776
Loss at iteration 530 : 0.022864429280161858
Loss at iteration 540 : 0.023537032306194305
Loss at iteration 550 : 0.018616944551467896
Loss at iteration 560 : 0.018766149878501892
Loss at iteration 570 : 0.018806137144565582
Loss at iteration 580 : 0.020742012187838554
Loss at iteration 590 : 0.011578965000808239
Loss at iteration 600 : 0.01763889566063881
Loss at iteration 610 : 0.021070590242743492
Loss at iteration 620 : 0.020763378590345383
Loss at iteration 630 : 0.020929260179400444
Loss at iteration 640 : 0.011444826610386372
Loss at iteration 650 : 0.015547774732112885
Loss at iteration 660 : 0.01928657293319702
Loss at iteration 670 : 0.024533016607165337
Loss at iteration 680 : 0.01765979267656803
Loss at iteration 690 : 0.02529100701212883
Loss at iteration 700 : 0.012199997901916504
Loss at iteration 710 : 0.019701335579156876
Loss at iteration 720 : 0.01004380639642477
Loss at iteration 730 : 0.01775311306118965
Loss at iteration 740 : 0.025036778301000595
Loss at iteration 750 : 0.0216161347925663
Loss at iteration 760 : 0.01340415794402361
Loss at iteration 770 : 0.015506729483604431
Loss at iteration 780 : 0.036637358367443085
Loss at iteration 790 : 0.026903605088591576
Loss at iteration 800 : 0.025763370096683502
Loss at iteration 810 : 0.0258115753531456
Loss at iteration 820 : 0.018985077738761902
Loss at iteration 830 : 0.012868274934589863
Loss at iteration 840 : 0.01896754652261734
Loss at iteration 850 : 0.01740361750125885
Loss at iteration 860 : 0.015772409737110138
Loss at iteration 870 : 0.041670411825180054
Loss at iteration 880 : 0.01554427482187748
Loss at iteration 890 : 0.016414763405919075
Loss at iteration 900 : 0.022976212203502655
Loss at iteration 910 : 0.026313958689570427
Loss at iteration 920 : 0.019352607429027557
Loss at iteration 930 : 0.013102419674396515
Loss at iteration 940 : 0.026943759992718697
Loss at iteration 950 : 0.012784741818904877
Loss at iteration 960 : 0.015211300924420357
Loss at iteration 970 : 0.027642864733934402
Loss at iteration 980 : 0.01311018131673336
Loss at iteration 990 : 0.01950932666659355
Loss at iteration 1000 : 0.01261320523917675
Loss at iteration 1010 : 0.017206130549311638
Loss at iteration 1020 : 0.027659039944410324
Loss at iteration 1030 : 0.01860099658370018
Loss at iteration 1040 : 0.024585172533988953
Loss at iteration 1050 : 0.016581706702709198
Loss at iteration 1060 : 0.018742799758911133
Loss at iteration 1070 : 0.012951659969985485
Loss at iteration 1080 : 0.024913661181926727
Loss at iteration 1090 : 0.012690834701061249
Loss at iteration 1100 : 0.020689692348241806
Loss at iteration 1110 : 0.021299157291650772
Loss at iteration 1120 : 0.02413027174770832
Loss at iteration 1130 : 0.0132487453520298
Loss at iteration 1140 : 0.014575507491827011
Loss at iteration 1150 : 0.02379046194255352
Loss at iteration 1160 : 0.017367500811815262
Loss at iteration 1170 : 0.03945235535502434
Loss at iteration 1180 : 0.01553529966622591
Loss at iteration 1190 : 0.01502079889178276
Loss at iteration 1200 : 0.03468761220574379
Loss at iteration 1210 : 0.02492954581975937
The SSIM Value is: 0.7217311004797617
The PSNR Value is: 16.18822100957235
the epoch is: 4
Loss at iteration 10 : 0.010804830119013786
Loss at iteration 20 : 0.01928878016769886
Loss at iteration 30 : 0.015854161232709885
Loss at iteration 40 : 0.030081069096922874
Loss at iteration 50 : 0.017943967133760452
Loss at iteration 60 : 0.016950801014900208
Loss at iteration 70 : 0.01824977435171604
Loss at iteration 80 : 0.017272336408495903
Loss at iteration 90 : 0.02180144377052784
Loss at iteration 100 : 0.01941261813044548
Loss at iteration 110 : 0.009453260339796543
Loss at iteration 120 : 0.012940497137606144
Loss at iteration 130 : 0.0174508485943079
Loss at iteration 140 : 0.014874684624373913
Loss at iteration 150 : 0.008542630821466446
Loss at iteration 160 : 0.019168280065059662
Loss at iteration 170 : 0.03127065300941467
Loss at iteration 180 : 0.011396590620279312
Loss at iteration 190 : 0.022563941776752472
Loss at iteration 200 : 0.011327942833304405
Loss at iteration 210 : 0.018024124205112457
Loss at iteration 220 : 0.028660066425800323
Loss at iteration 230 : 0.023366104811429977
Loss at iteration 240 : 0.020133988931775093
Loss at iteration 250 : 0.02397497370839119
Loss at iteration 260 : 0.016227705404162407
Loss at iteration 270 : 0.023398660123348236
Loss at iteration 280 : 0.018322547897696495
Loss at iteration 290 : 0.013314696960151196
Loss at iteration 300 : 0.016376212239265442
Loss at iteration 310 : 0.017918966710567474
Loss at iteration 320 : 0.014935711398720741
Loss at iteration 330 : 0.025100665166974068
Loss at iteration 340 : 0.017773672938346863
Loss at iteration 350 : 0.019351599738001823
Loss at iteration 360 : 0.015603475272655487
Loss at iteration 370 : 0.01623505912721157
Loss at iteration 380 : 0.018604524433612823
Loss at iteration 390 : 0.017020758241415024
Loss at iteration 400 : 0.01973673515021801
Loss at iteration 410 : 0.01415100134909153
Loss at iteration 420 : 0.014492053538560867
Loss at iteration 430 : 0.025265589356422424
Loss at iteration 440 : 0.018113868311047554
Loss at iteration 450 : 0.022980593144893646
Loss at iteration 460 : 0.018849868327379227
Loss at iteration 470 : 0.010795876383781433
Loss at iteration 480 : 0.02071394957602024
Loss at iteration 490 : 0.01353483833372593
Loss at iteration 500 : 0.019180959090590477
Loss at iteration 510 : 0.020864738151431084
Loss at iteration 520 : 0.020643575116991997
Loss at iteration 530 : 0.014012832194566727
Loss at iteration 540 : 0.022547174245119095
Loss at iteration 550 : 0.023820333182811737
Loss at iteration 560 : 0.01175415888428688
Loss at iteration 570 : 0.012754278257489204
Loss at iteration 580 : 0.013940012082457542
Loss at iteration 590 : 0.0156082883477211
Loss at iteration 600 : 0.012250203639268875
Loss at iteration 610 : 0.0177125446498394
Loss at iteration 620 : 0.015130403451621532
Loss at iteration 630 : 0.020329516381025314
Loss at iteration 640 : 0.014459979720413685
Loss at iteration 650 : 0.028819076716899872
Loss at iteration 660 : 0.017560360953211784
Loss at iteration 670 : 0.018307862803339958
Loss at iteration 680 : 0.017843622714281082
Loss at iteration 690 : 0.01741693913936615
Loss at iteration 700 : 0.017905879765748978
Loss at iteration 710 : 0.020346321165561676
Loss at iteration 720 : 0.022407852113246918
Loss at iteration 730 : 0.017728378996253014
Loss at iteration 740 : 0.02698703482747078
Loss at iteration 750 : 0.01766015775501728
Loss at iteration 760 : 0.01900242641568184
Loss at iteration 770 : 0.016720136627554893
Loss at iteration 780 : 0.026328789070248604
Loss at iteration 790 : 0.027377866208553314
Loss at iteration 800 : 0.019829969853162766
Loss at iteration 810 : 0.012866947799921036
Loss at iteration 820 : 0.014681275933980942
Loss at iteration 830 : 0.013571668416261673
Loss at iteration 840 : 0.020693091675639153
Loss at iteration 850 : 0.022379253059625626
Loss at iteration 860 : 0.020037930458784103
Loss at iteration 870 : 0.012240340001881123
Loss at iteration 880 : 0.021669205278158188
Loss at iteration 890 : 0.014745448715984821
Loss at iteration 900 : 0.020762108266353607
Loss at iteration 910 : 0.020085591822862625
Loss at iteration 920 : 0.021600637584924698
Loss at iteration 930 : 0.009695122949779034
Loss at iteration 940 : 0.017047662287950516
Loss at iteration 950 : 0.0261104516685009
Loss at iteration 960 : 0.013610896654427052
Loss at iteration 970 : 0.020711835473775864
Loss at iteration 980 : 0.016882477328181267
Loss at iteration 990 : 0.02439769357442856
Loss at iteration 1000 : 0.007481683976948261
Loss at iteration 1010 : 0.015389765612781048
Loss at iteration 1020 : 0.0362083725631237
Loss at iteration 1030 : 0.015083467587828636
Loss at iteration 1040 : 0.017898671329021454
Loss at iteration 1050 : 0.01571931317448616
Loss at iteration 1060 : 0.01373022049665451
Loss at iteration 1070 : 0.02866467460989952
Loss at iteration 1080 : 0.017745353281497955
Loss at iteration 1090 : 0.022260211408138275
Loss at iteration 1100 : 0.02397482469677925
Loss at iteration 1110 : 0.015682313591241837
Loss at iteration 1120 : 0.01577180251479149
Loss at iteration 1130 : 0.012786928564310074
Loss at iteration 1140 : 0.017832046374678612
Loss at iteration 1150 : 0.028484970331192017
Loss at iteration 1160 : 0.01827066019177437
Loss at iteration 1170 : 0.022081799805164337
Loss at iteration 1180 : 0.022595226764678955
Loss at iteration 1190 : 0.01634189859032631
Loss at iteration 1200 : 0.010415478609502316
Loss at iteration 1210 : 0.01972252130508423
The SSIM Value is: 0.7946513652801513
The PSNR Value is: 18.532647959391277
the highest SSIM value is: 18.532647959391277
the epoch is: 5
Loss at iteration 10 : 0.018605291843414307
Loss at iteration 20 : 0.02592078223824501
Loss at iteration 30 : 0.014860530383884907
Loss at iteration 40 : 0.015493283048272133
Loss at iteration 50 : 0.012306861579418182
Loss at iteration 60 : 0.020541060715913773
Loss at iteration 70 : 0.018173618242144585
Loss at iteration 80 : 0.017516257241368294
Loss at iteration 90 : 0.03357448801398277
Loss at iteration 100 : 0.020878203213214874
Loss at iteration 110 : 0.019577430561184883
Loss at iteration 120 : 0.01166531816124916
Loss at iteration 130 : 0.0254206545650959
Loss at iteration 140 : 0.00889468751847744
Loss at iteration 150 : 0.019753726199269295
Loss at iteration 160 : 0.025135252624750137
Loss at iteration 170 : 0.02735782414674759
Loss at iteration 180 : 0.017108766362071037
Loss at iteration 190 : 0.020165197551250458
Loss at iteration 200 : 0.01383909396827221
Loss at iteration 210 : 0.017013072967529297
Loss at iteration 220 : 0.019811049103736877
Loss at iteration 230 : 0.01331581175327301
Loss at iteration 240 : 0.012054004706442356
Loss at iteration 250 : 0.01516743190586567
Loss at iteration 260 : 0.01658981293439865
Loss at iteration 270 : 0.01409217994660139
Loss at iteration 280 : 0.011961212381720543
Loss at iteration 290 : 0.025442807003855705
Loss at iteration 300 : 0.029410921037197113
Loss at iteration 310 : 0.022932404652237892
Loss at iteration 320 : 0.013832694850862026
Loss at iteration 330 : 0.017185918986797333
Loss at iteration 340 : 0.01900172233581543
Loss at iteration 350 : 0.010604683309793472
Loss at iteration 360 : 0.02287384867668152
Loss at iteration 370 : 0.014006269164383411
Loss at iteration 380 : 0.016501616686582565
Loss at iteration 390 : 0.023104127496480942
Loss at iteration 400 : 0.01552370935678482
Loss at iteration 410 : 0.01728197932243347
Loss at iteration 420 : 0.02766506001353264
Loss at iteration 430 : 0.01693185605108738
Loss at iteration 440 : 0.01495154108852148
Loss at iteration 450 : 0.024340637028217316
Loss at iteration 460 : 0.022701233625411987
Loss at iteration 470 : 0.00815631728619337
Loss at iteration 480 : 0.01861678622663021
Loss at iteration 490 : 0.020872898399829865
Loss at iteration 500 : 0.018891099840402603
Loss at iteration 510 : 0.013642699457705021
Loss at iteration 520 : 0.021994706243276596
Loss at iteration 530 : 0.015645503997802734
Loss at iteration 540 : 0.02081051841378212
Loss at iteration 550 : 0.014052281156182289
Loss at iteration 560 : 0.020942561328411102
Loss at iteration 570 : 0.015913158655166626
Loss at iteration 580 : 0.017140397801995277
Loss at iteration 590 : 0.021567150950431824
Loss at iteration 600 : 0.018888462334871292
Loss at iteration 610 : 0.016048913821578026
Loss at iteration 620 : 0.01696930080652237
Loss at iteration 630 : 0.022412149235606194
Loss at iteration 640 : 0.015085454098880291
Loss at iteration 650 : 0.03758692741394043
Loss at iteration 660 : 0.024504393339157104
Loss at iteration 670 : 0.00970297958701849
Loss at iteration 680 : 0.015491864643990993
Loss at iteration 690 : 0.011116322129964828
Loss at iteration 700 : 0.019161993637681007
Loss at iteration 710 : 0.034342046827077866
Loss at iteration 720 : 0.016707953065633774
Loss at iteration 730 : 0.02854391746222973
Loss at iteration 740 : 0.01970486342906952
Loss at iteration 750 : 0.019588902592658997
Loss at iteration 760 : 0.01572505384683609
Loss at iteration 770 : 0.01342608593404293
Loss at iteration 780 : 0.022223617881536484
Loss at iteration 790 : 0.028781909495592117
Loss at iteration 800 : 0.019397826865315437
Loss at iteration 810 : 0.016805944964289665
Loss at iteration 820 : 0.010747556574642658
Loss at iteration 830 : 0.012288866564631462
Loss at iteration 840 : 0.01700420118868351
Loss at iteration 850 : 0.02743789367377758
Loss at iteration 860 : 0.01400410570204258
Loss at iteration 870 : 0.02345208451151848
Loss at iteration 880 : 0.011597669683396816
Loss at iteration 890 : 0.01479972805827856
Loss at iteration 900 : 0.012416288256645203
Loss at iteration 910 : 0.012337420135736465
Loss at iteration 920 : 0.02117537334561348
Loss at iteration 930 : 0.01777968369424343
Loss at iteration 940 : 0.03239249065518379
Loss at iteration 950 : 0.017306940630078316
Loss at iteration 960 : 0.020951399579644203
Loss at iteration 970 : 0.011500922031700611
Loss at iteration 980 : 0.010668200440704823
Loss at iteration 990 : 0.018667643889784813
Loss at iteration 1000 : 0.01865808665752411
Loss at iteration 1010 : 0.015109731815755367
Loss at iteration 1020 : 0.018555298447608948
Loss at iteration 1030 : 0.0171106718480587
Loss at iteration 1040 : 0.01777757704257965
Loss at iteration 1050 : 0.023071011528372765
Loss at iteration 1060 : 0.020543968304991722
Loss at iteration 1070 : 0.019198058173060417
Loss at iteration 1080 : 0.01719423569738865
Loss at iteration 1090 : 0.014267448335886002
Loss at iteration 1100 : 0.017138410359621048
Loss at iteration 1110 : 0.015134340152144432
Loss at iteration 1120 : 0.014550533145666122
Loss at iteration 1130 : 0.013482407666742802
Loss at iteration 1140 : 0.015203243121504784
Loss at iteration 1150 : 0.025506557896733284
Loss at iteration 1160 : 0.018324080854654312
Loss at iteration 1170 : 0.012469474226236343
Loss at iteration 1180 : 0.025686590000987053
Loss at iteration 1190 : 0.012765134684741497
Loss at iteration 1200 : 0.020208340138196945
Loss at iteration 1210 : 0.017595525830984116
The SSIM Value is: 0.7573709527651469
The PSNR Value is: 16.31458307902018
the epoch is: 6
Loss at iteration 10 : 0.04159140586853027
Loss at iteration 20 : 0.016561221331357956
Loss at iteration 30 : 0.02368171513080597
Loss at iteration 40 : 0.02631761133670807
Loss at iteration 50 : 0.032054319977760315
Loss at iteration 60 : 0.013997205533087254
Loss at iteration 70 : 0.016096387058496475
Loss at iteration 80 : 0.01617087423801422
Loss at iteration 90 : 0.01771005243062973
Loss at iteration 100 : 0.0268850140273571
Loss at iteration 110 : 0.021906515583395958
Loss at iteration 120 : 0.02059810608625412
Loss at iteration 130 : 0.022777125239372253
Loss at iteration 140 : 0.01538349874317646
Loss at iteration 150 : 0.009948350489139557
Loss at iteration 160 : 0.01764671504497528
Loss at iteration 170 : 0.009955032728612423
Loss at iteration 180 : 0.01356531586498022
Loss at iteration 190 : 0.022241683676838875
Loss at iteration 200 : 0.009415529668331146
Loss at iteration 210 : 0.018709708005189896
Loss at iteration 220 : 0.015191350132226944
Loss at iteration 230 : 0.023551931604743004
Loss at iteration 240 : 0.020189184695482254
Loss at iteration 250 : 0.018694452941417694
Loss at iteration 260 : 0.01810433715581894
Loss at iteration 270 : 0.023280151188373566
Loss at iteration 280 : 0.01908491551876068
Loss at iteration 290 : 0.0252207200974226
Loss at iteration 300 : 0.017168719321489334
Loss at iteration 310 : 0.019007381051778793
Loss at iteration 320 : 0.01255700271576643
Loss at iteration 330 : 0.01212000660598278
Loss at iteration 340 : 0.01732904277741909
Loss at iteration 350 : 0.01413970347493887
Loss at iteration 360 : 0.023207560181617737
Loss at iteration 370 : 0.01656871661543846
Loss at iteration 380 : 0.020807597786188126
Loss at iteration 390 : 0.01690027490258217
Loss at iteration 400 : 0.01416173204779625
Loss at iteration 410 : 0.01287621259689331
Loss at iteration 420 : 0.021026261150836945
Loss at iteration 430 : 0.019468948245048523
Loss at iteration 440 : 0.010584046132862568
Loss at iteration 450 : 0.02849893644452095
Loss at iteration 460 : 0.015848036855459213
Loss at iteration 470 : 0.017219211906194687
Loss at iteration 480 : 0.010976281017065048
Loss at iteration 490 : 0.020205136388540268
Loss at iteration 500 : 0.025641538202762604
Loss at iteration 510 : 0.027848917990922928
Loss at iteration 520 : 0.01381651870906353
Loss at iteration 530 : 0.012465443462133408
Loss at iteration 540 : 0.016265634447336197
Loss at iteration 550 : 0.013796178624033928
Loss at iteration 560 : 0.031030990183353424
Loss at iteration 570 : 0.0251888707280159
Loss at iteration 580 : 0.01862940937280655
Loss at iteration 590 : 0.020554834976792336
Loss at iteration 600 : 0.025570575147867203
Loss at iteration 610 : 0.01381345372647047
Loss at iteration 620 : 0.015406925231218338
Loss at iteration 630 : 0.014985784888267517
Loss at iteration 640 : 0.014988605864346027
Loss at iteration 650 : 0.019900597631931305
Loss at iteration 660 : 0.017602287232875824
Loss at iteration 670 : 0.018350254744291306
Loss at iteration 680 : 0.012571079656481743
Loss at iteration 690 : 0.01923164539039135
Loss at iteration 700 : 0.018863409757614136
Loss at iteration 710 : 0.01958348974585533
Loss at iteration 720 : 0.013711616396903992
Loss at iteration 730 : 0.015010740607976913
Loss at iteration 740 : 0.024917881935834885
Loss at iteration 750 : 0.0248684324324131
Loss at iteration 760 : 0.01973669044673443
Loss at iteration 770 : 0.017496274784207344
Loss at iteration 780 : 0.024920623749494553
Loss at iteration 790 : 0.025243178009986877
Loss at iteration 800 : 0.01697593182325363
Loss at iteration 810 : 0.01795230433344841
Loss at iteration 820 : 0.02059835195541382
Loss at iteration 830 : 0.010625137016177177
Loss at iteration 840 : 0.012346840463578701
Loss at iteration 850 : 0.011820938438177109
Loss at iteration 860 : 0.01592876762151718
Loss at iteration 870 : 0.012096961960196495
Loss at iteration 880 : 0.018860626965761185
Loss at iteration 890 : 0.013075161725282669
Loss at iteration 900 : 0.03640271723270416
Loss at iteration 910 : 0.009572302922606468
Loss at iteration 920 : 0.012848136946558952
Loss at iteration 930 : 0.021575896069407463
Loss at iteration 940 : 0.010171562433242798
Loss at iteration 950 : 0.014208929613232613
Loss at iteration 960 : 0.008626333437860012
Loss at iteration 970 : 0.012801957316696644
Loss at iteration 980 : 0.014354364946484566
Loss at iteration 990 : 0.021752452477812767
Loss at iteration 1000 : 0.015444469638168812
Loss at iteration 1010 : 0.020293166860938072
Loss at iteration 1020 : 0.01378159411251545
Loss at iteration 1030 : 0.01878836192190647
Loss at iteration 1040 : 0.011749633587896824
Loss at iteration 1050 : 0.017782241106033325
Loss at iteration 1060 : 0.012639562599360943
Loss at iteration 1070 : 0.02546854317188263
Loss at iteration 1080 : 0.014964813366532326
Loss at iteration 1090 : 0.013686737976968288
Loss at iteration 1100 : 0.013389765284955502
Loss at iteration 1110 : 0.01896873489022255
Loss at iteration 1120 : 0.022588826715946198
Loss at iteration 1130 : 0.019963383674621582
Loss at iteration 1140 : 0.024463851004838943
Loss at iteration 1150 : 0.016682248562574387
Loss at iteration 1160 : 0.01936344988644123
Loss at iteration 1170 : 0.013922753743827343
Loss at iteration 1180 : 0.014874382875859737
Loss at iteration 1190 : 0.01531376875936985
Loss at iteration 1200 : 0.016368694603443146
Loss at iteration 1210 : 0.022993814200162888
The SSIM Value is: 0.7836360335350037
The PSNR Value is: 17.448652521769205
the epoch is: 7
Loss at iteration 10 : 0.018666978925466537
Loss at iteration 20 : 0.01809713989496231
Loss at iteration 30 : 0.015266265720129013
Loss at iteration 40 : 0.018265241757035255
Loss at iteration 50 : 0.017552001401782036
Loss at iteration 60 : 0.016395021229982376
Loss at iteration 70 : 0.018289152532815933
Loss at iteration 80 : 0.012526452541351318
Loss at iteration 90 : 0.013477887958288193
Loss at iteration 100 : 0.01791439764201641
Loss at iteration 110 : 0.017066406086087227
Loss at iteration 120 : 0.01255366113036871
Loss at iteration 130 : 0.016492819413542747
Loss at iteration 140 : 0.020033912733197212
Loss at iteration 150 : 0.01766975224018097
Loss at iteration 160 : 0.023166337981820107
Loss at iteration 170 : 0.018942251801490784
Loss at iteration 180 : 0.013921212404966354
Loss at iteration 190 : 0.017375383526086807
Loss at iteration 200 : 0.01174997165799141
Loss at iteration 210 : 0.015218301676213741
Loss at iteration 220 : 0.0051896097138524055
Loss at iteration 230 : 0.014171961694955826
Loss at iteration 240 : 0.019365742802619934
Loss at iteration 250 : 0.026715528219938278
Loss at iteration 260 : 0.014773618429899216
Loss at iteration 270 : 0.013388467952609062
Loss at iteration 280 : 0.01455262117087841
Loss at iteration 290 : 0.021549057215452194
Loss at iteration 300 : 0.01584673300385475
Loss at iteration 310 : 0.023013677448034286
Loss at iteration 320 : 0.018125414848327637
Loss at iteration 330 : 0.015843374654650688
Loss at iteration 340 : 0.018408238887786865
Loss at iteration 350 : 0.019569050520658493
Loss at iteration 360 : 0.008256730623543262
Loss at iteration 370 : 0.010512905195355415
Loss at iteration 380 : 0.016411174088716507
Loss at iteration 390 : 0.016910288482904434
Loss at iteration 400 : 0.02251378633081913
Loss at iteration 410 : 0.013891661539673805
Loss at iteration 420 : 0.01831083744764328
Loss at iteration 430 : 0.013887863606214523
Loss at iteration 440 : 0.012632651254534721
Loss at iteration 450 : 0.02001018263399601
Loss at iteration 460 : 0.02157801389694214
Loss at iteration 470 : 0.01206835638731718
Loss at iteration 480 : 0.014281496405601501
Loss at iteration 490 : 0.029310066252946854
Loss at iteration 500 : 0.01608114130795002
Loss at iteration 510 : 0.01511340867727995
Loss at iteration 520 : 0.011121643707156181
Loss at iteration 530 : 0.023013196885585785
Loss at iteration 540 : 0.027651570737361908
Loss at iteration 550 : 0.015436635352671146
Loss at iteration 560 : 0.016863681375980377
Loss at iteration 570 : 0.013104134239256382
Loss at iteration 580 : 0.01033792831003666
Loss at iteration 590 : 0.014074109494686127
Loss at iteration 600 : 0.015387031249701977
Loss at iteration 610 : 0.01524733193218708
Loss at iteration 620 : 0.017863091081380844
Loss at iteration 630 : 0.025155065581202507
Loss at iteration 640 : 0.011126942001283169
Loss at iteration 650 : 0.016652807593345642
Loss at iteration 660 : 0.013831776566803455
Loss at iteration 670 : 0.010529126040637493
Loss at iteration 680 : 0.01818629540503025
Loss at iteration 690 : 0.012570366263389587
Loss at iteration 700 : 0.01665605418384075
Loss at iteration 710 : 0.016016492620110512
Loss at iteration 720 : 0.016797706484794617
Loss at iteration 730 : 0.017325319349765778
Loss at iteration 740 : 0.015149170532822609
Loss at iteration 750 : 0.01680717058479786
Loss at iteration 760 : 0.012174880132079124
Loss at iteration 770 : 0.02156170643866062
Loss at iteration 780 : 0.020467622205615044
Loss at iteration 790 : 0.012572863139212132
Loss at iteration 800 : 0.026370003819465637
Loss at iteration 810 : 0.019868135452270508
Loss at iteration 820 : 0.015565410256385803
Loss at iteration 830 : 0.023221205919981003
Loss at iteration 840 : 0.017391089349985123
Loss at iteration 850 : 0.013988462276756763
Loss at iteration 860 : 0.018804941326379776
Loss at iteration 870 : 0.0275166854262352
Loss at iteration 880 : 0.013524627313017845
Loss at iteration 890 : 0.017758483067154884
Loss at iteration 900 : 0.01525163371115923
Loss at iteration 910 : 0.0164138562977314
Loss at iteration 920 : 0.013210801407694817
Loss at iteration 930 : 0.021334348246455193
Loss at iteration 940 : 0.01770630106329918
Loss at iteration 950 : 0.00721585052087903
Loss at iteration 960 : 0.010035218670964241
Loss at iteration 970 : 0.015801748260855675
Loss at iteration 980 : 0.013739226385951042
Loss at iteration 990 : 0.018588244915008545
Loss at iteration 1000 : 0.01888665184378624
Loss at iteration 1010 : 0.014452400617301464
Loss at iteration 1020 : 0.013521560467779636
Loss at iteration 1030 : 0.02523093670606613
Loss at iteration 1040 : 0.017422081902623177
Loss at iteration 1050 : 0.012891758233308792
Loss at iteration 1060 : 0.0141242491081357
Loss at iteration 1070 : 0.014664829708635807
Loss at iteration 1080 : 0.018056634813547134
Loss at iteration 1090 : 0.03863266855478287
Loss at iteration 1100 : 0.023063398897647858
Loss at iteration 1110 : 0.023565467447042465
Loss at iteration 1120 : 0.027372270822525024
Loss at iteration 1130 : 0.014416433870792389
Loss at iteration 1140 : 0.020465422421693802
Loss at iteration 1150 : 0.013710936531424522
Loss at iteration 1160 : 0.016811266541481018
Loss at iteration 1170 : 0.022623641416430473
Loss at iteration 1180 : 0.018696364015340805
Loss at iteration 1190 : 0.020752757787704468
Loss at iteration 1200 : 0.021069316193461418
Loss at iteration 1210 : 0.017705349251627922
The SSIM Value is: 0.7273889025052388
The PSNR Value is: 16.63463128407796
the epoch is: 8
Loss at iteration 10 : 0.015349446795880795
Loss at iteration 20 : 0.021821901202201843
Loss at iteration 30 : 0.018683848902583122
Loss at iteration 40 : 0.016449162736535072
Loss at iteration 50 : 0.014243078418076038
Loss at iteration 60 : 0.018887024372816086
Loss at iteration 70 : 0.01057668961584568
Loss at iteration 80 : 0.008459479548037052
Loss at iteration 90 : 0.013549456372857094
Loss at iteration 100 : 0.016138523817062378
Loss at iteration 110 : 0.013587312772870064
Loss at iteration 120 : 0.010468034073710442
Loss at iteration 130 : 0.015486279502511024
Loss at iteration 140 : 0.02289334312081337
Loss at iteration 150 : 0.020924944430589676
Loss at iteration 160 : 0.013282951898872852
Loss at iteration 170 : 0.016248727217316628
Loss at iteration 180 : 0.01800265535712242
Loss at iteration 190 : 0.01938648521900177
Loss at iteration 200 : 0.01837797835469246
Loss at iteration 210 : 0.016837742179632187
Loss at iteration 220 : 0.010531516745686531
Loss at iteration 230 : 0.018902618438005447
Loss at iteration 240 : 0.01996464468538761
Loss at iteration 250 : 0.013678118586540222
Loss at iteration 260 : 0.014011695981025696
Loss at iteration 270 : 0.022187281399965286
Loss at iteration 280 : 0.021432925015687943
Loss at iteration 290 : 0.01784006878733635
Loss at iteration 300 : 0.026483958587050438
Loss at iteration 310 : 0.022219352424144745
Loss at iteration 320 : 0.01926940679550171
Loss at iteration 330 : 0.014122418127954006
Loss at iteration 340 : 0.02377268858253956
Loss at iteration 350 : 0.011933956295251846
Loss at iteration 360 : 0.010928578674793243
Loss at iteration 370 : 0.014594662003219128
Loss at iteration 380 : 0.009850813075900078
Loss at iteration 390 : 0.017590535804629326
Loss at iteration 400 : 0.015818320214748383
Loss at iteration 410 : 0.014469250105321407
Loss at iteration 420 : 0.01720365323126316
Loss at iteration 430 : 0.015777597203850746
Loss at iteration 440 : 0.009688304737210274
Loss at iteration 450 : 0.021079180762171745
Loss at iteration 460 : 0.009801959618926048
Loss at iteration 470 : 0.020421180874109268
Loss at iteration 480 : 0.01306405570358038
Loss at iteration 490 : 0.013037431053817272
Loss at iteration 500 : 0.01564028672873974
Loss at iteration 510 : 0.01558441948145628
Loss at iteration 520 : 0.015212512575089931
Loss at iteration 530 : 0.009710547514259815
Loss at iteration 540 : 0.013141486793756485
Loss at iteration 550 : 0.018984194844961166
Loss at iteration 560 : 0.020356887951493263
Loss at iteration 570 : 0.015346434898674488
Loss at iteration 580 : 0.01623443141579628
Loss at iteration 590 : 0.018770607188344002
Loss at iteration 600 : 0.015809012576937675
Loss at iteration 610 : 0.022526148706674576
Loss at iteration 620 : 0.02071116864681244
Loss at iteration 630 : 0.019435148686170578
Loss at iteration 640 : 0.009260278195142746
Loss at iteration 650 : 0.011729251593351364
Loss at iteration 660 : 0.025340566411614418
Loss at iteration 670 : 0.014228281565010548
Loss at iteration 680 : 0.020612647756934166
Loss at iteration 690 : 0.019576024264097214
Loss at iteration 700 : 0.019181057810783386
Loss at iteration 710 : 0.012802253477275372
Loss at iteration 720 : 0.0156765915453434
Loss at iteration 730 : 0.016620391979813576
Loss at iteration 740 : 0.02222209982573986
Loss at iteration 750 : 0.020036734640598297
Loss at iteration 760 : 0.012671283446252346
Loss at iteration 770 : 0.029946859925985336
Loss at iteration 780 : 0.019983677193522453
Loss at iteration 790 : 0.015539356507360935
Loss at iteration 800 : 0.015629399567842484
Loss at iteration 810 : 0.01695873588323593
Loss at iteration 820 : 0.017306707799434662
Loss at iteration 830 : 0.009696858935058117
Loss at iteration 840 : 0.011594974435865879
Loss at iteration 850 : 0.013972118496894836
Loss at iteration 860 : 0.021482760086655617
Loss at iteration 870 : 0.01561209000647068
Loss at iteration 880 : 0.018406258895993233
Loss at iteration 890 : 0.012433654628694057
Loss at iteration 900 : 0.013153577223420143
Loss at iteration 910 : 0.013287898153066635
Loss at iteration 920 : 0.016771890223026276
Loss at iteration 930 : 0.014924720861017704
Loss at iteration 940 : 0.017845407128334045
Loss at iteration 950 : 0.009282687678933144
Loss at iteration 960 : 0.01291574351489544
Loss at iteration 970 : 0.013244874775409698
Loss at iteration 980 : 0.01634105294942856
Loss at iteration 990 : 0.01893097534775734
Loss at iteration 1000 : 0.018243534490466118
Loss at iteration 1010 : 0.019909432157874107
Loss at iteration 1020 : 0.027763716876506805
Loss at iteration 1030 : 0.013774890452623367
Loss at iteration 1040 : 0.011559819802641869
Loss at iteration 1050 : 0.018309898674488068
Loss at iteration 1060 : 0.018549064174294472
Loss at iteration 1070 : 0.020029451698064804
Loss at iteration 1080 : 0.014363517984747887
Loss at iteration 1090 : 0.02230452373623848
Loss at iteration 1100 : 0.01587161235511303
Loss at iteration 1110 : 0.020197007805109024
Loss at iteration 1120 : 0.026128143072128296
Loss at iteration 1130 : 0.016625462099909782
Loss at iteration 1140 : 0.0254750307649374
Loss at iteration 1150 : 0.013900265097618103
Loss at iteration 1160 : 0.016906600445508957
Loss at iteration 1170 : 0.015546402893960476
Loss at iteration 1180 : 0.024428466334939003
Loss at iteration 1190 : 0.02811550535261631
Loss at iteration 1200 : 0.01977686956524849
Loss at iteration 1210 : 0.015623124316334724
The SSIM Value is: 0.7950751105944316
The PSNR Value is: 17.511352920532225
the epoch is: 9
Loss at iteration 10 : 0.012914005666971207
Loss at iteration 20 : 0.014874511398375034
Loss at iteration 30 : 0.018151339143514633
Loss at iteration 40 : 0.01346740685403347
Loss at iteration 50 : 0.02342291548848152
Loss at iteration 60 : 0.010149812325835228
Loss at iteration 70 : 0.01535948459059
Loss at iteration 80 : 0.023628801107406616
Loss at iteration 90 : 0.014269893988966942
Loss at iteration 100 : 0.013000790029764175
Loss at iteration 110 : 0.017158910632133484
Loss at iteration 120 : 0.019174721091985703
Loss at iteration 130 : 0.017669441178441048
Loss at iteration 140 : 0.015973588451743126
Loss at iteration 150 : 0.014347904361784458
Loss at iteration 160 : 0.01801217719912529
Loss at iteration 170 : 0.015899918973445892
Loss at iteration 180 : 0.011743320152163506
Loss at iteration 190 : 0.013806536793708801
Loss at iteration 200 : 0.011818763799965382
Loss at iteration 210 : 0.01856115274131298
Loss at iteration 220 : 0.02683154307305813
Loss at iteration 230 : 0.0317939817905426
Loss at iteration 240 : 0.01909429207444191
Loss at iteration 250 : 0.014959879219532013
Loss at iteration 260 : 0.015709513798356056
Loss at iteration 270 : 0.022446773946285248
Loss at iteration 280 : 0.019197696819901466
Loss at iteration 290 : 0.01804317533969879
Loss at iteration 300 : 0.014132337644696236
Loss at iteration 310 : 0.01815575361251831
Loss at iteration 320 : 0.01964058354496956
Loss at iteration 330 : 0.02233048342168331
Loss at iteration 340 : 0.01834605634212494
Loss at iteration 350 : 0.015768548473715782
Loss at iteration 360 : 0.011864421889185905
Loss at iteration 370 : 0.012308153323829174
Loss at iteration 380 : 0.01893511600792408
Loss at iteration 390 : 0.01619209721684456
Loss at iteration 400 : 0.014967182651162148
Loss at iteration 410 : 0.016358116641640663
Loss at iteration 420 : 0.017896853387355804
Loss at iteration 430 : 0.014005383476614952
Loss at iteration 440 : 0.014036325737833977
Loss at iteration 450 : 0.01723032258450985
Loss at iteration 460 : 0.022658560425043106
Loss at iteration 470 : 0.01561458595097065
Loss at iteration 480 : 0.013193240389227867
Loss at iteration 490 : 0.014120806008577347
Loss at iteration 500 : 0.027431679889559746
Loss at iteration 510 : 0.015624496154487133
Loss at iteration 520 : 0.024081606417894363
Loss at iteration 530 : 0.011637602001428604
Loss at iteration 540 : 0.013611683622002602
Loss at iteration 550 : 0.008523859083652496
Loss at iteration 560 : 0.0213369969278574
Loss at iteration 570 : 0.013435134664177895
Loss at iteration 580 : 0.020276542752981186
Loss at iteration 590 : 0.014246957376599312
Loss at iteration 600 : 0.01870088092982769
Loss at iteration 610 : 0.013101833872497082
Loss at iteration 620 : 0.013484518975019455
Loss at iteration 630 : 0.019951432943344116
Loss at iteration 640 : 0.01405326183885336
Loss at iteration 650 : 0.016928840428590775
Loss at iteration 660 : 0.012063848786056042
Loss at iteration 670 : 0.016560014337301254
Loss at iteration 680 : 0.01230528298765421
Loss at iteration 690 : 0.018550895154476166
Loss at iteration 700 : 0.022256778553128242
Loss at iteration 710 : 0.011982720345258713
Loss at iteration 720 : 0.011808390729129314
Loss at iteration 730 : 0.015204023569822311
Loss at iteration 740 : 0.015617672353982925
Loss at iteration 750 : 0.02647174522280693
Loss at iteration 760 : 0.017745716497302055
Loss at iteration 770 : 0.02332741767168045
Loss at iteration 780 : 0.02261371910572052
Loss at iteration 790 : 0.013786090537905693
Loss at iteration 800 : 0.012085802853107452
Loss at iteration 810 : 0.021153829991817474
Loss at iteration 820 : 0.012126591056585312
Loss at iteration 830 : 0.015470454469323158
Loss at iteration 840 : 0.01062958687543869
Loss at iteration 850 : 0.015321259386837482
Loss at iteration 860 : 0.022332727909088135
Loss at iteration 870 : 0.01739506796002388
Loss at iteration 880 : 0.017398614436388016
Loss at iteration 890 : 0.015534812584519386
Loss at iteration 900 : 0.019296571612358093
Loss at iteration 910 : 0.019329264760017395
Loss at iteration 920 : 0.016403522342443466
Loss at iteration 930 : 0.01394832693040371
Loss at iteration 940 : 0.015114439651370049
Loss at iteration 950 : 0.013671275228261948
Loss at iteration 960 : 0.017533497884869576
Loss at iteration 970 : 0.013439557515084743
Loss at iteration 980 : 0.011130759492516518
Loss at iteration 990 : 0.019571516662836075
Loss at iteration 1000 : 0.02306007593870163
Loss at iteration 1010 : 0.012372057884931564
Loss at iteration 1020 : 0.014879638329148293
Loss at iteration 1030 : 0.011951979249715805
Loss at iteration 1040 : 0.010459057986736298
Loss at iteration 1050 : 0.020295873284339905
Loss at iteration 1060 : 0.012433855794370174
Loss at iteration 1070 : 0.013372214511036873
Loss at iteration 1080 : 0.01758410595357418
Loss at iteration 1090 : 0.01767588220536709
Loss at iteration 1100 : 0.014455216936767101
Loss at iteration 1110 : 0.012587863020598888
Loss at iteration 1120 : 0.018267955631017685
Loss at iteration 1130 : 0.013975383713841438
Loss at iteration 1140 : 0.010025912895798683
Loss at iteration 1150 : 0.014856068417429924
Loss at iteration 1160 : 0.020636066794395447
Loss at iteration 1170 : 0.029878702014684677
Loss at iteration 1180 : 0.01921849511563778
Loss at iteration 1190 : 0.014969171956181526
Loss at iteration 1200 : 0.019947292283177376
Loss at iteration 1210 : 0.01739317737519741
The SSIM Value is: 0.7905956784884135
The PSNR Value is: 18.138785870869956
the epoch is: 10
Loss at iteration 10 : 0.029335469007492065
Loss at iteration 20 : 0.018318500369787216
Loss at iteration 30 : 0.014664013870060444
Loss at iteration 40 : 0.01673637516796589
Loss at iteration 50 : 0.013206377625465393
Loss at iteration 60 : 0.02583572454750538
Loss at iteration 70 : 0.03124728426337242
Loss at iteration 80 : 0.013403655961155891
Loss at iteration 90 : 0.022106938064098358
Loss at iteration 100 : 0.021545367315411568
Loss at iteration 110 : 0.010022641159594059
Loss at iteration 120 : 0.012685398571193218
Loss at iteration 130 : 0.01664014346897602
Loss at iteration 140 : 0.015827562659978867
Loss at iteration 150 : 0.014356212690472603
Loss at iteration 160 : 0.01143159344792366
Loss at iteration 170 : 0.014993526041507721
Loss at iteration 180 : 0.011718746274709702
Loss at iteration 190 : 0.014416709542274475
Loss at iteration 200 : 0.01505840104073286
Loss at iteration 210 : 0.010989390313625336
Loss at iteration 220 : 0.012845806777477264
Loss at iteration 230 : 0.012673001736402512
Loss at iteration 240 : 0.010097092017531395
Loss at iteration 250 : 0.028736284002661705
Loss at iteration 260 : 0.012087883427739143
Loss at iteration 270 : 0.017203647643327713
Loss at iteration 280 : 0.02656560204923153
Loss at iteration 290 : 0.015052923001348972
Loss at iteration 300 : 0.01649373583495617
Loss at iteration 310 : 0.018104683607816696
Loss at iteration 320 : 0.018699370324611664
Loss at iteration 330 : 0.01564040035009384
Loss at iteration 340 : 0.011917056515812874
Loss at iteration 350 : 0.018150895833969116
Loss at iteration 360 : 0.023229291662573814
Loss at iteration 370 : 0.01672065258026123
Loss at iteration 380 : 0.02382882684469223
Loss at iteration 390 : 0.01498010940849781
Loss at iteration 400 : 0.00985411275178194
Loss at iteration 410 : 0.012670459225773811
Loss at iteration 420 : 0.021664250642061234
Loss at iteration 430 : 0.013537216931581497
Loss at iteration 440 : 0.02190590277314186
Loss at iteration 450 : 0.017117301002144814
Loss at iteration 460 : 0.018264994025230408
Loss at iteration 470 : 0.02481544017791748
Loss at iteration 480 : 0.01178059447556734
Loss at iteration 490 : 0.016109703108668327
Loss at iteration 500 : 0.014945246279239655
Loss at iteration 510 : 0.015084514394402504
Loss at iteration 520 : 0.013982664793729782
Loss at iteration 530 : 0.01652657985687256
Loss at iteration 540 : 0.018874282017350197
Loss at iteration 550 : 0.014374187216162682
Loss at iteration 560 : 0.018900969997048378
Loss at iteration 570 : 0.016894448548555374
Loss at iteration 580 : 0.022688180208206177
Loss at iteration 590 : 0.013707393780350685
Loss at iteration 600 : 0.012935789301991463
Loss at iteration 610 : 0.013755258172750473
Loss at iteration 620 : 0.017801661044359207
Loss at iteration 630 : 0.014490111730992794
Loss at iteration 640 : 0.009402898140251637
Loss at iteration 650 : 0.013158008456230164
Loss at iteration 660 : 0.01243534404784441
Loss at iteration 670 : 0.010737722739577293
Loss at iteration 680 : 0.009036974050104618
Loss at iteration 690 : 0.009071706794202328
Loss at iteration 700 : 0.017685195431113243
Loss at iteration 710 : 0.012453187257051468
Loss at iteration 720 : 0.0157267265021801
Loss at iteration 730 : 0.014596454799175262
Loss at iteration 740 : 0.013170372694730759
Loss at iteration 750 : 0.015785688534379005
Loss at iteration 760 : 0.021270809695124626
Loss at iteration 770 : 0.020163241773843765
Loss at iteration 780 : 0.010838113725185394
Loss at iteration 790 : 0.023823818191885948
Loss at iteration 800 : 0.014804678969085217
Loss at iteration 810 : 0.019042983651161194
Loss at iteration 820 : 0.01980270817875862
Loss at iteration 830 : 0.009662248194217682
Loss at iteration 840 : 0.02170630358159542
Loss at iteration 850 : 0.009497986175119877
Loss at iteration 860 : 0.013124055229127407
Loss at iteration 870 : 0.02152419090270996
Loss at iteration 880 : 0.026761339977383614
Loss at iteration 890 : 0.012504730373620987
Loss at iteration 900 : 0.012128514237701893
Loss at iteration 910 : 0.018998589366674423
Loss at iteration 920 : 0.013802715577185154
Loss at iteration 930 : 0.018734749406576157
Loss at iteration 940 : 0.017487989738583565
Loss at iteration 950 : 0.01206843089312315
Loss at iteration 960 : 0.014755046926438808
Loss at iteration 970 : 0.017549440264701843
Loss at iteration 980 : 0.021695323288440704
Loss at iteration 990 : 0.021937739104032516
Loss at iteration 1000 : 0.01615511067211628
Loss at iteration 1010 : 0.011497577652335167
Loss at iteration 1020 : 0.018244005739688873
Loss at iteration 1030 : 0.020362630486488342
Loss at iteration 1040 : 0.011823362670838833
Loss at iteration 1050 : 0.017404446378350258
Loss at iteration 1060 : 0.019412314519286156
Loss at iteration 1070 : 0.016454532742500305
Loss at iteration 1080 : 0.011168139055371284
Loss at iteration 1090 : 0.018546517938375473
Loss at iteration 1100 : 0.020746463909745216
Loss at iteration 1110 : 0.025807920843362808
Loss at iteration 1120 : 0.014263637363910675
Loss at iteration 1130 : 0.01759606972336769
Loss at iteration 1140 : 0.009458121843636036
Loss at iteration 1150 : 0.02724307030439377
Loss at iteration 1160 : 0.02834245376288891
Loss at iteration 1170 : 0.014908978715538979
Loss at iteration 1180 : 0.020912019535899162
Loss at iteration 1190 : 0.018642589449882507
Loss at iteration 1200 : 0.008650494739413261
Loss at iteration 1210 : 0.01230931282043457
The SSIM Value is: 0.791092864672343
The PSNR Value is: 17.96191234588623
the epoch is: 11
Loss at iteration 10 : 0.01604933850467205
Loss at iteration 20 : 0.011931623332202435
Loss at iteration 30 : 0.012390905991196632
Loss at iteration 40 : 0.0193080622702837
Loss at iteration 50 : 0.01964685320854187
Loss at iteration 60 : 0.025280838832259178
Loss at iteration 70 : 0.016241539269685745
Loss at iteration 80 : 0.0128885293379426
Loss at iteration 90 : 0.011725829914212227
Loss at iteration 100 : 0.014026753604412079
Loss at iteration 110 : 0.01899631880223751
Loss at iteration 120 : 0.017552325502038002
Loss at iteration 130 : 0.025136763229966164
Loss at iteration 140 : 0.01157441921532154
Loss at iteration 150 : 0.015234461054205894
Loss at iteration 160 : 0.015777818858623505
Loss at iteration 170 : 0.013274789787828922
Loss at iteration 180 : 0.01793701946735382
Loss at iteration 190 : 0.01858454756438732
Loss at iteration 200 : 0.01336909830570221
Loss at iteration 210 : 0.015315087512135506
Loss at iteration 220 : 0.025652876123785973
Loss at iteration 230 : 0.02052442729473114
Loss at iteration 240 : 0.017479222267866135
Loss at iteration 250 : 0.012681511230766773
Loss at iteration 260 : 0.013977650552988052
Loss at iteration 270 : 0.013438830152153969
Loss at iteration 280 : 0.019747894257307053
Loss at iteration 290 : 0.011614007875323296
Loss at iteration 300 : 0.030508944764733315
Loss at iteration 310 : 0.017015425488352776
Loss at iteration 320 : 0.021721210330724716
Loss at iteration 330 : 0.019926095381379128
Loss at iteration 340 : 0.01576944813132286
Loss at iteration 350 : 0.017601633444428444
Loss at iteration 360 : 0.021127069368958473
Loss at iteration 370 : 0.016429701820015907
Loss at iteration 380 : 0.018091633915901184
Loss at iteration 390 : 0.016919460147619247
Loss at iteration 400 : 0.02410152368247509
Loss at iteration 410 : 0.015092995017766953
Loss at iteration 420 : 0.025234950706362724
Loss at iteration 430 : 0.010673186741769314
Loss at iteration 440 : 0.020250875502824783
Loss at iteration 450 : 0.009752001613378525
Loss at iteration 460 : 0.014994030818343163
Loss at iteration 470 : 0.020792093127965927
Loss at iteration 480 : 0.011989462189376354
Loss at iteration 490 : 0.021221909672021866
Loss at iteration 500 : 0.009546017274260521
Loss at iteration 510 : 0.017512429505586624
Loss at iteration 520 : 0.01648740842938423
Loss at iteration 530 : 0.014647523872554302
Loss at iteration 540 : 0.014178166165947914
Loss at iteration 550 : 0.014920985326170921
Loss at iteration 560 : 0.02159632369875908
Loss at iteration 570 : 0.01863543502986431
Loss at iteration 580 : 0.020515872165560722
Loss at iteration 590 : 0.01776662841439247
Loss at iteration 600 : 0.014144292101264
Loss at iteration 610 : 0.016327712684869766
Loss at iteration 620 : 0.012943222187459469
Loss at iteration 630 : 0.011071001179516315
Loss at iteration 640 : 0.02497089095413685
Loss at iteration 650 : 0.011934340000152588
Loss at iteration 660 : 0.018344581127166748
Loss at iteration 670 : 0.013637224212288857
Loss at iteration 680 : 0.01179707795381546
Loss at iteration 690 : 0.015048004686832428
Loss at iteration 700 : 0.011883823201060295
Loss at iteration 710 : 0.013878602534532547
Loss at iteration 720 : 0.014474866911768913
Loss at iteration 730 : 0.012168537825345993
Loss at iteration 740 : 0.011139865964651108
Loss at iteration 750 : 0.016081854701042175
Loss at iteration 760 : 0.013575918972492218
Loss at iteration 770 : 0.022751472890377045
Loss at iteration 780 : 0.02876647561788559
Loss at iteration 790 : 0.01502244919538498
Loss at iteration 800 : 0.01632317155599594
Loss at iteration 810 : 0.021195340901613235
Loss at iteration 820 : 0.0194587092846632
Loss at iteration 830 : 0.010579066351056099
Loss at iteration 840 : 0.011601651087403297
Loss at iteration 850 : 0.009850233793258667
Loss at iteration 860 : 0.016631189733743668
Loss at iteration 870 : 0.016234172508120537
Loss at iteration 880 : 0.00865558534860611
Loss at iteration 890 : 0.011272130534052849
Loss at iteration 900 : 0.017287760972976685
Loss at iteration 910 : 0.01581665687263012
Loss at iteration 920 : 0.022424951195716858
Loss at iteration 930 : 0.015214033424854279
Loss at iteration 940 : 0.007183717098087072
Loss at iteration 950 : 0.017813825979828835
Loss at iteration 960 : 0.008610605262219906
Loss at iteration 970 : 0.009755718521773815
Loss at iteration 980 : 0.015170333907008171
Loss at iteration 990 : 0.012843013741075993
Loss at iteration 1000 : 0.010674526914954185
Loss at iteration 1010 : 0.017891783267259598
Loss at iteration 1020 : 0.015454296953976154
Loss at iteration 1030 : 0.019585536792874336
Loss at iteration 1040 : 0.016063306480646133
Loss at iteration 1050 : 0.011636873707175255
Loss at iteration 1060 : 0.014554250054061413
Loss at iteration 1070 : 0.014380613341927528
Loss at iteration 1080 : 0.019953224807977676
Loss at iteration 1090 : 0.01733110100030899
Loss at iteration 1100 : 0.02256091870367527
Loss at iteration 1110 : 0.024759866297245026
Loss at iteration 1120 : 0.022378290072083473
Loss at iteration 1130 : 0.017457902431488037
Loss at iteration 1140 : 0.0209161639213562
Loss at iteration 1150 : 0.013052014634013176
Loss at iteration 1160 : 0.011764049530029297
Loss at iteration 1170 : 0.015302686020731926
Loss at iteration 1180 : 0.02582624740898609
Loss at iteration 1190 : 0.014581313356757164
Loss at iteration 1200 : 0.01693190075457096
Loss at iteration 1210 : 0.012418694794178009
The SSIM Value is: 0.7887808799743652
The PSNR Value is: 17.92046635945638
the epoch is: 12
Loss at iteration 10 : 0.019969847053289413
Loss at iteration 20 : 0.01073368452489376
Loss at iteration 30 : 0.011986786499619484
Loss at iteration 40 : 0.015044169500470161
Loss at iteration 50 : 0.01546718180179596
Loss at iteration 60 : 0.01536130253225565
Loss at iteration 70 : 0.022070731967687607
Loss at iteration 80 : 0.016897141933441162
Loss at iteration 90 : 0.014123313128948212
Loss at iteration 100 : 0.008805152028799057
Loss at iteration 110 : 0.011323969811201096
Loss at iteration 120 : 0.016797591000795364
Loss at iteration 130 : 0.02031698264181614
Loss at iteration 140 : 0.017650466412305832
Loss at iteration 150 : 0.014042125083506107
Loss at iteration 160 : 0.011435589753091335
Loss at iteration 170 : 0.01979830116033554
Loss at iteration 180 : 0.017422325909137726
Loss at iteration 190 : 0.01740369386970997
Loss at iteration 200 : 0.01882454752922058
Loss at iteration 210 : 0.014750699512660503
Loss at iteration 220 : 0.014202717691659927
Loss at iteration 230 : 0.017207780852913857
Loss at iteration 240 : 0.014404339715838432
Loss at iteration 250 : 0.017160426825284958
Loss at iteration 260 : 0.017865151166915894
Loss at iteration 270 : 0.015804922208189964
Loss at iteration 280 : 0.019952954724431038
Loss at iteration 290 : 0.016534844413399696
Loss at iteration 300 : 0.014185369946062565
Loss at iteration 310 : 0.014534245245158672
Loss at iteration 320 : 0.020643014460802078
Loss at iteration 330 : 0.020099857822060585
Loss at iteration 340 : 0.01919163390994072
Loss at iteration 350 : 0.018332121893763542
Loss at iteration 360 : 0.01341999601572752
Loss at iteration 370 : 0.023743178695440292
Loss at iteration 380 : 0.017166633158922195
Loss at iteration 390 : 0.019279662519693375
Loss at iteration 400 : 0.015455391258001328
Loss at iteration 410 : 0.016130559146404266
Loss at iteration 420 : 0.020883355289697647
Loss at iteration 430 : 0.013907737098634243
Loss at iteration 440 : 0.014139153063297272
Loss at iteration 450 : 0.017665285617113113
Loss at iteration 460 : 0.01839640736579895
Loss at iteration 470 : 0.02244144305586815
Loss at iteration 480 : 0.016123507171869278
Loss at iteration 490 : 0.008464748039841652
Loss at iteration 500 : 0.02131401002407074
Loss at iteration 510 : 0.023256734013557434
Loss at iteration 520 : 0.016780229285359383
Loss at iteration 530 : 0.016463417559862137
Loss at iteration 540 : 0.009304356761276722
Loss at iteration 550 : 0.01532174926251173
Loss at iteration 560 : 0.028148377314209938
Loss at iteration 570 : 0.013988751918077469
Loss at iteration 580 : 0.014983872883021832
Loss at iteration 590 : 0.011836004443466663
Loss at iteration 600 : 0.018551908433437347
Loss at iteration 610 : 0.014674406498670578
Loss at iteration 620 : 0.011749633587896824
Loss at iteration 630 : 0.011401144787669182
Loss at iteration 640 : 0.024655073881149292
Loss at iteration 650 : 0.013208618387579918
Loss at iteration 660 : 0.015846088528633118
Loss at iteration 670 : 0.02471119351685047
Loss at iteration 680 : 0.02200186625123024
Loss at iteration 690 : 0.010394107550382614
Loss at iteration 700 : 0.012024539522826672
Loss at iteration 710 : 0.0186753086745739
Loss at iteration 720 : 0.008238512091338634
Loss at iteration 730 : 0.008982276543974876
Loss at iteration 740 : 0.007802697364240885
Loss at iteration 750 : 0.01640496961772442
Loss at iteration 760 : 0.012715203687548637
Loss at iteration 770 : 0.01951402798295021
Loss at iteration 780 : 0.012097152881324291
Loss at iteration 790 : 0.012523430399596691
Loss at iteration 800 : 0.022678840905427933
Loss at iteration 810 : 0.015103330835700035
Loss at iteration 820 : 0.01624467223882675
Loss at iteration 830 : 0.01823113113641739
Loss at iteration 840 : 0.016216613352298737
Loss at iteration 850 : 0.011425026692450047
Loss at iteration 860 : 0.016200292855501175
Loss at iteration 870 : 0.01777714118361473
Loss at iteration 880 : 0.018864883109927177
Loss at iteration 890 : 0.028072282671928406
Loss at iteration 900 : 0.025382185354828835
Loss at iteration 910 : 0.013192608952522278
Loss at iteration 920 : 0.01034291461110115
Loss at iteration 930 : 0.01786838099360466
Loss at iteration 940 : 0.027206404134631157
Loss at iteration 950 : 0.014156246557831764
Loss at iteration 960 : 0.013750627636909485
Loss at iteration 970 : 0.02032809890806675
Loss at iteration 980 : 0.019515350461006165
Loss at iteration 990 : 0.01420779712498188
Loss at iteration 1000 : 0.013538656756281853
Loss at iteration 1010 : 0.028450436890125275
Loss at iteration 1020 : 0.025455767288804054
Loss at iteration 1030 : 0.010119379498064518
Loss at iteration 1040 : 0.01195557788014412
Loss at iteration 1050 : 0.009844464249908924
Loss at iteration 1060 : 0.02011588029563427
Loss at iteration 1070 : 0.027191700413823128
Loss at iteration 1080 : 0.02913103997707367
Loss at iteration 1090 : 0.013774218037724495
Loss at iteration 1100 : 0.020495885983109474
Loss at iteration 1110 : 0.01465870626270771
Loss at iteration 1120 : 0.015597493387758732
Loss at iteration 1130 : 0.017911160364747047
Loss at iteration 1140 : 0.014663690701127052
Loss at iteration 1150 : 0.014941476285457611
Loss at iteration 1160 : 0.01448226161301136
Loss at iteration 1170 : 0.014912379905581474
Loss at iteration 1180 : 0.01220024935901165
Loss at iteration 1190 : 0.012358196079730988
Loss at iteration 1200 : 0.011674591340124607
Loss at iteration 1210 : 0.022718682885169983
The SSIM Value is: 0.7770961125691732
The PSNR Value is: 17.628107770284018
the epoch is: 13
Loss at iteration 10 : 0.009509025141596794
Loss at iteration 20 : 0.015165291726589203
Loss at iteration 30 : 0.017165038734674454
Loss at iteration 40 : 0.008324285969138145
Loss at iteration 50 : 0.015088597312569618
Loss at iteration 60 : 0.01501508243381977
Loss at iteration 70 : 0.02351432666182518
Loss at iteration 80 : 0.013847535476088524
Loss at iteration 90 : 0.016379758715629578
Loss at iteration 100 : 0.011998054571449757
Loss at iteration 110 : 0.011482354253530502
Loss at iteration 120 : 0.01154071930795908
Loss at iteration 130 : 0.010453537106513977
Loss at iteration 140 : 0.016078051179647446
Loss at iteration 150 : 0.013805583119392395
Loss at iteration 160 : 0.01817154511809349
Loss at iteration 170 : 0.013604586012661457
Loss at iteration 180 : 0.01442709006369114
Loss at iteration 190 : 0.01512222457677126
Loss at iteration 200 : 0.014520607888698578
Loss at iteration 210 : 0.01895124837756157
Loss at iteration 220 : 0.014921484515070915
Loss at iteration 230 : 0.011827469803392887
Loss at iteration 240 : 0.02338121086359024
Loss at iteration 250 : 0.031710460782051086
Loss at iteration 260 : 0.02561386488378048
Loss at iteration 270 : 0.01209321990609169
Loss at iteration 280 : 0.011420363560318947
Loss at iteration 290 : 0.021490199491381645
Loss at iteration 300 : 0.01000489853322506
Loss at iteration 310 : 0.009633045643568039
Loss at iteration 320 : 0.02759266458451748
Loss at iteration 330 : 0.0116856899112463
Loss at iteration 340 : 0.009281763806939125
Loss at iteration 350 : 0.013405892997980118
Loss at iteration 360 : 0.012894691899418831
Loss at iteration 370 : 0.018577538430690765
Loss at iteration 380 : 0.02064412832260132
Loss at iteration 390 : 0.01412714459002018
Loss at iteration 400 : 0.016651753336191177
Loss at iteration 410 : 0.010661981999874115
Loss at iteration 420 : 0.012380611151456833
Loss at iteration 430 : 0.014969199895858765
Loss at iteration 440 : 0.014117375016212463
Loss at iteration 450 : 0.02163621410727501
Loss at iteration 460 : 0.010881960391998291
Loss at iteration 470 : 0.015917427837848663
Loss at iteration 480 : 0.01876169629395008
Loss at iteration 490 : 0.012808231636881828
Loss at iteration 500 : 0.017571236938238144
Loss at iteration 510 : 0.01665298081934452
Loss at iteration 520 : 0.010514732450246811
Loss at iteration 530 : 0.02288520708680153
Loss at iteration 540 : 0.011122857220470905
Loss at iteration 550 : 0.018066395074129105
Loss at iteration 560 : 0.014956336468458176
Loss at iteration 570 : 0.0200912207365036
Loss at iteration 580 : 0.02280949056148529
Loss at iteration 590 : 0.01795285940170288
Loss at iteration 600 : 0.014322390779852867
Loss at iteration 610 : 0.011166839860379696
Loss at iteration 620 : 0.011250412091612816
Loss at iteration 630 : 0.012673594988882542
Loss at iteration 640 : 0.018035124987363815
Loss at iteration 650 : 0.011601468548178673
Loss at iteration 660 : 0.03219464793801308
Loss at iteration 670 : 0.016924910247325897
Loss at iteration 680 : 0.025074493139982224
Loss at iteration 690 : 0.01602715626358986
Loss at iteration 700 : 0.019391342997550964
Loss at iteration 710 : 0.01674090139567852
Loss at iteration 720 : 0.010690974071621895
Loss at iteration 730 : 0.01057923398911953
Loss at iteration 740 : 0.014484046027064323
Loss at iteration 750 : 0.015368250198662281
Loss at iteration 760 : 0.01493050903081894
Loss at iteration 770 : 0.018429363146424294
Loss at iteration 780 : 0.01699155569076538
Loss at iteration 790 : 0.013892507180571556
Loss at iteration 800 : 0.015939494594931602
Loss at iteration 810 : 0.008068523369729519
Loss at iteration 820 : 0.00852235872298479
Loss at iteration 830 : 0.013176800683140755
Loss at iteration 840 : 0.011905524879693985
Loss at iteration 850 : 0.012202482670545578
Loss at iteration 860 : 0.009468823671340942
Loss at iteration 870 : 0.01317633781582117
Loss at iteration 880 : 0.009999400936067104
Loss at iteration 890 : 0.010581731796264648
Loss at iteration 900 : 0.014640521258115768
Loss at iteration 910 : 0.013339241966605186
Loss at iteration 920 : 0.01401706226170063
Loss at iteration 930 : 0.022124245762825012
Loss at iteration 940 : 0.016882658004760742
Loss at iteration 950 : 0.011770921759307384
Loss at iteration 960 : 0.019107559695839882
Loss at iteration 970 : 0.0104756411164999
Loss at iteration 980 : 0.013834532350301743
Loss at iteration 990 : 0.027465878054499626
Loss at iteration 1000 : 0.01534029096364975
Loss at iteration 1010 : 0.01782905124127865
Loss at iteration 1020 : 0.019596796482801437
Loss at iteration 1030 : 0.017531828954815865
Loss at iteration 1040 : 0.020659005269408226
Loss at iteration 1050 : 0.014963440597057343
Loss at iteration 1060 : 0.013826861046254635
Loss at iteration 1070 : 0.010982244275510311
Loss at iteration 1080 : 0.011536065489053726
Loss at iteration 1090 : 0.019182881340384483
Loss at iteration 1100 : 0.013425828889012337
Loss at iteration 1110 : 0.01275385171175003
Loss at iteration 1120 : 0.012095015496015549
Loss at iteration 1130 : 0.016522610560059547
Loss at iteration 1140 : 0.015485482290387154
Loss at iteration 1150 : 0.014774690382182598
Loss at iteration 1160 : 0.011394894681870937
Loss at iteration 1170 : 0.026770496740937233
Loss at iteration 1180 : 0.018249284476041794
Loss at iteration 1190 : 0.018787499517202377
Loss at iteration 1200 : 0.014655949547886848
Loss at iteration 1210 : 0.022037887945771217
The SSIM Value is: 0.7671797553698222
The PSNR Value is: 17.568766657511393
the epoch is: 14
Loss at iteration 10 : 0.015264210291206837
Loss at iteration 20 : 0.013764141127467155
Loss at iteration 30 : 0.010499542579054832
Loss at iteration 40 : 0.00689471373334527
Loss at iteration 50 : 0.012473579496145248
Loss at iteration 60 : 0.011128169484436512
Loss at iteration 70 : 0.014943502843379974
Loss at iteration 80 : 0.02121393010020256
Loss at iteration 90 : 0.025128161534667015
Loss at iteration 100 : 0.019535182043910027
Loss at iteration 110 : 0.01977277174592018
Loss at iteration 120 : 0.022278962656855583
Loss at iteration 130 : 0.024094723165035248
Loss at iteration 140 : 0.017464376986026764
Loss at iteration 150 : 0.011279967613518238
Loss at iteration 160 : 0.017364950850605965
Loss at iteration 170 : 0.013802824541926384
Loss at iteration 180 : 0.015766199678182602
Loss at iteration 190 : 0.0199444517493248
Loss at iteration 200 : 0.020773597061634064
Loss at iteration 210 : 0.015612158924341202
Loss at iteration 220 : 0.015117902308702469
Loss at iteration 230 : 0.011020002886652946
Loss at iteration 240 : 0.014637401327490807
Loss at iteration 250 : 0.017738087102770805
Loss at iteration 260 : 0.017809420824050903
Loss at iteration 270 : 0.01288783922791481
Loss at iteration 280 : 0.012724330648779869
Loss at iteration 290 : 0.03411727398633957
Loss at iteration 300 : 0.012088419869542122
Loss at iteration 310 : 0.018571248278021812
Loss at iteration 320 : 0.014682097360491753
Loss at iteration 330 : 0.01151645090430975
Loss at iteration 340 : 0.015203150920569897
Loss at iteration 350 : 0.014324605464935303
Loss at iteration 360 : 0.013490688987076283
Loss at iteration 370 : 0.011571313254535198
Loss at iteration 380 : 0.01230696402490139
Loss at iteration 390 : 0.025605618953704834
Loss at iteration 400 : 0.015275657176971436
Loss at iteration 410 : 0.015074901282787323
Loss at iteration 420 : 0.010263362899422646
Loss at iteration 430 : 0.0175686813890934
Loss at iteration 440 : 0.01423661969602108
Loss at iteration 450 : 0.012245824560523033
Loss at iteration 460 : 0.014267519116401672
Loss at iteration 470 : 0.013906886801123619
Loss at iteration 480 : 0.011620663106441498
Loss at iteration 490 : 0.010223571211099625
Loss at iteration 500 : 0.013782663270831108
Loss at iteration 510 : 0.012956264428794384
Loss at iteration 520 : 0.01965859718620777
Loss at iteration 530 : 0.011303617618978024
Loss at iteration 540 : 0.013926729559898376
Loss at iteration 550 : 0.013956870883703232
Loss at iteration 560 : 0.007874341681599617
Loss at iteration 570 : 0.016982536762952805
Loss at iteration 580 : 0.02033914625644684
Loss at iteration 590 : 0.011926703155040741
Loss at iteration 600 : 0.021492797881364822
Loss at iteration 610 : 0.01726127229630947
Loss at iteration 620 : 0.01329769566655159
Loss at iteration 630 : 0.01757960021495819
Loss at iteration 640 : 0.01804060861468315
Loss at iteration 650 : 0.018766004592180252
Loss at iteration 660 : 0.01573454588651657
Loss at iteration 670 : 0.01449645683169365
Loss at iteration 680 : 0.017430519685149193
Loss at iteration 690 : 0.01547849178314209
Loss at iteration 700 : 0.011568514630198479
Loss at iteration 710 : 0.012693884782493114
Loss at iteration 720 : 0.016460735350847244
Loss at iteration 730 : 0.01483183167874813
Loss at iteration 740 : 0.0373869463801384
Loss at iteration 750 : 0.008133874274790287
Loss at iteration 760 : 0.012456130236387253
Loss at iteration 770 : 0.014648759737610817
Loss at iteration 780 : 0.01967688463628292
Loss at iteration 790 : 0.022137116640806198
Loss at iteration 800 : 0.015059109777212143
Loss at iteration 810 : 0.0166676826775074
Loss at iteration 820 : 0.010129785165190697
Loss at iteration 830 : 0.012191986665129662
Loss at iteration 840 : 0.01842069998383522
Loss at iteration 850 : 0.014362752437591553
Loss at iteration 860 : 0.01736275479197502
Loss at iteration 870 : 0.017292805016040802
Loss at iteration 880 : 0.018695201724767685
Loss at iteration 890 : 0.015496533364057541
Loss at iteration 900 : 0.010393010452389717
Loss at iteration 910 : 0.012174800969660282
Loss at iteration 920 : 0.01818431168794632
Loss at iteration 930 : 0.013560878112912178
Loss at iteration 940 : 0.012032419443130493
Loss at iteration 950 : 0.01894751936197281
Loss at iteration 960 : 0.012455185875296593
Loss at iteration 970 : 0.03134508803486824
Loss at iteration 980 : 0.017439495772123337
Loss at iteration 990 : 0.018925687298178673
Loss at iteration 1000 : 0.024356631562113762
Loss at iteration 1010 : 0.012535428628325462
Loss at iteration 1020 : 0.01819280907511711
Loss at iteration 1030 : 0.024493098258972168
Loss at iteration 1040 : 0.013627961277961731
Loss at iteration 1050 : 0.01671895571053028
Loss at iteration 1060 : 0.03660379722714424
Loss at iteration 1070 : 0.016269879415631294
Loss at iteration 1080 : 0.021563684567809105
Loss at iteration 1090 : 0.009695385582745075
Loss at iteration 1100 : 0.01749582216143608
Loss at iteration 1110 : 0.01079136598855257
Loss at iteration 1120 : 0.02290060743689537
Loss at iteration 1130 : 0.013379402458667755
Loss at iteration 1140 : 0.015368828549981117
Loss at iteration 1150 : 0.01791093498468399
Loss at iteration 1160 : 0.011324411258101463
Loss at iteration 1170 : 0.025174034759402275
Loss at iteration 1180 : 0.016621682792901993
Loss at iteration 1190 : 0.013419385999441147
Loss at iteration 1200 : 0.011725690215826035
Loss at iteration 1210 : 0.02130712941288948
The SSIM Value is: 0.7926885485649109
The PSNR Value is: 18.217110188802085
the epoch is: 15
Loss at iteration 10 : 0.014365468174219131
Loss at iteration 20 : 0.02198757417500019
Loss at iteration 30 : 0.015662796795368195
Loss at iteration 40 : 0.009741034358739853
Loss at iteration 50 : 0.013037377968430519
Loss at iteration 60 : 0.01747935265302658
Loss at iteration 70 : 0.014390171505510807
Loss at iteration 80 : 0.017311755567789078
Loss at iteration 90 : 0.015053210780024529
Loss at iteration 100 : 0.022402947768568993
Loss at iteration 110 : 0.01973116397857666
Loss at iteration 120 : 0.010142308659851551
Loss at iteration 130 : 0.026791639626026154
Loss at iteration 140 : 0.02146073430776596
Loss at iteration 150 : 0.011340776458382607
Loss at iteration 160 : 0.009213668294250965
Loss at iteration 170 : 0.014567358419299126
Loss at iteration 180 : 0.021998954936861992
Loss at iteration 190 : 0.011663991026580334
Loss at iteration 200 : 0.020590106025338173
Loss at iteration 210 : 0.013996408320963383
Loss at iteration 220 : 0.019504692405462265
Loss at iteration 230 : 0.020277265459299088
Loss at iteration 240 : 0.010746626183390617
Loss at iteration 250 : 0.012622062116861343
Loss at iteration 260 : 0.01480913907289505
Loss at iteration 270 : 0.02248399332165718
Loss at iteration 280 : 0.024169541895389557
Loss at iteration 290 : 0.014850668609142303
Loss at iteration 300 : 0.018699435517191887
Loss at iteration 310 : 0.02096594125032425
Loss at iteration 320 : 0.018533453345298767
Loss at iteration 330 : 0.015972768887877464
Loss at iteration 340 : 0.01553376205265522
Loss at iteration 350 : 0.012878680601716042
Loss at iteration 360 : 0.014549272134900093
Loss at iteration 370 : 0.02324935793876648
Loss at iteration 380 : 0.011651793494820595
Loss at iteration 390 : 0.013744979165494442
Loss at iteration 400 : 0.012450877577066422
Loss at iteration 410 : 0.0078011322766542435
Loss at iteration 420 : 0.01179150864481926
Loss at iteration 430 : 0.01328205969184637
Loss at iteration 440 : 0.008757993578910828
Loss at iteration 450 : 0.016367170959711075
Loss at iteration 460 : 0.018693845719099045
Loss at iteration 470 : 0.013200191780924797
Loss at iteration 480 : 0.015090731903910637
Loss at iteration 490 : 0.01869550533592701
Loss at iteration 500 : 0.013050653971731663
Loss at iteration 510 : 0.011125344783067703
Loss at iteration 520 : 0.0065269689075648785
Loss at iteration 530 : 0.021279145032167435
Loss at iteration 540 : 0.013765383511781693
Loss at iteration 550 : 0.012640010565519333
Loss at iteration 560 : 0.01593019627034664
Loss at iteration 570 : 0.020641805604100227
Loss at iteration 580 : 0.015875257551670074
Loss at iteration 590 : 0.015439189970493317
Loss at iteration 600 : 0.018814947456121445
Loss at iteration 610 : 0.015306119807064533
Loss at iteration 620 : 0.01550360769033432
Loss at iteration 630 : 0.015795156359672546
Loss at iteration 640 : 0.022698089480400085
Loss at iteration 650 : 0.007761784829199314
Loss at iteration 660 : 0.013331224210560322
Loss at iteration 670 : 0.013083741068840027
Loss at iteration 680 : 0.01179662998765707
Loss at iteration 690 : 0.012828335165977478
Loss at iteration 700 : 0.015849700197577477
Loss at iteration 710 : 0.014261853881180286
Loss at iteration 720 : 0.015146493911743164
Loss at iteration 730 : 0.01823098585009575
Loss at iteration 740 : 0.036648720502853394
Loss at iteration 750 : 0.018862631171941757
Loss at iteration 760 : 0.017145685851573944
Loss at iteration 770 : 0.015560714527964592
Loss at iteration 780 : 0.013467558659613132
Loss at iteration 790 : 0.02035081572830677
Loss at iteration 800 : 0.022583141922950745
Loss at iteration 810 : 0.012296666391193867
Loss at iteration 820 : 0.0112262312322855
Loss at iteration 830 : 0.013736706227064133
Loss at iteration 840 : 0.01846281811594963
Loss at iteration 850 : 0.010041490197181702
Loss at iteration 860 : 0.011573961935937405
Loss at iteration 870 : 0.011402013711631298
Loss at iteration 880 : 0.008272537030279636
Loss at iteration 890 : 0.010168951004743576
Loss at iteration 900 : 0.007620060350745916
Loss at iteration 910 : 0.017514945939183235
Loss at iteration 920 : 0.014667811803519726
Loss at iteration 930 : 0.014993774704635143
Loss at iteration 940 : 0.015781104564666748
Loss at iteration 950 : 0.020748842507600784
Loss at iteration 960 : 0.019228246062994003
Loss at iteration 970 : 0.014676189050078392
Loss at iteration 980 : 0.018269892781972885
Loss at iteration 990 : 0.01304704137146473
Loss at iteration 1000 : 0.016143931075930595
Loss at iteration 1010 : 0.015107175335288048
Loss at iteration 1020 : 0.014521320350468159
Loss at iteration 1030 : 0.015718262642621994
Loss at iteration 1040 : 0.019874397665262222
Loss at iteration 1050 : 0.01521763950586319
Loss at iteration 1060 : 0.021000169217586517
Loss at iteration 1070 : 0.018658481538295746
Loss at iteration 1080 : 0.018912585452198982
Loss at iteration 1090 : 0.017732739448547363
Loss at iteration 1100 : 0.013176027685403824
Loss at iteration 1110 : 0.014104416593909264
Loss at iteration 1120 : 0.009805004112422466
Loss at iteration 1130 : 0.020057762041687965
Loss at iteration 1140 : 0.005544579587876797
Loss at iteration 1150 : 0.021709542721509933
Loss at iteration 1160 : 0.014510801993310452
Loss at iteration 1170 : 0.017315920442342758
Loss at iteration 1180 : 0.011756286025047302
Loss at iteration 1190 : 0.016314446926116943
Loss at iteration 1200 : 0.015604629181325436
Loss at iteration 1210 : 0.015520326793193817
The SSIM Value is: 0.796348488330841
The PSNR Value is: 18.176299222310384
the epoch is: 16
Loss at iteration 10 : 0.0187748521566391
Loss at iteration 20 : 0.021655075252056122
Loss at iteration 30 : 0.021616697311401367
Loss at iteration 40 : 0.011687506921589375
Loss at iteration 50 : 0.013157817535102367
Loss at iteration 60 : 0.019489314407110214
Loss at iteration 70 : 0.012105734087526798
Loss at iteration 80 : 0.0109435198828578
Loss at iteration 90 : 0.013607087545096874
Loss at iteration 100 : 0.015937576070427895
Loss at iteration 110 : 0.020027751103043556
Loss at iteration 120 : 0.020061466842889786
Loss at iteration 130 : 0.02022966369986534
Loss at iteration 140 : 0.018297826871275902
Loss at iteration 150 : 0.01534308958798647
Loss at iteration 160 : 0.013071401976048946
Loss at iteration 170 : 0.013234967365860939
Loss at iteration 180 : 0.019468938931822777
Loss at iteration 190 : 0.017705053091049194
Loss at iteration 200 : 0.013571392744779587
Loss at iteration 210 : 0.014432745054364204
Loss at iteration 220 : 0.024956727400422096
Loss at iteration 230 : 0.013774611987173557
Loss at iteration 240 : 0.016889581456780434
Loss at iteration 250 : 0.008224819786846638
Loss at iteration 260 : 0.019812505692243576
Loss at iteration 270 : 0.018378211185336113
Loss at iteration 280 : 0.018258390948176384
Loss at iteration 290 : 0.015007808804512024
Loss at iteration 300 : 0.010790343396365643
Loss at iteration 310 : 0.019673597067594528
Loss at iteration 320 : 0.01315300166606903
Loss at iteration 330 : 0.014797630719840527
Loss at iteration 340 : 0.013834238052368164
Loss at iteration 350 : 0.014267286285758018
Loss at iteration 360 : 0.022394195199012756
Loss at iteration 370 : 0.023610558360815048
Loss at iteration 380 : 0.018756143748760223
Loss at iteration 390 : 0.019308287650346756
Loss at iteration 400 : 0.01822352036833763
Loss at iteration 410 : 0.01631562039256096
Loss at iteration 420 : 0.01246749795973301
Loss at iteration 430 : 0.013001777231693268
Loss at iteration 440 : 0.01794862002134323
Loss at iteration 450 : 0.020700810477137566
Loss at iteration 460 : 0.01154259592294693
Loss at iteration 470 : 0.011611422523856163
Loss at iteration 480 : 0.008094741962850094
Loss at iteration 490 : 0.014018245972692966
Loss at iteration 500 : 0.018689319491386414
Loss at iteration 510 : 0.009567618370056152
Loss at iteration 520 : 0.011863485909998417
Loss at iteration 530 : 0.01420653983950615
Loss at iteration 540 : 0.014730888418853283
Loss at iteration 550 : 0.0286048986017704
Loss at iteration 560 : 0.013979185372591019
Loss at iteration 570 : 0.016177983954548836
Loss at iteration 580 : 0.018537228927016258
Loss at iteration 590 : 0.015670202672481537
Loss at iteration 600 : 0.012700943276286125
Loss at iteration 610 : 0.007830965332686901
Loss at iteration 620 : 0.014230532571673393
Loss at iteration 630 : 0.017862213775515556
Loss at iteration 640 : 0.01162608154118061
Loss at iteration 650 : 0.016366828233003616
Loss at iteration 660 : 0.02139466628432274
Loss at iteration 670 : 0.010128711350262165
Loss at iteration 680 : 0.011119892820715904
Loss at iteration 690 : 0.021388284862041473
Loss at iteration 700 : 0.030374180525541306
Loss at iteration 710 : 0.012758876197040081
Loss at iteration 720 : 0.02607344463467598
Loss at iteration 730 : 0.013509713113307953
Loss at iteration 740 : 0.014808747917413712
Loss at iteration 750 : 0.01666536182165146
Loss at iteration 760 : 0.01557364221662283
Loss at iteration 770 : 0.013783292844891548
Loss at iteration 780 : 0.01236911304295063
Loss at iteration 790 : 0.011131547391414642
Loss at iteration 800 : 0.014834205619990826
Loss at iteration 810 : 0.012442275881767273
Loss at iteration 820 : 0.013310234993696213
Loss at iteration 830 : 0.02112792804837227
Loss at iteration 840 : 0.011488526128232479
Loss at iteration 850 : 0.016263725236058235
Loss at iteration 860 : 0.01958891749382019
Loss at iteration 870 : 0.011058344505727291
Loss at iteration 880 : 0.016352185979485512
Loss at iteration 890 : 0.012031997554004192
Loss at iteration 900 : 0.016228511929512024
Loss at iteration 910 : 0.010670451447367668
Loss at iteration 920 : 0.009232385084033012
Loss at iteration 930 : 0.01662445068359375
Loss at iteration 940 : 0.01204015128314495
Loss at iteration 950 : 0.013336366042494774
Loss at iteration 960 : 0.014401978813111782
Loss at iteration 970 : 0.016336072236299515
Loss at iteration 980 : 0.020745836198329926
Loss at iteration 990 : 0.008972316980361938
Loss at iteration 1000 : 0.012156829237937927
Loss at iteration 1010 : 0.015083879232406616
Loss at iteration 1020 : 0.0110620791092515
Loss at iteration 1030 : 0.014664080925285816
Loss at iteration 1040 : 0.026735957711935043
Loss at iteration 1050 : 0.015899701043963432
Loss at iteration 1060 : 0.00885125994682312
Loss at iteration 1070 : 0.023721255362033844
Loss at iteration 1080 : 0.018655847758054733
Loss at iteration 1090 : 0.011991012841463089
Loss at iteration 1100 : 0.013583400286734104
Loss at iteration 1110 : 0.01033039577305317
Loss at iteration 1120 : 0.014240588061511517
Loss at iteration 1130 : 0.020097561180591583
Loss at iteration 1140 : 0.015744492411613464
Loss at iteration 1150 : 0.017156533896923065
Loss at iteration 1160 : 0.00878567062318325
Loss at iteration 1170 : 0.010364880785346031
Loss at iteration 1180 : 0.016008328646421432
Loss at iteration 1190 : 0.019606593996286392
Loss at iteration 1200 : 0.012755973264575005
Loss at iteration 1210 : 0.012211025692522526
The SSIM Value is: 0.7849135319391887
The PSNR Value is: 17.64739729563395
the epoch is: 17
Loss at iteration 10 : 0.014903626404702663
Loss at iteration 20 : 0.014194685034453869
Loss at iteration 30 : 0.018905144184827805
Loss at iteration 40 : 0.01508000586181879
Loss at iteration 50 : 0.020632794126868248
Loss at iteration 60 : 0.01660158298909664
Loss at iteration 70 : 0.018863359466195107
Loss at iteration 80 : 0.018165938556194305
Loss at iteration 90 : 0.0107466084882617
Loss at iteration 100 : 0.012440150603652
Loss at iteration 110 : 0.009808308444917202
Loss at iteration 120 : 0.010270355269312859
Loss at iteration 130 : 0.018375396728515625
Loss at iteration 140 : 0.015506904572248459
Loss at iteration 150 : 0.01566372811794281
Loss at iteration 160 : 0.012769816443324089
Loss at iteration 170 : 0.0158909372985363
Loss at iteration 180 : 0.012330962345004082
Loss at iteration 190 : 0.020809346809983253
Loss at iteration 200 : 0.018344171345233917
Loss at iteration 210 : 0.014662254601716995
Loss at iteration 220 : 0.015181277878582478
Loss at iteration 230 : 0.011670682579278946
Loss at iteration 240 : 0.0189885925501585
Loss at iteration 250 : 0.01766953244805336
Loss at iteration 260 : 0.016494372859597206
Loss at iteration 270 : 0.0170282069593668
Loss at iteration 280 : 0.015842748805880547
Loss at iteration 290 : 0.01682213693857193
Loss at iteration 300 : 0.020895903930068016
Loss at iteration 310 : 0.0112849660217762
Loss at iteration 320 : 0.014486005529761314
Loss at iteration 330 : 0.010587791912257671
Loss at iteration 340 : 0.017846938222646713
Loss at iteration 350 : 0.015431318432092667
Loss at iteration 360 : 0.014140129089355469
Loss at iteration 370 : 0.015815453603863716
Loss at iteration 380 : 0.01685383915901184
Loss at iteration 390 : 0.010538946837186813
Loss at iteration 400 : 0.015608353540301323
Loss at iteration 410 : 0.020045919343829155
Loss at iteration 420 : 0.01792595535516739
Loss at iteration 430 : 0.01549881137907505
Loss at iteration 440 : 0.015167837962508202
Loss at iteration 450 : 0.023076381534337997
Loss at iteration 460 : 0.01671944186091423
Loss at iteration 470 : 0.009643318131566048
Loss at iteration 480 : 0.021290350705385208
Loss at iteration 490 : 0.014522773213684559
Loss at iteration 500 : 0.018110092729330063
Loss at iteration 510 : 0.015544142574071884
Loss at iteration 520 : 0.012023107148706913
Loss at iteration 530 : 0.01847275346517563
Loss at iteration 540 : 0.01868418976664543
Loss at iteration 550 : 0.014027255587279797
Loss at iteration 560 : 0.016176873818039894
Loss at iteration 570 : 0.006086661480367184
Loss at iteration 580 : 0.01937304623425007
Loss at iteration 590 : 0.01608334295451641
Loss at iteration 600 : 0.0111503005027771
Loss at iteration 610 : 0.012449813075363636
Loss at iteration 620 : 0.012078902684152126
Loss at iteration 630 : 0.014532797038555145
Loss at iteration 640 : 0.017135225236415863
Loss at iteration 650 : 0.018128708004951477
Loss at iteration 660 : 0.01874573528766632
Loss at iteration 670 : 0.01271391473710537
Loss at iteration 680 : 0.017390940338373184
Loss at iteration 690 : 0.016962509602308273
Loss at iteration 700 : 0.020624570548534393
Loss at iteration 710 : 0.013323226943612099
Loss at iteration 720 : 0.01837402954697609
Loss at iteration 730 : 0.014784923754632473
Loss at iteration 740 : 0.01862567849457264
Loss at iteration 750 : 0.012464780360460281
Loss at iteration 760 : 0.00809391401708126
Loss at iteration 770 : 0.013600433245301247
Loss at iteration 780 : 0.01264837384223938
Loss at iteration 790 : 0.008059403859078884
Loss at iteration 800 : 0.009916109964251518
Loss at iteration 810 : 0.02455059066414833
Loss at iteration 820 : 0.026594478636980057
Loss at iteration 830 : 0.012255433946847916
Loss at iteration 840 : 0.014701888896524906
Loss at iteration 850 : 0.011692277155816555
Loss at iteration 860 : 0.015398886054754257
Loss at iteration 870 : 0.01291092112660408
Loss at iteration 880 : 0.010450303554534912
Loss at iteration 890 : 0.0157229732722044
Loss at iteration 900 : 0.013688383623957634
Loss at iteration 910 : 0.02359878458082676
Loss at iteration 920 : 0.011276605539023876
Loss at iteration 930 : 0.015800561755895615
Loss at iteration 940 : 0.011571506038308144
Loss at iteration 950 : 0.01715569756925106
Loss at iteration 960 : 0.014147045090794563
Loss at iteration 970 : 0.01303434744477272
Loss at iteration 980 : 0.016105525195598602
Loss at iteration 990 : 0.015963371843099594
Loss at iteration 1000 : 0.01552078127861023
Loss at iteration 1010 : 0.01466276403516531
Loss at iteration 1020 : 0.017324605956673622
Loss at iteration 1030 : 0.020568836480379105
Loss at iteration 1040 : 0.01648949645459652
Loss at iteration 1050 : 0.014695342630147934
Loss at iteration 1060 : 0.0140283964574337
Loss at iteration 1070 : 0.011250795796513557
Loss at iteration 1080 : 0.015779167413711548
Loss at iteration 1090 : 0.012734346091747284
Loss at iteration 1100 : 0.014966200105845928
Loss at iteration 1110 : 0.009794296696782112
Loss at iteration 1120 : 0.015260946936905384
Loss at iteration 1130 : 0.015537946484982967
Loss at iteration 1140 : 0.020791351795196533
Loss at iteration 1150 : 0.02080020308494568
Loss at iteration 1160 : 0.01784025877714157
Loss at iteration 1170 : 0.019964300096035004
Loss at iteration 1180 : 0.02181844785809517
Loss at iteration 1190 : 0.013405023142695427
Loss at iteration 1200 : 0.014186246320605278
Loss at iteration 1210 : 0.019662510603666306
The SSIM Value is: 0.7571395198504131
The PSNR Value is: 17.6409397761027
the epoch is: 18
Loss at iteration 10 : 0.013867279514670372
Loss at iteration 20 : 0.019473906606435776
Loss at iteration 30 : 0.009768198244273663
Loss at iteration 40 : 0.0210865568369627
Loss at iteration 50 : 0.02587616629898548
Loss at iteration 60 : 0.011417282745242119
Loss at iteration 70 : 0.013665882870554924
Loss at iteration 80 : 0.015960047021508217
Loss at iteration 90 : 0.01369814109057188
Loss at iteration 100 : 0.015518004074692726
Loss at iteration 110 : 0.008146385662257671
Loss at iteration 120 : 0.013679664582014084
Loss at iteration 130 : 0.016606613993644714
Loss at iteration 140 : 0.013914309442043304
Loss at iteration 150 : 0.010676519013941288
Loss at iteration 160 : 0.016873829066753387
Loss at iteration 170 : 0.012045832350850105
Loss at iteration 180 : 0.013888395391404629
Loss at iteration 190 : 0.018776018172502518
Loss at iteration 200 : 0.019614165648818016
Loss at iteration 210 : 0.02055373415350914
Loss at iteration 220 : 0.017831120640039444
Loss at iteration 230 : 0.013075807131826878
Loss at iteration 240 : 0.010377963073551655
Loss at iteration 250 : 0.013652858324348927
Loss at iteration 260 : 0.015458482317626476
Loss at iteration 270 : 0.01234268769621849
Loss at iteration 280 : 0.014364372938871384
Loss at iteration 290 : 0.013436509296298027
Loss at iteration 300 : 0.00930818635970354
Loss at iteration 310 : 0.0197325199842453
Loss at iteration 320 : 0.010533188469707966
Loss at iteration 330 : 0.009571138769388199
Loss at iteration 340 : 0.017348207533359528
Loss at iteration 350 : 0.012951862066984177
Loss at iteration 360 : 0.015758566558361053
Loss at iteration 370 : 0.01833862066268921
Loss at iteration 380 : 0.006870562210679054
Loss at iteration 390 : 0.020385289564728737
Loss at iteration 400 : 0.010422054678201675
Loss at iteration 410 : 0.014091303572058678
Loss at iteration 420 : 0.013504302129149437
Loss at iteration 430 : 0.012041785754263401
Loss at iteration 440 : 0.012223254889249802
Loss at iteration 450 : 0.01339668594300747
Loss at iteration 460 : 0.018040113151073456
Loss at iteration 470 : 0.014265249483287334
Loss at iteration 480 : 0.00987011007964611
Loss at iteration 490 : 0.016098465770483017
Loss at iteration 500 : 0.007319778203964233
Loss at iteration 510 : 0.020725836977362633
Loss at iteration 520 : 0.018092133104801178
Loss at iteration 530 : 0.013489775359630585
Loss at iteration 540 : 0.02435203641653061
Loss at iteration 550 : 0.01426416914910078
Loss at iteration 560 : 0.011867489665746689
Loss at iteration 570 : 0.012163459323346615
Loss at iteration 580 : 0.013424837030470371
Loss at iteration 590 : 0.01277615875005722
Loss at iteration 600 : 0.01608441025018692
Loss at iteration 610 : 0.011756768450140953
Loss at iteration 620 : 0.019164491444826126
Loss at iteration 630 : 0.014526775106787682
Loss at iteration 640 : 0.014996768906712532
Loss at iteration 650 : 0.02265249565243721
Loss at iteration 660 : 0.016384724527597427
Loss at iteration 670 : 0.007259783800691366
Loss at iteration 680 : 0.00995552260428667
Loss at iteration 690 : 0.009054144844412804
Loss at iteration 700 : 0.02055157721042633
Loss at iteration 710 : 0.017343655228614807
Loss at iteration 720 : 0.014377934858202934
Loss at iteration 730 : 0.01582479476928711
Loss at iteration 740 : 0.01533615030348301
Loss at iteration 750 : 0.014752986840903759
Loss at iteration 760 : 0.010682209394872189
Loss at iteration 770 : 0.010530810803174973
Loss at iteration 780 : 0.018212012946605682
Loss at iteration 790 : 0.008256298489868641
Loss at iteration 800 : 0.017572389915585518
Loss at iteration 810 : 0.015032870694994926
Loss at iteration 820 : 0.011293282732367516
Loss at iteration 830 : 0.014318656176328659
Loss at iteration 840 : 0.012629922479391098
Loss at iteration 850 : 0.012715141288936138
Loss at iteration 860 : 0.019535906612873077
Loss at iteration 870 : 0.012457001022994518
Loss at iteration 880 : 0.01689785160124302
Loss at iteration 890 : 0.014451802708208561
Loss at iteration 900 : 0.013731265440583229
Loss at iteration 910 : 0.010525340214371681
Loss at iteration 920 : 0.011923575773835182
Loss at iteration 930 : 0.010857751592993736
Loss at iteration 940 : 0.014039294794201851
Loss at iteration 950 : 0.023127734661102295
Loss at iteration 960 : 0.015938345342874527
Loss at iteration 970 : 0.00860021822154522
Loss at iteration 980 : 0.013638436794281006
Loss at iteration 990 : 0.014486871659755707
Loss at iteration 1000 : 0.013311350718140602
Loss at iteration 1010 : 0.01612011343240738
Loss at iteration 1020 : 0.01814139634370804
Loss at iteration 1030 : 0.014459554105997086
Loss at iteration 1040 : 0.019294505938887596
Loss at iteration 1050 : 0.015438081696629524
Loss at iteration 1060 : 0.013044783845543861
Loss at iteration 1070 : 0.01902182586491108
Loss at iteration 1080 : 0.013658976182341576
Loss at iteration 1090 : 0.01685202866792679
Loss at iteration 1100 : 0.011400707066059113
Loss at iteration 1110 : 0.020385336130857468
Loss at iteration 1120 : 0.010213745757937431
Loss at iteration 1130 : 0.01988682895898819
Loss at iteration 1140 : 0.0143718421459198
Loss at iteration 1150 : 0.015063907019793987
Loss at iteration 1160 : 0.01397175993770361
Loss at iteration 1170 : 0.013736685737967491
Loss at iteration 1180 : 0.014153236523270607
Loss at iteration 1190 : 0.018791642040014267
Loss at iteration 1200 : 0.013244683854281902
Loss at iteration 1210 : 0.011445802636444569
The SSIM Value is: 0.7999967455863952
The PSNR Value is: 18.579981931050618
the highest SSIM value is: 18.579981931050618
the epoch is: 19
Loss at iteration 10 : 0.010180212557315826
Loss at iteration 20 : 0.011307594366371632
Loss at iteration 30 : 0.0130486274138093
Loss at iteration 40 : 0.009949449449777603
Loss at iteration 50 : 0.022388126701116562
Loss at iteration 60 : 0.011868909001350403
Loss at iteration 70 : 0.014437692239880562
Loss at iteration 80 : 0.009896736592054367
Loss at iteration 90 : 0.012927301228046417
Loss at iteration 100 : 0.017144665122032166
Loss at iteration 110 : 0.02328123152256012
Loss at iteration 120 : 0.017643200233578682
Loss at iteration 130 : 0.02059018239378929
Loss at iteration 140 : 0.009982670657336712
Loss at iteration 150 : 0.01634760946035385
Loss at iteration 160 : 0.013973871245980263
Loss at iteration 170 : 0.02072470635175705
Loss at iteration 180 : 0.01725403591990471
Loss at iteration 190 : 0.015514439903199673
Loss at iteration 200 : 0.01869112066924572
Loss at iteration 210 : 0.03007498010993004
Loss at iteration 220 : 0.013238420709967613
Loss at iteration 230 : 0.016544468700885773
Loss at iteration 240 : 0.01571917161345482
Loss at iteration 250 : 0.014799007214605808
Loss at iteration 260 : 0.009510761126875877
Loss at iteration 270 : 0.01594565249979496
Loss at iteration 280 : 0.015034358948469162
Loss at iteration 290 : 0.018074626103043556
Loss at iteration 300 : 0.01352330856025219
Loss at iteration 310 : 0.009685478173196316
Loss at iteration 320 : 0.0104625029489398
Loss at iteration 330 : 0.016478251665830612
Loss at iteration 340 : 0.011091104708611965
Loss at iteration 350 : 0.00872562825679779
Loss at iteration 360 : 0.016339529305696487
Loss at iteration 370 : 0.020993100479245186
Loss at iteration 380 : 0.016101401299238205
Loss at iteration 390 : 0.011895948089659214
Loss at iteration 400 : 0.01631397008895874
Loss at iteration 410 : 0.012399032711982727
Loss at iteration 420 : 0.020613374188542366
Loss at iteration 430 : 0.01326910313218832
Loss at iteration 440 : 0.02034887485206127
Loss at iteration 450 : 0.01477290503680706
Loss at iteration 460 : 0.01603953167796135
Loss at iteration 470 : 0.013346226885914803
Loss at iteration 480 : 0.007054041605442762
Loss at iteration 490 : 0.015259608626365662
Loss at iteration 500 : 0.012013115920126438
Loss at iteration 510 : 0.013873166404664516
Loss at iteration 520 : 0.020708639174699783
Loss at iteration 530 : 0.019959352910518646
Loss at iteration 540 : 0.011437713168561459
Loss at iteration 550 : 0.009649927727878094
Loss at iteration 560 : 0.028657251968979836
Loss at iteration 570 : 0.015100108459591866
Loss at iteration 580 : 0.019020119681954384
Loss at iteration 590 : 0.016523070633411407
Loss at iteration 600 : 0.013306250795722008
Loss at iteration 610 : 0.020104065537452698
Loss at iteration 620 : 0.019783716648817062
Loss at iteration 630 : 0.014254441484808922
Loss at iteration 640 : 0.013362368568778038
Loss at iteration 650 : 0.015154489316046238
Loss at iteration 660 : 0.016845863312482834
Loss at iteration 670 : 0.009586373344063759
Loss at iteration 680 : 0.01601465791463852
Loss at iteration 690 : 0.011329466477036476
Loss at iteration 700 : 0.017390431836247444
Loss at iteration 710 : 0.014293800108134747
Loss at iteration 720 : 0.015994928777217865
Loss at iteration 730 : 0.008053518831729889
Loss at iteration 740 : 0.0104179996997118
Loss at iteration 750 : 0.009996237233281136
Loss at iteration 760 : 0.01513401698321104
Loss at iteration 770 : 0.02088199183344841
Loss at iteration 780 : 0.02003902941942215
Loss at iteration 790 : 0.016694404184818268
Loss at iteration 800 : 0.02327454462647438
Loss at iteration 810 : 0.01775604486465454
Loss at iteration 820 : 0.013074668124318123
Loss at iteration 830 : 0.017523691058158875
Loss at iteration 840 : 0.010271056555211544
Loss at iteration 850 : 0.020540039986371994
Loss at iteration 860 : 0.020510610193014145
Loss at iteration 870 : 0.019240329042077065
Loss at iteration 880 : 0.010814588516950607
Loss at iteration 890 : 0.013090529479086399
Loss at iteration 900 : 0.024777354672551155
Loss at iteration 910 : 0.014166557230055332
Loss at iteration 920 : 0.011410976760089397
Loss at iteration 930 : 0.007847815752029419
Loss at iteration 940 : 0.019861280918121338
Loss at iteration 950 : 0.015647798776626587
Loss at iteration 960 : 0.01971472054719925
Loss at iteration 970 : 0.020431475713849068
Loss at iteration 980 : 0.016880225390195847
Loss at iteration 990 : 0.01259232871234417
Loss at iteration 1000 : 0.01596863940358162
Loss at iteration 1010 : 0.013567639514803886
Loss at iteration 1020 : 0.027331970632076263
Loss at iteration 1030 : 0.01135110855102539
Loss at iteration 1040 : 0.024596260860562325
Loss at iteration 1050 : 0.00955483503639698
Loss at iteration 1060 : 0.017422303557395935
Loss at iteration 1070 : 0.02045479603111744
Loss at iteration 1080 : 0.014300906099379063
Loss at iteration 1090 : 0.011699380353093147
Loss at iteration 1100 : 0.011146397329866886
Loss at iteration 1110 : 0.016719909384846687
Loss at iteration 1120 : 0.015155740082263947
Loss at iteration 1130 : 0.005705099552869797
Loss at iteration 1140 : 0.019064191728830338
Loss at iteration 1150 : 0.009913311339914799
Loss at iteration 1160 : 0.030658621340990067
Loss at iteration 1170 : 0.011732271872460842
Loss at iteration 1180 : 0.01387768890708685
Loss at iteration 1190 : 0.015647023916244507
Loss at iteration 1200 : 0.015026150271296501
Loss at iteration 1210 : 0.013772580772638321
The SSIM Value is: 0.7637138207753499
The PSNR Value is: 17.587411562601726
the epoch is: 20
Loss at iteration 10 : 0.010785595513880253
Loss at iteration 20 : 0.014448858797550201
Loss at iteration 30 : 0.01786264032125473
Loss at iteration 40 : 0.016224440187215805
Loss at iteration 50 : 0.011995790526270866
Loss at iteration 60 : 0.02164982445538044
Loss at iteration 70 : 0.018120506778359413
Loss at iteration 80 : 0.015441474504768848
Loss at iteration 90 : 0.017932474613189697
Loss at iteration 100 : 0.02445385977625847
Loss at iteration 110 : 0.02279483713209629
Loss at iteration 120 : 0.021016545593738556
Loss at iteration 130 : 0.011304831132292747
Loss at iteration 140 : 0.0222177617251873
Loss at iteration 150 : 0.015603199601173401
Loss at iteration 160 : 0.023044034838676453
Loss at iteration 170 : 0.01742691732943058
Loss at iteration 180 : 0.013916661962866783
Loss at iteration 190 : 0.01928711123764515
Loss at iteration 200 : 0.012725170701742172
Loss at iteration 210 : 0.014953161589801311
Loss at iteration 220 : 0.018691005185246468
Loss at iteration 230 : 0.021914605051279068
Loss at iteration 240 : 0.015498241409659386
Loss at iteration 250 : 0.01199539564549923
Loss at iteration 260 : 0.01339639537036419
Loss at iteration 270 : 0.013874209485948086
Loss at iteration 280 : 0.017271602526307106
Loss at iteration 290 : 0.019897907972335815
Loss at iteration 300 : 0.017437178641557693
Loss at iteration 310 : 0.01392635889351368
Loss at iteration 320 : 0.01721975952386856
Loss at iteration 330 : 0.014904078096151352
Loss at iteration 340 : 0.01151323039084673
Loss at iteration 350 : 0.008093584328889847
Loss at iteration 360 : 0.013773404993116856
Loss at iteration 370 : 0.01681988686323166
Loss at iteration 380 : 0.01596491038799286
Loss at iteration 390 : 0.012777871452271938
Loss at iteration 400 : 0.01885436847805977
Loss at iteration 410 : 0.009723891504108906
Loss at iteration 420 : 0.012081459164619446
Loss at iteration 430 : 0.007769556250423193
Loss at iteration 440 : 0.014313455671072006
Loss at iteration 450 : 0.01613572984933853
Loss at iteration 460 : 0.015761271119117737
Loss at iteration 470 : 0.014259540475904942
Loss at iteration 480 : 0.021911706775426865
Loss at iteration 490 : 0.01405643206089735
Loss at iteration 500 : 0.015711097046732903
Loss at iteration 510 : 0.007340782321989536
Loss at iteration 520 : 0.018181610852479935
Loss at iteration 530 : 0.018192242830991745
Loss at iteration 540 : 0.012933927588164806
Loss at iteration 550 : 0.024599380791187286
Loss at iteration 560 : 0.01348110567778349
Loss at iteration 570 : 0.012958984822034836
Loss at iteration 580 : 0.02492590993642807
Loss at iteration 590 : 0.013498558662831783
Loss at iteration 600 : 0.01973346248269081
Loss at iteration 610 : 0.014876146800816059
Loss at iteration 620 : 0.013401495292782784
Loss at iteration 630 : 0.009514196775853634
Loss at iteration 640 : 0.013708728365600109
Loss at iteration 650 : 0.013640515506267548
Loss at iteration 660 : 0.018029749393463135
Loss at iteration 670 : 0.00858157966285944
Loss at iteration 680 : 0.012017807923257351
Loss at iteration 690 : 0.02782221883535385
Loss at iteration 700 : 0.013227744027972221
Loss at iteration 710 : 0.011272098869085312
Loss at iteration 720 : 0.016095992177724838
Loss at iteration 730 : 0.0195465087890625
Loss at iteration 740 : 0.01638501137495041
Loss at iteration 750 : 0.016286753118038177
Loss at iteration 760 : 0.011483956128358841
Loss at iteration 770 : 0.012755193747580051
Loss at iteration 780 : 0.015176868997514248
Loss at iteration 790 : 0.01199653372168541
Loss at iteration 800 : 0.016924988478422165
Loss at iteration 810 : 0.021976836025714874
Loss at iteration 820 : 0.00947926752269268
Loss at iteration 830 : 0.018487166613340378
Loss at iteration 840 : 0.013348986394703388
Loss at iteration 850 : 0.01703234761953354
Loss at iteration 860 : 0.008829771541059017
Loss at iteration 870 : 0.016081325709819794
Loss at iteration 880 : 0.010479932650923729
Loss at iteration 890 : 0.01137351430952549
Loss at iteration 900 : 0.017571406438946724
Loss at iteration 910 : 0.020980574190616608
Loss at iteration 920 : 0.021686673164367676
Loss at iteration 930 : 0.01816391572356224
Loss at iteration 940 : 0.012365197762846947
Loss at iteration 950 : 0.014596382156014442
Loss at iteration 960 : 0.01745338924229145
Loss at iteration 970 : 0.012562938034534454
Loss at iteration 980 : 0.01267185527831316
Loss at iteration 990 : 0.008795268833637238
Loss at iteration 1000 : 0.012979444116353989
Loss at iteration 1010 : 0.00908270850777626
Loss at iteration 1020 : 0.01173124648630619
Loss at iteration 1030 : 0.01152198575437069
Loss at iteration 1040 : 0.012052125297486782
Loss at iteration 1050 : 0.021772857755422592
Loss at iteration 1060 : 0.015598899684846401
Loss at iteration 1070 : 0.013986848294734955
Loss at iteration 1080 : 0.022183943539857864
Loss at iteration 1090 : 0.014568546786904335
Loss at iteration 1100 : 0.012870163656771183
Loss at iteration 1110 : 0.017841603606939316
Loss at iteration 1120 : 0.01937505044043064
Loss at iteration 1130 : 0.019966166466474533
Loss at iteration 1140 : 0.01481750700622797
Loss at iteration 1150 : 0.015379845164716244
Loss at iteration 1160 : 0.015834316611289978
Loss at iteration 1170 : 0.011307391338050365
Loss at iteration 1180 : 0.010407775640487671
Loss at iteration 1190 : 0.017610089853405952
Loss at iteration 1200 : 0.013926884159445763
Loss at iteration 1210 : 0.01638352870941162
The SSIM Value is: 0.792620583375295
The PSNR Value is: 18.528183046976725
the epoch is: 21
Loss at iteration 10 : 0.02041703090071678
Loss at iteration 20 : 0.013560537248849869
Loss at iteration 30 : 0.015380477532744408
Loss at iteration 40 : 0.010801422409713268
Loss at iteration 50 : 0.023513415828347206
Loss at iteration 60 : 0.013881245627999306
Loss at iteration 70 : 0.014609093777835369
Loss at iteration 80 : 0.013898514211177826
Loss at iteration 90 : 0.01657070592045784
Loss at iteration 100 : 0.024603335186839104
Loss at iteration 110 : 0.01615688018500805
Loss at iteration 120 : 0.015039085410535336
Loss at iteration 130 : 0.011678701266646385
Loss at iteration 140 : 0.010920336470007896
Loss at iteration 150 : 0.01088740210980177
Loss at iteration 160 : 0.013520323671400547
Loss at iteration 170 : 0.010862588882446289
Loss at iteration 180 : 0.013035150244832039
Loss at iteration 190 : 0.01850959099829197
Loss at iteration 200 : 0.011379526928067207
Loss at iteration 210 : 0.018141262233257294
Loss at iteration 220 : 0.019753171131014824
Loss at iteration 230 : 0.012545395642518997
Loss at iteration 240 : 0.012067778035998344
Loss at iteration 250 : 0.01367449015378952
Loss at iteration 260 : 0.01043033692985773
Loss at iteration 270 : 0.013204725459218025
Loss at iteration 280 : 0.01512893009930849
Loss at iteration 290 : 0.01379036158323288
Loss at iteration 300 : 0.013454277999699116
Loss at iteration 310 : 0.015340504236519337
Loss at iteration 320 : 0.012457650154829025
Loss at iteration 330 : 0.013308843597769737
Loss at iteration 340 : 0.012334910221397877
Loss at iteration 350 : 0.012795072048902512
Loss at iteration 360 : 0.014252597466111183
Loss at iteration 370 : 0.01847907342016697
Loss at iteration 380 : 0.02040400542318821
Loss at iteration 390 : 0.013473236933350563
Loss at iteration 400 : 0.012374890968203545
Loss at iteration 410 : 0.013698242604732513
Loss at iteration 420 : 0.012594016268849373
Loss at iteration 430 : 0.014813230372965336
Loss at iteration 440 : 0.017624329775571823
Loss at iteration 450 : 0.0210577342659235
Loss at iteration 460 : 0.017867039889097214
Loss at iteration 470 : 0.00951846968382597
Loss at iteration 480 : 0.011393710039556026
Loss at iteration 490 : 0.013342509977519512
Loss at iteration 500 : 0.014704729430377483
Loss at iteration 510 : 0.014008844271302223
Loss at iteration 520 : 0.014616444706916809
Loss at iteration 530 : 0.02287708967924118
Loss at iteration 540 : 0.014442022889852524
Loss at iteration 550 : 0.015251203440129757
Loss at iteration 560 : 0.009816712699830532
Loss at iteration 570 : 0.0314374677836895
Loss at iteration 580 : 0.01742260903120041
Loss at iteration 590 : 0.01606488972902298
Loss at iteration 600 : 0.01470870990306139
Loss at iteration 610 : 0.012166202999651432
Loss at iteration 620 : 0.011772533878684044
Loss at iteration 630 : 0.011825475841760635
Loss at iteration 640 : 0.017846185714006424
Loss at iteration 650 : 0.015141049399971962
Loss at iteration 660 : 0.014326972886919975
Loss at iteration 670 : 0.020118936896324158
Loss at iteration 680 : 0.01360626146197319
Loss at iteration 690 : 0.012502152472734451
Loss at iteration 700 : 0.012109918519854546
Loss at iteration 710 : 0.011563804000616074
Loss at iteration 720 : 0.015977298840880394
Loss at iteration 730 : 0.017444536089897156
Loss at iteration 740 : 0.011343366466462612
Loss at iteration 750 : 0.019251316785812378
Loss at iteration 760 : 0.014330888167023659
Loss at iteration 770 : 0.01497594267129898
Loss at iteration 780 : 0.015111550688743591
Loss at iteration 790 : 0.020795883610844612
Loss at iteration 800 : 0.00852917693555355
Loss at iteration 810 : 0.017687896266579628
Loss at iteration 820 : 0.009389986284077168
Loss at iteration 830 : 0.012381630949676037
Loss at iteration 840 : 0.014550674706697464
Loss at iteration 850 : 0.02073368988931179
Loss at iteration 860 : 0.014654421247541904
Loss at iteration 870 : 0.011818142607808113
Loss at iteration 880 : 0.017856813967227936
Loss at iteration 890 : 0.01900237239897251
Loss at iteration 900 : 0.01392304990440607
Loss at iteration 910 : 0.029733575880527496
Loss at iteration 920 : 0.012989467941224575
Loss at iteration 930 : 0.014041883870959282
Loss at iteration 940 : 0.011559654958546162
Loss at iteration 950 : 0.014756357297301292
Loss at iteration 960 : 0.014039600268006325
Loss at iteration 970 : 0.017765110358595848
Loss at iteration 980 : 0.02596312016248703
Loss at iteration 990 : 0.018475955352187157
Loss at iteration 1000 : 0.01668250747025013
Loss at iteration 1010 : 0.010022400878369808
Loss at iteration 1020 : 0.01088639535009861
Loss at iteration 1030 : 0.01742689684033394
Loss at iteration 1040 : 0.009019854478538036
Loss at iteration 1050 : 0.016900617629289627
Loss at iteration 1060 : 0.015315113589167595
Loss at iteration 1070 : 0.019852526485919952
Loss at iteration 1080 : 0.013788270764052868
Loss at iteration 1090 : 0.016003679484128952
Loss at iteration 1100 : 0.014480996876955032
Loss at iteration 1110 : 0.022037938237190247
Loss at iteration 1120 : 0.01224378403276205
Loss at iteration 1130 : 0.012373726814985275
Loss at iteration 1140 : 0.009912488982081413
Loss at iteration 1150 : 0.019718090072274208
Loss at iteration 1160 : 0.010026433505117893
Loss at iteration 1170 : 0.016374995931982994
Loss at iteration 1180 : 0.00977388210594654
Loss at iteration 1190 : 0.00944795273244381
Loss at iteration 1200 : 0.012391860596835613
Loss at iteration 1210 : 0.013233721256256104
The SSIM Value is: 0.7965044061342875
The PSNR Value is: 18.41542689005534
the epoch is: 22
Loss at iteration 10 : 0.01863861083984375
Loss at iteration 20 : 0.014713408425450325
Loss at iteration 30 : 0.009138887748122215
Loss at iteration 40 : 0.013565750792622566
Loss at iteration 50 : 0.014294068329036236
Loss at iteration 60 : 0.012059955857694149
Loss at iteration 70 : 0.009666488505899906
Loss at iteration 80 : 0.01872921548783779
Loss at iteration 90 : 0.015361960977315903
Loss at iteration 100 : 0.012800970114767551
Loss at iteration 110 : 0.011220069602131844
Loss at iteration 120 : 0.013075956143438816
Loss at iteration 130 : 0.008274952881038189
Loss at iteration 140 : 0.030351566150784492
Loss at iteration 150 : 0.013350166380405426
Loss at iteration 160 : 0.023075604811310768
Loss at iteration 170 : 0.01676531508564949
Loss at iteration 180 : 0.016657229512929916
Loss at iteration 190 : 0.014909831807017326
Loss at iteration 200 : 0.01794951781630516
Loss at iteration 210 : 0.016069799661636353
Loss at iteration 220 : 0.01045597717165947
Loss at iteration 230 : 0.00670426432043314
Loss at iteration 240 : 0.021236758679151535
Loss at iteration 250 : 0.02535228803753853
Loss at iteration 260 : 0.01641516387462616
Loss at iteration 270 : 0.01774793490767479
Loss at iteration 280 : 0.01345868967473507
Loss at iteration 290 : 0.014853890985250473
Loss at iteration 300 : 0.02332353964447975
Loss at iteration 310 : 0.026692641898989677
Loss at iteration 320 : 0.01699102856218815
Loss at iteration 330 : 0.011201601475477219
Loss at iteration 340 : 0.00863609928637743
Loss at iteration 350 : 0.012570713646709919
Loss at iteration 360 : 0.01705526001751423
Loss at iteration 370 : 0.018908970057964325
Loss at iteration 380 : 0.016418708488345146
Loss at iteration 390 : 0.015284930355846882
Loss at iteration 400 : 0.012981574051082134
Loss at iteration 410 : 0.013860381208360195
Loss at iteration 420 : 0.016442574560642242
Loss at iteration 430 : 0.01604526862502098
Loss at iteration 440 : 0.016356006264686584
Loss at iteration 450 : 0.009698141366243362
Loss at iteration 460 : 0.018320977687835693
Loss at iteration 470 : 0.015712158754467964
Loss at iteration 480 : 0.019353149458765984
Loss at iteration 490 : 0.018862616270780563
Loss at iteration 500 : 0.015404192730784416
Loss at iteration 510 : 0.024046197533607483
Loss at iteration 520 : 0.018498389050364494
Loss at iteration 530 : 0.014505743980407715
Loss at iteration 540 : 0.016995321959257126
Loss at iteration 550 : 0.012183943763375282
Loss at iteration 560 : 0.014252971857786179
Loss at iteration 570 : 0.009153418242931366
Loss at iteration 580 : 0.014737908728420734
Loss at iteration 590 : 0.010283471085131168
Loss at iteration 600 : 0.010859539732336998
Loss at iteration 610 : 0.02607121877372265
Loss at iteration 620 : 0.020311802625656128
Loss at iteration 630 : 0.02461957558989525
Loss at iteration 640 : 0.030674222856760025
Loss at iteration 650 : 0.02338488958775997
Loss at iteration 660 : 0.010812392458319664
Loss at iteration 670 : 0.019629545509815216
Loss at iteration 680 : 0.008581016212701797
Loss at iteration 690 : 0.03496970236301422
Loss at iteration 700 : 0.009386274963617325
Loss at iteration 710 : 0.012310351245105267
Loss at iteration 720 : 0.01820552349090576
Loss at iteration 730 : 0.01243632286787033
Loss at iteration 740 : 0.009913135319948196
Loss at iteration 750 : 0.01166386529803276
Loss at iteration 760 : 0.010778268799185753
Loss at iteration 770 : 0.012688645161688328
Loss at iteration 780 : 0.02727038972079754
Loss at iteration 790 : 0.014457635581493378
Loss at iteration 800 : 0.011304093524813652
Loss at iteration 810 : 0.007324418053030968
Loss at iteration 820 : 0.01719127781689167
Loss at iteration 830 : 0.01890769600868225
Loss at iteration 840 : 0.010176371783018112
Loss at iteration 850 : 0.014273532666265965
Loss at iteration 860 : 0.013280179351568222
Loss at iteration 870 : 0.013636279851198196
Loss at iteration 880 : 0.014202700927853584
Loss at iteration 890 : 0.01767229661345482
Loss at iteration 900 : 0.016744030639529228
Loss at iteration 910 : 0.014215823262929916
Loss at iteration 920 : 0.012202857062220573
Loss at iteration 930 : 0.013197335414588451
Loss at iteration 940 : 0.009340961463749409
Loss at iteration 950 : 0.019021816551685333
Loss at iteration 960 : 0.012977204285562038
Loss at iteration 970 : 0.013065541163086891
Loss at iteration 980 : 0.010248769074678421
Loss at iteration 990 : 0.011654859408736229
Loss at iteration 1000 : 0.01875629648566246
Loss at iteration 1010 : 0.010855978354811668
Loss at iteration 1020 : 0.015565678477287292
Loss at iteration 1030 : 0.018118565902113914
Loss at iteration 1040 : 0.014623682014644146
Loss at iteration 1050 : 0.007131868042051792
Loss at iteration 1060 : 0.012513507157564163
Loss at iteration 1070 : 0.021382281556725502
Loss at iteration 1080 : 0.01719454675912857
Loss at iteration 1090 : 0.015473918057978153
Loss at iteration 1100 : 0.01037919893860817
Loss at iteration 1110 : 0.014340145513415337
Loss at iteration 1120 : 0.011640596203505993
Loss at iteration 1130 : 0.015723861753940582
Loss at iteration 1140 : 0.009759309701621532
Loss at iteration 1150 : 0.019592367112636566
Loss at iteration 1160 : 0.013526945374906063
Loss at iteration 1170 : 0.024870196357369423
Loss at iteration 1180 : 0.02269350364804268
Loss at iteration 1190 : 0.011537923477590084
Loss at iteration 1200 : 0.011737524531781673
Loss at iteration 1210 : 0.01614464819431305
The SSIM Value is: 0.793118929862976
The PSNR Value is: 18.596284739176433
the highest SSIM value is: 18.596284739176433
the epoch is: 23
Loss at iteration 10 : 0.015691999346017838
Loss at iteration 20 : 0.009801877662539482
Loss at iteration 30 : 0.00642988458275795
Loss at iteration 40 : 0.009075679816305637
Loss at iteration 50 : 0.011534307152032852
Loss at iteration 60 : 0.013933150097727776
Loss at iteration 70 : 0.009741488844156265
Loss at iteration 80 : 0.030654149129986763
Loss at iteration 90 : 0.012791674584150314
Loss at iteration 100 : 0.02207077667117119
Loss at iteration 110 : 0.013499672524631023
Loss at iteration 120 : 0.009225375019013882
Loss at iteration 130 : 0.012634841725230217
Loss at iteration 140 : 0.022751402109861374
Loss at iteration 150 : 0.013891339302062988
Loss at iteration 160 : 0.012825405225157738
Loss at iteration 170 : 0.015590895898640156
Loss at iteration 180 : 0.02695571444928646
Loss at iteration 190 : 0.00966992974281311
Loss at iteration 200 : 0.015323320403695107
Loss at iteration 210 : 0.012168400920927525
Loss at iteration 220 : 0.00820214580744505
Loss at iteration 230 : 0.02223096787929535
Loss at iteration 240 : 0.013788229785859585
Loss at iteration 250 : 0.009633834473788738
Loss at iteration 260 : 0.012980069033801556
Loss at iteration 270 : 0.01492977887392044
Loss at iteration 280 : 0.010972840711474419
Loss at iteration 290 : 0.009383462369441986
Loss at iteration 300 : 0.009684393182396889
Loss at iteration 310 : 0.017585892230272293
Loss at iteration 320 : 0.013585740700364113
Loss at iteration 330 : 0.014229046180844307
Loss at iteration 340 : 0.012590975500643253
Loss at iteration 350 : 0.012992262840270996
Loss at iteration 360 : 0.017868787050247192
Loss at iteration 370 : 0.01446759793907404
Loss at iteration 380 : 0.015587462112307549
Loss at iteration 390 : 0.01424163393676281
Loss at iteration 400 : 0.019606687128543854
Loss at iteration 410 : 0.028453655540943146
Loss at iteration 420 : 0.012263275682926178
Loss at iteration 430 : 0.008873844519257545
Loss at iteration 440 : 0.01098668109625578
Loss at iteration 450 : 0.01515593845397234
Loss at iteration 460 : 0.008923202753067017
Loss at iteration 470 : 0.014661727473139763
Loss at iteration 480 : 0.01546501461416483
Loss at iteration 490 : 0.01675897277891636
Loss at iteration 500 : 0.02010587602853775
Loss at iteration 510 : 0.010069126263260841
Loss at iteration 520 : 0.010931644588708878
Loss at iteration 530 : 0.015525606460869312
Loss at iteration 540 : 0.014326072297990322
Loss at iteration 550 : 0.016703756526112556
Loss at iteration 560 : 0.009993881918489933
Loss at iteration 570 : 0.016964375972747803
Loss at iteration 580 : 0.016098976135253906
Loss at iteration 590 : 0.016713084653019905
Loss at iteration 600 : 0.012144949287176132
Loss at iteration 610 : 0.012475034222006798
Loss at iteration 620 : 0.008818759582936764
Loss at iteration 630 : 0.017193667590618134
Loss at iteration 640 : 0.028146278113126755
Loss at iteration 650 : 0.014293122105300426
Loss at iteration 660 : 0.01713656820356846
Loss at iteration 670 : 0.015590399503707886
Loss at iteration 680 : 0.011984359472990036
Loss at iteration 690 : 0.01352282427251339
Loss at iteration 700 : 0.013244633562862873
Loss at iteration 710 : 0.014621448703110218
Loss at iteration 720 : 0.01308093499392271
Loss at iteration 730 : 0.013128847815096378
Loss at iteration 740 : 0.010055460035800934
Loss at iteration 750 : 0.01527191512286663
Loss at iteration 760 : 0.012671130709350109
Loss at iteration 770 : 0.0166096780449152
Loss at iteration 780 : 0.015234744176268578
Loss at iteration 790 : 0.02280740812420845
Loss at iteration 800 : 0.013196715153753757
Loss at iteration 810 : 0.014149961061775684
Loss at iteration 820 : 0.01628519780933857
Loss at iteration 830 : 0.0186687633395195
Loss at iteration 840 : 0.01251035276800394
Loss at iteration 850 : 0.017154425382614136
Loss at iteration 860 : 0.01698710396885872
Loss at iteration 870 : 0.018147919327020645
Loss at iteration 880 : 0.013434186577796936
Loss at iteration 890 : 0.013198049739003181
Loss at iteration 900 : 0.013175634667277336
Loss at iteration 910 : 0.016124431043863297
Loss at iteration 920 : 0.012853598222136497
Loss at iteration 930 : 0.01631416194140911
Loss at iteration 940 : 0.009130209684371948
Loss at iteration 950 : 0.014606169424951077
Loss at iteration 960 : 0.01200562622398138
Loss at iteration 970 : 0.014386884868144989
Loss at iteration 980 : 0.011842508800327778
Loss at iteration 990 : 0.013256413862109184
Loss at iteration 1000 : 0.016525061801075935
Loss at iteration 1010 : 0.011065377853810787
Loss at iteration 1020 : 0.014943528920412064
Loss at iteration 1030 : 0.014791026711463928
Loss at iteration 1040 : 0.015153683722019196
Loss at iteration 1050 : 0.015383636578917503
Loss at iteration 1060 : 0.022720377892255783
Loss at iteration 1070 : 0.010512655600905418
Loss at iteration 1080 : 0.015999896451830864
Loss at iteration 1090 : 0.01593599282205105
Loss at iteration 1100 : 0.014714306220412254
Loss at iteration 1110 : 0.021512692794203758
Loss at iteration 1120 : 0.022874517366290092
Loss at iteration 1130 : 0.015071380883455276
Loss at iteration 1140 : 0.011471234261989594
Loss at iteration 1150 : 0.008029665797948837
Loss at iteration 1160 : 0.012966308742761612
Loss at iteration 1170 : 0.015110770240426064
Loss at iteration 1180 : 0.014336635358631611
Loss at iteration 1190 : 0.013086273334920406
Loss at iteration 1200 : 0.01564222201704979
Loss at iteration 1210 : 0.01003718376159668
The SSIM Value is: 0.8031092325846354
The PSNR Value is: 18.11259536743164
the epoch is: 24
Loss at iteration 10 : 0.018154453486204147
Loss at iteration 20 : 0.013183597475290298
Loss at iteration 30 : 0.021072888746857643
Loss at iteration 40 : 0.009740322828292847
Loss at iteration 50 : 0.0085122250020504
Loss at iteration 60 : 0.017201252281665802
Loss at iteration 70 : 0.020532187074422836
Loss at iteration 80 : 0.012223905883729458
Loss at iteration 90 : 0.01087059173732996
Loss at iteration 100 : 0.014126910828053951
Loss at iteration 110 : 0.011693469248712063
Loss at iteration 120 : 0.011177917011082172
Loss at iteration 130 : 0.01053101196885109
Loss at iteration 140 : 0.02171112596988678
Loss at iteration 150 : 0.015709174796938896
Loss at iteration 160 : 0.017398305237293243
Loss at iteration 170 : 0.017856623977422714
Loss at iteration 180 : 0.013504315167665482
Loss at iteration 190 : 0.011503834277391434
Loss at iteration 200 : 0.009432252496480942
Loss at iteration 210 : 0.016348833218216896
Loss at iteration 220 : 0.011326298117637634
Loss at iteration 230 : 0.011222973465919495
Loss at iteration 240 : 0.020353883504867554
Loss at iteration 250 : 0.01840250939130783
Loss at iteration 260 : 0.01781483367085457
Loss at iteration 270 : 0.007103524636477232
Loss at iteration 280 : 0.025938795879483223
Loss at iteration 290 : 0.011231880635023117
Loss at iteration 300 : 0.01911292038857937
Loss at iteration 310 : 0.01555310096591711
Loss at iteration 320 : 0.014999644830822945
Loss at iteration 330 : 0.02556900680065155
Loss at iteration 340 : 0.010926802642643452
Loss at iteration 350 : 0.01648028939962387
Loss at iteration 360 : 0.014670399948954582
Loss at iteration 370 : 0.017317770048975945
Loss at iteration 380 : 0.021327439695596695
Loss at iteration 390 : 0.014187882654368877
Loss at iteration 400 : 0.01331725437194109
Loss at iteration 410 : 0.011482160538434982
Loss at iteration 420 : 0.009853159077465534
Loss at iteration 430 : 0.01039936114102602
Loss at iteration 440 : 0.025193344801664352
Loss at iteration 450 : 0.01093779131770134
Loss at iteration 460 : 0.012605342082679272
Loss at iteration 470 : 0.01152910478413105
Loss at iteration 480 : 0.01546985749155283
Loss at iteration 490 : 0.017664795741438866
Loss at iteration 500 : 0.017908720299601555
Loss at iteration 510 : 0.01681423932313919
Loss at iteration 520 : 0.013111693784594536
Loss at iteration 530 : 0.023964934051036835
Loss at iteration 540 : 0.010976659134030342
Loss at iteration 550 : 0.014260433614253998
Loss at iteration 560 : 0.015802908688783646
Loss at iteration 570 : 0.012360179796814919
Loss at iteration 580 : 0.014871453866362572
Loss at iteration 590 : 0.016179438680410385
Loss at iteration 600 : 0.01789502240717411
Loss at iteration 610 : 0.01691412553191185
Loss at iteration 620 : 0.01213797926902771
Loss at iteration 630 : 0.016202276572585106
Loss at iteration 640 : 0.012747706845402718
Loss at iteration 650 : 0.016122760251164436
Loss at iteration 660 : 0.01967909187078476
Loss at iteration 670 : 0.019558608531951904
Loss at iteration 680 : 0.016033321619033813
Loss at iteration 690 : 0.017129860818386078
Loss at iteration 700 : 0.013400426134467125
Loss at iteration 710 : 0.022298913449048996
Loss at iteration 720 : 0.010800397023558617
Loss at iteration 730 : 0.015541285276412964
Loss at iteration 740 : 0.011564468964934349
Loss at iteration 750 : 0.01020823884755373
Loss at iteration 760 : 0.015625063329935074
Loss at iteration 770 : 0.013091016560792923
Loss at iteration 780 : 0.010270301252603531
Loss at iteration 790 : 0.01561417244374752
Loss at iteration 800 : 0.01186797022819519
Loss at iteration 810 : 0.016085676848888397
Loss at iteration 820 : 0.017201121896505356
Loss at iteration 830 : 0.014750123023986816
Loss at iteration 840 : 0.014249274507164955
Loss at iteration 850 : 0.014900054782629013
Loss at iteration 860 : 0.019106939435005188
Loss at iteration 870 : 0.022016501054167747
Loss at iteration 880 : 0.021196838468313217
Loss at iteration 890 : 0.011900557205080986
Loss at iteration 900 : 0.026862530037760735
Loss at iteration 910 : 0.01314224861562252
Loss at iteration 920 : 0.01701442524790764
Loss at iteration 930 : 0.020882366225123405
Loss at iteration 940 : 0.012545996345579624
Loss at iteration 950 : 0.02130543440580368
Loss at iteration 960 : 0.013537051156163216
Loss at iteration 970 : 0.008200735785067081
Loss at iteration 980 : 0.00928081851452589
Loss at iteration 990 : 0.015681423246860504
Loss at iteration 1000 : 0.010219327174127102
Loss at iteration 1010 : 0.019288230687379837
Loss at iteration 1020 : 0.009698154404759407
Loss at iteration 1030 : 0.012219693511724472
Loss at iteration 1040 : 0.02279749885201454
Loss at iteration 1050 : 0.010615157894790173
Loss at iteration 1060 : 0.013829948380589485
Loss at iteration 1070 : 0.014997762627899647
Loss at iteration 1080 : 0.012079572305083275
Loss at iteration 1090 : 0.013429361395537853
Loss at iteration 1100 : 0.005954609252512455
Loss at iteration 1110 : 0.011052434332668781
Loss at iteration 1120 : 0.007522542029619217
Loss at iteration 1130 : 0.013692531734704971
Loss at iteration 1140 : 0.008345184847712517
Loss at iteration 1150 : 0.009637915529310703
Loss at iteration 1160 : 0.010486636310815811
Loss at iteration 1170 : 0.013319971971213818
Loss at iteration 1180 : 0.015333406627178192
Loss at iteration 1190 : 0.0168435201048851
Loss at iteration 1200 : 0.006580306217074394
Loss at iteration 1210 : 0.01860799454152584
The SSIM Value is: 0.7892004966735839
The PSNR Value is: 18.003533617655435
the epoch is: 25
Loss at iteration 10 : 0.010921595618128777
Loss at iteration 20 : 0.009583629667758942
Loss at iteration 30 : 0.009941676631569862
Loss at iteration 40 : 0.01643035002052784
Loss at iteration 50 : 0.01087149791419506
Loss at iteration 60 : 0.014727623201906681
Loss at iteration 70 : 0.011295272037386894
Loss at iteration 80 : 0.012181393802165985
Loss at iteration 90 : 0.0158280897885561
Loss at iteration 100 : 0.013089267536997795
Loss at iteration 110 : 0.013676246628165245
Loss at iteration 120 : 0.019299078732728958
Loss at iteration 130 : 0.01728704571723938
Loss at iteration 140 : 0.011636338196694851
Loss at iteration 150 : 0.01298321969807148
Loss at iteration 160 : 0.018777141347527504
Loss at iteration 170 : 0.011159173212945461
Loss at iteration 180 : 0.023150892928242683
Loss at iteration 190 : 0.015880582854151726
Loss at iteration 200 : 0.02904575690627098
Loss at iteration 210 : 0.010465063154697418
Loss at iteration 220 : 0.0067525627091526985
Loss at iteration 230 : 0.020407849922776222
Loss at iteration 240 : 0.016170965507626534
Loss at iteration 250 : 0.024212883785367012
Loss at iteration 260 : 0.014323033392429352
Loss at iteration 270 : 0.01429123803973198
Loss at iteration 280 : 0.018544582650065422
Loss at iteration 290 : 0.011127717792987823
Loss at iteration 300 : 0.010757111944258213
Loss at iteration 310 : 0.01924460381269455
Loss at iteration 320 : 0.010941287502646446
Loss at iteration 330 : 0.01621408760547638
Loss at iteration 340 : 0.00702221505343914
Loss at iteration 350 : 0.0145377516746521
Loss at iteration 360 : 0.018807610496878624
Loss at iteration 370 : 0.01237199641764164
Loss at iteration 380 : 0.010090484283864498
Loss at iteration 390 : 0.012524712830781937
Loss at iteration 400 : 0.015386058948934078
Loss at iteration 410 : 0.015037324279546738
Loss at iteration 420 : 0.01462617889046669
Loss at iteration 430 : 0.01456628367304802
Loss at iteration 440 : 0.01653299294412136
Loss at iteration 450 : 0.011712752282619476
Loss at iteration 460 : 0.008493359200656414
Loss at iteration 470 : 0.012774123810231686
Loss at iteration 480 : 0.016780832782387733
Loss at iteration 490 : 0.02183939702808857
Loss at iteration 500 : 0.013967392034828663
Loss at iteration 510 : 0.010288315825164318
Loss at iteration 520 : 0.014171401970088482
Loss at iteration 530 : 0.01240091398358345
Loss at iteration 540 : 0.019643183797597885
Loss at iteration 550 : 0.01245381124317646
Loss at iteration 560 : 0.013174019753932953
Loss at iteration 570 : 0.01683077961206436
Loss at iteration 580 : 0.019686903804540634
Loss at iteration 590 : 0.013430862687528133
Loss at iteration 600 : 0.011251885443925858
Loss at iteration 610 : 0.013325221836566925
Loss at iteration 620 : 0.017725389450788498
Loss at iteration 630 : 0.007071989588439465
Loss at iteration 640 : 0.013400091789662838
Loss at iteration 650 : 0.017528852447867393
Loss at iteration 660 : 0.011161673814058304
Loss at iteration 670 : 0.013751501217484474
Loss at iteration 680 : 0.009210125543177128
Loss at iteration 690 : 0.013308880850672722
Loss at iteration 700 : 0.01196858286857605
Loss at iteration 710 : 0.009458869695663452
Loss at iteration 720 : 0.013815494254231453
Loss at iteration 730 : 0.01457157637923956
Loss at iteration 740 : 0.008184990845620632
Loss at iteration 750 : 0.01699967496097088
Loss at iteration 760 : 0.012208755128085613
Loss at iteration 770 : 0.02822049707174301
Loss at iteration 780 : 0.013840820640325546
Loss at iteration 790 : 0.016487274318933487
Loss at iteration 800 : 0.02012557163834572
Loss at iteration 810 : 0.011796166189014912
Loss at iteration 820 : 0.0167005006223917
Loss at iteration 830 : 0.015675466507673264
Loss at iteration 840 : 0.017584718763828278
Loss at iteration 850 : 0.017133275046944618
Loss at iteration 860 : 0.011266499757766724
Loss at iteration 870 : 0.01588308811187744
Loss at iteration 880 : 0.010846573859453201
Loss at iteration 890 : 0.012468939647078514
Loss at iteration 900 : 0.007335380185395479
Loss at iteration 910 : 0.022089466452598572
Loss at iteration 920 : 0.012015225365757942
Loss at iteration 930 : 0.030024990439414978
Loss at iteration 940 : 0.02322576195001602
Loss at iteration 950 : 0.013002968393266201
Loss at iteration 960 : 0.016450397670269012
Loss at iteration 970 : 0.013882643543183804
Loss at iteration 980 : 0.014460288919508457
Loss at iteration 990 : 0.019990433007478714
Loss at iteration 1000 : 0.018582874909043312
Loss at iteration 1010 : 0.01975727453827858
Loss at iteration 1020 : 0.015157200396060944
Loss at iteration 1030 : 0.010594023391604424
Loss at iteration 1040 : 0.026574840769171715
Loss at iteration 1050 : 0.01556369662284851
Loss at iteration 1060 : 0.013065965846180916
Loss at iteration 1070 : 0.009612060151994228
Loss at iteration 1080 : 0.01782766729593277
Loss at iteration 1090 : 0.010727941058576107
Loss at iteration 1100 : 0.010664481669664383
Loss at iteration 1110 : 0.010740524157881737
Loss at iteration 1120 : 0.015898579731583595
Loss at iteration 1130 : 0.010412170551717281
Loss at iteration 1140 : 0.010520238429307938
Loss at iteration 1150 : 0.014407545328140259
Loss at iteration 1160 : 0.012545207515358925
Loss at iteration 1170 : 0.014140864834189415
Loss at iteration 1180 : 0.02677101269364357
Loss at iteration 1190 : 0.015186375938355923
Loss at iteration 1200 : 0.01217457465827465
Loss at iteration 1210 : 0.013369875960052013
The SSIM Value is: 0.8015363534291585
The PSNR Value is: 18.068251609802246
the epoch is: 26
Loss at iteration 10 : 0.019480932503938675
Loss at iteration 20 : 0.016798408702015877
Loss at iteration 30 : 0.015187172219157219
Loss at iteration 40 : 0.012079380452632904
Loss at iteration 50 : 0.01034159492701292
Loss at iteration 60 : 0.01210583932697773
Loss at iteration 70 : 0.016066722571849823
Loss at iteration 80 : 0.01396914105862379
Loss at iteration 90 : 0.019041594117879868
Loss at iteration 100 : 0.020029205828905106
Loss at iteration 110 : 0.013219996355473995
Loss at iteration 120 : 0.01585489884018898
Loss at iteration 130 : 0.023201659321784973
Loss at iteration 140 : 0.013059243559837341
Loss at iteration 150 : 0.017384923994541168
Loss at iteration 160 : 0.01996077410876751
Loss at iteration 170 : 0.014053110033273697
Loss at iteration 180 : 0.008871424943208694
Loss at iteration 190 : 0.012750406749546528
Loss at iteration 200 : 0.01125972718000412
Loss at iteration 210 : 0.014940276741981506
Loss at iteration 220 : 0.019840743392705917
Loss at iteration 230 : 0.020549125969409943
Loss at iteration 240 : 0.010637504979968071
Loss at iteration 250 : 0.013173049315810204
Loss at iteration 260 : 0.011926887556910515
Loss at iteration 270 : 0.01129484549164772
Loss at iteration 280 : 0.022084761410951614
Loss at iteration 290 : 0.010222679935395718
Loss at iteration 300 : 0.013458377681672573
Loss at iteration 310 : 0.02257666550576687
Loss at iteration 320 : 0.012957969680428505
Loss at iteration 330 : 0.009575845673680305
Loss at iteration 340 : 0.014830111525952816
Loss at iteration 350 : 0.020232677459716797
Loss at iteration 360 : 0.015271990559995174
Loss at iteration 370 : 0.01364712230861187
Loss at iteration 380 : 0.03394408896565437
Loss at iteration 390 : 0.013615011237561703
Loss at iteration 400 : 0.024003269150853157
Loss at iteration 410 : 0.01413511112332344
Loss at iteration 420 : 0.020104791969060898
Loss at iteration 430 : 0.013854779303073883
Loss at iteration 440 : 0.012868471443653107
Loss at iteration 450 : 0.029661793261766434
Loss at iteration 460 : 0.016981802880764008
Loss at iteration 470 : 0.018300261348485947
Loss at iteration 480 : 0.006694484036415815
Loss at iteration 490 : 0.017140623182058334
Loss at iteration 500 : 0.016990061849355698
Loss at iteration 510 : 0.011998508125543594
Loss at iteration 520 : 0.008759958669543266
Loss at iteration 530 : 0.01253545843064785
Loss at iteration 540 : 0.019454676657915115
Loss at iteration 550 : 0.011086735874414444
Loss at iteration 560 : 0.018046416342258453
Loss at iteration 570 : 0.01875855028629303
Loss at iteration 580 : 0.015659011900424957
Loss at iteration 590 : 0.010951071046292782
Loss at iteration 600 : 0.014165989123284817
Loss at iteration 610 : 0.01160139124840498
Loss at iteration 620 : 0.019795706495642662
Loss at iteration 630 : 0.014116552658379078
Loss at iteration 640 : 0.01616527885198593
Loss at iteration 650 : 0.01702793501317501
Loss at iteration 660 : 0.02100348100066185
Loss at iteration 670 : 0.012007373385131359
Loss at iteration 680 : 0.013419343158602715
Loss at iteration 690 : 0.013043747283518314
Loss at iteration 700 : 0.008410273119807243
Loss at iteration 710 : 0.011698421090841293
Loss at iteration 720 : 0.02059433050453663
Loss at iteration 730 : 0.01587987132370472
Loss at iteration 740 : 0.012577315792441368
Loss at iteration 750 : 0.008180161938071251
Loss at iteration 760 : 0.014314653351902962
Loss at iteration 770 : 0.00936869066208601
Loss at iteration 780 : 0.008727530017495155
Loss at iteration 790 : 0.017483944073319435
Loss at iteration 800 : 0.008048491552472115
Loss at iteration 810 : 0.01135319471359253
Loss at iteration 820 : 0.013031607493758202
Loss at iteration 830 : 0.016869813203811646
Loss at iteration 840 : 0.015203206799924374
Loss at iteration 850 : 0.018021387979388237
Loss at iteration 860 : 0.013524714857339859
Loss at iteration 870 : 0.01338588260114193
Loss at iteration 880 : 0.01356628630310297
Loss at iteration 890 : 0.016884934157133102
Loss at iteration 900 : 0.012479542754590511
Loss at iteration 910 : 0.015954799950122833
Loss at iteration 920 : 0.011991601437330246
Loss at iteration 930 : 0.02474096044898033
Loss at iteration 940 : 0.0066527025774121284
Loss at iteration 950 : 0.020523052662611008
Loss at iteration 960 : 0.01406673900783062
Loss at iteration 970 : 0.00880893412977457
Loss at iteration 980 : 0.008257681503891945
Loss at iteration 990 : 0.009209878742694855
Loss at iteration 1000 : 0.012718573212623596
Loss at iteration 1010 : 0.013675346970558167
Loss at iteration 1020 : 0.010733346454799175
Loss at iteration 1030 : 0.01593105122447014
Loss at iteration 1040 : 0.01300355326384306
Loss at iteration 1050 : 0.015417998656630516
Loss at iteration 1060 : 0.011281847953796387
Loss at iteration 1070 : 0.010788514278829098
Loss at iteration 1080 : 0.01877991482615471
Loss at iteration 1090 : 0.008289759978652
Loss at iteration 1100 : 0.014324856922030449
Loss at iteration 1110 : 0.009182529523968697
Loss at iteration 1120 : 0.00976490881294012
Loss at iteration 1130 : 0.007288752123713493
Loss at iteration 1140 : 0.014610275626182556
Loss at iteration 1150 : 0.01662660948932171
Loss at iteration 1160 : 0.021066837012767792
Loss at iteration 1170 : 0.011629357933998108
Loss at iteration 1180 : 0.013337868265807629
Loss at iteration 1190 : 0.013201044872403145
Loss at iteration 1200 : 0.015750635415315628
Loss at iteration 1210 : 0.013717190362513065
The SSIM Value is: 0.7632281462351481
The PSNR Value is: 16.291130765279135
the epoch is: 27
Loss at iteration 10 : 0.016078591346740723
Loss at iteration 20 : 0.0158778578042984
Loss at iteration 30 : 0.01197449117898941
Loss at iteration 40 : 0.013537799939513206
Loss at iteration 50 : 0.012580128386616707
Loss at iteration 60 : 0.008971156552433968
Loss at iteration 70 : 0.01492796279489994
Loss at iteration 80 : 0.015002984553575516
Loss at iteration 90 : 0.008954571560025215
Loss at iteration 100 : 0.012273632921278477
Loss at iteration 110 : 0.013247961178421974
Loss at iteration 120 : 0.00926889106631279
Loss at iteration 130 : 0.01323198713362217
Loss at iteration 140 : 0.017333053052425385
Loss at iteration 150 : 0.012333006598055363
Loss at iteration 160 : 0.020795375108718872
Loss at iteration 170 : 0.01286143809556961
Loss at iteration 180 : 0.019318606704473495
Loss at iteration 190 : 0.011082896031439304
Loss at iteration 200 : 0.016099903732538223
Loss at iteration 210 : 0.01098104752600193
Loss at iteration 220 : 0.013707410544157028
Loss at iteration 230 : 0.020516999065876007
Loss at iteration 240 : 0.012136842124164104
Loss at iteration 250 : 0.01799812912940979
Loss at iteration 260 : 0.013213759288191795
Loss at iteration 270 : 0.01123733725398779
Loss at iteration 280 : 0.014648365788161755
Loss at iteration 290 : 0.01236861664801836
Loss at iteration 300 : 0.021510601043701172
Loss at iteration 310 : 0.015533240512013435
Loss at iteration 320 : 0.008999123238027096
Loss at iteration 330 : 0.012697028927505016
Loss at iteration 340 : 0.016733596101403236
Loss at iteration 350 : 0.012408075854182243
Loss at iteration 360 : 0.015184733085334301
Loss at iteration 370 : 0.007787137757986784
Loss at iteration 380 : 0.024921197444200516
Loss at iteration 390 : 0.01186032872647047
Loss at iteration 400 : 0.009699997492134571
Loss at iteration 410 : 0.014230644330382347
Loss at iteration 420 : 0.018776079639792442
Loss at iteration 430 : 0.023753277957439423
Loss at iteration 440 : 0.011163461953401566
Loss at iteration 450 : 0.01454436220228672
Loss at iteration 460 : 0.009823152795433998
Loss at iteration 470 : 0.01676286943256855
Loss at iteration 480 : 0.0128428740426898
Loss at iteration 490 : 0.013255647383630276
Loss at iteration 500 : 0.011198622174561024
Loss at iteration 510 : 0.010458407923579216
Loss at iteration 520 : 0.014704713597893715
Loss at iteration 530 : 0.02574687823653221
Loss at iteration 540 : 0.013610679656267166
Loss at iteration 550 : 0.016319599002599716
Loss at iteration 560 : 0.01139229629188776
Loss at iteration 570 : 0.01866505667567253
Loss at iteration 580 : 0.013627391308546066
Loss at iteration 590 : 0.01436476781964302
Loss at iteration 600 : 0.018940815702080727
Loss at iteration 610 : 0.013835839927196503
Loss at iteration 620 : 0.0143757788464427
Loss at iteration 630 : 0.010759172961115837
Loss at iteration 640 : 0.019220683723688126
Loss at iteration 650 : 0.010064749047160149
Loss at iteration 660 : 0.009155825711786747
Loss at iteration 670 : 0.011252421885728836
Loss at iteration 680 : 0.01889539137482643
Loss at iteration 690 : 0.009862646460533142
Loss at iteration 700 : 0.013196681626141071
Loss at iteration 710 : 0.010868586599826813
Loss at iteration 720 : 0.01634412631392479
Loss at iteration 730 : 0.025506170466542244
Loss at iteration 740 : 0.01182706281542778
Loss at iteration 750 : 0.011418918147683144
Loss at iteration 760 : 0.01413930207490921
Loss at iteration 770 : 0.018683549016714096
Loss at iteration 780 : 0.007944983430206776
Loss at iteration 790 : 0.013560270890593529
Loss at iteration 800 : 0.018848808482289314
Loss at iteration 810 : 0.0115888100117445
Loss at iteration 820 : 0.010064906440675259
Loss at iteration 830 : 0.011004501953721046
Loss at iteration 840 : 0.014483621343970299
Loss at iteration 850 : 0.01015359815210104
Loss at iteration 860 : 0.03433997929096222
Loss at iteration 870 : 0.012998754158616066
Loss at iteration 880 : 0.013525288552045822
Loss at iteration 890 : 0.016040083020925522
Loss at iteration 900 : 0.01638849265873432
Loss at iteration 910 : 0.01663949340581894
Loss at iteration 920 : 0.014973601326346397
Loss at iteration 930 : 0.016643568873405457
Loss at iteration 940 : 0.011074438691139221
Loss at iteration 950 : 0.01711317151784897
Loss at iteration 960 : 0.015281615778803825
Loss at iteration 970 : 0.007003745995461941
Loss at iteration 980 : 0.01438199169933796
Loss at iteration 990 : 0.01650899648666382
Loss at iteration 1000 : 0.015800539404153824
Loss at iteration 1010 : 0.01457558386027813
Loss at iteration 1020 : 0.011267763562500477
Loss at iteration 1030 : 0.008657187223434448
Loss at iteration 1040 : 0.012482233345508575
Loss at iteration 1050 : 0.015817930921912193
Loss at iteration 1060 : 0.018177885562181473
Loss at iteration 1070 : 0.015181206166744232
Loss at iteration 1080 : 0.01567525789141655
Loss at iteration 1090 : 0.020152313634753227
Loss at iteration 1100 : 0.009700668975710869
Loss at iteration 1110 : 0.017755895853042603
Loss at iteration 1120 : 0.012959010899066925
Loss at iteration 1130 : 0.016293548047542572
Loss at iteration 1140 : 0.016730692237615585
Loss at iteration 1150 : 0.016850626096129417
Loss at iteration 1160 : 0.01599125936627388
Loss at iteration 1170 : 0.011294610798358917
Loss at iteration 1180 : 0.023868251591920853
Loss at iteration 1190 : 0.018338387832045555
Loss at iteration 1200 : 0.010566484183073044
Loss at iteration 1210 : 0.015178974717855453
The SSIM Value is: 0.7700493494669597
The PSNR Value is: 16.907915178934733
the epoch is: 28
Loss at iteration 10 : 0.018127551302313805
Loss at iteration 20 : 0.013705836609005928
Loss at iteration 30 : 0.01234472543001175
Loss at iteration 40 : 0.013159781694412231
Loss at iteration 50 : 0.014542315155267715
Loss at iteration 60 : 0.025647606700658798
Loss at iteration 70 : 0.009558494202792645
Loss at iteration 80 : 0.014544600620865822
Loss at iteration 90 : 0.018954692408442497
Loss at iteration 100 : 0.008731554262340069
Loss at iteration 110 : 0.020930562168359756
Loss at iteration 120 : 0.01270819827914238
Loss at iteration 130 : 0.014869431033730507
Loss at iteration 140 : 0.007883802056312561
Loss at iteration 150 : 0.016424711793661118
Loss at iteration 160 : 0.006166666746139526
Loss at iteration 170 : 0.011648221872746944
Loss at iteration 180 : 0.012795889750123024
Loss at iteration 190 : 0.007195552345365286
Loss at iteration 200 : 0.012907915748655796
Loss at iteration 210 : 0.011560815386474133
Loss at iteration 220 : 0.01332262996584177
Loss at iteration 230 : 0.011110847815871239
Loss at iteration 240 : 0.010086648166179657
Loss at iteration 250 : 0.010311132296919823
Loss at iteration 260 : 0.011180326342582703
Loss at iteration 270 : 0.01552613452076912
Loss at iteration 280 : 0.01402242761105299
Loss at iteration 290 : 0.017039790749549866
Loss at iteration 300 : 0.015648722648620605
Loss at iteration 310 : 0.015698345378041267
Loss at iteration 320 : 0.01309681311249733
Loss at iteration 330 : 0.005141036584973335
Loss at iteration 340 : 0.016051460057497025
Loss at iteration 350 : 0.012364823371171951
Loss at iteration 360 : 0.013676402159035206
Loss at iteration 370 : 0.013136276043951511
Loss at iteration 380 : 0.017436489462852478
Loss at iteration 390 : 0.010116560384631157
Loss at iteration 400 : 0.012062788009643555
Loss at iteration 410 : 0.014798635616898537
Loss at iteration 420 : 0.013343132100999355
Loss at iteration 430 : 0.01383906789124012
Loss at iteration 440 : 0.011899895034730434
Loss at iteration 450 : 0.010724089108407497
Loss at iteration 460 : 0.010452262125909328
Loss at iteration 470 : 0.01663878560066223
Loss at iteration 480 : 0.01604667492210865
Loss at iteration 490 : 0.014727160334587097
Loss at iteration 500 : 0.010859249159693718
Loss at iteration 510 : 0.032791975885629654
Loss at iteration 520 : 0.016948003321886063
Loss at iteration 530 : 0.017846086993813515
Loss at iteration 540 : 0.02002941258251667
Loss at iteration 550 : 0.016292743384838104
Loss at iteration 560 : 0.013943599537014961
Loss at iteration 570 : 0.0115249278023839
Loss at iteration 580 : 0.01489810086786747
Loss at iteration 590 : 0.01064426451921463
Loss at iteration 600 : 0.012126004323363304
Loss at iteration 610 : 0.013002664782106876
Loss at iteration 620 : 0.010574855841696262
Loss at iteration 630 : 0.023279275745153427
Loss at iteration 640 : 0.01290486752986908
Loss at iteration 650 : 0.015177596360445023
Loss at iteration 660 : 0.008593300357460976
Loss at iteration 670 : 0.011881688609719276
Loss at iteration 680 : 0.012769432738423347
Loss at iteration 690 : 0.021343916654586792
Loss at iteration 700 : 0.010263100266456604
Loss at iteration 710 : 0.01503988727927208
Loss at iteration 720 : 0.010446874424815178
Loss at iteration 730 : 0.017293227836489677
Loss at iteration 740 : 0.016790341585874557
Loss at iteration 750 : 0.01585288532078266
Loss at iteration 760 : 0.016069628298282623
Loss at iteration 770 : 0.0142169538885355
Loss at iteration 780 : 0.016260819509625435
Loss at iteration 790 : 0.019474441185593605
Loss at iteration 800 : 0.013669867068529129
Loss at iteration 810 : 0.013477441854774952
Loss at iteration 820 : 0.013966456055641174
Loss at iteration 830 : 0.024028606712818146
Loss at iteration 840 : 0.013622180558741093
Loss at iteration 850 : 0.011508619412779808
Loss at iteration 860 : 0.023774076253175735
Loss at iteration 870 : 0.011704315431416035
Loss at iteration 880 : 0.013838420622050762
Loss at iteration 890 : 0.012644851580262184
Loss at iteration 900 : 0.01103429775685072
Loss at iteration 910 : 0.011071925051510334
Loss at iteration 920 : 0.014325936324894428
Loss at iteration 930 : 0.01875179260969162
Loss at iteration 940 : 0.022419510409235954
Loss at iteration 950 : 0.020000111311674118
Loss at iteration 960 : 0.0126645527780056
Loss at iteration 970 : 0.016111761331558228
Loss at iteration 980 : 0.011177977547049522
Loss at iteration 990 : 0.015557055361568928
Loss at iteration 1000 : 0.016518477350473404
Loss at iteration 1010 : 0.017908848822116852
Loss at iteration 1020 : 0.0185990147292614
Loss at iteration 1030 : 0.011339925229549408
Loss at iteration 1040 : 0.01709945686161518
Loss at iteration 1050 : 0.00946112535893917
Loss at iteration 1060 : 0.011984569951891899
Loss at iteration 1070 : 0.01320610661059618
Loss at iteration 1080 : 0.009290095418691635
Loss at iteration 1090 : 0.015799647197127342
Loss at iteration 1100 : 0.01336649525910616
Loss at iteration 1110 : 0.014168721623718739
Loss at iteration 1120 : 0.01824703998863697
Loss at iteration 1130 : 0.01889367774128914
Loss at iteration 1140 : 0.01113875675946474
Loss at iteration 1150 : 0.010065420530736446
Loss at iteration 1160 : 0.013206472620368004
Loss at iteration 1170 : 0.013096611015498638
Loss at iteration 1180 : 0.02346213348209858
Loss at iteration 1190 : 0.015654806047677994
Loss at iteration 1200 : 0.02036558836698532
Loss at iteration 1210 : 0.018892675638198853
The SSIM Value is: 0.7929586052894593
The PSNR Value is: 18.456877326965333
the epoch is: 29
Loss at iteration 10 : 0.009835990145802498
Loss at iteration 20 : 0.012031547725200653
Loss at iteration 30 : 0.01659547910094261
Loss at iteration 40 : 0.009580347687005997
Loss at iteration 50 : 0.0123677309602499
Loss at iteration 60 : 0.007651800289750099
Loss at iteration 70 : 0.008814605884253979
Loss at iteration 80 : 0.014935286715626717
Loss at iteration 90 : 0.008570565842092037
Loss at iteration 100 : 0.016218194738030434
Loss at iteration 110 : 0.013444767333567142
Loss at iteration 120 : 0.010968144983053207
Loss at iteration 130 : 0.013763916678726673
Loss at iteration 140 : 0.015176613815128803
Loss at iteration 150 : 0.013140900991857052
Loss at iteration 160 : 0.012696193531155586
Loss at iteration 170 : 0.01751662790775299
Loss at iteration 180 : 0.015526614151895046
Loss at iteration 190 : 0.015750864520668983
Loss at iteration 200 : 0.013320280238986015
Loss at iteration 210 : 0.011765878647565842
Loss at iteration 220 : 0.017637595534324646
Loss at iteration 230 : 0.015677152201533318
Loss at iteration 240 : 0.020559074357151985
Loss at iteration 250 : 0.02244463935494423
Loss at iteration 260 : 0.011873623356223106
Loss at iteration 270 : 0.00962490402162075
Loss at iteration 280 : 0.015143930912017822
Loss at iteration 290 : 0.013316688127815723
Loss at iteration 300 : 0.009252685122191906
Loss at iteration 310 : 0.02213403582572937
Loss at iteration 320 : 0.017099959775805473
Loss at iteration 330 : 0.0126816276460886
Loss at iteration 340 : 0.012855608016252518
Loss at iteration 350 : 0.01729121245443821
Loss at iteration 360 : 0.013819597661495209
Loss at iteration 370 : 0.013469835743308067
Loss at iteration 380 : 0.01905154250562191
Loss at iteration 390 : 0.02000867947936058
Loss at iteration 400 : 0.011983010917901993
Loss at iteration 410 : 0.013609370216727257
Loss at iteration 420 : 0.010974022559821606
Loss at iteration 430 : 0.016326656565070152
Loss at iteration 440 : 0.015451114624738693
Loss at iteration 450 : 0.011882453225553036
Loss at iteration 460 : 0.013672093860805035
Loss at iteration 470 : 0.011447766795754433
Loss at iteration 480 : 0.021920034661889076
Loss at iteration 490 : 0.017315495759248734
Loss at iteration 500 : 0.018895912915468216
Loss at iteration 510 : 0.015943672508001328
Loss at iteration 520 : 0.013836869969964027
Loss at iteration 530 : 0.011481557041406631
Loss at iteration 540 : 0.013554027304053307
Loss at iteration 550 : 0.014932580292224884
Loss at iteration 560 : 0.013600284233689308
Loss at iteration 570 : 0.014866502955555916
Loss at iteration 580 : 0.013099512085318565
Loss at iteration 590 : 0.017591189593076706
Loss at iteration 600 : 0.015328435227274895
Loss at iteration 610 : 0.014159975573420525
Loss at iteration 620 : 0.011407149955630302
Loss at iteration 630 : 0.02328798919916153
Loss at iteration 640 : 0.009280432015657425
Loss at iteration 650 : 0.011100836098194122
Loss at iteration 660 : 0.018330223858356476
Loss at iteration 670 : 0.012717575766146183
Loss at iteration 680 : 0.013477098196744919
Loss at iteration 690 : 0.012144033797085285
Loss at iteration 700 : 0.015735814347863197
Loss at iteration 710 : 0.014835399575531483
Loss at iteration 720 : 0.018262581899762154
Loss at iteration 730 : 0.014194241724908352
Loss at iteration 740 : 0.012998271733522415
Loss at iteration 750 : 0.0129372114315629
Loss at iteration 760 : 0.017542805522680283
Loss at iteration 770 : 0.011556930840015411
Loss at iteration 780 : 0.011880865320563316
Loss at iteration 790 : 0.010820572264492512
Loss at iteration 800 : 0.01337521057575941
Loss at iteration 810 : 0.02350395917892456
Loss at iteration 820 : 0.013100193813443184
Loss at iteration 830 : 0.010705765336751938
Loss at iteration 840 : 0.017546050250530243
Loss at iteration 850 : 0.014594554901123047
Loss at iteration 860 : 0.015094192698597908
Loss at iteration 870 : 0.015404738485813141
Loss at iteration 880 : 0.014525706879794598
Loss at iteration 890 : 0.006994812283664942
Loss at iteration 900 : 0.017674991860985756
Loss at iteration 910 : 0.015860795974731445
Loss at iteration 920 : 0.014314322732388973
Loss at iteration 930 : 0.011372081935405731
Loss at iteration 940 : 0.010111341252923012
Loss at iteration 950 : 0.010506456717848778
Loss at iteration 960 : 0.013801977969706059
Loss at iteration 970 : 0.018091769888997078
Loss at iteration 980 : 0.016966819763183594
Loss at iteration 990 : 0.02187494933605194
Loss at iteration 1000 : 0.01237468607723713
Loss at iteration 1010 : 0.014278154820203781
Loss at iteration 1020 : 0.011008115485310555
Loss at iteration 1030 : 0.011869476176798344
Loss at iteration 1040 : 0.01689108833670616
Loss at iteration 1050 : 0.023400314152240753
Loss at iteration 1060 : 0.015247478149831295
Loss at iteration 1070 : 0.013491908088326454
Loss at iteration 1080 : 0.01446292083710432
Loss at iteration 1090 : 0.01113981008529663
Loss at iteration 1100 : 0.014064195565879345
Loss at iteration 1110 : 0.011320428922772408
Loss at iteration 1120 : 0.02855573408305645
Loss at iteration 1130 : 0.025082018226385117
Loss at iteration 1140 : 0.013381604105234146
Loss at iteration 1150 : 0.016655921936035156
Loss at iteration 1160 : 0.010641248896718025
Loss at iteration 1170 : 0.012824798002839088
Loss at iteration 1180 : 0.010281862691044807
Loss at iteration 1190 : 0.00930407177656889
Loss at iteration 1200 : 0.012427451089024544
Loss at iteration 1210 : 0.015414337627589703
The SSIM Value is: 0.7951466302076976
The PSNR Value is: 18.37404505411784
the epoch is: 30
Loss at iteration 10 : 0.0168721005320549
Loss at iteration 20 : 0.01866188272833824
Loss at iteration 30 : 0.012293502688407898
Loss at iteration 40 : 0.016624726355075836
Loss at iteration 50 : 0.010363825596868992
Loss at iteration 60 : 0.014010293409228325
Loss at iteration 70 : 0.010457657277584076
Loss at iteration 80 : 0.009325908496975899
Loss at iteration 90 : 0.01778937689960003
Loss at iteration 100 : 0.01759084314107895
Loss at iteration 110 : 0.015577957034111023
Loss at iteration 120 : 0.022909492254257202
Loss at iteration 130 : 0.014303626492619514
Loss at iteration 140 : 0.016324050724506378
Loss at iteration 150 : 0.011776548810303211
Loss at iteration 160 : 0.016042184084653854
Loss at iteration 170 : 0.010899803601205349
Loss at iteration 180 : 0.01745033636689186
Loss at iteration 190 : 0.01802140288054943
Loss at iteration 200 : 0.010512692853808403
Loss at iteration 210 : 0.014753761701285839
Loss at iteration 220 : 0.01297415979206562
Loss at iteration 230 : 0.013492240570485592
Loss at iteration 240 : 0.012436644174158573
Loss at iteration 250 : 0.015269987285137177
Loss at iteration 260 : 0.010576587170362473
Loss at iteration 270 : 0.011796891689300537
Loss at iteration 280 : 0.014449861831963062
Loss at iteration 290 : 0.0055928886868059635
Loss at iteration 300 : 0.01550416648387909
Loss at iteration 310 : 0.011098312214016914
Loss at iteration 320 : 0.017768381163477898
Loss at iteration 330 : 0.013018490746617317
Loss at iteration 340 : 0.015117662027478218
Loss at iteration 350 : 0.025608375668525696
Loss at iteration 360 : 0.015397169627249241
Loss at iteration 370 : 0.008858616463840008
Loss at iteration 380 : 0.01381792314350605
Loss at iteration 390 : 0.01231168583035469
Loss at iteration 400 : 0.02036372199654579
Loss at iteration 410 : 0.01303500309586525
Loss at iteration 420 : 0.02141660824418068
Loss at iteration 430 : 0.016850262880325317
Loss at iteration 440 : 0.020186936482787132
Loss at iteration 450 : 0.019674178212881088
Loss at iteration 460 : 0.01450779102742672
Loss at iteration 470 : 0.019587554037570953
Loss at iteration 480 : 0.021011225879192352
Loss at iteration 490 : 0.00809482578188181
Loss at iteration 500 : 0.01627461425960064
Loss at iteration 510 : 0.017907844856381416
Loss at iteration 520 : 0.012530950829386711
Loss at iteration 530 : 0.014723045751452446
Loss at iteration 540 : 0.015942027792334557
Loss at iteration 550 : 0.014576371759176254
Loss at iteration 560 : 0.017953407019376755
Loss at iteration 570 : 0.012601318769156933
Loss at iteration 580 : 0.010344401001930237
Loss at iteration 590 : 0.012023226357996464
Loss at iteration 600 : 0.008635921403765678
Loss at iteration 610 : 0.019235245883464813
Loss at iteration 620 : 0.00649448623880744
Loss at iteration 630 : 0.012511143460869789
Loss at iteration 640 : 0.009411468170583248
Loss at iteration 650 : 0.020935332402586937
Loss at iteration 660 : 0.02076765149831772
Loss at iteration 670 : 0.011492536403238773
Loss at iteration 680 : 0.008793694898486137
Loss at iteration 690 : 0.012228470295667648
Loss at iteration 700 : 0.010461939498782158
Loss at iteration 710 : 0.009830585680902004
Loss at iteration 720 : 0.017689239233732224
Loss at iteration 730 : 0.014973293989896774
Loss at iteration 740 : 0.01808207854628563
Loss at iteration 750 : 0.01471372228115797
Loss at iteration 760 : 0.00767074478790164
Loss at iteration 770 : 0.013233505189418793
Loss at iteration 780 : 0.012141389772295952
Loss at iteration 790 : 0.01186169870197773
Loss at iteration 800 : 0.01769919879734516
Loss at iteration 810 : 0.010485981591045856
Loss at iteration 820 : 0.024289745837450027
Loss at iteration 830 : 0.028447650372982025
Loss at iteration 840 : 0.011441148817539215
Loss at iteration 850 : 0.015266605652868748
Loss at iteration 860 : 0.014813967980444431
Loss at iteration 870 : 0.010916349478065968
Loss at iteration 880 : 0.010247108526527882
Loss at iteration 890 : 0.021648669615387917
Loss at iteration 900 : 0.015957679599523544
Loss at iteration 910 : 0.010647665709257126
Loss at iteration 920 : 0.014839982613921165
Loss at iteration 930 : 0.018988216295838356
Loss at iteration 940 : 0.015323241241276264
Loss at iteration 950 : 0.017938055098056793
Loss at iteration 960 : 0.012143689207732677
Loss at iteration 970 : 0.012074354104697704
Loss at iteration 980 : 0.01075440552085638
Loss at iteration 990 : 0.017213130369782448
Loss at iteration 1000 : 0.014337202534079552
Loss at iteration 1010 : 0.014544159173965454
Loss at iteration 1020 : 0.015570573508739471
Loss at iteration 1030 : 0.018600914627313614
Loss at iteration 1040 : 0.01251351647078991
Loss at iteration 1050 : 0.014293387532234192
Loss at iteration 1060 : 0.009187011048197746
Loss at iteration 1070 : 0.009757873602211475
Loss at iteration 1080 : 0.012323516421020031
Loss at iteration 1090 : 0.011972206644713879
Loss at iteration 1100 : 0.007564466446638107
Loss at iteration 1110 : 0.009658445604145527
Loss at iteration 1120 : 0.01655063033103943
Loss at iteration 1130 : 0.009836619719862938
Loss at iteration 1140 : 0.013820534572005272
Loss at iteration 1150 : 0.0169859379529953
Loss at iteration 1160 : 0.020811915397644043
Loss at iteration 1170 : 0.01139514334499836
Loss at iteration 1180 : 0.020620035007596016
Loss at iteration 1190 : 0.013797538354992867
Loss at iteration 1200 : 0.013529680669307709
Loss at iteration 1210 : 0.0092963557690382
The SSIM Value is: 0.8132047096888224
The PSNR Value is: 18.928991826375327
the highest SSIM value is: 18.928991826375327
the epoch is: 31
Loss at iteration 10 : 0.014436798170208931
Loss at iteration 20 : 0.015949955210089684
Loss at iteration 30 : 0.010567806661128998
Loss at iteration 40 : 0.010717974975705147
Loss at iteration 50 : 0.0107133649289608
Loss at iteration 60 : 0.013553769327700138
Loss at iteration 70 : 0.01731112226843834
Loss at iteration 80 : 0.022285370156168938
Loss at iteration 90 : 0.018871275708079338
Loss at iteration 100 : 0.017148451879620552
Loss at iteration 110 : 0.020366741344332695
Loss at iteration 120 : 0.016282226890325546
Loss at iteration 130 : 0.0228823684155941
Loss at iteration 140 : 0.011333191767334938
Loss at iteration 150 : 0.014759885147213936
Loss at iteration 160 : 0.015526119619607925
Loss at iteration 170 : 0.016072604805231094
Loss at iteration 180 : 0.01449887827038765
Loss at iteration 190 : 0.01182466745376587
Loss at iteration 200 : 0.013336846604943275
Loss at iteration 210 : 0.01408701203763485
Loss at iteration 220 : 0.015325043350458145
Loss at iteration 230 : 0.01607820950448513
Loss at iteration 240 : 0.01232977956533432
Loss at iteration 250 : 0.011089183390140533
Loss at iteration 260 : 0.010455342940986156
Loss at iteration 270 : 0.012011190876364708
Loss at iteration 280 : 0.014560012146830559
Loss at iteration 290 : 0.016780491918325424
Loss at iteration 300 : 0.016456764191389084
Loss at iteration 310 : 0.01320779137313366
Loss at iteration 320 : 0.01028356235474348
Loss at iteration 330 : 0.013974500820040703
Loss at iteration 340 : 0.010720280930399895
Loss at iteration 350 : 0.01295039989054203
Loss at iteration 360 : 0.01606193743646145
Loss at iteration 370 : 0.01219173800200224
Loss at iteration 380 : 0.00739201158285141
Loss at iteration 390 : 0.0073500387370586395
Loss at iteration 400 : 0.028911970555782318
Loss at iteration 410 : 0.014860007911920547
Loss at iteration 420 : 0.015688659623265266
Loss at iteration 430 : 0.00932478066533804
Loss at iteration 440 : 0.00904683768749237
Loss at iteration 450 : 0.015423744916915894
Loss at iteration 460 : 0.013270517811179161
Loss at iteration 470 : 0.020338615402579308
Loss at iteration 480 : 0.01244993694126606
Loss at iteration 490 : 0.012290412560105324
Loss at iteration 500 : 0.01332638319581747
Loss at iteration 510 : 0.013155011460185051
Loss at iteration 520 : 0.010358060710132122
Loss at iteration 530 : 0.01770554855465889
Loss at iteration 540 : 0.017832808196544647
Loss at iteration 550 : 0.015079652890563011
Loss at iteration 560 : 0.011686574667692184
Loss at iteration 570 : 0.01895504631102085
Loss at iteration 580 : 0.00625689048320055
Loss at iteration 590 : 0.009668109938502312
Loss at iteration 600 : 0.013742348179221153
Loss at iteration 610 : 0.01334240660071373
Loss at iteration 620 : 0.010806649923324585
Loss at iteration 630 : 0.010353406891226768
Loss at iteration 640 : 0.010544352233409882
Loss at iteration 650 : 0.02103506214916706
Loss at iteration 660 : 0.015353415161371231
Loss at iteration 670 : 0.017016030848026276
Loss at iteration 680 : 0.017073892056941986
Loss at iteration 690 : 0.009948190301656723
Loss at iteration 700 : 0.008962040767073631
Loss at iteration 710 : 0.013291972689330578
Loss at iteration 720 : 0.020971983671188354
Loss at iteration 730 : 0.014086630195379257
Loss at iteration 740 : 0.011923514306545258
Loss at iteration 750 : 0.016051527112722397
Loss at iteration 760 : 0.012046813033521175
Loss at iteration 770 : 0.015781093388795853
Loss at iteration 780 : 0.018254615366458893
Loss at iteration 790 : 0.01391407661139965
Loss at iteration 800 : 0.01412813551723957
Loss at iteration 810 : 0.019021039828658104
Loss at iteration 820 : 0.01821870729327202
Loss at iteration 830 : 0.013111595064401627
Loss at iteration 840 : 0.008454065769910812
Loss at iteration 850 : 0.013929867185652256
Loss at iteration 860 : 0.025696460157632828
Loss at iteration 870 : 0.016209697350859642
Loss at iteration 880 : 0.012355351820588112
Loss at iteration 890 : 0.011170819401741028
Loss at iteration 900 : 0.0086251525208354
Loss at iteration 910 : 0.017551202327013016
Loss at iteration 920 : 0.013917388394474983
Loss at iteration 930 : 0.01703634113073349
Loss at iteration 940 : 0.00912031065672636
Loss at iteration 950 : 0.029679296538233757
Loss at iteration 960 : 0.022816725075244904
Loss at iteration 970 : 0.007966523990035057
Loss at iteration 980 : 0.02222904935479164
Loss at iteration 990 : 0.011269453912973404
Loss at iteration 1000 : 0.013162435032427311
Loss at iteration 1010 : 0.011532601900398731
Loss at iteration 1020 : 0.019110899418592453
Loss at iteration 1030 : 0.012593453750014305
Loss at iteration 1040 : 0.009303872473537922
Loss at iteration 1050 : 0.02149840071797371
Loss at iteration 1060 : 0.007208989001810551
Loss at iteration 1070 : 0.014019353315234184
Loss at iteration 1080 : 0.012775324285030365
Loss at iteration 1090 : 0.027422893792390823
Loss at iteration 1100 : 0.01664174720644951
Loss at iteration 1110 : 0.012329227291047573
Loss at iteration 1120 : 0.012650701217353344
Loss at iteration 1130 : 0.01657477207481861
Loss at iteration 1140 : 0.010864552110433578
Loss at iteration 1150 : 0.01200840249657631
Loss at iteration 1160 : 0.013412329368293285
Loss at iteration 1170 : 0.010283973067998886
Loss at iteration 1180 : 0.011181710287928581
Loss at iteration 1190 : 0.016726380214095116
Loss at iteration 1200 : 0.007473069708794355
Loss at iteration 1210 : 0.011130335740745068
The SSIM Value is: 0.8038237929344177
The PSNR Value is: 18.629945119222004
the epoch is: 32
Loss at iteration 10 : 0.010102973319590092
Loss at iteration 20 : 0.013865316286683083
Loss at iteration 30 : 0.009230848401784897
Loss at iteration 40 : 0.0097360135987401
Loss at iteration 50 : 0.011666755191981792
Loss at iteration 60 : 0.018675848841667175
Loss at iteration 70 : 0.010615650564432144
Loss at iteration 80 : 0.012625087052583694
Loss at iteration 90 : 0.013318215496838093
Loss at iteration 100 : 0.014010163024067879
Loss at iteration 110 : 0.007380691822618246
Loss at iteration 120 : 0.0218370221555233
Loss at iteration 130 : 0.012834650464355946
Loss at iteration 140 : 0.011966144666075706
Loss at iteration 150 : 0.02000531181693077
Loss at iteration 160 : 0.015593458898365498
Loss at iteration 170 : 0.012494400143623352
Loss at iteration 180 : 0.013904029503464699
Loss at iteration 190 : 0.012223882600665092
Loss at iteration 200 : 0.018490198999643326
Loss at iteration 210 : 0.01261230930685997
Loss at iteration 220 : 0.010952454060316086
Loss at iteration 230 : 0.007226480636745691
Loss at iteration 240 : 0.013563757762312889
Loss at iteration 250 : 0.016585923731327057
Loss at iteration 260 : 0.013232184574007988
Loss at iteration 270 : 0.010050110518932343
Loss at iteration 280 : 0.01143439020961523
Loss at iteration 290 : 0.014648172073066235
Loss at iteration 300 : 0.010757530108094215
Loss at iteration 310 : 0.022039875388145447
Loss at iteration 320 : 0.01416505966335535
Loss at iteration 330 : 0.012111486867070198
Loss at iteration 340 : 0.013199331238865852
Loss at iteration 350 : 0.01338371355086565
Loss at iteration 360 : 0.022008106112480164
Loss at iteration 370 : 0.014208495616912842
Loss at iteration 380 : 0.013339605182409286
Loss at iteration 390 : 0.010786766186356544
Loss at iteration 400 : 0.015575364232063293
Loss at iteration 410 : 0.009807677939534187
Loss at iteration 420 : 0.017917603254318237
Loss at iteration 430 : 0.009913267567753792
Loss at iteration 440 : 0.013040944933891296
Loss at iteration 450 : 0.010758448392152786
Loss at iteration 460 : 0.013681745156645775
Loss at iteration 470 : 0.011137322522699833
Loss at iteration 480 : 0.007562780287116766
Loss at iteration 490 : 0.011653759516775608
Loss at iteration 500 : 0.011827249079942703
Loss at iteration 510 : 0.009101731702685356
Loss at iteration 520 : 0.015251632779836655
Loss at iteration 530 : 0.020777937024831772
Loss at iteration 540 : 0.008011654019355774
Loss at iteration 550 : 0.01776139624416828
Loss at iteration 560 : 0.012454742565751076
Loss at iteration 570 : 0.02003052644431591
Loss at iteration 580 : 0.013526557944715023
Loss at iteration 590 : 0.013898367062211037
Loss at iteration 600 : 0.008651046082377434
Loss at iteration 610 : 0.00810039509087801
Loss at iteration 620 : 0.00990309752523899
Loss at iteration 630 : 0.012538524344563484
Loss at iteration 640 : 0.013089277781546116
Loss at iteration 650 : 0.01173833105713129
Loss at iteration 660 : 0.014697235077619553
Loss at iteration 670 : 0.016959749162197113
Loss at iteration 680 : 0.011845970526337624
Loss at iteration 690 : 0.00867890752851963
Loss at iteration 700 : 0.014231663197278976
Loss at iteration 710 : 0.012239927425980568
Loss at iteration 720 : 0.014841427095234394
Loss at iteration 730 : 0.02069692686200142
Loss at iteration 740 : 0.016760515049099922
Loss at iteration 750 : 0.018285812810063362
Loss at iteration 760 : 0.012458369135856628
Loss at iteration 770 : 0.0173172764480114
Loss at iteration 780 : 0.01374153420329094
Loss at iteration 790 : 0.008226246573030949
Loss at iteration 800 : 0.018464384600520134
Loss at iteration 810 : 0.015127910301089287
Loss at iteration 820 : 0.020834753289818764
Loss at iteration 830 : 0.0092293880879879
Loss at iteration 840 : 0.018646813929080963
Loss at iteration 850 : 0.014432743191719055
Loss at iteration 860 : 0.016691964119672775
Loss at iteration 870 : 0.00944050308316946
Loss at iteration 880 : 0.010162264108657837
Loss at iteration 890 : 0.016128510236740112
Loss at iteration 900 : 0.01826871559023857
Loss at iteration 910 : 0.0176358912140131
Loss at iteration 920 : 0.012756496667861938
Loss at iteration 930 : 0.013097157701849937
Loss at iteration 940 : 0.01284988783299923
Loss at iteration 950 : 0.015124456025660038
Loss at iteration 960 : 0.013087557628750801
Loss at iteration 970 : 0.010797169990837574
Loss at iteration 980 : 0.01934225857257843
Loss at iteration 990 : 0.010204970836639404
Loss at iteration 1000 : 0.006363739259541035
Loss at iteration 1010 : 0.015297604724764824
Loss at iteration 1020 : 0.01545463316142559
Loss at iteration 1030 : 0.0241016186773777
Loss at iteration 1040 : 0.01442696526646614
Loss at iteration 1050 : 0.010809104889631271
Loss at iteration 1060 : 0.009944770485162735
Loss at iteration 1070 : 0.01083657518029213
Loss at iteration 1080 : 0.008809980005025864
Loss at iteration 1090 : 0.01463647186756134
Loss at iteration 1100 : 0.013720403425395489
Loss at iteration 1110 : 0.009700125083327293
Loss at iteration 1120 : 0.008376971818506718
Loss at iteration 1130 : 0.008865457028150558
Loss at iteration 1140 : 0.011750138364732265
Loss at iteration 1150 : 0.013415261171758175
Loss at iteration 1160 : 0.014755255542695522
Loss at iteration 1170 : 0.006066267378628254
Loss at iteration 1180 : 0.008973076939582825
Loss at iteration 1190 : 0.018578993156552315
Loss at iteration 1200 : 0.018386563286185265
Loss at iteration 1210 : 0.010072380304336548
The SSIM Value is: 0.7976730028788249
The PSNR Value is: 18.446461232503257
the epoch is: 33
Loss at iteration 10 : 0.011790066957473755
Loss at iteration 20 : 0.012616658583283424
Loss at iteration 30 : 0.01709246262907982
Loss at iteration 40 : 0.03036479651927948
Loss at iteration 50 : 0.016004780307412148
Loss at iteration 60 : 0.011196792125701904
Loss at iteration 70 : 0.016804268583655357
Loss at iteration 80 : 0.014577770605683327
Loss at iteration 90 : 0.018552422523498535
Loss at iteration 100 : 0.012515891343355179
Loss at iteration 110 : 0.018874555826187134
Loss at iteration 120 : 0.013316147029399872
Loss at iteration 130 : 0.010303037241101265
Loss at iteration 140 : 0.016028789803385735
Loss at iteration 150 : 0.013107155449688435
Loss at iteration 160 : 0.011649543419480324
Loss at iteration 170 : 0.013253571465611458
Loss at iteration 180 : 0.01891665905714035
Loss at iteration 190 : 0.016832837834954262
Loss at iteration 200 : 0.019357750192284584
Loss at iteration 210 : 0.012478349730372429
Loss at iteration 220 : 0.012896552681922913
Loss at iteration 230 : 0.01098691951483488
Loss at iteration 240 : 0.01552150584757328
Loss at iteration 250 : 0.017529482021927834
Loss at iteration 260 : 0.016126416623592377
Loss at iteration 270 : 0.014626850374042988
Loss at iteration 280 : 0.016932321712374687
Loss at iteration 290 : 0.00967117678374052
Loss at iteration 300 : 0.011527861468493938
Loss at iteration 310 : 0.014052221551537514
Loss at iteration 320 : 0.013221800327301025
Loss at iteration 330 : 0.012084048241376877
Loss at iteration 340 : 0.013824895024299622
Loss at iteration 350 : 0.014264843426644802
Loss at iteration 360 : 0.01629766821861267
Loss at iteration 370 : 0.013023599982261658
Loss at iteration 380 : 0.010236693546175957
Loss at iteration 390 : 0.01479378156363964
Loss at iteration 400 : 0.014068538323044777
Loss at iteration 410 : 0.010509819723665714
Loss at iteration 420 : 0.01771634630858898
Loss at iteration 430 : 0.01963295415043831
Loss at iteration 440 : 0.010887986049056053
Loss at iteration 450 : 0.015888111665844917
Loss at iteration 460 : 0.011966288089752197
Loss at iteration 470 : 0.01402956061065197
Loss at iteration 480 : 0.012944645248353481
Loss at iteration 490 : 0.014088593423366547
Loss at iteration 500 : 0.013456529937684536
Loss at iteration 510 : 0.01479128934442997
Loss at iteration 520 : 0.010061709210276604
Loss at iteration 530 : 0.011993339285254478
Loss at iteration 540 : 0.014487333595752716
Loss at iteration 550 : 0.013125172816216946
Loss at iteration 560 : 0.008673837408423424
Loss at iteration 570 : 0.011511461809277534
Loss at iteration 580 : 0.02066812664270401
Loss at iteration 590 : 0.014131827279925346
Loss at iteration 600 : 0.008408566936850548
Loss at iteration 610 : 0.014676788821816444
Loss at iteration 620 : 0.012381205335259438
Loss at iteration 630 : 0.015370463952422142
Loss at iteration 640 : 0.008473776280879974
Loss at iteration 650 : 0.011842245236039162
Loss at iteration 660 : 0.010942739434540272
Loss at iteration 670 : 0.010300309397280216
Loss at iteration 680 : 0.014679700136184692
Loss at iteration 690 : 0.017758851870894432
Loss at iteration 700 : 0.009224874898791313
Loss at iteration 710 : 0.010007519274950027
Loss at iteration 720 : 0.020354419946670532
Loss at iteration 730 : 0.013588635250926018
Loss at iteration 740 : 0.005978011060506105
Loss at iteration 750 : 0.0113490866497159
Loss at iteration 760 : 0.01782100647687912
Loss at iteration 770 : 0.02105625718832016
Loss at iteration 780 : 0.012979289516806602
Loss at iteration 790 : 0.01075037196278572
Loss at iteration 800 : 0.008054407313466072
Loss at iteration 810 : 0.014427177608013153
Loss at iteration 820 : 0.01915213093161583
Loss at iteration 830 : 0.018740613013505936
Loss at iteration 840 : 0.010338105261325836
Loss at iteration 850 : 0.020292524248361588
Loss at iteration 860 : 0.017807332798838615
Loss at iteration 870 : 0.009625883772969246
Loss at iteration 880 : 0.010597463697195053
Loss at iteration 890 : 0.01352897472679615
Loss at iteration 900 : 0.018405050039291382
Loss at iteration 910 : 0.013795832172036171
Loss at iteration 920 : 0.019067320972681046
Loss at iteration 930 : 0.011802740395069122
Loss at iteration 940 : 0.014349715784192085
Loss at iteration 950 : 0.0162995345890522
Loss at iteration 960 : 0.015167237259447575
Loss at iteration 970 : 0.018175825476646423
Loss at iteration 980 : 0.013052848167717457
Loss at iteration 990 : 0.009415853768587112
Loss at iteration 1000 : 0.009039109572768211
Loss at iteration 1010 : 0.016255436465144157
Loss at iteration 1020 : 0.014133733697235584
Loss at iteration 1030 : 0.010550327599048615
Loss at iteration 1040 : 0.012931803241372108
Loss at iteration 1050 : 0.01286159735172987
Loss at iteration 1060 : 0.008614784106612206
Loss at iteration 1070 : 0.014943616464734077
Loss at iteration 1080 : 0.011446178890764713
Loss at iteration 1090 : 0.014045597985386848
Loss at iteration 1100 : 0.011197192594408989
Loss at iteration 1110 : 0.019402936100959778
Loss at iteration 1120 : 0.016291897743940353
Loss at iteration 1130 : 0.007148450240492821
Loss at iteration 1140 : 0.013838132843375206
Loss at iteration 1150 : 0.010191221721470356
Loss at iteration 1160 : 0.0071020955219864845
Loss at iteration 1170 : 0.007486926391720772
Loss at iteration 1180 : 0.015863440930843353
Loss at iteration 1190 : 0.010175373405218124
Loss at iteration 1200 : 0.018341906368732452
Loss at iteration 1210 : 0.011010413989424706
The SSIM Value is: 0.7959940393765768
The PSNR Value is: 18.379109700520832
the epoch is: 34
Loss at iteration 10 : 0.010989557020366192
Loss at iteration 20 : 0.017175670713186264
Loss at iteration 30 : 0.009112383238971233
Loss at iteration 40 : 0.009525676257908344
Loss at iteration 50 : 0.00864405557513237
Loss at iteration 60 : 0.01751565746963024
Loss at iteration 70 : 0.015630943700671196
Loss at iteration 80 : 0.010322324931621552
Loss at iteration 90 : 0.014234342612326145
Loss at iteration 100 : 0.015199139714241028
Loss at iteration 110 : 0.014265906997025013
Loss at iteration 120 : 0.017287231981754303
Loss at iteration 130 : 0.020132428035140038
Loss at iteration 140 : 0.012721531093120575
Loss at iteration 150 : 0.016002055257558823
Loss at iteration 160 : 0.014585204422473907
Loss at iteration 170 : 0.018746577203273773
Loss at iteration 180 : 0.02301613613963127
Loss at iteration 190 : 0.019667740911245346
Loss at iteration 200 : 0.010121608152985573
Loss at iteration 210 : 0.014789892360568047
Loss at iteration 220 : 0.014217655174434185
Loss at iteration 230 : 0.012870250269770622
Loss at iteration 240 : 0.005427918396890163
Loss at iteration 250 : 0.01612834259867668
Loss at iteration 260 : 0.01407160609960556
Loss at iteration 270 : 0.01759379170835018
Loss at iteration 280 : 0.009579240344464779
Loss at iteration 290 : 0.012740075588226318
Loss at iteration 300 : 0.010473683476448059
Loss at iteration 310 : 0.010795215144753456
Loss at iteration 320 : 0.01122165285050869
Loss at iteration 330 : 0.022782448679208755
Loss at iteration 340 : 0.015390116721391678
Loss at iteration 350 : 0.01441908348351717
Loss at iteration 360 : 0.014535338617861271
Loss at iteration 370 : 0.013973522000014782
Loss at iteration 380 : 0.006434776820242405
Loss at iteration 390 : 0.013429546728730202
Loss at iteration 400 : 0.017377762123942375
Loss at iteration 410 : 0.014313476160168648
Loss at iteration 420 : 0.011764557100832462
Loss at iteration 430 : 0.021077271550893784
Loss at iteration 440 : 0.012594548054039478
Loss at iteration 450 : 0.013205565512180328
Loss at iteration 460 : 0.011128697544336319
Loss at iteration 470 : 0.019426656886935234
Loss at iteration 480 : 0.013724176213145256
Loss at iteration 490 : 0.01201254315674305
Loss at iteration 500 : 0.011636890470981598
Loss at iteration 510 : 0.007432893849909306
Loss at iteration 520 : 0.013633066788315773
Loss at iteration 530 : 0.007953546941280365
Loss at iteration 540 : 0.00855935551226139
Loss at iteration 550 : 0.007074351888149977
Loss at iteration 560 : 0.0071129403077065945
Loss at iteration 570 : 0.00853453204035759
Loss at iteration 580 : 0.015860091894865036
Loss at iteration 590 : 0.01455628126859665
Loss at iteration 600 : 0.0077834352850914
Loss at iteration 610 : 0.012413226068019867
Loss at iteration 620 : 0.015761885792016983
Loss at iteration 630 : 0.01032562367618084
Loss at iteration 640 : 0.008583726361393929
Loss at iteration 650 : 0.009160337038338184
Loss at iteration 660 : 0.018048519268631935
Loss at iteration 670 : 0.011544831097126007
Loss at iteration 680 : 0.012830701656639576
Loss at iteration 690 : 0.011517280712723732
Loss at iteration 700 : 0.012931105680763721
Loss at iteration 710 : 0.018170081079006195
Loss at iteration 720 : 0.010504569858312607
Loss at iteration 730 : 0.013838110491633415
Loss at iteration 740 : 0.01698501780629158
Loss at iteration 750 : 0.01229618489742279
Loss at iteration 760 : 0.016655219718813896
Loss at iteration 770 : 0.009198939427733421
Loss at iteration 780 : 0.010284725576639175
Loss at iteration 790 : 0.011582507751882076
Loss at iteration 800 : 0.01820567436516285
Loss at iteration 810 : 0.014142182655632496
Loss at iteration 820 : 0.01914079114794731
Loss at iteration 830 : 0.018292050808668137
Loss at iteration 840 : 0.010715803131461143
Loss at iteration 850 : 0.0135513786226511
Loss at iteration 860 : 0.031345974653959274
Loss at iteration 870 : 0.00858662836253643
Loss at iteration 880 : 0.008706381544470787
Loss at iteration 890 : 0.011845352128148079
Loss at iteration 900 : 0.01233750581741333
Loss at iteration 910 : 0.010821004398167133
Loss at iteration 920 : 0.009070826694369316
Loss at iteration 930 : 0.014059806242585182
Loss at iteration 940 : 0.022190537303686142
Loss at iteration 950 : 0.006844492629170418
Loss at iteration 960 : 0.010141655802726746
Loss at iteration 970 : 0.011884463019669056
Loss at iteration 980 : 0.011267871595919132
Loss at iteration 990 : 0.010973123833537102
Loss at iteration 1000 : 0.007555963937193155
Loss at iteration 1010 : 0.01667039282619953
Loss at iteration 1020 : 0.010707895271480083
Loss at iteration 1030 : 0.012376741506159306
Loss at iteration 1040 : 0.007245635613799095
Loss at iteration 1050 : 0.012258602306246758
Loss at iteration 1060 : 0.010935886763036251
Loss at iteration 1070 : 0.011908875778317451
Loss at iteration 1080 : 0.01699334755539894
Loss at iteration 1090 : 0.01182556338608265
Loss at iteration 1100 : 0.015126882120966911
Loss at iteration 1110 : 0.012074831873178482
Loss at iteration 1120 : 0.02319135144352913
Loss at iteration 1130 : 0.02383960410952568
Loss at iteration 1140 : 0.014005225151777267
Loss at iteration 1150 : 0.01349565852433443
Loss at iteration 1160 : 0.018890289589762688
Loss at iteration 1170 : 0.013545944355428219
Loss at iteration 1180 : 0.013547152280807495
Loss at iteration 1190 : 0.018459012731909752
Loss at iteration 1200 : 0.010513653978705406
Loss at iteration 1210 : 0.013225484639406204
The SSIM Value is: 0.807330850760142
The PSNR Value is: 18.690987586975098
the epoch is: 35
Loss at iteration 10 : 0.01692746952176094
Loss at iteration 20 : 0.016829784959554672
Loss at iteration 30 : 0.021412154659628868
Loss at iteration 40 : 0.017404824495315552
Loss at iteration 50 : 0.01417817547917366
Loss at iteration 60 : 0.014411264099180698
Loss at iteration 70 : 0.010620852932333946
Loss at iteration 80 : 0.013486281037330627
Loss at iteration 90 : 0.02005733922123909
Loss at iteration 100 : 0.009733753278851509
Loss at iteration 110 : 0.014307212084531784
Loss at iteration 120 : 0.01318544615060091
Loss at iteration 130 : 0.009560882113873959
Loss at iteration 140 : 0.016230445355176926
Loss at iteration 150 : 0.017080942168831825
Loss at iteration 160 : 0.011810671538114548
Loss at iteration 170 : 0.010761967860162258
Loss at iteration 180 : 0.012182323262095451
Loss at iteration 190 : 0.007451888173818588
Loss at iteration 200 : 0.011538148857653141
Loss at iteration 210 : 0.016123997047543526
Loss at iteration 220 : 0.010571780614554882
Loss at iteration 230 : 0.013927644118666649
Loss at iteration 240 : 0.009828572161495686
Loss at iteration 250 : 0.008879090659320354
Loss at iteration 260 : 0.016317296773195267
Loss at iteration 270 : 0.010197480209171772
Loss at iteration 280 : 0.010304910130798817
Loss at iteration 290 : 0.013097519055008888
Loss at iteration 300 : 0.014532627537846565
Loss at iteration 310 : 0.009764463640749454
Loss at iteration 320 : 0.01051412895321846
Loss at iteration 330 : 0.011055951938033104
Loss at iteration 340 : 0.008059017360210419
Loss at iteration 350 : 0.01796124503016472
Loss at iteration 360 : 0.01347288303077221
Loss at iteration 370 : 0.020131833851337433
Loss at iteration 380 : 0.010637317784130573
Loss at iteration 390 : 0.016333691775798798
Loss at iteration 400 : 0.018838118761777878
Loss at iteration 410 : 0.016900289803743362
Loss at iteration 420 : 0.014971883967518806
Loss at iteration 430 : 0.014552325010299683
Loss at iteration 440 : 0.020899435505270958
Loss at iteration 450 : 0.013532232493162155
Loss at iteration 460 : 0.011808384209871292
Loss at iteration 470 : 0.016360074281692505
Loss at iteration 480 : 0.011333698406815529
Loss at iteration 490 : 0.018692104145884514
Loss at iteration 500 : 0.009703965857625008
Loss at iteration 510 : 0.022473309189081192
Loss at iteration 520 : 0.013572510331869125
Loss at iteration 530 : 0.01907888613641262
Loss at iteration 540 : 0.013698719441890717
Loss at iteration 550 : 0.016405880451202393
Loss at iteration 560 : 0.017742399126291275
Loss at iteration 570 : 0.011162761598825455
Loss at iteration 580 : 0.011943459510803223
Loss at iteration 590 : 0.01640145853161812
Loss at iteration 600 : 0.011396238580346107
Loss at iteration 610 : 0.011423138901591301
Loss at iteration 620 : 0.017809221521019936
Loss at iteration 630 : 0.00801536999642849
Loss at iteration 640 : 0.011599671095609665
Loss at iteration 650 : 0.021216295659542084
Loss at iteration 660 : 0.017189644277095795
Loss at iteration 670 : 0.010540774092078209
Loss at iteration 680 : 0.016769656911492348
Loss at iteration 690 : 0.014345414936542511
Loss at iteration 700 : 0.013745630159974098
Loss at iteration 710 : 0.012616731226444244
Loss at iteration 720 : 0.019843747839331627
Loss at iteration 730 : 0.011241991072893143
Loss at iteration 740 : 0.01212332770228386
Loss at iteration 750 : 0.02071671560406685
Loss at iteration 760 : 0.012630331330001354
Loss at iteration 770 : 0.01508026197552681
Loss at iteration 780 : 0.011905267834663391
Loss at iteration 790 : 0.014419307932257652
Loss at iteration 800 : 0.009532010182738304
Loss at iteration 810 : 0.01216051820665598
Loss at iteration 820 : 0.010903813876211643
Loss at iteration 830 : 0.016846612095832825
Loss at iteration 840 : 0.014766975305974483
Loss at iteration 850 : 0.00835404172539711
Loss at iteration 860 : 0.018046870827674866
Loss at iteration 870 : 0.012750603258609772
Loss at iteration 880 : 0.008340639993548393
Loss at iteration 890 : 0.0072723571211099625
Loss at iteration 900 : 0.019676484167575836
Loss at iteration 910 : 0.015801049768924713
Loss at iteration 920 : 0.009288212284445763
Loss at iteration 930 : 0.016960006207227707
Loss at iteration 940 : 0.006034079939126968
Loss at iteration 950 : 0.010777144692838192
Loss at iteration 960 : 0.020360762253403664
Loss at iteration 970 : 0.012761405669152737
Loss at iteration 980 : 0.02429061010479927
Loss at iteration 990 : 0.012049033306539059
Loss at iteration 1000 : 0.010095072910189629
Loss at iteration 1010 : 0.01589609496295452
Loss at iteration 1020 : 0.01359596662223339
Loss at iteration 1030 : 0.012024713680148125
Loss at iteration 1040 : 0.010976390913128853
Loss at iteration 1050 : 0.023686397820711136
Loss at iteration 1060 : 0.00880509801208973
Loss at iteration 1070 : 0.013355560600757599
Loss at iteration 1080 : 0.011737091466784477
Loss at iteration 1090 : 0.011827548034489155
Loss at iteration 1100 : 0.008720427751541138
Loss at iteration 1110 : 0.014500275254249573
Loss at iteration 1120 : 0.009340580552816391
Loss at iteration 1130 : 0.015690410509705544
Loss at iteration 1140 : 0.01994137465953827
Loss at iteration 1150 : 0.01825343817472458
Loss at iteration 1160 : 0.017576688900589943
Loss at iteration 1170 : 0.011291486211121082
Loss at iteration 1180 : 0.017572112381458282
Loss at iteration 1190 : 0.014260940253734589
Loss at iteration 1200 : 0.015379784628748894
Loss at iteration 1210 : 0.011900083161890507
The SSIM Value is: 0.793343432744344
The PSNR Value is: 17.87045211791992
the epoch is: 36
Loss at iteration 10 : 0.010119115002453327
Loss at iteration 20 : 0.018292363733053207
Loss at iteration 30 : 0.013539101928472519
Loss at iteration 40 : 0.012473572045564651
Loss at iteration 50 : 0.013300715014338493
Loss at iteration 60 : 0.008722922764718533
Loss at iteration 70 : 0.009891882538795471
Loss at iteration 80 : 0.014040086418390274
Loss at iteration 90 : 0.009503256529569626
Loss at iteration 100 : 0.011573933064937592
Loss at iteration 110 : 0.018894685432314873
Loss at iteration 120 : 0.012450792826712132
Loss at iteration 130 : 0.014589284546673298
Loss at iteration 140 : 0.010920112021267414
Loss at iteration 150 : 0.011475371196866035
Loss at iteration 160 : 0.014587821438908577
Loss at iteration 170 : 0.011305995285511017
Loss at iteration 180 : 0.018283121287822723
Loss at iteration 190 : 0.014135557226836681
Loss at iteration 200 : 0.0100055281072855
Loss at iteration 210 : 0.012912582606077194
Loss at iteration 220 : 0.012184415012598038
Loss at iteration 230 : 0.011553552933037281
Loss at iteration 240 : 0.015816938132047653
Loss at iteration 250 : 0.013939977623522282
Loss at iteration 260 : 0.013268285430967808
Loss at iteration 270 : 0.017969878390431404
Loss at iteration 280 : 0.011642050929367542
Loss at iteration 290 : 0.016003450378775597
Loss at iteration 300 : 0.020256537944078445
Loss at iteration 310 : 0.01286410540342331
Loss at iteration 320 : 0.012681598775088787
Loss at iteration 330 : 0.02200966514647007
Loss at iteration 340 : 0.0132944006472826
Loss at iteration 350 : 0.010704048909246922
Loss at iteration 360 : 0.01661367528140545
Loss at iteration 370 : 0.016770323738455772
Loss at iteration 380 : 0.022254567593336105
Loss at iteration 390 : 0.021839385852217674
Loss at iteration 400 : 0.010244566947221756
Loss at iteration 410 : 0.013375673443078995
Loss at iteration 420 : 0.013829885981976986
Loss at iteration 430 : 0.01832323893904686
Loss at iteration 440 : 0.012214791029691696
Loss at iteration 450 : 0.009115122258663177
Loss at iteration 460 : 0.012847824953496456
Loss at iteration 470 : 0.012527760118246078
Loss at iteration 480 : 0.012868993915617466
Loss at iteration 490 : 0.012821907177567482
Loss at iteration 500 : 0.015708349645137787
Loss at iteration 510 : 0.009359885938465595
Loss at iteration 520 : 0.01059517078101635
Loss at iteration 530 : 0.014631271362304688
Loss at iteration 540 : 0.020239874720573425
Loss at iteration 550 : 0.013481134548783302
Loss at iteration 560 : 0.015263672918081284
Loss at iteration 570 : 0.016698788851499557
Loss at iteration 580 : 0.013296527788043022
Loss at iteration 590 : 0.014349197968840599
Loss at iteration 600 : 0.011424296535551548
Loss at iteration 610 : 0.014445843175053596
Loss at iteration 620 : 0.01807815581560135
Loss at iteration 630 : 0.010184510610997677
Loss at iteration 640 : 0.010965099558234215
Loss at iteration 650 : 0.00822474341839552
Loss at iteration 660 : 0.012968395836651325
Loss at iteration 670 : 0.010867339558899403
Loss at iteration 680 : 0.013529911637306213
Loss at iteration 690 : 0.015577059239149094
Loss at iteration 700 : 0.010958919301629066
Loss at iteration 710 : 0.008908803574740887
Loss at iteration 720 : 0.019582975655794144
Loss at iteration 730 : 0.017130523920059204
Loss at iteration 740 : 0.012001048773527145
Loss at iteration 750 : 0.01445773709565401
Loss at iteration 760 : 0.015282029286026955
Loss at iteration 770 : 0.017911311239004135
Loss at iteration 780 : 0.0191517136991024
Loss at iteration 790 : 0.011335610412061214
Loss at iteration 800 : 0.009301050566136837
Loss at iteration 810 : 0.010573592968285084
Loss at iteration 820 : 0.007465179078280926
Loss at iteration 830 : 0.01019296981394291
Loss at iteration 840 : 0.0163896381855011
Loss at iteration 850 : 0.01074250042438507
Loss at iteration 860 : 0.009681674651801586
Loss at iteration 870 : 0.008713016286492348
Loss at iteration 880 : 0.020408982411026955
Loss at iteration 890 : 0.012455682270228863
Loss at iteration 900 : 0.006951373536139727
Loss at iteration 910 : 0.015551774762570858
Loss at iteration 920 : 0.015858042985200882
Loss at iteration 930 : 0.012428759597241879
Loss at iteration 940 : 0.006998941767960787
Loss at iteration 950 : 0.022983208298683167
Loss at iteration 960 : 0.012123712338507175
Loss at iteration 970 : 0.01142734382301569
Loss at iteration 980 : 0.01237389538437128
Loss at iteration 990 : 0.009848303161561489
Loss at iteration 1000 : 0.01199875958263874
Loss at iteration 1010 : 0.01853741705417633
Loss at iteration 1020 : 0.01373215951025486
Loss at iteration 1030 : 0.012834528461098671
Loss at iteration 1040 : 0.01175631582736969
Loss at iteration 1050 : 0.014862916432321072
Loss at iteration 1060 : 0.008908468298614025
Loss at iteration 1070 : 0.013074586167931557
Loss at iteration 1080 : 0.0114357378333807
Loss at iteration 1090 : 0.02027924358844757
Loss at iteration 1100 : 0.017540112137794495
Loss at iteration 1110 : 0.019982513040304184
Loss at iteration 1120 : 0.028792070224881172
Loss at iteration 1130 : 0.017581386491656303
Loss at iteration 1140 : 0.015788720920681953
Loss at iteration 1150 : 0.009419189766049385
Loss at iteration 1160 : 0.007331036496907473
Loss at iteration 1170 : 0.01235125306993723
Loss at iteration 1180 : 0.014831166714429855
Loss at iteration 1190 : 0.01768748089671135
Loss at iteration 1200 : 0.019845718517899513
Loss at iteration 1210 : 0.013076134026050568
The SSIM Value is: 0.7913595318794251
The PSNR Value is: 17.864682706197105
the epoch is: 37
Loss at iteration 10 : 0.010119734331965446
Loss at iteration 20 : 0.016492316499352455
Loss at iteration 30 : 0.011214230209589005
Loss at iteration 40 : 0.007800639141350985
Loss at iteration 50 : 0.014755796641111374
Loss at iteration 60 : 0.013246575370430946
Loss at iteration 70 : 0.011807813309133053
Loss at iteration 80 : 0.012011697515845299
Loss at iteration 90 : 0.01295480877161026
Loss at iteration 100 : 0.010753381997346878
Loss at iteration 110 : 0.01407606154680252
Loss at iteration 120 : 0.01766020618379116
Loss at iteration 130 : 0.005212234333157539
Loss at iteration 140 : 0.010288459248840809
Loss at iteration 150 : 0.007998324930667877
Loss at iteration 160 : 0.01248228270560503
Loss at iteration 170 : 0.009872459806501865
Loss at iteration 180 : 0.014102933928370476
Loss at iteration 190 : 0.01780558191239834
Loss at iteration 200 : 0.010745760053396225
Loss at iteration 210 : 0.009332789108157158
Loss at iteration 220 : 0.022114595398306847
Loss at iteration 230 : 0.01338900625705719
Loss at iteration 240 : 0.01600615680217743
Loss at iteration 250 : 0.01675870455801487
Loss at iteration 260 : 0.01809702441096306
Loss at iteration 270 : 0.019833160564303398
Loss at iteration 280 : 0.011146900244057178
Loss at iteration 290 : 0.012193892151117325
Loss at iteration 300 : 0.014660108834505081
Loss at iteration 310 : 0.015741825103759766
Loss at iteration 320 : 0.011460437439382076
Loss at iteration 330 : 0.010200568474829197
Loss at iteration 340 : 0.016260117292404175
Loss at iteration 350 : 0.029063867405056953
Loss at iteration 360 : 0.01488298550248146
Loss at iteration 370 : 0.016300804913043976
Loss at iteration 380 : 0.012832913547754288
Loss at iteration 390 : 0.014976770617067814
Loss at iteration 400 : 0.010751429945230484
Loss at iteration 410 : 0.01272582821547985
Loss at iteration 420 : 0.012742946855723858
Loss at iteration 430 : 0.012893235310912132
Loss at iteration 440 : 0.016234420239925385
Loss at iteration 450 : 0.012261120602488518
Loss at iteration 460 : 0.010986162349581718
Loss at iteration 470 : 0.013367481529712677
Loss at iteration 480 : 0.009572099894285202
Loss at iteration 490 : 0.01288802083581686
Loss at iteration 500 : 0.01368200033903122
Loss at iteration 510 : 0.015115812420845032
Loss at iteration 520 : 0.017600167542696
Loss at iteration 530 : 0.012236849404871464
Loss at iteration 540 : 0.007997328415513039
Loss at iteration 550 : 0.01740299165248871
Loss at iteration 560 : 0.014392690733075142
Loss at iteration 570 : 0.009075994603335857
Loss at iteration 580 : 0.011427654884755611
Loss at iteration 590 : 0.015201798640191555
Loss at iteration 600 : 0.018582548946142197
Loss at iteration 610 : 0.025091148912906647
Loss at iteration 620 : 0.01317791361361742
Loss at iteration 630 : 0.01575007662177086
Loss at iteration 640 : 0.013433658517897129
Loss at iteration 650 : 0.011904244311153889
Loss at iteration 660 : 0.01473984494805336
Loss at iteration 670 : 0.015900589525699615
Loss at iteration 680 : 0.014287854544818401
Loss at iteration 690 : 0.008784017525613308
Loss at iteration 700 : 0.01057806983590126
Loss at iteration 710 : 0.014008786529302597
Loss at iteration 720 : 0.02069821208715439
Loss at iteration 730 : 0.010028237476944923
Loss at iteration 740 : 0.016763921827077866
Loss at iteration 750 : 0.01461848895996809
Loss at iteration 760 : 0.018347617238759995
Loss at iteration 770 : 0.0094514861702919
Loss at iteration 780 : 0.013049272820353508
Loss at iteration 790 : 0.016731221228837967
Loss at iteration 800 : 0.020952574908733368
Loss at iteration 810 : 0.016693398356437683
Loss at iteration 820 : 0.022411301732063293
Loss at iteration 830 : 0.018454916775226593
Loss at iteration 840 : 0.0121545335277915
Loss at iteration 850 : 0.010846909135580063
Loss at iteration 860 : 0.011801330372691154
Loss at iteration 870 : 0.020199917256832123
Loss at iteration 880 : 0.016024429351091385
Loss at iteration 890 : 0.012930895201861858
Loss at iteration 900 : 0.011474492028355598
Loss at iteration 910 : 0.025034785270690918
Loss at iteration 920 : 0.010213830508291721
Loss at iteration 930 : 0.010740101337432861
Loss at iteration 940 : 0.007890434935688972
Loss at iteration 950 : 0.015857376158237457
Loss at iteration 960 : 0.020868826657533646
Loss at iteration 970 : 0.009651895612478256
Loss at iteration 980 : 0.012425157241523266
Loss at iteration 990 : 0.02544114552438259
Loss at iteration 1000 : 0.01716310903429985
Loss at iteration 1010 : 0.019045988097786903
Loss at iteration 1020 : 0.008920007385313511
Loss at iteration 1030 : 0.014457166194915771
Loss at iteration 1040 : 0.009087510406970978
Loss at iteration 1050 : 0.028686974197626114
Loss at iteration 1060 : 0.013333882205188274
Loss at iteration 1070 : 0.01495454739779234
Loss at iteration 1080 : 0.01235269196331501
Loss at iteration 1090 : 0.011738082394003868
Loss at iteration 1100 : 0.011942829936742783
Loss at iteration 1110 : 0.012010626494884491
Loss at iteration 1120 : 0.02010233886539936
Loss at iteration 1130 : 0.013948775827884674
Loss at iteration 1140 : 0.011758355423808098
Loss at iteration 1150 : 0.009466126561164856
Loss at iteration 1160 : 0.008595861494541168
Loss at iteration 1170 : 0.015825379639863968
Loss at iteration 1180 : 0.01725161448121071
Loss at iteration 1190 : 0.00897879060357809
Loss at iteration 1200 : 0.021947121247649193
Loss at iteration 1210 : 0.015794318169355392
The SSIM Value is: 0.8029828707377116
The PSNR Value is: 18.517400232950845
the epoch is: 38
Loss at iteration 10 : 0.013703013770282269
Loss at iteration 20 : 0.00901846308261156
Loss at iteration 30 : 0.012595072388648987
Loss at iteration 40 : 0.016866128891706467
Loss at iteration 50 : 0.015379783697426319
Loss at iteration 60 : 0.009990861639380455
Loss at iteration 70 : 0.012293238192796707
Loss at iteration 80 : 0.017215043306350708
Loss at iteration 90 : 0.016620997339487076
Loss at iteration 100 : 0.014733690768480301
Loss at iteration 110 : 0.009907204657793045
Loss at iteration 120 : 0.014625582844018936
Loss at iteration 130 : 0.010366274043917656
Loss at iteration 140 : 0.013104311190545559
Loss at iteration 150 : 0.01770993508398533
Loss at iteration 160 : 0.0151006318628788
Loss at iteration 170 : 0.011202137917280197
Loss at iteration 180 : 0.018049173057079315
Loss at iteration 190 : 0.007617411203682423
Loss at iteration 200 : 0.019825056195259094
Loss at iteration 210 : 0.010107235983014107
Loss at iteration 220 : 0.013773033395409584
Loss at iteration 230 : 0.009371455758810043
Loss at iteration 240 : 0.011860772036015987
Loss at iteration 250 : 0.010919492691755295
Loss at iteration 260 : 0.01449008658528328
Loss at iteration 270 : 0.011233779601752758
Loss at iteration 280 : 0.01468967366963625
Loss at iteration 290 : 0.013669008389115334
Loss at iteration 300 : 0.024716531857848167
Loss at iteration 310 : 0.01675303652882576
Loss at iteration 320 : 0.010788742452859879
Loss at iteration 330 : 0.011960548348724842
Loss at iteration 340 : 0.015781791880726814
Loss at iteration 350 : 0.009813890792429447
Loss at iteration 360 : 0.014691902324557304
Loss at iteration 370 : 0.013215524144470692
Loss at iteration 380 : 0.008656356483697891
Loss at iteration 390 : 0.024801578372716904
Loss at iteration 400 : 0.01392708532512188
Loss at iteration 410 : 0.015599225647747517
Loss at iteration 420 : 0.015578338876366615
Loss at iteration 430 : 0.012188419699668884
Loss at iteration 440 : 0.014526666142046452
Loss at iteration 450 : 0.009280912578105927
Loss at iteration 460 : 0.013021102175116539
Loss at iteration 470 : 0.014662064611911774
Loss at iteration 480 : 0.011942372657358646
Loss at iteration 490 : 0.01113180909305811
Loss at iteration 500 : 0.013620080426335335
Loss at iteration 510 : 0.010523946955800056
Loss at iteration 520 : 0.01950986683368683
Loss at iteration 530 : 0.016446446999907494
Loss at iteration 540 : 0.016035545617341995
Loss at iteration 550 : 0.012543179094791412
Loss at iteration 560 : 0.013827716931700706
Loss at iteration 570 : 0.01342341210693121
Loss at iteration 580 : 0.013722775503993034
Loss at iteration 590 : 0.007390780374407768
Loss at iteration 600 : 0.015415968373417854
Loss at iteration 610 : 0.01952863670885563
Loss at iteration 620 : 0.011804820969700813
Loss at iteration 630 : 0.012503352016210556
Loss at iteration 640 : 0.017319129779934883
Loss at iteration 650 : 0.013018004596233368
Loss at iteration 660 : 0.016575325280427933
Loss at iteration 670 : 0.021991737186908722
Loss at iteration 680 : 0.015318726189434528
Loss at iteration 690 : 0.01485611405223608
Loss at iteration 700 : 0.011775475926697254
Loss at iteration 710 : 0.013687720522284508
Loss at iteration 720 : 0.015685368329286575
Loss at iteration 730 : 0.013288005255162716
Loss at iteration 740 : 0.01730273850262165
Loss at iteration 750 : 0.012804735451936722
Loss at iteration 760 : 0.007601570338010788
Loss at iteration 770 : 0.021025503054261208
Loss at iteration 780 : 0.010728578083217144
Loss at iteration 790 : 0.0175602026283741
Loss at iteration 800 : 0.009961669333279133
Loss at iteration 810 : 0.01185673475265503
Loss at iteration 820 : 0.008899131789803505
Loss at iteration 830 : 0.014923794195055962
Loss at iteration 840 : 0.010974578559398651
Loss at iteration 850 : 0.012720800936222076
Loss at iteration 860 : 0.013176464475691319
Loss at iteration 870 : 0.011327452026307583
Loss at iteration 880 : 0.010594657622277737
Loss at iteration 890 : 0.017564699053764343
Loss at iteration 900 : 0.017473315820097923
Loss at iteration 910 : 0.00863775797188282
Loss at iteration 920 : 0.013149434700608253
Loss at iteration 930 : 0.019149411469697952
Loss at iteration 940 : 0.012952154502272606
Loss at iteration 950 : 0.01514342799782753
Loss at iteration 960 : 0.011466809548437595
Loss at iteration 970 : 0.015525252558290958
Loss at iteration 980 : 0.016980618238449097
Loss at iteration 990 : 0.012033146806061268
Loss at iteration 1000 : 0.008758069016039371
Loss at iteration 1010 : 0.005897774361073971
Loss at iteration 1020 : 0.009802112355828285
Loss at iteration 1030 : 0.016335805878043175
Loss at iteration 1040 : 0.0144420200958848
Loss at iteration 1050 : 0.01537953969091177
Loss at iteration 1060 : 0.012334132567048073
Loss at iteration 1070 : 0.01068166270852089
Loss at iteration 1080 : 0.009388764388859272
Loss at iteration 1090 : 0.009657875634729862
Loss at iteration 1100 : 0.0077604735270142555
Loss at iteration 1110 : 0.014078851789236069
Loss at iteration 1120 : 0.017579831182956696
Loss at iteration 1130 : 0.009677274152636528
Loss at iteration 1140 : 0.008096471428871155
Loss at iteration 1150 : 0.009092293679714203
Loss at iteration 1160 : 0.012560226023197174
Loss at iteration 1170 : 0.01137196272611618
Loss at iteration 1180 : 0.016966555267572403
Loss at iteration 1190 : 0.015324922278523445
Loss at iteration 1200 : 0.013408972881734371
Loss at iteration 1210 : 0.015216317027807236
The SSIM Value is: 0.804176131884257
The PSNR Value is: 18.468997319539387
the epoch is: 39
Loss at iteration 10 : 0.011063473299145699
Loss at iteration 20 : 0.009837435558438301
Loss at iteration 30 : 0.02098759263753891
Loss at iteration 40 : 0.011371435597538948
Loss at iteration 50 : 0.007586858235299587
Loss at iteration 60 : 0.011472705751657486
Loss at iteration 70 : 0.011577606201171875
Loss at iteration 80 : 0.009884788654744625
Loss at iteration 90 : 0.011637458577752113
Loss at iteration 100 : 0.01050338800996542
Loss at iteration 110 : 0.010225456207990646
Loss at iteration 120 : 0.01549874059855938
Loss at iteration 130 : 0.012496048584580421
Loss at iteration 140 : 0.010584903880953789
Loss at iteration 150 : 0.012084185145795345
Loss at iteration 160 : 0.012878481298685074
Loss at iteration 170 : 0.01379053108394146
Loss at iteration 180 : 0.015165533870458603
Loss at iteration 190 : 0.014037695713341236
Loss at iteration 200 : 0.010611271485686302
Loss at iteration 210 : 0.009064668789505959
Loss at iteration 220 : 0.014242713339626789
Loss at iteration 230 : 0.01271878369152546
Loss at iteration 240 : 0.014932484365999699
Loss at iteration 250 : 0.01576831191778183
Loss at iteration 260 : 0.011400114744901657
Loss at iteration 270 : 0.010743405669927597
Loss at iteration 280 : 0.007890596985816956
Loss at iteration 290 : 0.01692858338356018
Loss at iteration 300 : 0.010698197409510612
Loss at iteration 310 : 0.012847572565078735
Loss at iteration 320 : 0.013914402574300766
Loss at iteration 330 : 0.01638089492917061
Loss at iteration 340 : 0.006724598817527294
Loss at iteration 350 : 0.013264579698443413
Loss at iteration 360 : 0.012673139572143555
Loss at iteration 370 : 0.01212148554623127
Loss at iteration 380 : 0.013173326849937439
Loss at iteration 390 : 0.031101778149604797
Loss at iteration 400 : 0.025366216897964478
Loss at iteration 410 : 0.010693494230508804
Loss at iteration 420 : 0.012392552569508553
Loss at iteration 430 : 0.008299974724650383
Loss at iteration 440 : 0.009317439049482346
Loss at iteration 450 : 0.01445227861404419
Loss at iteration 460 : 0.013740859925746918
Loss at iteration 470 : 0.015268215909600258
Loss at iteration 480 : 0.016156740486621857
Loss at iteration 490 : 0.028622951358556747
Loss at iteration 500 : 0.012981103733181953
Loss at iteration 510 : 0.01171395368874073
Loss at iteration 520 : 0.014726011082530022
Loss at iteration 530 : 0.017004165798425674
Loss at iteration 540 : 0.016404731199145317
Loss at iteration 550 : 0.012541132047772408
Loss at iteration 560 : 0.011455832049250603
Loss at iteration 570 : 0.011641721241176128
Loss at iteration 580 : 0.013954364694654942
Loss at iteration 590 : 0.01797477900981903
Loss at iteration 600 : 0.011817495338618755
Loss at iteration 610 : 0.021626342087984085
Loss at iteration 620 : 0.0138922780752182
Loss at iteration 630 : 0.010453163646161556
Loss at iteration 640 : 0.010050018317997456
Loss at iteration 650 : 0.01563253626227379
Loss at iteration 660 : 0.016648925840854645
Loss at iteration 670 : 0.01153151597827673
Loss at iteration 680 : 0.023999609053134918
Loss at iteration 690 : 0.012589160352945328
Loss at iteration 700 : 0.014031456783413887
Loss at iteration 710 : 0.014511493034660816
Loss at iteration 720 : 0.018442504107952118
Loss at iteration 730 : 0.015372132882475853
Loss at iteration 740 : 0.02399437688291073
Loss at iteration 750 : 0.013668625615537167
Loss at iteration 760 : 0.015154710039496422
Loss at iteration 770 : 0.00803480762988329
Loss at iteration 780 : 0.012268265709280968
Loss at iteration 790 : 0.011868095025420189
Loss at iteration 800 : 0.011792756617069244
Loss at iteration 810 : 0.01990026980638504
Loss at iteration 820 : 0.013720730319619179
Loss at iteration 830 : 0.01795070432126522
Loss at iteration 840 : 0.019273292273283005
Loss at iteration 850 : 0.010172754526138306
Loss at iteration 860 : 0.014036746695637703
Loss at iteration 870 : 0.017205828800797462
Loss at iteration 880 : 0.013203952461481094
Loss at iteration 890 : 0.013473748229444027
Loss at iteration 900 : 0.01609528623521328
Loss at iteration 910 : 0.013571063056588173
Loss at iteration 920 : 0.010960696265101433
Loss at iteration 930 : 0.014954110607504845
Loss at iteration 940 : 0.022670112550258636
Loss at iteration 950 : 0.009338823147118092
Loss at iteration 960 : 0.011063397862017155
Loss at iteration 970 : 0.015660297125577927
Loss at iteration 980 : 0.009887338615953922
Loss at iteration 990 : 0.01931009814143181
Loss at iteration 1000 : 0.013006733730435371
Loss at iteration 1010 : 0.011818485334515572
Loss at iteration 1020 : 0.012797003611922264
Loss at iteration 1030 : 0.018950508907437325
Loss at iteration 1040 : 0.012587969191372395
Loss at iteration 1050 : 0.010616066865622997
Loss at iteration 1060 : 0.012373359873890877
Loss at iteration 1070 : 0.013968348503112793
Loss at iteration 1080 : 0.01999557577073574
Loss at iteration 1090 : 0.01542866975069046
Loss at iteration 1100 : 0.020719466730952263
Loss at iteration 1110 : 0.01827872544527054
Loss at iteration 1120 : 0.01880425587296486
Loss at iteration 1130 : 0.01941838301718235
Loss at iteration 1140 : 0.01530645415186882
Loss at iteration 1150 : 0.01334640197455883
Loss at iteration 1160 : 0.016266873106360435
Loss at iteration 1170 : 0.009648634120821953
Loss at iteration 1180 : 0.011909089982509613
Loss at iteration 1190 : 0.014109708368778229
Loss at iteration 1200 : 0.011182799935340881
Loss at iteration 1210 : 0.008894057944417
The SSIM Value is: 0.8097407817840576
The PSNR Value is: 18.718690617879233
the epoch is: 40
Loss at iteration 10 : 0.01847805827856064
Loss at iteration 20 : 0.010055771097540855
Loss at iteration 30 : 0.013949556276202202
Loss at iteration 40 : 0.006590661127120256
Loss at iteration 50 : 0.010709259659051895
Loss at iteration 60 : 0.009096251800656319
Loss at iteration 70 : 0.010745522566139698
Loss at iteration 80 : 0.016823623329401016
Loss at iteration 90 : 0.016615673899650574
Loss at iteration 100 : 0.010129384696483612
Loss at iteration 110 : 0.011358167044818401
Loss at iteration 120 : 0.01376416441053152
Loss at iteration 130 : 0.017770780250430107
Loss at iteration 140 : 0.014556057751178741
Loss at iteration 150 : 0.008689388632774353
Loss at iteration 160 : 0.015154857188463211
Loss at iteration 170 : 0.013330390676856041
Loss at iteration 180 : 0.02255914732813835
Loss at iteration 190 : 0.012604565359652042
Loss at iteration 200 : 0.009333943948149681
Loss at iteration 210 : 0.011798910796642303
Loss at iteration 220 : 0.008379507809877396
Loss at iteration 230 : 0.012012610211968422
Loss at iteration 240 : 0.01253480650484562
Loss at iteration 250 : 0.010489140637218952
Loss at iteration 260 : 0.022062834352254868
Loss at iteration 270 : 0.011726481840014458
Loss at iteration 280 : 0.013407045975327492
Loss at iteration 290 : 0.01590264029800892
Loss at iteration 300 : 0.015216232277452946
Loss at iteration 310 : 0.012114283628761768
Loss at iteration 320 : 0.019671181216835976
Loss at iteration 330 : 0.0075804200023412704
Loss at iteration 340 : 0.010342169553041458
Loss at iteration 350 : 0.011450758203864098
Loss at iteration 360 : 0.01184241846203804
Loss at iteration 370 : 0.015964247286319733
Loss at iteration 380 : 0.007070313207805157
Loss at iteration 390 : 0.012929750606417656
Loss at iteration 400 : 0.01528116688132286
Loss at iteration 410 : 0.02187453582882881
Loss at iteration 420 : 0.015816349536180496
Loss at iteration 430 : 0.0153408357873559
Loss at iteration 440 : 0.019859852269291878
Loss at iteration 450 : 0.011719080619513988
Loss at iteration 460 : 0.014020148664712906
Loss at iteration 470 : 0.015683548524975777
Loss at iteration 480 : 0.012909669429063797
Loss at iteration 490 : 0.015108078718185425
Loss at iteration 500 : 0.010083997622132301
Loss at iteration 510 : 0.009745236486196518
Loss at iteration 520 : 0.010441495105624199
Loss at iteration 530 : 0.012732052244246006
Loss at iteration 540 : 0.02165936678647995
Loss at iteration 550 : 0.018759243190288544
Loss at iteration 560 : 0.012967376038432121
Loss at iteration 570 : 0.016234876587986946
Loss at iteration 580 : 0.014683924615383148
Loss at iteration 590 : 0.020046129822731018
Loss at iteration 600 : 0.012018858455121517
Loss at iteration 610 : 0.017838820815086365
Loss at iteration 620 : 0.017071418464183807
Loss at iteration 630 : 0.01565057598054409
Loss at iteration 640 : 0.013827490620315075
Loss at iteration 650 : 0.017502985894680023
Loss at iteration 660 : 0.010158967226743698
Loss at iteration 670 : 0.015743857249617577
Loss at iteration 680 : 0.011890498921275139
Loss at iteration 690 : 0.012844376266002655
Loss at iteration 700 : 0.019811095669865608
Loss at iteration 710 : 0.014383357018232346
Loss at iteration 720 : 0.009436770342290401
Loss at iteration 730 : 0.010796267539262772
Loss at iteration 740 : 0.01253611221909523
Loss at iteration 750 : 0.013260504230856895
Loss at iteration 760 : 0.018176160752773285
Loss at iteration 770 : 0.013123744167387486
Loss at iteration 780 : 0.00893891416490078
Loss at iteration 790 : 0.01348966360092163
Loss at iteration 800 : 0.015058323740959167
Loss at iteration 810 : 0.014898611232638359
Loss at iteration 820 : 0.014883319847285748
Loss at iteration 830 : 0.01033729873597622
Loss at iteration 840 : 0.015235962346196175
Loss at iteration 850 : 0.00852607749402523
Loss at iteration 860 : 0.015767261385917664
Loss at iteration 870 : 0.010061324574053288
Loss at iteration 880 : 0.013003626838326454
Loss at iteration 890 : 0.013355152681469917
Loss at iteration 900 : 0.02414846047759056
Loss at iteration 910 : 0.014282098971307278
Loss at iteration 920 : 0.0069498056545853615
Loss at iteration 930 : 0.0092691071331501
Loss at iteration 940 : 0.01061943732202053
Loss at iteration 950 : 0.014898601919412613
Loss at iteration 960 : 0.007894565351307392
Loss at iteration 970 : 0.009532544761896133
Loss at iteration 980 : 0.013876320794224739
Loss at iteration 990 : 0.009922272525727749
Loss at iteration 1000 : 0.009392878971993923
Loss at iteration 1010 : 0.01807650364935398
Loss at iteration 1020 : 0.01190953329205513
Loss at iteration 1030 : 0.013229754753410816
Loss at iteration 1040 : 0.010851784609258175
Loss at iteration 1050 : 0.015501504763960838
Loss at iteration 1060 : 0.013788344338536263
Loss at iteration 1070 : 0.01580028049647808
Loss at iteration 1080 : 0.014768583700060844
Loss at iteration 1090 : 0.013448716141283512
Loss at iteration 1100 : 0.013551445677876472
Loss at iteration 1110 : 0.010294698178768158
Loss at iteration 1120 : 0.017660100013017654
Loss at iteration 1130 : 0.010191630572080612
Loss at iteration 1140 : 0.011995112523436546
Loss at iteration 1150 : 0.012361408211290836
Loss at iteration 1160 : 0.008887754753232002
Loss at iteration 1170 : 0.010784395039081573
Loss at iteration 1180 : 0.008747604675590992
Loss at iteration 1190 : 0.014937927946448326
Loss at iteration 1200 : 0.016277100890874863
Loss at iteration 1210 : 0.009714256972074509
The SSIM Value is: 0.7958909789721171
The PSNR Value is: 17.83569399515788
the epoch is: 41
Loss at iteration 10 : 0.01679869368672371
Loss at iteration 20 : 0.008433603681623936
Loss at iteration 30 : 0.014103865250945091
Loss at iteration 40 : 0.014570596627891064
Loss at iteration 50 : 0.01661669835448265
Loss at iteration 60 : 0.012236187234520912
Loss at iteration 70 : 0.01408841647207737
Loss at iteration 80 : 0.015841742977499962
Loss at iteration 90 : 0.010507567785680294
Loss at iteration 100 : 0.012633341364562511
Loss at iteration 110 : 0.009144616313278675
Loss at iteration 120 : 0.011852476745843887
Loss at iteration 130 : 0.010913915932178497
Loss at iteration 140 : 0.012545282952487469
Loss at iteration 150 : 0.00855429656803608
Loss at iteration 160 : 0.011782783083617687
Loss at iteration 170 : 0.008083373308181763
Loss at iteration 180 : 0.012349506840109825
Loss at iteration 190 : 0.013312458992004395
Loss at iteration 200 : 0.006085381843149662
Loss at iteration 210 : 0.015769531950354576
Loss at iteration 220 : 0.008441193960607052
Loss at iteration 230 : 0.008207861334085464
Loss at iteration 240 : 0.010224251076579094
Loss at iteration 250 : 0.01476009376347065
Loss at iteration 260 : 0.010464798659086227
Loss at iteration 270 : 0.011021390557289124
Loss at iteration 280 : 0.020880937576293945
Loss at iteration 290 : 0.02274813875555992
Loss at iteration 300 : 0.016984641551971436
Loss at iteration 310 : 0.007866286672651768
Loss at iteration 320 : 0.011249301955103874
Loss at iteration 330 : 0.013261532410979271
Loss at iteration 340 : 0.00732968095690012
Loss at iteration 350 : 0.012711255811154842
Loss at iteration 360 : 0.011721605435013771
Loss at iteration 370 : 0.00961264781653881
Loss at iteration 380 : 0.01587766222655773
Loss at iteration 390 : 0.014119703322649002
Loss at iteration 400 : 0.026578310877084732
Loss at iteration 410 : 0.01370519120246172
Loss at iteration 420 : 0.013479935936629772
Loss at iteration 430 : 0.008288465440273285
Loss at iteration 440 : 0.011484060436487198
Loss at iteration 450 : 0.011298011057078838
Loss at iteration 460 : 0.013171860948204994
Loss at iteration 470 : 0.011844650842249393
Loss at iteration 480 : 0.01210841815918684
Loss at iteration 490 : 0.01692427322268486
Loss at iteration 500 : 0.012601697817444801
Loss at iteration 510 : 0.01215025782585144
Loss at iteration 520 : 0.019398149102926254
Loss at iteration 530 : 0.01397460512816906
Loss at iteration 540 : 0.010091714560985565
Loss at iteration 550 : 0.009591487236320972
Loss at iteration 560 : 0.010396679863333702
Loss at iteration 570 : 0.014248639345169067
Loss at iteration 580 : 0.009738128632307053
Loss at iteration 590 : 0.01364852674305439
Loss at iteration 600 : 0.012747477740049362
Loss at iteration 610 : 0.009820690378546715
Loss at iteration 620 : 0.014676464721560478
Loss at iteration 630 : 0.029027272015810013
Loss at iteration 640 : 0.017334353178739548
Loss at iteration 650 : 0.017529398202896118
Loss at iteration 660 : 0.013105008751153946
Loss at iteration 670 : 0.022227071225643158
Loss at iteration 680 : 0.010995311662554741
Loss at iteration 690 : 0.011578366160392761
Loss at iteration 700 : 0.011870305985212326
Loss at iteration 710 : 0.010037695057690144
Loss at iteration 720 : 0.020586155354976654
Loss at iteration 730 : 0.013561440631747246
Loss at iteration 740 : 0.012388125993311405
Loss at iteration 750 : 0.01711476966738701
Loss at iteration 760 : 0.010435445234179497
Loss at iteration 770 : 0.015321463346481323
Loss at iteration 780 : 0.009000503458082676
Loss at iteration 790 : 0.014521712437272072
Loss at iteration 800 : 0.010777520947158337
Loss at iteration 810 : 0.012591863051056862
Loss at iteration 820 : 0.0197053924202919
Loss at iteration 830 : 0.011346878483891487
Loss at iteration 840 : 0.008165674284100533
Loss at iteration 850 : 0.012187010608613491
Loss at iteration 860 : 0.01149420253932476
Loss at iteration 870 : 0.015359201468527317
Loss at iteration 880 : 0.011901461519300938
Loss at iteration 890 : 0.011979982256889343
Loss at iteration 900 : 0.01120295561850071
Loss at iteration 910 : 0.009135760366916656
Loss at iteration 920 : 0.010365929454565048
Loss at iteration 930 : 0.01200496219098568
Loss at iteration 940 : 0.0241140928119421
Loss at iteration 950 : 0.010079892352223396
Loss at iteration 960 : 0.013475578278303146
Loss at iteration 970 : 0.006067350041121244
Loss at iteration 980 : 0.013242669403553009
Loss at iteration 990 : 0.01916702277958393
Loss at iteration 1000 : 0.011590903624892235
Loss at iteration 1010 : 0.008119117468595505
Loss at iteration 1020 : 0.017979033291339874
Loss at iteration 1030 : 0.016093898564577103
Loss at iteration 1040 : 0.017551420256495476
Loss at iteration 1050 : 0.011793793179094791
Loss at iteration 1060 : 0.01885632798075676
Loss at iteration 1070 : 0.014872235246002674
Loss at iteration 1080 : 0.012919329106807709
Loss at iteration 1090 : 0.0113957105204463
Loss at iteration 1100 : 0.010989908128976822
Loss at iteration 1110 : 0.01478186808526516
Loss at iteration 1120 : 0.011337164789438248
Loss at iteration 1130 : 0.010891491547226906
Loss at iteration 1140 : 0.00868174061179161
Loss at iteration 1150 : 0.017666231840848923
Loss at iteration 1160 : 0.011928282678127289
Loss at iteration 1170 : 0.01357591338455677
Loss at iteration 1180 : 0.011578690260648727
Loss at iteration 1190 : 0.009255509823560715
Loss at iteration 1200 : 0.016446614637970924
Loss at iteration 1210 : 0.011153925210237503
The SSIM Value is: 0.8081822832425435
The PSNR Value is: 18.62591692606608
the epoch is: 42
Loss at iteration 10 : 0.013207748532295227
Loss at iteration 20 : 0.006258080713450909
Loss at iteration 30 : 0.014384796842932701
Loss at iteration 40 : 0.007594650611281395
Loss at iteration 50 : 0.01309346966445446
Loss at iteration 60 : 0.009429222904145718
Loss at iteration 70 : 0.014451608061790466
Loss at iteration 80 : 0.01153295673429966
Loss at iteration 90 : 0.009521916508674622
Loss at iteration 100 : 0.013262543827295303
Loss at iteration 110 : 0.010596032254397869
Loss at iteration 120 : 0.015554670244455338
Loss at iteration 130 : 0.010574935004115105
Loss at iteration 140 : 0.02240600436925888
Loss at iteration 150 : 0.026499293744564056
Loss at iteration 160 : 0.012523340061306953
Loss at iteration 170 : 0.01242242380976677
Loss at iteration 180 : 0.017878249287605286
Loss at iteration 190 : 0.017321156337857246
Loss at iteration 200 : 0.015287386253476143
Loss at iteration 210 : 0.012750983238220215
Loss at iteration 220 : 0.019815845414996147
Loss at iteration 230 : 0.009621297009289265
Loss at iteration 240 : 0.01505763828754425
Loss at iteration 250 : 0.018202420324087143
Loss at iteration 260 : 0.019707296043634415
Loss at iteration 270 : 0.01382523588836193
Loss at iteration 280 : 0.017145927995443344
Loss at iteration 290 : 0.013994624838232994
Loss at iteration 300 : 0.01062605157494545
Loss at iteration 310 : 0.011684680357575417
Loss at iteration 320 : 0.010211535729467869
Loss at iteration 330 : 0.020773451775312424
Loss at iteration 340 : 0.013102138414978981
Loss at iteration 350 : 0.02350359782576561
Loss at iteration 360 : 0.016276275739073753
Loss at iteration 370 : 0.012151073664426804
Loss at iteration 380 : 0.018670769408345222
Loss at iteration 390 : 0.02849809266626835
Loss at iteration 400 : 0.012849105522036552
Loss at iteration 410 : 0.01451585628092289
Loss at iteration 420 : 0.01357071753591299
Loss at iteration 430 : 0.012750279158353806
Loss at iteration 440 : 0.010774386115372181
Loss at iteration 450 : 0.011190325021743774
Loss at iteration 460 : 0.00993103627115488
Loss at iteration 470 : 0.014893485233187675
Loss at iteration 480 : 0.011160037480294704
Loss at iteration 490 : 0.014227202162146568
Loss at iteration 500 : 0.011528984643518925
Loss at iteration 510 : 0.018180254846811295
Loss at iteration 520 : 0.020471788942813873
Loss at iteration 530 : 0.01555279828608036
Loss at iteration 540 : 0.011364283040165901
Loss at iteration 550 : 0.014334523119032383
Loss at iteration 560 : 0.008237408474087715
Loss at iteration 570 : 0.011983588337898254
Loss at iteration 580 : 0.013905361294746399
Loss at iteration 590 : 0.008787273429334164
Loss at iteration 600 : 0.011270374990999699
Loss at iteration 610 : 0.01832180842757225
Loss at iteration 620 : 0.01093188114464283
Loss at iteration 630 : 0.01443566381931305
Loss at iteration 640 : 0.01056666299700737
Loss at iteration 650 : 0.010667338967323303
Loss at iteration 660 : 0.012134531512856483
Loss at iteration 670 : 0.012363234534859657
Loss at iteration 680 : 0.014732817187905312
Loss at iteration 690 : 0.010860731825232506
Loss at iteration 700 : 0.015203235670924187
Loss at iteration 710 : 0.009142965078353882
Loss at iteration 720 : 0.022526081651449203
Loss at iteration 730 : 0.01031490694731474
Loss at iteration 740 : 0.012975090183317661
Loss at iteration 750 : 0.014079131186008453
Loss at iteration 760 : 0.010541339404881
Loss at iteration 770 : 0.014716822654008865
Loss at iteration 780 : 0.01194644346833229
Loss at iteration 790 : 0.0084037771448493
Loss at iteration 800 : 0.022969510406255722
Loss at iteration 810 : 0.011767137795686722
Loss at iteration 820 : 0.012909071519970894
Loss at iteration 830 : 0.013277238234877586
Loss at iteration 840 : 0.010885156691074371
Loss at iteration 850 : 0.01326519064605236
Loss at iteration 860 : 0.012272408232092857
Loss at iteration 870 : 0.010257667861878872
Loss at iteration 880 : 0.01023347582668066
Loss at iteration 890 : 0.009595884941518307
Loss at iteration 900 : 0.019899599254131317
Loss at iteration 910 : 0.018241597339510918
Loss at iteration 920 : 0.008650020696222782
Loss at iteration 930 : 0.01271938905119896
Loss at iteration 940 : 0.012747553177177906
Loss at iteration 950 : 0.014551781117916107
Loss at iteration 960 : 0.015319088473916054
Loss at iteration 970 : 0.013496662490069866
Loss at iteration 980 : 0.01220548152923584
Loss at iteration 990 : 0.00930703803896904
Loss at iteration 1000 : 0.01842360384762287
Loss at iteration 1010 : 0.015320008620619774
Loss at iteration 1020 : 0.01662200316786766
Loss at iteration 1030 : 0.025909535586833954
Loss at iteration 1040 : 0.020039040595293045
Loss at iteration 1050 : 0.01779334247112274
Loss at iteration 1060 : 0.010464917868375778
Loss at iteration 1070 : 0.016497967764735222
Loss at iteration 1080 : 0.009702781215310097
Loss at iteration 1090 : 0.0186549611389637
Loss at iteration 1100 : 0.01705973967909813
Loss at iteration 1110 : 0.008754999376833439
Loss at iteration 1120 : 0.015697047114372253
Loss at iteration 1130 : 0.02169697731733322
Loss at iteration 1140 : 0.015958163887262344
Loss at iteration 1150 : 0.016930684447288513
Loss at iteration 1160 : 0.017537828534841537
Loss at iteration 1170 : 0.012943251989781857
Loss at iteration 1180 : 0.010234164074063301
Loss at iteration 1190 : 0.0068961563520133495
Loss at iteration 1200 : 0.012799570336937904
Loss at iteration 1210 : 0.017715156078338623
The SSIM Value is: 0.7984968423843384
The PSNR Value is: 18.344919776916505
the epoch is: 43
Loss at iteration 10 : 0.011792916804552078
Loss at iteration 20 : 0.011667534708976746
Loss at iteration 30 : 0.013707713223993778
Loss at iteration 40 : 0.011846447363495827
Loss at iteration 50 : 0.015485540963709354
Loss at iteration 60 : 0.009444533847272396
Loss at iteration 70 : 0.010281698778271675
Loss at iteration 80 : 0.016364354640245438
Loss at iteration 90 : 0.011070040054619312
Loss at iteration 100 : 0.01522465143352747
Loss at iteration 110 : 0.011020124889910221
Loss at iteration 120 : 0.018582377582788467
Loss at iteration 130 : 0.009862497448921204
Loss at iteration 140 : 0.012846777215600014
Loss at iteration 150 : 0.01554284617304802
Loss at iteration 160 : 0.010145599022507668
Loss at iteration 170 : 0.01017153449356556
Loss at iteration 180 : 0.009440712630748749
Loss at iteration 190 : 0.010389714501798153
Loss at iteration 200 : 0.009622689336538315
Loss at iteration 210 : 0.015195176936686039
Loss at iteration 220 : 0.01268628891557455
Loss at iteration 230 : 0.012123829685151577
Loss at iteration 240 : 0.025335121899843216
Loss at iteration 250 : 0.013937416486442089
Loss at iteration 260 : 0.020858481526374817
Loss at iteration 270 : 0.01789972186088562
Loss at iteration 280 : 0.016820237040519714
Loss at iteration 290 : 0.012929331511259079
Loss at iteration 300 : 0.013783499598503113
Loss at iteration 310 : 0.018489211797714233
Loss at iteration 320 : 0.016410313546657562
Loss at iteration 330 : 0.01010245829820633
Loss at iteration 340 : 0.019666897132992744
Loss at iteration 350 : 0.01227778010070324
Loss at iteration 360 : 0.00856630876660347
Loss at iteration 370 : 0.010782884433865547
Loss at iteration 380 : 0.010276899673044682
Loss at iteration 390 : 0.01990511640906334
Loss at iteration 400 : 0.00902225635945797
Loss at iteration 410 : 0.021345222368836403
Loss at iteration 420 : 0.012003585696220398
Loss at iteration 430 : 0.018197601661086082
Loss at iteration 440 : 0.011720916256308556
Loss at iteration 450 : 0.009147819131612778
Loss at iteration 460 : 0.01765184849500656
Loss at iteration 470 : 0.008619467727839947
Loss at iteration 480 : 0.013173452578485012
Loss at iteration 490 : 0.008783498778939247
Loss at iteration 500 : 0.012897256761789322
Loss at iteration 510 : 0.0136154405772686
Loss at iteration 520 : 0.010388396680355072
Loss at iteration 530 : 0.01103812176734209
Loss at iteration 540 : 0.011346239596605301
Loss at iteration 550 : 0.013556087389588356
Loss at iteration 560 : 0.012337670661509037
Loss at iteration 570 : 0.01472650095820427
Loss at iteration 580 : 0.00889612641185522
Loss at iteration 590 : 0.012506137602031231
Loss at iteration 600 : 0.011087819933891296
Loss at iteration 610 : 0.01730370707809925
Loss at iteration 620 : 0.011335240676999092
Loss at iteration 630 : 0.013095594011247158
Loss at iteration 640 : 0.00968917366117239
Loss at iteration 650 : 0.01075551938265562
Loss at iteration 660 : 0.015089559368789196
Loss at iteration 670 : 0.009475662373006344
Loss at iteration 680 : 0.010563721880316734
Loss at iteration 690 : 0.0134064806625247
Loss at iteration 700 : 0.009761892259120941
Loss at iteration 710 : 0.012244928628206253
Loss at iteration 720 : 0.014417806640267372
Loss at iteration 730 : 0.013977603055536747
Loss at iteration 740 : 0.01555726584047079
Loss at iteration 750 : 0.008694317191839218
Loss at iteration 760 : 0.010061239823698997
Loss at iteration 770 : 0.016347408294677734
Loss at iteration 780 : 0.010809575207531452
Loss at iteration 790 : 0.011213133111596107
Loss at iteration 800 : 0.013180805370211601
Loss at iteration 810 : 0.013841204345226288
Loss at iteration 820 : 0.01718389242887497
Loss at iteration 830 : 0.010927839204668999
Loss at iteration 840 : 0.013417095877230167
Loss at iteration 850 : 0.016701964661478996
Loss at iteration 860 : 0.013222981244325638
Loss at iteration 870 : 0.019027220085263252
Loss at iteration 880 : 0.013051396235823631
Loss at iteration 890 : 0.010325660929083824
Loss at iteration 900 : 0.012708062306046486
Loss at iteration 910 : 0.010893745347857475
Loss at iteration 920 : 0.013220426626503468
Loss at iteration 930 : 0.017233174294233322
Loss at iteration 940 : 0.00942454393953085
Loss at iteration 950 : 0.015744496136903763
Loss at iteration 960 : 0.013706380501389503
Loss at iteration 970 : 0.017787214368581772
Loss at iteration 980 : 0.016330016776919365
Loss at iteration 990 : 0.009940914809703827
Loss at iteration 1000 : 0.01067289151251316
Loss at iteration 1010 : 0.021087583154439926
Loss at iteration 1020 : 0.01757599040865898
Loss at iteration 1030 : 0.027474641799926758
Loss at iteration 1040 : 0.008959236554801464
Loss at iteration 1050 : 0.00906501803547144
Loss at iteration 1060 : 0.015546431764960289
Loss at iteration 1070 : 0.011547761969268322
Loss at iteration 1080 : 0.012287123128771782
Loss at iteration 1090 : 0.01847456768155098
Loss at iteration 1100 : 0.01089781429618597
Loss at iteration 1110 : 0.014532828703522682
Loss at iteration 1120 : 0.013938245363533497
Loss at iteration 1130 : 0.01740437000989914
Loss at iteration 1140 : 0.018167154863476753
Loss at iteration 1150 : 0.014044824987649918
Loss at iteration 1160 : 0.019812697544693947
Loss at iteration 1170 : 0.015660002827644348
Loss at iteration 1180 : 0.007785990834236145
Loss at iteration 1190 : 0.007224360480904579
Loss at iteration 1200 : 0.014977355487644672
Loss at iteration 1210 : 0.008308345451951027
The SSIM Value is: 0.7870117783546448
The PSNR Value is: 17.739573796590168
the epoch is: 44
Loss at iteration 10 : 0.008156390860676765
Loss at iteration 20 : 0.006771553307771683
Loss at iteration 30 : 0.01316050998866558
Loss at iteration 40 : 0.011719660833477974
Loss at iteration 50 : 0.012309091165661812
Loss at iteration 60 : 0.012063426896929741
Loss at iteration 70 : 0.010774277150630951
Loss at iteration 80 : 0.014735342934727669
Loss at iteration 90 : 0.010132936760783195
Loss at iteration 100 : 0.013592520728707314
Loss at iteration 110 : 0.012797447852790356
Loss at iteration 120 : 0.015105974860489368
Loss at iteration 130 : 0.014250705018639565
Loss at iteration 140 : 0.018703868612647057
Loss at iteration 150 : 0.014365551061928272
Loss at iteration 160 : 0.010638282634317875
Loss at iteration 170 : 0.010935639962553978
Loss at iteration 180 : 0.011632815934717655
Loss at iteration 190 : 0.013258188962936401
Loss at iteration 200 : 0.013295048847794533
Loss at iteration 210 : 0.010515297763049603
Loss at iteration 220 : 0.004593988880515099
Loss at iteration 230 : 0.02975221537053585
Loss at iteration 240 : 0.01212413888424635
Loss at iteration 250 : 0.013929005712270737
Loss at iteration 260 : 0.01623370125889778
Loss at iteration 270 : 0.016642767935991287
Loss at iteration 280 : 0.01881246455013752
Loss at iteration 290 : 0.0185550469905138
Loss at iteration 300 : 0.014083374291658401
Loss at iteration 310 : 0.009580856189131737
Loss at iteration 320 : 0.01636645942926407
Loss at iteration 330 : 0.017064912244677544
Loss at iteration 340 : 0.015066558495163918
Loss at iteration 350 : 0.015062108635902405
Loss at iteration 360 : 0.011223338544368744
Loss at iteration 370 : 0.017063774168491364
Loss at iteration 380 : 0.008331076242029667
Loss at iteration 390 : 0.014858637936413288
Loss at iteration 400 : 0.01459513045847416
Loss at iteration 410 : 0.014482441358268261
Loss at iteration 420 : 0.015537397935986519
Loss at iteration 430 : 0.016246892511844635
Loss at iteration 440 : 0.012091458775103092
Loss at iteration 450 : 0.019501028582453728
Loss at iteration 460 : 0.017654141411185265
Loss at iteration 470 : 0.014218809083104134
Loss at iteration 480 : 0.009584788233041763
Loss at iteration 490 : 0.01571086049079895
Loss at iteration 500 : 0.008378283120691776
Loss at iteration 510 : 0.010680301114916801
Loss at iteration 520 : 0.01941952109336853
Loss at iteration 530 : 0.016334660351276398
Loss at iteration 540 : 0.00950445793569088
Loss at iteration 550 : 0.015507709234952927
Loss at iteration 560 : 0.012485274113714695
Loss at iteration 570 : 0.015568484552204609
Loss at iteration 580 : 0.01577869988977909
Loss at iteration 590 : 0.018411053344607353
Loss at iteration 600 : 0.016345972195267677
Loss at iteration 610 : 0.01122999656945467
Loss at iteration 620 : 0.009911750443279743
Loss at iteration 630 : 0.017041530460119247
Loss at iteration 640 : 0.011002613231539726
Loss at iteration 650 : 0.010368186980485916
Loss at iteration 660 : 0.03323005884885788
Loss at iteration 670 : 0.01568111963570118
Loss at iteration 680 : 0.015498279593884945
Loss at iteration 690 : 0.013221202418208122
Loss at iteration 700 : 0.015421047806739807
Loss at iteration 710 : 0.010619034990668297
Loss at iteration 720 : 0.011591033078730106
Loss at iteration 730 : 0.013378836214542389
Loss at iteration 740 : 0.009668951854109764
Loss at iteration 750 : 0.015656668692827225
Loss at iteration 760 : 0.023166412487626076
Loss at iteration 770 : 0.01616387628018856
Loss at iteration 780 : 0.012071823701262474
Loss at iteration 790 : 0.00984165258705616
Loss at iteration 800 : 0.013587861321866512
Loss at iteration 810 : 0.012423868291079998
Loss at iteration 820 : 0.010077612474560738
Loss at iteration 830 : 0.009093666449189186
Loss at iteration 840 : 0.009842779487371445
Loss at iteration 850 : 0.008028690703213215
Loss at iteration 860 : 0.013508043251931667
Loss at iteration 870 : 0.014072835445404053
Loss at iteration 880 : 0.009235324338078499
Loss at iteration 890 : 0.02050704136490822
Loss at iteration 900 : 0.024780383333563805
Loss at iteration 910 : 0.013642242178320885
Loss at iteration 920 : 0.014727795496582985
Loss at iteration 930 : 0.004391422029584646
Loss at iteration 940 : 0.009361558593809605
Loss at iteration 950 : 0.01645519770681858
Loss at iteration 960 : 0.017335254698991776
Loss at iteration 970 : 0.015267185866832733
Loss at iteration 980 : 0.012144945561885834
Loss at iteration 990 : 0.012164540588855743
Loss at iteration 1000 : 0.010322247631847858
Loss at iteration 1010 : 0.011784338392317295
Loss at iteration 1020 : 0.013809573836624622
Loss at iteration 1030 : 0.015901099890470505
Loss at iteration 1040 : 0.006950950250029564
Loss at iteration 1050 : 0.010215675458312035
Loss at iteration 1060 : 0.007028917782008648
Loss at iteration 1070 : 0.01138177141547203
Loss at iteration 1080 : 0.015376291237771511
Loss at iteration 1090 : 0.013722761534154415
Loss at iteration 1100 : 0.015317591838538647
Loss at iteration 1110 : 0.01331963948905468
Loss at iteration 1120 : 0.011622130870819092
Loss at iteration 1130 : 0.01433054730296135
Loss at iteration 1140 : 0.00982383731752634
Loss at iteration 1150 : 0.013064620085060596
Loss at iteration 1160 : 0.008535556495189667
Loss at iteration 1170 : 0.013308766297996044
Loss at iteration 1180 : 0.014675443060696125
Loss at iteration 1190 : 0.014690348878502846
Loss at iteration 1200 : 0.009603018872439861
Loss at iteration 1210 : 0.01527402177453041
The SSIM Value is: 0.8134319067001343
The PSNR Value is: 18.937504959106445
the highest SSIM value is: 18.937504959106445
the epoch is: 45
Loss at iteration 10 : 0.013568954542279243
Loss at iteration 20 : 0.012010554783046246
Loss at iteration 30 : 0.00734749436378479
Loss at iteration 40 : 0.019697699695825577
Loss at iteration 50 : 0.013520939275622368
Loss at iteration 60 : 0.01583823189139366
Loss at iteration 70 : 0.007858620956540108
Loss at iteration 80 : 0.008073927834630013
Loss at iteration 90 : 0.014931177720427513
Loss at iteration 100 : 0.013955739326775074
Loss at iteration 110 : 0.00907530914992094
Loss at iteration 120 : 0.00786374881863594
Loss at iteration 130 : 0.013982406817376614
Loss at iteration 140 : 0.015425283461809158
Loss at iteration 150 : 0.012776294723153114
Loss at iteration 160 : 0.013631859794259071
Loss at iteration 170 : 0.013171480037271976
Loss at iteration 180 : 0.01634000428020954
Loss at iteration 190 : 0.011405760422348976
Loss at iteration 200 : 0.011914643459022045
Loss at iteration 210 : 0.014957261271774769
Loss at iteration 220 : 0.013626744970679283
Loss at iteration 230 : 0.013851786963641644
Loss at iteration 240 : 0.008834837935864925
Loss at iteration 250 : 0.00991029106080532
Loss at iteration 260 : 0.012647048570215702
Loss at iteration 270 : 0.02250845730304718
Loss at iteration 280 : 0.0073130205273628235
Loss at iteration 290 : 0.013443578034639359
Loss at iteration 300 : 0.015527383424341679
Loss at iteration 310 : 0.01687733456492424
Loss at iteration 320 : 0.01083818543702364
Loss at iteration 330 : 0.006128593347966671
Loss at iteration 340 : 0.014836949296295643
Loss at iteration 350 : 0.014458955265581608
Loss at iteration 360 : 0.007842568680644035
Loss at iteration 370 : 0.006975238211452961
Loss at iteration 380 : 0.013473416678607464
Loss at iteration 390 : 0.011014126241207123
Loss at iteration 400 : 0.015200536698102951
Loss at iteration 410 : 0.020997118204832077
Loss at iteration 420 : 0.02478661760687828
Loss at iteration 430 : 0.01736111380159855
Loss at iteration 440 : 0.0147491954267025
Loss at iteration 450 : 0.011297540739178658
Loss at iteration 460 : 0.011864687316119671
Loss at iteration 470 : 0.011088704690337181
Loss at iteration 480 : 0.012700937688350677
Loss at iteration 490 : 0.012412842363119125
Loss at iteration 500 : 0.01976606249809265
Loss at iteration 510 : 0.007743449416011572
Loss at iteration 520 : 0.014616438187658787
Loss at iteration 530 : 0.013785664923489094
Loss at iteration 540 : 0.010066123679280281
Loss at iteration 550 : 0.009925028309226036
Loss at iteration 560 : 0.01050376147031784
Loss at iteration 570 : 0.006699707359075546
Loss at iteration 580 : 0.016634484753012657
Loss at iteration 590 : 0.010526292026042938
Loss at iteration 600 : 0.010479177348315716
Loss at iteration 610 : 0.016047276556491852
Loss at iteration 620 : 0.021627195179462433
Loss at iteration 630 : 0.020514391362667084
Loss at iteration 640 : 0.011756557039916515
Loss at iteration 650 : 0.013196653686463833
Loss at iteration 660 : 0.011027660220861435
Loss at iteration 670 : 0.011883840896189213
Loss at iteration 680 : 0.01460784487426281
Loss at iteration 690 : 0.010865825228393078
Loss at iteration 700 : 0.013001689687371254
Loss at iteration 710 : 0.014495952054858208
Loss at iteration 720 : 0.0158503670245409
Loss at iteration 730 : 0.008232575841248035
Loss at iteration 740 : 0.012422401458024979
Loss at iteration 750 : 0.012493731454014778
Loss at iteration 760 : 0.01448057871311903
Loss at iteration 770 : 0.013377416878938675
Loss at iteration 780 : 0.012244670651853085
Loss at iteration 790 : 0.013184623792767525
Loss at iteration 800 : 0.006387634202837944
Loss at iteration 810 : 0.010074963793158531
Loss at iteration 820 : 0.016344117000699043
Loss at iteration 830 : 0.015777362510561943
Loss at iteration 840 : 0.009091023355722427
Loss at iteration 850 : 0.00918333139270544
Loss at iteration 860 : 0.019108254462480545
Loss at iteration 870 : 0.011255540885031223
Loss at iteration 880 : 0.007272087968885899
Loss at iteration 890 : 0.01243398617953062
Loss at iteration 900 : 0.012223077937960625
Loss at iteration 910 : 0.007718830369412899
Loss at iteration 920 : 0.016627030447125435
Loss at iteration 930 : 0.006590827368199825
Loss at iteration 940 : 0.013876287266612053
Loss at iteration 950 : 0.018431276082992554
Loss at iteration 960 : 0.014472045004367828
Loss at iteration 970 : 0.016504663974046707
Loss at iteration 980 : 0.013112448155879974
Loss at iteration 990 : 0.009119081310927868
Loss at iteration 1000 : 0.011525009758770466
Loss at iteration 1010 : 0.011534478515386581
Loss at iteration 1020 : 0.0172695592045784
Loss at iteration 1030 : 0.011224048212170601
Loss at iteration 1040 : 0.014341898262500763
Loss at iteration 1050 : 0.015425587072968483
Loss at iteration 1060 : 0.01596877910196781
Loss at iteration 1070 : 0.012353572994470596
Loss at iteration 1080 : 0.01518130861222744
Loss at iteration 1090 : 0.015890639275312424
Loss at iteration 1100 : 0.011320356279611588
Loss at iteration 1110 : 0.020719869062304497
Loss at iteration 1120 : 0.009842794388532639
Loss at iteration 1130 : 0.011988667771220207
Loss at iteration 1140 : 0.01289418339729309
Loss at iteration 1150 : 0.017918117344379425
Loss at iteration 1160 : 0.012128510512411594
Loss at iteration 1170 : 0.012438923120498657
Loss at iteration 1180 : 0.013357575051486492
Loss at iteration 1190 : 0.010817689821124077
Loss at iteration 1200 : 0.009341382421553135
Loss at iteration 1210 : 0.009184315800666809
The SSIM Value is: 0.8130866885185242
The PSNR Value is: 19.04349282582601
the highest SSIM value is: 19.04349282582601
the epoch is: 46
Loss at iteration 10 : 0.00930313766002655
Loss at iteration 20 : 0.012606438249349594
Loss at iteration 30 : 0.012417912483215332
Loss at iteration 40 : 0.010054446756839752
Loss at iteration 50 : 0.015537640079855919
Loss at iteration 60 : 0.017051223665475845
Loss at iteration 70 : 0.011116929352283478
Loss at iteration 80 : 0.010920988395810127
Loss at iteration 90 : 0.011153746396303177
Loss at iteration 100 : 0.01471266895532608
Loss at iteration 110 : 0.010783666744828224
Loss at iteration 120 : 0.010714173316955566
Loss at iteration 130 : 0.017311610281467438
Loss at iteration 140 : 0.011100013740360737
Loss at iteration 150 : 0.011323124170303345
Loss at iteration 160 : 0.01879076659679413
Loss at iteration 170 : 0.016745682805776596
Loss at iteration 180 : 0.01716724783182144
Loss at iteration 190 : 0.01083218865096569
Loss at iteration 200 : 0.01575654372572899
Loss at iteration 210 : 0.01817293092608452
Loss at iteration 220 : 0.014661469496786594
Loss at iteration 230 : 0.018429674208164215
Loss at iteration 240 : 0.012141445651650429
Loss at iteration 250 : 0.008245616219937801
Loss at iteration 260 : 0.01636861450970173
Loss at iteration 270 : 0.011377643793821335
Loss at iteration 280 : 0.014432691037654877
Loss at iteration 290 : 0.01584438607096672
Loss at iteration 300 : 0.011615294963121414
Loss at iteration 310 : 0.01322946697473526
Loss at iteration 320 : 0.01644940674304962
Loss at iteration 330 : 0.007485712878406048
Loss at iteration 340 : 0.007235162425786257
Loss at iteration 350 : 0.015279673039913177
Loss at iteration 360 : 0.019609415903687477
Loss at iteration 370 : 0.012656756676733494
Loss at iteration 380 : 0.013244375586509705
Loss at iteration 390 : 0.008244313299655914
Loss at iteration 400 : 0.013736074790358543
Loss at iteration 410 : 0.00958137959241867
Loss at iteration 420 : 0.011704519391059875
Loss at iteration 430 : 0.011332936584949493
Loss at iteration 440 : 0.011337575502693653
Loss at iteration 450 : 0.009200867265462875
Loss at iteration 460 : 0.01763206161558628
Loss at iteration 470 : 0.014641698449850082
Loss at iteration 480 : 0.007751080673187971
Loss at iteration 490 : 0.008060907945036888
Loss at iteration 500 : 0.013826511800289154
Loss at iteration 510 : 0.00846860371530056
Loss at iteration 520 : 0.02074487879872322
Loss at iteration 530 : 0.012193268164992332
Loss at iteration 540 : 0.010129321366548538
Loss at iteration 550 : 0.01565634272992611
Loss at iteration 560 : 0.010972453281283379
Loss at iteration 570 : 0.015054017305374146
Loss at iteration 580 : 0.016289595514535904
Loss at iteration 590 : 0.013544810004532337
Loss at iteration 600 : 0.015757832676172256
Loss at iteration 610 : 0.012936200015246868
Loss at iteration 620 : 0.01873881369829178
Loss at iteration 630 : 0.011335095390677452
Loss at iteration 640 : 0.015832651406526566
Loss at iteration 650 : 0.012319148518145084
Loss at iteration 660 : 0.012662040069699287
Loss at iteration 670 : 0.019040890038013458
Loss at iteration 680 : 0.014618763700127602
Loss at iteration 690 : 0.0117760319262743
Loss at iteration 700 : 0.012876380234956741
Loss at iteration 710 : 0.007180236745625734
Loss at iteration 720 : 0.01580232009291649
Loss at iteration 730 : 0.017413999885320663
Loss at iteration 740 : 0.012493583373725414
Loss at iteration 750 : 0.01729227975010872
Loss at iteration 760 : 0.023310992866754532
Loss at iteration 770 : 0.011733404360711575
Loss at iteration 780 : 0.010041894391179085
Loss at iteration 790 : 0.010370293632149696
Loss at iteration 800 : 0.008950416930019855
Loss at iteration 810 : 0.014095321297645569
Loss at iteration 820 : 0.012803340330719948
Loss at iteration 830 : 0.01701759546995163
Loss at iteration 840 : 0.010940754786133766
Loss at iteration 850 : 0.013797042891383171
Loss at iteration 860 : 0.008152861148118973
Loss at iteration 870 : 0.01890159770846367
Loss at iteration 880 : 0.018979616463184357
Loss at iteration 890 : 0.012087758630514145
Loss at iteration 900 : 0.010678495280444622
Loss at iteration 910 : 0.01298290491104126
Loss at iteration 920 : 0.010389563627541065
Loss at iteration 930 : 0.01625438965857029
Loss at iteration 940 : 0.00875900685787201
Loss at iteration 950 : 0.019306980073451996
Loss at iteration 960 : 0.016354361549019814
Loss at iteration 970 : 0.012192705646157265
Loss at iteration 980 : 0.010286500677466393
Loss at iteration 990 : 0.012304089963436127
Loss at iteration 1000 : 0.015405705198645592
Loss at iteration 1010 : 0.01181070413440466
Loss at iteration 1020 : 0.008278195746243
Loss at iteration 1030 : 0.007871893234550953
Loss at iteration 1040 : 0.013475400395691395
Loss at iteration 1050 : 0.011795608326792717
Loss at iteration 1060 : 0.012615017592906952
Loss at iteration 1070 : 0.011418388225138187
Loss at iteration 1080 : 0.014501279219985008
Loss at iteration 1090 : 0.01130148209631443
Loss at iteration 1100 : 0.014166612178087234
Loss at iteration 1110 : 0.008935884572565556
Loss at iteration 1120 : 0.015032153576612473
Loss at iteration 1130 : 0.015048384666442871
Loss at iteration 1140 : 0.009948446415364742
Loss at iteration 1150 : 0.009505919180810452
Loss at iteration 1160 : 0.013312095776200294
Loss at iteration 1170 : 0.012304656207561493
Loss at iteration 1180 : 0.011349614709615707
Loss at iteration 1190 : 0.018012236803770065
Loss at iteration 1200 : 0.017189349979162216
Loss at iteration 1210 : 0.00862801168113947
The SSIM Value is: 0.8061685005823771
The PSNR Value is: 18.766565958658855
the epoch is: 47
Loss at iteration 10 : 0.017686212435364723
Loss at iteration 20 : 0.013361625373363495
Loss at iteration 30 : 0.01153484731912613
Loss at iteration 40 : 0.006556565873324871
Loss at iteration 50 : 0.014559661038219929
Loss at iteration 60 : 0.017496883869171143
Loss at iteration 70 : 0.010558128356933594
Loss at iteration 80 : 0.013996100053191185
Loss at iteration 90 : 0.013851250521838665
Loss at iteration 100 : 0.01283204648643732
Loss at iteration 110 : 0.016904717311263084
Loss at iteration 120 : 0.010935370810329914
Loss at iteration 130 : 0.012620877474546432
Loss at iteration 140 : 0.011023812927305698
Loss at iteration 150 : 0.009843923151493073
Loss at iteration 160 : 0.022347355261445045
Loss at iteration 170 : 0.012612943537533283
Loss at iteration 180 : 0.017032023519277573
Loss at iteration 190 : 0.009445651434361935
Loss at iteration 200 : 0.01013180986046791
Loss at iteration 210 : 0.008321930654346943
Loss at iteration 220 : 0.01653193309903145
Loss at iteration 230 : 0.01045374758541584
Loss at iteration 240 : 0.004613905213773251
Loss at iteration 250 : 0.014328423887491226
Loss at iteration 260 : 0.015614074654877186
Loss at iteration 270 : 0.013760901987552643
Loss at iteration 280 : 0.01041162945330143
Loss at iteration 290 : 0.012083802372217178
Loss at iteration 300 : 0.019403517246246338
Loss at iteration 310 : 0.021488351747393608
Loss at iteration 320 : 0.014006748795509338
Loss at iteration 330 : 0.016739781945943832
Loss at iteration 340 : 0.011672133579850197
Loss at iteration 350 : 0.00936625525355339
Loss at iteration 360 : 0.009998716413974762
Loss at iteration 370 : 0.01493404246866703
Loss at iteration 380 : 0.011228810995817184
Loss at iteration 390 : 0.0063158851116895676
Loss at iteration 400 : 0.012434608303010464
Loss at iteration 410 : 0.012055291794240475
Loss at iteration 420 : 0.01741834171116352
Loss at iteration 430 : 0.015438690781593323
Loss at iteration 440 : 0.014301958493888378
Loss at iteration 450 : 0.009422391653060913
Loss at iteration 460 : 0.01555204950273037
Loss at iteration 470 : 0.017279859632253647
Loss at iteration 480 : 0.011094365268945694
Loss at iteration 490 : 0.010309439152479172
Loss at iteration 500 : 0.010104991495609283
Loss at iteration 510 : 0.011506756767630577
Loss at iteration 520 : 0.009862164035439491
Loss at iteration 530 : 0.013178549706935883
Loss at iteration 540 : 0.015993043780326843
Loss at iteration 550 : 0.011651420965790749
Loss at iteration 560 : 0.015257478691637516
Loss at iteration 570 : 0.016779059544205666
Loss at iteration 580 : 0.008028330281376839
Loss at iteration 590 : 0.011617991141974926
Loss at iteration 600 : 0.01304314099252224
Loss at iteration 610 : 0.014645677991211414
Loss at iteration 620 : 0.010923437774181366
Loss at iteration 630 : 0.010234395042061806
Loss at iteration 640 : 0.010806512087583542
Loss at iteration 650 : 0.017650239169597626
Loss at iteration 660 : 0.024062078446149826
Loss at iteration 670 : 0.016297489404678345
Loss at iteration 680 : 0.01471695490181446
Loss at iteration 690 : 0.01053093932569027
Loss at iteration 700 : 0.012650187127292156
Loss at iteration 710 : 0.02052575722336769
Loss at iteration 720 : 0.016272515058517456
Loss at iteration 730 : 0.012918183580040932
Loss at iteration 740 : 0.008109468035399914
Loss at iteration 750 : 0.01626187562942505
Loss at iteration 760 : 0.010447487235069275
Loss at iteration 770 : 0.011823172681033611
Loss at iteration 780 : 0.01252971775829792
Loss at iteration 790 : 0.01318892277777195
Loss at iteration 800 : 0.010909638367593288
Loss at iteration 810 : 0.013183379545807838
Loss at iteration 820 : 0.01112491823732853
Loss at iteration 830 : 0.009469008073210716
Loss at iteration 840 : 0.013615629635751247
Loss at iteration 850 : 0.010590242221951485
Loss at iteration 860 : 0.012542800046503544
Loss at iteration 870 : 0.009066559374332428
Loss at iteration 880 : 0.01106968056410551
Loss at iteration 890 : 0.010200174525380135
Loss at iteration 900 : 0.008071286603808403
Loss at iteration 910 : 0.01823718473315239
Loss at iteration 920 : 0.01174962054938078
Loss at iteration 930 : 0.012495161965489388
Loss at iteration 940 : 0.014307521283626556
Loss at iteration 950 : 0.015502920374274254
Loss at iteration 960 : 0.013511484488844872
Loss at iteration 970 : 0.011116981506347656
Loss at iteration 980 : 0.021703345701098442
Loss at iteration 990 : 0.01605088636279106
Loss at iteration 1000 : 0.02248053252696991
Loss at iteration 1010 : 0.016169730573892593
Loss at iteration 1020 : 0.015040128491818905
Loss at iteration 1030 : 0.01776387169957161
Loss at iteration 1040 : 0.015925366431474686
Loss at iteration 1050 : 0.013129094615578651
Loss at iteration 1060 : 0.013740231283009052
Loss at iteration 1070 : 0.008098019286990166
Loss at iteration 1080 : 0.014353489503264427
Loss at iteration 1090 : 0.015658460557460785
Loss at iteration 1100 : 0.007208186201751232
Loss at iteration 1110 : 0.01157714705914259
Loss at iteration 1120 : 0.018730085343122482
Loss at iteration 1130 : 0.013195475563406944
Loss at iteration 1140 : 0.012118034064769745
Loss at iteration 1150 : 0.010721172206103802
Loss at iteration 1160 : 0.013276882469654083
Loss at iteration 1170 : 0.019731605425477028
Loss at iteration 1180 : 0.012962047010660172
Loss at iteration 1190 : 0.01741774007678032
Loss at iteration 1200 : 0.023571724072098732
Loss at iteration 1210 : 0.0077733187936246395
The SSIM Value is: 0.8072349190711975
The PSNR Value is: 18.554515393575034
the epoch is: 48
Loss at iteration 10 : 0.007471354678273201
Loss at iteration 20 : 0.013847078196704388
Loss at iteration 30 : 0.015250279568135738
Loss at iteration 40 : 0.013104185461997986
Loss at iteration 50 : 0.01202431507408619
Loss at iteration 60 : 0.010504946112632751
Loss at iteration 70 : 0.013317883014678955
Loss at iteration 80 : 0.014394359663128853
Loss at iteration 90 : 0.010333314538002014
Loss at iteration 100 : 0.01320975087583065
Loss at iteration 110 : 0.00875324197113514
Loss at iteration 120 : 0.014920555986464024
Loss at iteration 130 : 0.013229528442025185
Loss at iteration 140 : 0.011053407564759254
Loss at iteration 150 : 0.011586392298340797
Loss at iteration 160 : 0.012180380523204803
Loss at iteration 170 : 0.013102834112942219
Loss at iteration 180 : 0.008151605725288391
Loss at iteration 190 : 0.0108112758025527
Loss at iteration 200 : 0.0110230203717947
Loss at iteration 210 : 0.011918999254703522
Loss at iteration 220 : 0.01603991724550724
Loss at iteration 230 : 0.011650258675217628
Loss at iteration 240 : 0.011283542960882187
Loss at iteration 250 : 0.013968190178275108
Loss at iteration 260 : 0.0326463058590889
Loss at iteration 270 : 0.00908136647194624
Loss at iteration 280 : 0.01037247758358717
Loss at iteration 290 : 0.01645699515938759
Loss at iteration 300 : 0.012824507430195808
Loss at iteration 310 : 0.010386386886239052
Loss at iteration 320 : 0.012556873261928558
Loss at iteration 330 : 0.010333117097616196
Loss at iteration 340 : 0.01595107652246952
Loss at iteration 350 : 0.011294635012745857
Loss at iteration 360 : 0.004972916562110186
Loss at iteration 370 : 0.024042334407567978
Loss at iteration 380 : 0.008501322008669376
Loss at iteration 390 : 0.0069814566522836685
Loss at iteration 400 : 0.00970381498336792
Loss at iteration 410 : 0.011933375149965286
Loss at iteration 420 : 0.011108029633760452
Loss at iteration 430 : 0.013439198955893517
Loss at iteration 440 : 0.014324091374874115
Loss at iteration 450 : 0.016048209741711617
Loss at iteration 460 : 0.01970263198018074
Loss at iteration 470 : 0.010467993095517159
Loss at iteration 480 : 0.01332581415772438
Loss at iteration 490 : 0.017744094133377075
Loss at iteration 500 : 0.014537332579493523
Loss at iteration 510 : 0.016594205051660538
Loss at iteration 520 : 0.009026252664625645
Loss at iteration 530 : 0.012210888788104057
Loss at iteration 540 : 0.012425660155713558
Loss at iteration 550 : 0.01634281314909458
Loss at iteration 560 : 0.009960278868675232
Loss at iteration 570 : 0.01966308429837227
Loss at iteration 580 : 0.01568407192826271
Loss at iteration 590 : 0.017838656902313232
Loss at iteration 600 : 0.006426246836781502
Loss at iteration 610 : 0.02452744171023369
Loss at iteration 620 : 0.016423121094703674
Loss at iteration 630 : 0.011692440137267113
Loss at iteration 640 : 0.011377052403986454
Loss at iteration 650 : 0.01500764861702919
Loss at iteration 660 : 0.011021352373063564
Loss at iteration 670 : 0.016346028074622154
Loss at iteration 680 : 0.016048448160290718
Loss at iteration 690 : 0.014812760055065155
Loss at iteration 700 : 0.014012178406119347
Loss at iteration 710 : 0.011641820892691612
Loss at iteration 720 : 0.011359530501067638
Loss at iteration 730 : 0.013731702230870724
Loss at iteration 740 : 0.013189494609832764
Loss at iteration 750 : 0.01629597321152687
Loss at iteration 760 : 0.010450679808855057
Loss at iteration 770 : 0.01157983299344778
Loss at iteration 780 : 0.012578489258885384
Loss at iteration 790 : 0.016395265236496925
Loss at iteration 800 : 0.007292483001947403
Loss at iteration 810 : 0.012962313368916512
Loss at iteration 820 : 0.016824301332235336
Loss at iteration 830 : 0.01153535582125187
Loss at iteration 840 : 0.014214041642844677
Loss at iteration 850 : 0.010629222728312016
Loss at iteration 860 : 0.007415870204567909
Loss at iteration 870 : 0.009965217672288418
Loss at iteration 880 : 0.008531305007636547
Loss at iteration 890 : 0.015147192403674126
Loss at iteration 900 : 0.010690858587622643
Loss at iteration 910 : 0.013673707842826843
Loss at iteration 920 : 0.01260586827993393
Loss at iteration 930 : 0.009125977754592896
Loss at iteration 940 : 0.011669223196804523
Loss at iteration 950 : 0.01458401046693325
Loss at iteration 960 : 0.007768220733851194
Loss at iteration 970 : 0.017336495220661163
Loss at iteration 980 : 0.01675984635949135
Loss at iteration 990 : 0.016321994364261627
Loss at iteration 1000 : 0.013093322515487671
Loss at iteration 1010 : 0.009952779859304428
Loss at iteration 1020 : 0.013068282045423985
Loss at iteration 1030 : 0.019818583503365517
Loss at iteration 1040 : 0.008561922237277031
Loss at iteration 1050 : 0.00937076285481453
Loss at iteration 1060 : 0.009735282510519028
Loss at iteration 1070 : 0.009178342297673225
Loss at iteration 1080 : 0.033348023891448975
Loss at iteration 1090 : 0.009540624916553497
Loss at iteration 1100 : 0.009740588255226612
Loss at iteration 1110 : 0.0072602988220751286
Loss at iteration 1120 : 0.02112087979912758
Loss at iteration 1130 : 0.00866898987442255
Loss at iteration 1140 : 0.009864412248134613
Loss at iteration 1150 : 0.01592973805963993
Loss at iteration 1160 : 0.013270224444568157
Loss at iteration 1170 : 0.011394528672099113
Loss at iteration 1180 : 0.009512161836028099
Loss at iteration 1190 : 0.007394733838737011
Loss at iteration 1200 : 0.008886383846402168
Loss at iteration 1210 : 0.010339449159801006
The SSIM Value is: 0.8075566371281941
The PSNR Value is: 18.92652244567871
the epoch is: 49
Loss at iteration 10 : 0.013886693865060806
Loss at iteration 20 : 0.011798222549259663
Loss at iteration 30 : 0.009287361055612564
Loss at iteration 40 : 0.010676056146621704
Loss at iteration 50 : 0.014606005512177944
Loss at iteration 60 : 0.01375514641404152
Loss at iteration 70 : 0.012314815074205399
Loss at iteration 80 : 0.013025481253862381
Loss at iteration 90 : 0.012076061218976974
Loss at iteration 100 : 0.012875707820057869
Loss at iteration 110 : 0.010536326095461845
Loss at iteration 120 : 0.00829104334115982
Loss at iteration 130 : 0.012104988098144531
Loss at iteration 140 : 0.011097082868218422
Loss at iteration 150 : 0.011168570257723331
Loss at iteration 160 : 0.010956676676869392
Loss at iteration 170 : 0.013929459266364574
Loss at iteration 180 : 0.016003141179680824
Loss at iteration 190 : 0.019780367612838745
Loss at iteration 200 : 0.015024831518530846
Loss at iteration 210 : 0.020073790103197098
Loss at iteration 220 : 0.012202280573546886
Loss at iteration 230 : 0.00849208515137434
Loss at iteration 240 : 0.01195528544485569
Loss at iteration 250 : 0.01284987572580576
Loss at iteration 260 : 0.007918238639831543
Loss at iteration 270 : 0.014940530061721802
Loss at iteration 280 : 0.025101061910390854
Loss at iteration 290 : 0.01598230004310608
Loss at iteration 300 : 0.014042484574019909
Loss at iteration 310 : 0.011353002861142159
Loss at iteration 320 : 0.02443018928170204
Loss at iteration 330 : 0.01419051643460989
Loss at iteration 340 : 0.013873707503080368
Loss at iteration 350 : 0.012332084588706493
Loss at iteration 360 : 0.0188343096524477
Loss at iteration 370 : 0.014059832319617271
Loss at iteration 380 : 0.012029804289340973
Loss at iteration 390 : 0.016429482027888298
Loss at iteration 400 : 0.010686911642551422
Loss at iteration 410 : 0.01569141075015068
Loss at iteration 420 : 0.013618063181638718
Loss at iteration 430 : 0.01805376261472702
Loss at iteration 440 : 0.02705967053771019
Loss at iteration 450 : 0.012621811591088772
Loss at iteration 460 : 0.010808488354086876
Loss at iteration 470 : 0.011421062983572483
Loss at iteration 480 : 0.01657618209719658
Loss at iteration 490 : 0.01117437332868576
Loss at iteration 500 : 0.014393513090908527
Loss at iteration 510 : 0.009291538968682289
Loss at iteration 520 : 0.012221262790262699
Loss at iteration 530 : 0.014388695359230042
Loss at iteration 540 : 0.01699298433959484
Loss at iteration 550 : 0.008278890512883663
Loss at iteration 560 : 0.014109842479228973
Loss at iteration 570 : 0.009977702051401138
Loss at iteration 580 : 0.014234738424420357
Loss at iteration 590 : 0.018417606130242348
Loss at iteration 600 : 0.014520830474793911
Loss at iteration 610 : 0.008880117908120155
Loss at iteration 620 : 0.015622243285179138
Loss at iteration 630 : 0.013436689972877502
Loss at iteration 640 : 0.011148001998662949
Loss at iteration 650 : 0.010430029593408108
Loss at iteration 660 : 0.014380056411027908
Loss at iteration 670 : 0.010255195200443268
Loss at iteration 680 : 0.010147913359105587
Loss at iteration 690 : 0.012086516246199608
Loss at iteration 700 : 0.014287212863564491
Loss at iteration 710 : 0.012070134282112122
Loss at iteration 720 : 0.012886717915534973
Loss at iteration 730 : 0.010101620107889175
Loss at iteration 740 : 0.014673232100903988
Loss at iteration 750 : 0.015002734027802944
Loss at iteration 760 : 0.009064797312021255
Loss at iteration 770 : 0.008847467601299286
Loss at iteration 780 : 0.012437479570508003
Loss at iteration 790 : 0.010896694846451283
Loss at iteration 800 : 0.01605718955397606
Loss at iteration 810 : 0.010838602669537067
Loss at iteration 820 : 0.0113278329372406
Loss at iteration 830 : 0.011701400391757488
Loss at iteration 840 : 0.01464933529496193
Loss at iteration 850 : 0.01606772281229496
Loss at iteration 860 : 0.01208437979221344
Loss at iteration 870 : 0.009431647136807442
Loss at iteration 880 : 0.01601952686905861
Loss at iteration 890 : 0.011018017306923866
Loss at iteration 900 : 0.007616343908011913
Loss at iteration 910 : 0.02279815822839737
Loss at iteration 920 : 0.014706016518175602
Loss at iteration 930 : 0.012317605316638947
Loss at iteration 940 : 0.022046424448490143
Loss at iteration 950 : 0.00998669397085905
Loss at iteration 960 : 0.016615059226751328
Loss at iteration 970 : 0.011433804407715797
Loss at iteration 980 : 0.009574931114912033
Loss at iteration 990 : 0.01784156635403633
Loss at iteration 1000 : 0.016177967190742493
Loss at iteration 1010 : 0.0130072683095932
Loss at iteration 1020 : 0.012025219388306141
Loss at iteration 1030 : 0.011258723214268684
Loss at iteration 1040 : 0.027329351752996445
Loss at iteration 1050 : 0.015082532539963722
Loss at iteration 1060 : 0.01664242148399353
Loss at iteration 1070 : 0.0077556646429002285
Loss at iteration 1080 : 0.007942931726574898
Loss at iteration 1090 : 0.011437494307756424
Loss at iteration 1100 : 0.012329181656241417
Loss at iteration 1110 : 0.015781281515955925
Loss at iteration 1120 : 0.014768091030418873
Loss at iteration 1130 : 0.011446629650890827
Loss at iteration 1140 : 0.008841240778565407
Loss at iteration 1150 : 0.01618329994380474
Loss at iteration 1160 : 0.014423170126974583
Loss at iteration 1170 : 0.015878083184361458
Loss at iteration 1180 : 0.01240218710154295
Loss at iteration 1190 : 0.01258817594498396
Loss at iteration 1200 : 0.006448512896895409
Loss at iteration 1210 : 0.01233675703406334
The SSIM Value is: 0.8118000944455465
The PSNR Value is: 19.293198776245116
the highest SSIM value is: 19.293198776245116
the epoch is: 50
Loss at iteration 10 : 0.013593493960797787
Loss at iteration 20 : 0.014749374240636826
Loss at iteration 30 : 0.011293657124042511
Loss at iteration 40 : 0.01165965385735035
Loss at iteration 50 : 0.013492882251739502
Loss at iteration 60 : 0.010176439769566059
Loss at iteration 70 : 0.011894993484020233
Loss at iteration 80 : 0.01938677206635475
Loss at iteration 90 : 0.007295621559023857
Loss at iteration 100 : 0.012044341303408146
Loss at iteration 110 : 0.012004474177956581
Loss at iteration 120 : 0.015301544219255447
Loss at iteration 130 : 0.022815436124801636
Loss at iteration 140 : 0.020425591617822647
Loss at iteration 150 : 0.01261424832046032
Loss at iteration 160 : 0.013928848318755627
Loss at iteration 170 : 0.019883040338754654
Loss at iteration 180 : 0.018081966787576675
Loss at iteration 190 : 0.01570066064596176
Loss at iteration 200 : 0.01713053695857525
Loss at iteration 210 : 0.00946984626352787
Loss at iteration 220 : 0.014048976823687553
Loss at iteration 230 : 0.021871209144592285
Loss at iteration 240 : 0.0177578404545784
Loss at iteration 250 : 0.016237696632742882
Loss at iteration 260 : 0.010343542322516441
Loss at iteration 270 : 0.014410548843443394
Loss at iteration 280 : 0.009163920767605305
Loss at iteration 290 : 0.018979327753186226
Loss at iteration 300 : 0.011687085032463074
Loss at iteration 310 : 0.007857024669647217
Loss at iteration 320 : 0.01848624274134636
Loss at iteration 330 : 0.013299637474119663
Loss at iteration 340 : 0.008403541520237923
Loss at iteration 350 : 0.012719318270683289
Loss at iteration 360 : 0.014504755847156048
Loss at iteration 370 : 0.01456765178591013
Loss at iteration 380 : 0.009134365245699883
Loss at iteration 390 : 0.009763114154338837
Loss at iteration 400 : 0.009489216841757298
Loss at iteration 410 : 0.019476966932415962
Loss at iteration 420 : 0.006629273295402527
Loss at iteration 430 : 0.021768121048808098
Loss at iteration 440 : 0.010554619133472443
Loss at iteration 450 : 0.01711517572402954
Loss at iteration 460 : 0.013625282794237137
Loss at iteration 470 : 0.015966245904564857
Loss at iteration 480 : 0.023536574095487595
Loss at iteration 490 : 0.014693847857415676
Loss at iteration 500 : 0.01347494125366211
Loss at iteration 510 : 0.01213478110730648
Loss at iteration 520 : 0.011400654911994934
Loss at iteration 530 : 0.021561264991760254
Loss at iteration 540 : 0.017492689192295074
Loss at iteration 550 : 0.01323983259499073
Loss at iteration 560 : 0.0140555240213871
Loss at iteration 570 : 0.011907374486327171
Loss at iteration 580 : 0.01924758404493332
Loss at iteration 590 : 0.01302174013108015
Loss at iteration 600 : 0.00866902805864811
Loss at iteration 610 : 0.01186743937432766
Loss at iteration 620 : 0.008901707828044891
Loss at iteration 630 : 0.00991004891693592
Loss at iteration 640 : 0.01713830605149269
Loss at iteration 650 : 0.009667878970503807
Loss at iteration 660 : 0.022023003548383713
Loss at iteration 670 : 0.02154499478638172
Loss at iteration 680 : 0.016571303829550743
Loss at iteration 690 : 0.021555213257670403
Loss at iteration 700 : 0.021249357610940933
Loss at iteration 710 : 0.009909475222229958
Loss at iteration 720 : 0.009562278166413307
Loss at iteration 730 : 0.01383276842534542
Loss at iteration 740 : 0.011834627017378807
Loss at iteration 750 : 0.014497433789074421
Loss at iteration 760 : 0.011818384751677513
Loss at iteration 770 : 0.013091439381241798
Loss at iteration 780 : 0.010593973100185394
Loss at iteration 790 : 0.0125449039041996
Loss at iteration 800 : 0.012496967799961567
Loss at iteration 810 : 0.01806063950061798
Loss at iteration 820 : 0.007696768268942833
Loss at iteration 830 : 0.010314695537090302
Loss at iteration 840 : 0.012090001255273819
Loss at iteration 850 : 0.017967935651540756
Loss at iteration 860 : 0.007722225971519947
Loss at iteration 870 : 0.013075272552669048
Loss at iteration 880 : 0.007112900726497173
Loss at iteration 890 : 0.010658949613571167
Loss at iteration 900 : 0.014044137671589851
Loss at iteration 910 : 0.0071030729450285435
Loss at iteration 920 : 0.01016047690063715
Loss at iteration 930 : 0.010476212948560715
Loss at iteration 940 : 0.010657371953129768
Loss at iteration 950 : 0.01565515622496605
Loss at iteration 960 : 0.011621024459600449
Loss at iteration 970 : 0.006348967086523771
Loss at iteration 980 : 0.011999184265732765
Loss at iteration 990 : 0.015078146010637283
Loss at iteration 1000 : 0.015843549743294716
Loss at iteration 1010 : 0.010330717079341412
Loss at iteration 1020 : 0.00728524150326848
Loss at iteration 1030 : 0.017384883016347885
Loss at iteration 1040 : 0.012664426118135452
Loss at iteration 1050 : 0.009211496450006962
Loss at iteration 1060 : 0.014183891005814075
Loss at iteration 1070 : 0.011020340025424957
Loss at iteration 1080 : 0.013047629036009312
Loss at iteration 1090 : 0.017209583893418312
Loss at iteration 1100 : 0.012194289825856686
Loss at iteration 1110 : 0.015114926733076572
Loss at iteration 1120 : 0.008345521055161953
Loss at iteration 1130 : 0.006526396609842777
Loss at iteration 1140 : 0.012765170074999332
Loss at iteration 1150 : 0.016757048666477203
Loss at iteration 1160 : 0.00926167517900467
Loss at iteration 1170 : 0.01454079058021307
Loss at iteration 1180 : 0.009617527946829796
Loss at iteration 1190 : 0.010115567594766617
Loss at iteration 1200 : 0.015034448355436325
Loss at iteration 1210 : 0.006879809312522411
The SSIM Value is: 0.810473104317983
The PSNR Value is: 18.774295743306478
the epoch is: 51
Loss at iteration 10 : 0.011769974604249
Loss at iteration 20 : 0.015727242454886436
Loss at iteration 30 : 0.018531063571572304
Loss at iteration 40 : 0.008577010594308376
Loss at iteration 50 : 0.006786542944610119
Loss at iteration 60 : 0.014878417365252972
Loss at iteration 70 : 0.010824217461049557
Loss at iteration 80 : 0.0152155552059412
Loss at iteration 90 : 0.004515345208346844
Loss at iteration 100 : 0.006881712004542351
Loss at iteration 110 : 0.010677609592676163
Loss at iteration 120 : 0.011200133711099625
Loss at iteration 130 : 0.014721850864589214
Loss at iteration 140 : 0.01185392402112484
Loss at iteration 150 : 0.011606205254793167
Loss at iteration 160 : 0.011980175971984863
Loss at iteration 170 : 0.014086768962442875
Loss at iteration 180 : 0.016365282237529755
Loss at iteration 190 : 0.008099472150206566
Loss at iteration 200 : 0.010754413902759552
Loss at iteration 210 : 0.01543388795107603
Loss at iteration 220 : 0.013763217255473137
Loss at iteration 230 : 0.021106228232383728
Loss at iteration 240 : 0.007817326113581657
Loss at iteration 250 : 0.005777583457529545
Loss at iteration 260 : 0.01243466418236494
Loss at iteration 270 : 0.01152550894767046
Loss at iteration 280 : 0.015299173071980476
Loss at iteration 290 : 0.01582988351583481
Loss at iteration 300 : 0.012959444895386696
Loss at iteration 310 : 0.010053158737719059
Loss at iteration 320 : 0.010736508294939995
Loss at iteration 330 : 0.010394295677542686
Loss at iteration 340 : 0.010378028266131878
Loss at iteration 350 : 0.01241234689950943
Loss at iteration 360 : 0.011440755799412727
Loss at iteration 370 : 0.015045760199427605
Loss at iteration 380 : 0.012633604928851128
Loss at iteration 390 : 0.011564116925001144
Loss at iteration 400 : 0.009481748566031456
Loss at iteration 410 : 0.007977309636771679
Loss at iteration 420 : 0.014187468215823174
Loss at iteration 430 : 0.015086633153259754
Loss at iteration 440 : 0.014178860001266003
Loss at iteration 450 : 0.009583602659404278
Loss at iteration 460 : 0.011296503245830536
Loss at iteration 470 : 0.01866900734603405
Loss at iteration 480 : 0.012284558266401291
Loss at iteration 490 : 0.008388558402657509
Loss at iteration 500 : 0.01090338546782732
Loss at iteration 510 : 0.015167152509093285
Loss at iteration 520 : 0.013915428891777992
Loss at iteration 530 : 0.006783658638596535
Loss at iteration 540 : 0.011538512073457241
Loss at iteration 550 : 0.011899398639798164
Loss at iteration 560 : 0.01742890663444996
Loss at iteration 570 : 0.015238501131534576
Loss at iteration 580 : 0.01709180697798729
Loss at iteration 590 : 0.009883889928460121
Loss at iteration 600 : 0.01968320831656456
Loss at iteration 610 : 0.01475925650447607
Loss at iteration 620 : 0.019103914499282837
Loss at iteration 630 : 0.013099460862576962
Loss at iteration 640 : 0.012346210889518261
Loss at iteration 650 : 0.018596358597278595
Loss at iteration 660 : 0.011955109424889088
Loss at iteration 670 : 0.013557538390159607
Loss at iteration 680 : 0.014240712858736515
Loss at iteration 690 : 0.014090605080127716
Loss at iteration 700 : 0.009345635771751404
Loss at iteration 710 : 0.013860121369361877
Loss at iteration 720 : 0.009956493973731995
Loss at iteration 730 : 0.01138086337596178
Loss at iteration 740 : 0.01028327364474535
Loss at iteration 750 : 0.012212187983095646
Loss at iteration 760 : 0.009848367422819138
Loss at iteration 770 : 0.011498614214360714
Loss at iteration 780 : 0.007623427081853151
Loss at iteration 790 : 0.008974447846412659
Loss at iteration 800 : 0.0105771878734231
Loss at iteration 810 : 0.01281590573489666
Loss at iteration 820 : 0.01067617442458868
Loss at iteration 830 : 0.010521134361624718
Loss at iteration 840 : 0.011037703603506088
Loss at iteration 850 : 0.01723640225827694
Loss at iteration 860 : 0.008713023737072945
Loss at iteration 870 : 0.01422911323606968
Loss at iteration 880 : 0.019225357100367546
Loss at iteration 890 : 0.020069558173418045
Loss at iteration 900 : 0.01146039366722107
Loss at iteration 910 : 0.012122143059968948
Loss at iteration 920 : 0.010692336596548557
Loss at iteration 930 : 0.011678215116262436
Loss at iteration 940 : 0.010009723715484142
Loss at iteration 950 : 0.0098795834928751
Loss at iteration 960 : 0.01422069501131773
Loss at iteration 970 : 0.012991870753467083
Loss at iteration 980 : 0.011682220734655857
Loss at iteration 990 : 0.012826595455408096
Loss at iteration 1000 : 0.01219300739467144
Loss at iteration 1010 : 0.011951413005590439
Loss at iteration 1020 : 0.014397362247109413
Loss at iteration 1030 : 0.010537316091358662
Loss at iteration 1040 : 0.01292717270553112
Loss at iteration 1050 : 0.015143763273954391
Loss at iteration 1060 : 0.013387334533035755
Loss at iteration 1070 : 0.011092618107795715
Loss at iteration 1080 : 0.01123419776558876
Loss at iteration 1090 : 0.011555129662156105
Loss at iteration 1100 : 0.02274935692548752
Loss at iteration 1110 : 0.0076773203909397125
Loss at iteration 1120 : 0.013772533275187016
Loss at iteration 1130 : 0.007961684837937355
Loss at iteration 1140 : 0.006960425525903702
Loss at iteration 1150 : 0.013078374788165092
Loss at iteration 1160 : 0.012051546014845371
Loss at iteration 1170 : 0.008783337660133839
Loss at iteration 1180 : 0.012334056198596954
Loss at iteration 1190 : 0.013801506720483303
Loss at iteration 1200 : 0.013396243564784527
Loss at iteration 1210 : 0.014786170795559883
The SSIM Value is: 0.7998802502950032
The PSNR Value is: 18.01465326944987
the epoch is: 52
Loss at iteration 10 : 0.01012715045362711
Loss at iteration 20 : 0.012272970750927925
Loss at iteration 30 : 0.013512864708900452
Loss at iteration 40 : 0.0069071026518940926
Loss at iteration 50 : 0.015339341014623642
Loss at iteration 60 : 0.012675114907324314
Loss at iteration 70 : 0.021360380575060844
Loss at iteration 80 : 0.014615707099437714
Loss at iteration 90 : 0.012638856656849384
Loss at iteration 100 : 0.010648144409060478
Loss at iteration 110 : 0.009769552387297153
Loss at iteration 120 : 0.012880142778158188
Loss at iteration 130 : 0.014056727290153503
Loss at iteration 140 : 0.012021245434880257
Loss at iteration 150 : 0.016613803803920746
Loss at iteration 160 : 0.011186604388058186
Loss at iteration 170 : 0.012493730522692204
Loss at iteration 180 : 0.014872795902192593
Loss at iteration 190 : 0.015607677400112152
Loss at iteration 200 : 0.014498215168714523
Loss at iteration 210 : 0.011670967563986778
Loss at iteration 220 : 0.018135903403162956
Loss at iteration 230 : 0.013086746446788311
Loss at iteration 240 : 0.01405283436179161
Loss at iteration 250 : 0.013403746299445629
Loss at iteration 260 : 0.012755152769386768
Loss at iteration 270 : 0.017663205042481422
Loss at iteration 280 : 0.01607915200293064
Loss at iteration 290 : 0.009082705713808537
Loss at iteration 300 : 0.009459441527724266
Loss at iteration 310 : 0.017267975956201553
Loss at iteration 320 : 0.01646566390991211
Loss at iteration 330 : 0.010247462429106236
Loss at iteration 340 : 0.011590542271733284
Loss at iteration 350 : 0.006693048402667046
Loss at iteration 360 : 0.008706387132406235
Loss at iteration 370 : 0.01384884025901556
Loss at iteration 380 : 0.016333822160959244
Loss at iteration 390 : 0.01735537126660347
Loss at iteration 400 : 0.015136899426579475
Loss at iteration 410 : 0.028655987232923508
Loss at iteration 420 : 0.0186458807438612
Loss at iteration 430 : 0.009207315742969513
Loss at iteration 440 : 0.007406715303659439
Loss at iteration 450 : 0.009834698401391506
Loss at iteration 460 : 0.011429613456130028
Loss at iteration 470 : 0.007129428908228874
Loss at iteration 480 : 0.014290226623415947
Loss at iteration 490 : 0.007400875445455313
Loss at iteration 500 : 0.010415786877274513
Loss at iteration 510 : 0.008027655072510242
Loss at iteration 520 : 0.01831217110157013
Loss at iteration 530 : 0.018559932708740234
Loss at iteration 540 : 0.013936781324446201
Loss at iteration 550 : 0.008929800242185593
Loss at iteration 560 : 0.0112056415528059
Loss at iteration 570 : 0.011827826499938965
Loss at iteration 580 : 0.009955289773643017
Loss at iteration 590 : 0.01551927998661995
Loss at iteration 600 : 0.011443618685007095
Loss at iteration 610 : 0.013070506975054741
Loss at iteration 620 : 0.013023704290390015
Loss at iteration 630 : 0.015229555778205395
Loss at iteration 640 : 0.022322561591863632
Loss at iteration 650 : 0.010057149454951286
Loss at iteration 660 : 0.011060014367103577
Loss at iteration 670 : 0.008529792539775372
Loss at iteration 680 : 0.019600411877036095
Loss at iteration 690 : 0.014076445251703262
Loss at iteration 700 : 0.014378765597939491
Loss at iteration 710 : 0.016981326043605804
Loss at iteration 720 : 0.0156853087246418
Loss at iteration 730 : 0.012063262984156609
Loss at iteration 740 : 0.013258878141641617
Loss at iteration 750 : 0.011642204597592354
Loss at iteration 760 : 0.00957082211971283
Loss at iteration 770 : 0.01206193771213293
Loss at iteration 780 : 0.02369486540555954
Loss at iteration 790 : 0.010526931844651699
Loss at iteration 800 : 0.009013434872031212
Loss at iteration 810 : 0.012002040632069111
Loss at iteration 820 : 0.011222943663597107
Loss at iteration 830 : 0.010263977572321892
Loss at iteration 840 : 0.011550119146704674
Loss at iteration 850 : 0.011096167378127575
Loss at iteration 860 : 0.013731380924582481
Loss at iteration 870 : 0.010732284747064114
Loss at iteration 880 : 0.01638118363916874
Loss at iteration 890 : 0.012599317356944084
Loss at iteration 900 : 0.012399434112012386
Loss at iteration 910 : 0.014418104663491249
Loss at iteration 920 : 0.010151784867048264
Loss at iteration 930 : 0.021777234971523285
Loss at iteration 940 : 0.014978808350861073
Loss at iteration 950 : 0.012658125720918179
Loss at iteration 960 : 0.01273723691701889
Loss at iteration 970 : 0.009002823382616043
Loss at iteration 980 : 0.009569445624947548
Loss at iteration 990 : 0.01481363270431757
Loss at iteration 1000 : 0.00775800971314311
Loss at iteration 1010 : 0.011216597631573677
Loss at iteration 1020 : 0.014586144126951694
Loss at iteration 1030 : 0.01728185825049877
Loss at iteration 1040 : 0.009901845827698708
Loss at iteration 1050 : 0.00794206466525793
Loss at iteration 1060 : 0.013346271589398384
Loss at iteration 1070 : 0.008626316674053669
Loss at iteration 1080 : 0.01119201723486185
Loss at iteration 1090 : 0.013414713554084301
Loss at iteration 1100 : 0.0165474321693182
Loss at iteration 1110 : 0.011760588735342026
Loss at iteration 1120 : 0.014004713855683804
Loss at iteration 1130 : 0.021404743194580078
Loss at iteration 1140 : 0.015540467575192451
Loss at iteration 1150 : 0.008670500479638577
Loss at iteration 1160 : 0.013708967715501785
Loss at iteration 1170 : 0.011314240284264088
Loss at iteration 1180 : 0.01260727271437645
Loss at iteration 1190 : 0.00889604538679123
Loss at iteration 1200 : 0.011652655899524689
Loss at iteration 1210 : 0.007138994988054037
The SSIM Value is: 0.8063131054242452
The PSNR Value is: 18.6847536722819
the epoch is: 53
Loss at iteration 10 : 0.015203878283500671
Loss at iteration 20 : 0.010557693429291248
Loss at iteration 30 : 0.008112418465316296
Loss at iteration 40 : 0.017481232061982155
Loss at iteration 50 : 0.0121742133051157
Loss at iteration 60 : 0.009231684729456902
Loss at iteration 70 : 0.016159258782863617
Loss at iteration 80 : 0.008230719715356827
Loss at iteration 90 : 0.018579546362161636
Loss at iteration 100 : 0.014647046104073524
Loss at iteration 110 : 0.016727913171052933
Loss at iteration 120 : 0.01994682289659977
Loss at iteration 130 : 0.01290222443640232
Loss at iteration 140 : 0.015077434480190277
Loss at iteration 150 : 0.012844229117035866
Loss at iteration 160 : 0.01746978983283043
Loss at iteration 170 : 0.014384454116225243
Loss at iteration 180 : 0.012806890532374382
Loss at iteration 190 : 0.016618013381958008
Loss at iteration 200 : 0.015577678568661213
Loss at iteration 210 : 0.012314067222177982
Loss at iteration 220 : 0.01454257033765316
Loss at iteration 230 : 0.011466704308986664
Loss at iteration 240 : 0.013603872619569302
Loss at iteration 250 : 0.014286080375313759
Loss at iteration 260 : 0.0064963530749082565
Loss at iteration 270 : 0.011823190376162529
Loss at iteration 280 : 0.010801213793456554
Loss at iteration 290 : 0.0172248724848032
Loss at iteration 300 : 0.017169952392578125
Loss at iteration 310 : 0.0170914176851511
Loss at iteration 320 : 0.0169388297945261
Loss at iteration 330 : 0.009911122731864452
Loss at iteration 340 : 0.011693932116031647
Loss at iteration 350 : 0.009376881644129753
Loss at iteration 360 : 0.010944036766886711
Loss at iteration 370 : 0.007895566523075104
Loss at iteration 380 : 0.014288682490587234
Loss at iteration 390 : 0.008230611681938171
Loss at iteration 400 : 0.013110880739986897
Loss at iteration 410 : 0.009706972166895866
Loss at iteration 420 : 0.00957033783197403
Loss at iteration 430 : 0.009718097746372223
Loss at iteration 440 : 0.006762008182704449
Loss at iteration 450 : 0.007314886432141066
Loss at iteration 460 : 0.01805802248418331
Loss at iteration 470 : 0.011795133352279663
Loss at iteration 480 : 0.013133103027939796
Loss at iteration 490 : 0.011492853052914143
Loss at iteration 500 : 0.018837643787264824
Loss at iteration 510 : 0.013396898284554482
Loss at iteration 520 : 0.018273739144206047
Loss at iteration 530 : 0.017018316313624382
Loss at iteration 540 : 0.016248758882284164
Loss at iteration 550 : 0.013697842136025429
Loss at iteration 560 : 0.009301225654780865
Loss at iteration 570 : 0.008508093655109406
Loss at iteration 580 : 0.011944396421313286
Loss at iteration 590 : 0.013791411183774471
Loss at iteration 600 : 0.010713435709476471
Loss at iteration 610 : 0.011711431667208672
Loss at iteration 620 : 0.010661503300070763
Loss at iteration 630 : 0.013501022011041641
Loss at iteration 640 : 0.012417769059538841
Loss at iteration 650 : 0.017855841666460037
Loss at iteration 660 : 0.011800730600953102
Loss at iteration 670 : 0.009090332314372063
Loss at iteration 680 : 0.0059279464185237885
Loss at iteration 690 : 0.014044403098523617
Loss at iteration 700 : 0.008995478972792625
Loss at iteration 710 : 0.019523967057466507
Loss at iteration 720 : 0.011648900806903839
Loss at iteration 730 : 0.014257228001952171
Loss at iteration 740 : 0.0072618164122104645
Loss at iteration 750 : 0.009130255319178104
Loss at iteration 760 : 0.011218121275305748
Loss at iteration 770 : 0.01802697405219078
Loss at iteration 780 : 0.014843650162220001
Loss at iteration 790 : 0.009915230795741081
Loss at iteration 800 : 0.011951146647334099
Loss at iteration 810 : 0.012895663268864155
Loss at iteration 820 : 0.009907377883791924
Loss at iteration 830 : 0.023867040872573853
Loss at iteration 840 : 0.010915502905845642
Loss at iteration 850 : 0.006542340852320194
Loss at iteration 860 : 0.012798072770237923
Loss at iteration 870 : 0.014389915391802788
Loss at iteration 880 : 0.010151563212275505
Loss at iteration 890 : 0.009935038164258003
Loss at iteration 900 : 0.019201058894395828
Loss at iteration 910 : 0.010541366413235664
Loss at iteration 920 : 0.018371548503637314
Loss at iteration 930 : 0.011200517416000366
Loss at iteration 940 : 0.008451413363218307
Loss at iteration 950 : 0.011355653405189514
Loss at iteration 960 : 0.009431065991520882
Loss at iteration 970 : 0.018250254914164543
Loss at iteration 980 : 0.013186684809625149
Loss at iteration 990 : 0.012965226545929909
Loss at iteration 1000 : 0.009065361693501472
Loss at iteration 1010 : 0.013102421537041664
Loss at iteration 1020 : 0.005483259446918964
Loss at iteration 1030 : 0.012540801428258419
Loss at iteration 1040 : 0.020729266107082367
Loss at iteration 1050 : 0.013348123989999294
Loss at iteration 1060 : 0.009348107501864433
Loss at iteration 1070 : 0.015782667323946953
Loss at iteration 1080 : 0.012601913884282112
Loss at iteration 1090 : 0.024745166301727295
Loss at iteration 1100 : 0.010004421696066856
Loss at iteration 1110 : 0.010031070560216904
Loss at iteration 1120 : 0.006670510396361351
Loss at iteration 1130 : 0.01301446184515953
Loss at iteration 1140 : 0.013382431119680405
Loss at iteration 1150 : 0.011868361383676529
Loss at iteration 1160 : 0.010654930956661701
Loss at iteration 1170 : 0.013009309768676758
Loss at iteration 1180 : 0.017525723204016685
Loss at iteration 1190 : 0.01831079088151455
Loss at iteration 1200 : 0.013317322358489037
Loss at iteration 1210 : 0.009362041018903255
The SSIM Value is: 0.8067423303922018
The PSNR Value is: 18.88698101043701
the epoch is: 54
Loss at iteration 10 : 0.013561258092522621
Loss at iteration 20 : 0.016095921397209167
Loss at iteration 30 : 0.010057415813207626
Loss at iteration 40 : 0.012244598008692265
Loss at iteration 50 : 0.008042985573410988
Loss at iteration 60 : 0.007030957378447056
Loss at iteration 70 : 0.00614206725731492
Loss at iteration 80 : 0.011139942333102226
Loss at iteration 90 : 0.01420675590634346
Loss at iteration 100 : 0.015106831677258015
Loss at iteration 110 : 0.008402050472795963
Loss at iteration 120 : 0.01798989810049534
Loss at iteration 130 : 0.025135258212685585
Loss at iteration 140 : 0.010164318606257439
Loss at iteration 150 : 0.01124761626124382
Loss at iteration 160 : 0.008692586794495583
Loss at iteration 170 : 0.0118594691157341
Loss at iteration 180 : 0.009206139482557774
Loss at iteration 190 : 0.011852973140776157
Loss at iteration 200 : 0.013401498086750507
Loss at iteration 210 : 0.013996943831443787
Loss at iteration 220 : 0.01356018241494894
Loss at iteration 230 : 0.008813426829874516
Loss at iteration 240 : 0.00926152803003788
Loss at iteration 250 : 0.016302404925227165
Loss at iteration 260 : 0.012385154142975807
Loss at iteration 270 : 0.0118671003729105
Loss at iteration 280 : 0.009299096651375294
Loss at iteration 290 : 0.013543006964027882
Loss at iteration 300 : 0.009237187914550304
Loss at iteration 310 : 0.023822713643312454
Loss at iteration 320 : 0.014033748768270016
Loss at iteration 330 : 0.005250072572380304
Loss at iteration 340 : 0.007998134940862656
Loss at iteration 350 : 0.01146819069981575
Loss at iteration 360 : 0.008898891508579254
Loss at iteration 370 : 0.01395487692207098
Loss at iteration 380 : 0.009709617123007774
Loss at iteration 390 : 0.008357823826372623
Loss at iteration 400 : 0.009303412400186062
Loss at iteration 410 : 0.011798227205872536
Loss at iteration 420 : 0.011295659467577934
Loss at iteration 430 : 0.014506552368402481
Loss at iteration 440 : 0.014322832226753235
Loss at iteration 450 : 0.01531826239079237
Loss at iteration 460 : 0.014861534349620342
Loss at iteration 470 : 0.012550124898552895
Loss at iteration 480 : 0.008565475232899189
Loss at iteration 490 : 0.021121103316545486
Loss at iteration 500 : 0.023844532668590546
Loss at iteration 510 : 0.011510934680700302
Loss at iteration 520 : 0.013654708862304688
Loss at iteration 530 : 0.009685158729553223
Loss at iteration 540 : 0.01406008005142212
Loss at iteration 550 : 0.009453073143959045
Loss at iteration 560 : 0.009914635680615902
Loss at iteration 570 : 0.0197233147919178
Loss at iteration 580 : 0.009596947580575943
Loss at iteration 590 : 0.010794823057949543
Loss at iteration 600 : 0.017834536731243134
Loss at iteration 610 : 0.01387858483940363
Loss at iteration 620 : 0.011918071657419205
Loss at iteration 630 : 0.008563168346881866
Loss at iteration 640 : 0.009094073437154293
Loss at iteration 650 : 0.012106990441679955
Loss at iteration 660 : 0.01840572990477085
Loss at iteration 670 : 0.012606242671608925
Loss at iteration 680 : 0.008514730259776115
Loss at iteration 690 : 0.015241971239447594
Loss at iteration 700 : 0.021362166851758957
Loss at iteration 710 : 0.016134008765220642
Loss at iteration 720 : 0.017394572496414185
Loss at iteration 730 : 0.007471718359738588
Loss at iteration 740 : 0.010279729962348938
Loss at iteration 750 : 0.007775822188705206
Loss at iteration 760 : 0.010532635264098644
Loss at iteration 770 : 0.010373685508966446
Loss at iteration 780 : 0.007793012540787458
Loss at iteration 790 : 0.016231877729296684
Loss at iteration 800 : 0.014896168373525143
Loss at iteration 810 : 0.012543848715722561
Loss at iteration 820 : 0.012965863570570946
Loss at iteration 830 : 0.015904609113931656
Loss at iteration 840 : 0.012583492323756218
Loss at iteration 850 : 0.009837052784860134
Loss at iteration 860 : 0.008627120405435562
Loss at iteration 870 : 0.014253339730203152
Loss at iteration 880 : 0.02142340876162052
Loss at iteration 890 : 0.008706401102244854
Loss at iteration 900 : 0.011661127209663391
Loss at iteration 910 : 0.019818389788269997
Loss at iteration 920 : 0.011124039068818092
Loss at iteration 930 : 0.011559387668967247
Loss at iteration 940 : 0.011349378153681755
Loss at iteration 950 : 0.011442393995821476
Loss at iteration 960 : 0.010125938802957535
Loss at iteration 970 : 0.009510813280940056
Loss at iteration 980 : 0.010448288172483444
Loss at iteration 990 : 0.013805896043777466
Loss at iteration 1000 : 0.011362324468791485
Loss at iteration 1010 : 0.01313440129160881
Loss at iteration 1020 : 0.011518310755491257
Loss at iteration 1030 : 0.011974907480180264
Loss at iteration 1040 : 0.00898646842688322
Loss at iteration 1050 : 0.012095008976757526
Loss at iteration 1060 : 0.009573129005730152
Loss at iteration 1070 : 0.0100672272965312
Loss at iteration 1080 : 0.013217300176620483
Loss at iteration 1090 : 0.014677323400974274
Loss at iteration 1100 : 0.009989041835069656
Loss at iteration 1110 : 0.01599029079079628
Loss at iteration 1120 : 0.016518648713827133
Loss at iteration 1130 : 0.00938645750284195
Loss at iteration 1140 : 0.010914266109466553
Loss at iteration 1150 : 0.013418609276413918
Loss at iteration 1160 : 0.014764836058020592
Loss at iteration 1170 : 0.013018803671002388
Loss at iteration 1180 : 0.009794885292649269
Loss at iteration 1190 : 0.011341548524796963
Loss at iteration 1200 : 0.016341783106327057
Loss at iteration 1210 : 0.009763947688043118
The SSIM Value is: 0.8024771372477214
The PSNR Value is: 17.962598037719726
the epoch is: 55
Loss at iteration 10 : 0.021657757461071014
Loss at iteration 20 : 0.007852915674448013
Loss at iteration 30 : 0.012425320222973824
Loss at iteration 40 : 0.011054858565330505
Loss at iteration 50 : 0.01805742457509041
Loss at iteration 60 : 0.011521309614181519
Loss at iteration 70 : 0.013304021209478378
Loss at iteration 80 : 0.011436139233410358
Loss at iteration 90 : 0.015517049469053745
Loss at iteration 100 : 0.016351668164134026
Loss at iteration 110 : 0.018983688205480576
Loss at iteration 120 : 0.014274649322032928
Loss at iteration 130 : 0.014508812688291073
Loss at iteration 140 : 0.012039878405630589
Loss at iteration 150 : 0.009376542642712593
Loss at iteration 160 : 0.012151580303907394
Loss at iteration 170 : 0.01811356283724308
Loss at iteration 180 : 0.014887824654579163
Loss at iteration 190 : 0.012077241204679012
Loss at iteration 200 : 0.013087056577205658
Loss at iteration 210 : 0.016075752675533295
Loss at iteration 220 : 0.01410914957523346
Loss at iteration 230 : 0.020071035251021385
Loss at iteration 240 : 0.010603422299027443
Loss at iteration 250 : 0.022447898983955383
Loss at iteration 260 : 0.00978560745716095
Loss at iteration 270 : 0.009646045044064522
Loss at iteration 280 : 0.010216291062533855
Loss at iteration 290 : 0.010365328751504421
Loss at iteration 300 : 0.015295704826712608
Loss at iteration 310 : 0.01149472314864397
Loss at iteration 320 : 0.011868391185998917
Loss at iteration 330 : 0.011684599332511425
Loss at iteration 340 : 0.013524769805371761
Loss at iteration 350 : 0.013352970592677593
Loss at iteration 360 : 0.017956679686903954
Loss at iteration 370 : 0.01256264466792345
Loss at iteration 380 : 0.011347022838890553
Loss at iteration 390 : 0.012269987724721432
Loss at iteration 400 : 0.006560984067618847
Loss at iteration 410 : 0.010490244254469872
Loss at iteration 420 : 0.007974084466695786
Loss at iteration 430 : 0.010644668713212013
Loss at iteration 440 : 0.0125809907913208
Loss at iteration 450 : 0.009598081931471825
Loss at iteration 460 : 0.018041793256998062
Loss at iteration 470 : 0.011475352570414543
Loss at iteration 480 : 0.017560143023729324
Loss at iteration 490 : 0.006320406682789326
Loss at iteration 500 : 0.017367616295814514
Loss at iteration 510 : 0.011598663404583931
Loss at iteration 520 : 0.015716010704636574
Loss at iteration 530 : 0.013854553923010826
Loss at iteration 540 : 0.011774657294154167
Loss at iteration 550 : 0.01160559244453907
Loss at iteration 560 : 0.01729751005768776
Loss at iteration 570 : 0.008372190408408642
Loss at iteration 580 : 0.014625397510826588
Loss at iteration 590 : 0.013006024993956089
Loss at iteration 600 : 0.008280192501842976
Loss at iteration 610 : 0.009435693733394146
Loss at iteration 620 : 0.013562229461967945
Loss at iteration 630 : 0.010144312866032124
Loss at iteration 640 : 0.008379507809877396
Loss at iteration 650 : 0.011923836544156075
Loss at iteration 660 : 0.00709505332633853
Loss at iteration 670 : 0.019172020256519318
Loss at iteration 680 : 0.012099589221179485
Loss at iteration 690 : 0.004944921005517244
Loss at iteration 700 : 0.009145590476691723
Loss at iteration 710 : 0.013131475076079369
Loss at iteration 720 : 0.007947856560349464
Loss at iteration 730 : 0.010942410677671432
Loss at iteration 740 : 0.009424140676856041
Loss at iteration 750 : 0.01545071229338646
Loss at iteration 760 : 0.015737667679786682
Loss at iteration 770 : 0.010455561801791191
Loss at iteration 780 : 0.01112227514386177
Loss at iteration 790 : 0.01684749871492386
Loss at iteration 800 : 0.008591651916503906
Loss at iteration 810 : 0.013755596242845058
Loss at iteration 820 : 0.01733788475394249
Loss at iteration 830 : 0.01401514746248722
Loss at iteration 840 : 0.013356379233300686
Loss at iteration 850 : 0.011972526088356972
Loss at iteration 860 : 0.011487431824207306
Loss at iteration 870 : 0.01798521727323532
Loss at iteration 880 : 0.023149464279413223
Loss at iteration 890 : 0.01563940942287445
Loss at iteration 900 : 0.01459179725497961
Loss at iteration 910 : 0.013351069763302803
Loss at iteration 920 : 0.01064591109752655
Loss at iteration 930 : 0.018728960305452347
Loss at iteration 940 : 0.00895219948142767
Loss at iteration 950 : 0.017585214227437973
Loss at iteration 960 : 0.013373857364058495
Loss at iteration 970 : 0.013388379476964474
Loss at iteration 980 : 0.012825019657611847
Loss at iteration 990 : 0.011225509457290173
Loss at iteration 1000 : 0.008741926401853561
Loss at iteration 1010 : 0.010101606138050556
Loss at iteration 1020 : 0.0116706732660532
Loss at iteration 1030 : 0.012635208666324615
Loss at iteration 1040 : 0.012289226055145264
Loss at iteration 1050 : 0.011392681859433651
Loss at iteration 1060 : 0.010179569944739342
Loss at iteration 1070 : 0.0284926425665617
Loss at iteration 1080 : 0.023883594200015068
Loss at iteration 1090 : 0.005045949947088957
Loss at iteration 1100 : 0.016956094652414322
Loss at iteration 1110 : 0.009081672877073288
Loss at iteration 1120 : 0.016956357285380363
Loss at iteration 1130 : 0.008028533309698105
Loss at iteration 1140 : 0.009509354829788208
Loss at iteration 1150 : 0.012375177815556526
Loss at iteration 1160 : 0.013249151408672333
Loss at iteration 1170 : 0.009801560081541538
Loss at iteration 1180 : 0.009904082864522934
Loss at iteration 1190 : 0.009713894687592983
Loss at iteration 1200 : 0.011913596652448177
Loss at iteration 1210 : 0.014241114258766174
The SSIM Value is: 0.8055979092915853
The PSNR Value is: 18.63738396962484
the epoch is: 56
Loss at iteration 10 : 0.01668759621679783
Loss at iteration 20 : 0.011531408876180649
Loss at iteration 30 : 0.014868484809994698
Loss at iteration 40 : 0.010112801566720009
Loss at iteration 50 : 0.02156832255423069
Loss at iteration 60 : 0.00912432000041008
Loss at iteration 70 : 0.011089269071817398
Loss at iteration 80 : 0.012485682964324951
Loss at iteration 90 : 0.010448887944221497
Loss at iteration 100 : 0.015558505430817604
Loss at iteration 110 : 0.01262611337006092
Loss at iteration 120 : 0.015139339491724968
Loss at iteration 130 : 0.009053117595613003
Loss at iteration 140 : 0.009617138653993607
Loss at iteration 150 : 0.012721018865704536
Loss at iteration 160 : 0.010746458545327187
Loss at iteration 170 : 0.016164811328053474
Loss at iteration 180 : 0.01068068202584982
Loss at iteration 190 : 0.01532476581633091
Loss at iteration 200 : 0.014400431886315346
Loss at iteration 210 : 0.019081825390458107
Loss at iteration 220 : 0.016514644026756287
Loss at iteration 230 : 0.014272517524659634
Loss at iteration 240 : 0.012949526309967041
Loss at iteration 250 : 0.01726164110004902
Loss at iteration 260 : 0.006818546913564205
Loss at iteration 270 : 0.008665801025927067
Loss at iteration 280 : 0.009245187975466251
Loss at iteration 290 : 0.016083087772130966
Loss at iteration 300 : 0.017579425126314163
Loss at iteration 310 : 0.009946259669959545
Loss at iteration 320 : 0.007447639014571905
Loss at iteration 330 : 0.009409504011273384
Loss at iteration 340 : 0.010187231004238129
Loss at iteration 350 : 0.025280294939875603
Loss at iteration 360 : 0.011407284066081047
Loss at iteration 370 : 0.016038712114095688
Loss at iteration 380 : 0.00979633443057537
Loss at iteration 390 : 0.015397289767861366
Loss at iteration 400 : 0.010663162916898727
Loss at iteration 410 : 0.005715616513043642
Loss at iteration 420 : 0.009807601571083069
Loss at iteration 430 : 0.013677805662155151
Loss at iteration 440 : 0.011772047728300095
Loss at iteration 450 : 0.017693201079964638
Loss at iteration 460 : 0.01305137574672699
Loss at iteration 470 : 0.014434385113418102
Loss at iteration 480 : 0.013949085026979446
Loss at iteration 490 : 0.013790518045425415
Loss at iteration 500 : 0.014980589039623737
Loss at iteration 510 : 0.016018938273191452
Loss at iteration 520 : 0.00938483141362667
Loss at iteration 530 : 0.017020592465996742
Loss at iteration 540 : 0.011604337021708488
Loss at iteration 550 : 0.010003095492720604
Loss at iteration 560 : 0.009535292163491249
Loss at iteration 570 : 0.013427895493805408
Loss at iteration 580 : 0.006685775704681873
Loss at iteration 590 : 0.016371462494134903
Loss at iteration 600 : 0.012018078938126564
Loss at iteration 610 : 0.008454527705907822
Loss at iteration 620 : 0.008503617718815804
Loss at iteration 630 : 0.010970741510391235
Loss at iteration 640 : 0.017771078273653984
Loss at iteration 650 : 0.009040837176144123
Loss at iteration 660 : 0.016471367329359055
Loss at iteration 670 : 0.016008909791707993
Loss at iteration 680 : 0.014246436767280102
Loss at iteration 690 : 0.01799890026450157
Loss at iteration 700 : 0.007051342166960239
Loss at iteration 710 : 0.010726934298872948
Loss at iteration 720 : 0.01346339751034975
Loss at iteration 730 : 0.010653894394636154
Loss at iteration 740 : 0.014599700458347797
Loss at iteration 750 : 0.015900256112217903
Loss at iteration 760 : 0.02408364973962307
Loss at iteration 770 : 0.015817975625395775
Loss at iteration 780 : 0.016062915325164795
Loss at iteration 790 : 0.0097455820068717
Loss at iteration 800 : 0.010907572694122791
Loss at iteration 810 : 0.011013071984052658
Loss at iteration 820 : 0.01195303350687027
Loss at iteration 830 : 0.017102297395467758
Loss at iteration 840 : 0.01587655022740364
Loss at iteration 850 : 0.009597403928637505
Loss at iteration 860 : 0.016643958166241646
Loss at iteration 870 : 0.019065532833337784
Loss at iteration 880 : 0.011102210730314255
Loss at iteration 890 : 0.017257729545235634
Loss at iteration 900 : 0.017512446269392967
Loss at iteration 910 : 0.010397341102361679
Loss at iteration 920 : 0.011293193325400352
Loss at iteration 930 : 0.01102064922451973
Loss at iteration 940 : 0.01344003900885582
Loss at iteration 950 : 0.013705696910619736
Loss at iteration 960 : 0.016269803047180176
Loss at iteration 970 : 0.014335007406771183
Loss at iteration 980 : 0.01158716157078743
Loss at iteration 990 : 0.018022434785962105
Loss at iteration 1000 : 0.01492241770029068
Loss at iteration 1010 : 0.010220829397439957
Loss at iteration 1020 : 0.010162277147173882
Loss at iteration 1030 : 0.010544098913669586
Loss at iteration 1040 : 0.017000366002321243
Loss at iteration 1050 : 0.010422923602163792
Loss at iteration 1060 : 0.011507872492074966
Loss at iteration 1070 : 0.015467880293726921
Loss at iteration 1080 : 0.01204659789800644
Loss at iteration 1090 : 0.014206754975020885
Loss at iteration 1100 : 0.012359105050563812
Loss at iteration 1110 : 0.010470369830727577
Loss at iteration 1120 : 0.007814174517989159
Loss at iteration 1130 : 0.008369265124201775
Loss at iteration 1140 : 0.008804152719676495
Loss at iteration 1150 : 0.017527986317873
Loss at iteration 1160 : 0.013380227610468864
Loss at iteration 1170 : 0.008738921023905277
Loss at iteration 1180 : 0.01176060177385807
Loss at iteration 1190 : 0.012193452566862106
Loss at iteration 1200 : 0.01180000975728035
Loss at iteration 1210 : 0.010937020182609558
The SSIM Value is: 0.7992379426956177
The PSNR Value is: 18.05824432373047
the epoch is: 57
Loss at iteration 10 : 0.016032172366976738
Loss at iteration 20 : 0.008955063298344612
Loss at iteration 30 : 0.0135006969794631
Loss at iteration 40 : 0.01049963477998972
Loss at iteration 50 : 0.013459272682666779
Loss at iteration 60 : 0.007131892256438732
Loss at iteration 70 : 0.008300910703837872
Loss at iteration 80 : 0.014136191457509995
Loss at iteration 90 : 0.014187893830239773
Loss at iteration 100 : 0.014720560982823372
Loss at iteration 110 : 0.019465701654553413
Loss at iteration 120 : 0.007724727503955364
Loss at iteration 130 : 0.012147525325417519
Loss at iteration 140 : 0.006771767511963844
Loss at iteration 150 : 0.008496501483023167
Loss at iteration 160 : 0.013667849823832512
Loss at iteration 170 : 0.01287031639367342
Loss at iteration 180 : 0.010123086161911488
Loss at iteration 190 : 0.019014105200767517
Loss at iteration 200 : 0.008433442562818527
Loss at iteration 210 : 0.011708891950547695
Loss at iteration 220 : 0.015773296356201172
Loss at iteration 230 : 0.013257198967039585
Loss at iteration 240 : 0.016828715801239014
Loss at iteration 250 : 0.017653584480285645
Loss at iteration 260 : 0.012788616120815277
Loss at iteration 270 : 0.014381647109985352
Loss at iteration 280 : 0.017212163656949997
Loss at iteration 290 : 0.017208315432071686
Loss at iteration 300 : 0.009433906525373459
Loss at iteration 310 : 0.012227993458509445
Loss at iteration 320 : 0.014744113199412823
Loss at iteration 330 : 0.006928606424480677
Loss at iteration 340 : 0.007145721465349197
Loss at iteration 350 : 0.011336780153214931
Loss at iteration 360 : 0.011498617008328438
Loss at iteration 370 : 0.011026362888514996
Loss at iteration 380 : 0.010419475845992565
Loss at iteration 390 : 0.018279094249010086
Loss at iteration 400 : 0.010946318507194519
Loss at iteration 410 : 0.01239739079028368
Loss at iteration 420 : 0.009273318573832512
Loss at iteration 430 : 0.009618422016501427
Loss at iteration 440 : 0.008551571518182755
Loss at iteration 450 : 0.010354356840252876
Loss at iteration 460 : 0.0070686498656868935
Loss at iteration 470 : 0.017472486943006516
Loss at iteration 480 : 0.020991545170545578
Loss at iteration 490 : 0.010453322902321815
Loss at iteration 500 : 0.01252981461584568
Loss at iteration 510 : 0.010935608297586441
Loss at iteration 520 : 0.018477391451597214
Loss at iteration 530 : 0.008924544788897038
Loss at iteration 540 : 0.01644405536353588
Loss at iteration 550 : 0.017926471307873726
Loss at iteration 560 : 0.01057374943047762
Loss at iteration 570 : 0.012810985557734966
Loss at iteration 580 : 0.00994617398828268
Loss at iteration 590 : 0.010992743074893951
Loss at iteration 600 : 0.012212462723255157
Loss at iteration 610 : 0.012291635386645794
Loss at iteration 620 : 0.009206635877490044
Loss at iteration 630 : 0.013117987662553787
Loss at iteration 640 : 0.010250750929117203
Loss at iteration 650 : 0.00674248393625021
Loss at iteration 660 : 0.010455705225467682
Loss at iteration 670 : 0.010908767580986023
Loss at iteration 680 : 0.00998360849916935
Loss at iteration 690 : 0.011439216323196888
Loss at iteration 700 : 0.017090698704123497
Loss at iteration 710 : 0.009660441428422928
Loss at iteration 720 : 0.013882055878639221
Loss at iteration 730 : 0.011988107115030289
Loss at iteration 740 : 0.014274057000875473
Loss at iteration 750 : 0.011574766598641872
Loss at iteration 760 : 0.009400911629199982
Loss at iteration 770 : 0.010558809153735638
Loss at iteration 780 : 0.017561234533786774
Loss at iteration 790 : 0.01401870884001255
Loss at iteration 800 : 0.013630226254463196
Loss at iteration 810 : 0.014690764248371124
Loss at iteration 820 : 0.006046014837920666
Loss at iteration 830 : 0.009540430270135403
Loss at iteration 840 : 0.015627477318048477
Loss at iteration 850 : 0.010166655294597149
Loss at iteration 860 : 0.014500289224088192
Loss at iteration 870 : 0.016343744471669197
Loss at iteration 880 : 0.01803728938102722
Loss at iteration 890 : 0.01195395365357399
Loss at iteration 900 : 0.012156693264842033
Loss at iteration 910 : 0.008565111085772514
Loss at iteration 920 : 0.011714251711964607
Loss at iteration 930 : 0.01565200835466385
Loss at iteration 940 : 0.01017061062157154
Loss at iteration 950 : 0.008513495326042175
Loss at iteration 960 : 0.009004014544188976
Loss at iteration 970 : 0.01579873636364937
Loss at iteration 980 : 0.01416093297302723
Loss at iteration 990 : 0.008442837744951248
Loss at iteration 1000 : 0.015390554443001747
Loss at iteration 1010 : 0.016811097040772438
Loss at iteration 1020 : 0.010163819417357445
Loss at iteration 1030 : 0.015224764123558998
Loss at iteration 1040 : 0.013865236192941666
Loss at iteration 1050 : 0.024581965059041977
Loss at iteration 1060 : 0.01798521727323532
Loss at iteration 1070 : 0.00859049055725336
Loss at iteration 1080 : 0.010077151469886303
Loss at iteration 1090 : 0.00570199079811573
Loss at iteration 1100 : 0.012885509990155697
Loss at iteration 1110 : 0.007275697309523821
Loss at iteration 1120 : 0.013266418129205704
Loss at iteration 1130 : 0.019681021571159363
Loss at iteration 1140 : 0.012269193306565285
Loss at iteration 1150 : 0.005518438760191202
Loss at iteration 1160 : 0.011672021821141243
Loss at iteration 1170 : 0.008563395589590073
Loss at iteration 1180 : 0.015359819866716862
Loss at iteration 1190 : 0.01778114214539528
Loss at iteration 1200 : 0.013734724372625351
Loss at iteration 1210 : 0.01009576115757227
The SSIM Value is: 0.8010639627774556
The PSNR Value is: 18.26051820119222
the epoch is: 58
Loss at iteration 10 : 0.009597589261829853
Loss at iteration 20 : 0.01187033113092184
Loss at iteration 30 : 0.013278299942612648
Loss at iteration 40 : 0.011341733857989311
Loss at iteration 50 : 0.005901055410504341
Loss at iteration 60 : 0.009099861606955528
Loss at iteration 70 : 0.016205478459596634
Loss at iteration 80 : 0.007809093222022057
Loss at iteration 90 : 0.007957765832543373
Loss at iteration 100 : 0.016512315720319748
Loss at iteration 110 : 0.013661453500390053
Loss at iteration 120 : 0.011760358698666096
Loss at iteration 130 : 0.015934376046061516
Loss at iteration 140 : 0.014798462390899658
Loss at iteration 150 : 0.008925357833504677
Loss at iteration 160 : 0.011514349840581417
Loss at iteration 170 : 0.008587891235947609
Loss at iteration 180 : 0.016713164746761322
Loss at iteration 190 : 0.013803308829665184
Loss at iteration 200 : 0.008588187396526337
Loss at iteration 210 : 0.012974480167031288
Loss at iteration 220 : 0.01275978609919548
Loss at iteration 230 : 0.009564688429236412
Loss at iteration 240 : 0.0116193238645792
Loss at iteration 250 : 0.01869959384202957
Loss at iteration 260 : 0.007018654607236385
Loss at iteration 270 : 0.01330537162721157
Loss at iteration 280 : 0.010957738384604454
Loss at iteration 290 : 0.014306524768471718
Loss at iteration 300 : 0.015186562202870846
Loss at iteration 310 : 0.009602146223187447
Loss at iteration 320 : 0.01863868162035942
Loss at iteration 330 : 0.014136790297925472
Loss at iteration 340 : 0.011453387327492237
Loss at iteration 350 : 0.006762484088540077
Loss at iteration 360 : 0.01022140122950077
Loss at iteration 370 : 0.007467410992830992
Loss at iteration 380 : 0.014896301552653313
Loss at iteration 390 : 0.007874357514083385
Loss at iteration 400 : 0.010820986703038216
Loss at iteration 410 : 0.010503130033612251
Loss at iteration 420 : 0.01047759409993887
Loss at iteration 430 : 0.017034372314810753
Loss at iteration 440 : 0.011561166495084763
Loss at iteration 450 : 0.0075766039080917835
Loss at iteration 460 : 0.012521298602223396
Loss at iteration 470 : 0.012535380199551582
Loss at iteration 480 : 0.009611660614609718
Loss at iteration 490 : 0.008109218440949917
Loss at iteration 500 : 0.014805719256401062
Loss at iteration 510 : 0.012974601238965988
Loss at iteration 520 : 0.014230431988835335
Loss at iteration 530 : 0.015034551732242107
Loss at iteration 540 : 0.014536427333950996
Loss at iteration 550 : 0.009898953139781952
Loss at iteration 560 : 0.007182179484516382
Loss at iteration 570 : 0.008195007219910622
Loss at iteration 580 : 0.009403800591826439
Loss at iteration 590 : 0.01598210074007511
Loss at iteration 600 : 0.008565869182348251
Loss at iteration 610 : 0.010844845324754715
Loss at iteration 620 : 0.011874734424054623
Loss at iteration 630 : 0.010232968255877495
Loss at iteration 640 : 0.00849792081862688
Loss at iteration 650 : 0.012495450675487518
Loss at iteration 660 : 0.015611193142831326
Loss at iteration 670 : 0.011422141455113888
Loss at iteration 680 : 0.025207243859767914
Loss at iteration 690 : 0.011684351600706577
Loss at iteration 700 : 0.010168904438614845
Loss at iteration 710 : 0.01258849911391735
Loss at iteration 720 : 0.011605323292315006
Loss at iteration 730 : 0.012742681428790092
Loss at iteration 740 : 0.009903923608362675
Loss at iteration 750 : 0.008281872607767582
Loss at iteration 760 : 0.012737668119370937
Loss at iteration 770 : 0.013109262101352215
Loss at iteration 780 : 0.008748859167098999
Loss at iteration 790 : 0.009388737380504608
Loss at iteration 800 : 0.01883104257285595
Loss at iteration 810 : 0.01599859446287155
Loss at iteration 820 : 0.019140014424920082
Loss at iteration 830 : 0.01622641086578369
Loss at iteration 840 : 0.016757376492023468
Loss at iteration 850 : 0.011642538011074066
Loss at iteration 860 : 0.016909077763557434
Loss at iteration 870 : 0.01597318984568119
Loss at iteration 880 : 0.008655405603349209
Loss at iteration 890 : 0.013814008794724941
Loss at iteration 900 : 0.016897298395633698
Loss at iteration 910 : 0.011699171736836433
Loss at iteration 920 : 0.010719286277890205
Loss at iteration 930 : 0.01140418741852045
Loss at iteration 940 : 0.013305946253240108
Loss at iteration 950 : 0.013347351923584938
Loss at iteration 960 : 0.009905295446515083
Loss at iteration 970 : 0.015157116577029228
Loss at iteration 980 : 0.012915629893541336
Loss at iteration 990 : 0.010588545352220535
Loss at iteration 1000 : 0.007771491073071957
Loss at iteration 1010 : 0.015274133533239365
Loss at iteration 1020 : 0.012182329781353474
Loss at iteration 1030 : 0.009352551773190498
Loss at iteration 1040 : 0.013614645227789879
Loss at iteration 1050 : 0.011962457560002804
Loss at iteration 1060 : 0.00935724563896656
Loss at iteration 1070 : 0.011161196045577526
Loss at iteration 1080 : 0.010409444570541382
Loss at iteration 1090 : 0.011973617598414421
Loss at iteration 1100 : 0.008265304379165173
Loss at iteration 1110 : 0.00581701286137104
Loss at iteration 1120 : 0.01584162935614586
Loss at iteration 1130 : 0.008382553234696388
Loss at iteration 1140 : 0.009610791690647602
Loss at iteration 1150 : 0.019381634891033173
Loss at iteration 1160 : 0.014428019523620605
Loss at iteration 1170 : 0.018623311072587967
Loss at iteration 1180 : 0.00982704758644104
Loss at iteration 1190 : 0.011788025498390198
Loss at iteration 1200 : 0.010112237185239792
Loss at iteration 1210 : 0.012054973281919956
The SSIM Value is: 0.8164334416389465
The PSNR Value is: 19.524043464660643
the highest SSIM value is: 19.524043464660643
the epoch is: 59
Loss at iteration 10 : 0.011936947703361511
Loss at iteration 20 : 0.007478553801774979
Loss at iteration 30 : 0.015849700197577477
Loss at iteration 40 : 0.01505563035607338
Loss at iteration 50 : 0.008653013035655022
Loss at iteration 60 : 0.010708851739764214
Loss at iteration 70 : 0.009989110752940178
Loss at iteration 80 : 0.017966795712709427
Loss at iteration 90 : 0.010178321041166782
Loss at iteration 100 : 0.013657649978995323
Loss at iteration 110 : 0.00669661071151495
Loss at iteration 120 : 0.010913517326116562
Loss at iteration 130 : 0.013764233328402042
Loss at iteration 140 : 0.012963701970875263
Loss at iteration 150 : 0.017695853486657143
Loss at iteration 160 : 0.012419530190527439
Loss at iteration 170 : 0.012652361765503883
Loss at iteration 180 : 0.015672892332077026
Loss at iteration 190 : 0.02070850133895874
Loss at iteration 200 : 0.011776532046496868
Loss at iteration 210 : 0.018437698483467102
Loss at iteration 220 : 0.0136041808873415
Loss at iteration 230 : 0.01627250388264656
Loss at iteration 240 : 0.01315009593963623
Loss at iteration 250 : 0.011211840435862541
Loss at iteration 260 : 0.014265257865190506
Loss at iteration 270 : 0.00882028415799141
Loss at iteration 280 : 0.00972045585513115
Loss at iteration 290 : 0.006872338242828846
Loss at iteration 300 : 0.009305234998464584
Loss at iteration 310 : 0.02417765185236931
Loss at iteration 320 : 0.01632506400346756
Loss at iteration 330 : 0.009021341800689697
Loss at iteration 340 : 0.007188416086137295
Loss at iteration 350 : 0.014557253569364548
Loss at iteration 360 : 0.017490049824118614
Loss at iteration 370 : 0.007867947220802307
Loss at iteration 380 : 0.011525098234415054
Loss at iteration 390 : 0.013820402324199677
Loss at iteration 400 : 0.008097234182059765
Loss at iteration 410 : 0.008353805169463158
Loss at iteration 420 : 0.012738995254039764
Loss at iteration 430 : 0.009491361677646637
Loss at iteration 440 : 0.019217971712350845
Loss at iteration 450 : 0.014623965136706829
Loss at iteration 460 : 0.009347097016870975
Loss at iteration 470 : 0.012477625161409378
Loss at iteration 480 : 0.009969109669327736
Loss at iteration 490 : 0.013350292108952999
Loss at iteration 500 : 0.006902213208377361
Loss at iteration 510 : 0.013059023767709732
Loss at iteration 520 : 0.008695626631379128
Loss at iteration 530 : 0.008448412641882896
Loss at iteration 540 : 0.012586016207933426
Loss at iteration 550 : 0.016128206625580788
Loss at iteration 560 : 0.00740756606683135
Loss at iteration 570 : 0.016322355717420578
Loss at iteration 580 : 0.014031615108251572
Loss at iteration 590 : 0.013153379783034325
Loss at iteration 600 : 0.011886157095432281
Loss at iteration 610 : 0.021944094449281693
Loss at iteration 620 : 0.008433664217591286
Loss at iteration 630 : 0.0104988943785429
Loss at iteration 640 : 0.01990319788455963
Loss at iteration 650 : 0.010141090489923954
Loss at iteration 660 : 0.015295709483325481
Loss at iteration 670 : 0.01097332127392292
Loss at iteration 680 : 0.010237254202365875
Loss at iteration 690 : 0.010510880500078201
Loss at iteration 700 : 0.008668603375554085
Loss at iteration 710 : 0.010965877212584019
Loss at iteration 720 : 0.014508584514260292
Loss at iteration 730 : 0.013366669416427612
Loss at iteration 740 : 0.010372597724199295
Loss at iteration 750 : 0.012640806846320629
Loss at iteration 760 : 0.016029438003897667
Loss at iteration 770 : 0.012959797866642475
Loss at iteration 780 : 0.007863564416766167
Loss at iteration 790 : 0.02067943662405014
Loss at iteration 800 : 0.009561849758028984
Loss at iteration 810 : 0.018984509631991386
Loss at iteration 820 : 0.027043353766202927
Loss at iteration 830 : 0.008927127346396446
Loss at iteration 840 : 0.007556751370429993
Loss at iteration 850 : 0.015674451366066933
Loss at iteration 860 : 0.02516310103237629
Loss at iteration 870 : 0.009265759028494358
Loss at iteration 880 : 0.0145952720195055
Loss at iteration 890 : 0.012181944213807583
Loss at iteration 900 : 0.007860329933464527
Loss at iteration 910 : 0.01082536019384861
Loss at iteration 920 : 0.014760756865143776
Loss at iteration 930 : 0.008155453950166702
Loss at iteration 940 : 0.011295609176158905
Loss at iteration 950 : 0.01373518630862236
Loss at iteration 960 : 0.012996924109756947
Loss at iteration 970 : 0.017229806631803513
Loss at iteration 980 : 0.011287154629826546
Loss at iteration 990 : 0.013259942643344402
Loss at iteration 1000 : 0.01132276002317667
Loss at iteration 1010 : 0.009598130360245705
Loss at iteration 1020 : 0.00839902088046074
Loss at iteration 1030 : 0.0077324821613729
Loss at iteration 1040 : 0.010899443179368973
Loss at iteration 1050 : 0.014368978329002857
Loss at iteration 1060 : 0.011710344813764095
Loss at iteration 1070 : 0.012476801872253418
Loss at iteration 1080 : 0.008019824512302876
Loss at iteration 1090 : 0.012920699082314968
Loss at iteration 1100 : 0.010989253409206867
Loss at iteration 1110 : 0.00960614625364542
Loss at iteration 1120 : 0.00935241300612688
Loss at iteration 1130 : 0.011203298345208168
Loss at iteration 1140 : 0.01712051033973694
Loss at iteration 1150 : 0.016977611929178238
Loss at iteration 1160 : 0.00905357114970684
Loss at iteration 1170 : 0.025285903364419937
Loss at iteration 1180 : 0.013624327257275581
Loss at iteration 1190 : 0.012816231697797775
Loss at iteration 1200 : 0.011168104596436024
Loss at iteration 1210 : 0.012291672639548779
The SSIM Value is: 0.7932728091875713
The PSNR Value is: 17.94811922709147
the epoch is: 60
Loss at iteration 10 : 0.009982608258724213
Loss at iteration 20 : 0.013108387589454651
Loss at iteration 30 : 0.01683422550559044
Loss at iteration 40 : 0.008492977358400822
Loss at iteration 50 : 0.010921597480773926
Loss at iteration 60 : 0.019924094900488853
Loss at iteration 70 : 0.011413626372814178
Loss at iteration 80 : 0.011062107980251312
Loss at iteration 90 : 0.010396493598818779
Loss at iteration 100 : 0.01069751475006342
Loss at iteration 110 : 0.016733814030885696
Loss at iteration 120 : 0.0177810937166214
Loss at iteration 130 : 0.014993135817348957
Loss at iteration 140 : 0.010543525218963623
Loss at iteration 150 : 0.013637940399348736
Loss at iteration 160 : 0.01117698848247528
Loss at iteration 170 : 0.016009408980607986
Loss at iteration 180 : 0.011328836902976036
Loss at iteration 190 : 0.010539349168539047
Loss at iteration 200 : 0.012952106073498726
Loss at iteration 210 : 0.01517685130238533
Loss at iteration 220 : 0.014056619256734848
Loss at iteration 230 : 0.019746117293834686
Loss at iteration 240 : 0.010837721638381481
Loss at iteration 250 : 0.011327088810503483
Loss at iteration 260 : 0.009412315674126148
Loss at iteration 270 : 0.0071772923693060875
Loss at iteration 280 : 0.01676979474723339
Loss at iteration 290 : 0.010398033075034618
Loss at iteration 300 : 0.013223350048065186
Loss at iteration 310 : 0.011178119108080864
Loss at iteration 320 : 0.012786567211151123
Loss at iteration 330 : 0.009072352200746536
Loss at iteration 340 : 0.008837776258587837
Loss at iteration 350 : 0.012537715025246143
Loss at iteration 360 : 0.016411136835813522
Loss at iteration 370 : 0.00964946486055851
Loss at iteration 380 : 0.010540377348661423
Loss at iteration 390 : 0.015892429277300835
Loss at iteration 400 : 0.012990634888410568
Loss at iteration 410 : 0.020734887570142746
Loss at iteration 420 : 0.019477810710668564
Loss at iteration 430 : 0.010717891156673431
Loss at iteration 440 : 0.017916832119226456
Loss at iteration 450 : 0.010516971349716187
Loss at iteration 460 : 0.00787266530096531
Loss at iteration 470 : 0.011338603682816029
Loss at iteration 480 : 0.013249147683382034
Loss at iteration 490 : 0.010102106258273125
Loss at iteration 500 : 0.009702484123408794
Loss at iteration 510 : 0.011745228432118893
Loss at iteration 520 : 0.014386545866727829
Loss at iteration 530 : 0.006747720763087273
Loss at iteration 540 : 0.013723764568567276
Loss at iteration 550 : 0.012321890331804752
Loss at iteration 560 : 0.013759167864918709
Loss at iteration 570 : 0.0072130318731069565
Loss at iteration 580 : 0.013106834143400192
Loss at iteration 590 : 0.00878164917230606
Loss at iteration 600 : 0.00838182121515274
Loss at iteration 610 : 0.00777441868558526
Loss at iteration 620 : 0.012931354343891144
Loss at iteration 630 : 0.016077635809779167
Loss at iteration 640 : 0.012805527076125145
Loss at iteration 650 : 0.014299873262643814
Loss at iteration 660 : 0.013549993745982647
Loss at iteration 670 : 0.005943872965872288
Loss at iteration 680 : 0.016954651102423668
Loss at iteration 690 : 0.010339662432670593
Loss at iteration 700 : 0.013954337686300278
Loss at iteration 710 : 0.012840286828577518
Loss at iteration 720 : 0.008678896352648735
Loss at iteration 730 : 0.012739603407680988
Loss at iteration 740 : 0.009954261593520641
Loss at iteration 750 : 0.013963449746370316
Loss at iteration 760 : 0.022551245987415314
Loss at iteration 770 : 0.00854592677205801
Loss at iteration 780 : 0.007448319345712662
Loss at iteration 790 : 0.02134079486131668
Loss at iteration 800 : 0.0123277073726058
Loss at iteration 810 : 0.010096458718180656
Loss at iteration 820 : 0.014523148536682129
Loss at iteration 830 : 0.018282603472471237
Loss at iteration 840 : 0.013143617659807205
Loss at iteration 850 : 0.009541891515254974
Loss at iteration 860 : 0.02433842420578003
Loss at iteration 870 : 0.01305681373924017
Loss at iteration 880 : 0.016090139746665955
Loss at iteration 890 : 0.025556370615959167
Loss at iteration 900 : 0.026436837390065193
Loss at iteration 910 : 0.016756100580096245
Loss at iteration 920 : 0.011901495046913624
Loss at iteration 930 : 0.013087447732686996
Loss at iteration 940 : 0.008087961003184319
Loss at iteration 950 : 0.009935400448739529
Loss at iteration 960 : 0.012945381924510002
Loss at iteration 970 : 0.020648527890443802
Loss at iteration 980 : 0.013920364901423454
Loss at iteration 990 : 0.01103645097464323
Loss at iteration 1000 : 0.015310137532651424
Loss at iteration 1010 : 0.013309202156960964
Loss at iteration 1020 : 0.013876553624868393
Loss at iteration 1030 : 0.010592411272227764
Loss at iteration 1040 : 0.009733115322887897
Loss at iteration 1050 : 0.008502187207341194
Loss at iteration 1060 : 0.024740776047110558
Loss at iteration 1070 : 0.013286516070365906
Loss at iteration 1080 : 0.008201111108064651
Loss at iteration 1090 : 0.011705126613378525
Loss at iteration 1100 : 0.014190034940838814
Loss at iteration 1110 : 0.0161396823823452
Loss at iteration 1120 : 0.01696302928030491
Loss at iteration 1130 : 0.011039343662559986
Loss at iteration 1140 : 0.014367325231432915
Loss at iteration 1150 : 0.007152387872338295
Loss at iteration 1160 : 0.00732462527230382
Loss at iteration 1170 : 0.011315451934933662
Loss at iteration 1180 : 0.008875463157892227
Loss at iteration 1190 : 0.014458238147199154
Loss at iteration 1200 : 0.019470877945423126
Loss at iteration 1210 : 0.010076972655951977
The SSIM Value is: 0.8088469505310059
The PSNR Value is: 18.995927492777508
the epoch is: 61
Loss at iteration 10 : 0.008986181579530239
Loss at iteration 20 : 0.00901487935334444
Loss at iteration 30 : 0.0072280410677194595
Loss at iteration 40 : 0.009994376450777054
Loss at iteration 50 : 0.00906382780522108
Loss at iteration 60 : 0.011687533929944038
Loss at iteration 70 : 0.008174664340913296
Loss at iteration 80 : 0.011250540614128113
Loss at iteration 90 : 0.007188702002167702
Loss at iteration 100 : 0.013733985833823681
Loss at iteration 110 : 0.014197140000760555
Loss at iteration 120 : 0.008098657242953777
Loss at iteration 130 : 0.011060991324484348
Loss at iteration 140 : 0.013404855504631996
Loss at iteration 150 : 0.02364540845155716
Loss at iteration 160 : 0.010979833081364632
Loss at iteration 170 : 0.007721422705799341
Loss at iteration 180 : 0.016857678070664406
Loss at iteration 190 : 0.00813291035592556
Loss at iteration 200 : 0.010089968331158161
Loss at iteration 210 : 0.005517481826245785
Loss at iteration 220 : 0.01000598818063736
Loss at iteration 230 : 0.01559613086283207
Loss at iteration 240 : 0.014212191104888916
Loss at iteration 250 : 0.01093594916164875
Loss at iteration 260 : 0.016375401988625526
Loss at iteration 270 : 0.014409247785806656
Loss at iteration 280 : 0.013196413405239582
Loss at iteration 290 : 0.010450588539242744
Loss at iteration 300 : 0.017112283036112785
Loss at iteration 310 : 0.006205565296113491
Loss at iteration 320 : 0.013990258798003197
Loss at iteration 330 : 0.01041015051305294
Loss at iteration 340 : 0.010171400383114815
Loss at iteration 350 : 0.008851975202560425
Loss at iteration 360 : 0.01271859835833311
Loss at iteration 370 : 0.01341528631746769
Loss at iteration 380 : 0.00933010969310999
Loss at iteration 390 : 0.009097065776586533
Loss at iteration 400 : 0.008076224476099014
Loss at iteration 410 : 0.010196331888437271
Loss at iteration 420 : 0.014076379127800465
Loss at iteration 430 : 0.013607071712613106
Loss at iteration 440 : 0.007468752562999725
Loss at iteration 450 : 0.010814335197210312
Loss at iteration 460 : 0.013226239010691643
Loss at iteration 470 : 0.010280201211571693
Loss at iteration 480 : 0.014949759468436241
Loss at iteration 490 : 0.010818546637892723
Loss at iteration 500 : 0.014320909976959229
Loss at iteration 510 : 0.02164989709854126
Loss at iteration 520 : 0.014365514740347862
Loss at iteration 530 : 0.008134212344884872
Loss at iteration 540 : 0.012712663970887661
Loss at iteration 550 : 0.012223872356116772
Loss at iteration 560 : 0.012440521270036697
Loss at iteration 570 : 0.02017015404999256
Loss at iteration 580 : 0.007152275647968054
Loss at iteration 590 : 0.005412387195974588
Loss at iteration 600 : 0.010116145014762878
Loss at iteration 610 : 0.006875204853713512
Loss at iteration 620 : 0.01001131534576416
Loss at iteration 630 : 0.0160916019231081
Loss at iteration 640 : 0.011290309019386768
Loss at iteration 650 : 0.009800311177968979
Loss at iteration 660 : 0.014301799237728119
Loss at iteration 670 : 0.017465360462665558
Loss at iteration 680 : 0.0047261216677725315
Loss at iteration 690 : 0.010165601968765259
Loss at iteration 700 : 0.011033529415726662
Loss at iteration 710 : 0.00735837034881115
Loss at iteration 720 : 0.011769509874284267
Loss at iteration 730 : 0.017282821238040924
Loss at iteration 740 : 0.01452118530869484
Loss at iteration 750 : 0.009212557226419449
Loss at iteration 760 : 0.009489743039011955
Loss at iteration 770 : 0.01259190309792757
Loss at iteration 780 : 0.010094784200191498
Loss at iteration 790 : 0.009571060538291931
Loss at iteration 800 : 0.013407579623162746
Loss at iteration 810 : 0.012536879628896713
Loss at iteration 820 : 0.0244895089417696
Loss at iteration 830 : 0.017531897872686386
Loss at iteration 840 : 0.012547498568892479
Loss at iteration 850 : 0.01322396844625473
Loss at iteration 860 : 0.013686583377420902
Loss at iteration 870 : 0.014699367806315422
Loss at iteration 880 : 0.008358106948435307
Loss at iteration 890 : 0.011625939048826694
Loss at iteration 900 : 0.013475620187819004
Loss at iteration 910 : 0.010400385595858097
Loss at iteration 920 : 0.014096317812800407
Loss at iteration 930 : 0.015371492132544518
Loss at iteration 940 : 0.012421410530805588
Loss at iteration 950 : 0.01064752135425806
Loss at iteration 960 : 0.006915281526744366
Loss at iteration 970 : 0.01826721988618374
Loss at iteration 980 : 0.009839670732617378
Loss at iteration 990 : 0.010387327522039413
Loss at iteration 1000 : 0.011908864602446556
Loss at iteration 1010 : 0.018370371311903
Loss at iteration 1020 : 0.00799001008272171
Loss at iteration 1030 : 0.01952526718378067
Loss at iteration 1040 : 0.01683747209608555
Loss at iteration 1050 : 0.010746967047452927
Loss at iteration 1060 : 0.012766014784574509
Loss at iteration 1070 : 0.012257924303412437
Loss at iteration 1080 : 0.011268737725913525
Loss at iteration 1090 : 0.009969593957066536
Loss at iteration 1100 : 0.00683211162686348
Loss at iteration 1110 : 0.013528439216315746
Loss at iteration 1120 : 0.006887272000312805
Loss at iteration 1130 : 0.011937975883483887
Loss at iteration 1140 : 0.008668575435876846
Loss at iteration 1150 : 0.010128284804522991
Loss at iteration 1160 : 0.016705121845006943
Loss at iteration 1170 : 0.009290588088333607
Loss at iteration 1180 : 0.011708497069776058
Loss at iteration 1190 : 0.012343600392341614
Loss at iteration 1200 : 0.00870593637228012
Loss at iteration 1210 : 0.018531396985054016
The SSIM Value is: 0.8048734108606974
The PSNR Value is: 18.690347162882485
the epoch is: 62
Loss at iteration 10 : 0.016119444742798805
Loss at iteration 20 : 0.015192443504929543
Loss at iteration 30 : 0.011232681572437286
Loss at iteration 40 : 0.01331466156989336
Loss at iteration 50 : 0.00893024355173111
Loss at iteration 60 : 0.015271914191544056
Loss at iteration 70 : 0.013987990096211433
Loss at iteration 80 : 0.012524506077170372
Loss at iteration 90 : 0.01556399092078209
Loss at iteration 100 : 0.012994165532290936
Loss at iteration 110 : 0.018663503229618073
Loss at iteration 120 : 0.011611842550337315
Loss at iteration 130 : 0.012011116370558739
Loss at iteration 140 : 0.013327324762940407
Loss at iteration 150 : 0.015439318493008614
Loss at iteration 160 : 0.013411704450845718
Loss at iteration 170 : 0.013451945036649704
Loss at iteration 180 : 0.01151172537356615
Loss at iteration 190 : 0.015096504241228104
Loss at iteration 200 : 0.009080993011593819
Loss at iteration 210 : 0.014457952231168747
Loss at iteration 220 : 0.008444084785878658
Loss at iteration 230 : 0.017247270792722702
Loss at iteration 240 : 0.011733245104551315
Loss at iteration 250 : 0.009215490892529488
Loss at iteration 260 : 0.011129933409392834
Loss at iteration 270 : 0.013043256476521492
Loss at iteration 280 : 0.011058391071856022
Loss at iteration 290 : 0.012817760929465294
Loss at iteration 300 : 0.012856991030275822
Loss at iteration 310 : 0.0070154499262571335
Loss at iteration 320 : 0.014998050406575203
Loss at iteration 330 : 0.012487686239182949
Loss at iteration 340 : 0.011668061837553978
Loss at iteration 350 : 0.00960010476410389
Loss at iteration 360 : 0.02331133559346199
Loss at iteration 370 : 0.011546073481440544
Loss at iteration 380 : 0.013471707701683044
Loss at iteration 390 : 0.009308531880378723
Loss at iteration 400 : 0.01137261837720871
Loss at iteration 410 : 0.022629832848906517
Loss at iteration 420 : 0.015564974397420883
Loss at iteration 430 : 0.01155366376042366
Loss at iteration 440 : 0.01052054762840271
Loss at iteration 450 : 0.01926649548113346
Loss at iteration 460 : 0.010693111456930637
Loss at iteration 470 : 0.01509394496679306
Loss at iteration 480 : 0.012791085988283157
Loss at iteration 490 : 0.01931857317686081
Loss at iteration 500 : 0.022760603576898575
Loss at iteration 510 : 0.010077429935336113
Loss at iteration 520 : 0.009298929944634438
Loss at iteration 530 : 0.010969141498208046
Loss at iteration 540 : 0.013462389819324017
Loss at iteration 550 : 0.007262634113430977
Loss at iteration 560 : 0.014954134821891785
Loss at iteration 570 : 0.009535595774650574
Loss at iteration 580 : 0.013447161763906479
Loss at iteration 590 : 0.009005255997180939
Loss at iteration 600 : 0.012244893237948418
Loss at iteration 610 : 0.015519708395004272
Loss at iteration 620 : 0.01907654106616974
Loss at iteration 630 : 0.013670336455106735
Loss at iteration 640 : 0.020053235813975334
Loss at iteration 650 : 0.012619971297681332
Loss at iteration 660 : 0.01382395252585411
Loss at iteration 670 : 0.016542524099349976
Loss at iteration 680 : 0.02170197293162346
Loss at iteration 690 : 0.007778647821396589
Loss at iteration 700 : 0.012095386162400246
Loss at iteration 710 : 0.011235979385674
Loss at iteration 720 : 0.016392184421420097
Loss at iteration 730 : 0.011773772537708282
Loss at iteration 740 : 0.010251747444272041
Loss at iteration 750 : 0.009508525021374226
Loss at iteration 760 : 0.013774508610367775
Loss at iteration 770 : 0.009611999616026878
Loss at iteration 780 : 0.017345260828733444
Loss at iteration 790 : 0.006147080101072788
Loss at iteration 800 : 0.010624740272760391
Loss at iteration 810 : 0.012231787666678429
Loss at iteration 820 : 0.010711650364100933
Loss at iteration 830 : 0.013399266637861729
Loss at iteration 840 : 0.00591241056099534
Loss at iteration 850 : 0.00832419004291296
Loss at iteration 860 : 0.013639120385050774
Loss at iteration 870 : 0.01528552733361721
Loss at iteration 880 : 0.00948339607566595
Loss at iteration 890 : 0.021162666380405426
Loss at iteration 900 : 0.023954294621944427
Loss at iteration 910 : 0.008910615928471088
Loss at iteration 920 : 0.00643883366137743
Loss at iteration 930 : 0.008843149989843369
Loss at iteration 940 : 0.010077424347400665
Loss at iteration 950 : 0.007356408052146435
Loss at iteration 960 : 0.00865511130541563
Loss at iteration 970 : 0.009813857264816761
Loss at iteration 980 : 0.013517688028514385
Loss at iteration 990 : 0.01087326928973198
Loss at iteration 1000 : 0.014049945399165154
Loss at iteration 1010 : 0.014803771860897541
Loss at iteration 1020 : 0.019157622009515762
Loss at iteration 1030 : 0.021254783496260643
Loss at iteration 1040 : 0.00907926820218563
Loss at iteration 1050 : 0.009997472167015076
Loss at iteration 1060 : 0.011931812390685081
Loss at iteration 1070 : 0.01493486575782299
Loss at iteration 1080 : 0.007917109876871109
Loss at iteration 1090 : 0.015384681522846222
Loss at iteration 1100 : 0.009769808501005173
Loss at iteration 1110 : 0.01643717661499977
Loss at iteration 1120 : 0.006979532539844513
Loss at iteration 1130 : 0.011505575850605965
Loss at iteration 1140 : 0.007899133488535881
Loss at iteration 1150 : 0.012057056650519371
Loss at iteration 1160 : 0.009838691912591457
Loss at iteration 1170 : 0.009789537638425827
Loss at iteration 1180 : 0.013070940971374512
Loss at iteration 1190 : 0.01721278950572014
Loss at iteration 1200 : 0.00974561832845211
Loss at iteration 1210 : 0.013691341504454613
The SSIM Value is: 0.8144180695215861
The PSNR Value is: 19.354529444376627
the epoch is: 63
Loss at iteration 10 : 0.011423549614846706
Loss at iteration 20 : 0.017904669046401978
Loss at iteration 30 : 0.016886761412024498
Loss at iteration 40 : 0.007577207870781422
Loss at iteration 50 : 0.011864695698022842
Loss at iteration 60 : 0.010371552780270576
Loss at iteration 70 : 0.012382679618895054
Loss at iteration 80 : 0.008329535834491253
Loss at iteration 90 : 0.007593117188662291
Loss at iteration 100 : 0.007993100211024284
Loss at iteration 110 : 0.011468718759715557
Loss at iteration 120 : 0.006931652780622244
Loss at iteration 130 : 0.007851429283618927
Loss at iteration 140 : 0.01152986753731966
Loss at iteration 150 : 0.009875987656414509
Loss at iteration 160 : 0.015212086960673332
Loss at iteration 170 : 0.012870512902736664
Loss at iteration 180 : 0.013855623081326485
Loss at iteration 190 : 0.012063361704349518
Loss at iteration 200 : 0.012407138012349606
Loss at iteration 210 : 0.015215407125651836
Loss at iteration 220 : 0.009528608061373234
Loss at iteration 230 : 0.007465209346264601
Loss at iteration 240 : 0.01353459246456623
Loss at iteration 250 : 0.02412007376551628
Loss at iteration 260 : 0.011946040205657482
Loss at iteration 270 : 0.008720502257347107
Loss at iteration 280 : 0.014758419245481491
Loss at iteration 290 : 0.009183382615447044
Loss at iteration 300 : 0.008426693268120289
Loss at iteration 310 : 0.008050965145230293
Loss at iteration 320 : 0.014374442398548126
Loss at iteration 330 : 0.014057711698114872
Loss at iteration 340 : 0.027969740331172943
Loss at iteration 350 : 0.010127007961273193
Loss at iteration 360 : 0.015994537621736526
Loss at iteration 370 : 0.005187945440411568
Loss at iteration 380 : 0.016035502776503563
Loss at iteration 390 : 0.01793273724615574
Loss at iteration 400 : 0.01151212677359581
Loss at iteration 410 : 0.008571045473217964
Loss at iteration 420 : 0.012819197960197926
Loss at iteration 430 : 0.012981844134628773
Loss at iteration 440 : 0.01762288436293602
Loss at iteration 450 : 0.005186782218515873
Loss at iteration 460 : 0.015590429306030273
Loss at iteration 470 : 0.01974155753850937
Loss at iteration 480 : 0.010317357257008553
Loss at iteration 490 : 0.009732265025377274
Loss at iteration 500 : 0.010858009569346905
Loss at iteration 510 : 0.01833171397447586
Loss at iteration 520 : 0.014608542434871197
Loss at iteration 530 : 0.010487871244549751
Loss at iteration 540 : 0.010045151226222515
Loss at iteration 550 : 0.013879516161978245
Loss at iteration 560 : 0.010684175416827202
Loss at iteration 570 : 0.012201465666294098
Loss at iteration 580 : 0.010454664006829262
Loss at iteration 590 : 0.00908400397747755
Loss at iteration 600 : 0.008868152275681496
Loss at iteration 610 : 0.016552118584513664
Loss at iteration 620 : 0.016926374286413193
Loss at iteration 630 : 0.011621507816016674
Loss at iteration 640 : 0.009687494486570358
Loss at iteration 650 : 0.00994010642170906
Loss at iteration 660 : 0.009216411039233208
Loss at iteration 670 : 0.009510391391813755
Loss at iteration 680 : 0.008325682953000069
Loss at iteration 690 : 0.009979039430618286
Loss at iteration 700 : 0.015771128237247467
Loss at iteration 710 : 0.01248748879879713
Loss at iteration 720 : 0.01448768563568592
Loss at iteration 730 : 0.014414754696190357
Loss at iteration 740 : 0.010098118335008621
Loss at iteration 750 : 0.008182015269994736
Loss at iteration 760 : 0.010744721628725529
Loss at iteration 770 : 0.013255095109343529
Loss at iteration 780 : 0.011186465620994568
Loss at iteration 790 : 0.01583532989025116
Loss at iteration 800 : 0.014628006145358086
Loss at iteration 810 : 0.018704954534769058
Loss at iteration 820 : 0.007301716599613428
Loss at iteration 830 : 0.019864993169903755
Loss at iteration 840 : 0.009854906238615513
Loss at iteration 850 : 0.009351338259875774
Loss at iteration 860 : 0.011179059743881226
Loss at iteration 870 : 0.006699580233544111
Loss at iteration 880 : 0.01304441224783659
Loss at iteration 890 : 0.01631370559334755
Loss at iteration 900 : 0.016954846680164337
Loss at iteration 910 : 0.007883097976446152
Loss at iteration 920 : 0.009359431453049183
Loss at iteration 930 : 0.0108862966299057
Loss at iteration 940 : 0.012061115354299545
Loss at iteration 950 : 0.007592726498842239
Loss at iteration 960 : 0.016228292137384415
Loss at iteration 970 : 0.01676536723971367
Loss at iteration 980 : 0.016196593642234802
Loss at iteration 990 : 0.011937050148844719
Loss at iteration 1000 : 0.012720087543129921
Loss at iteration 1010 : 0.011416405439376831
Loss at iteration 1020 : 0.014182573184370995
Loss at iteration 1030 : 0.009286457672715187
Loss at iteration 1040 : 0.00433118361979723
Loss at iteration 1050 : 0.015220360830426216
Loss at iteration 1060 : 0.012896622531116009
Loss at iteration 1070 : 0.011526371352374554
Loss at iteration 1080 : 0.011096648871898651
Loss at iteration 1090 : 0.014256749302148819
Loss at iteration 1100 : 0.01383248157799244
Loss at iteration 1110 : 0.009903321042656898
Loss at iteration 1120 : 0.010132945142686367
Loss at iteration 1130 : 0.014761725440621376
Loss at iteration 1140 : 0.013876572251319885
Loss at iteration 1150 : 0.019948504865169525
Loss at iteration 1160 : 0.011726154014468193
Loss at iteration 1170 : 0.011663048528134823
Loss at iteration 1180 : 0.017247268930077553
Loss at iteration 1190 : 0.010611035861074924
Loss at iteration 1200 : 0.02262062579393387
Loss at iteration 1210 : 0.01507535669952631
The SSIM Value is: 0.805395778020223
The PSNR Value is: 18.57782859802246
the epoch is: 64
Loss at iteration 10 : 0.008695128373801708
Loss at iteration 20 : 0.012681934051215649
Loss at iteration 30 : 0.009033532813191414
Loss at iteration 40 : 0.01048955973237753
Loss at iteration 50 : 0.006264392286539078
Loss at iteration 60 : 0.008123081177473068
Loss at iteration 70 : 0.006887990981340408
Loss at iteration 80 : 0.007521303836256266
Loss at iteration 90 : 0.014336137101054192
Loss at iteration 100 : 0.0074763172306120396
Loss at iteration 110 : 0.00808801781386137
Loss at iteration 120 : 0.01115281879901886
Loss at iteration 130 : 0.00920734740793705
Loss at iteration 140 : 0.014909814111888409
Loss at iteration 150 : 0.0075347330421209335
Loss at iteration 160 : 0.016802407801151276
Loss at iteration 170 : 0.009876446798443794
Loss at iteration 180 : 0.009466160088777542
Loss at iteration 190 : 0.01063445769250393
Loss at iteration 200 : 0.007051140535622835
Loss at iteration 210 : 0.011217397637665272
Loss at iteration 220 : 0.009176719933748245
Loss at iteration 230 : 0.010266412980854511
Loss at iteration 240 : 0.010527301579713821
Loss at iteration 250 : 0.011799460276961327
Loss at iteration 260 : 0.006684336811304092
Loss at iteration 270 : 0.009742584079504013
Loss at iteration 280 : 0.011816020123660564
Loss at iteration 290 : 0.015222517773509026
Loss at iteration 300 : 0.012522454373538494
Loss at iteration 310 : 0.01178655307739973
Loss at iteration 320 : 0.009152865968644619
Loss at iteration 330 : 0.013347897678613663
Loss at iteration 340 : 0.012109210714697838
Loss at iteration 350 : 0.010655177757143974
Loss at iteration 360 : 0.011155504733324051
Loss at iteration 370 : 0.011541648767888546
Loss at iteration 380 : 0.00960482470691204
Loss at iteration 390 : 0.008365309797227383
Loss at iteration 400 : 0.006203220225870609
Loss at iteration 410 : 0.018633585423231125
Loss at iteration 420 : 0.030456291511654854
Loss at iteration 430 : 0.012565392069518566
Loss at iteration 440 : 0.024837572127580643
Loss at iteration 450 : 0.020045511424541473
Loss at iteration 460 : 0.01839783787727356
Loss at iteration 470 : 0.014495251700282097
Loss at iteration 480 : 0.012854048050940037
Loss at iteration 490 : 0.012437788769602776
Loss at iteration 500 : 0.011926823295652866
Loss at iteration 510 : 0.013413773849606514
Loss at iteration 520 : 0.011741366237401962
Loss at iteration 530 : 0.011896265670657158
Loss at iteration 540 : 0.007194709964096546
Loss at iteration 550 : 0.010308781638741493
Loss at iteration 560 : 0.017207305878400803
Loss at iteration 570 : 0.008357923477888107
Loss at iteration 580 : 0.014813943766057491
Loss at iteration 590 : 0.013439275324344635
Loss at iteration 600 : 0.012533227913081646
Loss at iteration 610 : 0.005801182705909014
Loss at iteration 620 : 0.010857072658836842
Loss at iteration 630 : 0.010749224573373795
Loss at iteration 640 : 0.008085726760327816
Loss at iteration 650 : 0.008166162297129631
Loss at iteration 660 : 0.01354315597563982
Loss at iteration 670 : 0.010452326387166977
Loss at iteration 680 : 0.014577286317944527
Loss at iteration 690 : 0.009360440075397491
Loss at iteration 700 : 0.012402263469994068
Loss at iteration 710 : 0.02188594453036785
Loss at iteration 720 : 0.007737771142274141
Loss at iteration 730 : 0.008459322154521942
Loss at iteration 740 : 0.01507714856415987
Loss at iteration 750 : 0.013361831195652485
Loss at iteration 760 : 0.012229809537529945
Loss at iteration 770 : 0.008409913629293442
Loss at iteration 780 : 0.021057462319731712
Loss at iteration 790 : 0.019911808893084526
Loss at iteration 800 : 0.018590383231639862
Loss at iteration 810 : 0.0071112364530563354
Loss at iteration 820 : 0.011154105886816978
Loss at iteration 830 : 0.010513558983802795
Loss at iteration 840 : 0.007880149409174919
Loss at iteration 850 : 0.013353392481803894
Loss at iteration 860 : 0.016195222735404968
Loss at iteration 870 : 0.013114998117089272
Loss at iteration 880 : 0.011338368058204651
Loss at iteration 890 : 0.008286112919449806
Loss at iteration 900 : 0.0082950284704566
Loss at iteration 910 : 0.010783109813928604
Loss at iteration 920 : 0.005969740450382233
Loss at iteration 930 : 0.014781922101974487
Loss at iteration 940 : 0.011793297715485096
Loss at iteration 950 : 0.009542714804410934
Loss at iteration 960 : 0.012976066209375858
Loss at iteration 970 : 0.011617659591138363
Loss at iteration 980 : 0.019413834437727928
Loss at iteration 990 : 0.012382777407765388
Loss at iteration 1000 : 0.017656153067946434
Loss at iteration 1010 : 0.007838841527700424
Loss at iteration 1020 : 0.01445407047867775
Loss at iteration 1030 : 0.011025920510292053
Loss at iteration 1040 : 0.010783243924379349
Loss at iteration 1050 : 0.00800096895545721
Loss at iteration 1060 : 0.014605364762246609
Loss at iteration 1070 : 0.01441423874348402
Loss at iteration 1080 : 0.014161568135023117
Loss at iteration 1090 : 0.011808918789029121
Loss at iteration 1100 : 0.02323208563029766
Loss at iteration 1110 : 0.015728149563074112
Loss at iteration 1120 : 0.019536903128027916
Loss at iteration 1130 : 0.02076101116836071
Loss at iteration 1140 : 0.007102660369127989
Loss at iteration 1150 : 0.01176193356513977
Loss at iteration 1160 : 0.013769830577075481
Loss at iteration 1170 : 0.03659820556640625
Loss at iteration 1180 : 0.013259843923151493
Loss at iteration 1190 : 0.01001596637070179
Loss at iteration 1200 : 0.009277377277612686
Loss at iteration 1210 : 0.01742233894765377
The SSIM Value is: 0.8002148310343424
The PSNR Value is: 17.886455154418947
the epoch is: 65
Loss at iteration 10 : 0.008650852367281914
Loss at iteration 20 : 0.010013017803430557
Loss at iteration 30 : 0.01135449018329382
Loss at iteration 40 : 0.015432992950081825
Loss at iteration 50 : 0.010994093492627144
Loss at iteration 60 : 0.012758119963109493
Loss at iteration 70 : 0.008587257005274296
Loss at iteration 80 : 0.012318176217377186
Loss at iteration 90 : 0.014762775972485542
Loss at iteration 100 : 0.013581032864749432
Loss at iteration 110 : 0.022665314376354218
Loss at iteration 120 : 0.007596868090331554
Loss at iteration 130 : 0.006992528215050697
Loss at iteration 140 : 0.014026112854480743
Loss at iteration 150 : 0.009908118285238743
Loss at iteration 160 : 0.009995238855481148
Loss at iteration 170 : 0.0181445125490427
Loss at iteration 180 : 0.01067749410867691
Loss at iteration 190 : 0.006828877609223127
Loss at iteration 200 : 0.023134784772992134
Loss at iteration 210 : 0.006037898361682892
Loss at iteration 220 : 0.012483276426792145
Loss at iteration 230 : 0.013338839635252953
Loss at iteration 240 : 0.018625034019351006
Loss at iteration 250 : 0.010313533246517181
Loss at iteration 260 : 0.009156407788395882
Loss at iteration 270 : 0.014248241670429707
Loss at iteration 280 : 0.011445523239672184
Loss at iteration 290 : 0.011920290067791939
Loss at iteration 300 : 0.0069046844728291035
Loss at iteration 310 : 0.012385305017232895
Loss at iteration 320 : 0.008630404248833656
Loss at iteration 330 : 0.012326742522418499
Loss at iteration 340 : 0.014993847347795963
Loss at iteration 350 : 0.007250970229506493
Loss at iteration 360 : 0.023825297132134438
Loss at iteration 370 : 0.011024472303688526
Loss at iteration 380 : 0.01265450194478035
Loss at iteration 390 : 0.010851710103452206
Loss at iteration 400 : 0.014699643477797508
Loss at iteration 410 : 0.014111412689089775
Loss at iteration 420 : 0.01526561938226223
Loss at iteration 430 : 0.01436309702694416
Loss at iteration 440 : 0.010457982309162617
Loss at iteration 450 : 0.01800626888871193
Loss at iteration 460 : 0.014112086966633797
Loss at iteration 470 : 0.007510403636842966
Loss at iteration 480 : 0.008392967283725739
Loss at iteration 490 : 0.01473008468747139
Loss at iteration 500 : 0.007867599837481976
Loss at iteration 510 : 0.011122715659439564
Loss at iteration 520 : 0.014953536912798882
Loss at iteration 530 : 0.017906920984387398
Loss at iteration 540 : 0.009870041161775589
Loss at iteration 550 : 0.006057454273104668
Loss at iteration 560 : 0.013406386598944664
Loss at iteration 570 : 0.007550849579274654
Loss at iteration 580 : 0.010057937353849411
Loss at iteration 590 : 0.013101845048367977
Loss at iteration 600 : 0.02303871512413025
Loss at iteration 610 : 0.008474412374198437
Loss at iteration 620 : 0.010886082425713539
Loss at iteration 630 : 0.01012447103857994
Loss at iteration 640 : 0.013699736446142197
Loss at iteration 650 : 0.011283806525170803
Loss at iteration 660 : 0.0158160999417305
Loss at iteration 670 : 0.01987716555595398
Loss at iteration 680 : 0.010517749935388565
Loss at iteration 690 : 0.01541054341942072
Loss at iteration 700 : 0.007704498711973429
Loss at iteration 710 : 0.014003165066242218
Loss at iteration 720 : 0.008856168016791344
Loss at iteration 730 : 0.010399321094155312
Loss at iteration 740 : 0.009006280452013016
Loss at iteration 750 : 0.014990735799074173
Loss at iteration 760 : 0.017628716304898262
Loss at iteration 770 : 0.015525981783866882
Loss at iteration 780 : 0.01207546703517437
Loss at iteration 790 : 0.008647497743368149
Loss at iteration 800 : 0.009587579406797886
Loss at iteration 810 : 0.012090668082237244
Loss at iteration 820 : 0.011516682803630829
Loss at iteration 830 : 0.011524920351803303
Loss at iteration 840 : 0.013641197234392166
Loss at iteration 850 : 0.011150320060551167
Loss at iteration 860 : 0.012816004455089569
Loss at iteration 870 : 0.01341172680258751
Loss at iteration 880 : 0.013728623278439045
Loss at iteration 890 : 0.012383142486214638
Loss at iteration 900 : 0.013494439423084259
Loss at iteration 910 : 0.007128827273845673
Loss at iteration 920 : 0.018940147012472153
Loss at iteration 930 : 0.014639055356383324
Loss at iteration 940 : 0.012827310711145401
Loss at iteration 950 : 0.017328910529613495
Loss at iteration 960 : 0.014164668507874012
Loss at iteration 970 : 0.01427060179412365
Loss at iteration 980 : 0.0064100055024027824
Loss at iteration 990 : 0.009232602082192898
Loss at iteration 1000 : 0.01221513468772173
Loss at iteration 1010 : 0.007578516844660044
Loss at iteration 1020 : 0.01012831088155508
Loss at iteration 1030 : 0.006620130036026239
Loss at iteration 1040 : 0.01655806228518486
Loss at iteration 1050 : 0.017668098211288452
Loss at iteration 1060 : 0.012625202536582947
Loss at iteration 1070 : 0.009701881557703018
Loss at iteration 1080 : 0.012534594163298607
Loss at iteration 1090 : 0.010157104581594467
Loss at iteration 1100 : 0.017311803996562958
Loss at iteration 1110 : 0.017392314970493317
Loss at iteration 1120 : 0.011470820754766464
Loss at iteration 1130 : 0.013297954574227333
Loss at iteration 1140 : 0.008587915450334549
Loss at iteration 1150 : 0.018161216750741005
Loss at iteration 1160 : 0.01352495513856411
Loss at iteration 1170 : 0.010205838829278946
Loss at iteration 1180 : 0.01687355525791645
Loss at iteration 1190 : 0.015556765720248222
Loss at iteration 1200 : 0.007008574903011322
Loss at iteration 1210 : 0.007886221632361412
The SSIM Value is: 0.8069456895192464
The PSNR Value is: 18.869512176513673
the epoch is: 66
Loss at iteration 10 : 0.013718795031309128
Loss at iteration 20 : 0.013902302831411362
Loss at iteration 30 : 0.014443272724747658
Loss at iteration 40 : 0.00962863676249981
Loss at iteration 50 : 0.013692045584321022
Loss at iteration 60 : 0.008966309949755669
Loss at iteration 70 : 0.010729997418820858
Loss at iteration 80 : 0.01606196165084839
Loss at iteration 90 : 0.008750872686505318
Loss at iteration 100 : 0.00971392821520567
Loss at iteration 110 : 0.009796243160963058
Loss at iteration 120 : 0.011129558086395264
Loss at iteration 130 : 0.025627467781305313
Loss at iteration 140 : 0.010640881955623627
Loss at iteration 150 : 0.010908675380051136
Loss at iteration 160 : 0.013599097728729248
Loss at iteration 170 : 0.01055905781686306
Loss at iteration 180 : 0.007774930913001299
Loss at iteration 190 : 0.01005680300295353
Loss at iteration 200 : 0.018767666071653366
Loss at iteration 210 : 0.009937438182532787
Loss at iteration 220 : 0.013869000598788261
Loss at iteration 230 : 0.011297807097434998
Loss at iteration 240 : 0.008942293003201485
Loss at iteration 250 : 0.021877141669392586
Loss at iteration 260 : 0.00929205771535635
Loss at iteration 270 : 0.012038471177220345
Loss at iteration 280 : 0.009915116243064404
Loss at iteration 290 : 0.007961789146065712
Loss at iteration 300 : 0.015936605632305145
Loss at iteration 310 : 0.009936361573636532
Loss at iteration 320 : 0.011247803457081318
Loss at iteration 330 : 0.015251567587256432
Loss at iteration 340 : 0.011193497106432915
Loss at iteration 350 : 0.011051766574382782
Loss at iteration 360 : 0.011393226683139801
Loss at iteration 370 : 0.01038581132888794
Loss at iteration 380 : 0.015083066187798977
Loss at iteration 390 : 0.012189473956823349
Loss at iteration 400 : 0.011260604485869408
Loss at iteration 410 : 0.011819126084446907
Loss at iteration 420 : 0.011730892583727837
Loss at iteration 430 : 0.01168779470026493
Loss at iteration 440 : 0.010030893608927727
Loss at iteration 450 : 0.008424077183008194
Loss at iteration 460 : 0.014416228979825974
Loss at iteration 470 : 0.0064000217244029045
Loss at iteration 480 : 0.00991355162113905
Loss at iteration 490 : 0.01153135858476162
Loss at iteration 500 : 0.009409311227500439
Loss at iteration 510 : 0.015712516382336617
Loss at iteration 520 : 0.00844483356922865
Loss at iteration 530 : 0.004522525239735842
Loss at iteration 540 : 0.011947850696742535
Loss at iteration 550 : 0.013545637018978596
Loss at iteration 560 : 0.015147021971642971
Loss at iteration 570 : 0.014067809097468853
Loss at iteration 580 : 0.009054817259311676
Loss at iteration 590 : 0.008480479940772057
Loss at iteration 600 : 0.009309705346822739
Loss at iteration 610 : 0.011723272502422333
Loss at iteration 620 : 0.00971934013068676
Loss at iteration 630 : 0.012620026245713234
Loss at iteration 640 : 0.010803675279021263
Loss at iteration 650 : 0.014467631466686726
Loss at iteration 660 : 0.011455095373094082
Loss at iteration 670 : 0.01729116216301918
Loss at iteration 680 : 0.01236902829259634
Loss at iteration 690 : 0.010718462988734245
Loss at iteration 700 : 0.011516822502017021
Loss at iteration 710 : 0.014445023611187935
Loss at iteration 720 : 0.00616870541125536
Loss at iteration 730 : 0.010164178907871246
Loss at iteration 740 : 0.010470448061823845
Loss at iteration 750 : 0.0113440016284585
Loss at iteration 760 : 0.016746826469898224
Loss at iteration 770 : 0.015980370342731476
Loss at iteration 780 : 0.009130063466727734
Loss at iteration 790 : 0.005123035982251167
Loss at iteration 800 : 0.014570708386600018
Loss at iteration 810 : 0.01281308475881815
Loss at iteration 820 : 0.011292694136500359
Loss at iteration 830 : 0.011194434016942978
Loss at iteration 840 : 0.01294863410294056
Loss at iteration 850 : 0.010790584608912468
Loss at iteration 860 : 0.010463149286806583
Loss at iteration 870 : 0.006922439206391573
Loss at iteration 880 : 0.009222116321325302
Loss at iteration 890 : 0.01613457500934601
Loss at iteration 900 : 0.01141008548438549
Loss at iteration 910 : 0.012137922458350658
Loss at iteration 920 : 0.0135401152074337
Loss at iteration 930 : 0.009537504985928535
Loss at iteration 940 : 0.02731604129076004
Loss at iteration 950 : 0.009632574394345284
Loss at iteration 960 : 0.013073639012873173
Loss at iteration 970 : 0.020633356645703316
Loss at iteration 980 : 0.00684308959171176
Loss at iteration 990 : 0.012455224059522152
Loss at iteration 1000 : 0.022304430603981018
Loss at iteration 1010 : 0.01173657737672329
Loss at iteration 1020 : 0.0091514578089118
Loss at iteration 1030 : 0.014944253489375114
Loss at iteration 1040 : 0.01135735772550106
Loss at iteration 1050 : 0.02302500605583191
Loss at iteration 1060 : 0.008376521989703178
Loss at iteration 1070 : 0.008185097016394138
Loss at iteration 1080 : 0.014009295031428337
Loss at iteration 1090 : 0.011060971766710281
Loss at iteration 1100 : 0.013359260745346546
Loss at iteration 1110 : 0.006869310047477484
Loss at iteration 1120 : 0.01743321307003498
Loss at iteration 1130 : 0.019033633172512054
Loss at iteration 1140 : 0.019148526713252068
Loss at iteration 1150 : 0.013935385271906853
Loss at iteration 1160 : 0.00828423909842968
Loss at iteration 1170 : 0.008832534775137901
Loss at iteration 1180 : 0.007975724525749683
Loss at iteration 1190 : 0.016251247376203537
Loss at iteration 1200 : 0.01502254419028759
Loss at iteration 1210 : 0.01258727815002203
The SSIM Value is: 0.7985222419102986
The PSNR Value is: 18.05504455566406
the epoch is: 67
Loss at iteration 10 : 0.009717805311083794
Loss at iteration 20 : 0.009384248405694962
Loss at iteration 30 : 0.012219350785017014
Loss at iteration 40 : 0.006702682003378868
Loss at iteration 50 : 0.020389705896377563
Loss at iteration 60 : 0.016095787286758423
Loss at iteration 70 : 0.014391359873116016
Loss at iteration 80 : 0.01572185941040516
Loss at iteration 90 : 0.012683022767305374
Loss at iteration 100 : 0.006625433452427387
Loss at iteration 110 : 0.013418643735349178
Loss at iteration 120 : 0.00785896461457014
Loss at iteration 130 : 0.012184996157884598
Loss at iteration 140 : 0.010612363927066326
Loss at iteration 150 : 0.012685353867709637
Loss at iteration 160 : 0.015246603637933731
Loss at iteration 170 : 0.017423441633582115
Loss at iteration 180 : 0.013173680752515793
Loss at iteration 190 : 0.011743176728487015
Loss at iteration 200 : 0.008159860968589783
Loss at iteration 210 : 0.01498997863382101
Loss at iteration 220 : 0.010422434657812119
Loss at iteration 230 : 0.016162266954779625
Loss at iteration 240 : 0.014651486650109291
Loss at iteration 250 : 0.013392478227615356
Loss at iteration 260 : 0.012595386244356632
Loss at iteration 270 : 0.010012648068368435
Loss at iteration 280 : 0.010986109264194965
Loss at iteration 290 : 0.013378501869738102
Loss at iteration 300 : 0.016844291239976883
Loss at iteration 310 : 0.011567259207367897
Loss at iteration 320 : 0.005568391643464565
Loss at iteration 330 : 0.021600812673568726
Loss at iteration 340 : 0.006845255382359028
Loss at iteration 350 : 0.012799639254808426
Loss at iteration 360 : 0.012994212098419666
Loss at iteration 370 : 0.013211189769208431
Loss at iteration 380 : 0.012118763290345669
Loss at iteration 390 : 0.015972044318914413
Loss at iteration 400 : 0.010808169841766357
Loss at iteration 410 : 0.01066554058343172
Loss at iteration 420 : 0.017822211608290672
Loss at iteration 430 : 0.011796794831752777
Loss at iteration 440 : 0.011860683560371399
Loss at iteration 450 : 0.0184028260409832
Loss at iteration 460 : 0.006869613658636808
Loss at iteration 470 : 0.010989638976752758
Loss at iteration 480 : 0.016273895278573036
Loss at iteration 490 : 0.009052898734807968
Loss at iteration 500 : 0.014750627800822258
Loss at iteration 510 : 0.011338967829942703
Loss at iteration 520 : 0.013616558164358139
Loss at iteration 530 : 0.011038895696401596
Loss at iteration 540 : 0.014716116711497307
Loss at iteration 550 : 0.012203102931380272
Loss at iteration 560 : 0.012888990342617035
Loss at iteration 570 : 0.015473591163754463
Loss at iteration 580 : 0.011872773990035057
Loss at iteration 590 : 0.008189840242266655
Loss at iteration 600 : 0.013473575934767723
Loss at iteration 610 : 0.005351378582417965
Loss at iteration 620 : 0.009389886632561684
Loss at iteration 630 : 0.008370022289454937
Loss at iteration 640 : 0.013646380044519901
Loss at iteration 650 : 0.010565618984401226
Loss at iteration 660 : 0.007881135679781437
Loss at iteration 670 : 0.005619186908006668
Loss at iteration 680 : 0.015168008394539356
Loss at iteration 690 : 0.013675671070814133
Loss at iteration 700 : 0.011833125725388527
Loss at iteration 710 : 0.014522337354719639
Loss at iteration 720 : 0.0129229836165905
Loss at iteration 730 : 0.02068074606359005
Loss at iteration 740 : 0.015194563195109367
Loss at iteration 750 : 0.016045711934566498
Loss at iteration 760 : 0.007576897740364075
Loss at iteration 770 : 0.02571387216448784
Loss at iteration 780 : 0.012707076966762543
Loss at iteration 790 : 0.011384918354451656
Loss at iteration 800 : 0.010141553357243538
Loss at iteration 810 : 0.010365861468017101
Loss at iteration 820 : 0.014391469769179821
Loss at iteration 830 : 0.016774721443653107
Loss at iteration 840 : 0.025474458932876587
Loss at iteration 850 : 0.009128755889832973
Loss at iteration 860 : 0.010100603103637695
Loss at iteration 870 : 0.011235829442739487
Loss at iteration 880 : 0.009099530056118965
Loss at iteration 890 : 0.011962205171585083
Loss at iteration 900 : 0.014357649721205235
Loss at iteration 910 : 0.008459463715553284
Loss at iteration 920 : 0.0057969046756625175
Loss at iteration 930 : 0.009455365128815174
Loss at iteration 940 : 0.008479072712361813
Loss at iteration 950 : 0.007859937846660614
Loss at iteration 960 : 0.01657693460583687
Loss at iteration 970 : 0.011149880476295948
Loss at iteration 980 : 0.007222658954560757
Loss at iteration 990 : 0.011575189419090748
Loss at iteration 1000 : 0.008419898338615894
Loss at iteration 1010 : 0.010298988781869411
Loss at iteration 1020 : 0.010000886395573616
Loss at iteration 1030 : 0.00833488442003727
Loss at iteration 1040 : 0.015466848388314247
Loss at iteration 1050 : 0.01100193802267313
Loss at iteration 1060 : 0.007349513936787844
Loss at iteration 1070 : 0.010310446843504906
Loss at iteration 1080 : 0.009518901817500591
Loss at iteration 1090 : 0.014566470868885517
Loss at iteration 1100 : 0.014763114973902702
Loss at iteration 1110 : 0.014365997165441513
Loss at iteration 1120 : 0.012072054669260979
Loss at iteration 1130 : 0.01382541935890913
Loss at iteration 1140 : 0.015398923307657242
Loss at iteration 1150 : 0.011814756318926811
Loss at iteration 1160 : 0.010853610932826996
Loss at iteration 1170 : 0.01382831484079361
Loss at iteration 1180 : 0.011430411599576473
Loss at iteration 1190 : 0.009336147457361221
Loss at iteration 1200 : 0.010243727825582027
Loss at iteration 1210 : 0.016304632648825645
The SSIM Value is: 0.8125831802686055
The PSNR Value is: 18.99671090443929
the epoch is: 68
Loss at iteration 10 : 0.009598227217793465
Loss at iteration 20 : 0.015781864523887634
Loss at iteration 30 : 0.006509891711175442
Loss at iteration 40 : 0.010989177040755749
Loss at iteration 50 : 0.009723294526338577
Loss at iteration 60 : 0.012778779491782188
Loss at iteration 70 : 0.009042080491781235
Loss at iteration 80 : 0.010363608598709106
Loss at iteration 90 : 0.012436441145837307
Loss at iteration 100 : 0.008036382496356964
Loss at iteration 110 : 0.014042573049664497
Loss at iteration 120 : 0.01800219528377056
Loss at iteration 130 : 0.012655899859964848
Loss at iteration 140 : 0.015736881643533707
Loss at iteration 150 : 0.008885856717824936
Loss at iteration 160 : 0.009123584255576134
Loss at iteration 170 : 0.0090658999979496
Loss at iteration 180 : 0.00788898766040802
Loss at iteration 190 : 0.012217053212225437
Loss at iteration 200 : 0.009415531530976295
Loss at iteration 210 : 0.01534187514334917
Loss at iteration 220 : 0.008448908105492592
Loss at iteration 230 : 0.011729169636964798
Loss at iteration 240 : 0.009921809658408165
Loss at iteration 250 : 0.018930533900856972
Loss at iteration 260 : 0.013121062889695168
Loss at iteration 270 : 0.01093733124434948
Loss at iteration 280 : 0.01637100987136364
Loss at iteration 290 : 0.012181516736745834
Loss at iteration 300 : 0.01847858540713787
Loss at iteration 310 : 0.012368674390017986
Loss at iteration 320 : 0.022625412791967392
Loss at iteration 330 : 0.011162843555212021
Loss at iteration 340 : 0.014354005455970764
Loss at iteration 350 : 0.012527432292699814
Loss at iteration 360 : 0.015586033463478088
Loss at iteration 370 : 0.017920739948749542
Loss at iteration 380 : 0.00967083778232336
Loss at iteration 390 : 0.019092310220003128
Loss at iteration 400 : 0.011044500395655632
Loss at iteration 410 : 0.010347447358071804
Loss at iteration 420 : 0.007666874676942825
Loss at iteration 430 : 0.020824745297431946
Loss at iteration 440 : 0.00833672471344471
Loss at iteration 450 : 0.01340264268219471
Loss at iteration 460 : 0.01354427170008421
Loss at iteration 470 : 0.011529246345162392
Loss at iteration 480 : 0.017566725611686707
Loss at iteration 490 : 0.007893325760960579
Loss at iteration 500 : 0.01357618160545826
Loss at iteration 510 : 0.009532726369798183
Loss at iteration 520 : 0.01411903090775013
Loss at iteration 530 : 0.007638503331691027
Loss at iteration 540 : 0.011567823588848114
Loss at iteration 550 : 0.010176966898143291
Loss at iteration 560 : 0.011490827426314354
Loss at iteration 570 : 0.016172023490071297
Loss at iteration 580 : 0.012855324894189835
Loss at iteration 590 : 0.006501035764813423
Loss at iteration 600 : 0.015180956572294235
Loss at iteration 610 : 0.010379461571574211
Loss at iteration 620 : 0.014469211921095848
Loss at iteration 630 : 0.015307586640119553
Loss at iteration 640 : 0.009470872581005096
Loss at iteration 650 : 0.00857466273009777
Loss at iteration 660 : 0.012730046175420284
Loss at iteration 670 : 0.008340157568454742
Loss at iteration 680 : 0.008869173936545849
Loss at iteration 690 : 0.015475601889193058
Loss at iteration 700 : 0.012525543570518494
Loss at iteration 710 : 0.012628600932657719
Loss at iteration 720 : 0.016367580741643906
Loss at iteration 730 : 0.010318515822291374
Loss at iteration 740 : 0.007019209675490856
Loss at iteration 750 : 0.016745707020163536
Loss at iteration 760 : 0.012746402993798256
Loss at iteration 770 : 0.011237889528274536
Loss at iteration 780 : 0.011060322634875774
Loss at iteration 790 : 0.012558937072753906
Loss at iteration 800 : 0.01312156580388546
Loss at iteration 810 : 0.01242372952401638
Loss at iteration 820 : 0.005889472551643848
Loss at iteration 830 : 0.005971410311758518
Loss at iteration 840 : 0.021643593907356262
Loss at iteration 850 : 0.0188735518604517
Loss at iteration 860 : 0.008277039974927902
Loss at iteration 870 : 0.00799871888011694
Loss at iteration 880 : 0.012406342662870884
Loss at iteration 890 : 0.013185916468501091
Loss at iteration 900 : 0.016072459518909454
Loss at iteration 910 : 0.012633000500500202
Loss at iteration 920 : 0.007736118510365486
Loss at iteration 930 : 0.0074751116335392
Loss at iteration 940 : 0.011666799895465374
Loss at iteration 950 : 0.012102402746677399
Loss at iteration 960 : 0.009402249939739704
Loss at iteration 970 : 0.011646242812275887
Loss at iteration 980 : 0.007269653491675854
Loss at iteration 990 : 0.01159505546092987
Loss at iteration 1000 : 0.00679311528801918
Loss at iteration 1010 : 0.017199687659740448
Loss at iteration 1020 : 0.011440359055995941
Loss at iteration 1030 : 0.011842346750199795
Loss at iteration 1040 : 0.01325583178550005
Loss at iteration 1050 : 0.00977252796292305
Loss at iteration 1060 : 0.016607515513896942
Loss at iteration 1070 : 0.022176843136548996
Loss at iteration 1080 : 0.008050465025007725
Loss at iteration 1090 : 0.01210066955536604
Loss at iteration 1100 : 0.011110811494290829
Loss at iteration 1110 : 0.00825805775821209
Loss at iteration 1120 : 0.011183301918208599
Loss at iteration 1130 : 0.011786920949816704
Loss at iteration 1140 : 0.016624728217720985
Loss at iteration 1150 : 0.019791562110185623
Loss at iteration 1160 : 0.00995250977575779
Loss at iteration 1170 : 0.007230174262076616
Loss at iteration 1180 : 0.009682290256023407
Loss at iteration 1190 : 0.009878532961010933
Loss at iteration 1200 : 0.009671329520642757
Loss at iteration 1210 : 0.009542002342641354
The SSIM Value is: 0.8138966242472331
The PSNR Value is: 19.078694025675457
the epoch is: 69
Loss at iteration 10 : 0.012510611675679684
Loss at iteration 20 : 0.009162724949419498
Loss at iteration 30 : 0.008333954960107803
Loss at iteration 40 : 0.006490867119282484
Loss at iteration 50 : 0.011992091313004494
Loss at iteration 60 : 0.013708972372114658
Loss at iteration 70 : 0.013270215131342411
Loss at iteration 80 : 0.016259316354990005
Loss at iteration 90 : 0.0140381446108222
Loss at iteration 100 : 0.012736966833472252
Loss at iteration 110 : 0.008675449527800083
Loss at iteration 120 : 0.012284113094210625
Loss at iteration 130 : 0.017664184793829918
Loss at iteration 140 : 0.012529638595879078
Loss at iteration 150 : 0.008872760459780693
Loss at iteration 160 : 0.014068889431655407
Loss at iteration 170 : 0.011971083469688892
Loss at iteration 180 : 0.009495739825069904
Loss at iteration 190 : 0.013406509533524513
Loss at iteration 200 : 0.006032807286828756
Loss at iteration 210 : 0.021043801680207253
Loss at iteration 220 : 0.023083532229065895
Loss at iteration 230 : 0.008797794580459595
Loss at iteration 240 : 0.010855691507458687
Loss at iteration 250 : 0.009721338748931885
Loss at iteration 260 : 0.00885835662484169
Loss at iteration 270 : 0.015872377902269363
Loss at iteration 280 : 0.013594080694019794
Loss at iteration 290 : 0.0127454474568367
Loss at iteration 300 : 0.012818768620491028
Loss at iteration 310 : 0.011858722195029259
Loss at iteration 320 : 0.012669411487877369
Loss at iteration 330 : 0.008999219164252281
Loss at iteration 340 : 0.010610095225274563
Loss at iteration 350 : 0.013728324323892593
Loss at iteration 360 : 0.010566744022071362
Loss at iteration 370 : 0.010070604272186756
Loss at iteration 380 : 0.013836797326803207
Loss at iteration 390 : 0.011937261559069157
Loss at iteration 400 : 0.011687982827425003
Loss at iteration 410 : 0.01328585296869278
Loss at iteration 420 : 0.00956403836607933
Loss at iteration 430 : 0.007070546504110098
Loss at iteration 440 : 0.013918530195951462
Loss at iteration 450 : 0.012072548270225525
Loss at iteration 460 : 0.011279556900262833
Loss at iteration 470 : 0.009882031008601189
Loss at iteration 480 : 0.007406107150018215
Loss at iteration 490 : 0.008613833226263523
Loss at iteration 500 : 0.008873321115970612
Loss at iteration 510 : 0.015136448666453362
Loss at iteration 520 : 0.010977729223668575
Loss at iteration 530 : 0.00729125551879406
Loss at iteration 540 : 0.009989692829549313
Loss at iteration 550 : 0.013018302619457245
Loss at iteration 560 : 0.015290134586393833
Loss at iteration 570 : 0.008690628223121166
Loss at iteration 580 : 0.005525506101548672
Loss at iteration 590 : 0.008534395135939121
Loss at iteration 600 : 0.01348890457302332
Loss at iteration 610 : 0.009771094657480717
Loss at iteration 620 : 0.006513921543955803
Loss at iteration 630 : 0.008895901031792164
Loss at iteration 640 : 0.0073077320121228695
Loss at iteration 650 : 0.010040241293609142
Loss at iteration 660 : 0.010583111084997654
Loss at iteration 670 : 0.009029539301991463
Loss at iteration 680 : 0.007384166121482849
Loss at iteration 690 : 0.005381446331739426
Loss at iteration 700 : 0.013413339853286743
Loss at iteration 710 : 0.01558128371834755
Loss at iteration 720 : 0.017214879393577576
Loss at iteration 730 : 0.011534806340932846
Loss at iteration 740 : 0.014867529273033142
Loss at iteration 750 : 0.008559877052903175
Loss at iteration 760 : 0.013429787941277027
Loss at iteration 770 : 0.010657540522515774
Loss at iteration 780 : 0.010275336913764477
Loss at iteration 790 : 0.008463595993816853
Loss at iteration 800 : 0.01758471131324768
Loss at iteration 810 : 0.01727377623319626
Loss at iteration 820 : 0.009225750342011452
Loss at iteration 830 : 0.01537606306374073
Loss at iteration 840 : 0.011865225620567799
Loss at iteration 850 : 0.01471463218331337
Loss at iteration 860 : 0.012293700128793716
Loss at iteration 870 : 0.013850807212293148
Loss at iteration 880 : 0.021480852738022804
Loss at iteration 890 : 0.003130342811346054
Loss at iteration 900 : 0.013288598507642746
Loss at iteration 910 : 0.013193361461162567
Loss at iteration 920 : 0.010752692818641663
Loss at iteration 930 : 0.013928409665822983
Loss at iteration 940 : 0.011944330297410488
Loss at iteration 950 : 0.008635497651994228
Loss at iteration 960 : 0.00822803471237421
Loss at iteration 970 : 0.01786762848496437
Loss at iteration 980 : 0.012328187003731728
Loss at iteration 990 : 0.01468939334154129
Loss at iteration 1000 : 0.009493280202150345
Loss at iteration 1010 : 0.012016771361231804
Loss at iteration 1020 : 0.013285517692565918
Loss at iteration 1030 : 0.012141339480876923
Loss at iteration 1040 : 0.005512638948857784
Loss at iteration 1050 : 0.013419157825410366
Loss at iteration 1060 : 0.023003291338682175
Loss at iteration 1070 : 0.014358977787196636
Loss at iteration 1080 : 0.014590333215892315
Loss at iteration 1090 : 0.012640691362321377
Loss at iteration 1100 : 0.012768157757818699
Loss at iteration 1110 : 0.015280351974070072
Loss at iteration 1120 : 0.009951415471732616
Loss at iteration 1130 : 0.012329437769949436
Loss at iteration 1140 : 0.014061888679862022
Loss at iteration 1150 : 0.009173091500997543
Loss at iteration 1160 : 0.013865670189261436
Loss at iteration 1170 : 0.012802152894437313
Loss at iteration 1180 : 0.014755682088434696
Loss at iteration 1190 : 0.01572617143392563
Loss at iteration 1200 : 0.01986217498779297
Loss at iteration 1210 : 0.017782066017389297
The SSIM Value is: 0.8022235592206319
The PSNR Value is: 18.4020289738973
the epoch is: 70
Loss at iteration 10 : 0.009751754812896252
Loss at iteration 20 : 0.00900325458496809
Loss at iteration 30 : 0.00757232028990984
Loss at iteration 40 : 0.01054525375366211
Loss at iteration 50 : 0.006384151056408882
Loss at iteration 60 : 0.007016207091510296
Loss at iteration 70 : 0.013115203008055687
Loss at iteration 80 : 0.009871709160506725
Loss at iteration 90 : 0.01388783659785986
Loss at iteration 100 : 0.013745862059295177
Loss at iteration 110 : 0.008351915515959263
Loss at iteration 120 : 0.009190158918499947
Loss at iteration 130 : 0.009927649982273579
Loss at iteration 140 : 0.00963347963988781
Loss at iteration 150 : 0.010976461693644524
Loss at iteration 160 : 0.008881742134690285
Loss at iteration 170 : 0.012933902442455292
Loss at iteration 180 : 0.009827852249145508
Loss at iteration 190 : 0.010547834448516369
Loss at iteration 200 : 0.016304032877087593
Loss at iteration 210 : 0.015279978513717651
Loss at iteration 220 : 0.007304102182388306
Loss at iteration 230 : 0.009326335042715073
Loss at iteration 240 : 0.010480242781341076
Loss at iteration 250 : 0.01670129783451557
Loss at iteration 260 : 0.010100530460476875
Loss at iteration 270 : 0.010448964312672615
Loss at iteration 280 : 0.015322783961892128
Loss at iteration 290 : 0.012270585633814335
Loss at iteration 300 : 0.009724435396492481
Loss at iteration 310 : 0.013184173963963985
Loss at iteration 320 : 0.009701108559966087
Loss at iteration 330 : 0.01147441565990448
Loss at iteration 340 : 0.012882335111498833
Loss at iteration 350 : 0.01841295138001442
Loss at iteration 360 : 0.011409323662519455
Loss at iteration 370 : 0.019043156877160072
Loss at iteration 380 : 0.02210889384150505
Loss at iteration 390 : 0.011200251057744026
Loss at iteration 400 : 0.00996018573641777
Loss at iteration 410 : 0.010721433907747269
Loss at iteration 420 : 0.006631619296967983
Loss at iteration 430 : 0.014940854161977768
Loss at iteration 440 : 0.010519757866859436
Loss at iteration 450 : 0.011616193689405918
Loss at iteration 460 : 0.0065361992456018925
Loss at iteration 470 : 0.007522180676460266
Loss at iteration 480 : 0.007083002477884293
Loss at iteration 490 : 0.01207929290831089
Loss at iteration 500 : 0.013248885050415993
Loss at iteration 510 : 0.00855221040546894
Loss at iteration 520 : 0.007541315630078316
Loss at iteration 530 : 0.022171376273036003
Loss at iteration 540 : 0.011021830141544342
Loss at iteration 550 : 0.011383945122361183
Loss at iteration 560 : 0.015245353803038597
Loss at iteration 570 : 0.010719157755374908
Loss at iteration 580 : 0.017616361379623413
Loss at iteration 590 : 0.015896853059530258
Loss at iteration 600 : 0.01024216040968895
Loss at iteration 610 : 0.011783132329583168
Loss at iteration 620 : 0.008981755003333092
Loss at iteration 630 : 0.012924938462674618
Loss at iteration 640 : 0.01679230108857155
Loss at iteration 650 : 0.01958281546831131
Loss at iteration 660 : 0.011542778462171555
Loss at iteration 670 : 0.011547846719622612
Loss at iteration 680 : 0.013370031490921974
Loss at iteration 690 : 0.009867589920759201
Loss at iteration 700 : 0.009907727129757404
Loss at iteration 710 : 0.018074752762913704
Loss at iteration 720 : 0.017461741343140602
Loss at iteration 730 : 0.011726222932338715
Loss at iteration 740 : 0.01004995871335268
Loss at iteration 750 : 0.0052360426634550095
Loss at iteration 760 : 0.008199415169656277
Loss at iteration 770 : 0.010118462145328522
Loss at iteration 780 : 0.02251744642853737
Loss at iteration 790 : 0.009400821290910244
Loss at iteration 800 : 0.009148076176643372
Loss at iteration 810 : 0.010968883521854877
Loss at iteration 820 : 0.011068107560276985
Loss at iteration 830 : 0.016813647001981735
Loss at iteration 840 : 0.020547546446323395
Loss at iteration 850 : 0.0200498066842556
Loss at iteration 860 : 0.012646698392927647
Loss at iteration 870 : 0.011083921417593956
Loss at iteration 880 : 0.015991967171430588
Loss at iteration 890 : 0.011988005600869656
Loss at iteration 900 : 0.017649516463279724
Loss at iteration 910 : 0.010819677263498306
Loss at iteration 920 : 0.013977640308439732
Loss at iteration 930 : 0.006324470974504948
Loss at iteration 940 : 0.0063011785969138145
Loss at iteration 950 : 0.008022374473512173
Loss at iteration 960 : 0.007763412781059742
Loss at iteration 970 : 0.013619516044855118
Loss at iteration 980 : 0.010684454813599586
Loss at iteration 990 : 0.015865439549088478
Loss at iteration 1000 : 0.008460447192192078
Loss at iteration 1010 : 0.01368360873311758
Loss at iteration 1020 : 0.008074505254626274
Loss at iteration 1030 : 0.013486675918102264
Loss at iteration 1040 : 0.012364756315946579
Loss at iteration 1050 : 0.00804704800248146
Loss at iteration 1060 : 0.01732012815773487
Loss at iteration 1070 : 0.01657901145517826
Loss at iteration 1080 : 0.01157500222325325
Loss at iteration 1090 : 0.0109293507412076
Loss at iteration 1100 : 0.008333651348948479
Loss at iteration 1110 : 0.00995870865881443
Loss at iteration 1120 : 0.011051079258322716
Loss at iteration 1130 : 0.0050243497826159
Loss at iteration 1140 : 0.013473947532474995
Loss at iteration 1150 : 0.013173647224903107
Loss at iteration 1160 : 0.01792396791279316
Loss at iteration 1170 : 0.007707017939537764
Loss at iteration 1180 : 0.011330138891935349
Loss at iteration 1190 : 0.01030515693128109
Loss at iteration 1200 : 0.01700608991086483
Loss at iteration 1210 : 0.00923348218202591
The SSIM Value is: 0.8110767126083374
The PSNR Value is: 19.060174433390298
the epoch is: 71
Loss at iteration 10 : 0.011856138706207275
Loss at iteration 20 : 0.013527040369808674
Loss at iteration 30 : 0.00894859153777361
Loss at iteration 40 : 0.009999372996389866
Loss at iteration 50 : 0.012926977127790451
Loss at iteration 60 : 0.008987130597233772
Loss at iteration 70 : 0.015168161131441593
Loss at iteration 80 : 0.013807587325572968
Loss at iteration 90 : 0.010674180462956429
Loss at iteration 100 : 0.008907174691557884
Loss at iteration 110 : 0.010964663699269295
Loss at iteration 120 : 0.007127728778868914
Loss at iteration 130 : 0.012211899273097515
Loss at iteration 140 : 0.013168562203645706
Loss at iteration 150 : 0.009759580716490746
Loss at iteration 160 : 0.015336766839027405
Loss at iteration 170 : 0.008480977267026901
Loss at iteration 180 : 0.014153368771076202
Loss at iteration 190 : 0.0067786481231451035
Loss at iteration 200 : 0.013346090912818909
Loss at iteration 210 : 0.014487054198980331
Loss at iteration 220 : 0.01608823798596859
Loss at iteration 230 : 0.008840478025376797
Loss at iteration 240 : 0.009977079927921295
Loss at iteration 250 : 0.012301739305257797
Loss at iteration 260 : 0.010089694522321224
Loss at iteration 270 : 0.012204975821077824
Loss at iteration 280 : 0.007156753446906805
Loss at iteration 290 : 0.011506164446473122
Loss at iteration 300 : 0.013343963772058487
Loss at iteration 310 : 0.013890620321035385
Loss at iteration 320 : 0.009978733956813812
Loss at iteration 330 : 0.009651154279708862
Loss at iteration 340 : 0.009474252350628376
Loss at iteration 350 : 0.012479683384299278
Loss at iteration 360 : 0.011440936475992203
Loss at iteration 370 : 0.024762053042650223
Loss at iteration 380 : 0.01282590813934803
Loss at iteration 390 : 0.011852477677166462
Loss at iteration 400 : 0.014831727370619774
Loss at iteration 410 : 0.0105756726115942
Loss at iteration 420 : 0.011467000469565392
Loss at iteration 430 : 0.01669490709900856
Loss at iteration 440 : 0.01188095286488533
Loss at iteration 450 : 0.011497590690851212
Loss at iteration 460 : 0.010055964812636375
Loss at iteration 470 : 0.00951550155878067
Loss at iteration 480 : 0.01278197206556797
Loss at iteration 490 : 0.00544388173148036
Loss at iteration 500 : 0.01481621153652668
Loss at iteration 510 : 0.013217825442552567
Loss at iteration 520 : 0.00798574648797512
Loss at iteration 530 : 0.01333355437964201
Loss at iteration 540 : 0.014124020002782345
Loss at iteration 550 : 0.009196056984364986
Loss at iteration 560 : 0.009228148497641087
Loss at iteration 570 : 0.007507130969315767
Loss at iteration 580 : 0.008948709815740585
Loss at iteration 590 : 0.01250753179192543
Loss at iteration 600 : 0.012913298793137074
Loss at iteration 610 : 0.011439897119998932
Loss at iteration 620 : 0.01488944236189127
Loss at iteration 630 : 0.008253918960690498
Loss at iteration 640 : 0.016184212639927864
Loss at iteration 650 : 0.010923258028924465
Loss at iteration 660 : 0.01260281726717949
Loss at iteration 670 : 0.019292514771223068
Loss at iteration 680 : 0.01787097565829754
Loss at iteration 690 : 0.00972864218056202
Loss at iteration 700 : 0.017044465988874435
Loss at iteration 710 : 0.012847382575273514
Loss at iteration 720 : 0.010829498060047626
Loss at iteration 730 : 0.011896837502717972
Loss at iteration 740 : 0.009267566725611687
Loss at iteration 750 : 0.016957737505435944
Loss at iteration 760 : 0.013161258772015572
Loss at iteration 770 : 0.0089797992259264
Loss at iteration 780 : 0.008792690932750702
Loss at iteration 790 : 0.015922127291560173
Loss at iteration 800 : 0.017422020435333252
Loss at iteration 810 : 0.00585064897313714
Loss at iteration 820 : 0.012537180446088314
Loss at iteration 830 : 0.01224273070693016
Loss at iteration 840 : 0.014831990003585815
Loss at iteration 850 : 0.013018375262618065
Loss at iteration 860 : 0.011346694082021713
Loss at iteration 870 : 0.010057913139462471
Loss at iteration 880 : 0.0053830076940357685
Loss at iteration 890 : 0.01014036312699318
Loss at iteration 900 : 0.010290342383086681
Loss at iteration 910 : 0.010773317888379097
Loss at iteration 920 : 0.01286290492862463
Loss at iteration 930 : 0.009942950680851936
Loss at iteration 940 : 0.011813675984740257
Loss at iteration 950 : 0.009342270903289318
Loss at iteration 960 : 0.012746934778988361
Loss at iteration 970 : 0.011363646015524864
Loss at iteration 980 : 0.015512790530920029
Loss at iteration 990 : 0.01726696826517582
Loss at iteration 1000 : 0.009661722928285599
Loss at iteration 1010 : 0.019213762134313583
Loss at iteration 1020 : 0.009580666199326515
Loss at iteration 1030 : 0.01269770972430706
Loss at iteration 1040 : 0.009933184832334518
Loss at iteration 1050 : 0.006852691527456045
Loss at iteration 1060 : 0.008136543445289135
Loss at iteration 1070 : 0.012674294412136078
Loss at iteration 1080 : 0.016242584213614464
Loss at iteration 1090 : 0.0119092408567667
Loss at iteration 1100 : 0.012415348552167416
Loss at iteration 1110 : 0.01294906809926033
Loss at iteration 1120 : 0.012513246387243271
Loss at iteration 1130 : 0.007688682526350021
Loss at iteration 1140 : 0.014958631247282028
Loss at iteration 1150 : 0.011097821407020092
Loss at iteration 1160 : 0.013917525298893452
Loss at iteration 1170 : 0.012488194741308689
Loss at iteration 1180 : 0.011972040869295597
Loss at iteration 1190 : 0.00791730172932148
Loss at iteration 1200 : 0.01389308087527752
Loss at iteration 1210 : 0.008156392723321915
The SSIM Value is: 0.8124200344085694
The PSNR Value is: 18.983836682637534
the epoch is: 72
Loss at iteration 10 : 0.01647857576608658
Loss at iteration 20 : 0.0073586017824709415
Loss at iteration 30 : 0.013640670105814934
Loss at iteration 40 : 0.008222278207540512
Loss at iteration 50 : 0.011713117361068726
Loss at iteration 60 : 0.008629241958260536
Loss at iteration 70 : 0.015022742561995983
Loss at iteration 80 : 0.008906751871109009
Loss at iteration 90 : 0.008203069679439068
Loss at iteration 100 : 0.0084198834374547
Loss at iteration 110 : 0.016996562480926514
Loss at iteration 120 : 0.014861669391393661
Loss at iteration 130 : 0.011600328609347343
Loss at iteration 140 : 0.010319681838154793
Loss at iteration 150 : 0.009006545878946781
Loss at iteration 160 : 0.007316112518310547
Loss at iteration 170 : 0.010414055548608303
Loss at iteration 180 : 0.008681176230311394
Loss at iteration 190 : 0.020824410021305084
Loss at iteration 200 : 0.010029410943388939
Loss at iteration 210 : 0.008476589806377888
Loss at iteration 220 : 0.011792633682489395
Loss at iteration 230 : 0.015803826972842216
Loss at iteration 240 : 0.013568209484219551
Loss at iteration 250 : 0.010963868349790573
Loss at iteration 260 : 0.013888048008084297
Loss at iteration 270 : 0.01362732332199812
Loss at iteration 280 : 0.008728536777198315
Loss at iteration 290 : 0.018885206431150436
Loss at iteration 300 : 0.01598408818244934
Loss at iteration 310 : 0.014899848960340023
Loss at iteration 320 : 0.0164964497089386
Loss at iteration 330 : 0.011104532517492771
Loss at iteration 340 : 0.008805638179183006
Loss at iteration 350 : 0.008701728656888008
Loss at iteration 360 : 0.01364956796169281
Loss at iteration 370 : 0.011169950477778912
Loss at iteration 380 : 0.017196765169501305
Loss at iteration 390 : 0.009386451914906502
Loss at iteration 400 : 0.016924114897847176
Loss at iteration 410 : 0.012341589666903019
Loss at iteration 420 : 0.013550174422562122
Loss at iteration 430 : 0.011546827852725983
Loss at iteration 440 : 0.009224271401762962
Loss at iteration 450 : 0.012301258742809296
Loss at iteration 460 : 0.008677619509398937
Loss at iteration 470 : 0.011799857020378113
Loss at iteration 480 : 0.01962103322148323
Loss at iteration 490 : 0.017401747405529022
Loss at iteration 500 : 0.018513508141040802
Loss at iteration 510 : 0.012574004009366035
Loss at iteration 520 : 0.013848556205630302
Loss at iteration 530 : 0.008070116862654686
Loss at iteration 540 : 0.013148711994290352
Loss at iteration 550 : 0.00749787874519825
Loss at iteration 560 : 0.011830233037471771
Loss at iteration 570 : 0.01601823791861534
Loss at iteration 580 : 0.011116266250610352
Loss at iteration 590 : 0.01501421257853508
Loss at iteration 600 : 0.0087325694039464
Loss at iteration 610 : 0.008858518674969673
Loss at iteration 620 : 0.010239949449896812
Loss at iteration 630 : 0.0142818633466959
Loss at iteration 640 : 0.013839283026754856
Loss at iteration 650 : 0.015159275382757187
Loss at iteration 660 : 0.020278044044971466
Loss at iteration 670 : 0.01546323113143444
Loss at iteration 680 : 0.017081236466765404
Loss at iteration 690 : 0.01008695363998413
Loss at iteration 700 : 0.013959230855107307
Loss at iteration 710 : 0.010654532350599766
Loss at iteration 720 : 0.01171819493174553
Loss at iteration 730 : 0.011918408796191216
Loss at iteration 740 : 0.014384281821548939
Loss at iteration 750 : 0.01840672269463539
Loss at iteration 760 : 0.005625867750495672
Loss at iteration 770 : 0.006391366012394428
Loss at iteration 780 : 0.017205923795700073
Loss at iteration 790 : 0.014176048338413239
Loss at iteration 800 : 0.013974558562040329
Loss at iteration 810 : 0.010768178850412369
Loss at iteration 820 : 0.008965054526925087
Loss at iteration 830 : 0.012716642580926418
Loss at iteration 840 : 0.008630277588963509
Loss at iteration 850 : 0.007892375811934471
Loss at iteration 860 : 0.0146553423255682
Loss at iteration 870 : 0.010042691603302956
Loss at iteration 880 : 0.011154195293784142
Loss at iteration 890 : 0.008575530722737312
Loss at iteration 900 : 0.008734354749321938
Loss at iteration 910 : 0.011053793132305145
Loss at iteration 920 : 0.010079827159643173
Loss at iteration 930 : 0.013156050816178322
Loss at iteration 940 : 0.011622950434684753
Loss at iteration 950 : 0.014439349062740803
Loss at iteration 960 : 0.011033296585083008
Loss at iteration 970 : 0.007260930724442005
Loss at iteration 980 : 0.012325859628617764
Loss at iteration 990 : 0.013320185244083405
Loss at iteration 1000 : 0.009217735379934311
Loss at iteration 1010 : 0.01144828088581562
Loss at iteration 1020 : 0.01333952508866787
Loss at iteration 1030 : 0.013000006787478924
Loss at iteration 1040 : 0.007080843672156334
Loss at iteration 1050 : 0.007512275129556656
Loss at iteration 1060 : 0.012818391434848309
Loss at iteration 1070 : 0.02291177026927471
Loss at iteration 1080 : 0.008763985708355904
Loss at iteration 1090 : 0.013603976927697659
Loss at iteration 1100 : 0.011019554920494556
Loss at iteration 1110 : 0.006602664943784475
Loss at iteration 1120 : 0.023037156090140343
Loss at iteration 1130 : 0.007685428950935602
Loss at iteration 1140 : 0.012089774012565613
Loss at iteration 1150 : 0.010227487422525883
Loss at iteration 1160 : 0.010930104181170464
Loss at iteration 1170 : 0.010047243908047676
Loss at iteration 1180 : 0.020607519894838333
Loss at iteration 1190 : 0.007352599874138832
Loss at iteration 1200 : 0.011983784846961498
Loss at iteration 1210 : 0.011155623942613602
The SSIM Value is: 0.8077844897905986
The PSNR Value is: 18.923511250813803
the epoch is: 73
Loss at iteration 10 : 0.006984332110732794
Loss at iteration 20 : 0.008883493021130562
Loss at iteration 30 : 0.010884944349527359
Loss at iteration 40 : 0.01395257469266653
Loss at iteration 50 : 0.010137148201465607
Loss at iteration 60 : 0.014575336128473282
Loss at iteration 70 : 0.011324457824230194
Loss at iteration 80 : 0.008195505477488041
Loss at iteration 90 : 0.017078200355172157
Loss at iteration 100 : 0.008092081174254417
Loss at iteration 110 : 0.013538317754864693
Loss at iteration 120 : 0.008127537555992603
Loss at iteration 130 : 0.01622605137526989
Loss at iteration 140 : 0.00833897851407528
Loss at iteration 150 : 0.008646517060697079
Loss at iteration 160 : 0.011926290579140186
Loss at iteration 170 : 0.013815630227327347
Loss at iteration 180 : 0.011446228250861168
Loss at iteration 190 : 0.019666019827127457
Loss at iteration 200 : 0.009675330482423306
Loss at iteration 210 : 0.006788530386984348
Loss at iteration 220 : 0.008635860867798328
Loss at iteration 230 : 0.011331435292959213
Loss at iteration 240 : 0.020843295380473137
Loss at iteration 250 : 0.009866874665021896
Loss at iteration 260 : 0.014528675004839897
Loss at iteration 270 : 0.010968070477247238
Loss at iteration 280 : 0.006547527387738228
Loss at iteration 290 : 0.007958587259054184
Loss at iteration 300 : 0.006161490920931101
Loss at iteration 310 : 0.014783540740609169
Loss at iteration 320 : 0.01703028753399849
Loss at iteration 330 : 0.012008309364318848
Loss at iteration 340 : 0.011142086237668991
Loss at iteration 350 : 0.006928375922143459
Loss at iteration 360 : 0.0208453182131052
Loss at iteration 370 : 0.011231371201574802
Loss at iteration 380 : 0.008118478581309319
Loss at iteration 390 : 0.012173780240118504
Loss at iteration 400 : 0.01527208462357521
Loss at iteration 410 : 0.010048226453363895
Loss at iteration 420 : 0.013028869405388832
Loss at iteration 430 : 0.007521528750658035
Loss at iteration 440 : 0.01011571940034628
Loss at iteration 450 : 0.008898194879293442
Loss at iteration 460 : 0.011580637656152248
Loss at iteration 470 : 0.009943867102265358
Loss at iteration 480 : 0.020471151918172836
Loss at iteration 490 : 0.007811480201780796
Loss at iteration 500 : 0.007717910222709179
Loss at iteration 510 : 0.017342180013656616
Loss at iteration 520 : 0.012553001753985882
Loss at iteration 530 : 0.015160715207457542
Loss at iteration 540 : 0.004470692947506905
Loss at iteration 550 : 0.012338017113506794
Loss at iteration 560 : 0.013411121442914009
Loss at iteration 570 : 0.014598468318581581
Loss at iteration 580 : 0.013041861355304718
Loss at iteration 590 : 0.009949080646038055
Loss at iteration 600 : 0.01533759105950594
Loss at iteration 610 : 0.01368736196309328
Loss at iteration 620 : 0.009761516004800797
Loss at iteration 630 : 0.010289349593222141
Loss at iteration 640 : 0.01737911067903042
Loss at iteration 650 : 0.009081571362912655
Loss at iteration 660 : 0.00908089242875576
Loss at iteration 670 : 0.007584035396575928
Loss at iteration 680 : 0.009556709788739681
Loss at iteration 690 : 0.012110251933336258
Loss at iteration 700 : 0.01230001449584961
Loss at iteration 710 : 0.008554056286811829
Loss at iteration 720 : 0.011021370068192482
Loss at iteration 730 : 0.013604164123535156
Loss at iteration 740 : 0.011817164719104767
Loss at iteration 750 : 0.008061304688453674
Loss at iteration 760 : 0.011955317109823227
Loss at iteration 770 : 0.013772867619991302
Loss at iteration 780 : 0.014464974403381348
Loss at iteration 790 : 0.00919480249285698
Loss at iteration 800 : 0.017578687518835068
Loss at iteration 810 : 0.010893142782151699
Loss at iteration 820 : 0.011321436613798141
Loss at iteration 830 : 0.008774546906352043
Loss at iteration 840 : 0.017726238816976547
Loss at iteration 850 : 0.007428039330989122
Loss at iteration 860 : 0.006407583132386208
Loss at iteration 870 : 0.010060129687190056
Loss at iteration 880 : 0.013139261864125729
Loss at iteration 890 : 0.010407419875264168
Loss at iteration 900 : 0.015358959324657917
Loss at iteration 910 : 0.015916645526885986
Loss at iteration 920 : 0.006746442057192326
Loss at iteration 930 : 0.023884646594524384
Loss at iteration 940 : 0.011023284867405891
Loss at iteration 950 : 0.012939087115228176
Loss at iteration 960 : 0.00922844186425209
Loss at iteration 970 : 0.014587124809622765
Loss at iteration 980 : 0.015344226732850075
Loss at iteration 990 : 0.01003055740147829
Loss at iteration 1000 : 0.00969315879046917
Loss at iteration 1010 : 0.012762295082211494
Loss at iteration 1020 : 0.010857531800866127
Loss at iteration 1030 : 0.014145412482321262
Loss at iteration 1040 : 0.01315421424806118
Loss at iteration 1050 : 0.01229570060968399
Loss at iteration 1060 : 0.01964031346142292
Loss at iteration 1070 : 0.011710252612829208
Loss at iteration 1080 : 0.012202112935483456
Loss at iteration 1090 : 0.011624407023191452
Loss at iteration 1100 : 0.010984674096107483
Loss at iteration 1110 : 0.016883689910173416
Loss at iteration 1120 : 0.011402174830436707
Loss at iteration 1130 : 0.01124502718448639
Loss at iteration 1140 : 0.02469961903989315
Loss at iteration 1150 : 0.009207654744386673
Loss at iteration 1160 : 0.0173198115080595
Loss at iteration 1170 : 0.01834547519683838
Loss at iteration 1180 : 0.01742834970355034
Loss at iteration 1190 : 0.007689277641475201
Loss at iteration 1200 : 0.013184239156544209
Loss at iteration 1210 : 0.009108155965805054
The SSIM Value is: 0.8042004942893982
The PSNR Value is: 18.3359858194987
the epoch is: 74
Loss at iteration 10 : 0.00980345904827118
Loss at iteration 20 : 0.012589739635586739
Loss at iteration 30 : 0.00954863429069519
Loss at iteration 40 : 0.012277966365218163
Loss at iteration 50 : 0.007058977149426937
Loss at iteration 60 : 0.010598484426736832
Loss at iteration 70 : 0.014928286895155907
Loss at iteration 80 : 0.01668839529156685
Loss at iteration 90 : 0.010948646813631058
Loss at iteration 100 : 0.00949465949088335
Loss at iteration 110 : 0.014500435441732407
Loss at iteration 120 : 0.01454230397939682
Loss at iteration 130 : 0.011029507033526897
Loss at iteration 140 : 0.010700509883463383
Loss at iteration 150 : 0.006470375694334507
Loss at iteration 160 : 0.016366463154554367
Loss at iteration 170 : 0.011407663114368916
Loss at iteration 180 : 0.01205655187368393
Loss at iteration 190 : 0.007701879367232323
Loss at iteration 200 : 0.018306773155927658
Loss at iteration 210 : 0.014336008578538895
Loss at iteration 220 : 0.011376583948731422
Loss at iteration 230 : 0.007155049592256546
Loss at iteration 240 : 0.015500074252486229
Loss at iteration 250 : 0.009484929032623768
Loss at iteration 260 : 0.020375696942210197
Loss at iteration 270 : 0.005753765348345041
Loss at iteration 280 : 0.011700352653861046
Loss at iteration 290 : 0.00994807481765747
Loss at iteration 300 : 0.015798794105648994
Loss at iteration 310 : 0.010966851375997066
Loss at iteration 320 : 0.009253127500414848
Loss at iteration 330 : 0.01055369433015585
Loss at iteration 340 : 0.010233113542199135
Loss at iteration 350 : 0.011367971077561378
Loss at iteration 360 : 0.01657714881002903
Loss at iteration 370 : 0.011450263671576977
Loss at iteration 380 : 0.018125727772712708
Loss at iteration 390 : 0.011373325251042843
Loss at iteration 400 : 0.021089114248752594
Loss at iteration 410 : 0.014594599604606628
Loss at iteration 420 : 0.008497023023664951
Loss at iteration 430 : 0.012034256011247635
Loss at iteration 440 : 0.013994292356073856
Loss at iteration 450 : 0.014198058284819126
Loss at iteration 460 : 0.01171172596514225
Loss at iteration 470 : 0.012488314881920815
Loss at iteration 480 : 0.011174740269780159
Loss at iteration 490 : 0.013809453696012497
Loss at iteration 500 : 0.008253566920757294
Loss at iteration 510 : 0.01055346429347992
Loss at iteration 520 : 0.014323748648166656
Loss at iteration 530 : 0.009418965317308903
Loss at iteration 540 : 0.015208528377115726
Loss at iteration 550 : 0.015030018985271454
Loss at iteration 560 : 0.006992622744292021
Loss at iteration 570 : 0.013649332337081432
Loss at iteration 580 : 0.009099069982767105
Loss at iteration 590 : 0.012164033949375153
Loss at iteration 600 : 0.007232036907225847
Loss at iteration 610 : 0.007144458591938019
Loss at iteration 620 : 0.013204149901866913
Loss at iteration 630 : 0.022144876420497894
Loss at iteration 640 : 0.010966966859996319
Loss at iteration 650 : 0.019034087657928467
Loss at iteration 660 : 0.019189100712537766
Loss at iteration 670 : 0.014074813574552536
Loss at iteration 680 : 0.011574998497962952
Loss at iteration 690 : 0.009867925196886063
Loss at iteration 700 : 0.010001568123698235
Loss at iteration 710 : 0.007903478108346462
Loss at iteration 720 : 0.009501315653324127
Loss at iteration 730 : 0.012992123141884804
Loss at iteration 740 : 0.013340399600565434
Loss at iteration 750 : 0.01252937875688076
Loss at iteration 760 : 0.01133179385215044
Loss at iteration 770 : 0.008742199279367924
Loss at iteration 780 : 0.008012027479708195
Loss at iteration 790 : 0.009400894865393639
Loss at iteration 800 : 0.008510656654834747
Loss at iteration 810 : 0.014071367681026459
Loss at iteration 820 : 0.01042071171104908
Loss at iteration 830 : 0.007858791388571262
Loss at iteration 840 : 0.010991394519805908
Loss at iteration 850 : 0.013493589125573635
Loss at iteration 860 : 0.010556447319686413
Loss at iteration 870 : 0.01090237032622099
Loss at iteration 880 : 0.011928507126867771
Loss at iteration 890 : 0.009303174912929535
Loss at iteration 900 : 0.006905005779117346
Loss at iteration 910 : 0.012865555472671986
Loss at iteration 920 : 0.01391463354229927
Loss at iteration 930 : 0.011452246457338333
Loss at iteration 940 : 0.010478864423930645
Loss at iteration 950 : 0.008570530451834202
Loss at iteration 960 : 0.015189599245786667
Loss at iteration 970 : 0.012829508632421494
Loss at iteration 980 : 0.015147022902965546
Loss at iteration 990 : 0.011656727641820908
Loss at iteration 1000 : 0.008886989206075668
Loss at iteration 1010 : 0.012181993573904037
Loss at iteration 1020 : 0.012866227887570858
Loss at iteration 1030 : 0.012265196070075035
Loss at iteration 1040 : 0.01282944343984127
Loss at iteration 1050 : 0.012833036482334137
Loss at iteration 1060 : 0.011560716666281223
Loss at iteration 1070 : 0.012971637770533562
Loss at iteration 1080 : 0.009010160341858864
Loss at iteration 1090 : 0.012359644286334515
Loss at iteration 1100 : 0.010891892947256565
Loss at iteration 1110 : 0.016537990421056747
Loss at iteration 1120 : 0.010262683965265751
Loss at iteration 1130 : 0.011219725012779236
Loss at iteration 1140 : 0.007332799956202507
Loss at iteration 1150 : 0.009869297966361046
Loss at iteration 1160 : 0.00642671762034297
Loss at iteration 1170 : 0.019554266706109047
Loss at iteration 1180 : 0.008248696103692055
Loss at iteration 1190 : 0.00929738488048315
Loss at iteration 1200 : 0.010499171912670135
Loss at iteration 1210 : 0.008017810061573982
The SSIM Value is: 0.8181634227434794
The PSNR Value is: 19.546057573954265
the highest SSIM value is: 19.546057573954265
the epoch is: 75
Loss at iteration 10 : 0.008614764548838139
Loss at iteration 20 : 0.009073556400835514
Loss at iteration 30 : 0.0070160455070436
Loss at iteration 40 : 0.016156353056430817
Loss at iteration 50 : 0.008794221095740795
Loss at iteration 60 : 0.009242099709808826
Loss at iteration 70 : 0.010549260303378105
Loss at iteration 80 : 0.012877607718110085
Loss at iteration 90 : 0.014974484220147133
Loss at iteration 100 : 0.012716717086732388
Loss at iteration 110 : 0.013017451390624046
Loss at iteration 120 : 0.007233749143779278
Loss at iteration 130 : 0.008656509220600128
Loss at iteration 140 : 0.014942560344934464
Loss at iteration 150 : 0.008674383163452148
Loss at iteration 160 : 0.01774648204445839
Loss at iteration 170 : 0.01596379093825817
Loss at iteration 180 : 0.006942372769117355
Loss at iteration 190 : 0.011953750625252724
Loss at iteration 200 : 0.006108933128416538
Loss at iteration 210 : 0.015217680484056473
Loss at iteration 220 : 0.008703021332621574
Loss at iteration 230 : 0.020349673926830292
Loss at iteration 240 : 0.015639791265130043
Loss at iteration 250 : 0.008896855637431145
Loss at iteration 260 : 0.006006258074194193
Loss at iteration 270 : 0.00804213061928749
Loss at iteration 280 : 0.013654494658112526
Loss at iteration 290 : 0.014064093120396137
Loss at iteration 300 : 0.0075344061478972435
Loss at iteration 310 : 0.01738583669066429
Loss at iteration 320 : 0.00639520026743412
Loss at iteration 330 : 0.005956438370049
Loss at iteration 340 : 0.008687075227499008
Loss at iteration 350 : 0.009501658380031586
Loss at iteration 360 : 0.014688977040350437
Loss at iteration 370 : 0.0168693196028471
Loss at iteration 380 : 0.013129114173352718
Loss at iteration 390 : 0.01245886366814375
Loss at iteration 400 : 0.02078443393111229
Loss at iteration 410 : 0.011195703409612179
Loss at iteration 420 : 0.007508263923227787
Loss at iteration 430 : 0.009548725560307503
Loss at iteration 440 : 0.007543311454355717
Loss at iteration 450 : 0.011171083897352219
Loss at iteration 460 : 0.008758682757616043
Loss at iteration 470 : 0.005937868729233742
Loss at iteration 480 : 0.010875587351620197
Loss at iteration 490 : 0.009574241936206818
Loss at iteration 500 : 0.017345169559121132
Loss at iteration 510 : 0.00830808188766241
Loss at iteration 520 : 0.011482607573270798
Loss at iteration 530 : 0.008326146751642227
Loss at iteration 540 : 0.010677765123546124
Loss at iteration 550 : 0.01404445618391037
Loss at iteration 560 : 0.016159607097506523
Loss at iteration 570 : 0.006087108049541712
Loss at iteration 580 : 0.021562598645687103
Loss at iteration 590 : 0.011059710755944252
Loss at iteration 600 : 0.01139349490404129
Loss at iteration 610 : 0.016994565725326538
Loss at iteration 620 : 0.018016640096902847
Loss at iteration 630 : 0.014478649012744427
Loss at iteration 640 : 0.022959407418966293
Loss at iteration 650 : 0.011766869574785233
Loss at iteration 660 : 0.013437863439321518
Loss at iteration 670 : 0.018855299800634384
Loss at iteration 680 : 0.01607585698366165
Loss at iteration 690 : 0.013914873823523521
Loss at iteration 700 : 0.011848637834191322
Loss at iteration 710 : 0.021796878427267075
Loss at iteration 720 : 0.0059508467093110085
Loss at iteration 730 : 0.015336328186094761
Loss at iteration 740 : 0.008827175945043564
Loss at iteration 750 : 0.00865271594375372
Loss at iteration 760 : 0.014073923230171204
Loss at iteration 770 : 0.010884314775466919
Loss at iteration 780 : 0.012581015937030315
Loss at iteration 790 : 0.005499480292201042
Loss at iteration 800 : 0.010163052007555962
Loss at iteration 810 : 0.008993415161967278
Loss at iteration 820 : 0.006184309720993042
Loss at iteration 830 : 0.007056553848087788
Loss at iteration 840 : 0.007445971015840769
Loss at iteration 850 : 0.015602773055434227
Loss at iteration 860 : 0.0071736485697329044
Loss at iteration 870 : 0.007636555470526218
Loss at iteration 880 : 0.0100111598148942
Loss at iteration 890 : 0.011356808245182037
Loss at iteration 900 : 0.02114117704331875
Loss at iteration 910 : 0.004763646516948938
Loss at iteration 920 : 0.015289840288460255
Loss at iteration 930 : 0.01432129181921482
Loss at iteration 940 : 0.014759172685444355
Loss at iteration 950 : 0.011075019836425781
Loss at iteration 960 : 0.014611748978495598
Loss at iteration 970 : 0.007491156458854675
Loss at iteration 980 : 0.012121429666876793
Loss at iteration 990 : 0.010074233636260033
Loss at iteration 1000 : 0.008908827789127827
Loss at iteration 1010 : 0.011476784944534302
Loss at iteration 1020 : 0.0058642239309847355
Loss at iteration 1030 : 0.00986464973539114
Loss at iteration 1040 : 0.015620536170899868
Loss at iteration 1050 : 0.015193258412182331
Loss at iteration 1060 : 0.013342308811843395
Loss at iteration 1070 : 0.011953148990869522
Loss at iteration 1080 : 0.012595479376614094
Loss at iteration 1090 : 0.01824691891670227
Loss at iteration 1100 : 0.011782968416810036
Loss at iteration 1110 : 0.011210444383323193
Loss at iteration 1120 : 0.025305749848484993
Loss at iteration 1130 : 0.014163398183882236
Loss at iteration 1140 : 0.009494176134467125
Loss at iteration 1150 : 0.011827356182038784
Loss at iteration 1160 : 0.01439402811229229
Loss at iteration 1170 : 0.009585388004779816
Loss at iteration 1180 : 0.0072504375129938126
Loss at iteration 1190 : 0.006886348128318787
Loss at iteration 1200 : 0.00909754354506731
Loss at iteration 1210 : 0.009876154363155365
The SSIM Value is: 0.8123941977818807
The PSNR Value is: 18.893788210550944
the epoch is: 76
Loss at iteration 10 : 0.008929247036576271
Loss at iteration 20 : 0.007786771282553673
Loss at iteration 30 : 0.009512504562735558
Loss at iteration 40 : 0.01179924514144659
Loss at iteration 50 : 0.012288217432796955
Loss at iteration 60 : 0.00954756885766983
Loss at iteration 70 : 0.007531529758125544
Loss at iteration 80 : 0.011441171169281006
Loss at iteration 90 : 0.011348491534590721
Loss at iteration 100 : 0.007254051044583321
Loss at iteration 110 : 0.012635808438062668
Loss at iteration 120 : 0.01294587180018425
Loss at iteration 130 : 0.015167435631155968
Loss at iteration 140 : 0.011528410948812962
Loss at iteration 150 : 0.012616160325706005
Loss at iteration 160 : 0.009151129052042961
Loss at iteration 170 : 0.013247719965875149
Loss at iteration 180 : 0.01584220491349697
Loss at iteration 190 : 0.0076926155015826225
Loss at iteration 200 : 0.01630123145878315
Loss at iteration 210 : 0.007512310519814491
Loss at iteration 220 : 0.012058819644153118
Loss at iteration 230 : 0.012366322800517082
Loss at iteration 240 : 0.013576222583651543
Loss at iteration 250 : 0.008145399391651154
Loss at iteration 260 : 0.017263755202293396
Loss at iteration 270 : 0.011856988072395325
Loss at iteration 280 : 0.013712890446186066
Loss at iteration 290 : 0.023622963577508926
Loss at iteration 300 : 0.008718226104974747
Loss at iteration 310 : 0.012676908634603024
Loss at iteration 320 : 0.011979482136666775
Loss at iteration 330 : 0.016061387956142426
Loss at iteration 340 : 0.015453310683369637
Loss at iteration 350 : 0.016316160559654236
Loss at iteration 360 : 0.009614404290914536
Loss at iteration 370 : 0.011455133557319641
Loss at iteration 380 : 0.0069982437416911125
Loss at iteration 390 : 0.01715860329568386
Loss at iteration 400 : 0.015225807204842567
Loss at iteration 410 : 0.01566966250538826
Loss at iteration 420 : 0.009941931813955307
Loss at iteration 430 : 0.010062940418720245
Loss at iteration 440 : 0.009215984493494034
Loss at iteration 450 : 0.0106400977820158
Loss at iteration 460 : 0.01274319738149643
Loss at iteration 470 : 0.009113611653447151
Loss at iteration 480 : 0.015623243525624275
Loss at iteration 490 : 0.011242330074310303
Loss at iteration 500 : 0.014065307565033436
Loss at iteration 510 : 0.007908374071121216
Loss at iteration 520 : 0.010030531324446201
Loss at iteration 530 : 0.009353695437312126
Loss at iteration 540 : 0.008609465323388577
Loss at iteration 550 : 0.006445974111557007
Loss at iteration 560 : 0.011096905916929245
Loss at iteration 570 : 0.012240390293300152
Loss at iteration 580 : 0.01445435918867588
Loss at iteration 590 : 0.017835337668657303
Loss at iteration 600 : 0.011263344436883926
Loss at iteration 610 : 0.010962567292153835
Loss at iteration 620 : 0.012401256710290909
Loss at iteration 630 : 0.013320964761078358
Loss at iteration 640 : 0.007706010714173317
Loss at iteration 650 : 0.007121509872376919
Loss at iteration 660 : 0.021274389699101448
Loss at iteration 670 : 0.007437895983457565
Loss at iteration 680 : 0.009181292727589607
Loss at iteration 690 : 0.00941320601850748
Loss at iteration 700 : 0.014422905631363392
Loss at iteration 710 : 0.01592077687382698
Loss at iteration 720 : 0.021691277623176575
Loss at iteration 730 : 0.014843626879155636
Loss at iteration 740 : 0.013253721408545971
Loss at iteration 750 : 0.015518979169428349
Loss at iteration 760 : 0.010796867311000824
Loss at iteration 770 : 0.019328368827700615
Loss at iteration 780 : 0.02267160639166832
Loss at iteration 790 : 0.008749724365770817
Loss at iteration 800 : 0.010682262480258942
Loss at iteration 810 : 0.009697823785245419
Loss at iteration 820 : 0.00889547262340784
Loss at iteration 830 : 0.01378914900124073
Loss at iteration 840 : 0.013023230247199535
Loss at iteration 850 : 0.005247927736490965
Loss at iteration 860 : 0.011230900883674622
Loss at iteration 870 : 0.01911994442343712
Loss at iteration 880 : 0.012866289354860783
Loss at iteration 890 : 0.01034061424434185
Loss at iteration 900 : 0.010762222111225128
Loss at iteration 910 : 0.00994997937232256
Loss at iteration 920 : 0.010426642373204231
Loss at iteration 930 : 0.010645365342497826
Loss at iteration 940 : 0.009786964394152164
Loss at iteration 950 : 0.0073796785436570644
Loss at iteration 960 : 0.008010279387235641
Loss at iteration 970 : 0.008920968510210514
Loss at iteration 980 : 0.009066198021173477
Loss at iteration 990 : 0.013381600379943848
Loss at iteration 1000 : 0.006493156775832176
Loss at iteration 1010 : 0.009554598480463028
Loss at iteration 1020 : 0.012754552066326141
Loss at iteration 1030 : 0.010840188711881638
Loss at iteration 1040 : 0.015726396813988686
Loss at iteration 1050 : 0.009126370772719383
Loss at iteration 1060 : 0.029539132490754128
Loss at iteration 1070 : 0.015279722400009632
Loss at iteration 1080 : 0.0074866702780127525
Loss at iteration 1090 : 0.007976721972227097
Loss at iteration 1100 : 0.023209404200315475
Loss at iteration 1110 : 0.022284962236881256
Loss at iteration 1120 : 0.016010483726859093
Loss at iteration 1130 : 0.01168886385858059
Loss at iteration 1140 : 0.007324950769543648
Loss at iteration 1150 : 0.020575471222400665
Loss at iteration 1160 : 0.00796188972890377
Loss at iteration 1170 : 0.009774529375135899
Loss at iteration 1180 : 0.012660054489970207
Loss at iteration 1190 : 0.00843418762087822
Loss at iteration 1200 : 0.012725288048386574
Loss at iteration 1210 : 0.013743137940764427
The SSIM Value is: 0.8085036714871724
The PSNR Value is: 18.597621154785156
the epoch is: 77
Loss at iteration 10 : 0.011541105806827545
Loss at iteration 20 : 0.012023848481476307
Loss at iteration 30 : 0.010117578320205212
Loss at iteration 40 : 0.007425238844007254
Loss at iteration 50 : 0.010637171566486359
Loss at iteration 60 : 0.012311533093452454
Loss at iteration 70 : 0.014543314464390278
Loss at iteration 80 : 0.010970914736390114
Loss at iteration 90 : 0.011170737445354462
Loss at iteration 100 : 0.009524096734821796
Loss at iteration 110 : 0.007961885072290897
Loss at iteration 120 : 0.014829660765826702
Loss at iteration 130 : 0.01067856140434742
Loss at iteration 140 : 0.01753043383359909
Loss at iteration 150 : 0.013598251156508923
Loss at iteration 160 : 0.025561127811670303
Loss at iteration 170 : 0.013157491572201252
Loss at iteration 180 : 0.022020414471626282
Loss at iteration 190 : 0.014102230779826641
Loss at iteration 200 : 0.01431844662874937
Loss at iteration 210 : 0.012191048823297024
Loss at iteration 220 : 0.012051012367010117
Loss at iteration 230 : 0.012067257426679134
Loss at iteration 240 : 0.007174511440098286
Loss at iteration 250 : 0.014058451168239117
Loss at iteration 260 : 0.016867181286215782
Loss at iteration 270 : 0.013604478910565376
Loss at iteration 280 : 0.011657005175948143
Loss at iteration 290 : 0.01217628549784422
Loss at iteration 300 : 0.010674869641661644
Loss at iteration 310 : 0.008663461543619633
Loss at iteration 320 : 0.017771407961845398
Loss at iteration 330 : 0.00875408947467804
Loss at iteration 340 : 0.015169255435466766
Loss at iteration 350 : 0.010833695530891418
Loss at iteration 360 : 0.010145549662411213
Loss at iteration 370 : 0.018014248460531235
Loss at iteration 380 : 0.013459347188472748
Loss at iteration 390 : 0.009266491048038006
Loss at iteration 400 : 0.01463315635919571
Loss at iteration 410 : 0.01725294627249241
Loss at iteration 420 : 0.009857556782662868
Loss at iteration 430 : 0.006486133672297001
Loss at iteration 440 : 0.013135107234120369
Loss at iteration 450 : 0.014142999425530434
Loss at iteration 460 : 0.010689161717891693
Loss at iteration 470 : 0.008510311134159565
Loss at iteration 480 : 0.012641080655157566
Loss at iteration 490 : 0.009010029956698418
Loss at iteration 500 : 0.01367249246686697
Loss at iteration 510 : 0.008378520607948303
Loss at iteration 520 : 0.009624448604881763
Loss at iteration 530 : 0.011759679764509201
Loss at iteration 540 : 0.00937582366168499
Loss at iteration 550 : 0.008983490988612175
Loss at iteration 560 : 0.016384921967983246
Loss at iteration 570 : 0.015110311098396778
Loss at iteration 580 : 0.013209235854446888
Loss at iteration 590 : 0.008632112294435501
Loss at iteration 600 : 0.012894032523036003
Loss at iteration 610 : 0.011088814586400986
Loss at iteration 620 : 0.01150108315050602
Loss at iteration 630 : 0.016586123034358025
Loss at iteration 640 : 0.018831387162208557
Loss at iteration 650 : 0.011889840476214886
Loss at iteration 660 : 0.0112369479611516
Loss at iteration 670 : 0.020158208906650543
Loss at iteration 680 : 0.016346918419003487
Loss at iteration 690 : 0.01429220475256443
Loss at iteration 700 : 0.008612215518951416
Loss at iteration 710 : 0.008114716969430447
Loss at iteration 720 : 0.022353999316692352
Loss at iteration 730 : 0.013084235601127148
Loss at iteration 740 : 0.01113593578338623
Loss at iteration 750 : 0.004737530369311571
Loss at iteration 760 : 0.011370196007192135
Loss at iteration 770 : 0.010886038653552532
Loss at iteration 780 : 0.008642366155982018
Loss at iteration 790 : 0.013300812803208828
Loss at iteration 800 : 0.009139206260442734
Loss at iteration 810 : 0.011789381504058838
Loss at iteration 820 : 0.01065224502235651
Loss at iteration 830 : 0.014327621087431908
Loss at iteration 840 : 0.010192837566137314
Loss at iteration 850 : 0.013091469183564186
Loss at iteration 860 : 0.01308859046548605
Loss at iteration 870 : 0.015825791284441948
Loss at iteration 880 : 0.015946857631206512
Loss at iteration 890 : 0.0122455433011055
Loss at iteration 900 : 0.009275183081626892
Loss at iteration 910 : 0.012228002771735191
Loss at iteration 920 : 0.008504007011651993
Loss at iteration 930 : 0.010694026947021484
Loss at iteration 940 : 0.012189827859401703
Loss at iteration 950 : 0.004957946948707104
Loss at iteration 960 : 0.010537240654230118
Loss at iteration 970 : 0.008294103667140007
Loss at iteration 980 : 0.017796192318201065
Loss at iteration 990 : 0.010072490200400352
Loss at iteration 1000 : 0.013281276449561119
Loss at iteration 1010 : 0.007276395335793495
Loss at iteration 1020 : 0.010079322382807732
Loss at iteration 1030 : 0.01744132488965988
Loss at iteration 1040 : 0.01260390691459179
Loss at iteration 1050 : 0.008726976811885834
Loss at iteration 1060 : 0.0098932646214962
Loss at iteration 1070 : 0.01176393497735262
Loss at iteration 1080 : 0.016427382826805115
Loss at iteration 1090 : 0.012422049418091774
Loss at iteration 1100 : 0.012498367577791214
Loss at iteration 1110 : 0.011025484651327133
Loss at iteration 1120 : 0.008583001792430878
Loss at iteration 1130 : 0.010107174515724182
Loss at iteration 1140 : 0.012832620181143284
Loss at iteration 1150 : 0.012382718734443188
Loss at iteration 1160 : 0.017381126061081886
Loss at iteration 1170 : 0.009003627113997936
Loss at iteration 1180 : 0.012032555416226387
Loss at iteration 1190 : 0.008394349366426468
Loss at iteration 1200 : 0.013485935516655445
Loss at iteration 1210 : 0.016711141914129257
The SSIM Value is: 0.7960441668828329
The PSNR Value is: 18.30348014831543
the epoch is: 78
Loss at iteration 10 : 0.010226115584373474
Loss at iteration 20 : 0.008695639669895172
Loss at iteration 30 : 0.011074751615524292
Loss at iteration 40 : 0.010221203789114952
Loss at iteration 50 : 0.009989599697291851
Loss at iteration 60 : 0.011328281834721565
Loss at iteration 70 : 0.010779576376080513
Loss at iteration 80 : 0.012761594727635384
Loss at iteration 90 : 0.008308984339237213
Loss at iteration 100 : 0.007038372103124857
Loss at iteration 110 : 0.0151315126568079
Loss at iteration 120 : 0.011080695316195488
Loss at iteration 130 : 0.015034157782793045
Loss at iteration 140 : 0.009235545061528683
Loss at iteration 150 : 0.011477886699140072
Loss at iteration 160 : 0.013656300492584705
Loss at iteration 170 : 0.010427253320813179
Loss at iteration 180 : 0.020533975213766098
Loss at iteration 190 : 0.016686152666807175
Loss at iteration 200 : 0.027561457827687263
Loss at iteration 210 : 0.020497702062129974
Loss at iteration 220 : 0.00672555435448885
Loss at iteration 230 : 0.01652977615594864
Loss at iteration 240 : 0.01224232092499733
Loss at iteration 250 : 0.0072445496916770935
Loss at iteration 260 : 0.013908591121435165
Loss at iteration 270 : 0.012510303407907486
Loss at iteration 280 : 0.014700490981340408
Loss at iteration 290 : 0.02006387710571289
Loss at iteration 300 : 0.015489122830331326
Loss at iteration 310 : 0.013909350149333477
Loss at iteration 320 : 0.011023398488759995
Loss at iteration 330 : 0.010246653109788895
Loss at iteration 340 : 0.011769453063607216
Loss at iteration 350 : 0.01884739100933075
Loss at iteration 360 : 0.013137321919202805
Loss at iteration 370 : 0.01751559041440487
Loss at iteration 380 : 0.013049229979515076
Loss at iteration 390 : 0.007227545138448477
Loss at iteration 400 : 0.013962376862764359
Loss at iteration 410 : 0.00821726955473423
Loss at iteration 420 : 0.010079041123390198
Loss at iteration 430 : 0.011916985735297203
Loss at iteration 440 : 0.01352215651422739
Loss at iteration 450 : 0.010805340483784676
Loss at iteration 460 : 0.00801210105419159
Loss at iteration 470 : 0.0065205395221710205
Loss at iteration 480 : 0.007984296418726444
Loss at iteration 490 : 0.02084856480360031
Loss at iteration 500 : 0.01978278160095215
Loss at iteration 510 : 0.010855921544134617
Loss at iteration 520 : 0.016807647421956062
Loss at iteration 530 : 0.012911424040794373
Loss at iteration 540 : 0.01426875963807106
Loss at iteration 550 : 0.023623768240213394
Loss at iteration 560 : 0.009696293622255325
Loss at iteration 570 : 0.01094664353877306
Loss at iteration 580 : 0.00795789249241352
Loss at iteration 590 : 0.008426662534475327
Loss at iteration 600 : 0.01634502038359642
Loss at iteration 610 : 0.01577480137348175
Loss at iteration 620 : 0.014302386902272701
Loss at iteration 630 : 0.010664412751793861
Loss at iteration 640 : 0.009199148043990135
Loss at iteration 650 : 0.00723936827853322
Loss at iteration 660 : 0.008527172729372978
Loss at iteration 670 : 0.014798380434513092
Loss at iteration 680 : 0.012767836451530457
Loss at iteration 690 : 0.011328425258398056
Loss at iteration 700 : 0.01630401983857155
Loss at iteration 710 : 0.009100272320210934
Loss at iteration 720 : 0.011067627929151058
Loss at iteration 730 : 0.007655545137822628
Loss at iteration 740 : 0.0099031338468194
Loss at iteration 750 : 0.012828095816075802
Loss at iteration 760 : 0.012387210503220558
Loss at iteration 770 : 0.00913418922573328
Loss at iteration 780 : 0.01459531206637621
Loss at iteration 790 : 0.015623324550688267
Loss at iteration 800 : 0.005849333480000496
Loss at iteration 810 : 0.009115070104598999
Loss at iteration 820 : 0.01300723571330309
Loss at iteration 830 : 0.013005878776311874
Loss at iteration 840 : 0.014641799032688141
Loss at iteration 850 : 0.011107931844890118
Loss at iteration 860 : 0.0096813989803195
Loss at iteration 870 : 0.010792924091219902
Loss at iteration 880 : 0.009310292080044746
Loss at iteration 890 : 0.011702857911586761
Loss at iteration 900 : 0.007645266130566597
Loss at iteration 910 : 0.007799041457474232
Loss at iteration 920 : 0.010198746807873249
Loss at iteration 930 : 0.014707928523421288
Loss at iteration 940 : 0.01331481896340847
Loss at iteration 950 : 0.016467446461319923
Loss at iteration 960 : 0.00782698206603527
Loss at iteration 970 : 0.009480360895395279
Loss at iteration 980 : 0.014652524143457413
Loss at iteration 990 : 0.012249596416950226
Loss at iteration 1000 : 0.011454552412033081
Loss at iteration 1010 : 0.010354266501963139
Loss at iteration 1020 : 0.010970892384648323
Loss at iteration 1030 : 0.02379414439201355
Loss at iteration 1040 : 0.017303146421909332
Loss at iteration 1050 : 0.010859414935112
Loss at iteration 1060 : 0.00526842288672924
Loss at iteration 1070 : 0.015667995437979698
Loss at iteration 1080 : 0.00963524729013443
Loss at iteration 1090 : 0.014999468810856342
Loss at iteration 1100 : 0.009230999276041985
Loss at iteration 1110 : 0.016679756343364716
Loss at iteration 1120 : 0.011081740260124207
Loss at iteration 1130 : 0.011079622432589531
Loss at iteration 1140 : 0.004980597645044327
Loss at iteration 1150 : 0.012336578220129013
Loss at iteration 1160 : 0.01177411898970604
Loss at iteration 1170 : 0.013470280915498734
Loss at iteration 1180 : 0.007874562405049801
Loss at iteration 1190 : 0.00719789881259203
Loss at iteration 1200 : 0.01155744306743145
Loss at iteration 1210 : 0.009010091423988342
The SSIM Value is: 0.8034530361493428
The PSNR Value is: 18.665806643168132
the epoch is: 79
Loss at iteration 10 : 0.010711717419326305
Loss at iteration 20 : 0.005676634609699249
Loss at iteration 30 : 0.010844357311725616
Loss at iteration 40 : 0.004162857308983803
Loss at iteration 50 : 0.014402499422430992
Loss at iteration 60 : 0.014154663309454918
Loss at iteration 70 : 0.009995777159929276
Loss at iteration 80 : 0.006234562024474144
Loss at iteration 90 : 0.01115401741117239
Loss at iteration 100 : 0.010642014443874359
Loss at iteration 110 : 0.007073359563946724
Loss at iteration 120 : 0.015635155141353607
Loss at iteration 130 : 0.00991086009889841
Loss at iteration 140 : 0.009527617134153843
Loss at iteration 150 : 0.011746805161237717
Loss at iteration 160 : 0.01038025226444006
Loss at iteration 170 : 0.010757137089967728
Loss at iteration 180 : 0.01037120632827282
Loss at iteration 190 : 0.009778568521142006
Loss at iteration 200 : 0.009657260030508041
Loss at iteration 210 : 0.014903543516993523
Loss at iteration 220 : 0.010446254163980484
Loss at iteration 230 : 0.013131034560501575
Loss at iteration 240 : 0.0166877880692482
Loss at iteration 250 : 0.012839917093515396
Loss at iteration 260 : 0.009434464387595654
Loss at iteration 270 : 0.01234031654894352
Loss at iteration 280 : 0.00958434771746397
Loss at iteration 290 : 0.015880681574344635
Loss at iteration 300 : 0.012231904082000256
Loss at iteration 310 : 0.01408268604427576
Loss at iteration 320 : 0.012997584417462349
Loss at iteration 330 : 0.01573624461889267
Loss at iteration 340 : 0.012661709450185299
Loss at iteration 350 : 0.010590807534754276
Loss at iteration 360 : 0.009581384249031544
Loss at iteration 370 : 0.008087091147899628
Loss at iteration 380 : 0.017647799104452133
Loss at iteration 390 : 0.005194849334657192
Loss at iteration 400 : 0.015975752845406532
Loss at iteration 410 : 0.016602108255028725
Loss at iteration 420 : 0.009631922468543053
Loss at iteration 430 : 0.012968149036169052
Loss at iteration 440 : 0.00612447876483202
Loss at iteration 450 : 0.010673931799829006
Loss at iteration 460 : 0.013665816746652126
Loss at iteration 470 : 0.009204461239278316
Loss at iteration 480 : 0.011134020984172821
Loss at iteration 490 : 0.00812449213117361
Loss at iteration 500 : 0.013399602845311165
Loss at iteration 510 : 0.013668825849890709
Loss at iteration 520 : 0.007777741178870201
Loss at iteration 530 : 0.013899605721235275
Loss at iteration 540 : 0.010140907019376755
Loss at iteration 550 : 0.01200195960700512
Loss at iteration 560 : 0.01540654432028532
Loss at iteration 570 : 0.01699029840528965
Loss at iteration 580 : 0.01386657077819109
Loss at iteration 590 : 0.0137696024030447
Loss at iteration 600 : 0.018860958516597748
Loss at iteration 610 : 0.013640490360558033
Loss at iteration 620 : 0.011496786028146744
Loss at iteration 630 : 0.014999131672084332
Loss at iteration 640 : 0.014443716034293175
Loss at iteration 650 : 0.009433314204216003
Loss at iteration 660 : 0.013084840029478073
Loss at iteration 670 : 0.011094190180301666
Loss at iteration 680 : 0.011671086773276329
Loss at iteration 690 : 0.01329655572772026
Loss at iteration 700 : 0.013270983472466469
Loss at iteration 710 : 0.02433515340089798
Loss at iteration 720 : 0.012795139104127884
Loss at iteration 730 : 0.009332388639450073
Loss at iteration 740 : 0.011229957453906536
Loss at iteration 750 : 0.01143975555896759
Loss at iteration 760 : 0.010700398124754429
Loss at iteration 770 : 0.013210727833211422
Loss at iteration 780 : 0.013875956647098064
Loss at iteration 790 : 0.015184754505753517
Loss at iteration 800 : 0.012072322890162468
Loss at iteration 810 : 0.0067204562947154045
Loss at iteration 820 : 0.019009120762348175
Loss at iteration 830 : 0.015662452206015587
Loss at iteration 840 : 0.006519932299852371
Loss at iteration 850 : 0.009372931905090809
Loss at iteration 860 : 0.010687821544706821
Loss at iteration 870 : 0.011451266705989838
Loss at iteration 880 : 0.012784907594323158
Loss at iteration 890 : 0.011219615116715431
Loss at iteration 900 : 0.01119176670908928
Loss at iteration 910 : 0.015599689446389675
Loss at iteration 920 : 0.006442934274673462
Loss at iteration 930 : 0.008790328167378902
Loss at iteration 940 : 0.007012303452938795
Loss at iteration 950 : 0.01007722970098257
Loss at iteration 960 : 0.008449416607618332
Loss at iteration 970 : 0.015338800847530365
Loss at iteration 980 : 0.01228003203868866
Loss at iteration 990 : 0.011796632781624794
Loss at iteration 1000 : 0.018354473635554314
Loss at iteration 1010 : 0.010211735963821411
Loss at iteration 1020 : 0.010086946189403534
Loss at iteration 1030 : 0.01652401313185692
Loss at iteration 1040 : 0.00902683474123478
Loss at iteration 1050 : 0.010917272418737411
Loss at iteration 1060 : 0.008958556689321995
Loss at iteration 1070 : 0.01483550388365984
Loss at iteration 1080 : 0.017321256920695305
Loss at iteration 1090 : 0.012060747481882572
Loss at iteration 1100 : 0.010712512768805027
Loss at iteration 1110 : 0.010675093159079552
Loss at iteration 1120 : 0.012193707749247551
Loss at iteration 1130 : 0.011511702090501785
Loss at iteration 1140 : 0.007710698060691357
Loss at iteration 1150 : 0.013875392265617847
Loss at iteration 1160 : 0.009633270092308521
Loss at iteration 1170 : 0.007579632103443146
Loss at iteration 1180 : 0.010599255561828613
Loss at iteration 1190 : 0.01114555262029171
Loss at iteration 1200 : 0.010782742872834206
Loss at iteration 1210 : 0.012683546170592308
The SSIM Value is: 0.8019305030504863
The PSNR Value is: 18.597902870178224
the epoch is: 80
Loss at iteration 10 : 0.015931013971567154
Loss at iteration 20 : 0.010154836811125278
Loss at iteration 30 : 0.007733650505542755
Loss at iteration 40 : 0.008723721839487553
Loss at iteration 50 : 0.012153953313827515
Loss at iteration 60 : 0.009708740748465061
Loss at iteration 70 : 0.00772425252944231
Loss at iteration 80 : 0.01063526887446642
Loss at iteration 90 : 0.012101655825972557
Loss at iteration 100 : 0.00984202977269888
Loss at iteration 110 : 0.013202568516135216
Loss at iteration 120 : 0.010941574349999428
Loss at iteration 130 : 0.007938575930893421
Loss at iteration 140 : 0.010662063956260681
Loss at iteration 150 : 0.013115682639181614
Loss at iteration 160 : 0.014081546105444431
Loss at iteration 170 : 0.00953296571969986
Loss at iteration 180 : 0.012340703047811985
Loss at iteration 190 : 0.008499348536133766
Loss at iteration 200 : 0.019327735528349876
Loss at iteration 210 : 0.01259036734700203
Loss at iteration 220 : 0.018824301660060883
Loss at iteration 230 : 0.012248963117599487
Loss at iteration 240 : 0.010403908789157867
Loss at iteration 250 : 0.007896292954683304
Loss at iteration 260 : 0.011910948902368546
Loss at iteration 270 : 0.015808865427970886
Loss at iteration 280 : 0.00950759369879961
Loss at iteration 290 : 0.01259615272283554
Loss at iteration 300 : 0.01922614499926567
Loss at iteration 310 : 0.016277171671390533
Loss at iteration 320 : 0.011350109241902828
Loss at iteration 330 : 0.013938569463789463
Loss at iteration 340 : 0.012856634333729744
Loss at iteration 350 : 0.006279177963733673
Loss at iteration 360 : 0.014208769425749779
Loss at iteration 370 : 0.008214719593524933
Loss at iteration 380 : 0.016831140965223312
Loss at iteration 390 : 0.014758138917386532
Loss at iteration 400 : 0.011379692703485489
Loss at iteration 410 : 0.013408279977738857
Loss at iteration 420 : 0.008173458278179169
Loss at iteration 430 : 0.016301095485687256
Loss at iteration 440 : 0.007163224741816521
Loss at iteration 450 : 0.017241068184375763
Loss at iteration 460 : 0.011869363486766815
Loss at iteration 470 : 0.012947726994752884
Loss at iteration 480 : 0.019087478518486023
Loss at iteration 490 : 0.008821234107017517
Loss at iteration 500 : 0.01274062693119049
Loss at iteration 510 : 0.009919004514813423
Loss at iteration 520 : 0.01215816754847765
Loss at iteration 530 : 0.012602027505636215
Loss at iteration 540 : 0.013355414383113384
Loss at iteration 550 : 0.02080877497792244
Loss at iteration 560 : 0.009918173775076866
Loss at iteration 570 : 0.016202669590711594
Loss at iteration 580 : 0.010013740509748459
Loss at iteration 590 : 0.016518715769052505
Loss at iteration 600 : 0.01915324106812477
Loss at iteration 610 : 0.00818082969635725
Loss at iteration 620 : 0.010830266401171684
Loss at iteration 630 : 0.009411104023456573
Loss at iteration 640 : 0.008658431470394135
Loss at iteration 650 : 0.013329419307410717
Loss at iteration 660 : 0.012719189748167992
Loss at iteration 670 : 0.014899005182087421
Loss at iteration 680 : 0.0074826376512646675
Loss at iteration 690 : 0.010717028751969337
Loss at iteration 700 : 0.010136290453374386
Loss at iteration 710 : 0.011823968030512333
Loss at iteration 720 : 0.010305117815732956
Loss at iteration 730 : 0.010418076068162918
Loss at iteration 740 : 0.009025754407048225
Loss at iteration 750 : 0.0060549527406692505
Loss at iteration 760 : 0.010093392804265022
Loss at iteration 770 : 0.008966912515461445
Loss at iteration 780 : 0.01742011308670044
Loss at iteration 790 : 0.00816412828862667
Loss at iteration 800 : 0.011448281817138195
Loss at iteration 810 : 0.015548797324299812
Loss at iteration 820 : 0.01235164888203144
Loss at iteration 830 : 0.011033538728952408
Loss at iteration 840 : 0.01252052839845419
Loss at iteration 850 : 0.01019600685685873
Loss at iteration 860 : 0.011661260388791561
Loss at iteration 870 : 0.012582945637404919
Loss at iteration 880 : 0.010150669142603874
Loss at iteration 890 : 0.013028963468968868
Loss at iteration 900 : 0.01216968521475792
Loss at iteration 910 : 0.01084059290587902
Loss at iteration 920 : 0.014407187700271606
Loss at iteration 930 : 0.011025376617908478
Loss at iteration 940 : 0.015062818303704262
Loss at iteration 950 : 0.01592078059911728
Loss at iteration 960 : 0.01816890761256218
Loss at iteration 970 : 0.010374147444963455
Loss at iteration 980 : 0.016563361510634422
Loss at iteration 990 : 0.005741553381085396
Loss at iteration 1000 : 0.010464651510119438
Loss at iteration 1010 : 0.014706100337207317
Loss at iteration 1020 : 0.01386562641710043
Loss at iteration 1030 : 0.004933576565235853
Loss at iteration 1040 : 0.012797122821211815
Loss at iteration 1050 : 0.007871288806200027
Loss at iteration 1060 : 0.011263245716691017
Loss at iteration 1070 : 0.009493572637438774
Loss at iteration 1080 : 0.004662009887397289
Loss at iteration 1090 : 0.019024545326828957
Loss at iteration 1100 : 0.009838288649916649
Loss at iteration 1110 : 0.006797707639634609
Loss at iteration 1120 : 0.009979747235774994
Loss at iteration 1130 : 0.01106895599514246
Loss at iteration 1140 : 0.008645095862448215
Loss at iteration 1150 : 0.006186025217175484
Loss at iteration 1160 : 0.011204716749489307
Loss at iteration 1170 : 0.006841931026428938
Loss at iteration 1180 : 0.015359746292233467
Loss at iteration 1190 : 0.013393718749284744
Loss at iteration 1200 : 0.01219910942018032
Loss at iteration 1210 : 0.009191658347845078
The SSIM Value is: 0.7997372547785441
The PSNR Value is: 18.153615442911782
the epoch is: 81
Loss at iteration 10 : 0.010965454392135143
Loss at iteration 20 : 0.010213392786681652
Loss at iteration 30 : 0.010884779505431652
Loss at iteration 40 : 0.015772752463817596
Loss at iteration 50 : 0.007279617711901665
Loss at iteration 60 : 0.005684354342520237
Loss at iteration 70 : 0.013551956042647362
Loss at iteration 80 : 0.024248920381069183
Loss at iteration 90 : 0.008409191854298115
Loss at iteration 100 : 0.012775504030287266
Loss at iteration 110 : 0.021873699501156807
Loss at iteration 120 : 0.015930164605379105
Loss at iteration 130 : 0.009060729295015335
Loss at iteration 140 : 0.0054822880774736404
Loss at iteration 150 : 0.014133764430880547
Loss at iteration 160 : 0.009596566669642925
Loss at iteration 170 : 0.007655583322048187
Loss at iteration 180 : 0.015812948346138
Loss at iteration 190 : 0.013028337620198727
Loss at iteration 200 : 0.01305632758885622
Loss at iteration 210 : 0.010264541953802109
Loss at iteration 220 : 0.013385603204369545
Loss at iteration 230 : 0.013848270289599895
Loss at iteration 240 : 0.012991832569241524
Loss at iteration 250 : 0.014398541301488876
Loss at iteration 260 : 0.007537166588008404
Loss at iteration 270 : 0.012669667601585388
Loss at iteration 280 : 0.010800743475556374
Loss at iteration 290 : 0.009909522719681263
Loss at iteration 300 : 0.01578129082918167
Loss at iteration 310 : 0.010645704343914986
Loss at iteration 320 : 0.011017298325896263
Loss at iteration 330 : 0.008329948410391808
Loss at iteration 340 : 0.011048444546759129
Loss at iteration 350 : 0.01563677191734314
Loss at iteration 360 : 0.014443499967455864
Loss at iteration 370 : 0.010195951908826828
Loss at iteration 380 : 0.009090844541788101
Loss at iteration 390 : 0.007544924505054951
Loss at iteration 400 : 0.013677192851901054
Loss at iteration 410 : 0.009645371697843075
Loss at iteration 420 : 0.01629127562046051
Loss at iteration 430 : 0.00871395692229271
Loss at iteration 440 : 0.009261485189199448
Loss at iteration 450 : 0.007380299270153046
Loss at iteration 460 : 0.010126768611371517
Loss at iteration 470 : 0.010226057842373848
Loss at iteration 480 : 0.008224890567362309
Loss at iteration 490 : 0.010691139847040176
Loss at iteration 500 : 0.019340787082910538
Loss at iteration 510 : 0.010570421814918518
Loss at iteration 520 : 0.019850797951221466
Loss at iteration 530 : 0.012580126523971558
Loss at iteration 540 : 0.016467511653900146
Loss at iteration 550 : 0.015227701514959335
Loss at iteration 560 : 0.004785831086337566
Loss at iteration 570 : 0.01750238612294197
Loss at iteration 580 : 0.008618282154202461
Loss at iteration 590 : 0.012802661396563053
Loss at iteration 600 : 0.014883949421346188
Loss at iteration 610 : 0.01373346894979477
Loss at iteration 620 : 0.01167561486363411
Loss at iteration 630 : 0.006725043524056673
Loss at iteration 640 : 0.011321455240249634
Loss at iteration 650 : 0.01078392006456852
Loss at iteration 660 : 0.009927668608725071
Loss at iteration 670 : 0.010089147835969925
Loss at iteration 680 : 0.009245035238564014
Loss at iteration 690 : 0.008817114867269993
Loss at iteration 700 : 0.008467119187116623
Loss at iteration 710 : 0.009017303586006165
Loss at iteration 720 : 0.006662128027528524
Loss at iteration 730 : 0.018205981701612473
Loss at iteration 740 : 0.011011261492967606
Loss at iteration 750 : 0.009916402399539948
Loss at iteration 760 : 0.011187500320374966
Loss at iteration 770 : 0.008104942739009857
Loss at iteration 780 : 0.01323431171476841
Loss at iteration 790 : 0.013977865688502789
Loss at iteration 800 : 0.012318508699536324
Loss at iteration 810 : 0.010731644928455353
Loss at iteration 820 : 0.007625764235854149
Loss at iteration 830 : 0.009237349033355713
Loss at iteration 840 : 0.014327341690659523
Loss at iteration 850 : 0.009009910747408867
Loss at iteration 860 : 0.012149735353887081
Loss at iteration 870 : 0.01502162218093872
Loss at iteration 880 : 0.011721585877239704
Loss at iteration 890 : 0.012082727625966072
Loss at iteration 900 : 0.012569490820169449
Loss at iteration 910 : 0.014390300959348679
Loss at iteration 920 : 0.012170825153589249
Loss at iteration 930 : 0.011542337015271187
Loss at iteration 940 : 0.015115246176719666
Loss at iteration 950 : 0.0129803866147995
Loss at iteration 960 : 0.008347701281309128
Loss at iteration 970 : 0.010872991755604744
Loss at iteration 980 : 0.008558564819395542
Loss at iteration 990 : 0.008733376860618591
Loss at iteration 1000 : 0.01102120615541935
Loss at iteration 1010 : 0.013589048758149147
Loss at iteration 1020 : 0.007239676546305418
Loss at iteration 1030 : 0.014446153305470943
Loss at iteration 1040 : 0.01747879758477211
Loss at iteration 1050 : 0.012074122205376625
Loss at iteration 1060 : 0.008869173936545849
Loss at iteration 1070 : 0.00998649001121521
Loss at iteration 1080 : 0.006675844080746174
Loss at iteration 1090 : 0.027817584574222565
Loss at iteration 1100 : 0.00901457667350769
Loss at iteration 1110 : 0.013027941808104515
Loss at iteration 1120 : 0.012989026494324207
Loss at iteration 1130 : 0.019100015982985497
Loss at iteration 1140 : 0.007807804271578789
Loss at iteration 1150 : 0.008870908990502357
Loss at iteration 1160 : 0.010447103530168533
Loss at iteration 1170 : 0.013829156756401062
Loss at iteration 1180 : 0.013293590396642685
Loss at iteration 1190 : 0.008052347227931023
Loss at iteration 1200 : 0.017897825688123703
Loss at iteration 1210 : 0.012168013490736485
The SSIM Value is: 0.8148688554763794
The PSNR Value is: 19.04131711324056
the epoch is: 82
Loss at iteration 10 : 0.011119796894490719
Loss at iteration 20 : 0.014597155153751373
Loss at iteration 30 : 0.014018064364790916
Loss at iteration 40 : 0.012035028077661991
Loss at iteration 50 : 0.011316449381411076
Loss at iteration 60 : 0.010150033980607986
Loss at iteration 70 : 0.009227300994098186
Loss at iteration 80 : 0.008727306500077248
Loss at iteration 90 : 0.010021020658314228
Loss at iteration 100 : 0.007209214381873608
Loss at iteration 110 : 0.012747538276016712
Loss at iteration 120 : 0.010146750137209892
Loss at iteration 130 : 0.004751531407237053
Loss at iteration 140 : 0.013236293569207191
Loss at iteration 150 : 0.012041802518069744
Loss at iteration 160 : 0.011627092957496643
Loss at iteration 170 : 0.009364544413983822
Loss at iteration 180 : 0.012759928591549397
Loss at iteration 190 : 0.014555932022631168
Loss at iteration 200 : 0.011151828803122044
Loss at iteration 210 : 0.008934743702411652
Loss at iteration 220 : 0.007149352692067623
Loss at iteration 230 : 0.0059889801777899265
Loss at iteration 240 : 0.01164443138986826
Loss at iteration 250 : 0.007413436193019152
Loss at iteration 260 : 0.012416687794029713
Loss at iteration 270 : 0.009681761264801025
Loss at iteration 280 : 0.012318828143179417
Loss at iteration 290 : 0.009899299591779709
Loss at iteration 300 : 0.008046157658100128
Loss at iteration 310 : 0.009180635213851929
Loss at iteration 320 : 0.010776113718748093
Loss at iteration 330 : 0.011658790521323681
Loss at iteration 340 : 0.014237743802368641
Loss at iteration 350 : 0.013495438732206821
Loss at iteration 360 : 0.011285560205578804
Loss at iteration 370 : 0.010783105157315731
Loss at iteration 380 : 0.019231099635362625
Loss at iteration 390 : 0.012282075360417366
Loss at iteration 400 : 0.00984067004173994
Loss at iteration 410 : 0.007490549702197313
Loss at iteration 420 : 0.013653760775923729
Loss at iteration 430 : 0.01160923670977354
Loss at iteration 440 : 0.01703345961868763
Loss at iteration 450 : 0.008762996643781662
Loss at iteration 460 : 0.01176549680531025
Loss at iteration 470 : 0.012034712359309196
Loss at iteration 480 : 0.00991895142942667
Loss at iteration 490 : 0.01112628448754549
Loss at iteration 500 : 0.010737257078289986
Loss at iteration 510 : 0.009034276008605957
Loss at iteration 520 : 0.010683836415410042
Loss at iteration 530 : 0.011278415098786354
Loss at iteration 540 : 0.014121334068477154
Loss at iteration 550 : 0.008704837411642075
Loss at iteration 560 : 0.012089250609278679
Loss at iteration 570 : 0.017880506813526154
Loss at iteration 580 : 0.011950455605983734
Loss at iteration 590 : 0.00948190875351429
Loss at iteration 600 : 0.008381135761737823
Loss at iteration 610 : 0.01075423788279295
Loss at iteration 620 : 0.009063180536031723
Loss at iteration 630 : 0.010157841257750988
Loss at iteration 640 : 0.008830277249217033
Loss at iteration 650 : 0.019813673570752144
Loss at iteration 660 : 0.01230479497462511
Loss at iteration 670 : 0.008808113634586334
Loss at iteration 680 : 0.009832405485212803
Loss at iteration 690 : 0.010917728766798973
Loss at iteration 700 : 0.012421106919646263
Loss at iteration 710 : 0.014470061287283897
Loss at iteration 720 : 0.014652756042778492
Loss at iteration 730 : 0.010950349271297455
Loss at iteration 740 : 0.011009570211172104
Loss at iteration 750 : 0.010818888433277607
Loss at iteration 760 : 0.008299475535750389
Loss at iteration 770 : 0.011805001646280289
Loss at iteration 780 : 0.011034485884010792
Loss at iteration 790 : 0.008470284752547741
Loss at iteration 800 : 0.011085066944360733
Loss at iteration 810 : 0.007585979998111725
Loss at iteration 820 : 0.016950830817222595
Loss at iteration 830 : 0.01292443834245205
Loss at iteration 840 : 0.010324552655220032
Loss at iteration 850 : 0.007649749517440796
Loss at iteration 860 : 0.011322729289531708
Loss at iteration 870 : 0.012998316437005997
Loss at iteration 880 : 0.011376563459634781
Loss at iteration 890 : 0.015659477561712265
Loss at iteration 900 : 0.007641111500561237
Loss at iteration 910 : 0.006613995414227247
Loss at iteration 920 : 0.015873687341809273
Loss at iteration 930 : 0.00732752401381731
Loss at iteration 940 : 0.007902916520833969
Loss at iteration 950 : 0.02046491764485836
Loss at iteration 960 : 0.018880615010857582
Loss at iteration 970 : 0.020270507782697678
Loss at iteration 980 : 0.00836181826889515
Loss at iteration 990 : 0.009204743430018425
Loss at iteration 1000 : 0.008808194659650326
Loss at iteration 1010 : 0.01419926155358553
Loss at iteration 1020 : 0.006252123974263668
Loss at iteration 1030 : 0.008823699317872524
Loss at iteration 1040 : 0.010784653946757317
Loss at iteration 1050 : 0.010694939643144608
Loss at iteration 1060 : 0.01234115194529295
Loss at iteration 1070 : 0.011486126109957695
Loss at iteration 1080 : 0.012359676882624626
Loss at iteration 1090 : 0.01842602714896202
Loss at iteration 1100 : 0.01449788361787796
Loss at iteration 1110 : 0.019929643720388412
Loss at iteration 1120 : 0.008104277774691582
Loss at iteration 1130 : 0.01359429582953453
Loss at iteration 1140 : 0.014083996415138245
Loss at iteration 1150 : 0.006790430285036564
Loss at iteration 1160 : 0.012058716267347336
Loss at iteration 1170 : 0.014403466135263443
Loss at iteration 1180 : 0.011953884735703468
Loss at iteration 1190 : 0.014834890142083168
Loss at iteration 1200 : 0.011649719439446926
Loss at iteration 1210 : 0.010494040325284004
The SSIM Value is: 0.8042974472045898
The PSNR Value is: 18.577472305297853
the epoch is: 83
Loss at iteration 10 : 0.012950272299349308
Loss at iteration 20 : 0.012429151684045792
Loss at iteration 30 : 0.02142702415585518
Loss at iteration 40 : 0.005543488077819347
Loss at iteration 50 : 0.010832300409674644
Loss at iteration 60 : 0.008329384960234165
Loss at iteration 70 : 0.011089622974395752
Loss at iteration 80 : 0.012809459120035172
Loss at iteration 90 : 0.011687980964779854
Loss at iteration 100 : 0.011482268571853638
Loss at iteration 110 : 0.006516237743198872
Loss at iteration 120 : 0.008989587426185608
Loss at iteration 130 : 0.010116967372596264
Loss at iteration 140 : 0.006715516559779644
Loss at iteration 150 : 0.01513825822621584
Loss at iteration 160 : 0.01616821624338627
Loss at iteration 170 : 0.013226330280303955
Loss at iteration 180 : 0.018445663154125214
Loss at iteration 190 : 0.011912943795323372
Loss at iteration 200 : 0.009058626368641853
Loss at iteration 210 : 0.019955173134803772
Loss at iteration 220 : 0.00552188279107213
Loss at iteration 230 : 0.01819165050983429
Loss at iteration 240 : 0.006931906566023827
Loss at iteration 250 : 0.007748839445412159
Loss at iteration 260 : 0.009063788689672947
Loss at iteration 270 : 0.015498930588364601
Loss at iteration 280 : 0.010121509432792664
Loss at iteration 290 : 0.007797964848577976
Loss at iteration 300 : 0.008497516624629498
Loss at iteration 310 : 0.00923314318060875
Loss at iteration 320 : 0.00795980915427208
Loss at iteration 330 : 0.015941906720399857
Loss at iteration 340 : 0.009605743922293186
Loss at iteration 350 : 0.012414071708917618
Loss at iteration 360 : 0.008673314936459064
Loss at iteration 370 : 0.007183134090155363
Loss at iteration 380 : 0.011637451127171516
Loss at iteration 390 : 0.010470292530953884
Loss at iteration 400 : 0.011982218362390995
Loss at iteration 410 : 0.008284643292427063
Loss at iteration 420 : 0.012870268896222115
Loss at iteration 430 : 0.010673949494957924
Loss at iteration 440 : 0.009817205369472504
Loss at iteration 450 : 0.010182039812207222
Loss at iteration 460 : 0.00839129276573658
Loss at iteration 470 : 0.010796882212162018
Loss at iteration 480 : 0.008685722947120667
Loss at iteration 490 : 0.013781269080936909
Loss at iteration 500 : 0.00960408803075552
Loss at iteration 510 : 0.011224850080907345
Loss at iteration 520 : 0.014705169945955276
Loss at iteration 530 : 0.006739112548530102
Loss at iteration 540 : 0.008265304379165173
Loss at iteration 550 : 0.017285099253058434
Loss at iteration 560 : 0.0061814323998987675
Loss at iteration 570 : 0.009853103198111057
Loss at iteration 580 : 0.01733730174601078
Loss at iteration 590 : 0.00735792750492692
Loss at iteration 600 : 0.027969680726528168
Loss at iteration 610 : 0.004965142346918583
Loss at iteration 620 : 0.007201113738119602
Loss at iteration 630 : 0.02070295624434948
Loss at iteration 640 : 0.007651458028703928
Loss at iteration 650 : 0.018119189888238907
Loss at iteration 660 : 0.009199464693665504
Loss at iteration 670 : 0.010927891358733177
Loss at iteration 680 : 0.00979201402515173
Loss at iteration 690 : 0.02065172605216503
Loss at iteration 700 : 0.008481714874505997
Loss at iteration 710 : 0.009894903749227524
Loss at iteration 720 : 0.01170978881418705
Loss at iteration 730 : 0.010469501838088036
Loss at iteration 740 : 0.012814713642001152
Loss at iteration 750 : 0.011581659317016602
Loss at iteration 760 : 0.009213775396347046
Loss at iteration 770 : 0.0057554589584469795
Loss at iteration 780 : 0.011002613231539726
Loss at iteration 790 : 0.008934615179896355
Loss at iteration 800 : 0.008494816720485687
Loss at iteration 810 : 0.015903430059552193
Loss at iteration 820 : 0.02111957222223282
Loss at iteration 830 : 0.0077518257312476635
Loss at iteration 840 : 0.008832994848489761
Loss at iteration 850 : 0.015840327367186546
Loss at iteration 860 : 0.007234374526888132
Loss at iteration 870 : 0.013876152224838734
Loss at iteration 880 : 0.014278524555265903
Loss at iteration 890 : 0.009726734831929207
Loss at iteration 900 : 0.010619213804602623
Loss at iteration 910 : 0.015853257849812508
Loss at iteration 920 : 0.00818578526377678
Loss at iteration 930 : 0.008310666307806969
Loss at iteration 940 : 0.008623557165265083
Loss at iteration 950 : 0.007018902339041233
Loss at iteration 960 : 0.0071164933033287525
Loss at iteration 970 : 0.01071274746209383
Loss at iteration 980 : 0.012660019099712372
Loss at iteration 990 : 0.012203614227473736
Loss at iteration 1000 : 0.013978429138660431
Loss at iteration 1010 : 0.010015079751610756
Loss at iteration 1020 : 0.00510232662782073
Loss at iteration 1030 : 0.010313518345355988
Loss at iteration 1040 : 0.012350273318588734
Loss at iteration 1050 : 0.010971338488161564
Loss at iteration 1060 : 0.009888457134366035
Loss at iteration 1070 : 0.006160261109471321
Loss at iteration 1080 : 0.007196740247309208
Loss at iteration 1090 : 0.006488013546913862
Loss at iteration 1100 : 0.02230723202228546
Loss at iteration 1110 : 0.007240661885589361
Loss at iteration 1120 : 0.005680561531335115
Loss at iteration 1130 : 0.009294632822275162
Loss at iteration 1140 : 0.012176789343357086
Loss at iteration 1150 : 0.016466978937387466
Loss at iteration 1160 : 0.01649428904056549
Loss at iteration 1170 : 0.016903743147850037
Loss at iteration 1180 : 0.012945642694830894
Loss at iteration 1190 : 0.012400126084685326
Loss at iteration 1200 : 0.012607921846210957
Loss at iteration 1210 : 0.015499710105359554
The SSIM Value is: 0.7893872022628784
The PSNR Value is: 18.089175923665366
the epoch is: 84
Loss at iteration 10 : 0.010550174862146378
Loss at iteration 20 : 0.006115789525210857
Loss at iteration 30 : 0.011608168482780457
Loss at iteration 40 : 0.010777574963867664
Loss at iteration 50 : 0.011100136674940586
Loss at iteration 60 : 0.009902805089950562
Loss at iteration 70 : 0.009972942993044853
Loss at iteration 80 : 0.014997649937868118
Loss at iteration 90 : 0.015911629423499107
Loss at iteration 100 : 0.011414457112550735
Loss at iteration 110 : 0.01569782942533493
Loss at iteration 120 : 0.013184000737965107
Loss at iteration 130 : 0.006334433797746897
Loss at iteration 140 : 0.011078971438109875
Loss at iteration 150 : 0.01901514083147049
Loss at iteration 160 : 0.010249389335513115
Loss at iteration 170 : 0.007841566577553749
Loss at iteration 180 : 0.016181085258722305
Loss at iteration 190 : 0.008626961149275303
Loss at iteration 200 : 0.02014906331896782
Loss at iteration 210 : 0.012917609885334969
Loss at iteration 220 : 0.013184288516640663
Loss at iteration 230 : 0.010697688907384872
Loss at iteration 240 : 0.009197885170578957
Loss at iteration 250 : 0.011202946305274963
Loss at iteration 260 : 0.011737612076103687
Loss at iteration 270 : 0.010749376378953457
Loss at iteration 280 : 0.007909479551017284
Loss at iteration 290 : 0.007823020219802856
Loss at iteration 300 : 0.01189371757209301
Loss at iteration 310 : 0.008634642697870731
Loss at iteration 320 : 0.011600138619542122
Loss at iteration 330 : 0.008320022374391556
Loss at iteration 340 : 0.007695415988564491
Loss at iteration 350 : 0.008007853291928768
Loss at iteration 360 : 0.021853365004062653
Loss at iteration 370 : 0.021459637209773064
Loss at iteration 380 : 0.01832979917526245
Loss at iteration 390 : 0.009824799373745918
Loss at iteration 400 : 0.009377753362059593
Loss at iteration 410 : 0.01460035890340805
Loss at iteration 420 : 0.00803469680249691
Loss at iteration 430 : 0.014274967834353447
Loss at iteration 440 : 0.012901987880468369
Loss at iteration 450 : 0.017446985468268394
Loss at iteration 460 : 0.00874098390340805
Loss at iteration 470 : 0.016507066786289215
Loss at iteration 480 : 0.01645958051085472
Loss at iteration 490 : 0.009636692702770233
Loss at iteration 500 : 0.01201300323009491
Loss at iteration 510 : 0.011429933831095695
Loss at iteration 520 : 0.00551910325884819
Loss at iteration 530 : 0.01718081533908844
Loss at iteration 540 : 0.008354108780622482
Loss at iteration 550 : 0.015146184712648392
Loss at iteration 560 : 0.014610270969569683
Loss at iteration 570 : 0.007325196638703346
Loss at iteration 580 : 0.008729740045964718
Loss at iteration 590 : 0.007143559865653515
Loss at iteration 600 : 0.014465888030827045
Loss at iteration 610 : 0.009722458198666573
Loss at iteration 620 : 0.005696083419024944
Loss at iteration 630 : 0.011537575162947178
Loss at iteration 640 : 0.011368735693395138
Loss at iteration 650 : 0.01026336569339037
Loss at iteration 660 : 0.021598758175969124
Loss at iteration 670 : 0.008274679072201252
Loss at iteration 680 : 0.007828351110219955
Loss at iteration 690 : 0.011334058828651905
Loss at iteration 700 : 0.010434519499540329
Loss at iteration 710 : 0.017448849976062775
Loss at iteration 720 : 0.010517819784581661
Loss at iteration 730 : 0.00825459137558937
Loss at iteration 740 : 0.005786712281405926
Loss at iteration 750 : 0.009317127987742424
Loss at iteration 760 : 0.015587585978209972
Loss at iteration 770 : 0.010393185541033745
Loss at iteration 780 : 0.006883428432047367
Loss at iteration 790 : 0.014105036854743958
Loss at iteration 800 : 0.012267809361219406
Loss at iteration 810 : 0.0061396025121212006
Loss at iteration 820 : 0.011435681022703648
Loss at iteration 830 : 0.008990216068923473
Loss at iteration 840 : 0.019499948248267174
Loss at iteration 850 : 0.010716493241488934
Loss at iteration 860 : 0.015184314921498299
Loss at iteration 870 : 0.014815576374530792
Loss at iteration 880 : 0.011949094012379646
Loss at iteration 890 : 0.00722857378423214
Loss at iteration 900 : 0.01538020372390747
Loss at iteration 910 : 0.012879080139100552
Loss at iteration 920 : 0.009768964722752571
Loss at iteration 930 : 0.01609872281551361
Loss at iteration 940 : 0.015560910105705261
Loss at iteration 950 : 0.013687739148736
Loss at iteration 960 : 0.009677807800471783
Loss at iteration 970 : 0.015364333987236023
Loss at iteration 980 : 0.00912579894065857
Loss at iteration 990 : 0.014579382725059986
Loss at iteration 1000 : 0.011528488248586655
Loss at iteration 1010 : 0.013767477124929428
Loss at iteration 1020 : 0.010743774473667145
Loss at iteration 1030 : 0.010998351499438286
Loss at iteration 1040 : 0.009580958634614944
Loss at iteration 1050 : 0.009203897789120674
Loss at iteration 1060 : 0.004187524318695068
Loss at iteration 1070 : 0.004731669556349516
Loss at iteration 1080 : 0.0125045757740736
Loss at iteration 1090 : 0.010748020373284817
Loss at iteration 1100 : 0.005453993566334248
Loss at iteration 1110 : 0.012321868911385536
Loss at iteration 1120 : 0.013940954580903053
Loss at iteration 1130 : 0.008554107509553432
Loss at iteration 1140 : 0.01094845775514841
Loss at iteration 1150 : 0.014251667074859142
Loss at iteration 1160 : 0.011707764118909836
Loss at iteration 1170 : 0.007446823641657829
Loss at iteration 1180 : 0.010612228885293007
Loss at iteration 1190 : 0.008799315430223942
Loss at iteration 1200 : 0.006929353345185518
Loss at iteration 1210 : 0.012353666126728058
The SSIM Value is: 0.8055280486742655
The PSNR Value is: 18.82759323120117
the epoch is: 85
Loss at iteration 10 : 0.008846811018884182
Loss at iteration 20 : 0.008572247810661793
Loss at iteration 30 : 0.011138750240206718
Loss at iteration 40 : 0.010193432681262493
Loss at iteration 50 : 0.02872563526034355
Loss at iteration 60 : 0.006990022491663694
Loss at iteration 70 : 0.011790824122726917
Loss at iteration 80 : 0.00849056988954544
Loss at iteration 90 : 0.01369543094187975
Loss at iteration 100 : 0.0076673454605042934
Loss at iteration 110 : 0.01238025538623333
Loss at iteration 120 : 0.007897885516285896
Loss at iteration 130 : 0.028119772672653198
Loss at iteration 140 : 0.015332309529185295
Loss at iteration 150 : 0.018584048375487328
Loss at iteration 160 : 0.00870263110846281
Loss at iteration 170 : 0.006986530963331461
Loss at iteration 180 : 0.021915467455983162
Loss at iteration 190 : 0.007766328752040863
Loss at iteration 200 : 0.019541200250387192
Loss at iteration 210 : 0.005482602398842573
Loss at iteration 220 : 0.012158655561506748
Loss at iteration 230 : 0.013425581157207489
Loss at iteration 240 : 0.012929189950227737
Loss at iteration 250 : 0.011529720388352871
Loss at iteration 260 : 0.015344001352787018
Loss at iteration 270 : 0.009443706832826138
Loss at iteration 280 : 0.020959191024303436
Loss at iteration 290 : 0.01169002428650856
Loss at iteration 300 : 0.008557984605431557
Loss at iteration 310 : 0.008198980242013931
Loss at iteration 320 : 0.013368510641157627
Loss at iteration 330 : 0.01100145373493433
Loss at iteration 340 : 0.013146470300853252
Loss at iteration 350 : 0.009384972974658012
Loss at iteration 360 : 0.008816618472337723
Loss at iteration 370 : 0.011523434892296791
Loss at iteration 380 : 0.013006279245018959
Loss at iteration 390 : 0.006175079382956028
Loss at iteration 400 : 0.011108353734016418
Loss at iteration 410 : 0.01298040896654129
Loss at iteration 420 : 0.019105970859527588
Loss at iteration 430 : 0.01029327791184187
Loss at iteration 440 : 0.010080852545797825
Loss at iteration 450 : 0.011983165517449379
Loss at iteration 460 : 0.012416314333677292
Loss at iteration 470 : 0.014373453333973885
Loss at iteration 480 : 0.021072309464216232
Loss at iteration 490 : 0.012143377214670181
Loss at iteration 500 : 0.016179364174604416
Loss at iteration 510 : 0.00892120972275734
Loss at iteration 520 : 0.012066653929650784
Loss at iteration 530 : 0.012161090038716793
Loss at iteration 540 : 0.00952088087797165
Loss at iteration 550 : 0.007704725489020348
Loss at iteration 560 : 0.01133759692311287
Loss at iteration 570 : 0.015068072825670242
Loss at iteration 580 : 0.009345058351755142
Loss at iteration 590 : 0.0077317701652646065
Loss at iteration 600 : 0.007551497779786587
Loss at iteration 610 : 0.008332571014761925
Loss at iteration 620 : 0.01399233192205429
Loss at iteration 630 : 0.010471232235431671
Loss at iteration 640 : 0.007910436019301414
Loss at iteration 650 : 0.009837895631790161
Loss at iteration 660 : 0.012798459269106388
Loss at iteration 670 : 0.014278210699558258
Loss at iteration 680 : 0.016998086124658585
Loss at iteration 690 : 0.01147849764674902
Loss at iteration 700 : 0.009041027165949345
Loss at iteration 710 : 0.014279299415647984
Loss at iteration 720 : 0.013727223500609398
Loss at iteration 730 : 0.009766587987542152
Loss at iteration 740 : 0.012305130250751972
Loss at iteration 750 : 0.0176691897213459
Loss at iteration 760 : 0.01298021711409092
Loss at iteration 770 : 0.014114368706941605
Loss at iteration 780 : 0.01576370932161808
Loss at iteration 790 : 0.0154550950974226
Loss at iteration 800 : 0.010983175598084927
Loss at iteration 810 : 0.011811308562755585
Loss at iteration 820 : 0.007508753798902035
Loss at iteration 830 : 0.008077438920736313
Loss at iteration 840 : 0.012011464685201645
Loss at iteration 850 : 0.01658649370074272
Loss at iteration 860 : 0.007814956828951836
Loss at iteration 870 : 0.014729456976056099
Loss at iteration 880 : 0.01809164322912693
Loss at iteration 890 : 0.012512076646089554
Loss at iteration 900 : 0.014951243996620178
Loss at iteration 910 : 0.00977368839085102
Loss at iteration 920 : 0.012786786071956158
Loss at iteration 930 : 0.009930957108736038
Loss at iteration 940 : 0.009070204570889473
Loss at iteration 950 : 0.012140857055783272
Loss at iteration 960 : 0.00801132619380951
Loss at iteration 970 : 0.012417728081345558
Loss at iteration 980 : 0.011677462607622147
Loss at iteration 990 : 0.013218206353485584
Loss at iteration 1000 : 0.01162712462246418
Loss at iteration 1010 : 0.008773824200034142
Loss at iteration 1020 : 0.01042797602713108
Loss at iteration 1030 : 0.005650543607771397
Loss at iteration 1040 : 0.008854402229189873
Loss at iteration 1050 : 0.015951916575431824
Loss at iteration 1060 : 0.015069215558469296
Loss at iteration 1070 : 0.007487953174859285
Loss at iteration 1080 : 0.011356391943991184
Loss at iteration 1090 : 0.008265094831585884
Loss at iteration 1100 : 0.011149587109684944
Loss at iteration 1110 : 0.008986620232462883
Loss at iteration 1120 : 0.006960444152355194
Loss at iteration 1130 : 0.008479146286845207
Loss at iteration 1140 : 0.018962716683745384
Loss at iteration 1150 : 0.01508775819092989
Loss at iteration 1160 : 0.011774128302931786
Loss at iteration 1170 : 0.01689254865050316
Loss at iteration 1180 : 0.00992767047137022
Loss at iteration 1190 : 0.013171822763979435
Loss at iteration 1200 : 0.013403739780187607
Loss at iteration 1210 : 0.017102986574172974
The SSIM Value is: 0.7980076114336649
The PSNR Value is: 18.062592188517254
the epoch is: 86
Loss at iteration 10 : 0.01670977659523487
Loss at iteration 20 : 0.012622139416635036
Loss at iteration 30 : 0.015533993020653725
Loss at iteration 40 : 0.014684788882732391
Loss at iteration 50 : 0.01456657238304615
Loss at iteration 60 : 0.018164291977882385
Loss at iteration 70 : 0.01059914194047451
Loss at iteration 80 : 0.02205265313386917
Loss at iteration 90 : 0.009933548048138618
Loss at iteration 100 : 0.013203100301325321
Loss at iteration 110 : 0.012102331966161728
Loss at iteration 120 : 0.011334818787872791
Loss at iteration 130 : 0.010635736398398876
Loss at iteration 140 : 0.0153395626693964
Loss at iteration 150 : 0.014991573989391327
Loss at iteration 160 : 0.010419254191219807
Loss at iteration 170 : 0.012835541740059853
Loss at iteration 180 : 0.009428733959794044
Loss at iteration 190 : 0.013745690695941448
Loss at iteration 200 : 0.012088368646800518
Loss at iteration 210 : 0.010060487315058708
Loss at iteration 220 : 0.007882023230195045
Loss at iteration 230 : 0.010474152863025665
Loss at iteration 240 : 0.009899831376969814
Loss at iteration 250 : 0.008933067321777344
Loss at iteration 260 : 0.00902713555842638
Loss at iteration 270 : 0.008969411253929138
Loss at iteration 280 : 0.011997759342193604
Loss at iteration 290 : 0.0102576008066535
Loss at iteration 300 : 0.012029035948216915
Loss at iteration 310 : 0.007878598757088184
Loss at iteration 320 : 0.01390908844769001
Loss at iteration 330 : 0.012580410577356815
Loss at iteration 340 : 0.00622239476069808
Loss at iteration 350 : 0.011398282833397388
Loss at iteration 360 : 0.006705684587359428
Loss at iteration 370 : 0.008333045057952404
Loss at iteration 380 : 0.010483582504093647
Loss at iteration 390 : 0.009169787168502808
Loss at iteration 400 : 0.012200961820781231
Loss at iteration 410 : 0.006829168647527695
Loss at iteration 420 : 0.010513709858059883
Loss at iteration 430 : 0.014592223800718784
Loss at iteration 440 : 0.011433972045779228
Loss at iteration 450 : 0.011860208585858345
Loss at iteration 460 : 0.011721751652657986
Loss at iteration 470 : 0.009141859598457813
Loss at iteration 480 : 0.010684886947274208
Loss at iteration 490 : 0.011217103339731693
Loss at iteration 500 : 0.015514247119426727
Loss at iteration 510 : 0.015301509760320187
Loss at iteration 520 : 0.007111203856766224
Loss at iteration 530 : 0.025005526840686798
Loss at iteration 540 : 0.012534977868199348
Loss at iteration 550 : 0.008499471470713615
Loss at iteration 560 : 0.010270463302731514
Loss at iteration 570 : 0.012514108791947365
Loss at iteration 580 : 0.017634959891438484
Loss at iteration 590 : 0.009034007787704468
Loss at iteration 600 : 0.010095714591443539
Loss at iteration 610 : 0.009646110236644745
Loss at iteration 620 : 0.011178726330399513
Loss at iteration 630 : 0.011270341463387012
Loss at iteration 640 : 0.015751350671052933
Loss at iteration 650 : 0.012007002718746662
Loss at iteration 660 : 0.010485779494047165
Loss at iteration 670 : 0.008029619231820107
Loss at iteration 680 : 0.01275930181145668
Loss at iteration 690 : 0.011605754494667053
Loss at iteration 700 : 0.01376114971935749
Loss at iteration 710 : 0.005776589270681143
Loss at iteration 720 : 0.012166304513812065
Loss at iteration 730 : 0.007446709554642439
Loss at iteration 740 : 0.008549206890165806
Loss at iteration 750 : 0.008387302048504353
Loss at iteration 760 : 0.009285391308367252
Loss at iteration 770 : 0.009627691470086575
Loss at iteration 780 : 0.007139377295970917
Loss at iteration 790 : 0.007837469689548016
Loss at iteration 800 : 0.009372703731060028
Loss at iteration 810 : 0.013343431055545807
Loss at iteration 820 : 0.00843842513859272
Loss at iteration 830 : 0.013449760153889656
Loss at iteration 840 : 0.0066300914622843266
Loss at iteration 850 : 0.023306742310523987
Loss at iteration 860 : 0.01502937451004982
Loss at iteration 870 : 0.021506763994693756
Loss at iteration 880 : 0.008491400629281998
Loss at iteration 890 : 0.014520791359245777
Loss at iteration 900 : 0.012027679942548275
Loss at iteration 910 : 0.006335521582514048
Loss at iteration 920 : 0.007510766386985779
Loss at iteration 930 : 0.009818987920880318
Loss at iteration 940 : 0.01548320334404707
Loss at iteration 950 : 0.007240802515298128
Loss at iteration 960 : 0.015813149511814117
Loss at iteration 970 : 0.01798359677195549
Loss at iteration 980 : 0.010401918552815914
Loss at iteration 990 : 0.013160455971956253
Loss at iteration 1000 : 0.014249501749873161
Loss at iteration 1010 : 0.01622617617249489
Loss at iteration 1020 : 0.012136233039200306
Loss at iteration 1030 : 0.017801688984036446
Loss at iteration 1040 : 0.008178634569048882
Loss at iteration 1050 : 0.009143877774477005
Loss at iteration 1060 : 0.007526830304414034
Loss at iteration 1070 : 0.010140268132090569
Loss at iteration 1080 : 0.014297738671302795
Loss at iteration 1090 : 0.012229391373693943
Loss at iteration 1100 : 0.017533522099256516
Loss at iteration 1110 : 0.011181691661477089
Loss at iteration 1120 : 0.011043554171919823
Loss at iteration 1130 : 0.010876432992517948
Loss at iteration 1140 : 0.006538878194987774
Loss at iteration 1150 : 0.01637144759297371
Loss at iteration 1160 : 0.012097532860934734
Loss at iteration 1170 : 0.010275330394506454
Loss at iteration 1180 : 0.014812606386840343
Loss at iteration 1190 : 0.011760220862925053
Loss at iteration 1200 : 0.01197605300694704
Loss at iteration 1210 : 0.011266110464930534
The SSIM Value is: 0.7926436543464661
The PSNR Value is: 17.700708134969076
the epoch is: 87
Loss at iteration 10 : 0.009151636622846127
Loss at iteration 20 : 0.010252377949655056
Loss at iteration 30 : 0.01137070544064045
Loss at iteration 40 : 0.019576983526349068
Loss at iteration 50 : 0.008864465169608593
Loss at iteration 60 : 0.011096584610641003
Loss at iteration 70 : 0.015552620403468609
Loss at iteration 80 : 0.010730319656431675
Loss at iteration 90 : 0.01782429963350296
Loss at iteration 100 : 0.012839734554290771
Loss at iteration 110 : 0.015107693150639534
Loss at iteration 120 : 0.011170104146003723
Loss at iteration 130 : 0.015624398365616798
Loss at iteration 140 : 0.010622525587677956
Loss at iteration 150 : 0.012822814285755157
Loss at iteration 160 : 0.009692816995084286
Loss at iteration 170 : 0.010882658883929253
Loss at iteration 180 : 0.018720615655183792
Loss at iteration 190 : 0.008413884788751602
Loss at iteration 200 : 0.012181551195681095
Loss at iteration 210 : 0.015866762027144432
Loss at iteration 220 : 0.017880652099847794
Loss at iteration 230 : 0.012692197225987911
Loss at iteration 240 : 0.00975047517567873
Loss at iteration 250 : 0.010456590913236141
Loss at iteration 260 : 0.009501604363322258
Loss at iteration 270 : 0.006502480711787939
Loss at iteration 280 : 0.009006090462207794
Loss at iteration 290 : 0.008845997974276543
Loss at iteration 300 : 0.009700246155261993
Loss at iteration 310 : 0.010360180400311947
Loss at iteration 320 : 0.007095555774867535
Loss at iteration 330 : 0.01102120615541935
Loss at iteration 340 : 0.016261978074908257
Loss at iteration 350 : 0.014703599736094475
Loss at iteration 360 : 0.010828335769474506
Loss at iteration 370 : 0.012702099978923798
Loss at iteration 380 : 0.014158632606267929
Loss at iteration 390 : 0.01560135930776596
Loss at iteration 400 : 0.008140062913298607
Loss at iteration 410 : 0.015888959169387817
Loss at iteration 420 : 0.0041829124093055725
Loss at iteration 430 : 0.007991814985871315
Loss at iteration 440 : 0.011642173863947392
Loss at iteration 450 : 0.020239343866705894
Loss at iteration 460 : 0.011766071431338787
Loss at iteration 470 : 0.013445399701595306
Loss at iteration 480 : 0.017009254544973373
Loss at iteration 490 : 0.00996427796781063
Loss at iteration 500 : 0.011716773733496666
Loss at iteration 510 : 0.011371813714504242
Loss at iteration 520 : 0.01147070899605751
Loss at iteration 530 : 0.018311522901058197
Loss at iteration 540 : 0.007592685054987669
Loss at iteration 550 : 0.011546792462468147
Loss at iteration 560 : 0.013104635290801525
Loss at iteration 570 : 0.014711886644363403
Loss at iteration 580 : 0.0091244513168931
Loss at iteration 590 : 0.011506564915180206
Loss at iteration 600 : 0.014722051098942757
Loss at iteration 610 : 0.008299188688397408
Loss at iteration 620 : 0.01099587045609951
Loss at iteration 630 : 0.011176160536706448
Loss at iteration 640 : 0.010734028182923794
Loss at iteration 650 : 0.014084750786423683
Loss at iteration 660 : 0.006401551887392998
Loss at iteration 670 : 0.011484679765999317
Loss at iteration 680 : 0.011363152414560318
Loss at iteration 690 : 0.008774477057158947
Loss at iteration 700 : 0.010181156918406487
Loss at iteration 710 : 0.016175806522369385
Loss at iteration 720 : 0.016527323052287102
Loss at iteration 730 : 0.017365064471960068
Loss at iteration 740 : 0.009578414261341095
Loss at iteration 750 : 0.011362487450242043
Loss at iteration 760 : 0.011364428326487541
Loss at iteration 770 : 0.01559778768569231
Loss at iteration 780 : 0.008021080866456032
Loss at iteration 790 : 0.011833541095256805
Loss at iteration 800 : 0.012269088067114353
Loss at iteration 810 : 0.009892545640468597
Loss at iteration 820 : 0.014313989318907261
Loss at iteration 830 : 0.007087373174726963
Loss at iteration 840 : 0.006886882241815329
Loss at iteration 850 : 0.0077593340538442135
Loss at iteration 860 : 0.015476807951927185
Loss at iteration 870 : 0.021744780242443085
Loss at iteration 880 : 0.01553548313677311
Loss at iteration 890 : 0.01969030126929283
Loss at iteration 900 : 0.011018920689821243
Loss at iteration 910 : 0.013839997351169586
Loss at iteration 920 : 0.0072233411483466625
Loss at iteration 930 : 0.008478942327201366
Loss at iteration 940 : 0.009335139766335487
Loss at iteration 950 : 0.01182510145008564
Loss at iteration 960 : 0.012431452982127666
Loss at iteration 970 : 0.013151602819561958
Loss at iteration 980 : 0.023710310459136963
Loss at iteration 990 : 0.006860530935227871
Loss at iteration 1000 : 0.016690904274582863
Loss at iteration 1010 : 0.011321283876895905
Loss at iteration 1020 : 0.014085964299738407
Loss at iteration 1030 : 0.010017153806984425
Loss at iteration 1040 : 0.015261387452483177
Loss at iteration 1050 : 0.014642505906522274
Loss at iteration 1060 : 0.013858102262020111
Loss at iteration 1070 : 0.015359168872237206
Loss at iteration 1080 : 0.011200533248484135
Loss at iteration 1090 : 0.02249918133020401
Loss at iteration 1100 : 0.010014252737164497
Loss at iteration 1110 : 0.010949209332466125
Loss at iteration 1120 : 0.010207056067883968
Loss at iteration 1130 : 0.015001695603132248
Loss at iteration 1140 : 0.01384267583489418
Loss at iteration 1150 : 0.010693957097828388
Loss at iteration 1160 : 0.014538927003741264
Loss at iteration 1170 : 0.010287992656230927
Loss at iteration 1180 : 0.013715730980038643
Loss at iteration 1190 : 0.011641323566436768
Loss at iteration 1200 : 0.015478596091270447
Loss at iteration 1210 : 0.012221276760101318
The SSIM Value is: 0.7956290404001872
The PSNR Value is: 18.353562355041504
the epoch is: 88
Loss at iteration 10 : 0.009083728305995464
Loss at iteration 20 : 0.014082353562116623
Loss at iteration 30 : 0.009997052140533924
Loss at iteration 40 : 0.005382351111620665
Loss at iteration 50 : 0.010803367011249065
Loss at iteration 60 : 0.009677169844508171
Loss at iteration 70 : 0.021988969296216965
Loss at iteration 80 : 0.014112550765275955
Loss at iteration 90 : 0.017408354207873344
Loss at iteration 100 : 0.007750897202640772
Loss at iteration 110 : 0.008958437480032444
Loss at iteration 120 : 0.010893696919083595
Loss at iteration 130 : 0.015633506700396538
Loss at iteration 140 : 0.010177027434110641
Loss at iteration 150 : 0.011178949847817421
Loss at iteration 160 : 0.0115229282528162
Loss at iteration 170 : 0.00964837335050106
Loss at iteration 180 : 0.011493165977299213
Loss at iteration 190 : 0.012451525777578354
Loss at iteration 200 : 0.009418705478310585
Loss at iteration 210 : 0.00862553808838129
Loss at iteration 220 : 0.009281120263040066
Loss at iteration 230 : 0.01703832671046257
Loss at iteration 240 : 0.011341539211571217
Loss at iteration 250 : 0.009832335636019707
Loss at iteration 260 : 0.017916886135935783
Loss at iteration 270 : 0.0071045756340026855
Loss at iteration 280 : 0.010392400436103344
Loss at iteration 290 : 0.007334096357226372
Loss at iteration 300 : 0.00996670313179493
Loss at iteration 310 : 0.006377589888870716
Loss at iteration 320 : 0.0086135845631361
Loss at iteration 330 : 0.017673742026090622
Loss at iteration 340 : 0.01086806133389473
Loss at iteration 350 : 0.012815927155315876
Loss at iteration 360 : 0.01068253442645073
Loss at iteration 370 : 0.010644959285855293
Loss at iteration 380 : 0.013358418829739094
Loss at iteration 390 : 0.011894969269633293
Loss at iteration 400 : 0.008118276484310627
Loss at iteration 410 : 0.008038372732698917
Loss at iteration 420 : 0.013809673488140106
Loss at iteration 430 : 0.014875013381242752
Loss at iteration 440 : 0.00786745548248291
Loss at iteration 450 : 0.005246483720839024
Loss at iteration 460 : 0.008742788806557655
Loss at iteration 470 : 0.01965257339179516
Loss at iteration 480 : 0.023376228287816048
Loss at iteration 490 : 0.014111505821347237
Loss at iteration 500 : 0.006519929505884647
Loss at iteration 510 : 0.01287918258458376
Loss at iteration 520 : 0.008122611790895462
Loss at iteration 530 : 0.010068530216813087
Loss at iteration 540 : 0.014948394149541855
Loss at iteration 550 : 0.016007443889975548
Loss at iteration 560 : 0.01640692539513111
Loss at iteration 570 : 0.009003343060612679
Loss at iteration 580 : 0.019521841779351234
Loss at iteration 590 : 0.014728749170899391
Loss at iteration 600 : 0.013627775944769382
Loss at iteration 610 : 0.011811400763690472
Loss at iteration 620 : 0.013089796528220177
Loss at iteration 630 : 0.014671389944851398
Loss at iteration 640 : 0.012505595572292805
Loss at iteration 650 : 0.009529383853077888
Loss at iteration 660 : 0.008664516732096672
Loss at iteration 670 : 0.011196519248187542
Loss at iteration 680 : 0.012928682379424572
Loss at iteration 690 : 0.010169263929128647
Loss at iteration 700 : 0.013750831596553326
Loss at iteration 710 : 0.01457966398447752
Loss at iteration 720 : 0.011341429315507412
Loss at iteration 730 : 0.008966668508946896
Loss at iteration 740 : 0.0114169055595994
Loss at iteration 750 : 0.009750369936227798
Loss at iteration 760 : 0.010842178016901016
Loss at iteration 770 : 0.008242111653089523
Loss at iteration 780 : 0.010166769847273827
Loss at iteration 790 : 0.009463599883019924
Loss at iteration 800 : 0.010636178776621819
Loss at iteration 810 : 0.011868552304804325
Loss at iteration 820 : 0.011854220181703568
Loss at iteration 830 : 0.013982314616441727
Loss at iteration 840 : 0.010183077305555344
Loss at iteration 850 : 0.017876403406262398
Loss at iteration 860 : 0.01883833296597004
Loss at iteration 870 : 0.011006639339029789
Loss at iteration 880 : 0.011841700412333012
Loss at iteration 890 : 0.018637072294950485
Loss at iteration 900 : 0.013089672662317753
Loss at iteration 910 : 0.010173800401389599
Loss at iteration 920 : 0.010205112397670746
Loss at iteration 930 : 0.011495335027575493
Loss at iteration 940 : 0.012130314484238625
Loss at iteration 950 : 0.012254584580659866
Loss at iteration 960 : 0.019349319860339165
Loss at iteration 970 : 0.01433364674448967
Loss at iteration 980 : 0.01137284655123949
Loss at iteration 990 : 0.014225334860384464
Loss at iteration 1000 : 0.010499697178602219
Loss at iteration 1010 : 0.007686606142669916
Loss at iteration 1020 : 0.007676524575799704
Loss at iteration 1030 : 0.009863774292171001
Loss at iteration 1040 : 0.017272280529141426
Loss at iteration 1050 : 0.009862884879112244
Loss at iteration 1060 : 0.008637463673949242
Loss at iteration 1070 : 0.011722423136234283
Loss at iteration 1080 : 0.0074804192408919334
Loss at iteration 1090 : 0.010321488603949547
Loss at iteration 1100 : 0.008829554542899132
Loss at iteration 1110 : 0.012071650475263596
Loss at iteration 1120 : 0.02516772970557213
Loss at iteration 1130 : 0.010914735496044159
Loss at iteration 1140 : 0.018717169761657715
Loss at iteration 1150 : 0.008392342366278172
Loss at iteration 1160 : 0.008966951631009579
Loss at iteration 1170 : 0.01550241932272911
Loss at iteration 1180 : 0.010794653557240963
Loss at iteration 1190 : 0.007309256587177515
Loss at iteration 1200 : 0.013538927771151066
Loss at iteration 1210 : 0.010374913923442364
The SSIM Value is: 0.7994159579277038
The PSNR Value is: 18.394287300109863
the epoch is: 89
Loss at iteration 10 : 0.012652503326535225
Loss at iteration 20 : 0.010988415218889713
Loss at iteration 30 : 0.008792667649686337
Loss at iteration 40 : 0.019314687699079514
Loss at iteration 50 : 0.009139449335634708
Loss at iteration 60 : 0.01241431012749672
Loss at iteration 70 : 0.009140567854046822
Loss at iteration 80 : 0.014870870858430862
Loss at iteration 90 : 0.012809840962290764
Loss at iteration 100 : 0.013899276964366436
Loss at iteration 110 : 0.01037617027759552
Loss at iteration 120 : 0.011408671736717224
Loss at iteration 130 : 0.009293715469539165
Loss at iteration 140 : 0.009547311812639236
Loss at iteration 150 : 0.010097615420818329
Loss at iteration 160 : 0.02075088769197464
Loss at iteration 170 : 0.013886108994483948
Loss at iteration 180 : 0.010310049168765545
Loss at iteration 190 : 0.0145310889929533
Loss at iteration 200 : 0.010359839536249638
Loss at iteration 210 : 0.008825420401990414
Loss at iteration 220 : 0.007387806661427021
Loss at iteration 230 : 0.01411112118512392
Loss at iteration 240 : 0.011121846735477448
Loss at iteration 250 : 0.01111471839249134
Loss at iteration 260 : 0.012957677245140076
Loss at iteration 270 : 0.008024068549275398
Loss at iteration 280 : 0.015484290197491646
Loss at iteration 290 : 0.016449978575110435
Loss at iteration 300 : 0.008664602413773537
Loss at iteration 310 : 0.008206668309867382
Loss at iteration 320 : 0.014389634132385254
Loss at iteration 330 : 0.020471397787332535
Loss at iteration 340 : 0.019528498873114586
Loss at iteration 350 : 0.014869822189211845
Loss at iteration 360 : 0.012581591494381428
Loss at iteration 370 : 0.011562888510525227
Loss at iteration 380 : 0.011952214874327183
Loss at iteration 390 : 0.013519251719117165
Loss at iteration 400 : 0.009826373308897018
Loss at iteration 410 : 0.00895173940807581
Loss at iteration 420 : 0.010506726801395416
Loss at iteration 430 : 0.004806551616638899
Loss at iteration 440 : 0.011331859976053238
Loss at iteration 450 : 0.010028446093201637
Loss at iteration 460 : 0.009406864643096924
Loss at iteration 470 : 0.021612131968140602
Loss at iteration 480 : 0.010530688799917698
Loss at iteration 490 : 0.0095575712621212
Loss at iteration 500 : 0.009879512712359428
Loss at iteration 510 : 0.008758952841162682
Loss at iteration 520 : 0.010261726565659046
Loss at iteration 530 : 0.009111689403653145
Loss at iteration 540 : 0.01846061646938324
Loss at iteration 550 : 0.007836825214326382
Loss at iteration 560 : 0.011659100651741028
Loss at iteration 570 : 0.011521280743181705
Loss at iteration 580 : 0.013296866789460182
Loss at iteration 590 : 0.009835497476160526
Loss at iteration 600 : 0.017432376742362976
Loss at iteration 610 : 0.015521623194217682
Loss at iteration 620 : 0.00916967075318098
Loss at iteration 630 : 0.006312352139502764
Loss at iteration 640 : 0.008047424256801605
Loss at iteration 650 : 0.010235917754471302
Loss at iteration 660 : 0.013219429180026054
Loss at iteration 670 : 0.01284836046397686
Loss at iteration 680 : 0.01142970286309719
Loss at iteration 690 : 0.008819046430289745
Loss at iteration 700 : 0.009726530872285366
Loss at iteration 710 : 0.015495000407099724
Loss at iteration 720 : 0.014206628315150738
Loss at iteration 730 : 0.011367806233465672
Loss at iteration 740 : 0.006665835622698069
Loss at iteration 750 : 0.00970945693552494
Loss at iteration 760 : 0.0104133365675807
Loss at iteration 770 : 0.014691116288304329
Loss at iteration 780 : 0.010029862634837627
Loss at iteration 790 : 0.014307411387562752
Loss at iteration 800 : 0.006527882535010576
Loss at iteration 810 : 0.009736179374158382
Loss at iteration 820 : 0.009122907184064388
Loss at iteration 830 : 0.01474781334400177
Loss at iteration 840 : 0.005617640912532806
Loss at iteration 850 : 0.012436997145414352
Loss at iteration 860 : 0.007066182792186737
Loss at iteration 870 : 0.007391050457954407
Loss at iteration 880 : 0.009132172912359238
Loss at iteration 890 : 0.0102926604449749
Loss at iteration 900 : 0.007606419734656811
Loss at iteration 910 : 0.011707084253430367
Loss at iteration 920 : 0.01716587133705616
Loss at iteration 930 : 0.01333265658468008
Loss at iteration 940 : 0.007217202335596085
Loss at iteration 950 : 0.006495236419141293
Loss at iteration 960 : 0.009191328659653664
Loss at iteration 970 : 0.009227201342582703
Loss at iteration 980 : 0.01033625565469265
Loss at iteration 990 : 0.012144293636083603
Loss at iteration 1000 : 0.013873632065951824
Loss at iteration 1010 : 0.015657048672437668
Loss at iteration 1020 : 0.009185101836919785
Loss at iteration 1030 : 0.010546086356043816
Loss at iteration 1040 : 0.011424701660871506
Loss at iteration 1050 : 0.009079218842089176
Loss at iteration 1060 : 0.010786294937133789
Loss at iteration 1070 : 0.007328658364713192
Loss at iteration 1080 : 0.018618501722812653
Loss at iteration 1090 : 0.01006005797535181
Loss at iteration 1100 : 0.008223254233598709
Loss at iteration 1110 : 0.009510715492069721
Loss at iteration 1120 : 0.01332294475287199
Loss at iteration 1130 : 0.009247209876775742
Loss at iteration 1140 : 0.010080376639962196
Loss at iteration 1150 : 0.008322902023792267
Loss at iteration 1160 : 0.019939815625548363
Loss at iteration 1170 : 0.008420380763709545
Loss at iteration 1180 : 0.012995913624763489
Loss at iteration 1190 : 0.006965614389628172
Loss at iteration 1200 : 0.009434722363948822
Loss at iteration 1210 : 0.013936877250671387
The SSIM Value is: 0.7935217301050822
The PSNR Value is: 18.374985122680663
the epoch is: 90
Loss at iteration 10 : 0.013435659930109978
Loss at iteration 20 : 0.01981975883245468
Loss at iteration 30 : 0.017075510695576668
Loss at iteration 40 : 0.006122778635472059
Loss at iteration 50 : 0.01235867664217949
Loss at iteration 60 : 0.0155965406447649
Loss at iteration 70 : 0.013257346116006374
Loss at iteration 80 : 0.013209741562604904
Loss at iteration 90 : 0.012020783498883247
Loss at iteration 100 : 0.01379577536135912
Loss at iteration 110 : 0.009419258683919907
Loss at iteration 120 : 0.009488529525697231
Loss at iteration 130 : 0.008580845780670643
Loss at iteration 140 : 0.011538666673004627
Loss at iteration 150 : 0.008048932068049908
Loss at iteration 160 : 0.009811840020120144
Loss at iteration 170 : 0.01152740977704525
Loss at iteration 180 : 0.01971421018242836
Loss at iteration 190 : 0.008988561108708382
Loss at iteration 200 : 0.009330559521913528
Loss at iteration 210 : 0.015592393465340137
Loss at iteration 220 : 0.006596280727535486
Loss at iteration 230 : 0.014643613249063492
Loss at iteration 240 : 0.012458731420338154
Loss at iteration 250 : 0.006554229650646448
Loss at iteration 260 : 0.00985658261924982
Loss at iteration 270 : 0.014163341373205185
Loss at iteration 280 : 0.015542661771178246
Loss at iteration 290 : 0.013075373135507107
Loss at iteration 300 : 0.01349818054586649
Loss at iteration 310 : 0.011806923896074295
Loss at iteration 320 : 0.023698346689343452
Loss at iteration 330 : 0.0099519994109869
Loss at iteration 340 : 0.009444398805499077
Loss at iteration 350 : 0.0058576371520757675
Loss at iteration 360 : 0.010945722460746765
Loss at iteration 370 : 0.012710245326161385
Loss at iteration 380 : 0.011491447687149048
Loss at iteration 390 : 0.006099791266024113
Loss at iteration 400 : 0.006181924603879452
Loss at iteration 410 : 0.012379541993141174
Loss at iteration 420 : 0.017123689875006676
Loss at iteration 430 : 0.008314264006912708
Loss at iteration 440 : 0.017641443759202957
Loss at iteration 450 : 0.011868707835674286
Loss at iteration 460 : 0.009970368817448616
Loss at iteration 470 : 0.019271384924650192
Loss at iteration 480 : 0.015241825953125954
Loss at iteration 490 : 0.008581498637795448
Loss at iteration 500 : 0.009363715536892414
Loss at iteration 510 : 0.0077200233936309814
Loss at iteration 520 : 0.013844081200659275
Loss at iteration 530 : 0.012162160128355026
Loss at iteration 540 : 0.01568768545985222
Loss at iteration 550 : 0.00765032134950161
Loss at iteration 560 : 0.015636103227734566
Loss at iteration 570 : 0.010950315743684769
Loss at iteration 580 : 0.013487264513969421
Loss at iteration 590 : 0.007511129602789879
Loss at iteration 600 : 0.011891631409525871
Loss at iteration 610 : 0.005651737097650766
Loss at iteration 620 : 0.013606383465230465
Loss at iteration 630 : 0.009052029810845852
Loss at iteration 640 : 0.017906686291098595
Loss at iteration 650 : 0.007788031827658415
Loss at iteration 660 : 0.014337228611111641
Loss at iteration 670 : 0.010406717658042908
Loss at iteration 680 : 0.015681661665439606
Loss at iteration 690 : 0.026133570820093155
Loss at iteration 700 : 0.0085424380376935
Loss at iteration 710 : 0.012817226350307465
Loss at iteration 720 : 0.009226354770362377
Loss at iteration 730 : 0.010159256868064404
Loss at iteration 740 : 0.007222938351333141
Loss at iteration 750 : 0.017171038314700127
Loss at iteration 760 : 0.009470008313655853
Loss at iteration 770 : 0.0117197185754776
Loss at iteration 780 : 0.010511180385947227
Loss at iteration 790 : 0.009908325970172882
Loss at iteration 800 : 0.020153796300292015
Loss at iteration 810 : 0.010914536193013191
Loss at iteration 820 : 0.013710228726267815
Loss at iteration 830 : 0.010763322003185749
Loss at iteration 840 : 0.007912436500191689
Loss at iteration 850 : 0.0104996208101511
Loss at iteration 860 : 0.010739622637629509
Loss at iteration 870 : 0.009962214156985283
Loss at iteration 880 : 0.011426692828536034
Loss at iteration 890 : 0.009584038518369198
Loss at iteration 900 : 0.007579520810395479
Loss at iteration 910 : 0.01184583269059658
Loss at iteration 920 : 0.012735363095998764
Loss at iteration 930 : 0.01380402222275734
Loss at iteration 940 : 0.00972745567560196
Loss at iteration 950 : 0.01861598715186119
Loss at iteration 960 : 0.011134501546621323
Loss at iteration 970 : 0.013199284672737122
Loss at iteration 980 : 0.02309049665927887
Loss at iteration 990 : 0.010642215609550476
Loss at iteration 1000 : 0.004930860362946987
Loss at iteration 1010 : 0.013544546440243721
Loss at iteration 1020 : 0.005996440537273884
Loss at iteration 1030 : 0.01879887655377388
Loss at iteration 1040 : 0.007450447883456945
Loss at iteration 1050 : 0.013414768502116203
Loss at iteration 1060 : 0.010116550140082836
Loss at iteration 1070 : 0.012753239832818508
Loss at iteration 1080 : 0.011768735945224762
Loss at iteration 1090 : 0.012297693639993668
Loss at iteration 1100 : 0.012236731126904488
Loss at iteration 1110 : 0.016926787793636322
Loss at iteration 1120 : 0.012112798169255257
Loss at iteration 1130 : 0.007227365858852863
Loss at iteration 1140 : 0.013519383035600185
Loss at iteration 1150 : 0.008253950625658035
Loss at iteration 1160 : 0.01177835464477539
Loss at iteration 1170 : 0.009056353010237217
Loss at iteration 1180 : 0.006538280751556158
Loss at iteration 1190 : 0.008504332974553108
Loss at iteration 1200 : 0.007847582921385765
Loss at iteration 1210 : 0.017999455332756042
The SSIM Value is: 0.8047183632850647
The PSNR Value is: 19.120520655314127
the epoch is: 91
Loss at iteration 10 : 0.009731068275868893
Loss at iteration 20 : 0.011852942407131195
Loss at iteration 30 : 0.01454131305217743
Loss at iteration 40 : 0.01345248892903328
Loss at iteration 50 : 0.014763611368834972
Loss at iteration 60 : 0.018596719950437546
Loss at iteration 70 : 0.009024819359183311
Loss at iteration 80 : 0.013074779883027077
Loss at iteration 90 : 0.006884410046041012
Loss at iteration 100 : 0.009830404072999954
Loss at iteration 110 : 0.012073410674929619
Loss at iteration 120 : 0.007640610449016094
Loss at iteration 130 : 0.010020112618803978
Loss at iteration 140 : 0.006951970048248768
Loss at iteration 150 : 0.0077972980216145515
Loss at iteration 160 : 0.010366850532591343
Loss at iteration 170 : 0.007355832029134035
Loss at iteration 180 : 0.01470165979117155
Loss at iteration 190 : 0.0070175486616790295
Loss at iteration 200 : 0.01182349119335413
Loss at iteration 210 : 0.01101085264235735
Loss at iteration 220 : 0.006340883206576109
Loss at iteration 230 : 0.01078978180885315
Loss at iteration 240 : 0.011910613626241684
Loss at iteration 250 : 0.012958631850779057
Loss at iteration 260 : 0.00812173169106245
Loss at iteration 270 : 0.015541790053248405
Loss at iteration 280 : 0.01179414987564087
Loss at iteration 290 : 0.004979756660759449
Loss at iteration 300 : 0.008564531803131104
Loss at iteration 310 : 0.009483544155955315
Loss at iteration 320 : 0.010503646917641163
Loss at iteration 330 : 0.013371560722589493
Loss at iteration 340 : 0.011074921116232872
Loss at iteration 350 : 0.009914599359035492
Loss at iteration 360 : 0.01509060151875019
Loss at iteration 370 : 0.019247017800807953
Loss at iteration 380 : 0.01638786867260933
Loss at iteration 390 : 0.007662281394004822
Loss at iteration 400 : 0.007536797784268856
Loss at iteration 410 : 0.011369157582521439
Loss at iteration 420 : 0.016492009162902832
Loss at iteration 430 : 0.010130857117474079
Loss at iteration 440 : 0.008086174726486206
Loss at iteration 450 : 0.014178200624883175
Loss at iteration 460 : 0.01644107885658741
Loss at iteration 470 : 0.012229329906404018
Loss at iteration 480 : 0.01599527895450592
Loss at iteration 490 : 0.016399547457695007
Loss at iteration 500 : 0.008943222463130951
Loss at iteration 510 : 0.010224228724837303
Loss at iteration 520 : 0.012377372942864895
Loss at iteration 530 : 0.009011664427816868
Loss at iteration 540 : 0.01172979362308979
Loss at iteration 550 : 0.01570568047463894
Loss at iteration 560 : 0.011011669412255287
Loss at iteration 570 : 0.0123512027785182
Loss at iteration 580 : 0.02436141110956669
Loss at iteration 590 : 0.00996212288737297
Loss at iteration 600 : 0.008373144082725048
Loss at iteration 610 : 0.011439058929681778
Loss at iteration 620 : 0.010219140909612179
Loss at iteration 630 : 0.008975151926279068
Loss at iteration 640 : 0.010980388149619102
Loss at iteration 650 : 0.00910462811589241
Loss at iteration 660 : 0.017457105219364166
Loss at iteration 670 : 0.012243733741343021
Loss at iteration 680 : 0.010323094204068184
Loss at iteration 690 : 0.01203733216971159
Loss at iteration 700 : 0.0076780859380960464
Loss at iteration 710 : 0.009307599626481533
Loss at iteration 720 : 0.011683927848935127
Loss at iteration 730 : 0.006985429674386978
Loss at iteration 740 : 0.020054953172802925
Loss at iteration 750 : 0.008322901092469692
Loss at iteration 760 : 0.010200034826993942
Loss at iteration 770 : 0.009311462752521038
Loss at iteration 780 : 0.006839280016720295
Loss at iteration 790 : 0.02273709513247013
Loss at iteration 800 : 0.005775038618594408
Loss at iteration 810 : 0.010427884757518768
Loss at iteration 820 : 0.012623396702110767
Loss at iteration 830 : 0.008354870602488518
Loss at iteration 840 : 0.01570928283035755
Loss at iteration 850 : 0.008345535956323147
Loss at iteration 860 : 0.007859396748244762
Loss at iteration 870 : 0.010007229633629322
Loss at iteration 880 : 0.010323574766516685
Loss at iteration 890 : 0.014197700656950474
Loss at iteration 900 : 0.008504088036715984
Loss at iteration 910 : 0.009454522281885147
Loss at iteration 920 : 0.012854904867708683
Loss at iteration 930 : 0.010687176138162613
Loss at iteration 940 : 0.008777573704719543
Loss at iteration 950 : 0.009039289318025112
Loss at iteration 960 : 0.00771462544798851
Loss at iteration 970 : 0.013109128922224045
Loss at iteration 980 : 0.009499337524175644
Loss at iteration 990 : 0.015801535919308662
Loss at iteration 1000 : 0.013387106359004974
Loss at iteration 1010 : 0.011202838271856308
Loss at iteration 1020 : 0.006987918168306351
Loss at iteration 1030 : 0.00838126614689827
Loss at iteration 1040 : 0.009201845154166222
Loss at iteration 1050 : 0.011664029210805893
Loss at iteration 1060 : 0.009113319218158722
Loss at iteration 1070 : 0.015325677581131458
Loss at iteration 1080 : 0.00613351259380579
Loss at iteration 1090 : 0.011387734673917294
Loss at iteration 1100 : 0.009440351277589798
Loss at iteration 1110 : 0.008703858591616154
Loss at iteration 1120 : 0.02407960593700409
Loss at iteration 1130 : 0.012156719341874123
Loss at iteration 1140 : 0.022045336663722992
Loss at iteration 1150 : 0.010596774518489838
Loss at iteration 1160 : 0.010295613668859005
Loss at iteration 1170 : 0.007173789665102959
Loss at iteration 1180 : 0.011506786569952965
Loss at iteration 1190 : 0.015010269358754158
Loss at iteration 1200 : 0.012623418122529984
Loss at iteration 1210 : 0.0063169533386826515
The SSIM Value is: 0.8112300634384155
The PSNR Value is: 19.152241770426432
the epoch is: 92
Loss at iteration 10 : 0.00774962967261672
Loss at iteration 20 : 0.010763948783278465
Loss at iteration 30 : 0.00975986197590828
Loss at iteration 40 : 0.011791490018367767
Loss at iteration 50 : 0.012717943638563156
Loss at iteration 60 : 0.008217690512537956
Loss at iteration 70 : 0.012504711747169495
Loss at iteration 80 : 0.019506270065903664
Loss at iteration 90 : 0.011476138606667519
Loss at iteration 100 : 0.01784083992242813
Loss at iteration 110 : 0.009128537960350513
Loss at iteration 120 : 0.00880315713584423
Loss at iteration 130 : 0.007657763082534075
Loss at iteration 140 : 0.015840735286474228
Loss at iteration 150 : 0.008531305938959122
Loss at iteration 160 : 0.009321736171841621
Loss at iteration 170 : 0.008664734661579132
Loss at iteration 180 : 0.01308374758809805
Loss at iteration 190 : 0.008113269694149494
Loss at iteration 200 : 0.012029450386762619
Loss at iteration 210 : 0.0076597910374403
Loss at iteration 220 : 0.006427260581403971
Loss at iteration 230 : 0.009898236952722073
Loss at iteration 240 : 0.01074476633220911
Loss at iteration 250 : 0.01387051586061716
Loss at iteration 260 : 0.01620161533355713
Loss at iteration 270 : 0.012170618399977684
Loss at iteration 280 : 0.010715087875723839
Loss at iteration 290 : 0.013757048174738884
Loss at iteration 300 : 0.01373392716050148
Loss at iteration 310 : 0.009028621017932892
Loss at iteration 320 : 0.015512672252953053
Loss at iteration 330 : 0.007495108060538769
Loss at iteration 340 : 0.007804982829838991
Loss at iteration 350 : 0.010269620455801487
Loss at iteration 360 : 0.013828286901116371
Loss at iteration 370 : 0.012451570481061935
Loss at iteration 380 : 0.010476437397301197
Loss at iteration 390 : 0.008435146883130074
Loss at iteration 400 : 0.01666703261435032
Loss at iteration 410 : 0.014223885722458363
Loss at iteration 420 : 0.007841420359909534
Loss at iteration 430 : 0.007893923670053482
Loss at iteration 440 : 0.008967414498329163
Loss at iteration 450 : 0.01025910023599863
Loss at iteration 460 : 0.007155013270676136
Loss at iteration 470 : 0.013633809983730316
Loss at iteration 480 : 0.01783299632370472
Loss at iteration 490 : 0.010435598902404308
Loss at iteration 500 : 0.0099520618095994
Loss at iteration 510 : 0.008266778662800789
Loss at iteration 520 : 0.011236971244215965
Loss at iteration 530 : 0.008535226806998253
Loss at iteration 540 : 0.009084148332476616
Loss at iteration 550 : 0.014682499691843987
Loss at iteration 560 : 0.01387452520430088
Loss at iteration 570 : 0.009557906538248062
Loss at iteration 580 : 0.01836491748690605
Loss at iteration 590 : 0.011092258617281914
Loss at iteration 600 : 0.009054680354893208
Loss at iteration 610 : 0.007413832005113363
Loss at iteration 620 : 0.014202682301402092
Loss at iteration 630 : 0.006357545033097267
Loss at iteration 640 : 0.006016845349222422
Loss at iteration 650 : 0.0088503398001194
Loss at iteration 660 : 0.0114110903814435
Loss at iteration 670 : 0.006598928011953831
Loss at iteration 680 : 0.01303832232952118
Loss at iteration 690 : 0.016139881685376167
Loss at iteration 700 : 0.009174211882054806
Loss at iteration 710 : 0.007287327200174332
Loss at iteration 720 : 0.02070336788892746
Loss at iteration 730 : 0.019626222550868988
Loss at iteration 740 : 0.008530139923095703
Loss at iteration 750 : 0.009991627186536789
Loss at iteration 760 : 0.009830517694354057
Loss at iteration 770 : 0.013155940920114517
Loss at iteration 780 : 0.011091179214417934
Loss at iteration 790 : 0.02547117881476879
Loss at iteration 800 : 0.027167823165655136
Loss at iteration 810 : 0.015884004533290863
Loss at iteration 820 : 0.007927248254418373
Loss at iteration 830 : 0.009995141997933388
Loss at iteration 840 : 0.014791885390877724
Loss at iteration 850 : 0.009125607088208199
Loss at iteration 860 : 0.010482443496584892
Loss at iteration 870 : 0.0071386913768947124
Loss at iteration 880 : 0.019761543720960617
Loss at iteration 890 : 0.016199085861444473
Loss at iteration 900 : 0.007980233058333397
Loss at iteration 910 : 0.013971434906125069
Loss at iteration 920 : 0.01006670668721199
Loss at iteration 930 : 0.00944620929658413
Loss at iteration 940 : 0.010158104822039604
Loss at iteration 950 : 0.011783663183450699
Loss at iteration 960 : 0.0106161218136549
Loss at iteration 970 : 0.00829463079571724
Loss at iteration 980 : 0.013171161524951458
Loss at iteration 990 : 0.01369020901620388
Loss at iteration 1000 : 0.014690615236759186
Loss at iteration 1010 : 0.010512856766581535
Loss at iteration 1020 : 0.00810050405561924
Loss at iteration 1030 : 0.009474419057369232
Loss at iteration 1040 : 0.010632827877998352
Loss at iteration 1050 : 0.008837735280394554
Loss at iteration 1060 : 0.010190455242991447
Loss at iteration 1070 : 0.009289313107728958
Loss at iteration 1080 : 0.01445566676557064
Loss at iteration 1090 : 0.010464094579219818
Loss at iteration 1100 : 0.01013203989714384
Loss at iteration 1110 : 0.018155144527554512
Loss at iteration 1120 : 0.00924784317612648
Loss at iteration 1130 : 0.007367866113781929
Loss at iteration 1140 : 0.011916033923625946
Loss at iteration 1150 : 0.008897390216588974
Loss at iteration 1160 : 0.00866070855408907
Loss at iteration 1170 : 0.013525590300559998
Loss at iteration 1180 : 0.01013134978711605
Loss at iteration 1190 : 0.008780374191701412
Loss at iteration 1200 : 0.012383107095956802
Loss at iteration 1210 : 0.012971094809472561
The SSIM Value is: 0.8018040855725607
The PSNR Value is: 18.81859436035156
the epoch is: 93
Loss at iteration 10 : 0.013171808794140816
Loss at iteration 20 : 0.012906141579151154
Loss at iteration 30 : 0.013446718454360962
Loss at iteration 40 : 0.010743026621639729
Loss at iteration 50 : 0.013527094386518002
Loss at iteration 60 : 0.008377998135983944
Loss at iteration 70 : 0.012857368215918541
Loss at iteration 80 : 0.01504683680832386
Loss at iteration 90 : 0.013711215928196907
Loss at iteration 100 : 0.009695685468614101
Loss at iteration 110 : 0.007006064988672733
Loss at iteration 120 : 0.007194187492132187
Loss at iteration 130 : 0.008917832747101784
Loss at iteration 140 : 0.02256748452782631
Loss at iteration 150 : 0.00939279142767191
Loss at iteration 160 : 0.006194862071424723
Loss at iteration 170 : 0.013914999552071095
Loss at iteration 180 : 0.006236969493329525
Loss at iteration 190 : 0.009142703376710415
Loss at iteration 200 : 0.0075635723769664764
Loss at iteration 210 : 0.013982569798827171
Loss at iteration 220 : 0.009946956299245358
Loss at iteration 230 : 0.014308711513876915
Loss at iteration 240 : 0.007867633365094662
Loss at iteration 250 : 0.008306780830025673
Loss at iteration 260 : 0.012001370079815388
Loss at iteration 270 : 0.008844830095767975
Loss at iteration 280 : 0.005372037645429373
Loss at iteration 290 : 0.0051484489813447
Loss at iteration 300 : 0.009214119054377079
Loss at iteration 310 : 0.012468368746340275
Loss at iteration 320 : 0.005476800724864006
Loss at iteration 330 : 0.007014596834778786
Loss at iteration 340 : 0.008727282285690308
Loss at iteration 350 : 0.007744563743472099
Loss at iteration 360 : 0.00785262230783701
Loss at iteration 370 : 0.007460981607437134
Loss at iteration 380 : 0.01471829041838646
Loss at iteration 390 : 0.007374225649982691
Loss at iteration 400 : 0.01361655630171299
Loss at iteration 410 : 0.017467893660068512
Loss at iteration 420 : 0.013678713701665401
Loss at iteration 430 : 0.008808251470327377
Loss at iteration 440 : 0.013868339359760284
Loss at iteration 450 : 0.013398506678640842
Loss at iteration 460 : 0.005716495215892792
Loss at iteration 470 : 0.00743462610989809
Loss at iteration 480 : 0.014442503452301025
Loss at iteration 490 : 0.01912713423371315
Loss at iteration 500 : 0.00801372341811657
Loss at iteration 510 : 0.010561314411461353
Loss at iteration 520 : 0.010547397658228874
Loss at iteration 530 : 0.015469519421458244
Loss at iteration 540 : 0.010873722843825817
Loss at iteration 550 : 0.008128471672534943
Loss at iteration 560 : 0.012214764952659607
Loss at iteration 570 : 0.00470131216570735
Loss at iteration 580 : 0.016615979373455048
Loss at iteration 590 : 0.012636436149477959
Loss at iteration 600 : 0.009116659872233868
Loss at iteration 610 : 0.012397769838571548
Loss at iteration 620 : 0.01119002141058445
Loss at iteration 630 : 0.01631588116288185
Loss at iteration 640 : 0.008440789766609669
Loss at iteration 650 : 0.010140377096831799
Loss at iteration 660 : 0.014145851135253906
Loss at iteration 670 : 0.01124285627156496
Loss at iteration 680 : 0.008527002297341824
Loss at iteration 690 : 0.010066761635243893
Loss at iteration 700 : 0.00999236386269331
Loss at iteration 710 : 0.012647991999983788
Loss at iteration 720 : 0.008228251710534096
Loss at iteration 730 : 0.0073659042827785015
Loss at iteration 740 : 0.012547459453344345
Loss at iteration 750 : 0.008740263059735298
Loss at iteration 760 : 0.009784238412976265
Loss at iteration 770 : 0.013129707425832748
Loss at iteration 780 : 0.017145870253443718
Loss at iteration 790 : 0.014254724606871605
Loss at iteration 800 : 0.011223046109080315
Loss at iteration 810 : 0.009346410632133484
Loss at iteration 820 : 0.011402152478694916
Loss at iteration 830 : 0.011307228356599808
Loss at iteration 840 : 0.009433703497052193
Loss at iteration 850 : 0.011780972592532635
Loss at iteration 860 : 0.009909821674227715
Loss at iteration 870 : 0.01602127030491829
Loss at iteration 880 : 0.011004583910107613
Loss at iteration 890 : 0.01461523026227951
Loss at iteration 900 : 0.014687477611005306
Loss at iteration 910 : 0.010643139481544495
Loss at iteration 920 : 0.009702778421342373
Loss at iteration 930 : 0.008931733667850494
Loss at iteration 940 : 0.012470806017518044
Loss at iteration 950 : 0.00727655366063118
Loss at iteration 960 : 0.01115497387945652
Loss at iteration 970 : 0.008704678155481815
Loss at iteration 980 : 0.010337739251554012
Loss at iteration 990 : 0.009116820991039276
Loss at iteration 1000 : 0.009962893091142178
Loss at iteration 1010 : 0.009731978178024292
Loss at iteration 1020 : 0.008953498676419258
Loss at iteration 1030 : 0.008369325660169125
Loss at iteration 1040 : 0.008404252119362354
Loss at iteration 1050 : 0.017490195110440254
Loss at iteration 1060 : 0.011973167769610882
Loss at iteration 1070 : 0.005900834687054157
Loss at iteration 1080 : 0.01669909432530403
Loss at iteration 1090 : 0.004134741146117449
Loss at iteration 1100 : 0.012105046771466732
Loss at iteration 1110 : 0.011310795322060585
Loss at iteration 1120 : 0.008859810419380665
Loss at iteration 1130 : 0.01719382032752037
Loss at iteration 1140 : 0.011457603424787521
Loss at iteration 1150 : 0.02006779983639717
Loss at iteration 1160 : 0.01380565483123064
Loss at iteration 1170 : 0.011080289259552956
Loss at iteration 1180 : 0.008741063997149467
Loss at iteration 1190 : 0.012367192655801773
Loss at iteration 1200 : 0.014952186495065689
Loss at iteration 1210 : 0.011620573699474335
The SSIM Value is: 0.7462877452373504
The PSNR Value is: 16.253019714355467
the epoch is: 94
Loss at iteration 10 : 0.011890147812664509
Loss at iteration 20 : 0.011346187442541122
Loss at iteration 30 : 0.014128506183624268
Loss at iteration 40 : 0.00506681390106678
Loss at iteration 50 : 0.011966574005782604
Loss at iteration 60 : 0.015694011002779007
Loss at iteration 70 : 0.01007724180817604
Loss at iteration 80 : 0.014265624806284904
Loss at iteration 90 : 0.013906288892030716
Loss at iteration 100 : 0.009922640398144722
Loss at iteration 110 : 0.008734136819839478
Loss at iteration 120 : 0.00906030461192131
Loss at iteration 130 : 0.008225947618484497
Loss at iteration 140 : 0.009482682682573795
Loss at iteration 150 : 0.009840821847319603
Loss at iteration 160 : 0.016646727919578552
Loss at iteration 170 : 0.013906125910580158
Loss at iteration 180 : 0.01342177763581276
Loss at iteration 190 : 0.005342014133930206
Loss at iteration 200 : 0.012206891551613808
Loss at iteration 210 : 0.010091675445437431
Loss at iteration 220 : 0.008535249158740044
Loss at iteration 230 : 0.01694970577955246
Loss at iteration 240 : 0.008509760722517967
Loss at iteration 250 : 0.014266842044889927
Loss at iteration 260 : 0.015995405614376068
Loss at iteration 270 : 0.0061916569247841835
Loss at iteration 280 : 0.011373900808393955
Loss at iteration 290 : 0.013127480633556843
Loss at iteration 300 : 0.009865851141512394
Loss at iteration 310 : 0.008718105964362621
Loss at iteration 320 : 0.011453978717327118
Loss at iteration 330 : 0.007750044576823711
Loss at iteration 340 : 0.00869673490524292
Loss at iteration 350 : 0.012765169143676758
Loss at iteration 360 : 0.00881602056324482
Loss at iteration 370 : 0.011511395685374737
Loss at iteration 380 : 0.00893107708543539
Loss at iteration 390 : 0.01158282719552517
Loss at iteration 400 : 0.013336912728846073
Loss at iteration 410 : 0.012607927434146404
Loss at iteration 420 : 0.00794442929327488
Loss at iteration 430 : 0.02278130128979683
Loss at iteration 440 : 0.011507948860526085
Loss at iteration 450 : 0.009697644039988518
Loss at iteration 460 : 0.013065151870250702
Loss at iteration 470 : 0.0066683730110526085
Loss at iteration 480 : 0.01614999957382679
Loss at iteration 490 : 0.009958830662071705
Loss at iteration 500 : 0.008490761741995811
Loss at iteration 510 : 0.007196159102022648
Loss at iteration 520 : 0.009647587314248085
Loss at iteration 530 : 0.016356296837329865
Loss at iteration 540 : 0.00995964091271162
Loss at iteration 550 : 0.01323767937719822
Loss at iteration 560 : 0.013318004086613655
Loss at iteration 570 : 0.006221184507012367
Loss at iteration 580 : 0.00860136654227972
Loss at iteration 590 : 0.007772388402372599
Loss at iteration 600 : 0.01089765876531601
Loss at iteration 610 : 0.004819993395358324
Loss at iteration 620 : 0.006353394128382206
Loss at iteration 630 : 0.015789903700351715
Loss at iteration 640 : 0.013429194688796997
Loss at iteration 650 : 0.006402667611837387
Loss at iteration 660 : 0.014293491840362549
Loss at iteration 670 : 0.01563923805952072
Loss at iteration 680 : 0.011864905245602131
Loss at iteration 690 : 0.013275492936372757
Loss at iteration 700 : 0.013323058374226093
Loss at iteration 710 : 0.011568703688681126
Loss at iteration 720 : 0.024929232895374298
Loss at iteration 730 : 0.009886788204312325
Loss at iteration 740 : 0.007562926039099693
Loss at iteration 750 : 0.009900335222482681
Loss at iteration 760 : 0.013460617512464523
Loss at iteration 770 : 0.012035896070301533
Loss at iteration 780 : 0.01952376961708069
Loss at iteration 790 : 0.011997847817838192
Loss at iteration 800 : 0.007317307870835066
Loss at iteration 810 : 0.020950622856616974
Loss at iteration 820 : 0.00892435573041439
Loss at iteration 830 : 0.011374427005648613
Loss at iteration 840 : 0.0082881860435009
Loss at iteration 850 : 0.010801696218550205
Loss at iteration 860 : 0.011253777891397476
Loss at iteration 870 : 0.01257188618183136
Loss at iteration 880 : 0.0062955571338534355
Loss at iteration 890 : 0.018034081906080246
Loss at iteration 900 : 0.010481835342943668
Loss at iteration 910 : 0.011552361771464348
Loss at iteration 920 : 0.01434982568025589
Loss at iteration 930 : 0.014708807691931725
Loss at iteration 940 : 0.014061877503991127
Loss at iteration 950 : 0.0138601278886199
Loss at iteration 960 : 0.00976561103016138
Loss at iteration 970 : 0.007616319227963686
Loss at iteration 980 : 0.011753739789128304
Loss at iteration 990 : 0.009212336502969265
Loss at iteration 1000 : 0.012393958866596222
Loss at iteration 1010 : 0.014096293598413467
Loss at iteration 1020 : 0.008524861186742783
Loss at iteration 1030 : 0.0071189068257808685
Loss at iteration 1040 : 0.008806901052594185
Loss at iteration 1050 : 0.021026860922574997
Loss at iteration 1060 : 0.011168510653078556
Loss at iteration 1070 : 0.007378264330327511
Loss at iteration 1080 : 0.008084961213171482
Loss at iteration 1090 : 0.009553813375532627
Loss at iteration 1100 : 0.011172743514180183
Loss at iteration 1110 : 0.008766459301114082
Loss at iteration 1120 : 0.012613050639629364
Loss at iteration 1130 : 0.006135026458650827
Loss at iteration 1140 : 0.01070659514516592
Loss at iteration 1150 : 0.008478548377752304
Loss at iteration 1160 : 0.0067071071825921535
Loss at iteration 1170 : 0.006931493990123272
Loss at iteration 1180 : 0.01721826381981373
Loss at iteration 1190 : 0.01130466628819704
Loss at iteration 1200 : 0.008851340040564537
Loss at iteration 1210 : 0.013212696649134159
The SSIM Value is: 0.7883619070053101
The PSNR Value is: 18.225893465677895
the epoch is: 95
Loss at iteration 10 : 0.010621817782521248
Loss at iteration 20 : 0.01086449809372425
Loss at iteration 30 : 0.011255532503128052
Loss at iteration 40 : 0.008618530817329884
Loss at iteration 50 : 0.007935297675430775
Loss at iteration 60 : 0.016462380066514015
Loss at iteration 70 : 0.009613990783691406
Loss at iteration 80 : 0.00867040827870369
Loss at iteration 90 : 0.008356362581253052
Loss at iteration 100 : 0.008568337187170982
Loss at iteration 110 : 0.013386605307459831
Loss at iteration 120 : 0.013814780861139297
Loss at iteration 130 : 0.014241487719118595
Loss at iteration 140 : 0.0180570837110281
Loss at iteration 150 : 0.007806434296071529
Loss at iteration 160 : 0.009029390290379524
Loss at iteration 170 : 0.012063390575349331
Loss at iteration 180 : 0.009715911000967026
Loss at iteration 190 : 0.013165367767214775
Loss at iteration 200 : 0.014417882077395916
Loss at iteration 210 : 0.009021494537591934
Loss at iteration 220 : 0.012789306230843067
Loss at iteration 230 : 0.007840863429009914
Loss at iteration 240 : 0.014431104063987732
Loss at iteration 250 : 0.012116838246583939
Loss at iteration 260 : 0.008102343417704105
Loss at iteration 270 : 0.013780209235846996
Loss at iteration 280 : 0.01375330425798893
Loss at iteration 290 : 0.006891212426126003
Loss at iteration 300 : 0.0068863388150930405
Loss at iteration 310 : 0.00632472662255168
Loss at iteration 320 : 0.009503171779215336
Loss at iteration 330 : 0.010023470968008041
Loss at iteration 340 : 0.014735380187630653
Loss at iteration 350 : 0.014875315129756927
Loss at iteration 360 : 0.012716567143797874
Loss at iteration 370 : 0.011257238686084747
Loss at iteration 380 : 0.015225939452648163
Loss at iteration 390 : 0.00909159705042839
Loss at iteration 400 : 0.014579834416508675
Loss at iteration 410 : 0.019029952585697174
Loss at iteration 420 : 0.009508905000984669
Loss at iteration 430 : 0.012897757813334465
Loss at iteration 440 : 0.007573959417641163
Loss at iteration 450 : 0.011699283495545387
Loss at iteration 460 : 0.013002969324588776
Loss at iteration 470 : 0.008720715530216694
Loss at iteration 480 : 0.01161509845405817
Loss at iteration 490 : 0.01378682442009449
Loss at iteration 500 : 0.006799204740673304
Loss at iteration 510 : 0.00823913887143135
Loss at iteration 520 : 0.00889680627733469
Loss at iteration 530 : 0.008503291755914688
Loss at iteration 540 : 0.00794524047523737
Loss at iteration 550 : 0.013772277161478996
Loss at iteration 560 : 0.016072263941168785
Loss at iteration 570 : 0.007376005873084068
Loss at iteration 580 : 0.012160475365817547
Loss at iteration 590 : 0.016784967854619026
Loss at iteration 600 : 0.009049881249666214
Loss at iteration 610 : 0.00681588239967823
Loss at iteration 620 : 0.01630648970603943
Loss at iteration 630 : 0.009054813534021378
Loss at iteration 640 : 0.012030297890305519
Loss at iteration 650 : 0.00971851497888565
Loss at iteration 660 : 0.012942968867719173
Loss at iteration 670 : 0.00818715337663889
Loss at iteration 680 : 0.009140519425272942
Loss at iteration 690 : 0.017405277118086815
Loss at iteration 700 : 0.006850580684840679
Loss at iteration 710 : 0.011660453863441944
Loss at iteration 720 : 0.013155918568372726
Loss at iteration 730 : 0.009044266305863857
Loss at iteration 740 : 0.011011502705514431
Loss at iteration 750 : 0.010423858650028706
Loss at iteration 760 : 0.014162719249725342
Loss at iteration 770 : 0.010921679437160492
Loss at iteration 780 : 0.011776262894272804
Loss at iteration 790 : 0.009341007098555565
Loss at iteration 800 : 0.010378655046224594
Loss at iteration 810 : 0.007122824899852276
Loss at iteration 820 : 0.010566440410912037
Loss at iteration 830 : 0.01274346373975277
Loss at iteration 840 : 0.010655011981725693
Loss at iteration 850 : 0.012218975462019444
Loss at iteration 860 : 0.009613459929823875
Loss at iteration 870 : 0.009574931114912033
Loss at iteration 880 : 0.010268425568938255
Loss at iteration 890 : 0.012663153931498528
Loss at iteration 900 : 0.013179617002606392
Loss at iteration 910 : 0.014338294044137001
Loss at iteration 920 : 0.015290739014744759
Loss at iteration 930 : 0.0159689262509346
Loss at iteration 940 : 0.01780858263373375
Loss at iteration 950 : 0.012325586751103401
Loss at iteration 960 : 0.014957628212869167
Loss at iteration 970 : 0.013205070048570633
Loss at iteration 980 : 0.006188033614307642
Loss at iteration 990 : 0.008125240914523602
Loss at iteration 1000 : 0.00718932319432497
Loss at iteration 1010 : 0.0117218978703022
Loss at iteration 1020 : 0.012381959706544876
Loss at iteration 1030 : 0.019005823880434036
Loss at iteration 1040 : 0.010545134544372559
Loss at iteration 1050 : 0.0072883740067481995
Loss at iteration 1060 : 0.012807348743081093
Loss at iteration 1070 : 0.01004069671034813
Loss at iteration 1080 : 0.01497467327862978
Loss at iteration 1090 : 0.009969513863325119
Loss at iteration 1100 : 0.012204669415950775
Loss at iteration 1110 : 0.011045949533581734
Loss at iteration 1120 : 0.014545612037181854
Loss at iteration 1130 : 0.005566968582570553
Loss at iteration 1140 : 0.012041871435940266
Loss at iteration 1150 : 0.00980856828391552
Loss at iteration 1160 : 0.009876340627670288
Loss at iteration 1170 : 0.006809966638684273
Loss at iteration 1180 : 0.013625064864754677
Loss at iteration 1190 : 0.013151704333722591
Loss at iteration 1200 : 0.021866705268621445
Loss at iteration 1210 : 0.009462709538638592
The SSIM Value is: 0.796030875047048
The PSNR Value is: 18.574812380472817
the epoch is: 96
Loss at iteration 10 : 0.01756209135055542
Loss at iteration 20 : 0.010854599997401237
Loss at iteration 30 : 0.008101778104901314
Loss at iteration 40 : 0.007436534855514765
Loss at iteration 50 : 0.014476900920271873
Loss at iteration 60 : 0.009847481735050678
Loss at iteration 70 : 0.02210479974746704
Loss at iteration 80 : 0.01088741421699524
Loss at iteration 90 : 0.023945586755871773
Loss at iteration 100 : 0.012362619861960411
Loss at iteration 110 : 0.011211764067411423
Loss at iteration 120 : 0.011522362008690834
Loss at iteration 130 : 0.013149494305253029
Loss at iteration 140 : 0.009243872947990894
Loss at iteration 150 : 0.014244407415390015
Loss at iteration 160 : 0.008485840633511543
Loss at iteration 170 : 0.018750911578536034
Loss at iteration 180 : 0.008174868300557137
Loss at iteration 190 : 0.015259867534041405
Loss at iteration 200 : 0.014815257862210274
Loss at iteration 210 : 0.014792590402066708
Loss at iteration 220 : 0.012577719055116177
Loss at iteration 230 : 0.009525280445814133
Loss at iteration 240 : 0.0058027771301567554
Loss at iteration 250 : 0.0064161489717662334
Loss at iteration 260 : 0.024174315854907036
Loss at iteration 270 : 0.011674825102090836
Loss at iteration 280 : 0.007381145842373371
Loss at iteration 290 : 0.00769880460575223
Loss at iteration 300 : 0.018860163167119026
Loss at iteration 310 : 0.012423304840922356
Loss at iteration 320 : 0.01256527192890644
Loss at iteration 330 : 0.008546365424990654
Loss at iteration 340 : 0.0127691850066185
Loss at iteration 350 : 0.00708447489887476
Loss at iteration 360 : 0.010796338319778442
Loss at iteration 370 : 0.011721178889274597
Loss at iteration 380 : 0.015178991481661797
Loss at iteration 390 : 0.011195765808224678
Loss at iteration 400 : 0.011233010329306126
Loss at iteration 410 : 0.011478835716843605
Loss at iteration 420 : 0.015673428773880005
Loss at iteration 430 : 0.009803816676139832
Loss at iteration 440 : 0.0069745127111673355
Loss at iteration 450 : 0.007681047543883324
Loss at iteration 460 : 0.010632459074258804
Loss at iteration 470 : 0.012192780151963234
Loss at iteration 480 : 0.012327980250120163
Loss at iteration 490 : 0.015011858195066452
Loss at iteration 500 : 0.004136293660849333
Loss at iteration 510 : 0.016424493864178658
Loss at iteration 520 : 0.010229338891804218
Loss at iteration 530 : 0.012130025774240494
Loss at iteration 540 : 0.010114653967320919
Loss at iteration 550 : 0.012245869264006615
Loss at iteration 560 : 0.014784841798245907
Loss at iteration 570 : 0.015531210228800774
Loss at iteration 580 : 0.014763547107577324
Loss at iteration 590 : 0.009797683916985989
Loss at iteration 600 : 0.007579792756587267
Loss at iteration 610 : 0.007179215084761381
Loss at iteration 620 : 0.010350663214921951
Loss at iteration 630 : 0.009898791089653969
Loss at iteration 640 : 0.010087991133332253
Loss at iteration 650 : 0.010930980555713177
Loss at iteration 660 : 0.008938723243772984
Loss at iteration 670 : 0.00988161563873291
Loss at iteration 680 : 0.009453117847442627
Loss at iteration 690 : 0.00933018047362566
Loss at iteration 700 : 0.01606723479926586
Loss at iteration 710 : 0.012167440727353096
Loss at iteration 720 : 0.013825371861457825
Loss at iteration 730 : 0.010686691850423813
Loss at iteration 740 : 0.020192770287394524
Loss at iteration 750 : 0.011681260541081429
Loss at iteration 760 : 0.012794889509677887
Loss at iteration 770 : 0.011891977861523628
Loss at iteration 780 : 0.009117670357227325
Loss at iteration 790 : 0.02120453491806984
Loss at iteration 800 : 0.00995890237390995
Loss at iteration 810 : 0.010482334531843662
Loss at iteration 820 : 0.007414121180772781
Loss at iteration 830 : 0.013979019597172737
Loss at iteration 840 : 0.008931271731853485
Loss at iteration 850 : 0.013790421187877655
Loss at iteration 860 : 0.008197935298085213
Loss at iteration 870 : 0.011091879568994045
Loss at iteration 880 : 0.007259019650518894
Loss at iteration 890 : 0.016275960952043533
Loss at iteration 900 : 0.006721124053001404
Loss at iteration 910 : 0.007306876592338085
Loss at iteration 920 : 0.013639174401760101
Loss at iteration 930 : 0.008583144284784794
Loss at iteration 940 : 0.006530714686959982
Loss at iteration 950 : 0.01636163517832756
Loss at iteration 960 : 0.01669219508767128
Loss at iteration 970 : 0.009591936133801937
Loss at iteration 980 : 0.011300427839159966
Loss at iteration 990 : 0.011764543130993843
Loss at iteration 1000 : 0.010624389164149761
Loss at iteration 1010 : 0.006458398886024952
Loss at iteration 1020 : 0.013842547312378883
Loss at iteration 1030 : 0.012549540027976036
Loss at iteration 1040 : 0.011825956404209137
Loss at iteration 1050 : 0.008106096647679806
Loss at iteration 1060 : 0.010734450072050095
Loss at iteration 1070 : 0.011339206248521805
Loss at iteration 1080 : 0.019801238551735878
Loss at iteration 1090 : 0.012693556025624275
Loss at iteration 1100 : 0.010104174725711346
Loss at iteration 1110 : 0.01907689869403839
Loss at iteration 1120 : 0.009537574835121632
Loss at iteration 1130 : 0.010819412767887115
Loss at iteration 1140 : 0.01427245233207941
Loss at iteration 1150 : 0.010048767551779747
Loss at iteration 1160 : 0.019807493314146996
Loss at iteration 1170 : 0.009236297570168972
Loss at iteration 1180 : 0.012294618412852287
Loss at iteration 1190 : 0.010795318521559238
Loss at iteration 1200 : 0.013111411593854427
Loss at iteration 1210 : 0.014385266229510307
The SSIM Value is: 0.7944310029347738
The PSNR Value is: 17.68111368815104
the epoch is: 97
Loss at iteration 10 : 0.011667256243526936
Loss at iteration 20 : 0.020472899079322815
Loss at iteration 30 : 0.007123265415430069
Loss at iteration 40 : 0.013445410877466202
Loss at iteration 50 : 0.0065912059508264065
Loss at iteration 60 : 0.014511818066239357
Loss at iteration 70 : 0.005950225051492453
Loss at iteration 80 : 0.00970095582306385
Loss at iteration 90 : 0.012525990605354309
Loss at iteration 100 : 0.013753946870565414
Loss at iteration 110 : 0.012450503185391426
Loss at iteration 120 : 0.010292877443134785
Loss at iteration 130 : 0.007801721338182688
Loss at iteration 140 : 0.016033705323934555
Loss at iteration 150 : 0.012387845665216446
Loss at iteration 160 : 0.009681742638349533
Loss at iteration 170 : 0.01308189332485199
Loss at iteration 180 : 0.008891423232853413
Loss at iteration 190 : 0.011764655821025372
Loss at iteration 200 : 0.01141215581446886
Loss at iteration 210 : 0.006487993523478508
Loss at iteration 220 : 0.008832715451717377
Loss at iteration 230 : 0.008451986126601696
Loss at iteration 240 : 0.009005405008792877
Loss at iteration 250 : 0.00958940014243126
Loss at iteration 260 : 0.013710522092878819
Loss at iteration 270 : 0.012325651943683624
Loss at iteration 280 : 0.007818206213414669
Loss at iteration 290 : 0.010938926599919796
Loss at iteration 300 : 0.0064382972195744514
Loss at iteration 310 : 0.010604375042021275
Loss at iteration 320 : 0.02003159001469612
Loss at iteration 330 : 0.012007374316453934
Loss at iteration 340 : 0.01120683178305626
Loss at iteration 350 : 0.011155698448419571
Loss at iteration 360 : 0.010892650112509727
Loss at iteration 370 : 0.011038861237466335
Loss at iteration 380 : 0.007936662063002586
Loss at iteration 390 : 0.023915402591228485
Loss at iteration 400 : 0.01461244560778141
Loss at iteration 410 : 0.010484697297215462
Loss at iteration 420 : 0.0049258070066571236
Loss at iteration 430 : 0.015390589833259583
Loss at iteration 440 : 0.01736775040626526
Loss at iteration 450 : 0.013461211696267128
Loss at iteration 460 : 0.010148994624614716
Loss at iteration 470 : 0.010351798497140408
Loss at iteration 480 : 0.006526848301291466
Loss at iteration 490 : 0.01169798243790865
Loss at iteration 500 : 0.012552629224956036
Loss at iteration 510 : 0.012151840142905712
Loss at iteration 520 : 0.01105677429586649
Loss at iteration 530 : 0.010064145550131798
Loss at iteration 540 : 0.015980593860149384
Loss at iteration 550 : 0.012062743306159973
Loss at iteration 560 : 0.011974649503827095
Loss at iteration 570 : 0.008150799199938774
Loss at iteration 580 : 0.018499435856938362
Loss at iteration 590 : 0.006477524526417255
Loss at iteration 600 : 0.010781812481582165
Loss at iteration 610 : 0.007092966232448816
Loss at iteration 620 : 0.006965131964534521
Loss at iteration 630 : 0.006931220646947622
Loss at iteration 640 : 0.008677037432789803
Loss at iteration 650 : 0.017742324620485306
Loss at iteration 660 : 0.009782481007277966
Loss at iteration 670 : 0.016161147505044937
Loss at iteration 680 : 0.012941760942339897
Loss at iteration 690 : 0.014446825720369816
Loss at iteration 700 : 0.007752103731036186
Loss at iteration 710 : 0.009532231837511063
Loss at iteration 720 : 0.025435011833906174
Loss at iteration 730 : 0.011111666448414326
Loss at iteration 740 : 0.011137650348246098
Loss at iteration 750 : 0.007355177775025368
Loss at iteration 760 : 0.011762985959649086
Loss at iteration 770 : 0.011962334625422955
Loss at iteration 780 : 0.007200116291642189
Loss at iteration 790 : 0.010041242465376854
Loss at iteration 800 : 0.017801713198423386
Loss at iteration 810 : 0.015090452507138252
Loss at iteration 820 : 0.0058165909722447395
Loss at iteration 830 : 0.005632089450955391
Loss at iteration 840 : 0.01674848608672619
Loss at iteration 850 : 0.0127020962536335
Loss at iteration 860 : 0.013976585119962692
Loss at iteration 870 : 0.0173441581428051
Loss at iteration 880 : 0.01316189207136631
Loss at iteration 890 : 0.014244201593101025
Loss at iteration 900 : 0.00634931493550539
Loss at iteration 910 : 0.010310019366443157
Loss at iteration 920 : 0.008267572149634361
Loss at iteration 930 : 0.015303833410143852
Loss at iteration 940 : 0.006209931336343288
Loss at iteration 950 : 0.00830457080155611
Loss at iteration 960 : 0.012215936556458473
Loss at iteration 970 : 0.011951670050621033
Loss at iteration 980 : 0.008113618940114975
Loss at iteration 990 : 0.008291293866932392
Loss at iteration 1000 : 0.009912347421050072
Loss at iteration 1010 : 0.02266242727637291
Loss at iteration 1020 : 0.009057773277163506
Loss at iteration 1030 : 0.01701756939291954
Loss at iteration 1040 : 0.014886396005749702
Loss at iteration 1050 : 0.008118079975247383
Loss at iteration 1060 : 0.019697625190019608
Loss at iteration 1070 : 0.009331803768873215
Loss at iteration 1080 : 0.008488824591040611
Loss at iteration 1090 : 0.00845593586564064
Loss at iteration 1100 : 0.012410073541104794
Loss at iteration 1110 : 0.011871843598783016
Loss at iteration 1120 : 0.01711348071694374
Loss at iteration 1130 : 0.013254698365926743
Loss at iteration 1140 : 0.007818150334060192
Loss at iteration 1150 : 0.023500926792621613
Loss at iteration 1160 : 0.007333431392908096
Loss at iteration 1170 : 0.012489236891269684
Loss at iteration 1180 : 0.011118743568658829
Loss at iteration 1190 : 0.011935977265238762
Loss at iteration 1200 : 0.007575345225632191
Loss at iteration 1210 : 0.01598685421049595
The SSIM Value is: 0.8011888265609741
The PSNR Value is: 18.08415953318278
the epoch is: 98
Loss at iteration 10 : 0.01149454340338707
Loss at iteration 20 : 0.0073748426511883736
Loss at iteration 30 : 0.01018588338047266
Loss at iteration 40 : 0.005805273074656725
Loss at iteration 50 : 0.010920194908976555
Loss at iteration 60 : 0.015058799646794796
Loss at iteration 70 : 0.014107886701822281
Loss at iteration 80 : 0.010575909167528152
Loss at iteration 90 : 0.014622493647038937
Loss at iteration 100 : 0.00784249696880579
Loss at iteration 110 : 0.009029796347022057
Loss at iteration 120 : 0.014571504667401314
Loss at iteration 130 : 0.010474499315023422
Loss at iteration 140 : 0.007734208833426237
Loss at iteration 150 : 0.01327928900718689
Loss at iteration 160 : 0.009010177105665207
Loss at iteration 170 : 0.009675916284322739
Loss at iteration 180 : 0.01197646651417017
Loss at iteration 190 : 0.013724567368626595
Loss at iteration 200 : 0.005028130952268839
Loss at iteration 210 : 0.0050975726917386055
Loss at iteration 220 : 0.017566312104463577
Loss at iteration 230 : 0.011655027978122234
Loss at iteration 240 : 0.008410419337451458
Loss at iteration 250 : 0.010273713618516922
Loss at iteration 260 : 0.0088119488209486
Loss at iteration 270 : 0.008387794718146324
Loss at iteration 280 : 0.012539835646748543
Loss at iteration 290 : 0.0205070823431015
Loss at iteration 300 : 0.016568221151828766
Loss at iteration 310 : 0.012278647162020206
Loss at iteration 320 : 0.00905238464474678
Loss at iteration 330 : 0.0050098588690161705
Loss at iteration 340 : 0.01213633269071579
Loss at iteration 350 : 0.01762782409787178
Loss at iteration 360 : 0.01187988556921482
Loss at iteration 370 : 0.013647048734128475
Loss at iteration 380 : 0.009699990972876549
Loss at iteration 390 : 0.006466014310717583
Loss at iteration 400 : 0.00730471545830369
Loss at iteration 410 : 0.00992976501584053
Loss at iteration 420 : 0.014450572431087494
Loss at iteration 430 : 0.012424422428011894
Loss at iteration 440 : 0.012927267700433731
Loss at iteration 450 : 0.0074280546978116035
Loss at iteration 460 : 0.0061498661525547504
Loss at iteration 470 : 0.014880380593240261
Loss at iteration 480 : 0.013798379339277744
Loss at iteration 490 : 0.004899564199149609
Loss at iteration 500 : 0.011078009381890297
Loss at iteration 510 : 0.009125135838985443
Loss at iteration 520 : 0.008175371214747429
Loss at iteration 530 : 0.014344358816742897
Loss at iteration 540 : 0.015035538002848625
Loss at iteration 550 : 0.011338366195559502
Loss at iteration 560 : 0.0070512741804122925
Loss at iteration 570 : 0.0085525531321764
Loss at iteration 580 : 0.01013614796102047
Loss at iteration 590 : 0.007976269349455833
Loss at iteration 600 : 0.010883446782827377
Loss at iteration 610 : 0.013126896694302559
Loss at iteration 620 : 0.012527389451861382
Loss at iteration 630 : 0.01096401922404766
Loss at iteration 640 : 0.011741207912564278
Loss at iteration 650 : 0.008621452376246452
Loss at iteration 660 : 0.010717229917645454
Loss at iteration 670 : 0.012820746749639511
Loss at iteration 680 : 0.028195397928357124
Loss at iteration 690 : 0.016071034595370293
Loss at iteration 700 : 0.009013946168124676
Loss at iteration 710 : 0.012845896184444427
Loss at iteration 720 : 0.010606132447719574
Loss at iteration 730 : 0.01706599071621895
Loss at iteration 740 : 0.012497635558247566
Loss at iteration 750 : 0.011102493852376938
Loss at iteration 760 : 0.016600769013166428
Loss at iteration 770 : 0.010231996886432171
Loss at iteration 780 : 0.006957210134714842
Loss at iteration 790 : 0.008815748617053032
Loss at iteration 800 : 0.010507667437195778
Loss at iteration 810 : 0.016190974041819572
Loss at iteration 820 : 0.01030026189982891
Loss at iteration 830 : 0.006602281238883734
Loss at iteration 840 : 0.010396953672170639
Loss at iteration 850 : 0.0071580056101083755
Loss at iteration 860 : 0.008351626805961132
Loss at iteration 870 : 0.00621026661247015
Loss at iteration 880 : 0.011663753539323807
Loss at iteration 890 : 0.011171219870448112
Loss at iteration 900 : 0.01497076265513897
Loss at iteration 910 : 0.010551203973591328
Loss at iteration 920 : 0.009308116510510445
Loss at iteration 930 : 0.007633526809513569
Loss at iteration 940 : 0.011287122964859009
Loss at iteration 950 : 0.011712471954524517
Loss at iteration 960 : 0.012306936085224152
Loss at iteration 970 : 0.01137283630669117
Loss at iteration 980 : 0.00746213598176837
Loss at iteration 990 : 0.015371730551123619
Loss at iteration 1000 : 0.009895816445350647
Loss at iteration 1010 : 0.018815120682120323
Loss at iteration 1020 : 0.0137558002024889
Loss at iteration 1030 : 0.01026848703622818
Loss at iteration 1040 : 0.01185986865311861
Loss at iteration 1050 : 0.02436920814216137
Loss at iteration 1060 : 0.011830194853246212
Loss at iteration 1070 : 0.01167311891913414
Loss at iteration 1080 : 0.0061096129938960075
Loss at iteration 1090 : 0.006151769310235977
Loss at iteration 1100 : 0.007695148698985577
Loss at iteration 1110 : 0.013671633787453175
Loss at iteration 1120 : 0.008792034350335598
Loss at iteration 1130 : 0.009064901620149612
Loss at iteration 1140 : 0.011484996415674686
Loss at iteration 1150 : 0.0094284787774086
Loss at iteration 1160 : 0.010931896045804024
Loss at iteration 1170 : 0.011813774704933167
Loss at iteration 1180 : 0.008221942000091076
Loss at iteration 1190 : 0.009038170799612999
Loss at iteration 1200 : 0.014685534872114658
Loss at iteration 1210 : 0.01208762638270855
The SSIM Value is: 0.7985414425532024
The PSNR Value is: 18.327563667297362
the epoch is: 99
Loss at iteration 10 : 0.008515071123838425
Loss at iteration 20 : 0.011731508187949657
Loss at iteration 30 : 0.015236547216773033
Loss at iteration 40 : 0.011125685647130013
Loss at iteration 50 : 0.010487220250070095
Loss at iteration 60 : 0.011636141687631607
Loss at iteration 70 : 0.012978332117199898
Loss at iteration 80 : 0.013519080355763435
Loss at iteration 90 : 0.005975816398859024
Loss at iteration 100 : 0.013460230082273483
Loss at iteration 110 : 0.009075714275240898
Loss at iteration 120 : 0.00859607569873333
Loss at iteration 130 : 0.011067137122154236
Loss at iteration 140 : 0.011456133797764778
Loss at iteration 150 : 0.007905024103820324
Loss at iteration 160 : 0.007648997940123081
Loss at iteration 170 : 0.01021147333085537
Loss at iteration 180 : 0.008024243637919426
Loss at iteration 190 : 0.019594252109527588
Loss at iteration 200 : 0.01377582922577858
Loss at iteration 210 : 0.014299791306257248
Loss at iteration 220 : 0.00798032060265541
Loss at iteration 230 : 0.005428647622466087
Loss at iteration 240 : 0.0109919598326087
Loss at iteration 250 : 0.01343701221048832
Loss at iteration 260 : 0.00952993892133236
Loss at iteration 270 : 0.01442349050194025
Loss at iteration 280 : 0.01434941217303276
Loss at iteration 290 : 0.010355710983276367
Loss at iteration 300 : 0.017712954431772232
Loss at iteration 310 : 0.010663410648703575
Loss at iteration 320 : 0.01707838848233223
Loss at iteration 330 : 0.007776974700391293
Loss at iteration 340 : 0.008619685657322407
Loss at iteration 350 : 0.011250680312514305
Loss at iteration 360 : 0.008784186094999313
Loss at iteration 370 : 0.009308962151408195
Loss at iteration 380 : 0.012412894517183304
Loss at iteration 390 : 0.007259890902787447
Loss at iteration 400 : 0.008235694840550423
Loss at iteration 410 : 0.009441318921744823
Loss at iteration 420 : 0.010413582436740398
Loss at iteration 430 : 0.013371310196816921
Loss at iteration 440 : 0.00753219798207283
Loss at iteration 450 : 0.01554554607719183
Loss at iteration 460 : 0.006307489704340696
Loss at iteration 470 : 0.012302431277930737
Loss at iteration 480 : 0.009816376492381096
Loss at iteration 490 : 0.012136701494455338
Loss at iteration 500 : 0.015443108044564724
Loss at iteration 510 : 0.006167607847601175
Loss at iteration 520 : 0.015675218775868416
Loss at iteration 530 : 0.008813207969069481
Loss at iteration 540 : 0.009785713627934456
Loss at iteration 550 : 0.010570737533271313
Loss at iteration 560 : 0.01027186680585146
Loss at iteration 570 : 0.011130411177873611
Loss at iteration 580 : 0.01132531464099884
Loss at iteration 590 : 0.007489556446671486
Loss at iteration 600 : 0.01035948283970356
Loss at iteration 610 : 0.008364779874682426
Loss at iteration 620 : 0.010019396431744099
Loss at iteration 630 : 0.009420261718332767
Loss at iteration 640 : 0.008901996538043022
Loss at iteration 650 : 0.008549666032195091
Loss at iteration 660 : 0.008098552003502846
Loss at iteration 670 : 0.012225007638335228
Loss at iteration 680 : 0.016192760318517685
Loss at iteration 690 : 0.01283725444227457
Loss at iteration 700 : 0.010185042396187782
Loss at iteration 710 : 0.011665412224829197
Loss at iteration 720 : 0.008034581318497658
Loss at iteration 730 : 0.01049371063709259
Loss at iteration 740 : 0.009375909343361855
Loss at iteration 750 : 0.008440469391644001
Loss at iteration 760 : 0.013940018601715565
Loss at iteration 770 : 0.02048725076019764
Loss at iteration 780 : 0.011476889252662659
Loss at iteration 790 : 0.01176493614912033
Loss at iteration 800 : 0.009393669664859772
Loss at iteration 810 : 0.008481761440634727
Loss at iteration 820 : 0.013103270903229713
Loss at iteration 830 : 0.01261385902762413
Loss at iteration 840 : 0.011540642939507961
Loss at iteration 850 : 0.009655621834099293
Loss at iteration 860 : 0.02178061567246914
Loss at iteration 870 : 0.013103676959872246
Loss at iteration 880 : 0.009120313450694084
Loss at iteration 890 : 0.014352187514305115
Loss at iteration 900 : 0.014467822387814522
Loss at iteration 910 : 0.012875651009380817
Loss at iteration 920 : 0.00860915333032608
Loss at iteration 930 : 0.011254264041781425
Loss at iteration 940 : 0.00794172566384077
Loss at iteration 950 : 0.005822350271046162
Loss at iteration 960 : 0.0076225521042943
Loss at iteration 970 : 0.01910274662077427
Loss at iteration 980 : 0.011440889909863472
Loss at iteration 990 : 0.004444570280611515
Loss at iteration 1000 : 0.007224350236356258
Loss at iteration 1010 : 0.007028955966234207
Loss at iteration 1020 : 0.006599178537726402
Loss at iteration 1030 : 0.020904535427689552
Loss at iteration 1040 : 0.01622665673494339
Loss at iteration 1050 : 0.011943110264837742
Loss at iteration 1060 : 0.013145976699888706
Loss at iteration 1070 : 0.014540392905473709
Loss at iteration 1080 : 0.012795618735253811
Loss at iteration 1090 : 0.008038942702114582
Loss at iteration 1100 : 0.009452976286411285
Loss at iteration 1110 : 0.0073615554720163345
Loss at iteration 1120 : 0.00943805556744337
Loss at iteration 1130 : 0.0111071253195405
Loss at iteration 1140 : 0.012142336927354336
Loss at iteration 1150 : 0.011999694630503654
Loss at iteration 1160 : 0.010791282169520855
Loss at iteration 1170 : 0.005755467340350151
Loss at iteration 1180 : 0.012952227145433426
Loss at iteration 1190 : 0.010890239849686623
Loss at iteration 1200 : 0.01659858226776123
Loss at iteration 1210 : 0.009787231683731079
The SSIM Value is: 0.7963452974955241
The PSNR Value is: 17.86264928181966
the epoch is: 100
Loss at iteration 10 : 0.011509068310260773
Loss at iteration 20 : 0.010878200642764568
Loss at iteration 30 : 0.008671187795698643
Loss at iteration 40 : 0.015086782164871693
Loss at iteration 50 : 0.007997184991836548
Loss at iteration 60 : 0.008433327078819275
Loss at iteration 70 : 0.009900672361254692
Loss at iteration 80 : 0.01275654137134552
Loss at iteration 90 : 0.016438310965895653
Loss at iteration 100 : 0.011381465010344982
Loss at iteration 110 : 0.006693601608276367
Loss at iteration 120 : 0.008185028098523617
Loss at iteration 130 : 0.00785633735358715
Loss at iteration 140 : 0.013827178627252579
Loss at iteration 150 : 0.012634402140974998
Loss at iteration 160 : 0.014731274917721748
Loss at iteration 170 : 0.005346454679965973
Loss at iteration 180 : 0.013354716822504997
Loss at iteration 190 : 0.009624691680073738
Loss at iteration 200 : 0.009708184748888016
Loss at iteration 210 : 0.012597305700182915
Loss at iteration 220 : 0.008238237351179123
Loss at iteration 230 : 0.014266710728406906
Loss at iteration 240 : 0.006554116029292345
Loss at iteration 250 : 0.01119137741625309
Loss at iteration 260 : 0.010096438229084015
Loss at iteration 270 : 0.010148932226002216
Loss at iteration 280 : 0.009986252523958683
Loss at iteration 290 : 0.009015774354338646
Loss at iteration 300 : 0.011808807961642742
Loss at iteration 310 : 0.006706268060952425
Loss at iteration 320 : 0.01021362654864788
Loss at iteration 330 : 0.009587637148797512
Loss at iteration 340 : 0.010055637918412685
Loss at iteration 350 : 0.014332378283143044
Loss at iteration 360 : 0.01533475425094366
Loss at iteration 370 : 0.011494988575577736
Loss at iteration 380 : 0.012763690203428268
Loss at iteration 390 : 0.0069691697135567665
Loss at iteration 400 : 0.013758929446339607
Loss at iteration 410 : 0.00933679286390543
Loss at iteration 420 : 0.010889662429690361
Loss at iteration 430 : 0.009559046477079391
Loss at iteration 440 : 0.008947823196649551
Loss at iteration 450 : 0.010267673060297966
Loss at iteration 460 : 0.013354893773794174
Loss at iteration 470 : 0.009317679330706596
Loss at iteration 480 : 0.01388317346572876
Loss at iteration 490 : 0.006082733627408743
Loss at iteration 500 : 0.005984606686979532
Loss at iteration 510 : 0.004388118162751198
Loss at iteration 520 : 0.014894494786858559
Loss at iteration 530 : 0.017067043110728264
Loss at iteration 540 : 0.005845440085977316
Loss at iteration 550 : 0.009693252854049206
Loss at iteration 560 : 0.008577949367463589
Loss at iteration 570 : 0.015620467253029346
Loss at iteration 580 : 0.009059974923729897
Loss at iteration 590 : 0.009624162688851357
Loss at iteration 600 : 0.012238016352057457
Loss at iteration 610 : 0.00536698941141367
Loss at iteration 620 : 0.01290501095354557
Loss at iteration 630 : 0.008130045607686043
Loss at iteration 640 : 0.006543303839862347
Loss at iteration 650 : 0.00939860101789236
Loss at iteration 660 : 0.01030649058520794
Loss at iteration 670 : 0.011631380766630173
Loss at iteration 680 : 0.009417841210961342
Loss at iteration 690 : 0.0078187957406044
Loss at iteration 700 : 0.00730441277846694
Loss at iteration 710 : 0.015276423655450344
Loss at iteration 720 : 0.015980232506990433
Loss at iteration 730 : 0.010755094699561596
Loss at iteration 740 : 0.021335646510124207
Loss at iteration 750 : 0.006708106026053429
Loss at iteration 760 : 0.014885006472468376
Loss at iteration 770 : 0.010440967977046967
Loss at iteration 780 : 0.015478292480111122
Loss at iteration 790 : 0.01163959689438343
Loss at iteration 800 : 0.009633054956793785
Loss at iteration 810 : 0.007398450747132301
Loss at iteration 820 : 0.01242853794246912
Loss at iteration 830 : 0.014630305580794811
Loss at iteration 840 : 0.006300840061157942
Loss at iteration 850 : 0.008966623805463314
Loss at iteration 860 : 0.01098017580807209
Loss at iteration 870 : 0.007934953086078167
Loss at iteration 880 : 0.007472041994333267
Loss at iteration 890 : 0.020104819908738136
Loss at iteration 900 : 0.008762581273913383
Loss at iteration 910 : 0.014757441356778145
Loss at iteration 920 : 0.009301062673330307
Loss at iteration 930 : 0.007711147889494896
Loss at iteration 940 : 0.011798969469964504
Loss at iteration 950 : 0.016485070809721947
Loss at iteration 960 : 0.01688566245138645
Loss at iteration 970 : 0.010537466034293175
Loss at iteration 980 : 0.012955590151250362
Loss at iteration 990 : 0.012359878048300743
Loss at iteration 1000 : 0.015720846131443977
Loss at iteration 1010 : 0.008288964629173279
Loss at iteration 1020 : 0.012143786065280437
Loss at iteration 1030 : 0.011363176628947258
Loss at iteration 1040 : 0.008091220632195473
Loss at iteration 1050 : 0.008695597760379314
Loss at iteration 1060 : 0.010767322964966297
Loss at iteration 1070 : 0.013309136033058167
Loss at iteration 1080 : 0.022315219044685364
Loss at iteration 1090 : 0.012431547045707703
Loss at iteration 1100 : 0.009581373073160648
Loss at iteration 1110 : 0.01134219579398632
Loss at iteration 1120 : 0.012201839126646519
Loss at iteration 1130 : 0.008794075809419155
Loss at iteration 1140 : 0.01036824844777584
Loss at iteration 1150 : 0.00966728013008833
Loss at iteration 1160 : 0.016111701726913452
Loss at iteration 1170 : 0.018770365044474602
Loss at iteration 1180 : 0.00950851570814848
Loss at iteration 1190 : 0.009889456443488598
Loss at iteration 1200 : 0.015555470250546932
Loss at iteration 1210 : 0.016400590538978577
The SSIM Value is: 0.8081812858581543
The PSNR Value is: 18.8502295811971
the epoch is: 101
Loss at iteration 10 : 0.010863300412893295
Loss at iteration 20 : 0.010792107321321964
Loss at iteration 30 : 0.012675127945840359
Loss at iteration 40 : 0.011211139149963856
Loss at iteration 50 : 0.011126894503831863
Loss at iteration 60 : 0.009066891856491566
Loss at iteration 70 : 0.013353366404771805
Loss at iteration 80 : 0.009924057871103287
Loss at iteration 90 : 0.011230186559259892
Loss at iteration 100 : 0.0078427130356431
Loss at iteration 110 : 0.009177332744002342
Loss at iteration 120 : 0.012553852051496506
Loss at iteration 130 : 0.008092842996120453
Loss at iteration 140 : 0.009099062532186508
Loss at iteration 150 : 0.01580940932035446
Loss at iteration 160 : 0.008418804034590721
Loss at iteration 170 : 0.00877792201936245
Loss at iteration 180 : 0.0050757587887346745
Loss at iteration 190 : 0.01289989985525608
Loss at iteration 200 : 0.006430820561945438
Loss at iteration 210 : 0.012443618848919868
Loss at iteration 220 : 0.010154010728001595
Loss at iteration 230 : 0.01690870337188244
Loss at iteration 240 : 0.005932148080319166
Loss at iteration 250 : 0.017964262515306473
Loss at iteration 260 : 0.021625131368637085
Loss at iteration 270 : 0.007905172184109688
Loss at iteration 280 : 0.008063793182373047
Loss at iteration 290 : 0.01278645172715187
Loss at iteration 300 : 0.010536134243011475
Loss at iteration 310 : 0.01209159567952156
Loss at iteration 320 : 0.010185424238443375
Loss at iteration 330 : 0.011971733532845974
Loss at iteration 340 : 0.010539229959249496
Loss at iteration 350 : 0.013122651726007462
Loss at iteration 360 : 0.009450070559978485
Loss at iteration 370 : 0.00752877676859498
Loss at iteration 380 : 0.009198909625411034
Loss at iteration 390 : 0.02246813476085663
Loss at iteration 400 : 0.013844357803463936
Loss at iteration 410 : 0.007733215112239122
Loss at iteration 420 : 0.010430135764181614
Loss at iteration 430 : 0.011845147237181664
Loss at iteration 440 : 0.00874808058142662
Loss at iteration 450 : 0.010285867378115654
Loss at iteration 460 : 0.01079800259321928
Loss at iteration 470 : 0.008894389495253563
Loss at iteration 480 : 0.020602619275450706
Loss at iteration 490 : 0.011218596249818802
Loss at iteration 500 : 0.007382194511592388
Loss at iteration 510 : 0.0153526421636343
Loss at iteration 520 : 0.006147387437522411
Loss at iteration 530 : 0.008920910768210888
Loss at iteration 540 : 0.010670995339751244
Loss at iteration 550 : 0.01173057034611702
Loss at iteration 560 : 0.011680547147989273
Loss at iteration 570 : 0.012661924585700035
Loss at iteration 580 : 0.007412330713123083
Loss at iteration 590 : 0.009702220559120178
Loss at iteration 600 : 0.0061380816623568535
Loss at iteration 610 : 0.010672908276319504
Loss at iteration 620 : 0.007211677730083466
Loss at iteration 630 : 0.01545571070164442
Loss at iteration 640 : 0.014925715513527393
Loss at iteration 650 : 0.016536477953195572
Loss at iteration 660 : 0.010970540344715118
Loss at iteration 670 : 0.008645656518638134
Loss at iteration 680 : 0.009906938299536705
Loss at iteration 690 : 0.009632068686187267
Loss at iteration 700 : 0.007264020852744579
Loss at iteration 710 : 0.00836591050028801
Loss at iteration 720 : 0.012300070375204086
Loss at iteration 730 : 0.012095453217625618
Loss at iteration 740 : 0.011203471571207047
Loss at iteration 750 : 0.007382654119282961
Loss at iteration 760 : 0.02048473432660103
Loss at iteration 770 : 0.01886543072760105
Loss at iteration 780 : 0.00592013681307435
Loss at iteration 790 : 0.012137183919548988
Loss at iteration 800 : 0.009953254833817482
Loss at iteration 810 : 0.00634764926508069
Loss at iteration 820 : 0.01732124388217926
Loss at iteration 830 : 0.009866971522569656
Loss at iteration 840 : 0.011600326746702194
Loss at iteration 850 : 0.010267305187880993
Loss at iteration 860 : 0.012539435178041458
Loss at iteration 870 : 0.009279901161789894
Loss at iteration 880 : 0.007104367949068546
Loss at iteration 890 : 0.0055270688608288765
Loss at iteration 900 : 0.008225963450968266
Loss at iteration 910 : 0.010941821150481701
Loss at iteration 920 : 0.009059352800250053
Loss at iteration 930 : 0.010224750265479088
Loss at iteration 940 : 0.010312885046005249
Loss at iteration 950 : 0.0090407095849514
Loss at iteration 960 : 0.009834558703005314
Loss at iteration 970 : 0.006444606930017471
Loss at iteration 980 : 0.008733104914426804
Loss at iteration 990 : 0.007513049524277449
Loss at iteration 1000 : 0.01381854247301817
Loss at iteration 1010 : 0.012059624306857586
Loss at iteration 1020 : 0.010281835682690144
Loss at iteration 1030 : 0.01379571296274662
Loss at iteration 1040 : 0.019113609567284584
Loss at iteration 1050 : 0.015316835604608059
Loss at iteration 1060 : 0.008550399914383888
Loss at iteration 1070 : 0.01727253943681717
Loss at iteration 1080 : 0.010613273829221725
Loss at iteration 1090 : 0.005868935491889715
Loss at iteration 1100 : 0.012620796449482441
Loss at iteration 1110 : 0.013089734129607677
Loss at iteration 1120 : 0.01627914048731327
Loss at iteration 1130 : 0.009065321646630764
Loss at iteration 1140 : 0.013246209360659122
Loss at iteration 1150 : 0.008499199524521828
Loss at iteration 1160 : 0.009978139773011208
Loss at iteration 1170 : 0.014700832776725292
Loss at iteration 1180 : 0.008924363180994987
Loss at iteration 1190 : 0.01778488978743553
Loss at iteration 1200 : 0.009357612580060959
Loss at iteration 1210 : 0.011252651922404766
The SSIM Value is: 0.8024301131566366
The PSNR Value is: 18.676661936442056
the epoch is: 102
Loss at iteration 10 : 0.010253716260194778
Loss at iteration 20 : 0.011465009301900864
Loss at iteration 30 : 0.008891942910850048
Loss at iteration 40 : 0.01121535710990429
Loss at iteration 50 : 0.009041635319590569
Loss at iteration 60 : 0.012557417154312134
Loss at iteration 70 : 0.010053232312202454
Loss at iteration 80 : 0.008503544144332409
Loss at iteration 90 : 0.008245422504842281
Loss at iteration 100 : 0.008667804300785065
Loss at iteration 110 : 0.007058690767735243
Loss at iteration 120 : 0.010185413993895054
Loss at iteration 130 : 0.00860572513192892
Loss at iteration 140 : 0.011888651177287102
Loss at iteration 150 : 0.026089545339345932
Loss at iteration 160 : 0.012937944382429123
Loss at iteration 170 : 0.011979522183537483
Loss at iteration 180 : 0.0100540891289711
Loss at iteration 190 : 0.007214486598968506
Loss at iteration 200 : 0.02046119049191475
Loss at iteration 210 : 0.009908894076943398
Loss at iteration 220 : 0.01512165181338787
Loss at iteration 230 : 0.024021968245506287
Loss at iteration 240 : 0.015875622630119324
Loss at iteration 250 : 0.007784641347825527
Loss at iteration 260 : 0.014497391879558563
Loss at iteration 270 : 0.016015909612178802
Loss at iteration 280 : 0.013153880834579468
Loss at iteration 290 : 0.009617125615477562
Loss at iteration 300 : 0.011320050805807114
Loss at iteration 310 : 0.012841778807342052
Loss at iteration 320 : 0.010921943932771683
Loss at iteration 330 : 0.010287443175911903
Loss at iteration 340 : 0.012586505152285099
Loss at iteration 350 : 0.008944761008024216
Loss at iteration 360 : 0.007150424178689718
Loss at iteration 370 : 0.011401972733438015
Loss at iteration 380 : 0.013958259485661983
Loss at iteration 390 : 0.007974685169756413
Loss at iteration 400 : 0.013042464852333069
Loss at iteration 410 : 0.010865766555070877
Loss at iteration 420 : 0.012675073929131031
Loss at iteration 430 : 0.00941416248679161
Loss at iteration 440 : 0.012179735116660595
Loss at iteration 450 : 0.01927027851343155
Loss at iteration 460 : 0.007777793798595667
Loss at iteration 470 : 0.011233093217015266
Loss at iteration 480 : 0.017554940655827522
Loss at iteration 490 : 0.010287472978234291
Loss at iteration 500 : 0.01149526797235012
Loss at iteration 510 : 0.012035198509693146
Loss at iteration 520 : 0.00945929903537035
Loss at iteration 530 : 0.01235157810151577
Loss at iteration 540 : 0.004598940256983042
Loss at iteration 550 : 0.013275177218019962
Loss at iteration 560 : 0.018073033541440964
Loss at iteration 570 : 0.0095377117395401
Loss at iteration 580 : 0.010169979184865952
Loss at iteration 590 : 0.013062168844044209
Loss at iteration 600 : 0.010345587506890297
Loss at iteration 610 : 0.013664997182786465
Loss at iteration 620 : 0.011935888789594173
Loss at iteration 630 : 0.016464838758111
Loss at iteration 640 : 0.010867144912481308
Loss at iteration 650 : 0.013232579454779625
Loss at iteration 660 : 0.013970605097711086
Loss at iteration 670 : 0.01040808204561472
Loss at iteration 680 : 0.011964826844632626
Loss at iteration 690 : 0.01043732836842537
Loss at iteration 700 : 0.011461136862635612
Loss at iteration 710 : 0.009873280301690102
Loss at iteration 720 : 0.006775819696485996
Loss at iteration 730 : 0.011767546646296978
Loss at iteration 740 : 0.011541683226823807
Loss at iteration 750 : 0.011372431181371212
Loss at iteration 760 : 0.010253477841615677
Loss at iteration 770 : 0.007623565848916769
Loss at iteration 780 : 0.004516805522143841
Loss at iteration 790 : 0.007184375077486038
Loss at iteration 800 : 0.010302534326910973
Loss at iteration 810 : 0.008330699987709522
Loss at iteration 820 : 0.013654205948114395
Loss at iteration 830 : 0.012612571008503437
Loss at iteration 840 : 0.011165574193000793
Loss at iteration 850 : 0.011372750625014305
Loss at iteration 860 : 0.01059239823371172
Loss at iteration 870 : 0.008094988763332367
Loss at iteration 880 : 0.01745026744902134
Loss at iteration 890 : 0.009930716827511787
Loss at iteration 900 : 0.012838806957006454
Loss at iteration 910 : 0.011845419183373451
Loss at iteration 920 : 0.009090298786759377
Loss at iteration 930 : 0.013979671522974968
Loss at iteration 940 : 0.01072213239967823
Loss at iteration 950 : 0.00804878119379282
Loss at iteration 960 : 0.012979261577129364
Loss at iteration 970 : 0.016028307378292084
Loss at iteration 980 : 0.011330537497997284
Loss at iteration 990 : 0.009229681454598904
Loss at iteration 1000 : 0.012906329706311226
Loss at iteration 1010 : 0.009951630607247353
Loss at iteration 1020 : 0.011058538220822811
Loss at iteration 1030 : 0.017894187942147255
Loss at iteration 1040 : 0.011275377124547958
Loss at iteration 1050 : 0.01386033184826374
Loss at iteration 1060 : 0.0063482616096735
Loss at iteration 1070 : 0.009086087346076965
Loss at iteration 1080 : 0.005658054258674383
Loss at iteration 1090 : 0.014494580216705799
Loss at iteration 1100 : 0.014060928486287594
Loss at iteration 1110 : 0.009486875496804714
Loss at iteration 1120 : 0.01647292822599411
Loss at iteration 1130 : 0.010449674911797047
Loss at iteration 1140 : 0.011745188385248184
Loss at iteration 1150 : 0.007947692647576332
Loss at iteration 1160 : 0.009159081615507603
Loss at iteration 1170 : 0.005778160411864519
Loss at iteration 1180 : 0.01306764967739582
Loss at iteration 1190 : 0.01107752975076437
Loss at iteration 1200 : 0.014883782714605331
Loss at iteration 1210 : 0.009963259100914001
The SSIM Value is: 0.8047396699587505
The PSNR Value is: 18.711697069803872
the epoch is: 103
Loss at iteration 10 : 0.01706625521183014
Loss at iteration 20 : 0.007136804983019829
Loss at iteration 30 : 0.014646217226982117
Loss at iteration 40 : 0.014740210957825184
Loss at iteration 50 : 0.007817698642611504
Loss at iteration 60 : 0.00968832429498434
Loss at iteration 70 : 0.01177212130278349
Loss at iteration 80 : 0.012629381380975246
Loss at iteration 90 : 0.011223666369915009
Loss at iteration 100 : 0.01704017072916031
Loss at iteration 110 : 0.00726060476154089
Loss at iteration 120 : 0.01395543571561575
Loss at iteration 130 : 0.01677696406841278
Loss at iteration 140 : 0.012893740087747574
Loss at iteration 150 : 0.012434025295078754
Loss at iteration 160 : 0.007654308807104826
Loss at iteration 170 : 0.010082313790917397
Loss at iteration 180 : 0.018704742193222046
Loss at iteration 190 : 0.0070835598744452
Loss at iteration 200 : 0.007205222733318806
Loss at iteration 210 : 0.007755338214337826
Loss at iteration 220 : 0.013875095173716545
Loss at iteration 230 : 0.013798683881759644
Loss at iteration 240 : 0.010742773301899433
Loss at iteration 250 : 0.0099150026217103
Loss at iteration 260 : 0.01766102761030197
Loss at iteration 270 : 0.010413877665996552
Loss at iteration 280 : 0.019344838336110115
Loss at iteration 290 : 0.009634326212108135
Loss at iteration 300 : 0.011600291356444359
Loss at iteration 310 : 0.007231245283037424
Loss at iteration 320 : 0.007155300118029118
Loss at iteration 330 : 0.02273418940603733
Loss at iteration 340 : 0.009237486869096756
Loss at iteration 350 : 0.011269452050328255
Loss at iteration 360 : 0.009924609214067459
Loss at iteration 370 : 0.00802576169371605
Loss at iteration 380 : 0.00570104643702507
Loss at iteration 390 : 0.014633871614933014
Loss at iteration 400 : 0.011890540830790997
Loss at iteration 410 : 0.011498517356812954
Loss at iteration 420 : 0.006349135190248489
Loss at iteration 430 : 0.009662965312600136
Loss at iteration 440 : 0.00909664761275053
Loss at iteration 450 : 0.011164174415171146
Loss at iteration 460 : 0.013334852643311024
Loss at iteration 470 : 0.010635372251272202
Loss at iteration 480 : 0.006363473832607269
Loss at iteration 490 : 0.0054262313060462475
Loss at iteration 500 : 0.009758265689015388
Loss at iteration 510 : 0.012388782575726509
Loss at iteration 520 : 0.00672469288110733
Loss at iteration 530 : 0.007727412041276693
Loss at iteration 540 : 0.0207508634775877
Loss at iteration 550 : 0.006226133555173874
Loss at iteration 560 : 0.01222363580018282
Loss at iteration 570 : 0.014266718178987503
Loss at iteration 580 : 0.017816975712776184
Loss at iteration 590 : 0.01466462854295969
Loss at iteration 600 : 0.018369358032941818
Loss at iteration 610 : 0.012129869312047958
Loss at iteration 620 : 0.009740866720676422
Loss at iteration 630 : 0.007809222210198641
Loss at iteration 640 : 0.010314073413610458
Loss at iteration 650 : 0.006482407450675964
Loss at iteration 660 : 0.01627245731651783
Loss at iteration 670 : 0.008362929336726665
Loss at iteration 680 : 0.012385951355099678
Loss at iteration 690 : 0.010715380311012268
Loss at iteration 700 : 0.017998341470956802
Loss at iteration 710 : 0.009429248049855232
Loss at iteration 720 : 0.01390841044485569
Loss at iteration 730 : 0.013460708782076836
Loss at iteration 740 : 0.011541083455085754
Loss at iteration 750 : 0.010525045916438103
Loss at iteration 760 : 0.010872981511056423
Loss at iteration 770 : 0.007802187465131283
Loss at iteration 780 : 0.007859939709305763
Loss at iteration 790 : 0.010463837534189224
Loss at iteration 800 : 0.00958295352756977
Loss at iteration 810 : 0.017132608219981194
Loss at iteration 820 : 0.01192188449203968
Loss at iteration 830 : 0.010994501411914825
Loss at iteration 840 : 0.010669104754924774
Loss at iteration 850 : 0.006843704264611006
Loss at iteration 860 : 0.009010661393404007
Loss at iteration 870 : 0.005944646429270506
Loss at iteration 880 : 0.016777414828538895
Loss at iteration 890 : 0.006889856420457363
Loss at iteration 900 : 0.007747856434434652
Loss at iteration 910 : 0.009869003668427467
Loss at iteration 920 : 0.008613459765911102
Loss at iteration 930 : 0.020447108894586563
Loss at iteration 940 : 0.01687861792743206
Loss at iteration 950 : 0.015728073194622993
Loss at iteration 960 : 0.012554255314171314
Loss at iteration 970 : 0.007021881174296141
Loss at iteration 980 : 0.011116930283606052
Loss at iteration 990 : 0.007021643221378326
Loss at iteration 1000 : 0.010169435292482376
Loss at iteration 1010 : 0.009349088184535503
Loss at iteration 1020 : 0.023655932396650314
Loss at iteration 1030 : 0.014255382120609283
Loss at iteration 1040 : 0.010714439675211906
Loss at iteration 1050 : 0.008890473283827305
Loss at iteration 1060 : 0.011175599880516529
Loss at iteration 1070 : 0.007975363172590733
Loss at iteration 1080 : 0.007803820073604584
Loss at iteration 1090 : 0.007947762496769428
Loss at iteration 1100 : 0.010840342380106449
Loss at iteration 1110 : 0.010552925989031792
Loss at iteration 1120 : 0.009889425709843636
Loss at iteration 1130 : 0.005603005178272724
Loss at iteration 1140 : 0.010665860027074814
Loss at iteration 1150 : 0.009853377938270569
Loss at iteration 1160 : 0.010902037844061852
Loss at iteration 1170 : 0.010057274252176285
Loss at iteration 1180 : 0.013467561453580856
Loss at iteration 1190 : 0.01750767230987549
Loss at iteration 1200 : 0.009108316153287888
Loss at iteration 1210 : 0.00973509717732668
The SSIM Value is: 0.7894750515619914
The PSNR Value is: 17.90029067993164
the epoch is: 104
Loss at iteration 10 : 0.011467247270047665
Loss at iteration 20 : 0.010816697962582111
Loss at iteration 30 : 0.010346322320401669
Loss at iteration 40 : 0.007826283574104309
Loss at iteration 50 : 0.008711138740181923
Loss at iteration 60 : 0.010151644237339497
Loss at iteration 70 : 0.006151470355689526
Loss at iteration 80 : 0.012510235421359539
Loss at iteration 90 : 0.013210460543632507
Loss at iteration 100 : 0.014686213806271553
Loss at iteration 110 : 0.011670028790831566
Loss at iteration 120 : 0.010800604708492756
Loss at iteration 130 : 0.005264532286673784
Loss at iteration 140 : 0.010471564717590809
Loss at iteration 150 : 0.0059421248733997345
Loss at iteration 160 : 0.016652964055538177
Loss at iteration 170 : 0.009269672445952892
Loss at iteration 180 : 0.007888677529990673
Loss at iteration 190 : 0.01790541410446167
Loss at iteration 200 : 0.007773036602884531
Loss at iteration 210 : 0.00906728208065033
Loss at iteration 220 : 0.005577492527663708
Loss at iteration 230 : 0.012070393189787865
Loss at iteration 240 : 0.006515120156109333
Loss at iteration 250 : 0.018566126003861427
Loss at iteration 260 : 0.007044858764857054
Loss at iteration 270 : 0.009809738025069237
Loss at iteration 280 : 0.013856370933353901
Loss at iteration 290 : 0.012796248309314251
Loss at iteration 300 : 0.009497864171862602
Loss at iteration 310 : 0.01099502295255661
Loss at iteration 320 : 0.0140575235709548
Loss at iteration 330 : 0.009907594881951809
Loss at iteration 340 : 0.014242975041270256
Loss at iteration 350 : 0.01142601016908884
Loss at iteration 360 : 0.018263433128595352
Loss at iteration 370 : 0.011895951814949512
Loss at iteration 380 : 0.0071135652251541615
Loss at iteration 390 : 0.007650231942534447
Loss at iteration 400 : 0.017875581979751587
Loss at iteration 410 : 0.016235917806625366
Loss at iteration 420 : 0.013969771564006805
Loss at iteration 430 : 0.01519531849771738
Loss at iteration 440 : 0.017683446407318115
Loss at iteration 450 : 0.01207590289413929
Loss at iteration 460 : 0.007485003210604191
Loss at iteration 470 : 0.007611301261931658
Loss at iteration 480 : 0.008075293153524399
Loss at iteration 490 : 0.008077815175056458
Loss at iteration 500 : 0.015361218713223934
Loss at iteration 510 : 0.00605417275801301
Loss at iteration 520 : 0.011079074814915657
Loss at iteration 530 : 0.009740084409713745
Loss at iteration 540 : 0.014792600646615028
Loss at iteration 550 : 0.015175500884652138
Loss at iteration 560 : 0.010301358066499233
Loss at iteration 570 : 0.01207212544977665
Loss at iteration 580 : 0.013670654967427254
Loss at iteration 590 : 0.015875723212957382
Loss at iteration 600 : 0.008919287472963333
Loss at iteration 610 : 0.009113527834415436
Loss at iteration 620 : 0.013037590309977531
Loss at iteration 630 : 0.008850488811731339
Loss at iteration 640 : 0.015919562429189682
Loss at iteration 650 : 0.012950959615409374
Loss at iteration 660 : 0.0066549768671393394
Loss at iteration 670 : 0.013501426205039024
Loss at iteration 680 : 0.012621777132153511
Loss at iteration 690 : 0.005919923074543476
Loss at iteration 700 : 0.006919472478330135
Loss at iteration 710 : 0.014749070629477501
Loss at iteration 720 : 0.007429668679833412
Loss at iteration 730 : 0.01301497220993042
Loss at iteration 740 : 0.00977843813598156
Loss at iteration 750 : 0.008055032230913639
Loss at iteration 760 : 0.010149120353162289
Loss at iteration 770 : 0.008158452808856964
Loss at iteration 780 : 0.0076796384528279305
Loss at iteration 790 : 0.006061729043722153
Loss at iteration 800 : 0.012686808593571186
Loss at iteration 810 : 0.013658319599926472
Loss at iteration 820 : 0.014200893230736256
Loss at iteration 830 : 0.008270733058452606
Loss at iteration 840 : 0.008067956194281578
Loss at iteration 850 : 0.013030866160988808
Loss at iteration 860 : 0.00909879244863987
Loss at iteration 870 : 0.013222022913396358
Loss at iteration 880 : 0.0099751316010952
Loss at iteration 890 : 0.010986636392772198
Loss at iteration 900 : 0.01186371874064207
Loss at iteration 910 : 0.009687816724181175
Loss at iteration 920 : 0.010446453467011452
Loss at iteration 930 : 0.010697046294808388
Loss at iteration 940 : 0.015444216318428516
Loss at iteration 950 : 0.007635325193405151
Loss at iteration 960 : 0.011008002795279026
Loss at iteration 970 : 0.009280816651880741
Loss at iteration 980 : 0.008530967868864536
Loss at iteration 990 : 0.006936901714652777
Loss at iteration 1000 : 0.00894431583583355
Loss at iteration 1010 : 0.005164587404578924
Loss at iteration 1020 : 0.012719862163066864
Loss at iteration 1030 : 0.014176747761666775
Loss at iteration 1040 : 0.00952572375535965
Loss at iteration 1050 : 0.01028345711529255
Loss at iteration 1060 : 0.01278948038816452
Loss at iteration 1070 : 0.008808121085166931
Loss at iteration 1080 : 0.01648944430053234
Loss at iteration 1090 : 0.011999070644378662
Loss at iteration 1100 : 0.014077156782150269
Loss at iteration 1110 : 0.010639701038599014
Loss at iteration 1120 : 0.00978960283100605
Loss at iteration 1130 : 0.015784118324518204
Loss at iteration 1140 : 0.008613241836428642
Loss at iteration 1150 : 0.00998738408088684
Loss at iteration 1160 : 0.012502577155828476
Loss at iteration 1170 : 0.00995681993663311
Loss at iteration 1180 : 0.012057543732225895
Loss at iteration 1190 : 0.01056224200874567
Loss at iteration 1200 : 0.008203866891562939
Loss at iteration 1210 : 0.01032897550612688
The SSIM Value is: 0.8099975466728211
The PSNR Value is: 18.890969848632814
the epoch is: 105
Loss at iteration 10 : 0.0134898005053401
Loss at iteration 20 : 0.011096455156803131
Loss at iteration 30 : 0.005527724511921406
Loss at iteration 40 : 0.005167100578546524
Loss at iteration 50 : 0.006745710037648678
Loss at iteration 60 : 0.004941160790622234
Loss at iteration 70 : 0.009715665131807327
Loss at iteration 80 : 0.018244527280330658
Loss at iteration 90 : 0.011465555988252163
Loss at iteration 100 : 0.009625724516808987
Loss at iteration 110 : 0.00647168280556798
Loss at iteration 120 : 0.006221720948815346
Loss at iteration 130 : 0.011272056959569454
Loss at iteration 140 : 0.009740532375872135
Loss at iteration 150 : 0.011661907657980919
Loss at iteration 160 : 0.008559415116906166
Loss at iteration 170 : 0.02091950550675392
Loss at iteration 180 : 0.011833800002932549
Loss at iteration 190 : 0.009226636961102486
Loss at iteration 200 : 0.013172343373298645
Loss at iteration 210 : 0.006179658696055412
Loss at iteration 220 : 0.00873461365699768
Loss at iteration 230 : 0.009418264962732792
Loss at iteration 240 : 0.016490638256072998
Loss at iteration 250 : 0.008016573265194893
Loss at iteration 260 : 0.015759536996483803
Loss at iteration 270 : 0.01005176268517971
Loss at iteration 280 : 0.010964920744299889
Loss at iteration 290 : 0.007053496316075325
Loss at iteration 300 : 0.007816791534423828
Loss at iteration 310 : 0.017167547717690468
Loss at iteration 320 : 0.007082168012857437
Loss at iteration 330 : 0.014203444123268127
Loss at iteration 340 : 0.00854494795203209
Loss at iteration 350 : 0.011310039088129997
Loss at iteration 360 : 0.010034797713160515
Loss at iteration 370 : 0.007798544596880674
Loss at iteration 380 : 0.008919446729123592
Loss at iteration 390 : 0.01064845360815525
Loss at iteration 400 : 0.01198624074459076
Loss at iteration 410 : 0.016452230513095856
Loss at iteration 420 : 0.012954369187355042
Loss at iteration 430 : 0.010148122906684875
Loss at iteration 440 : 0.009505881927907467
Loss at iteration 450 : 0.00819700863212347
Loss at iteration 460 : 0.012441716156899929
Loss at iteration 470 : 0.013713443651795387
Loss at iteration 480 : 0.014201886020600796
Loss at iteration 490 : 0.010748455300927162
Loss at iteration 500 : 0.006884570233523846
Loss at iteration 510 : 0.008789528161287308
Loss at iteration 520 : 0.010693421587347984
Loss at iteration 530 : 0.01050013117492199
Loss at iteration 540 : 0.010582906194031239
Loss at iteration 550 : 0.010949374176561832
Loss at iteration 560 : 0.0179467611014843
Loss at iteration 570 : 0.014703353866934776
Loss at iteration 580 : 0.010668187402188778
Loss at iteration 590 : 0.020865309983491898
Loss at iteration 600 : 0.009491704404354095
Loss at iteration 610 : 0.006996575277298689
Loss at iteration 620 : 0.008905588649213314
Loss at iteration 630 : 0.012514080852270126
Loss at iteration 640 : 0.010476622730493546
Loss at iteration 650 : 0.007939484901726246
Loss at iteration 660 : 0.014058075845241547
Loss at iteration 670 : 0.013677040114998817
Loss at iteration 680 : 0.01482316292822361
Loss at iteration 690 : 0.009186395443975925
Loss at iteration 700 : 0.007136779371649027
Loss at iteration 710 : 0.012806329876184464
Loss at iteration 720 : 0.007191829849034548
Loss at iteration 730 : 0.014245882630348206
Loss at iteration 740 : 0.011068987660109997
Loss at iteration 750 : 0.007038989569991827
Loss at iteration 760 : 0.009843042120337486
Loss at iteration 770 : 0.01149333082139492
Loss at iteration 780 : 0.006800468545407057
Loss at iteration 790 : 0.009454931132495403
Loss at iteration 800 : 0.006486782804131508
Loss at iteration 810 : 0.012716527096927166
Loss at iteration 820 : 0.0096083153039217
Loss at iteration 830 : 0.0117548992857337
Loss at iteration 840 : 0.006496557034552097
Loss at iteration 850 : 0.008958601392805576
Loss at iteration 860 : 0.010202571749687195
Loss at iteration 870 : 0.00897875428199768
Loss at iteration 880 : 0.02019677311182022
Loss at iteration 890 : 0.006780046969652176
Loss at iteration 900 : 0.009585028514266014
Loss at iteration 910 : 0.011880784295499325
Loss at iteration 920 : 0.009637650102376938
Loss at iteration 930 : 0.006323686800897121
Loss at iteration 940 : 0.007881823927164078
Loss at iteration 950 : 0.013880477286875248
Loss at iteration 960 : 0.00898035243153572
Loss at iteration 970 : 0.009214717894792557
Loss at iteration 980 : 0.013506351970136166
Loss at iteration 990 : 0.008336393162608147
Loss at iteration 1000 : 0.006291686557233334
Loss at iteration 1010 : 0.012306846678256989
Loss at iteration 1020 : 0.009853768162429333
Loss at iteration 1030 : 0.006465672515332699
Loss at iteration 1040 : 0.019574176520109177
Loss at iteration 1050 : 0.008565528318285942
Loss at iteration 1060 : 0.015822406858205795
Loss at iteration 1070 : 0.019999433308839798
Loss at iteration 1080 : 0.012161916121840477
Loss at iteration 1090 : 0.01364605687558651
Loss at iteration 1100 : 0.0108534786850214
Loss at iteration 1110 : 0.008268536999821663
Loss at iteration 1120 : 0.010578988119959831
Loss at iteration 1130 : 0.012121841311454773
Loss at iteration 1140 : 0.009113064035773277
Loss at iteration 1150 : 0.010293028317391872
Loss at iteration 1160 : 0.010581756010651588
Loss at iteration 1170 : 0.008252883329987526
Loss at iteration 1180 : 0.00817619077861309
Loss at iteration 1190 : 0.011672423221170902
Loss at iteration 1200 : 0.01602894999086857
Loss at iteration 1210 : 0.026090748608112335
The SSIM Value is: 0.7982475876808166
The PSNR Value is: 18.556603495279948
the epoch is: 106
Loss at iteration 10 : 0.012201143428683281
Loss at iteration 20 : 0.008172828704118729
Loss at iteration 30 : 0.012714026495814323
Loss at iteration 40 : 0.011181049980223179
Loss at iteration 50 : 0.01016196794807911
Loss at iteration 60 : 0.012243334203958511
Loss at iteration 70 : 0.010622324422001839
Loss at iteration 80 : 0.010477518662810326
Loss at iteration 90 : 0.010913293808698654
Loss at iteration 100 : 0.009234410710632801
Loss at iteration 110 : 0.008979769423604012
Loss at iteration 120 : 0.00850851833820343
Loss at iteration 130 : 0.013627052307128906
Loss at iteration 140 : 0.010960770770907402
Loss at iteration 150 : 0.012133646756410599
Loss at iteration 160 : 0.00649273581802845
Loss at iteration 170 : 0.012693017721176147
Loss at iteration 180 : 0.011421055532991886
Loss at iteration 190 : 0.009438121691346169
Loss at iteration 200 : 0.007366864010691643
Loss at iteration 210 : 0.012853794731199741
Loss at iteration 220 : 0.014751104637980461
Loss at iteration 230 : 0.007247635629028082
Loss at iteration 240 : 0.009877323172986507
Loss at iteration 250 : 0.012526086531579494
Loss at iteration 260 : 0.007900008000433445
Loss at iteration 270 : 0.008930337615311146
Loss at iteration 280 : 0.01207620557397604
Loss at iteration 290 : 0.015542479231953621
Loss at iteration 300 : 0.011724838986992836
Loss at iteration 310 : 0.013736631721258163
Loss at iteration 320 : 0.011457598768174648
Loss at iteration 330 : 0.0186406709253788
Loss at iteration 340 : 0.00797013845294714
Loss at iteration 350 : 0.012504519894719124
Loss at iteration 360 : 0.012070768512785435
Loss at iteration 370 : 0.016273517161607742
Loss at iteration 380 : 0.011475914157927036
Loss at iteration 390 : 0.00850195437669754
Loss at iteration 400 : 0.014178205281496048
Loss at iteration 410 : 0.022099627181887627
Loss at iteration 420 : 0.008555559441447258
Loss at iteration 430 : 0.0044797081500291824
Loss at iteration 440 : 0.009611422196030617
Loss at iteration 450 : 0.009757781401276588
Loss at iteration 460 : 0.008841605857014656
Loss at iteration 470 : 0.009047530591487885
Loss at iteration 480 : 0.00767547357827425
Loss at iteration 490 : 0.014927007257938385
Loss at iteration 500 : 0.013415665365755558
Loss at iteration 510 : 0.009026561863720417
Loss at iteration 520 : 0.006202888209372759
Loss at iteration 530 : 0.015710175037384033
Loss at iteration 540 : 0.012302672490477562
Loss at iteration 550 : 0.007038741838186979
Loss at iteration 560 : 0.006364166736602783
Loss at iteration 570 : 0.007217439357191324
Loss at iteration 580 : 0.017175987362861633
Loss at iteration 590 : 0.009969037026166916
Loss at iteration 600 : 0.009639096446335316
Loss at iteration 610 : 0.01102636568248272
Loss at iteration 620 : 0.01441549975425005
Loss at iteration 630 : 0.014748791232705116
Loss at iteration 640 : 0.016918616369366646
Loss at iteration 650 : 0.013648347929120064
Loss at iteration 660 : 0.01301063597202301
Loss at iteration 670 : 0.010247928090393543
Loss at iteration 680 : 0.01668081432580948
Loss at iteration 690 : 0.014939089305698872
Loss at iteration 700 : 0.013647684827446938
Loss at iteration 710 : 0.009815452620387077
Loss at iteration 720 : 0.012851821258664131
Loss at iteration 730 : 0.011435750871896744
Loss at iteration 740 : 0.0148273054510355
Loss at iteration 750 : 0.010282059200108051
Loss at iteration 760 : 0.012514854781329632
Loss at iteration 770 : 0.010270126163959503
Loss at iteration 780 : 0.009291871450841427
Loss at iteration 790 : 0.005535734351724386
Loss at iteration 800 : 0.013568702153861523
Loss at iteration 810 : 0.00664629228413105
Loss at iteration 820 : 0.012367451563477516
Loss at iteration 830 : 0.017019180580973625
Loss at iteration 840 : 0.011577808298170567
Loss at iteration 850 : 0.011282434687018394
Loss at iteration 860 : 0.012753935530781746
Loss at iteration 870 : 0.006999197416007519
Loss at iteration 880 : 0.011847779154777527
Loss at iteration 890 : 0.009588414803147316
Loss at iteration 900 : 0.012017311528325081
Loss at iteration 910 : 0.011180710978806019
Loss at iteration 920 : 0.01116212084889412
Loss at iteration 930 : 0.011503388173878193
Loss at iteration 940 : 0.01817593351006508
Loss at iteration 950 : 0.008885430172085762
Loss at iteration 960 : 0.012239898554980755
Loss at iteration 970 : 0.01169082522392273
Loss at iteration 980 : 0.012323628179728985
Loss at iteration 990 : 0.006074001081287861
Loss at iteration 1000 : 0.01372193731367588
Loss at iteration 1010 : 0.008086948655545712
Loss at iteration 1020 : 0.010378101840615273
Loss at iteration 1030 : 0.007339039817452431
Loss at iteration 1040 : 0.018160082399845123
Loss at iteration 1050 : 0.014242284931242466
Loss at iteration 1060 : 0.007662166841328144
Loss at iteration 1070 : 0.008386209607124329
Loss at iteration 1080 : 0.016766581684350967
Loss at iteration 1090 : 0.009220961481332779
Loss at iteration 1100 : 0.007887374609708786
Loss at iteration 1110 : 0.01666141487658024
Loss at iteration 1120 : 0.009488960728049278
Loss at iteration 1130 : 0.013858489692211151
Loss at iteration 1140 : 0.009929007850587368
Loss at iteration 1150 : 0.006436512805521488
Loss at iteration 1160 : 0.010576274245977402
Loss at iteration 1170 : 0.010882215574383736
Loss at iteration 1180 : 0.007433750666677952
Loss at iteration 1190 : 0.011873575858771801
Loss at iteration 1200 : 0.007666559889912605
Loss at iteration 1210 : 0.013160654343664646
The SSIM Value is: 0.7998269478480021
The PSNR Value is: 18.38423646291097
the epoch is: 107
Loss at iteration 10 : 0.01018450129777193
Loss at iteration 20 : 0.017490841448307037
Loss at iteration 30 : 0.006787645164877176
Loss at iteration 40 : 0.011592262424528599
Loss at iteration 50 : 0.007061039563268423
Loss at iteration 60 : 0.019560199230909348
Loss at iteration 70 : 0.006149038672447205
Loss at iteration 80 : 0.008191395550966263
Loss at iteration 90 : 0.0113851772621274
Loss at iteration 100 : 0.01434226892888546
Loss at iteration 110 : 0.012179028242826462
Loss at iteration 120 : 0.010100312530994415
Loss at iteration 130 : 0.013401664793491364
Loss at iteration 140 : 0.008293023332953453
Loss at iteration 150 : 0.008457954972982407
Loss at iteration 160 : 0.014054177328944206
Loss at iteration 170 : 0.010784781537950039
Loss at iteration 180 : 0.009222050197422504
Loss at iteration 190 : 0.012144031003117561
Loss at iteration 200 : 0.012361573055386543
Loss at iteration 210 : 0.00809063483029604
Loss at iteration 220 : 0.01421620137989521
Loss at iteration 230 : 0.011705518700182438
Loss at iteration 240 : 0.015278637409210205
Loss at iteration 250 : 0.013695456087589264
Loss at iteration 260 : 0.013969285413622856
Loss at iteration 270 : 0.006899126339703798
Loss at iteration 280 : 0.011936996132135391
Loss at iteration 290 : 0.012043669819831848
Loss at iteration 300 : 0.011495980434119701
Loss at iteration 310 : 0.01195246260613203
Loss at iteration 320 : 0.010651346296072006
Loss at iteration 330 : 0.009416289627552032
Loss at iteration 340 : 0.008468208834528923
Loss at iteration 350 : 0.014199514873325825
Loss at iteration 360 : 0.006690453737974167
Loss at iteration 370 : 0.017248645424842834
Loss at iteration 380 : 0.011324934661388397
Loss at iteration 390 : 0.012761207297444344
Loss at iteration 400 : 0.008533235639333725
Loss at iteration 410 : 0.013614500872790813
Loss at iteration 420 : 0.008026606403291225
Loss at iteration 430 : 0.01061671506613493
Loss at iteration 440 : 0.014300396665930748
Loss at iteration 450 : 0.014756630174815655
Loss at iteration 460 : 0.015173555351793766
Loss at iteration 470 : 0.013545751571655273
Loss at iteration 480 : 0.006498193368315697
Loss at iteration 490 : 0.007714038249105215
Loss at iteration 500 : 0.014833363704383373
Loss at iteration 510 : 0.006663483567535877
Loss at iteration 520 : 0.011916459538042545
Loss at iteration 530 : 0.010437698103487492
Loss at iteration 540 : 0.00879852008074522
Loss at iteration 550 : 0.008873136714100838
Loss at iteration 560 : 0.010090676136314869
Loss at iteration 570 : 0.008115268312394619
Loss at iteration 580 : 0.021261731162667274
Loss at iteration 590 : 0.008074485696852207
Loss at iteration 600 : 0.015163308009505272
Loss at iteration 610 : 0.015311464667320251
Loss at iteration 620 : 0.010591932572424412
Loss at iteration 630 : 0.016927655786275864
Loss at iteration 640 : 0.010491914115846157
Loss at iteration 650 : 0.009734421968460083
Loss at iteration 660 : 0.012128753587603569
Loss at iteration 670 : 0.012063214555382729
Loss at iteration 680 : 0.010358014144003391
Loss at iteration 690 : 0.01002094428986311
Loss at iteration 700 : 0.012739274650812149
Loss at iteration 710 : 0.017783740535378456
Loss at iteration 720 : 0.00940333865582943
Loss at iteration 730 : 0.01271172147244215
Loss at iteration 740 : 0.009406456723809242
Loss at iteration 750 : 0.007970415987074375
Loss at iteration 760 : 0.013750210404396057
Loss at iteration 770 : 0.015961075201630592
Loss at iteration 780 : 0.01065659150481224
Loss at iteration 790 : 0.008698711171746254
Loss at iteration 800 : 0.012455685064196587
Loss at iteration 810 : 0.010981576517224312
Loss at iteration 820 : 0.007899755612015724
Loss at iteration 830 : 0.012208784930408001
Loss at iteration 840 : 0.011335520073771477
Loss at iteration 850 : 0.014650835655629635
Loss at iteration 860 : 0.011373359709978104
Loss at iteration 870 : 0.006127894856035709
Loss at iteration 880 : 0.007657050620764494
Loss at iteration 890 : 0.012360893189907074
Loss at iteration 900 : 0.00828690454363823
Loss at iteration 910 : 0.008848806843161583
Loss at iteration 920 : 0.014527939260005951
Loss at iteration 930 : 0.008183575235307217
Loss at iteration 940 : 0.016889110207557678
Loss at iteration 950 : 0.013690792955458164
Loss at iteration 960 : 0.008569505997002125
Loss at iteration 970 : 0.013278467580676079
Loss at iteration 980 : 0.012270160019397736
Loss at iteration 990 : 0.01262169424444437
Loss at iteration 1000 : 0.010751866735517979
Loss at iteration 1010 : 0.012997394427657127
Loss at iteration 1020 : 0.01486569456756115
Loss at iteration 1030 : 0.017237890511751175
Loss at iteration 1040 : 0.009691442362964153
Loss at iteration 1050 : 0.01298559457063675
Loss at iteration 1060 : 0.012070681899785995
Loss at iteration 1070 : 0.01816447637975216
Loss at iteration 1080 : 0.007521085906773806
Loss at iteration 1090 : 0.011693661101162434
Loss at iteration 1100 : 0.010743116959929466
Loss at iteration 1110 : 0.0102733438834548
Loss at iteration 1120 : 0.011158296838402748
Loss at iteration 1130 : 0.008083183318376541
Loss at iteration 1140 : 0.01017974317073822
Loss at iteration 1150 : 0.01052873395383358
Loss at iteration 1160 : 0.012148485518991947
Loss at iteration 1170 : 0.005314793437719345
Loss at iteration 1180 : 0.012803358025848866
Loss at iteration 1190 : 0.009674949571490288
Loss at iteration 1200 : 0.006862000562250614
Loss at iteration 1210 : 0.010468093678355217
The SSIM Value is: 0.8051506519317627
The PSNR Value is: 18.81702423095703
the epoch is: 108
Loss at iteration 10 : 0.010765989311039448
Loss at iteration 20 : 0.013920776546001434
Loss at iteration 30 : 0.02053776942193508
Loss at iteration 40 : 0.011911006644368172
Loss at iteration 50 : 0.012288754805922508
Loss at iteration 60 : 0.01429839339107275
Loss at iteration 70 : 0.015199468471109867
Loss at iteration 80 : 0.011347769759595394
Loss at iteration 90 : 0.009422803297638893
Loss at iteration 100 : 0.01103336364030838
Loss at iteration 110 : 0.008279819041490555
Loss at iteration 120 : 0.017644835636019707
Loss at iteration 130 : 0.012825531885027885
Loss at iteration 140 : 0.008263794705271721
Loss at iteration 150 : 0.006097443867474794
Loss at iteration 160 : 0.012449820525944233
Loss at iteration 170 : 0.006414489354938269
Loss at iteration 180 : 0.019318319857120514
Loss at iteration 190 : 0.009552848525345325
Loss at iteration 200 : 0.014431475661695004
Loss at iteration 210 : 0.015516156330704689
Loss at iteration 220 : 0.01345297135412693
Loss at iteration 230 : 0.01799667254090309
Loss at iteration 240 : 0.00781942903995514
Loss at iteration 250 : 0.014675119891762733
Loss at iteration 260 : 0.0076790014281868935
Loss at iteration 270 : 0.006253370083868504
Loss at iteration 280 : 0.012146830558776855
Loss at iteration 290 : 0.010331840254366398
Loss at iteration 300 : 0.00903831236064434
Loss at iteration 310 : 0.010491389781236649
Loss at iteration 320 : 0.014296116307377815
Loss at iteration 330 : 0.006661814637482166
Loss at iteration 340 : 0.016761282458901405
Loss at iteration 350 : 0.0095366844907403
Loss at iteration 360 : 0.010864784941077232
Loss at iteration 370 : 0.00707122590392828
Loss at iteration 380 : 0.008573188446462154
Loss at iteration 390 : 0.013511545956134796
Loss at iteration 400 : 0.011056470684707165
Loss at iteration 410 : 0.007178008556365967
Loss at iteration 420 : 0.01568828523159027
Loss at iteration 430 : 0.01044399943202734
Loss at iteration 440 : 0.009359827265143394
Loss at iteration 450 : 0.012375812977552414
Loss at iteration 460 : 0.00992340873926878
Loss at iteration 470 : 0.0072966888546943665
Loss at iteration 480 : 0.006071861367672682
Loss at iteration 490 : 0.00681747542694211
Loss at iteration 500 : 0.011512724682688713
Loss at iteration 510 : 0.009837998077273369
Loss at iteration 520 : 0.007572024129331112
Loss at iteration 530 : 0.020333077758550644
Loss at iteration 540 : 0.009601296856999397
Loss at iteration 550 : 0.01090567372739315
Loss at iteration 560 : 0.018991176038980484
Loss at iteration 570 : 0.008925842121243477
Loss at iteration 580 : 0.014194538816809654
Loss at iteration 590 : 0.009122141636908054
Loss at iteration 600 : 0.013971881940960884
Loss at iteration 610 : 0.013134383596479893
Loss at iteration 620 : 0.01292963232845068
Loss at iteration 630 : 0.01130732987076044
Loss at iteration 640 : 0.008585802279412746
Loss at iteration 650 : 0.010910680517554283
Loss at iteration 660 : 0.0063896640203893185
Loss at iteration 670 : 0.012946631759405136
Loss at iteration 680 : 0.013055462390184402
Loss at iteration 690 : 0.011220533400774002
Loss at iteration 700 : 0.0141316382214427
Loss at iteration 710 : 0.0062093837186694145
Loss at iteration 720 : 0.017275502905249596
Loss at iteration 730 : 0.010124518536031246
Loss at iteration 740 : 0.0062242900021374226
Loss at iteration 750 : 0.009951883926987648
Loss at iteration 760 : 0.007369266822934151
Loss at iteration 770 : 0.020605014637112617
Loss at iteration 780 : 0.010239271447062492
Loss at iteration 790 : 0.007253473624587059
Loss at iteration 800 : 0.008876494131982327
Loss at iteration 810 : 0.008902352303266525
Loss at iteration 820 : 0.008041556924581528
Loss at iteration 830 : 0.0069097671657800674
Loss at iteration 840 : 0.016953468322753906
Loss at iteration 850 : 0.010107027366757393
Loss at iteration 860 : 0.008342867717146873
Loss at iteration 870 : 0.01189055573195219
Loss at iteration 880 : 0.010921923443675041
Loss at iteration 890 : 0.012864217162132263
Loss at iteration 900 : 0.008995318785309792
Loss at iteration 910 : 0.01285826787352562
Loss at iteration 920 : 0.011741268448531628
Loss at iteration 930 : 0.013634676113724709
Loss at iteration 940 : 0.009514888748526573
Loss at iteration 950 : 0.008849612437188625
Loss at iteration 960 : 0.005033379886299372
Loss at iteration 970 : 0.005191585049033165
Loss at iteration 980 : 0.009853621013462543
Loss at iteration 990 : 0.011343610472977161
Loss at iteration 1000 : 0.006888504605740309
Loss at iteration 1010 : 0.009540025144815445
Loss at iteration 1020 : 0.00853516161441803
Loss at iteration 1030 : 0.005963245406746864
Loss at iteration 1040 : 0.013391973450779915
Loss at iteration 1050 : 0.008905481547117233
Loss at iteration 1060 : 0.012464107014238834
Loss at iteration 1070 : 0.010810498148202896
Loss at iteration 1080 : 0.007473430596292019
Loss at iteration 1090 : 0.007714537903666496
Loss at iteration 1100 : 0.008483296260237694
Loss at iteration 1110 : 0.008535586297512054
Loss at iteration 1120 : 0.013997519388794899
Loss at iteration 1130 : 0.01092340424656868
Loss at iteration 1140 : 0.013830062001943588
Loss at iteration 1150 : 0.012101943604648113
Loss at iteration 1160 : 0.009873510338366032
Loss at iteration 1170 : 0.007584011182188988
Loss at iteration 1180 : 0.00703186821192503
Loss at iteration 1190 : 0.01640641689300537
Loss at iteration 1200 : 0.014664143323898315
Loss at iteration 1210 : 0.009784044697880745
The SSIM Value is: 0.8077357530593872
The PSNR Value is: 18.456891949971517
the epoch is: 109
Loss at iteration 10 : 0.007719076704233885
Loss at iteration 20 : 0.01078435406088829
Loss at iteration 30 : 0.008455391973257065
Loss at iteration 40 : 0.00681087002158165
Loss at iteration 50 : 0.009350970387458801
Loss at iteration 60 : 0.01063124556094408
Loss at iteration 70 : 0.009333416819572449
Loss at iteration 80 : 0.01486523449420929
Loss at iteration 90 : 0.005111509934067726
Loss at iteration 100 : 0.0072515737265348434
Loss at iteration 110 : 0.005986963398754597
Loss at iteration 120 : 0.014976026490330696
Loss at iteration 130 : 0.00686290767043829
Loss at iteration 140 : 0.01252707652747631
Loss at iteration 150 : 0.006740092299878597
Loss at iteration 160 : 0.01173477154225111
Loss at iteration 170 : 0.009964139200747013
Loss at iteration 180 : 0.005923076067119837
Loss at iteration 190 : 0.014559195376932621
Loss at iteration 200 : 0.009921321645379066
Loss at iteration 210 : 0.008971577510237694
Loss at iteration 220 : 0.009955568239092827
Loss at iteration 230 : 0.011851951479911804
Loss at iteration 240 : 0.011789512820541859
Loss at iteration 250 : 0.01516734529286623
Loss at iteration 260 : 0.01721065305173397
Loss at iteration 270 : 0.012020107358694077
Loss at iteration 280 : 0.0060211108066141605
Loss at iteration 290 : 0.008996850810945034
Loss at iteration 300 : 0.007892618887126446
Loss at iteration 310 : 0.012392595410346985
Loss at iteration 320 : 0.0133550725877285
Loss at iteration 330 : 0.011499777436256409
Loss at iteration 340 : 0.014381153509020805
Loss at iteration 350 : 0.012975050136446953
Loss at iteration 360 : 0.01099185086786747
Loss at iteration 370 : 0.009052427485585213
Loss at iteration 380 : 0.017883270978927612
Loss at iteration 390 : 0.011106248944997787
Loss at iteration 400 : 0.010480210185050964
Loss at iteration 410 : 0.021313989534974098
Loss at iteration 420 : 0.014237266965210438
Loss at iteration 430 : 0.00567386019974947
Loss at iteration 440 : 0.01088074129074812
Loss at iteration 450 : 0.008774702437222004
Loss at iteration 460 : 0.01238417997956276
Loss at iteration 470 : 0.006046480964869261
Loss at iteration 480 : 0.009485283866524696
Loss at iteration 490 : 0.006529915612190962
Loss at iteration 500 : 0.012941563501954079
Loss at iteration 510 : 0.016316069290041924
Loss at iteration 520 : 0.0155633594840765
Loss at iteration 530 : 0.0189540795981884
Loss at iteration 540 : 0.012119032442569733
Loss at iteration 550 : 0.005066277459263802
Loss at iteration 560 : 0.020034555345773697
Loss at iteration 570 : 0.011064982041716576
Loss at iteration 580 : 0.00774342380464077
Loss at iteration 590 : 0.011971848085522652
Loss at iteration 600 : 0.01474013552069664
Loss at iteration 610 : 0.0068787503987550735
Loss at iteration 620 : 0.008602089248597622
Loss at iteration 630 : 0.010019289329648018
Loss at iteration 640 : 0.014377540908753872
Loss at iteration 650 : 0.013636454939842224
Loss at iteration 660 : 0.012573161162436008
Loss at iteration 670 : 0.009416231885552406
Loss at iteration 680 : 0.0111974673345685
Loss at iteration 690 : 0.01387019269168377
Loss at iteration 700 : 0.01024060882627964
Loss at iteration 710 : 0.015371378511190414
Loss at iteration 720 : 0.018518827855587006
Loss at iteration 730 : 0.012630470097064972
Loss at iteration 740 : 0.012511246837675571
Loss at iteration 750 : 0.008101600222289562
Loss at iteration 760 : 0.01008814200758934
Loss at iteration 770 : 0.008300945162773132
Loss at iteration 780 : 0.008313680998980999
Loss at iteration 790 : 0.011581622064113617
Loss at iteration 800 : 0.007847574539482594
Loss at iteration 810 : 0.007131727412343025
Loss at iteration 820 : 0.011354825459420681
Loss at iteration 830 : 0.01306772232055664
Loss at iteration 840 : 0.014710387215018272
Loss at iteration 850 : 0.016246018931269646
Loss at iteration 860 : 0.011040030047297478
Loss at iteration 870 : 0.009645473212003708
Loss at iteration 880 : 0.009715620428323746
Loss at iteration 890 : 0.014223570935428143
Loss at iteration 900 : 0.007254210766404867
Loss at iteration 910 : 0.00527597963809967
Loss at iteration 920 : 0.006097424775362015
Loss at iteration 930 : 0.014491098001599312
Loss at iteration 940 : 0.016180235892534256
Loss at iteration 950 : 0.011153176426887512
Loss at iteration 960 : 0.012125436216592789
Loss at iteration 970 : 0.019625959917902946
Loss at iteration 980 : 0.014805986545979977
Loss at iteration 990 : 0.009987321682274342
Loss at iteration 1000 : 0.014235058799386024
Loss at iteration 1010 : 0.011724894866347313
Loss at iteration 1020 : 0.00664222426712513
Loss at iteration 1030 : 0.013573474250733852
Loss at iteration 1040 : 0.016052061691880226
Loss at iteration 1050 : 0.013971446081995964
Loss at iteration 1060 : 0.014366981573402882
Loss at iteration 1070 : 0.009064385667443275
Loss at iteration 1080 : 0.005667178891599178
Loss at iteration 1090 : 0.012421537190675735
Loss at iteration 1100 : 0.007618340663611889
Loss at iteration 1110 : 0.010134713724255562
Loss at iteration 1120 : 0.017983833327889442
Loss at iteration 1130 : 0.013911556452512741
Loss at iteration 1140 : 0.007873048074543476
Loss at iteration 1150 : 0.012117475271224976
Loss at iteration 1160 : 0.006948149297386408
Loss at iteration 1170 : 0.01725350320339203
Loss at iteration 1180 : 0.010672368109226227
Loss at iteration 1190 : 0.011344194412231445
Loss at iteration 1200 : 0.007103465031832457
Loss at iteration 1210 : 0.016672538593411446
The SSIM Value is: 0.80999622742335
The PSNR Value is: 18.741289393107095
the epoch is: 110
Loss at iteration 10 : 0.00897068902850151
Loss at iteration 20 : 0.009941630065441132
Loss at iteration 30 : 0.011612611822783947
Loss at iteration 40 : 0.009718450717628002
Loss at iteration 50 : 0.00459415465593338
Loss at iteration 60 : 0.014818049967288971
Loss at iteration 70 : 0.006631765514612198
Loss at iteration 80 : 0.0075881630182266235
Loss at iteration 90 : 0.013622237369418144
Loss at iteration 100 : 0.01341771800071001
Loss at iteration 110 : 0.011686401441693306
Loss at iteration 120 : 0.016133587807416916
Loss at iteration 130 : 0.014965277165174484
Loss at iteration 140 : 0.013696931302547455
Loss at iteration 150 : 0.017183883115649223
Loss at iteration 160 : 0.018215958029031754
Loss at iteration 170 : 0.016273995861411095
Loss at iteration 180 : 0.016822315752506256
Loss at iteration 190 : 0.009752999059855938
Loss at iteration 200 : 0.012039711698889732
Loss at iteration 210 : 0.011842088773846626
Loss at iteration 220 : 0.010606866329908371
Loss at iteration 230 : 0.010268454439938068
Loss at iteration 240 : 0.017625784501433372
Loss at iteration 250 : 0.003936920315027237
Loss at iteration 260 : 0.02199290134012699
Loss at iteration 270 : 0.0064516132697463036
Loss at iteration 280 : 0.010109620168805122
Loss at iteration 290 : 0.007584376726299524
Loss at iteration 300 : 0.009651243686676025
Loss at iteration 310 : 0.004718619864434004
Loss at iteration 320 : 0.010200491175055504
Loss at iteration 330 : 0.009054568596184254
Loss at iteration 340 : 0.0075885034166276455
Loss at iteration 350 : 0.010312661528587341
Loss at iteration 360 : 0.006148627959191799
Loss at iteration 370 : 0.007553961593657732
Loss at iteration 380 : 0.011057385243475437
Loss at iteration 390 : 0.012831425294280052
Loss at iteration 400 : 0.00945761427283287
Loss at iteration 410 : 0.010242790915071964
Loss at iteration 420 : 0.004986665211617947
Loss at iteration 430 : 0.007671857252717018
Loss at iteration 440 : 0.009608778171241283
Loss at iteration 450 : 0.011622242629528046
Loss at iteration 460 : 0.010238902643322945
Loss at iteration 470 : 0.004763719625771046
Loss at iteration 480 : 0.01376439817249775
Loss at iteration 490 : 0.006203030236065388
Loss at iteration 500 : 0.011609536595642567
Loss at iteration 510 : 0.010524725541472435
Loss at iteration 520 : 0.015043778344988823
Loss at iteration 530 : 0.018054813146591187
Loss at iteration 540 : 0.007287274114787579
Loss at iteration 550 : 0.013172503560781479
Loss at iteration 560 : 0.013769809156656265
Loss at iteration 570 : 0.0071989079006016254
Loss at iteration 580 : 0.008944160304963589
Loss at iteration 590 : 0.021507155150175095
Loss at iteration 600 : 0.009385012090206146
Loss at iteration 610 : 0.01124490611255169
Loss at iteration 620 : 0.011625261977314949
Loss at iteration 630 : 0.013363124802708626
Loss at iteration 640 : 0.012744124047458172
Loss at iteration 650 : 0.016878023743629456
Loss at iteration 660 : 0.01635243371129036
Loss at iteration 670 : 0.01111999899148941
Loss at iteration 680 : 0.009996602311730385
Loss at iteration 690 : 0.01284740213304758
Loss at iteration 700 : 0.010139663703739643
Loss at iteration 710 : 0.009105064906179905
Loss at iteration 720 : 0.007588829845190048
Loss at iteration 730 : 0.011318905279040337
Loss at iteration 740 : 0.0061530740931630135
Loss at iteration 750 : 0.010220050811767578
Loss at iteration 760 : 0.00835527665913105
Loss at iteration 770 : 0.009081592783331871
Loss at iteration 780 : 0.009292766451835632
Loss at iteration 790 : 0.011227348819375038
Loss at iteration 800 : 0.005521061830222607
Loss at iteration 810 : 0.0101890554651618
Loss at iteration 820 : 0.009689085185527802
Loss at iteration 830 : 0.010593599639832973
Loss at iteration 840 : 0.00779570359736681
Loss at iteration 850 : 0.009168406948447227
Loss at iteration 860 : 0.013063136488199234
Loss at iteration 870 : 0.010373837314546108
Loss at iteration 880 : 0.006207706406712532
Loss at iteration 890 : 0.015509983524680138
Loss at iteration 900 : 0.009119418449699879
Loss at iteration 910 : 0.007454234175384045
Loss at iteration 920 : 0.009825254790484905
Loss at iteration 930 : 0.017935361713171005
Loss at iteration 940 : 0.00883755274116993
Loss at iteration 950 : 0.006834628526121378
Loss at iteration 960 : 0.008623955771327019
Loss at iteration 970 : 0.008015789091587067
Loss at iteration 980 : 0.009919602423906326
Loss at iteration 990 : 0.011593937873840332
Loss at iteration 1000 : 0.011006897315382957
Loss at iteration 1010 : 0.009486127644777298
Loss at iteration 1020 : 0.01493170764297247
Loss at iteration 1030 : 0.015263190492987633
Loss at iteration 1040 : 0.011418154463171959
Loss at iteration 1050 : 0.012868434190750122
Loss at iteration 1060 : 0.017143452540040016
Loss at iteration 1070 : 0.008328964933753014
Loss at iteration 1080 : 0.014444421045482159
Loss at iteration 1090 : 0.00960634183138609
Loss at iteration 1100 : 0.010136579163372517
Loss at iteration 1110 : 0.007982499897480011
Loss at iteration 1120 : 0.00851716659963131
Loss at iteration 1130 : 0.008228292688727379
Loss at iteration 1140 : 0.013962872326374054
Loss at iteration 1150 : 0.0060568926855921745
Loss at iteration 1160 : 0.012080507352948189
Loss at iteration 1170 : 0.01278577372431755
Loss at iteration 1180 : 0.02100830152630806
Loss at iteration 1190 : 0.012572635896503925
Loss at iteration 1200 : 0.010240798816084862
Loss at iteration 1210 : 0.009138137102127075
The SSIM Value is: 0.8008259018262227
The PSNR Value is: 18.675015513102213
the epoch is: 111
Loss at iteration 10 : 0.00931868702173233
Loss at iteration 20 : 0.009246790781617165
Loss at iteration 30 : 0.016023781150579453
Loss at iteration 40 : 0.011354837566614151
Loss at iteration 50 : 0.00825729500502348
Loss at iteration 60 : 0.007741538342088461
Loss at iteration 70 : 0.006596557796001434
Loss at iteration 80 : 0.017954101786017418
Loss at iteration 90 : 0.009199707768857479
Loss at iteration 100 : 0.007827340625226498
Loss at iteration 110 : 0.01102031022310257
Loss at iteration 120 : 0.013248199597001076
Loss at iteration 130 : 0.00793677568435669
Loss at iteration 140 : 0.008859660476446152
Loss at iteration 150 : 0.01211170107126236
Loss at iteration 160 : 0.010430206544697285
Loss at iteration 170 : 0.02146526239812374
Loss at iteration 180 : 0.016230855137109756
Loss at iteration 190 : 0.00885037612169981
Loss at iteration 200 : 0.013799636624753475
Loss at iteration 210 : 0.009755440056324005
Loss at iteration 220 : 0.007120297756046057
Loss at iteration 230 : 0.01424943283200264
Loss at iteration 240 : 0.00788001250475645
Loss at iteration 250 : 0.01025553047657013
Loss at iteration 260 : 0.012679100036621094
Loss at iteration 270 : 0.00887167826294899
Loss at iteration 280 : 0.013926131650805473
Loss at iteration 290 : 0.009808498434722424
Loss at iteration 300 : 0.009222808293998241
Loss at iteration 310 : 0.009234253317117691
Loss at iteration 320 : 0.016431637108325958
Loss at iteration 330 : 0.011080561205744743
Loss at iteration 340 : 0.01121388841420412
Loss at iteration 350 : 0.008412248454988003
Loss at iteration 360 : 0.009599961340427399
Loss at iteration 370 : 0.009112310595810413
Loss at iteration 380 : 0.0066827465780079365
Loss at iteration 390 : 0.011066359467804432
Loss at iteration 400 : 0.018596455454826355
Loss at iteration 410 : 0.010240575298666954
Loss at iteration 420 : 0.01479403767734766
Loss at iteration 430 : 0.0076537830755114555
Loss at iteration 440 : 0.00633006077259779
Loss at iteration 450 : 0.010064486414194107
Loss at iteration 460 : 0.012287605553865433
Loss at iteration 470 : 0.00893325824290514
Loss at iteration 480 : 0.011365981772542
Loss at iteration 490 : 0.010350081138312817
Loss at iteration 500 : 0.012832973152399063
Loss at iteration 510 : 0.011258432641625404
Loss at iteration 520 : 0.014470020309090614
Loss at iteration 530 : 0.009411191567778587
Loss at iteration 540 : 0.006622148212045431
Loss at iteration 550 : 0.00924048013985157
Loss at iteration 560 : 0.013911438174545765
Loss at iteration 570 : 0.014720852486789227
Loss at iteration 580 : 0.01303558237850666
Loss at iteration 590 : 0.015939513221383095
Loss at iteration 600 : 0.013499675318598747
Loss at iteration 610 : 0.008877373300492764
Loss at iteration 620 : 0.010392795316874981
Loss at iteration 630 : 0.014426793903112411
Loss at iteration 640 : 0.020716432482004166
Loss at iteration 650 : 0.018060188740491867
Loss at iteration 660 : 0.008526534773409367
Loss at iteration 670 : 0.020444002002477646
Loss at iteration 680 : 0.009194111451506615
Loss at iteration 690 : 0.01000039279460907
Loss at iteration 700 : 0.013238709419965744
Loss at iteration 710 : 0.00679725781083107
Loss at iteration 720 : 0.009903542697429657
Loss at iteration 730 : 0.010084526613354683
Loss at iteration 740 : 0.014148427173495293
Loss at iteration 750 : 0.01161065511405468
Loss at iteration 760 : 0.01537060271948576
Loss at iteration 770 : 0.012833802960813046
Loss at iteration 780 : 0.00803911592811346
Loss at iteration 790 : 0.011603299528360367
Loss at iteration 800 : 0.009365370497107506
Loss at iteration 810 : 0.008823724463582039
Loss at iteration 820 : 0.008632219396531582
Loss at iteration 830 : 0.004086778033524752
Loss at iteration 840 : 0.009530957788228989
Loss at iteration 850 : 0.010895178653299809
Loss at iteration 860 : 0.007656021974980831
Loss at iteration 870 : 0.006428389810025692
Loss at iteration 880 : 0.0076349531300365925
Loss at iteration 890 : 0.02388390712440014
Loss at iteration 900 : 0.01675686240196228
Loss at iteration 910 : 0.012583788484334946
Loss at iteration 920 : 0.01134577952325344
Loss at iteration 930 : 0.007051914930343628
Loss at iteration 940 : 0.016468385234475136
Loss at iteration 950 : 0.010223565623164177
Loss at iteration 960 : 0.01572648249566555
Loss at iteration 970 : 0.014872726052999496
Loss at iteration 980 : 0.007720838766545057
Loss at iteration 990 : 0.013182830065488815
Loss at iteration 1000 : 0.013381130993366241
Loss at iteration 1010 : 0.012133060954511166
Loss at iteration 1020 : 0.010759275406599045
Loss at iteration 1030 : 0.013912071473896503
Loss at iteration 1040 : 0.015799015760421753
Loss at iteration 1050 : 0.010136125609278679
Loss at iteration 1060 : 0.010608522221446037
Loss at iteration 1070 : 0.008593086153268814
Loss at iteration 1080 : 0.007552015595138073
Loss at iteration 1090 : 0.009827186353504658
Loss at iteration 1100 : 0.010465512052178383
Loss at iteration 1110 : 0.008743450976908207
Loss at iteration 1120 : 0.012579110451042652
Loss at iteration 1130 : 0.014643365517258644
Loss at iteration 1140 : 0.009660519659519196
Loss at iteration 1150 : 0.00973580777645111
Loss at iteration 1160 : 0.008540492504835129
Loss at iteration 1170 : 0.007386934477835894
Loss at iteration 1180 : 0.02603849023580551
Loss at iteration 1190 : 0.007284724153578281
Loss at iteration 1200 : 0.0074648563750088215
Loss at iteration 1210 : 0.00606913585215807
The SSIM Value is: 0.8100572387377422
The PSNR Value is: 18.459326171875
the epoch is: 112
Loss at iteration 10 : 0.0092664435505867
Loss at iteration 20 : 0.0160105861723423
Loss at iteration 30 : 0.007130605634301901
Loss at iteration 40 : 0.01189163513481617
Loss at iteration 50 : 0.009791801683604717
Loss at iteration 60 : 0.019570617005228996
Loss at iteration 70 : 0.0116931963711977
Loss at iteration 80 : 0.007656470872461796
Loss at iteration 90 : 0.021295227110385895
Loss at iteration 100 : 0.007997632957994938
Loss at iteration 110 : 0.007455237675458193
Loss at iteration 120 : 0.02725234255194664
Loss at iteration 130 : 0.014135890640318394
Loss at iteration 140 : 0.006918854080140591
Loss at iteration 150 : 0.01402416080236435
Loss at iteration 160 : 0.013292514719069004
Loss at iteration 170 : 0.010355867445468903
Loss at iteration 180 : 0.014170798473060131
Loss at iteration 190 : 0.010908745229244232
Loss at iteration 200 : 0.02398061938583851
Loss at iteration 210 : 0.009733364917337894
Loss at iteration 220 : 0.0077343774028122425
Loss at iteration 230 : 0.011213883757591248
Loss at iteration 240 : 0.012483243830502033
Loss at iteration 250 : 0.01239476166665554
Loss at iteration 260 : 0.0103401904925704
Loss at iteration 270 : 0.007081712130457163
Loss at iteration 280 : 0.010457979515194893
Loss at iteration 290 : 0.00593710970133543
Loss at iteration 300 : 0.0105434013530612
Loss at iteration 310 : 0.005147827323526144
Loss at iteration 320 : 0.011849922128021717
Loss at iteration 330 : 0.019714394584298134
Loss at iteration 340 : 0.009201805107295513
Loss at iteration 350 : 0.01484471932053566
Loss at iteration 360 : 0.009927855804562569
Loss at iteration 370 : 0.013406587764620781
Loss at iteration 380 : 0.0084124356508255
Loss at iteration 390 : 0.010744213126599789
Loss at iteration 400 : 0.0059421793557703495
Loss at iteration 410 : 0.012920115143060684
Loss at iteration 420 : 0.008697383105754852
Loss at iteration 430 : 0.011744283139705658
Loss at iteration 440 : 0.005407809279859066
Loss at iteration 450 : 0.008287766017019749
Loss at iteration 460 : 0.012809524312615395
Loss at iteration 470 : 0.017333149909973145
Loss at iteration 480 : 0.011995959095656872
Loss at iteration 490 : 0.0066960700787603855
Loss at iteration 500 : 0.01386965811252594
Loss at iteration 510 : 0.014078734442591667
Loss at iteration 520 : 0.008005887269973755
Loss at iteration 530 : 0.010596075095236301
Loss at iteration 540 : 0.021738892421126366
Loss at iteration 550 : 0.007956246845424175
Loss at iteration 560 : 0.0076549481600522995
Loss at iteration 570 : 0.009854634292423725
Loss at iteration 580 : 0.007874363102018833
Loss at iteration 590 : 0.0052685821428895
Loss at iteration 600 : 0.014217261224985123
Loss at iteration 610 : 0.011490863747894764
Loss at iteration 620 : 0.010081719607114792
Loss at iteration 630 : 0.008241202682256699
Loss at iteration 640 : 0.01158065628260374
Loss at iteration 650 : 0.010562841780483723
Loss at iteration 660 : 0.011566509492695332
Loss at iteration 670 : 0.009486071765422821
Loss at iteration 680 : 0.00894990935921669
Loss at iteration 690 : 0.007323215249925852
Loss at iteration 700 : 0.010528037324547768
Loss at iteration 710 : 0.011000989004969597
Loss at iteration 720 : 0.0072865537367761135
Loss at iteration 730 : 0.005366583354771137
Loss at iteration 740 : 0.01717064157128334
Loss at iteration 750 : 0.010126614011824131
Loss at iteration 760 : 0.0074396454729139805
Loss at iteration 770 : 0.011494126170873642
Loss at iteration 780 : 0.014123138040304184
Loss at iteration 790 : 0.009408827871084213
Loss at iteration 800 : 0.00692620687186718
Loss at iteration 810 : 0.007375076413154602
Loss at iteration 820 : 0.007682262919843197
Loss at iteration 830 : 0.02279091067612171
Loss at iteration 840 : 0.00866316631436348
Loss at iteration 850 : 0.01401514932513237
Loss at iteration 860 : 0.012522310018539429
Loss at iteration 870 : 0.010999349877238274
Loss at iteration 880 : 0.00913090817630291
Loss at iteration 890 : 0.005545761436223984
Loss at iteration 900 : 0.011752069927752018
Loss at iteration 910 : 0.014368295669555664
Loss at iteration 920 : 0.01000780425965786
Loss at iteration 930 : 0.011663817800581455
Loss at iteration 940 : 0.006418248638510704
Loss at iteration 950 : 0.00756952166557312
Loss at iteration 960 : 0.009712504222989082
Loss at iteration 970 : 0.0190572626888752
Loss at iteration 980 : 0.013510545715689659
Loss at iteration 990 : 0.0112047353759408
Loss at iteration 1000 : 0.02367662452161312
Loss at iteration 1010 : 0.018751299008727074
Loss at iteration 1020 : 0.009093167260289192
Loss at iteration 1030 : 0.024711458012461662
Loss at iteration 1040 : 0.018579430878162384
Loss at iteration 1050 : 0.007001252379268408
Loss at iteration 1060 : 0.011038636788725853
Loss at iteration 1070 : 0.019352279603481293
Loss at iteration 1080 : 0.009035487659275532
Loss at iteration 1090 : 0.02002236247062683
Loss at iteration 1100 : 0.010003898292779922
Loss at iteration 1110 : 0.0068263886496424675
Loss at iteration 1120 : 0.014405363239347935
Loss at iteration 1130 : 0.02343706414103508
Loss at iteration 1140 : 0.009662125259637833
Loss at iteration 1150 : 0.008536607958376408
Loss at iteration 1160 : 0.010419405065476894
Loss at iteration 1170 : 0.012557624839246273
Loss at iteration 1180 : 0.011846067383885384
Loss at iteration 1190 : 0.012787009589374065
Loss at iteration 1200 : 0.006933251395821571
Loss at iteration 1210 : 0.011617304757237434
The SSIM Value is: 0.8139515161514282
The PSNR Value is: 18.854692649841308
the epoch is: 113
Loss at iteration 10 : 0.012064648792147636
Loss at iteration 20 : 0.009326990693807602
Loss at iteration 30 : 0.009388064034283161
Loss at iteration 40 : 0.01358763687312603
Loss at iteration 50 : 0.00792298186570406
Loss at iteration 60 : 0.016313966363668442
Loss at iteration 70 : 0.007524500600993633
Loss at iteration 80 : 0.008126826956868172
Loss at iteration 90 : 0.021499432623386383
Loss at iteration 100 : 0.009148307144641876
Loss at iteration 110 : 0.009291432797908783
Loss at iteration 120 : 0.013594729825854301
Loss at iteration 130 : 0.021865539252758026
Loss at iteration 140 : 0.013501787558197975
Loss at iteration 150 : 0.009767771698534489
Loss at iteration 160 : 0.012193484231829643
Loss at iteration 170 : 0.0157887302339077
Loss at iteration 180 : 0.01045939326286316
Loss at iteration 190 : 0.006714946590363979
Loss at iteration 200 : 0.007255936972796917
Loss at iteration 210 : 0.015132484957575798
Loss at iteration 220 : 0.009001740254461765
Loss at iteration 230 : 0.01138730812817812
Loss at iteration 240 : 0.011428630910813808
Loss at iteration 250 : 0.013443175703287125
Loss at iteration 260 : 0.013218231499195099
Loss at iteration 270 : 0.01000725757330656
Loss at iteration 280 : 0.010708698071539402
Loss at iteration 290 : 0.012717653065919876
Loss at iteration 300 : 0.007002179976552725
Loss at iteration 310 : 0.009204029105603695
Loss at iteration 320 : 0.010706469416618347
Loss at iteration 330 : 0.008260026574134827
Loss at iteration 340 : 0.010666830465197563
Loss at iteration 350 : 0.016294464468955994
Loss at iteration 360 : 0.014553287997841835
Loss at iteration 370 : 0.010729258880019188
Loss at iteration 380 : 0.016369618475437164
Loss at iteration 390 : 0.010328320786356926
Loss at iteration 400 : 0.014170205220580101
Loss at iteration 410 : 0.010721666738390923
Loss at iteration 420 : 0.0116856899112463
Loss at iteration 430 : 0.008703595027327538
Loss at iteration 440 : 0.01614801213145256
Loss at iteration 450 : 0.02126275934278965
Loss at iteration 460 : 0.008306004106998444
Loss at iteration 470 : 0.006142933387309313
Loss at iteration 480 : 0.009816505946218967
Loss at iteration 490 : 0.009866343811154366
Loss at iteration 500 : 0.018076173961162567
Loss at iteration 510 : 0.0187222883105278
Loss at iteration 520 : 0.008898008614778519
Loss at iteration 530 : 0.010972240939736366
Loss at iteration 540 : 0.010754642076790333
Loss at iteration 550 : 0.01363477110862732
Loss at iteration 560 : 0.012137249112129211
Loss at iteration 570 : 0.012500977143645287
Loss at iteration 580 : 0.01281764917075634
Loss at iteration 590 : 0.008733856491744518
Loss at iteration 600 : 0.021872591227293015
Loss at iteration 610 : 0.01727621629834175
Loss at iteration 620 : 0.010496356524527073
Loss at iteration 630 : 0.012616708874702454
Loss at iteration 640 : 0.008475497364997864
Loss at iteration 650 : 0.011663268320262432
Loss at iteration 660 : 0.011373985558748245
Loss at iteration 670 : 0.00681939534842968
Loss at iteration 680 : 0.009441481903195381
Loss at iteration 690 : 0.009107578545808792
Loss at iteration 700 : 0.005198409780859947
Loss at iteration 710 : 0.027863306924700737
Loss at iteration 720 : 0.008653678931295872
Loss at iteration 730 : 0.008012386970221996
Loss at iteration 740 : 0.010082118213176727
Loss at iteration 750 : 0.009431898593902588
Loss at iteration 760 : 0.009624012745916843
Loss at iteration 770 : 0.01383291743695736
Loss at iteration 780 : 0.008364157751202583
Loss at iteration 790 : 0.012041325680911541
Loss at iteration 800 : 0.006210649851709604
Loss at iteration 810 : 0.011323180980980396
Loss at iteration 820 : 0.010978490114212036
Loss at iteration 830 : 0.008665933273732662
Loss at iteration 840 : 0.012967764399945736
Loss at iteration 850 : 0.012393025681376457
Loss at iteration 860 : 0.010852059349417686
Loss at iteration 870 : 0.012529280036687851
Loss at iteration 880 : 0.011393883265554905
Loss at iteration 890 : 0.011892982758581638
Loss at iteration 900 : 0.008357941173017025
Loss at iteration 910 : 0.023998886346817017
Loss at iteration 920 : 0.012391475960612297
Loss at iteration 930 : 0.022417878732085228
Loss at iteration 940 : 0.009334170259535313
Loss at iteration 950 : 0.009070097468793392
Loss at iteration 960 : 0.010548807680606842
Loss at iteration 970 : 0.011338951997458935
Loss at iteration 980 : 0.011835988610982895
Loss at iteration 990 : 0.00734634418040514
Loss at iteration 1000 : 0.009138094261288643
Loss at iteration 1010 : 0.010940765962004662
Loss at iteration 1020 : 0.014929024502635002
Loss at iteration 1030 : 0.005859462544322014
Loss at iteration 1040 : 0.012606161646544933
Loss at iteration 1050 : 0.011393965221941471
Loss at iteration 1060 : 0.01488851010799408
Loss at iteration 1070 : 0.00853285938501358
Loss at iteration 1080 : 0.010506837628781796
Loss at iteration 1090 : 0.00577077129855752
Loss at iteration 1100 : 0.017873302102088928
Loss at iteration 1110 : 0.012830290012061596
Loss at iteration 1120 : 0.01317651942372322
Loss at iteration 1130 : 0.01032857783138752
Loss at iteration 1140 : 0.008761843666434288
Loss at iteration 1150 : 0.006981590762734413
Loss at iteration 1160 : 0.0073585668578743935
Loss at iteration 1170 : 0.018507419154047966
Loss at iteration 1180 : 0.009775258600711823
Loss at iteration 1190 : 0.006048273295164108
Loss at iteration 1200 : 0.014746557921171188
Loss at iteration 1210 : 0.014258874580264091
The SSIM Value is: 0.7998538692792256
The PSNR Value is: 18.25047664642334
the epoch is: 114
Loss at iteration 10 : 0.011254900135099888
Loss at iteration 20 : 0.009313295595347881
Loss at iteration 30 : 0.01477961428463459
Loss at iteration 40 : 0.016800077632069588
Loss at iteration 50 : 0.01463672798126936
Loss at iteration 60 : 0.00936428178101778
Loss at iteration 70 : 0.010402236133813858
Loss at iteration 80 : 0.009923620149493217
Loss at iteration 90 : 0.007182631175965071
Loss at iteration 100 : 0.013266999274492264
Loss at iteration 110 : 0.00901330728083849
Loss at iteration 120 : 0.006850919686257839
Loss at iteration 130 : 0.009866246022284031
Loss at iteration 140 : 0.010501413606107235
Loss at iteration 150 : 0.010676520876586437
Loss at iteration 160 : 0.0145603371784091
Loss at iteration 170 : 0.010990215465426445
Loss at iteration 180 : 0.00803324207663536
Loss at iteration 190 : 0.007166195195168257
Loss at iteration 200 : 0.015259308740496635
Loss at iteration 210 : 0.016261577606201172
Loss at iteration 220 : 0.010852609761059284
Loss at iteration 230 : 0.009389160200953484
Loss at iteration 240 : 0.006338467821478844
Loss at iteration 250 : 0.013183292001485825
Loss at iteration 260 : 0.010578041896224022
Loss at iteration 270 : 0.013348784297704697
Loss at iteration 280 : 0.009748497046530247
Loss at iteration 290 : 0.005587629042565823
Loss at iteration 300 : 0.007809068076312542
Loss at iteration 310 : 0.011417514644563198
Loss at iteration 320 : 0.011663047596812248
Loss at iteration 330 : 0.018451455980539322
Loss at iteration 340 : 0.007932995446026325
Loss at iteration 350 : 0.005288357846438885
Loss at iteration 360 : 0.011027605272829533
Loss at iteration 370 : 0.007562744431197643
Loss at iteration 380 : 0.012403860688209534
Loss at iteration 390 : 0.011212090961635113
Loss at iteration 400 : 0.01227699127048254
Loss at iteration 410 : 0.011307800188660622
Loss at iteration 420 : 0.011005365289747715
Loss at iteration 430 : 0.011548186652362347
Loss at iteration 440 : 0.01201969850808382
Loss at iteration 450 : 0.01336138416081667
Loss at iteration 460 : 0.010039974935352802
Loss at iteration 470 : 0.02097504213452339
Loss at iteration 480 : 0.008247947320342064
Loss at iteration 490 : 0.009960178285837173
Loss at iteration 500 : 0.008879194036126137
Loss at iteration 510 : 0.02011170983314514
Loss at iteration 520 : 0.010677577927708626
Loss at iteration 530 : 0.010180586948990822
Loss at iteration 540 : 0.006885644048452377
Loss at iteration 550 : 0.012149878777563572
Loss at iteration 560 : 0.006748793181031942
Loss at iteration 570 : 0.013533489778637886
Loss at iteration 580 : 0.00904223695397377
Loss at iteration 590 : 0.010051715187728405
Loss at iteration 600 : 0.00838804803788662
Loss at iteration 610 : 0.0070111192762851715
Loss at iteration 620 : 0.014093262143433094
Loss at iteration 630 : 0.011389343068003654
Loss at iteration 640 : 0.009456290863454342
Loss at iteration 650 : 0.010220330208539963
Loss at iteration 660 : 0.010380145162343979
Loss at iteration 670 : 0.004627215676009655
Loss at iteration 680 : 0.005654198117554188
Loss at iteration 690 : 0.009546231478452682
Loss at iteration 700 : 0.009724093601107597
Loss at iteration 710 : 0.008534304797649384
Loss at iteration 720 : 0.007143466267734766
Loss at iteration 730 : 0.005077412351965904
Loss at iteration 740 : 0.021397188305854797
Loss at iteration 750 : 0.014814269728958607
Loss at iteration 760 : 0.01298380084335804
Loss at iteration 770 : 0.01003076322376728
Loss at iteration 780 : 0.005723115988075733
Loss at iteration 790 : 0.017007147893309593
Loss at iteration 800 : 0.013664422556757927
Loss at iteration 810 : 0.005813452415168285
Loss at iteration 820 : 0.011945700272917747
Loss at iteration 830 : 0.012057909741997719
Loss at iteration 840 : 0.011605676263570786
Loss at iteration 850 : 0.012970926240086555
Loss at iteration 860 : 0.014811031520366669
Loss at iteration 870 : 0.016849951818585396
Loss at iteration 880 : 0.014154201373457909
Loss at iteration 890 : 0.014320778660476208
Loss at iteration 900 : 0.01943640410900116
Loss at iteration 910 : 0.011834605596959591
Loss at iteration 920 : 0.014638016000390053
Loss at iteration 930 : 0.014008309692144394
Loss at iteration 940 : 0.00808112695813179
Loss at iteration 950 : 0.015118228271603584
Loss at iteration 960 : 0.009242553263902664
Loss at iteration 970 : 0.00860202219337225
Loss at iteration 980 : 0.007305070757865906
Loss at iteration 990 : 0.022408759221434593
Loss at iteration 1000 : 0.010548269376158714
Loss at iteration 1010 : 0.008931359276175499
Loss at iteration 1020 : 0.006550319958478212
Loss at iteration 1030 : 0.012504490092396736
Loss at iteration 1040 : 0.012708548456430435
Loss at iteration 1050 : 0.010721567086875439
Loss at iteration 1060 : 0.010179193690419197
Loss at iteration 1070 : 0.011694285087287426
Loss at iteration 1080 : 0.012884359806776047
Loss at iteration 1090 : 0.01326442789286375
Loss at iteration 1100 : 0.00432016234844923
Loss at iteration 1110 : 0.011380350217223167
Loss at iteration 1120 : 0.005879250355064869
Loss at iteration 1130 : 0.00533348647877574
Loss at iteration 1140 : 0.009338367730379105
Loss at iteration 1150 : 0.0053084660321474075
Loss at iteration 1160 : 0.0153330247849226
Loss at iteration 1170 : 0.010095886886119843
Loss at iteration 1180 : 0.011327052488923073
Loss at iteration 1190 : 0.005366160534322262
Loss at iteration 1200 : 0.006974393501877785
Loss at iteration 1210 : 0.012993589974939823
The SSIM Value is: 0.8045189340909322
The PSNR Value is: 18.31129722595215
the epoch is: 115
Loss at iteration 10 : 0.010847935453057289
Loss at iteration 20 : 0.008952772244811058
Loss at iteration 30 : 0.009440741501748562
Loss at iteration 40 : 0.014400480315089226
Loss at iteration 50 : 0.017012588679790497
Loss at iteration 60 : 0.009164875373244286
Loss at iteration 70 : 0.013048849999904633
Loss at iteration 80 : 0.013444455340504646
Loss at iteration 90 : 0.007302050478756428
Loss at iteration 100 : 0.00947335921227932
Loss at iteration 110 : 0.012096346355974674
Loss at iteration 120 : 0.010725078172981739
Loss at iteration 130 : 0.014627808704972267
Loss at iteration 140 : 0.011149794794619083
Loss at iteration 150 : 0.01569051668047905
Loss at iteration 160 : 0.01465078815817833
Loss at iteration 170 : 0.011766348965466022
Loss at iteration 180 : 0.021229643374681473
Loss at iteration 190 : 0.011836063116788864
Loss at iteration 200 : 0.011859862133860588
Loss at iteration 210 : 0.011214214377105236
Loss at iteration 220 : 0.012319831177592278
Loss at iteration 230 : 0.010805856436491013
Loss at iteration 240 : 0.01172146201133728
Loss at iteration 250 : 0.013444682583212852
Loss at iteration 260 : 0.00827891007065773
Loss at iteration 270 : 0.015956856310367584
Loss at iteration 280 : 0.009532718919217587
Loss at iteration 290 : 0.01913057640194893
Loss at iteration 300 : 0.016438016667962074
Loss at iteration 310 : 0.007663795258849859
Loss at iteration 320 : 0.009798582643270493
Loss at iteration 330 : 0.005764744710177183
Loss at iteration 340 : 0.010144835337996483
Loss at iteration 350 : 0.009043530561029911
Loss at iteration 360 : 0.005074099637567997
Loss at iteration 370 : 0.015318520367145538
Loss at iteration 380 : 0.010817368514835835
Loss at iteration 390 : 0.009120706468820572
Loss at iteration 400 : 0.007872398942708969
Loss at iteration 410 : 0.011526523157954216
Loss at iteration 420 : 0.0076243882067501545
Loss at iteration 430 : 0.014398915693163872
Loss at iteration 440 : 0.013562778942286968
Loss at iteration 450 : 0.006800207309424877
Loss at iteration 460 : 0.008713306859135628
Loss at iteration 470 : 0.011485124006867409
Loss at iteration 480 : 0.008614413440227509
Loss at iteration 490 : 0.010920867323875427
Loss at iteration 500 : 0.010731000453233719
Loss at iteration 510 : 0.010019071400165558
Loss at iteration 520 : 0.009628325700759888
Loss at iteration 530 : 0.018290575593709946
Loss at iteration 540 : 0.009166895411908627
Loss at iteration 550 : 0.010106949135661125
Loss at iteration 560 : 0.009953112341463566
Loss at iteration 570 : 0.007898762822151184
Loss at iteration 580 : 0.009545445442199707
Loss at iteration 590 : 0.01640717126429081
Loss at iteration 600 : 0.008960603736341
Loss at iteration 610 : 0.008818830363452435
Loss at iteration 620 : 0.010186567902565002
Loss at iteration 630 : 0.00985727645456791
Loss at iteration 640 : 0.015016577206552029
Loss at iteration 650 : 0.01199333369731903
Loss at iteration 660 : 0.008488421328365803
Loss at iteration 670 : 0.011850959621369839
Loss at iteration 680 : 0.010111570358276367
Loss at iteration 690 : 0.007149892393499613
Loss at iteration 700 : 0.006622950546443462
Loss at iteration 710 : 0.009955285117030144
Loss at iteration 720 : 0.0058752913028001785
Loss at iteration 730 : 0.010291116312146187
Loss at iteration 740 : 0.010909146629273891
Loss at iteration 750 : 0.01020408608019352
Loss at iteration 760 : 0.016537662595510483
Loss at iteration 770 : 0.018306251615285873
Loss at iteration 780 : 0.013481184840202332
Loss at iteration 790 : 0.009168519638478756
Loss at iteration 800 : 0.012047305703163147
Loss at iteration 810 : 0.009920707903802395
Loss at iteration 820 : 0.010216545313596725
Loss at iteration 830 : 0.009980292059481144
Loss at iteration 840 : 0.014906360767781734
Loss at iteration 850 : 0.012580014765262604
Loss at iteration 860 : 0.016140075400471687
Loss at iteration 870 : 0.011240212246775627
Loss at iteration 880 : 0.016293447464704514
Loss at iteration 890 : 0.006782914977520704
Loss at iteration 900 : 0.006099395919591188
Loss at iteration 910 : 0.011214922182261944
Loss at iteration 920 : 0.009073993191123009
Loss at iteration 930 : 0.011270135641098022
Loss at iteration 940 : 0.00844356045126915
Loss at iteration 950 : 0.00908996257930994
Loss at iteration 960 : 0.011199197731912136
Loss at iteration 970 : 0.007089301943778992
Loss at iteration 980 : 0.00979603175073862
Loss at iteration 990 : 0.006948880851268768
Loss at iteration 1000 : 0.014562452211976051
Loss at iteration 1010 : 0.005483577959239483
Loss at iteration 1020 : 0.009762553498148918
Loss at iteration 1030 : 0.008432507514953613
Loss at iteration 1040 : 0.010571666061878204
Loss at iteration 1050 : 0.01498400792479515
Loss at iteration 1060 : 0.007450178265571594
Loss at iteration 1070 : 0.009349032305181026
Loss at iteration 1080 : 0.013024451211094856
Loss at iteration 1090 : 0.008736012503504753
Loss at iteration 1100 : 0.007140848319977522
Loss at iteration 1110 : 0.01603495143353939
Loss at iteration 1120 : 0.006585295312106609
Loss at iteration 1130 : 0.007100074551999569
Loss at iteration 1140 : 0.011467749252915382
Loss at iteration 1150 : 0.009780331514775753
Loss at iteration 1160 : 0.005728118121623993
Loss at iteration 1170 : 0.01202583871781826
Loss at iteration 1180 : 0.012305490672588348
Loss at iteration 1190 : 0.01071719080209732
Loss at iteration 1200 : 0.011127621866762638
Loss at iteration 1210 : 0.009642347693443298
The SSIM Value is: 0.8049155195554097
The PSNR Value is: 18.842772483825684
the epoch is: 116
Loss at iteration 10 : 0.01226421631872654
Loss at iteration 20 : 0.008972746320068836
Loss at iteration 30 : 0.014067314565181732
Loss at iteration 40 : 0.008936136029660702
Loss at iteration 50 : 0.018070422112941742
Loss at iteration 60 : 0.00788208656013012
Loss at iteration 70 : 0.010637609288096428
Loss at iteration 80 : 0.0075682662427425385
Loss at iteration 90 : 0.012998091988265514
Loss at iteration 100 : 0.011948451399803162
Loss at iteration 110 : 0.009760103188455105
Loss at iteration 120 : 0.012602275237441063
Loss at iteration 130 : 0.011637669056653976
Loss at iteration 140 : 0.013130199164152145
Loss at iteration 150 : 0.008916202001273632
Loss at iteration 160 : 0.008578470908105373
Loss at iteration 170 : 0.015653731301426888
Loss at iteration 180 : 0.014900058507919312
Loss at iteration 190 : 0.006581417750567198
Loss at iteration 200 : 0.019883647561073303
Loss at iteration 210 : 0.016141025349497795
Loss at iteration 220 : 0.020429188385605812
Loss at iteration 230 : 0.00650410819798708
Loss at iteration 240 : 0.008628426119685173
Loss at iteration 250 : 0.012494651600718498
Loss at iteration 260 : 0.00734026450663805
Loss at iteration 270 : 0.008777780458331108
Loss at iteration 280 : 0.005830125883221626
Loss at iteration 290 : 0.011850601062178612
Loss at iteration 300 : 0.008767073042690754
Loss at iteration 310 : 0.008296797052025795
Loss at iteration 320 : 0.011910422705113888
Loss at iteration 330 : 0.012830307707190514
Loss at iteration 340 : 0.009002991020679474
Loss at iteration 350 : 0.008534790948033333
Loss at iteration 360 : 0.007745964452624321
Loss at iteration 370 : 0.014104395173490047
Loss at iteration 380 : 0.008695656433701515
Loss at iteration 390 : 0.015935545787215233
Loss at iteration 400 : 0.00989263504743576
Loss at iteration 410 : 0.007997263222932816
Loss at iteration 420 : 0.013910528272390366
Loss at iteration 430 : 0.01033814623951912
Loss at iteration 440 : 0.01610594429075718
Loss at iteration 450 : 0.008604041300714016
Loss at iteration 460 : 0.007323895581066608
Loss at iteration 470 : 0.009612500667572021
Loss at iteration 480 : 0.007993538863956928
Loss at iteration 490 : 0.008592146448791027
Loss at iteration 500 : 0.009901510551571846
Loss at iteration 510 : 0.010974988341331482
Loss at iteration 520 : 0.010826366022229195
Loss at iteration 530 : 0.00956769846379757
Loss at iteration 540 : 0.011641440913081169
Loss at iteration 550 : 0.01395113579928875
Loss at iteration 560 : 0.01408067811280489
Loss at iteration 570 : 0.013886526226997375
Loss at iteration 580 : 0.00651861447840929
Loss at iteration 590 : 0.008637065067887306
Loss at iteration 600 : 0.022005993872880936
Loss at iteration 610 : 0.007588476873934269
Loss at iteration 620 : 0.011056695133447647
Loss at iteration 630 : 0.012811025604605675
Loss at iteration 640 : 0.007196965627372265
Loss at iteration 650 : 0.017705325037240982
Loss at iteration 660 : 0.007778865750879049
Loss at iteration 670 : 0.010731706395745277
Loss at iteration 680 : 0.01181649137288332
Loss at iteration 690 : 0.009181063622236252
Loss at iteration 700 : 0.018285498023033142
Loss at iteration 710 : 0.004627812188118696
Loss at iteration 720 : 0.01701710931956768
Loss at iteration 730 : 0.0096298698335886
Loss at iteration 740 : 0.00867724884301424
Loss at iteration 750 : 0.012437144294381142
Loss at iteration 760 : 0.010562330484390259
Loss at iteration 770 : 0.02033407613635063
Loss at iteration 780 : 0.011819129809737206
Loss at iteration 790 : 0.009295003488659859
Loss at iteration 800 : 0.009353309869766235
Loss at iteration 810 : 0.011581183411180973
Loss at iteration 820 : 0.00831559207290411
Loss at iteration 830 : 0.012141117826104164
Loss at iteration 840 : 0.008955362252891064
Loss at iteration 850 : 0.018074817955493927
Loss at iteration 860 : 0.009090006351470947
Loss at iteration 870 : 0.011740393005311489
Loss at iteration 880 : 0.007350075524300337
Loss at iteration 890 : 0.014045054093003273
Loss at iteration 900 : 0.013595933094620705
Loss at iteration 910 : 0.010640702210366726
Loss at iteration 920 : 0.007994540967047215
Loss at iteration 930 : 0.011455539613962173
Loss at iteration 940 : 0.014101924374699593
Loss at iteration 950 : 0.006286867894232273
Loss at iteration 960 : 0.013707318343222141
Loss at iteration 970 : 0.017466405406594276
Loss at iteration 980 : 0.010146789252758026
Loss at iteration 990 : 0.010452027432620525
Loss at iteration 1000 : 0.015953049063682556
Loss at iteration 1010 : 0.012596730142831802
Loss at iteration 1020 : 0.014902348630130291
Loss at iteration 1030 : 0.011678195558488369
Loss at iteration 1040 : 0.004280960187315941
Loss at iteration 1050 : 0.01542392186820507
Loss at iteration 1060 : 0.010725310072302818
Loss at iteration 1070 : 0.00850573368370533
Loss at iteration 1080 : 0.006869080476462841
Loss at iteration 1090 : 0.009758510626852512
Loss at iteration 1100 : 0.009164378046989441
Loss at iteration 1110 : 0.009405742399394512
Loss at iteration 1120 : 0.0110255042091012
Loss at iteration 1130 : 0.00845186598598957
Loss at iteration 1140 : 0.01810218021273613
Loss at iteration 1150 : 0.01429564319550991
Loss at iteration 1160 : 0.010525950230658054
Loss at iteration 1170 : 0.009062536060810089
Loss at iteration 1180 : 0.013515438884496689
Loss at iteration 1190 : 0.015807142481207848
Loss at iteration 1200 : 0.013403007760643959
Loss at iteration 1210 : 0.012426252476871014
The SSIM Value is: 0.8060801386833191
The PSNR Value is: 18.88171272277832
the epoch is: 117
Loss at iteration 10 : 0.011747937649488449
Loss at iteration 20 : 0.011436371132731438
Loss at iteration 30 : 0.008622178807854652
Loss at iteration 40 : 0.012067094445228577
Loss at iteration 50 : 0.019759656861424446
Loss at iteration 60 : 0.01099446602165699
Loss at iteration 70 : 0.017718929797410965
Loss at iteration 80 : 0.006272038444876671
Loss at iteration 90 : 0.009923516772687435
Loss at iteration 100 : 0.010558896698057652
Loss at iteration 110 : 0.006116749253123999
Loss at iteration 120 : 0.017704077064990997
Loss at iteration 130 : 0.0071806772612035275
Loss at iteration 140 : 0.009792781434953213
Loss at iteration 150 : 0.011155616492033005
Loss at iteration 160 : 0.00919543020427227
Loss at iteration 170 : 0.014635937288403511
Loss at iteration 180 : 0.016943801194429398
Loss at iteration 190 : 0.007135096937417984
Loss at iteration 200 : 0.017565743997693062
Loss at iteration 210 : 0.013972083106637001
Loss at iteration 220 : 0.009906850755214691
Loss at iteration 230 : 0.01042220275849104
Loss at iteration 240 : 0.016504134982824326
Loss at iteration 250 : 0.006861174013465643
Loss at iteration 260 : 0.009730696678161621
Loss at iteration 270 : 0.01126031018793583
Loss at iteration 280 : 0.01310611329972744
Loss at iteration 290 : 0.007355751935392618
Loss at iteration 300 : 0.007651112042367458
Loss at iteration 310 : 0.005959075875580311
Loss at iteration 320 : 0.011839969083666801
Loss at iteration 330 : 0.00801252294331789
Loss at iteration 340 : 0.016179867088794708
Loss at iteration 350 : 0.015109905041754246
Loss at iteration 360 : 0.012130336835980415
Loss at iteration 370 : 0.007916640490293503
Loss at iteration 380 : 0.012291867285966873
Loss at iteration 390 : 0.008164633996784687
Loss at iteration 400 : 0.007149191107600927
Loss at iteration 410 : 0.00951211154460907
Loss at iteration 420 : 0.009527727961540222
Loss at iteration 430 : 0.008421046659350395
Loss at iteration 440 : 0.011237784288823605
Loss at iteration 450 : 0.010916970670223236
Loss at iteration 460 : 0.00778866745531559
Loss at iteration 470 : 0.006604210939258337
Loss at iteration 480 : 0.01431602519005537
Loss at iteration 490 : 0.008385629393160343
Loss at iteration 500 : 0.009402122348546982
Loss at iteration 510 : 0.009700741618871689
Loss at iteration 520 : 0.012581611052155495
Loss at iteration 530 : 0.010261183604598045
Loss at iteration 540 : 0.005008826497942209
Loss at iteration 550 : 0.012196660041809082
Loss at iteration 560 : 0.012390821240842342
Loss at iteration 570 : 0.0058000292629003525
Loss at iteration 580 : 0.014005579054355621
Loss at iteration 590 : 0.007813487201929092
Loss at iteration 600 : 0.01566767878830433
Loss at iteration 610 : 0.008674352429807186
Loss at iteration 620 : 0.009299017488956451
Loss at iteration 630 : 0.009186722338199615
Loss at iteration 640 : 0.012635966762900352
Loss at iteration 650 : 0.015718931332230568
Loss at iteration 660 : 0.021379809826612473
Loss at iteration 670 : 0.012484154663980007
Loss at iteration 680 : 0.016167640686035156
Loss at iteration 690 : 0.010461135767400265
Loss at iteration 700 : 0.008788539096713066
Loss at iteration 710 : 0.014933548867702484
Loss at iteration 720 : 0.014198007062077522
Loss at iteration 730 : 0.014947177842259407
Loss at iteration 740 : 0.00652010552585125
Loss at iteration 750 : 0.006726759951561689
Loss at iteration 760 : 0.011147494427859783
Loss at iteration 770 : 0.007529777940362692
Loss at iteration 780 : 0.017738664522767067
Loss at iteration 790 : 0.009540751576423645
Loss at iteration 800 : 0.015173690393567085
Loss at iteration 810 : 0.01420833170413971
Loss at iteration 820 : 0.009738060645759106
Loss at iteration 830 : 0.007284823339432478
Loss at iteration 840 : 0.011034748516976833
Loss at iteration 850 : 0.015513008460402489
Loss at iteration 860 : 0.01950748823583126
Loss at iteration 870 : 0.005530418362468481
Loss at iteration 880 : 0.00928317941725254
Loss at iteration 890 : 0.008473537862300873
Loss at iteration 900 : 0.009566297754645348
Loss at iteration 910 : 0.0049947830848395824
Loss at iteration 920 : 0.012727668508887291
Loss at iteration 930 : 0.008122576400637627
Loss at iteration 940 : 0.009093554690480232
Loss at iteration 950 : 0.013075476512312889
Loss at iteration 960 : 0.011387011036276817
Loss at iteration 970 : 0.010737467557191849
Loss at iteration 980 : 0.011514134705066681
Loss at iteration 990 : 0.015187712386250496
Loss at iteration 1000 : 0.011333463713526726
Loss at iteration 1010 : 0.010050324723124504
Loss at iteration 1020 : 0.01868484728038311
Loss at iteration 1030 : 0.008850948885083199
Loss at iteration 1040 : 0.009444151073694229
Loss at iteration 1050 : 0.01162661612033844
Loss at iteration 1060 : 0.00955764576792717
Loss at iteration 1070 : 0.007522402331233025
Loss at iteration 1080 : 0.0158265121281147
Loss at iteration 1090 : 0.012155162170529366
Loss at iteration 1100 : 0.007169108837842941
Loss at iteration 1110 : 0.016206638887524605
Loss at iteration 1120 : 0.014329887926578522
Loss at iteration 1130 : 0.012889984995126724
Loss at iteration 1140 : 0.017267698422074318
Loss at iteration 1150 : 0.012799973599612713
Loss at iteration 1160 : 0.0055648102425038815
Loss at iteration 1170 : 0.013506039045751095
Loss at iteration 1180 : 0.010539497248828411
Loss at iteration 1190 : 0.007505663204938173
Loss at iteration 1200 : 0.007809756323695183
Loss at iteration 1210 : 0.008014490827918053
The SSIM Value is: 0.8116372028986613
The PSNR Value is: 18.976024373372397
the epoch is: 118
Loss at iteration 10 : 0.009036143310368061
Loss at iteration 20 : 0.011555317789316177
Loss at iteration 30 : 0.013635301031172276
Loss at iteration 40 : 0.010579724796116352
Loss at iteration 50 : 0.009964712895452976
Loss at iteration 60 : 0.014966687187552452
Loss at iteration 70 : 0.01264016330242157
Loss at iteration 80 : 0.010426166467368603
Loss at iteration 90 : 0.006659406237304211
Loss at iteration 100 : 0.011372681707143784
Loss at iteration 110 : 0.006125203799456358
Loss at iteration 120 : 0.014033081941306591
Loss at iteration 130 : 0.008897506631910801
Loss at iteration 140 : 0.013953963294625282
Loss at iteration 150 : 0.02279234677553177
Loss at iteration 160 : 0.01015136856585741
Loss at iteration 170 : 0.012777823954820633
Loss at iteration 180 : 0.006916477344930172
Loss at iteration 190 : 0.013018734753131866
Loss at iteration 200 : 0.005600153002887964
Loss at iteration 210 : 0.006229668390005827
Loss at iteration 220 : 0.004916192963719368
Loss at iteration 230 : 0.010316818952560425
Loss at iteration 240 : 0.008276780135929585
Loss at iteration 250 : 0.009290685877203941
Loss at iteration 260 : 0.005717171356081963
Loss at iteration 270 : 0.009382088668644428
Loss at iteration 280 : 0.008530111983418465
Loss at iteration 290 : 0.011693157255649567
Loss at iteration 300 : 0.013710200786590576
Loss at iteration 310 : 0.01149831898510456
Loss at iteration 320 : 0.018244873732328415
Loss at iteration 330 : 0.011542486026883125
Loss at iteration 340 : 0.009882163256406784
Loss at iteration 350 : 0.009782956913113594
Loss at iteration 360 : 0.0059554195031523705
Loss at iteration 370 : 0.010823367163538933
Loss at iteration 380 : 0.008058927953243256
Loss at iteration 390 : 0.01243812870234251
Loss at iteration 400 : 0.015317510813474655
Loss at iteration 410 : 0.01614389941096306
Loss at iteration 420 : 0.006399658974260092
Loss at iteration 430 : 0.012931544333696365
Loss at iteration 440 : 0.006123446859419346
Loss at iteration 450 : 0.008029134944081306
Loss at iteration 460 : 0.013597778044641018
Loss at iteration 470 : 0.011062192730605602
Loss at iteration 480 : 0.01464212778955698
Loss at iteration 490 : 0.01255739014595747
Loss at iteration 500 : 0.00673312321305275
Loss at iteration 510 : 0.006882076151669025
Loss at iteration 520 : 0.011097820475697517
Loss at iteration 530 : 0.014863749966025352
Loss at iteration 540 : 0.017424147576093674
Loss at iteration 550 : 0.008254890330135822
Loss at iteration 560 : 0.0178585983812809
Loss at iteration 570 : 0.008616599254310131
Loss at iteration 580 : 0.009094036184251308
Loss at iteration 590 : 0.00803404487669468
Loss at iteration 600 : 0.008874943479895592
Loss at iteration 610 : 0.005484040826559067
Loss at iteration 620 : 0.01485410239547491
Loss at iteration 630 : 0.01029294729232788
Loss at iteration 640 : 0.011062026023864746
Loss at iteration 650 : 0.00765417143702507
Loss at iteration 660 : 0.012115191668272018
Loss at iteration 670 : 0.011912869289517403
Loss at iteration 680 : 0.018028955906629562
Loss at iteration 690 : 0.009275735355913639
Loss at iteration 700 : 0.006225160788744688
Loss at iteration 710 : 0.012020407244563103
Loss at iteration 720 : 0.012488622218370438
Loss at iteration 730 : 0.010060320608317852
Loss at iteration 740 : 0.02442651242017746
Loss at iteration 750 : 0.011014548130333424
Loss at iteration 760 : 0.00710667809471488
Loss at iteration 770 : 0.01226096786558628
Loss at iteration 780 : 0.01479044184088707
Loss at iteration 790 : 0.01105472818017006
Loss at iteration 800 : 0.016618868336081505
Loss at iteration 810 : 0.007859549485147
Loss at iteration 820 : 0.0077875880524516106
Loss at iteration 830 : 0.012889053672552109
Loss at iteration 840 : 0.012171373702585697
Loss at iteration 850 : 0.013117000460624695
Loss at iteration 860 : 0.008543018251657486
Loss at iteration 870 : 0.010838152840733528
Loss at iteration 880 : 0.01707974448800087
Loss at iteration 890 : 0.012426471337676048
Loss at iteration 900 : 0.006898139603435993
Loss at iteration 910 : 0.01054740697145462
Loss at iteration 920 : 0.005257986485958099
Loss at iteration 930 : 0.02421555668115616
Loss at iteration 940 : 0.016208797693252563
Loss at iteration 950 : 0.009373577311635017
Loss at iteration 960 : 0.006851905956864357
Loss at iteration 970 : 0.008114112541079521
Loss at iteration 980 : 0.014515222050249577
Loss at iteration 990 : 0.011061007156968117
Loss at iteration 1000 : 0.012635983526706696
Loss at iteration 1010 : 0.013224370777606964
Loss at iteration 1020 : 0.00672186492010951
Loss at iteration 1030 : 0.011935011483728886
Loss at iteration 1040 : 0.011371862143278122
Loss at iteration 1050 : 0.011368514969944954
Loss at iteration 1060 : 0.014284120872616768
Loss at iteration 1070 : 0.008750739507377148
Loss at iteration 1080 : 0.015233434736728668
Loss at iteration 1090 : 0.009560167789459229
Loss at iteration 1100 : 0.007011387497186661
Loss at iteration 1110 : 0.015627248212695122
Loss at iteration 1120 : 0.01140887476503849
Loss at iteration 1130 : 0.015680905431509018
Loss at iteration 1140 : 0.01178402453660965
Loss at iteration 1150 : 0.01157703623175621
Loss at iteration 1160 : 0.016900090500712395
Loss at iteration 1170 : 0.009545007720589638
Loss at iteration 1180 : 0.00833441037684679
Loss at iteration 1190 : 0.013323599472641945
Loss at iteration 1200 : 0.009129266254603863
Loss at iteration 1210 : 0.011655798181891441
The SSIM Value is: 0.8005004763603211
The PSNR Value is: 18.773115221659342
the epoch is: 119
Loss at iteration 10 : 0.01084762904793024
Loss at iteration 20 : 0.014839176088571548
Loss at iteration 30 : 0.018355516716837883
Loss at iteration 40 : 0.013366259634494781
Loss at iteration 50 : 0.014430364593863487
Loss at iteration 60 : 0.008813516236841679
Loss at iteration 70 : 0.014654373750090599
Loss at iteration 80 : 0.0100422827526927
Loss at iteration 90 : 0.00911681167781353
Loss at iteration 100 : 0.008083026856184006
Loss at iteration 110 : 0.008511759340763092
Loss at iteration 120 : 0.006014822516590357
Loss at iteration 130 : 0.020017284899950027
Loss at iteration 140 : 0.014527780003845692
Loss at iteration 150 : 0.010879918932914734
Loss at iteration 160 : 0.01685257814824581
Loss at iteration 170 : 0.007520302198827267
Loss at iteration 180 : 0.012205077335238457
Loss at iteration 190 : 0.006811289582401514
Loss at iteration 200 : 0.009399110451340675
Loss at iteration 210 : 0.0113944411277771
Loss at iteration 220 : 0.01097586564719677
Loss at iteration 230 : 0.019282324239611626
Loss at iteration 240 : 0.010002530179917812
Loss at iteration 250 : 0.00781512726098299
Loss at iteration 260 : 0.0078074997290968895
Loss at iteration 270 : 0.007642189506441355
Loss at iteration 280 : 0.011647425591945648
Loss at iteration 290 : 0.010389825329184532
Loss at iteration 300 : 0.015591385774314404
Loss at iteration 310 : 0.015354620292782784
Loss at iteration 320 : 0.014833410270512104
Loss at iteration 330 : 0.007047493476420641
Loss at iteration 340 : 0.009730879217386246
Loss at iteration 350 : 0.008469315245747566
Loss at iteration 360 : 0.010361818596720695
Loss at iteration 370 : 0.005355047062039375
Loss at iteration 380 : 0.010089155286550522
Loss at iteration 390 : 0.007786744274199009
Loss at iteration 400 : 0.00806873943656683
Loss at iteration 410 : 0.012703262269496918
Loss at iteration 420 : 0.010177365504205227
Loss at iteration 430 : 0.00787311140447855
Loss at iteration 440 : 0.014332269318401814
Loss at iteration 450 : 0.01646517775952816
Loss at iteration 460 : 0.00953963678330183
Loss at iteration 470 : 0.012126722373068333
Loss at iteration 480 : 0.012340422719717026
Loss at iteration 490 : 0.008478508330881596
Loss at iteration 500 : 0.009822164662182331
Loss at iteration 510 : 0.008796144276857376
Loss at iteration 520 : 0.013474036008119583
Loss at iteration 530 : 0.018846390768885612
Loss at iteration 540 : 0.027340959757566452
Loss at iteration 550 : 0.007834525778889656
Loss at iteration 560 : 0.005849760491400957
Loss at iteration 570 : 0.015318406745791435
Loss at iteration 580 : 0.007971562445163727
Loss at iteration 590 : 0.015699656680226326
Loss at iteration 600 : 0.009857989847660065
Loss at iteration 610 : 0.01925012469291687
Loss at iteration 620 : 0.026189573109149933
Loss at iteration 630 : 0.01723705604672432
Loss at iteration 640 : 0.014163576066493988
Loss at iteration 650 : 0.00948360562324524
Loss at iteration 660 : 0.009805514477193356
Loss at iteration 670 : 0.013050377368927002
Loss at iteration 680 : 0.009512091055512428
Loss at iteration 690 : 0.011642355471849442
Loss at iteration 700 : 0.016169507056474686
Loss at iteration 710 : 0.008334539830684662
Loss at iteration 720 : 0.015348443761467934
Loss at iteration 730 : 0.006874691229313612
Loss at iteration 740 : 0.005759587045758963
Loss at iteration 750 : 0.008806716650724411
Loss at iteration 760 : 0.007356755901128054
Loss at iteration 770 : 0.011820913292467594
Loss at iteration 780 : 0.011019246652722359
Loss at iteration 790 : 0.009123513475060463
Loss at iteration 800 : 0.010747040621936321
Loss at iteration 810 : 0.005625532008707523
Loss at iteration 820 : 0.01675337366759777
Loss at iteration 830 : 0.011185171082615852
Loss at iteration 840 : 0.009733484126627445
Loss at iteration 850 : 0.012397799640893936
Loss at iteration 860 : 0.0118524469435215
Loss at iteration 870 : 0.0150414127856493
Loss at iteration 880 : 0.014201100915670395
Loss at iteration 890 : 0.014717381447553635
Loss at iteration 900 : 0.012222266755998135
Loss at iteration 910 : 0.011960180476307869
Loss at iteration 920 : 0.009341513738036156
Loss at iteration 930 : 0.004565082024782896
Loss at iteration 940 : 0.013066098093986511
Loss at iteration 950 : 0.01447981595993042
Loss at iteration 960 : 0.01487000659108162
Loss at iteration 970 : 0.013428937643766403
Loss at iteration 980 : 0.013067644089460373
Loss at iteration 990 : 0.011422671377658844
Loss at iteration 1000 : 0.00924505665898323
Loss at iteration 1010 : 0.00777785386890173
Loss at iteration 1020 : 0.006687704473733902
Loss at iteration 1030 : 0.01346297562122345
Loss at iteration 1040 : 0.009358525276184082
Loss at iteration 1050 : 0.008851212449371815
Loss at iteration 1060 : 0.006967529654502869
Loss at iteration 1070 : 0.014334911480545998
Loss at iteration 1080 : 0.015313261188566685
Loss at iteration 1090 : 0.021021079272031784
Loss at iteration 1100 : 0.00606374628841877
Loss at iteration 1110 : 0.009349435567855835
Loss at iteration 1120 : 0.010575108230113983
Loss at iteration 1130 : 0.010686792433261871
Loss at iteration 1140 : 0.01701321080327034
Loss at iteration 1150 : 0.006542837712913752
Loss at iteration 1160 : 0.007198382634669542
Loss at iteration 1170 : 0.010755820199847221
Loss at iteration 1180 : 0.008330993354320526
Loss at iteration 1190 : 0.012348968535661697
Loss at iteration 1200 : 0.012882042676210403
Loss at iteration 1210 : 0.014106890186667442
The SSIM Value is: 0.8022809068361918
The PSNR Value is: 18.77610232035319
the epoch is: 120
Loss at iteration 10 : 0.016934167593717575
Loss at iteration 20 : 0.012244205921888351
Loss at iteration 30 : 0.006751426495611668
Loss at iteration 40 : 0.013475366868078709
Loss at iteration 50 : 0.008587864227592945
Loss at iteration 60 : 0.013519121333956718
Loss at iteration 70 : 0.010790032334625721
Loss at iteration 80 : 0.01404281985014677
Loss at iteration 90 : 0.01093106996268034
Loss at iteration 100 : 0.011869911104440689
Loss at iteration 110 : 0.0063311271369457245
Loss at iteration 120 : 0.013716686517000198
Loss at iteration 130 : 0.011303728446364403
Loss at iteration 140 : 0.020915880799293518
Loss at iteration 150 : 0.013112622313201427
Loss at iteration 160 : 0.007339187432080507
Loss at iteration 170 : 0.014684081077575684
Loss at iteration 180 : 0.010449529625475407
Loss at iteration 190 : 0.006949853617697954
Loss at iteration 200 : 0.011880814097821712
Loss at iteration 210 : 0.013854136690497398
Loss at iteration 220 : 0.008080909959971905
Loss at iteration 230 : 0.009986471384763718
Loss at iteration 240 : 0.011032185517251492
Loss at iteration 250 : 0.014046970754861832
Loss at iteration 260 : 0.007455640472471714
Loss at iteration 270 : 0.010872649028897285
Loss at iteration 280 : 0.007550124078989029
Loss at iteration 290 : 0.014184270985424519
Loss at iteration 300 : 0.01544986292719841
Loss at iteration 310 : 0.014562247321009636
Loss at iteration 320 : 0.010717867873609066
Loss at iteration 330 : 0.008027998730540276
Loss at iteration 340 : 0.012113304808735847
Loss at iteration 350 : 0.004632554482668638
Loss at iteration 360 : 0.007170555181801319
Loss at iteration 370 : 0.009965576231479645
Loss at iteration 380 : 0.004191079176962376
Loss at iteration 390 : 0.009090670384466648
Loss at iteration 400 : 0.018313132226467133
Loss at iteration 410 : 0.008082544431090355
Loss at iteration 420 : 0.00957395788282156
Loss at iteration 430 : 0.007379056885838509
Loss at iteration 440 : 0.01736290566623211
Loss at iteration 450 : 0.00925239734351635
Loss at iteration 460 : 0.010851679369807243
Loss at iteration 470 : 0.0108750369399786
Loss at iteration 480 : 0.008250742219388485
Loss at iteration 490 : 0.011922052130103111
Loss at iteration 500 : 0.009478379040956497
Loss at iteration 510 : 0.010927267372608185
Loss at iteration 520 : 0.005252727307379246
Loss at iteration 530 : 0.007730156648904085
Loss at iteration 540 : 0.008799612522125244
Loss at iteration 550 : 0.007840553298592567
Loss at iteration 560 : 0.008804728277027607
Loss at iteration 570 : 0.011095132678747177
Loss at iteration 580 : 0.013852829113602638
Loss at iteration 590 : 0.010475094430148602
Loss at iteration 600 : 0.013979833573102951
Loss at iteration 610 : 0.02166637033224106
Loss at iteration 620 : 0.007840298116207123
Loss at iteration 630 : 0.0161287821829319
Loss at iteration 640 : 0.01232297345995903
Loss at iteration 650 : 0.00955787394195795
Loss at iteration 660 : 0.012037871405482292
Loss at iteration 670 : 0.018582826480269432
Loss at iteration 680 : 0.008446868509054184
Loss at iteration 690 : 0.015440363436937332
Loss at iteration 700 : 0.005626474507153034
Loss at iteration 710 : 0.012248370796442032
Loss at iteration 720 : 0.01186020765453577
Loss at iteration 730 : 0.006891663186252117
Loss at iteration 740 : 0.011463123373687267
Loss at iteration 750 : 0.013956310227513313
Loss at iteration 760 : 0.01380779966711998
Loss at iteration 770 : 0.00833902508020401
Loss at iteration 780 : 0.014685597270727158
Loss at iteration 790 : 0.011640558019280434
Loss at iteration 800 : 0.01312643475830555
Loss at iteration 810 : 0.011619306169450283
Loss at iteration 820 : 0.009892364032566547
Loss at iteration 830 : 0.01320294477045536
Loss at iteration 840 : 0.010138008743524551
Loss at iteration 850 : 0.007419823668897152
Loss at iteration 860 : 0.011595629155635834
Loss at iteration 870 : 0.00965918693691492
Loss at iteration 880 : 0.00450136698782444
Loss at iteration 890 : 0.02150184102356434
Loss at iteration 900 : 0.006628012750297785
Loss at iteration 910 : 0.0078068627044558525
Loss at iteration 920 : 0.015394176356494427
Loss at iteration 930 : 0.010080298408865929
Loss at iteration 940 : 0.015106499195098877
Loss at iteration 950 : 0.012543751858174801
Loss at iteration 960 : 0.00999625213444233
Loss at iteration 970 : 0.010685516521334648
Loss at iteration 980 : 0.00871339812874794
Loss at iteration 990 : 0.009571964852511883
Loss at iteration 1000 : 0.010326464660465717
Loss at iteration 1010 : 0.011259213089942932
Loss at iteration 1020 : 0.010569579899311066
Loss at iteration 1030 : 0.009990811347961426
Loss at iteration 1040 : 0.00784958153963089
Loss at iteration 1050 : 0.007738647982478142
Loss at iteration 1060 : 0.010594733990728855
Loss at iteration 1070 : 0.008092664182186127
Loss at iteration 1080 : 0.012577752582728863
Loss at iteration 1090 : 0.007909446023404598
Loss at iteration 1100 : 0.009932789020240307
Loss at iteration 1110 : 0.0075265830382704735
Loss at iteration 1120 : 0.007815437391400337
Loss at iteration 1130 : 0.012949652969837189
Loss at iteration 1140 : 0.010840734466910362
Loss at iteration 1150 : 0.010935540311038494
Loss at iteration 1160 : 0.007839608006179333
Loss at iteration 1170 : 0.009038123302161694
Loss at iteration 1180 : 0.008255775086581707
Loss at iteration 1190 : 0.02179080992937088
Loss at iteration 1200 : 0.012732100673019886
Loss at iteration 1210 : 0.008286007679998875
The SSIM Value is: 0.8053039749463399
The PSNR Value is: 18.5712553024292
the epoch is: 121
Loss at iteration 10 : 0.007727004121989012
Loss at iteration 20 : 0.011091362684965134
Loss at iteration 30 : 0.011497443541884422
Loss at iteration 40 : 0.009152408689260483
Loss at iteration 50 : 0.0065388148650527
Loss at iteration 60 : 0.006925236899405718
Loss at iteration 70 : 0.008888503536581993
Loss at iteration 80 : 0.011620888486504555
Loss at iteration 90 : 0.013222478330135345
Loss at iteration 100 : 0.011127099394798279
Loss at iteration 110 : 0.007148196920752525
Loss at iteration 120 : 0.008189677260816097
Loss at iteration 130 : 0.005847251508384943
Loss at iteration 140 : 0.008907884359359741
Loss at iteration 150 : 0.010308663360774517
Loss at iteration 160 : 0.009191825054585934
Loss at iteration 170 : 0.013496249914169312
Loss at iteration 180 : 0.014361068606376648
Loss at iteration 190 : 0.010941322892904282
Loss at iteration 200 : 0.011095445603132248
Loss at iteration 210 : 0.010022977367043495
Loss at iteration 220 : 0.00996892899274826
Loss at iteration 230 : 0.012518436647951603
Loss at iteration 240 : 0.00848297867923975
Loss at iteration 250 : 0.009563898667693138
Loss at iteration 260 : 0.011662798002362251
Loss at iteration 270 : 0.008104082196950912
Loss at iteration 280 : 0.006938030011951923
Loss at iteration 290 : 0.008271275088191032
Loss at iteration 300 : 0.011509900912642479
Loss at iteration 310 : 0.00960658211261034
Loss at iteration 320 : 0.007482332643121481
Loss at iteration 330 : 0.009679961949586868
Loss at iteration 340 : 0.013528893701732159
Loss at iteration 350 : 0.008005863055586815
Loss at iteration 360 : 0.009924434125423431
Loss at iteration 370 : 0.008349994197487831
Loss at iteration 380 : 0.016387391835451126
Loss at iteration 390 : 0.018874915316700935
Loss at iteration 400 : 0.007646006997674704
Loss at iteration 410 : 0.012655324302613735
Loss at iteration 420 : 0.011026791296899319
Loss at iteration 430 : 0.013959398493170738
Loss at iteration 440 : 0.007608544081449509
Loss at iteration 450 : 0.010893216356635094
Loss at iteration 460 : 0.01005820743739605
Loss at iteration 470 : 0.0078119696117937565
Loss at iteration 480 : 0.012483935803174973
Loss at iteration 490 : 0.01048192661255598
Loss at iteration 500 : 0.013019143603742123
Loss at iteration 510 : 0.005239698104560375
Loss at iteration 520 : 0.010059649124741554
Loss at iteration 530 : 0.008872153237462044
Loss at iteration 540 : 0.016537299379706383
Loss at iteration 550 : 0.012821373529732227
Loss at iteration 560 : 0.005752371158450842
Loss at iteration 570 : 0.010003186762332916
Loss at iteration 580 : 0.005420789588242769
Loss at iteration 590 : 0.0074078687466681
Loss at iteration 600 : 0.015985723584890366
Loss at iteration 610 : 0.011602343060076237
Loss at iteration 620 : 0.013161035254597664
Loss at iteration 630 : 0.010127824731171131
Loss at iteration 640 : 0.011435601860284805
Loss at iteration 650 : 0.014446661807596684
Loss at iteration 660 : 0.00767538882791996
Loss at iteration 670 : 0.008225196041166782
Loss at iteration 680 : 0.012801521457731724
Loss at iteration 690 : 0.012366819195449352
Loss at iteration 700 : 0.007907492108643055
Loss at iteration 710 : 0.014597728848457336
Loss at iteration 720 : 0.009441642090678215
Loss at iteration 730 : 0.013803750276565552
Loss at iteration 740 : 0.009764307178556919
Loss at iteration 750 : 0.008277413435280323
Loss at iteration 760 : 0.010458804666996002
Loss at iteration 770 : 0.0065736970864236355
Loss at iteration 780 : 0.013997258618474007
Loss at iteration 790 : 0.012740207836031914
Loss at iteration 800 : 0.010267741046845913
Loss at iteration 810 : 0.01356613077223301
Loss at iteration 820 : 0.021567609161138535
Loss at iteration 830 : 0.00926763005554676
Loss at iteration 840 : 0.010377367027103901
Loss at iteration 850 : 0.006408853456377983
Loss at iteration 860 : 0.012311769649386406
Loss at iteration 870 : 0.014799948781728745
Loss at iteration 880 : 0.016232460737228394
Loss at iteration 890 : 0.015697387978434563
Loss at iteration 900 : 0.010396021418273449
Loss at iteration 910 : 0.013470074161887169
Loss at iteration 920 : 0.009600862860679626
Loss at iteration 930 : 0.010020049288868904
Loss at iteration 940 : 0.009240415878593922
Loss at iteration 950 : 0.009930586442351341
Loss at iteration 960 : 0.0098646879196167
Loss at iteration 970 : 0.011140268296003342
Loss at iteration 980 : 0.00970502756536007
Loss at iteration 990 : 0.010704873129725456
Loss at iteration 1000 : 0.011331688612699509
Loss at iteration 1010 : 0.007599194534122944
Loss at iteration 1020 : 0.006657438352704048
Loss at iteration 1030 : 0.009447291493415833
Loss at iteration 1040 : 0.008941266685724258
Loss at iteration 1050 : 0.011073901318013668
Loss at iteration 1060 : 0.012060079723596573
Loss at iteration 1070 : 0.006606458220630884
Loss at iteration 1080 : 0.006292554549872875
Loss at iteration 1090 : 0.011998621746897697
Loss at iteration 1100 : 0.01240887027233839
Loss at iteration 1110 : 0.013401308096945286
Loss at iteration 1120 : 0.009485999122262001
Loss at iteration 1130 : 0.005698745604604483
Loss at iteration 1140 : 0.00699628284201026
Loss at iteration 1150 : 0.008459629490971565
Loss at iteration 1160 : 0.004898079205304384
Loss at iteration 1170 : 0.008175039663910866
Loss at iteration 1180 : 0.005841145291924477
Loss at iteration 1190 : 0.013472011312842369
Loss at iteration 1200 : 0.01029481366276741
Loss at iteration 1210 : 0.011980431154370308
The SSIM Value is: 0.8071229020754497
The PSNR Value is: 18.794801648457845
the epoch is: 122
Loss at iteration 10 : 0.012591397389769554
Loss at iteration 20 : 0.009356475435197353
Loss at iteration 30 : 0.009322072379291058
Loss at iteration 40 : 0.01767553947865963
Loss at iteration 50 : 0.011503493413329124
Loss at iteration 60 : 0.015442941337823868
Loss at iteration 70 : 0.006627129390835762
Loss at iteration 80 : 0.007899418473243713
Loss at iteration 90 : 0.013112752698361874
Loss at iteration 100 : 0.015560007654130459
Loss at iteration 110 : 0.00856877863407135
Loss at iteration 120 : 0.010321293957531452
Loss at iteration 130 : 0.017446205019950867
Loss at iteration 140 : 0.022979166358709335
Loss at iteration 150 : 0.012674410827457905
Loss at iteration 160 : 0.015380782075226307
Loss at iteration 170 : 0.018812056630849838
Loss at iteration 180 : 0.009975376538932323
Loss at iteration 190 : 0.01349879615008831
Loss at iteration 200 : 0.006867156829684973
Loss at iteration 210 : 0.007528072223067284
Loss at iteration 220 : 0.006955163553357124
Loss at iteration 230 : 0.011637554503977299
Loss at iteration 240 : 0.01117792446166277
Loss at iteration 250 : 0.015041416510939598
Loss at iteration 260 : 0.008943966589868069
Loss at iteration 270 : 0.011224931105971336
Loss at iteration 280 : 0.005469070747494698
Loss at iteration 290 : 0.015767037868499756
Loss at iteration 300 : 0.010896565392613411
Loss at iteration 310 : 0.008003182709217072
Loss at iteration 320 : 0.017233991995453835
Loss at iteration 330 : 0.01247220579534769
Loss at iteration 340 : 0.009349710308015347
Loss at iteration 350 : 0.018684960901737213
Loss at iteration 360 : 0.012279845774173737
Loss at iteration 370 : 0.007462525740265846
Loss at iteration 380 : 0.009743841364979744
Loss at iteration 390 : 0.017313435673713684
Loss at iteration 400 : 0.011639969423413277
Loss at iteration 410 : 0.012851010076701641
Loss at iteration 420 : 0.011335009709000587
Loss at iteration 430 : 0.010141052305698395
Loss at iteration 440 : 0.010344184935092926
Loss at iteration 450 : 0.022464312613010406
Loss at iteration 460 : 0.013080824166536331
Loss at iteration 470 : 0.010081697255373001
Loss at iteration 480 : 0.012586092576384544
Loss at iteration 490 : 0.011880714446306229
Loss at iteration 500 : 0.005296827759593725
Loss at iteration 510 : 0.01632385514676571
Loss at iteration 520 : 0.012893861159682274
Loss at iteration 530 : 0.008543341420590878
Loss at iteration 540 : 0.010265638120472431
Loss at iteration 550 : 0.012324964627623558
Loss at iteration 560 : 0.013089092448353767
Loss at iteration 570 : 0.012074422091245651
Loss at iteration 580 : 0.013002559542655945
Loss at iteration 590 : 0.006808246951550245
Loss at iteration 600 : 0.007174731232225895
Loss at iteration 610 : 0.011418722569942474
Loss at iteration 620 : 0.01247930433601141
Loss at iteration 630 : 0.010808399878442287
Loss at iteration 640 : 0.014620154164731503
Loss at iteration 650 : 0.010332619771361351
Loss at iteration 660 : 0.010108039714396
Loss at iteration 670 : 0.011309248395264149
Loss at iteration 680 : 0.00909867137670517
Loss at iteration 690 : 0.010884808376431465
Loss at iteration 700 : 0.012403127737343311
Loss at iteration 710 : 0.008254632353782654
Loss at iteration 720 : 0.008334574289619923
Loss at iteration 730 : 0.012200105004012585
Loss at iteration 740 : 0.012719772756099701
Loss at iteration 750 : 0.014724294655025005
Loss at iteration 760 : 0.010228467173874378
Loss at iteration 770 : 0.009392932988703251
Loss at iteration 780 : 0.010614199563860893
Loss at iteration 790 : 0.007711848709732294
Loss at iteration 800 : 0.015385741367936134
Loss at iteration 810 : 0.016969703137874603
Loss at iteration 820 : 0.010529188439249992
Loss at iteration 830 : 0.009226815775036812
Loss at iteration 840 : 0.015079413540661335
Loss at iteration 850 : 0.008316125720739365
Loss at iteration 860 : 0.005141426809132099
Loss at iteration 870 : 0.011067701503634453
Loss at iteration 880 : 0.0147849777713418
Loss at iteration 890 : 0.006963606923818588
Loss at iteration 900 : 0.007809844799339771
Loss at iteration 910 : 0.013043422251939774
Loss at iteration 920 : 0.018932927399873734
Loss at iteration 930 : 0.0151541568338871
Loss at iteration 940 : 0.01012606080621481
Loss at iteration 950 : 0.010353028774261475
Loss at iteration 960 : 0.015811849385499954
Loss at iteration 970 : 0.012984758242964745
Loss at iteration 980 : 0.009115044958889484
Loss at iteration 990 : 0.012637176550924778
Loss at iteration 1000 : 0.014429565519094467
Loss at iteration 1010 : 0.01256053987890482
Loss at iteration 1020 : 0.005701761227101088
Loss at iteration 1030 : 0.012258930131793022
Loss at iteration 1040 : 0.006302133202552795
Loss at iteration 1050 : 0.00754135474562645
Loss at iteration 1060 : 0.0057042911648750305
Loss at iteration 1070 : 0.008869970217347145
Loss at iteration 1080 : 0.009578324854373932
Loss at iteration 1090 : 0.007631347049027681
Loss at iteration 1100 : 0.015466047450900078
Loss at iteration 1110 : 0.006933724973350763
Loss at iteration 1120 : 0.010090759955346584
Loss at iteration 1130 : 0.00587959960103035
Loss at iteration 1140 : 0.012350046075880527
Loss at iteration 1150 : 0.00964733213186264
Loss at iteration 1160 : 0.013487309217453003
Loss at iteration 1170 : 0.011930722743272781
Loss at iteration 1180 : 0.006695058196783066
Loss at iteration 1190 : 0.012822424992918968
Loss at iteration 1200 : 0.00715708639472723
Loss at iteration 1210 : 0.01426122710108757
The SSIM Value is: 0.7967887878417969
The PSNR Value is: 18.20354833602905
the epoch is: 123
Loss at iteration 10 : 0.007189876399934292
Loss at iteration 20 : 0.008987553417682648
Loss at iteration 30 : 0.009252913296222687
Loss at iteration 40 : 0.012598111294209957
Loss at iteration 50 : 0.011336793191730976
Loss at iteration 60 : 0.011598361656069756
Loss at iteration 70 : 0.014486763626337051
Loss at iteration 80 : 0.012298865243792534
Loss at iteration 90 : 0.009551594033837318
Loss at iteration 100 : 0.005803931504487991
Loss at iteration 110 : 0.00861156452447176
Loss at iteration 120 : 0.016039524227380753
Loss at iteration 130 : 0.013020926155149937
Loss at iteration 140 : 0.015141217038035393
Loss at iteration 150 : 0.010630827397108078
Loss at iteration 160 : 0.016401095315814018
Loss at iteration 170 : 0.008742701262235641
Loss at iteration 180 : 0.010339801199734211
Loss at iteration 190 : 0.00924804899841547
Loss at iteration 200 : 0.007653664797544479
Loss at iteration 210 : 0.00904038455337286
Loss at iteration 220 : 0.010736599564552307
Loss at iteration 230 : 0.018961671739816666
Loss at iteration 240 : 0.008511899970471859
Loss at iteration 250 : 0.010431814007461071
Loss at iteration 260 : 0.01417098194360733
Loss at iteration 270 : 0.015575587749481201
Loss at iteration 280 : 0.01238802820444107
Loss at iteration 290 : 0.010997755452990532
Loss at iteration 300 : 0.011746356263756752
Loss at iteration 310 : 0.01468358002603054
Loss at iteration 320 : 0.008715282194316387
Loss at iteration 330 : 0.0069917356595396996
Loss at iteration 340 : 0.012959154322743416
Loss at iteration 350 : 0.006275131367146969
Loss at iteration 360 : 0.014362111687660217
Loss at iteration 370 : 0.012176470831036568
Loss at iteration 380 : 0.00709573645144701
Loss at iteration 390 : 0.00758828641846776
Loss at iteration 400 : 0.014219009317457676
Loss at iteration 410 : 0.010852299630641937
Loss at iteration 420 : 0.00983581505715847
Loss at iteration 430 : 0.017298642545938492
Loss at iteration 440 : 0.008130555041134357
Loss at iteration 450 : 0.0090201236307621
Loss at iteration 460 : 0.012656833976507187
Loss at iteration 470 : 0.010687509551644325
Loss at iteration 480 : 0.011803247034549713
Loss at iteration 490 : 0.01119513064622879
Loss at iteration 500 : 0.01893528364598751
Loss at iteration 510 : 0.015603484585881233
Loss at iteration 520 : 0.009168187156319618
Loss at iteration 530 : 0.012802943587303162
Loss at iteration 540 : 0.005843740422278643
Loss at iteration 550 : 0.013616043142974377
Loss at iteration 560 : 0.010182160884141922
Loss at iteration 570 : 0.011826753616333008
Loss at iteration 580 : 0.008329098112881184
Loss at iteration 590 : 0.016240505501627922
Loss at iteration 600 : 0.0105948057025671
Loss at iteration 610 : 0.008388612419366837
Loss at iteration 620 : 0.010276488028466702
Loss at iteration 630 : 0.010260475799441338
Loss at iteration 640 : 0.006707925349473953
Loss at iteration 650 : 0.006212675478309393
Loss at iteration 660 : 0.011207608506083488
Loss at iteration 670 : 0.011279778555035591
Loss at iteration 680 : 0.016641687601804733
Loss at iteration 690 : 0.012399050407111645
Loss at iteration 700 : 0.009626922197639942
Loss at iteration 710 : 0.00680061150342226
Loss at iteration 720 : 0.013948345556855202
Loss at iteration 730 : 0.013756143860518932
Loss at iteration 740 : 0.01298285648226738
Loss at iteration 750 : 0.009970704093575478
Loss at iteration 760 : 0.007721190340816975
Loss at iteration 770 : 0.009295010939240456
Loss at iteration 780 : 0.0076440973207354546
Loss at iteration 790 : 0.010022684931755066
Loss at iteration 800 : 0.019118700176477432
Loss at iteration 810 : 0.01679874211549759
Loss at iteration 820 : 0.022749748080968857
Loss at iteration 830 : 0.009263275191187859
Loss at iteration 840 : 0.013541057705879211
Loss at iteration 850 : 0.010585091076791286
Loss at iteration 860 : 0.01072478387504816
Loss at iteration 870 : 0.013332349248230457
Loss at iteration 880 : 0.007021610625088215
Loss at iteration 890 : 0.012253002263605595
Loss at iteration 900 : 0.015838375315070152
Loss at iteration 910 : 0.01613771542906761
Loss at iteration 920 : 0.009386412799358368
Loss at iteration 930 : 0.010120564140379429
Loss at iteration 940 : 0.00908513180911541
Loss at iteration 950 : 0.010357541963458061
Loss at iteration 960 : 0.01233808696269989
Loss at iteration 970 : 0.012431246228516102
Loss at iteration 980 : 0.005282114259898663
Loss at iteration 990 : 0.01149830874055624
Loss at iteration 1000 : 0.006567535921931267
Loss at iteration 1010 : 0.008801666088402271
Loss at iteration 1020 : 0.011999680660665035
Loss at iteration 1030 : 0.016693957149982452
Loss at iteration 1040 : 0.01104768831282854
Loss at iteration 1050 : 0.015703324228525162
Loss at iteration 1060 : 0.009880383498966694
Loss at iteration 1070 : 0.009496225975453854
Loss at iteration 1080 : 0.016046199947595596
Loss at iteration 1090 : 0.007402786519378424
Loss at iteration 1100 : 0.011682054027915001
Loss at iteration 1110 : 0.00911050383001566
Loss at iteration 1120 : 0.014873180538415909
Loss at iteration 1130 : 0.007637204602360725
Loss at iteration 1140 : 0.006257365923374891
Loss at iteration 1150 : 0.008134585805237293
Loss at iteration 1160 : 0.00781678594648838
Loss at iteration 1170 : 0.015100869350135326
Loss at iteration 1180 : 0.007923242636024952
Loss at iteration 1190 : 0.010481514967978
Loss at iteration 1200 : 0.010214501060545444
Loss at iteration 1210 : 0.017406990751624107
The SSIM Value is: 0.8112514098485311
The PSNR Value is: 19.1349302927653
the epoch is: 124
Loss at iteration 10 : 0.012024874798953533
Loss at iteration 20 : 0.007552317809313536
Loss at iteration 30 : 0.008564436808228493
Loss at iteration 40 : 0.015644576400518417
Loss at iteration 50 : 0.008235751651227474
Loss at iteration 60 : 0.009509781375527382
Loss at iteration 70 : 0.015063760802149773
Loss at iteration 80 : 0.015764839947223663
Loss at iteration 90 : 0.010839346796274185
Loss at iteration 100 : 0.013019952923059464
Loss at iteration 110 : 0.02486027590930462
Loss at iteration 120 : 0.011707037687301636
Loss at iteration 130 : 0.007119541987776756
Loss at iteration 140 : 0.008163711056113243
Loss at iteration 150 : 0.009998815134167671
Loss at iteration 160 : 0.008759882301092148
Loss at iteration 170 : 0.014656136743724346
Loss at iteration 180 : 0.011902754195034504
Loss at iteration 190 : 0.011751139536499977
Loss at iteration 200 : 0.009423685260117054
Loss at iteration 210 : 0.0077412743121385574
Loss at iteration 220 : 0.010359736159443855
Loss at iteration 230 : 0.012865124270319939
Loss at iteration 240 : 0.014672987163066864
Loss at iteration 250 : 0.010320833884179592
Loss at iteration 260 : 0.00909176841378212
Loss at iteration 270 : 0.007354219444096088
Loss at iteration 280 : 0.008956178091466427
Loss at iteration 290 : 0.01186567172408104
Loss at iteration 300 : 0.011875271797180176
Loss at iteration 310 : 0.00739456620067358
Loss at iteration 320 : 0.009065082296729088
Loss at iteration 330 : 0.01478185597807169
Loss at iteration 340 : 0.011294333264231682
Loss at iteration 350 : 0.006790922489017248
Loss at iteration 360 : 0.009367559105157852
Loss at iteration 370 : 0.010686132125556469
Loss at iteration 380 : 0.023166263476014137
Loss at iteration 390 : 0.015303710475564003
Loss at iteration 400 : 0.01600819081068039
Loss at iteration 410 : 0.011987379752099514
Loss at iteration 420 : 0.006770740263164043
Loss at iteration 430 : 0.023487232625484467
Loss at iteration 440 : 0.012189658358693123
Loss at iteration 450 : 0.006949663627892733
Loss at iteration 460 : 0.006809268146753311
Loss at iteration 470 : 0.012396858073771
Loss at iteration 480 : 0.008168782107532024
Loss at iteration 490 : 0.010328610427677631
Loss at iteration 500 : 0.00809550005942583
Loss at iteration 510 : 0.007835287600755692
Loss at iteration 520 : 0.008793485350906849
Loss at iteration 530 : 0.014267823658883572
Loss at iteration 540 : 0.00447362894192338
Loss at iteration 550 : 0.009631959721446037
Loss at iteration 560 : 0.011045238934457302
Loss at iteration 570 : 0.010664371773600578
Loss at iteration 580 : 0.009487038478255272
Loss at iteration 590 : 0.01570635847747326
Loss at iteration 600 : 0.013769522309303284
Loss at iteration 610 : 0.010961712338030338
Loss at iteration 620 : 0.021666880697011948
Loss at iteration 630 : 0.012610157951712608
Loss at iteration 640 : 0.009983979165554047
Loss at iteration 650 : 0.008965748362243176
Loss at iteration 660 : 0.011287208646535873
Loss at iteration 670 : 0.009058567695319653
Loss at iteration 680 : 0.007907574065029621
Loss at iteration 690 : 0.011114664375782013
Loss at iteration 700 : 0.01154395006597042
Loss at iteration 710 : 0.005721776746213436
Loss at iteration 720 : 0.00944729708135128
Loss at iteration 730 : 0.008117588236927986
Loss at iteration 740 : 0.010257987305521965
Loss at iteration 750 : 0.00844208337366581
Loss at iteration 760 : 0.010502627119421959
Loss at iteration 770 : 0.010232549160718918
Loss at iteration 780 : 0.011457915417850018
Loss at iteration 790 : 0.01121734082698822
Loss at iteration 800 : 0.01826939731836319
Loss at iteration 810 : 0.010610660538077354
Loss at iteration 820 : 0.006557305343449116
Loss at iteration 830 : 0.013249872252345085
Loss at iteration 840 : 0.007718217093497515
Loss at iteration 850 : 0.009265996515750885
Loss at iteration 860 : 0.011345328763127327
Loss at iteration 870 : 0.01064977701753378
Loss at iteration 880 : 0.013133980333805084
Loss at iteration 890 : 0.00531506072729826
Loss at iteration 900 : 0.01195582002401352
Loss at iteration 910 : 0.007715020328760147
Loss at iteration 920 : 0.0077149756252765656
Loss at iteration 930 : 0.014117790386080742
Loss at iteration 940 : 0.010739834979176521
Loss at iteration 950 : 0.015342891216278076
Loss at iteration 960 : 0.011778093874454498
Loss at iteration 970 : 0.006025065667927265
Loss at iteration 980 : 0.016619235277175903
Loss at iteration 990 : 0.007325901184231043
Loss at iteration 1000 : 0.007991960272192955
Loss at iteration 1010 : 0.014823053032159805
Loss at iteration 1020 : 0.011005597189068794
Loss at iteration 1030 : 0.007848825305700302
Loss at iteration 1040 : 0.014483405277132988
Loss at iteration 1050 : 0.015428289771080017
Loss at iteration 1060 : 0.009330658242106438
Loss at iteration 1070 : 0.013843131251633167
Loss at iteration 1080 : 0.009437738917768002
Loss at iteration 1090 : 0.007714568171650171
Loss at iteration 1100 : 0.012533276341855526
Loss at iteration 1110 : 0.013692428357899189
Loss at iteration 1120 : 0.007334026973694563
Loss at iteration 1130 : 0.008961427956819534
Loss at iteration 1140 : 0.007720847148448229
Loss at iteration 1150 : 0.008618181571364403
Loss at iteration 1160 : 0.009386146441102028
Loss at iteration 1170 : 0.008896773681044579
Loss at iteration 1180 : 0.010816896334290504
Loss at iteration 1190 : 0.016626326367259026
Loss at iteration 1200 : 0.008733398281037807
Loss at iteration 1210 : 0.013774417340755463
The SSIM Value is: 0.7963103175163269
The PSNR Value is: 18.131450780232747
the epoch is: 125
Loss at iteration 10 : 0.010218247771263123
Loss at iteration 20 : 0.00785787496715784
Loss at iteration 30 : 0.01540203858166933
Loss at iteration 40 : 0.008293719962239265
Loss at iteration 50 : 0.010680925101041794
Loss at iteration 60 : 0.011015675030648708
Loss at iteration 70 : 0.014659895561635494
Loss at iteration 80 : 0.0058118742890655994
Loss at iteration 90 : 0.006299342028796673
Loss at iteration 100 : 0.018836408853530884
Loss at iteration 110 : 0.01346552837640047
Loss at iteration 120 : 0.010803809389472008
Loss at iteration 130 : 0.007713028229773045
Loss at iteration 140 : 0.01046704314649105
Loss at iteration 150 : 0.010564478114247322
Loss at iteration 160 : 0.009582442231476307
Loss at iteration 170 : 0.010982035659253597
Loss at iteration 180 : 0.006952403113245964
Loss at iteration 190 : 0.011601267382502556
Loss at iteration 200 : 0.008232524618506432
Loss at iteration 210 : 0.007239407394081354
Loss at iteration 220 : 0.01364928763359785
Loss at iteration 230 : 0.015214548446238041
Loss at iteration 240 : 0.006651497911661863
Loss at iteration 250 : 0.010415332391858101
Loss at iteration 260 : 0.012061739340424538
Loss at iteration 270 : 0.008452881127595901
Loss at iteration 280 : 0.014488703571259975
Loss at iteration 290 : 0.007056914269924164
Loss at iteration 300 : 0.005833899602293968
Loss at iteration 310 : 0.008071156218647957
Loss at iteration 320 : 0.013278762809932232
Loss at iteration 330 : 0.010348760522902012
Loss at iteration 340 : 0.013160282745957375
Loss at iteration 350 : 0.01138366386294365
Loss at iteration 360 : 0.0071731992065906525
Loss at iteration 370 : 0.011211864650249481
Loss at iteration 380 : 0.010947193019092083
Loss at iteration 390 : 0.014597322791814804
Loss at iteration 400 : 0.013078683987259865
Loss at iteration 410 : 0.01911196857690811
Loss at iteration 420 : 0.008832255378365517
Loss at iteration 430 : 0.009696537628769875
Loss at iteration 440 : 0.008882461115717888
Loss at iteration 450 : 0.01323862373828888
Loss at iteration 460 : 0.01056759525090456
Loss at iteration 470 : 0.01957562007009983
Loss at iteration 480 : 0.009214301593601704
Loss at iteration 490 : 0.012248112820088863
Loss at iteration 500 : 0.008521998301148415
Loss at iteration 510 : 0.00883954856544733
Loss at iteration 520 : 0.00800224021077156
Loss at iteration 530 : 0.006561219692230225
Loss at iteration 540 : 0.010358109138906002
Loss at iteration 550 : 0.009319193661212921
Loss at iteration 560 : 0.005507201422005892
Loss at iteration 570 : 0.012417741119861603
Loss at iteration 580 : 0.012212242931127548
Loss at iteration 590 : 0.013131516054272652
Loss at iteration 600 : 0.011331789195537567
Loss at iteration 610 : 0.0077394964173436165
Loss at iteration 620 : 0.008433321490883827
Loss at iteration 630 : 0.011721787974238396
Loss at iteration 640 : 0.007649180479347706
Loss at iteration 650 : 0.008547085337340832
Loss at iteration 660 : 0.01167462021112442
Loss at iteration 670 : 0.011001445353031158
Loss at iteration 680 : 0.008486652746796608
Loss at iteration 690 : 0.009801991283893585
Loss at iteration 700 : 0.012699689716100693
Loss at iteration 710 : 0.011775907129049301
Loss at iteration 720 : 0.006900608539581299
Loss at iteration 730 : 0.01104809995740652
Loss at iteration 740 : 0.01258852332830429
Loss at iteration 750 : 0.010955028235912323
Loss at iteration 760 : 0.01418296992778778
Loss at iteration 770 : 0.009838986210525036
Loss at iteration 780 : 0.010837450623512268
Loss at iteration 790 : 0.013794668018817902
Loss at iteration 800 : 0.007578971795737743
Loss at iteration 810 : 0.007222937420010567
Loss at iteration 820 : 0.012116159312427044
Loss at iteration 830 : 0.008701108396053314
Loss at iteration 840 : 0.009530390612781048
Loss at iteration 850 : 0.012319679372012615
Loss at iteration 860 : 0.013064015656709671
Loss at iteration 870 : 0.014748870395123959
Loss at iteration 880 : 0.01090805884450674
Loss at iteration 890 : 0.005842944141477346
Loss at iteration 900 : 0.006517648696899414
Loss at iteration 910 : 0.01042110938578844
Loss at iteration 920 : 0.011579579673707485
Loss at iteration 930 : 0.013612727634608746
Loss at iteration 940 : 0.008678887039422989
Loss at iteration 950 : 0.008711365982890129
Loss at iteration 960 : 0.0048509929329156876
Loss at iteration 970 : 0.009578931145370007
Loss at iteration 980 : 0.007340556941926479
Loss at iteration 990 : 0.0160781592130661
Loss at iteration 1000 : 0.014659021981060505
Loss at iteration 1010 : 0.009519999846816063
Loss at iteration 1020 : 0.008472091518342495
Loss at iteration 1030 : 0.010549779050052166
Loss at iteration 1040 : 0.009416784159839153
Loss at iteration 1050 : 0.009227564558386803
Loss at iteration 1060 : 0.008858414366841316
Loss at iteration 1070 : 0.01711869426071644
Loss at iteration 1080 : 0.012209759093821049
Loss at iteration 1090 : 0.010141495615243912
Loss at iteration 1100 : 0.016979996114969254
Loss at iteration 1110 : 0.0089359600096941
Loss at iteration 1120 : 0.011071564629673958
Loss at iteration 1130 : 0.006762560922652483
Loss at iteration 1140 : 0.00841069221496582
Loss at iteration 1150 : 0.014227110892534256
Loss at iteration 1160 : 0.010549447499215603
Loss at iteration 1170 : 0.012674507685005665
Loss at iteration 1180 : 0.014762879349291325
Loss at iteration 1190 : 0.0102739492431283
Loss at iteration 1200 : 0.009399531409144402
Loss at iteration 1210 : 0.010135089047253132
The SSIM Value is: 0.7821216185887655
The PSNR Value is: 17.601252365112305
the epoch is: 126
Loss at iteration 10 : 0.010971778072416782
Loss at iteration 20 : 0.008846580050885677
Loss at iteration 30 : 0.006201414857059717
Loss at iteration 40 : 0.010255328379571438
Loss at iteration 50 : 0.0059743607416749
Loss at iteration 60 : 0.007369816303253174
Loss at iteration 70 : 0.012439820915460587
Loss at iteration 80 : 0.0075342389754951
Loss at iteration 90 : 0.013843321241438389
Loss at iteration 100 : 0.006308199837803841
Loss at iteration 110 : 0.013069055043160915
Loss at iteration 120 : 0.009912433102726936
Loss at iteration 130 : 0.007927658036351204
Loss at iteration 140 : 0.007950862869620323
Loss at iteration 150 : 0.007160020060837269
Loss at iteration 160 : 0.013092536479234695
Loss at iteration 170 : 0.0051752617582678795
Loss at iteration 180 : 0.017893634736537933
Loss at iteration 190 : 0.007834852673113346
Loss at iteration 200 : 0.010902258567512035
Loss at iteration 210 : 0.0181746743619442
Loss at iteration 220 : 0.00844363309442997
Loss at iteration 230 : 0.013662481680512428
Loss at iteration 240 : 0.010149235837161541
Loss at iteration 250 : 0.009195743128657341
Loss at iteration 260 : 0.01742534711956978
Loss at iteration 270 : 0.014475200325250626
Loss at iteration 280 : 0.00464904448017478
Loss at iteration 290 : 0.006874478422105312
Loss at iteration 300 : 0.007899378426373005
Loss at iteration 310 : 0.016359856352210045
Loss at iteration 320 : 0.014396049082279205
Loss at iteration 330 : 0.014105219393968582
Loss at iteration 340 : 0.013571122661232948
Loss at iteration 350 : 0.010431965813040733
Loss at iteration 360 : 0.010718092322349548
Loss at iteration 370 : 0.009949076920747757
Loss at iteration 380 : 0.016570940613746643
Loss at iteration 390 : 0.012834711000323296
Loss at iteration 400 : 0.01467736903578043
Loss at iteration 410 : 0.012586051598191261
Loss at iteration 420 : 0.013340397737920284
Loss at iteration 430 : 0.013671135529875755
Loss at iteration 440 : 0.009427716955542564
Loss at iteration 450 : 0.005647868849337101
Loss at iteration 460 : 0.005353756248950958
Loss at iteration 470 : 0.012799367308616638
Loss at iteration 480 : 0.008384631015360355
Loss at iteration 490 : 0.008342793211340904
Loss at iteration 500 : 0.012960587628185749
Loss at iteration 510 : 0.007636655122041702
Loss at iteration 520 : 0.007406629156321287
Loss at iteration 530 : 0.0077783698216080666
Loss at iteration 540 : 0.009178710170090199
Loss at iteration 550 : 0.011999595910310745
Loss at iteration 560 : 0.009552465751767159
Loss at iteration 570 : 0.013099483214318752
Loss at iteration 580 : 0.007548223249614239
Loss at iteration 590 : 0.006303984671831131
Loss at iteration 600 : 0.00771754514425993
Loss at iteration 610 : 0.01229098066687584
Loss at iteration 620 : 0.01167481578886509
Loss at iteration 630 : 0.010504649020731449
Loss at iteration 640 : 0.008174675516784191
Loss at iteration 650 : 0.00999679509550333
Loss at iteration 660 : 0.021249040961265564
Loss at iteration 670 : 0.01623579114675522
Loss at iteration 680 : 0.015258664265275002
Loss at iteration 690 : 0.013422424905002117
Loss at iteration 700 : 0.009093135595321655
Loss at iteration 710 : 0.008846839889883995
Loss at iteration 720 : 0.008217595517635345
Loss at iteration 730 : 0.010077226907014847
Loss at iteration 740 : 0.013809206895530224
Loss at iteration 750 : 0.008952694945037365
Loss at iteration 760 : 0.0119551382958889
Loss at iteration 770 : 0.008862124755978584
Loss at iteration 780 : 0.011723430827260017
Loss at iteration 790 : 0.0091474037617445
Loss at iteration 800 : 0.016100730746984482
Loss at iteration 810 : 0.008885006420314312
Loss at iteration 820 : 0.008080193772912025
Loss at iteration 830 : 0.007117456290870905
Loss at iteration 840 : 0.013744208961725235
Loss at iteration 850 : 0.014197733253240585
Loss at iteration 860 : 0.011368300765752792
Loss at iteration 870 : 0.014116906560957432
Loss at iteration 880 : 0.009317601099610329
Loss at iteration 890 : 0.013894166797399521
Loss at iteration 900 : 0.009303592145442963
Loss at iteration 910 : 0.021280914545059204
Loss at iteration 920 : 0.009766164235770702
Loss at iteration 930 : 0.00574459508061409
Loss at iteration 940 : 0.008327208459377289
Loss at iteration 950 : 0.01257566548883915
Loss at iteration 960 : 0.00791684165596962
Loss at iteration 970 : 0.007657131180167198
Loss at iteration 980 : 0.007619637995958328
Loss at iteration 990 : 0.0079202800989151
Loss at iteration 1000 : 0.013767139054834843
Loss at iteration 1010 : 0.006619100924581289
Loss at iteration 1020 : 0.01354202814400196
Loss at iteration 1030 : 0.010556813329458237
Loss at iteration 1040 : 0.005907955579459667
Loss at iteration 1050 : 0.01152584608644247
Loss at iteration 1060 : 0.011813664808869362
Loss at iteration 1070 : 0.009203564375638962
Loss at iteration 1080 : 0.009606881998479366
Loss at iteration 1090 : 0.01120918057858944
Loss at iteration 1100 : 0.01758347451686859
Loss at iteration 1110 : 0.013136320747435093
Loss at iteration 1120 : 0.01250508800148964
Loss at iteration 1130 : 0.008986063301563263
Loss at iteration 1140 : 0.018106533214449883
Loss at iteration 1150 : 0.010535970330238342
Loss at iteration 1160 : 0.009100553579628468
Loss at iteration 1170 : 0.01245412603020668
Loss at iteration 1180 : 0.013025933876633644
Loss at iteration 1190 : 0.008686432614922523
Loss at iteration 1200 : 0.010873416438698769
Loss at iteration 1210 : 0.03706890344619751
The SSIM Value is: 0.80899578332901
The PSNR Value is: 18.67105795542399
the epoch is: 127
Loss at iteration 10 : 0.007895667105913162
Loss at iteration 20 : 0.009574479423463345
Loss at iteration 30 : 0.007681793998926878
Loss at iteration 40 : 0.029165606945753098
Loss at iteration 50 : 0.010587964206933975
Loss at iteration 60 : 0.012795795686542988
Loss at iteration 70 : 0.010599002242088318
Loss at iteration 80 : 0.008809152990579605
Loss at iteration 90 : 0.01390431821346283
Loss at iteration 100 : 0.012996616773307323
Loss at iteration 110 : 0.01060970313847065
Loss at iteration 120 : 0.010442513972520828
Loss at iteration 130 : 0.011946282349526882
Loss at iteration 140 : 0.00840251985937357
Loss at iteration 150 : 0.009558234363794327
Loss at iteration 160 : 0.013219036161899567
Loss at iteration 170 : 0.014003746211528778
Loss at iteration 180 : 0.01342064794152975
Loss at iteration 190 : 0.010504348203539848
Loss at iteration 200 : 0.00658275093883276
Loss at iteration 210 : 0.008016395382583141
Loss at iteration 220 : 0.008109724149107933
Loss at iteration 230 : 0.005216730758547783
Loss at iteration 240 : 0.017417006194591522
Loss at iteration 250 : 0.00906138401478529
Loss at iteration 260 : 0.009165430441498756
Loss at iteration 270 : 0.013316837139427662
Loss at iteration 280 : 0.013819467276334763
Loss at iteration 290 : 0.009719238616526127
Loss at iteration 300 : 0.012655224651098251
Loss at iteration 310 : 0.008518495596945286
Loss at iteration 320 : 0.008475844748318195
Loss at iteration 330 : 0.008520585484802723
Loss at iteration 340 : 0.014465566724538803
Loss at iteration 350 : 0.01208097580820322
Loss at iteration 360 : 0.011610549874603748
Loss at iteration 370 : 0.007623677607625723
Loss at iteration 380 : 0.012278028763830662
Loss at iteration 390 : 0.009197337552905083
Loss at iteration 400 : 0.009882485494017601
Loss at iteration 410 : 0.008872514590620995
Loss at iteration 420 : 0.012559968046844006
Loss at iteration 430 : 0.011952156201004982
Loss at iteration 440 : 0.008609886281192303
Loss at iteration 450 : 0.011983253061771393
Loss at iteration 460 : 0.007927436381578445
Loss at iteration 470 : 0.012160754762589931
Loss at iteration 480 : 0.01367846131324768
Loss at iteration 490 : 0.0074972668662667274
Loss at iteration 500 : 0.008411450311541557
Loss at iteration 510 : 0.012289376929402351
Loss at iteration 520 : 0.0086506437510252
Loss at iteration 530 : 0.0069600255228579044
Loss at iteration 540 : 0.012118110433220863
Loss at iteration 550 : 0.005131134297698736
Loss at iteration 560 : 0.019870923832058907
Loss at iteration 570 : 0.011115173809230328
Loss at iteration 580 : 0.008211109787225723
Loss at iteration 590 : 0.010294760577380657
Loss at iteration 600 : 0.010576250962913036
Loss at iteration 610 : 0.008153241127729416
Loss at iteration 620 : 0.008107328787446022
Loss at iteration 630 : 0.008911130018532276
Loss at iteration 640 : 0.011930038221180439
Loss at iteration 650 : 0.007542050909250975
Loss at iteration 660 : 0.011258382350206375
Loss at iteration 670 : 0.012228254228830338
Loss at iteration 680 : 0.02056901343166828
Loss at iteration 690 : 0.010227792896330357
Loss at iteration 700 : 0.009212939999997616
Loss at iteration 710 : 0.008950582705438137
Loss at iteration 720 : 0.009041453711688519
Loss at iteration 730 : 0.009098004549741745
Loss at iteration 740 : 0.011338815093040466
Loss at iteration 750 : 0.015019586309790611
Loss at iteration 760 : 0.008037375286221504
Loss at iteration 770 : 0.017084205523133278
Loss at iteration 780 : 0.01330391876399517
Loss at iteration 790 : 0.013085144571959972
Loss at iteration 800 : 0.010758689604699612
Loss at iteration 810 : 0.007662808522582054
Loss at iteration 820 : 0.009422063827514648
Loss at iteration 830 : 0.00820531602948904
Loss at iteration 840 : 0.016662511974573135
Loss at iteration 850 : 0.006339044775813818
Loss at iteration 860 : 0.014178476296365261
Loss at iteration 870 : 0.008276420645415783
Loss at iteration 880 : 0.008805093355476856
Loss at iteration 890 : 0.007285588886588812
Loss at iteration 900 : 0.010515497997403145
Loss at iteration 910 : 0.008910493925213814
Loss at iteration 920 : 0.010590911842882633
Loss at iteration 930 : 0.010363210923969746
Loss at iteration 940 : 0.007513696327805519
Loss at iteration 950 : 0.009397740475833416
Loss at iteration 960 : 0.00970377866178751
Loss at iteration 970 : 0.012644500471651554
Loss at iteration 980 : 0.009081024676561356
Loss at iteration 990 : 0.0085797980427742
Loss at iteration 1000 : 0.007730420678853989
Loss at iteration 1010 : 0.007151703350245953
Loss at iteration 1020 : 0.021217280998826027
Loss at iteration 1030 : 0.008750295266509056
Loss at iteration 1040 : 0.009098351933062077
Loss at iteration 1050 : 0.009301864542067051
Loss at iteration 1060 : 0.008343486115336418
Loss at iteration 1070 : 0.012213233858346939
Loss at iteration 1080 : 0.006423585116863251
Loss at iteration 1090 : 0.00820002518594265
Loss at iteration 1100 : 0.010251237079501152
Loss at iteration 1110 : 0.023085476830601692
Loss at iteration 1120 : 0.007451219484210014
Loss at iteration 1130 : 0.009744485840201378
Loss at iteration 1140 : 0.010394091717898846
Loss at iteration 1150 : 0.012419313192367554
Loss at iteration 1160 : 0.009687293320894241
Loss at iteration 1170 : 0.010299207642674446
Loss at iteration 1180 : 0.008083125576376915
Loss at iteration 1190 : 0.008987868204712868
Loss at iteration 1200 : 0.011995043605566025
Loss at iteration 1210 : 0.013190471567213535
The SSIM Value is: 0.801387635866801
The PSNR Value is: 18.318744214375815
the epoch is: 128
Loss at iteration 10 : 0.007443813607096672
Loss at iteration 20 : 0.009267006069421768
Loss at iteration 30 : 0.011964919976890087
Loss at iteration 40 : 0.01156093180179596
Loss at iteration 50 : 0.007836776785552502
Loss at iteration 60 : 0.013566904701292515
Loss at iteration 70 : 0.007777292747050524
Loss at iteration 80 : 0.010482877492904663
Loss at iteration 90 : 0.007792217656970024
Loss at iteration 100 : 0.011403662152588367
Loss at iteration 110 : 0.008466539904475212
Loss at iteration 120 : 0.011703871190547943
Loss at iteration 130 : 0.012435884214937687
Loss at iteration 140 : 0.010974982753396034
Loss at iteration 150 : 0.012903652153909206
Loss at iteration 160 : 0.013295169919729233
Loss at iteration 170 : 0.013228391297161579
Loss at iteration 180 : 0.01619582809507847
Loss at iteration 190 : 0.015502361580729485
Loss at iteration 200 : 0.008034552447497845
Loss at iteration 210 : 0.012436081655323505
Loss at iteration 220 : 0.0059783244505524635
Loss at iteration 230 : 0.007082831580191851
Loss at iteration 240 : 0.015727490186691284
Loss at iteration 250 : 0.016441846266388893
Loss at iteration 260 : 0.009592998772859573
Loss at iteration 270 : 0.006546906661242247
Loss at iteration 280 : 0.007641546428203583
Loss at iteration 290 : 0.010226719081401825
Loss at iteration 300 : 0.006811556406319141
Loss at iteration 310 : 0.011046474799513817
Loss at iteration 320 : 0.015747491270303726
Loss at iteration 330 : 0.017797984182834625
Loss at iteration 340 : 0.01414016354829073
Loss at iteration 350 : 0.012120882049202919
Loss at iteration 360 : 0.007893966510891914
Loss at iteration 370 : 0.011719835922122002
Loss at iteration 380 : 0.009584685787558556
Loss at iteration 390 : 0.012489923276007175
Loss at iteration 400 : 0.0065937042236328125
Loss at iteration 410 : 0.010910054668784142
Loss at iteration 420 : 0.015936030074954033
Loss at iteration 430 : 0.008874191902577877
Loss at iteration 440 : 0.008379977196455002
Loss at iteration 450 : 0.006008865311741829
Loss at iteration 460 : 0.015532668679952621
Loss at iteration 470 : 0.010365855880081654
Loss at iteration 480 : 0.01175091601908207
Loss at iteration 490 : 0.007260007783770561
Loss at iteration 500 : 0.012773153372108936
Loss at iteration 510 : 0.011553347110748291
Loss at iteration 520 : 0.007082365453243256
Loss at iteration 530 : 0.007597166113555431
Loss at iteration 540 : 0.006686661392450333
Loss at iteration 550 : 0.010577524080872536
Loss at iteration 560 : 0.011808007955551147
Loss at iteration 570 : 0.0064800456166267395
Loss at iteration 580 : 0.011659746989607811
Loss at iteration 590 : 0.0063698142766952515
Loss at iteration 600 : 0.009166467934846878
Loss at iteration 610 : 0.01052582822740078
Loss at iteration 620 : 0.009023853577673435
Loss at iteration 630 : 0.007838716730475426
Loss at iteration 640 : 0.008329064585268497
Loss at iteration 650 : 0.005890531465411186
Loss at iteration 660 : 0.007275654934346676
Loss at iteration 670 : 0.011154803447425365
Loss at iteration 680 : 0.014343337155878544
Loss at iteration 690 : 0.014771515503525734
Loss at iteration 700 : 0.0072083440609276295
Loss at iteration 710 : 0.010572118684649467
Loss at iteration 720 : 0.011885911226272583
Loss at iteration 730 : 0.009704393334686756
Loss at iteration 740 : 0.008862292394042015
Loss at iteration 750 : 0.014477347023785114
Loss at iteration 760 : 0.01307265181094408
Loss at iteration 770 : 0.01257365196943283
Loss at iteration 780 : 0.008690766990184784
Loss at iteration 790 : 0.008578591048717499
Loss at iteration 800 : 0.008495270274579525
Loss at iteration 810 : 0.007700262125581503
Loss at iteration 820 : 0.017275474965572357
Loss at iteration 830 : 0.008463678881525993
Loss at iteration 840 : 0.011797716841101646
Loss at iteration 850 : 0.009443627670407295
Loss at iteration 860 : 0.008913379162549973
Loss at iteration 870 : 0.004798769950866699
Loss at iteration 880 : 0.016826333478093147
Loss at iteration 890 : 0.009408533573150635
Loss at iteration 900 : 0.022619593888521194
Loss at iteration 910 : 0.00930698774755001
Loss at iteration 920 : 0.007119928952306509
Loss at iteration 930 : 0.010835802182555199
Loss at iteration 940 : 0.013856295496225357
Loss at iteration 950 : 0.011594048701226711
Loss at iteration 960 : 0.009051069617271423
Loss at iteration 970 : 0.009276146069169044
Loss at iteration 980 : 0.009678022935986519
Loss at iteration 990 : 0.007611491717398167
Loss at iteration 1000 : 0.008097092621028423
Loss at iteration 1010 : 0.011616496369242668
Loss at iteration 1020 : 0.00778280571103096
Loss at iteration 1030 : 0.005997501313686371
Loss at iteration 1040 : 0.00875324197113514
Loss at iteration 1050 : 0.010039267130196095
Loss at iteration 1060 : 0.00748648913577199
Loss at iteration 1070 : 0.006025640293955803
Loss at iteration 1080 : 0.01327715814113617
Loss at iteration 1090 : 0.010861575603485107
Loss at iteration 1100 : 0.009523235261440277
Loss at iteration 1110 : 0.012185508385300636
Loss at iteration 1120 : 0.009731404483318329
Loss at iteration 1130 : 0.012779958546161652
Loss at iteration 1140 : 0.009571150876581669
Loss at iteration 1150 : 0.01372060738503933
Loss at iteration 1160 : 0.006533440668135881
Loss at iteration 1170 : 0.010965971276164055
Loss at iteration 1180 : 0.010588325560092926
Loss at iteration 1190 : 0.008638020604848862
Loss at iteration 1200 : 0.010774947702884674
Loss at iteration 1210 : 0.006258299574255943
The SSIM Value is: 0.8029253045717876
The PSNR Value is: 18.39845561981201
the epoch is: 129
Loss at iteration 10 : 0.0088657783344388
Loss at iteration 20 : 0.009534000419080257
Loss at iteration 30 : 0.011403493583202362
Loss at iteration 40 : 0.006352534051984549
Loss at iteration 50 : 0.02567574940621853
Loss at iteration 60 : 0.011692367494106293
Loss at iteration 70 : 0.011913524009287357
Loss at iteration 80 : 0.01323679368942976
Loss at iteration 90 : 0.014393098652362823
Loss at iteration 100 : 0.014333085156977177
Loss at iteration 110 : 0.007872944697737694
Loss at iteration 120 : 0.006319353822618723
Loss at iteration 130 : 0.011570868082344532
Loss at iteration 140 : 0.013489717617630959
Loss at iteration 150 : 0.009755988605320454
Loss at iteration 160 : 0.009776147082448006
Loss at iteration 170 : 0.009260586462914944
Loss at iteration 180 : 0.014339311048388481
Loss at iteration 190 : 0.011096615344285965
Loss at iteration 200 : 0.016828153282403946
Loss at iteration 210 : 0.014163410291075706
Loss at iteration 220 : 0.013188663870096207
Loss at iteration 230 : 0.014631347730755806
Loss at iteration 240 : 0.010468851774930954
Loss at iteration 250 : 0.011289212852716446
Loss at iteration 260 : 0.010396836325526237
Loss at iteration 270 : 0.009599466808140278
Loss at iteration 280 : 0.010745899751782417
Loss at iteration 290 : 0.008335242979228497
Loss at iteration 300 : 0.013075890019536018
Loss at iteration 310 : 0.0073849353939294815
Loss at iteration 320 : 0.007359480019658804
Loss at iteration 330 : 0.009968623518943787
Loss at iteration 340 : 0.012782933190464973
Loss at iteration 350 : 0.01738397777080536
Loss at iteration 360 : 0.006820161826908588
Loss at iteration 370 : 0.010394347831606865
Loss at iteration 380 : 0.014301269315183163
Loss at iteration 390 : 0.010705179534852505
Loss at iteration 400 : 0.014812985435128212
Loss at iteration 410 : 0.011591194197535515
Loss at iteration 420 : 0.010309398174285889
Loss at iteration 430 : 0.005655617453157902
Loss at iteration 440 : 0.011831180192530155
Loss at iteration 450 : 0.006887437775731087
Loss at iteration 460 : 0.006508472375571728
Loss at iteration 470 : 0.00668712891638279
Loss at iteration 480 : 0.0131907407194376
Loss at iteration 490 : 0.012777136638760567
Loss at iteration 500 : 0.01160118542611599
Loss at iteration 510 : 0.010929125361144543
Loss at iteration 520 : 0.012124787084758282
Loss at iteration 530 : 0.012718387879431248
Loss at iteration 540 : 0.00850814301520586
Loss at iteration 550 : 0.010449262335896492
Loss at iteration 560 : 0.0179623831063509
Loss at iteration 570 : 0.014329404570162296
Loss at iteration 580 : 0.010408633388578892
Loss at iteration 590 : 0.007434437982738018
Loss at iteration 600 : 0.009831503964960575
Loss at iteration 610 : 0.012653589248657227
Loss at iteration 620 : 0.008173910900950432
Loss at iteration 630 : 0.011165885254740715
Loss at iteration 640 : 0.008015641942620277
Loss at iteration 650 : 0.009470826014876366
Loss at iteration 660 : 0.011975382454693317
Loss at iteration 670 : 0.015860825777053833
Loss at iteration 680 : 0.012914384715259075
Loss at iteration 690 : 0.014862134121358395
Loss at iteration 700 : 0.008266521617770195
Loss at iteration 710 : 0.00759989395737648
Loss at iteration 720 : 0.006657182704657316
Loss at iteration 730 : 0.010495137423276901
Loss at iteration 740 : 0.009300715290009975
Loss at iteration 750 : 0.00867569912225008
Loss at iteration 760 : 0.010689917951822281
Loss at iteration 770 : 0.009249717928469181
Loss at iteration 780 : 0.007736345287412405
Loss at iteration 790 : 0.00999581627547741
Loss at iteration 800 : 0.008644157089293003
Loss at iteration 810 : 0.0103069506585598
Loss at iteration 820 : 0.008531552739441395
Loss at iteration 830 : 0.015300390310585499
Loss at iteration 840 : 0.0087588494643569
Loss at iteration 850 : 0.007840290665626526
Loss at iteration 860 : 0.009729375131428242
Loss at iteration 870 : 0.0067421807907521725
Loss at iteration 880 : 0.005358289461582899
Loss at iteration 890 : 0.006457928102463484
Loss at iteration 900 : 0.0047478266060352325
Loss at iteration 910 : 0.015291523188352585
Loss at iteration 920 : 0.008916027843952179
Loss at iteration 930 : 0.009012822061777115
Loss at iteration 940 : 0.01107631716877222
Loss at iteration 950 : 0.007156533654779196
Loss at iteration 960 : 0.011389435268938541
Loss at iteration 970 : 0.009499460458755493
Loss at iteration 980 : 0.010583418421447277
Loss at iteration 990 : 0.008986752480268478
Loss at iteration 1000 : 0.00737660750746727
Loss at iteration 1010 : 0.010053347796201706
Loss at iteration 1020 : 0.014552943408489227
Loss at iteration 1030 : 0.01178022287786007
Loss at iteration 1040 : 0.004126867279410362
Loss at iteration 1050 : 0.015752434730529785
Loss at iteration 1060 : 0.007708256598562002
Loss at iteration 1070 : 0.007428512908518314
Loss at iteration 1080 : 0.009352490305900574
Loss at iteration 1090 : 0.011909471824765205
Loss at iteration 1100 : 0.011368850246071815
Loss at iteration 1110 : 0.016136793419718742
Loss at iteration 1120 : 0.008419731631875038
Loss at iteration 1130 : 0.016610797494649887
Loss at iteration 1140 : 0.022352684289216995
Loss at iteration 1150 : 0.0061162556521594524
Loss at iteration 1160 : 0.009408886544406414
Loss at iteration 1170 : 0.014132964424788952
Loss at iteration 1180 : 0.013857986778020859
Loss at iteration 1190 : 0.01347571611404419
Loss at iteration 1200 : 0.017414532601833344
Loss at iteration 1210 : 0.012562930583953857
The SSIM Value is: 0.8089167475700378
The PSNR Value is: 18.77358226776123
the epoch is: 130
Loss at iteration 10 : 0.014661712571978569
Loss at iteration 20 : 0.00927877426147461
Loss at iteration 30 : 0.006696148309856653
Loss at iteration 40 : 0.010613066144287586
Loss at iteration 50 : 0.00871096272021532
Loss at iteration 60 : 0.011604259721934795
Loss at iteration 70 : 0.004672327544540167
Loss at iteration 80 : 0.010525355115532875
Loss at iteration 90 : 0.011577565222978592
Loss at iteration 100 : 0.011053269729018211
Loss at iteration 110 : 0.012907220050692558
Loss at iteration 120 : 0.0064905909821391106
Loss at iteration 130 : 0.013816457241773605
Loss at iteration 140 : 0.006848692428320646
Loss at iteration 150 : 0.007893841713666916
Loss at iteration 160 : 0.006950429640710354
Loss at iteration 170 : 0.006242825649678707
Loss at iteration 180 : 0.006597380619496107
Loss at iteration 190 : 0.013221649453043938
Loss at iteration 200 : 0.012479990720748901
Loss at iteration 210 : 0.0075974115170538425
Loss at iteration 220 : 0.004358748905360699
Loss at iteration 230 : 0.01000669039785862
Loss at iteration 240 : 0.011043725535273552
Loss at iteration 250 : 0.013266533613204956
Loss at iteration 260 : 0.012547804974019527
Loss at iteration 270 : 0.008411994203925133
Loss at iteration 280 : 0.008039443753659725
Loss at iteration 290 : 0.016574569046497345
Loss at iteration 300 : 0.011856196448206902
Loss at iteration 310 : 0.011451952159404755
Loss at iteration 320 : 0.011749726720154285
Loss at iteration 330 : 0.013538794592022896
Loss at iteration 340 : 0.008918887004256248
Loss at iteration 350 : 0.009032144211232662
Loss at iteration 360 : 0.006688883528113365
Loss at iteration 370 : 0.013685140758752823
Loss at iteration 380 : 0.018988600000739098
Loss at iteration 390 : 0.007726164069026709
Loss at iteration 400 : 0.014206121675670147
Loss at iteration 410 : 0.010096552781760693
Loss at iteration 420 : 0.007863504812121391
Loss at iteration 430 : 0.0111640440300107
Loss at iteration 440 : 0.00954949390143156
Loss at iteration 450 : 0.007950054481625557
Loss at iteration 460 : 0.011936891824007034
Loss at iteration 470 : 0.007530632894486189
Loss at iteration 480 : 0.01202945876866579
Loss at iteration 490 : 0.008486117236316204
Loss at iteration 500 : 0.014742563478648663
Loss at iteration 510 : 0.005623314529657364
Loss at iteration 520 : 0.008842508308589458
Loss at iteration 530 : 0.019513359293341637
Loss at iteration 540 : 0.007148168049752712
Loss at iteration 550 : 0.007468365132808685
Loss at iteration 560 : 0.007427365519106388
Loss at iteration 570 : 0.00961319450289011
Loss at iteration 580 : 0.009989029727876186
Loss at iteration 590 : 0.008419468067586422
Loss at iteration 600 : 0.010941946879029274
Loss at iteration 610 : 0.009160912595689297
Loss at iteration 620 : 0.01372236106544733
Loss at iteration 630 : 0.007545389235019684
Loss at iteration 640 : 0.008592342957854271
Loss at iteration 650 : 0.00809202529489994
Loss at iteration 660 : 0.007470458745956421
Loss at iteration 670 : 0.02073027938604355
Loss at iteration 680 : 0.015559840947389603
Loss at iteration 690 : 0.014970305375754833
Loss at iteration 700 : 0.013553677126765251
Loss at iteration 710 : 0.00827779807150364
Loss at iteration 720 : 0.014219998382031918
Loss at iteration 730 : 0.010083617642521858
Loss at iteration 740 : 0.008693857118487358
Loss at iteration 750 : 0.013170561753213406
Loss at iteration 760 : 0.008325639180839062
Loss at iteration 770 : 0.00841120257973671
Loss at iteration 780 : 0.013763217255473137
Loss at iteration 790 : 0.009235480800271034
Loss at iteration 800 : 0.008124439977109432
Loss at iteration 810 : 0.005887937266379595
Loss at iteration 820 : 0.006488381419330835
Loss at iteration 830 : 0.010295470245182514
Loss at iteration 840 : 0.01155907940119505
Loss at iteration 850 : 0.010723933577537537
Loss at iteration 860 : 0.011546056717634201
Loss at iteration 870 : 0.010210221633315086
Loss at iteration 880 : 0.008118870668113232
Loss at iteration 890 : 0.011797923594713211
Loss at iteration 900 : 0.011582482606172562
Loss at iteration 910 : 0.015891622751951218
Loss at iteration 920 : 0.007170090451836586
Loss at iteration 930 : 0.010396585799753666
Loss at iteration 940 : 0.008306635543704033
Loss at iteration 950 : 0.007375813089311123
Loss at iteration 960 : 0.013618807308375835
Loss at iteration 970 : 0.011745598167181015
Loss at iteration 980 : 0.012072171084582806
Loss at iteration 990 : 0.007091576233506203
Loss at iteration 1000 : 0.013177769258618355
Loss at iteration 1010 : 0.00927774515002966
Loss at iteration 1020 : 0.019604338333010674
Loss at iteration 1030 : 0.008715644478797913
Loss at iteration 1040 : 0.007668924052268267
Loss at iteration 1050 : 0.013386974111199379
Loss at iteration 1060 : 0.010058492422103882
Loss at iteration 1070 : 0.011842112988233566
Loss at iteration 1080 : 0.010010137222707272
Loss at iteration 1090 : 0.006817749701440334
Loss at iteration 1100 : 0.008983531035482883
Loss at iteration 1110 : 0.01148978341370821
Loss at iteration 1120 : 0.011869141831994057
Loss at iteration 1130 : 0.011005855165421963
Loss at iteration 1140 : 0.0042841169051826
Loss at iteration 1150 : 0.009031064808368683
Loss at iteration 1160 : 0.01001205574721098
Loss at iteration 1170 : 0.006727705243974924
Loss at iteration 1180 : 0.010507052764296532
Loss at iteration 1190 : 0.011759641580283642
Loss at iteration 1200 : 0.015448398888111115
Loss at iteration 1210 : 0.0067896428517997265
The SSIM Value is: 0.805451222260793
The PSNR Value is: 18.746400515238445
the epoch is: 131
Loss at iteration 10 : 0.00771618215367198
Loss at iteration 20 : 0.007334246300160885
Loss at iteration 30 : 0.005850343499332666
Loss at iteration 40 : 0.011654907837510109
Loss at iteration 50 : 0.01071887742727995
Loss at iteration 60 : 0.007753174286335707
Loss at iteration 70 : 0.009087015874683857
Loss at iteration 80 : 0.00531880185008049
Loss at iteration 90 : 0.005443800240755081
Loss at iteration 100 : 0.007312681060284376
Loss at iteration 110 : 0.0211405660957098
Loss at iteration 120 : 0.0064275311306118965
Loss at iteration 130 : 0.007142053451389074
Loss at iteration 140 : 0.01221364364027977
Loss at iteration 150 : 0.017402280122041702
Loss at iteration 160 : 0.010481078177690506
Loss at iteration 170 : 0.012870244681835175
Loss at iteration 180 : 0.010840626433491707
Loss at iteration 190 : 0.010783635079860687
Loss at iteration 200 : 0.011988053098320961
Loss at iteration 210 : 0.013140685856342316
Loss at iteration 220 : 0.008017480373382568
Loss at iteration 230 : 0.018288515508174896
Loss at iteration 240 : 0.008818309754133224
Loss at iteration 250 : 0.012091228738427162
Loss at iteration 260 : 0.00884558167308569
Loss at iteration 270 : 0.012526857666671276
Loss at iteration 280 : 0.015005195513367653
Loss at iteration 290 : 0.011274116113781929
Loss at iteration 300 : 0.00797602441161871
Loss at iteration 310 : 0.010348265059292316
Loss at iteration 320 : 0.011399747803807259
Loss at iteration 330 : 0.01834338717162609
Loss at iteration 340 : 0.01088619977235794
Loss at iteration 350 : 0.020641755312681198
Loss at iteration 360 : 0.010619797743856907
Loss at iteration 370 : 0.009745215997099876
Loss at iteration 380 : 0.008637159131467342
Loss at iteration 390 : 0.007310798391699791
Loss at iteration 400 : 0.0071286894381046295
Loss at iteration 410 : 0.0063734715804457664
Loss at iteration 420 : 0.007509864866733551
Loss at iteration 430 : 0.010156775824725628
Loss at iteration 440 : 0.010187274776399136
Loss at iteration 450 : 0.02221066877245903
Loss at iteration 460 : 0.011389024555683136
Loss at iteration 470 : 0.011127112433314323
Loss at iteration 480 : 0.009126463904976845
Loss at iteration 490 : 0.005857274867594242
Loss at iteration 500 : 0.010326970368623734
Loss at iteration 510 : 0.005462226923555136
Loss at iteration 520 : 0.014431299641728401
Loss at iteration 530 : 0.007017260417342186
Loss at iteration 540 : 0.01227396447211504
Loss at iteration 550 : 0.011631323955953121
Loss at iteration 560 : 0.009376058354973793
Loss at iteration 570 : 0.0124400295317173
Loss at iteration 580 : 0.015816891565918922
Loss at iteration 590 : 0.0072182477451860905
Loss at iteration 600 : 0.0067734564654529095
Loss at iteration 610 : 0.010089018382132053
Loss at iteration 620 : 0.007250690367072821
Loss at iteration 630 : 0.006574150174856186
Loss at iteration 640 : 0.008551105856895447
Loss at iteration 650 : 0.011788427829742432
Loss at iteration 660 : 0.012242710217833519
Loss at iteration 670 : 0.013884171843528748
Loss at iteration 680 : 0.012110985815525055
Loss at iteration 690 : 0.012558035552501678
Loss at iteration 700 : 0.013564018532633781
Loss at iteration 710 : 0.015117036178708076
Loss at iteration 720 : 0.0059960875660181046
Loss at iteration 730 : 0.012404247187077999
Loss at iteration 740 : 0.015352637507021427
Loss at iteration 750 : 0.01508445292711258
Loss at iteration 760 : 0.011873321607708931
Loss at iteration 770 : 0.008834781125187874
Loss at iteration 780 : 0.014599325135350227
Loss at iteration 790 : 0.020282361656427383
Loss at iteration 800 : 0.011575362645089626
Loss at iteration 810 : 0.007688144221901894
Loss at iteration 820 : 0.00763319805264473
Loss at iteration 830 : 0.0051703080534935
Loss at iteration 840 : 0.009416102431714535
Loss at iteration 850 : 0.016965486109256744
Loss at iteration 860 : 0.01224895566701889
Loss at iteration 870 : 0.005967508070170879
Loss at iteration 880 : 0.00802026130259037
Loss at iteration 890 : 0.008070038631558418
Loss at iteration 900 : 0.010331564582884312
Loss at iteration 910 : 0.01665959507226944
Loss at iteration 920 : 0.012863606214523315
Loss at iteration 930 : 0.010830812156200409
Loss at iteration 940 : 0.01483924686908722
Loss at iteration 950 : 0.010319371707737446
Loss at iteration 960 : 0.00819410290569067
Loss at iteration 970 : 0.01406954601407051
Loss at iteration 980 : 0.006698625162243843
Loss at iteration 990 : 0.010432938113808632
Loss at iteration 1000 : 0.010573353618383408
Loss at iteration 1010 : 0.007209299132227898
Loss at iteration 1020 : 0.009570799767971039
Loss at iteration 1030 : 0.007637324742972851
Loss at iteration 1040 : 0.009897645562887192
Loss at iteration 1050 : 0.011350242421030998
Loss at iteration 1060 : 0.007127722259610891
Loss at iteration 1070 : 0.004855295177549124
Loss at iteration 1080 : 0.012655900791287422
Loss at iteration 1090 : 0.009065454825758934
Loss at iteration 1100 : 0.010112841613590717
Loss at iteration 1110 : 0.006090178620070219
Loss at iteration 1120 : 0.005536566022783518
Loss at iteration 1130 : 0.017277289181947708
Loss at iteration 1140 : 0.006468335632234812
Loss at iteration 1150 : 0.00908992625772953
Loss at iteration 1160 : 0.010256360284984112
Loss at iteration 1170 : 0.01569916307926178
Loss at iteration 1180 : 0.010100586339831352
Loss at iteration 1190 : 0.009926896542310715
Loss at iteration 1200 : 0.00913785956799984
Loss at iteration 1210 : 0.010733574628829956
The SSIM Value is: 0.8035331885019938
The PSNR Value is: 18.68046455383301
the epoch is: 132
Loss at iteration 10 : 0.01053164154291153
Loss at iteration 20 : 0.015527097508311272
Loss at iteration 30 : 0.009003156796097755
Loss at iteration 40 : 0.009908133186399937
Loss at iteration 50 : 0.012705204077064991
Loss at iteration 60 : 0.010132838040590286
Loss at iteration 70 : 0.010184616781771183
Loss at iteration 80 : 0.007727464195340872
Loss at iteration 90 : 0.00742343021556735
Loss at iteration 100 : 0.012636877596378326
Loss at iteration 110 : 0.007778544444590807
Loss at iteration 120 : 0.005813542753458023
Loss at iteration 130 : 0.010146146640181541
Loss at iteration 140 : 0.01672172173857689
Loss at iteration 150 : 0.008850925602018833
Loss at iteration 160 : 0.007350447587668896
Loss at iteration 170 : 0.01290380023419857
Loss at iteration 180 : 0.008407894521951675
Loss at iteration 190 : 0.008679131977260113
Loss at iteration 200 : 0.006503576412796974
Loss at iteration 210 : 0.010889431461691856
Loss at iteration 220 : 0.008330225944519043
Loss at iteration 230 : 0.006531183607876301
Loss at iteration 240 : 0.011617641896009445
Loss at iteration 250 : 0.012444284744560719
Loss at iteration 260 : 0.013674484565854073
Loss at iteration 270 : 0.01863011159002781
Loss at iteration 280 : 0.009415588341653347
Loss at iteration 290 : 0.01078543160110712
Loss at iteration 300 : 0.006859515327960253
Loss at iteration 310 : 0.009926818311214447
Loss at iteration 320 : 0.01139029674232006
Loss at iteration 330 : 0.011865712702274323
Loss at iteration 340 : 0.009748837910592556
Loss at iteration 350 : 0.009249987080693245
Loss at iteration 360 : 0.007597743533551693
Loss at iteration 370 : 0.011811889708042145
Loss at iteration 380 : 0.007754121907055378
Loss at iteration 390 : 0.008402128703892231
Loss at iteration 400 : 0.012410594150424004
Loss at iteration 410 : 0.00833061896264553
Loss at iteration 420 : 0.008224875666201115
Loss at iteration 430 : 0.009946677833795547
Loss at iteration 440 : 0.012846190482378006
Loss at iteration 450 : 0.01162621658295393
Loss at iteration 460 : 0.009837144054472446
Loss at iteration 470 : 0.01378370076417923
Loss at iteration 480 : 0.011632952839136124
Loss at iteration 490 : 0.005054079927504063
Loss at iteration 500 : 0.009285234846174717
Loss at iteration 510 : 0.008459644392132759
Loss at iteration 520 : 0.010799655690789223
Loss at iteration 530 : 0.006470245774835348
Loss at iteration 540 : 0.006778424605727196
Loss at iteration 550 : 0.01159267034381628
Loss at iteration 560 : 0.0118476003408432
Loss at iteration 570 : 0.014482096768915653
Loss at iteration 580 : 0.009474566206336021
Loss at iteration 590 : 0.009619154036045074
Loss at iteration 600 : 0.008817840367555618
Loss at iteration 610 : 0.007852882146835327
Loss at iteration 620 : 0.009884779341518879
Loss at iteration 630 : 0.005421945359557867
Loss at iteration 640 : 0.012355893850326538
Loss at iteration 650 : 0.007049006875604391
Loss at iteration 660 : 0.012568135745823383
Loss at iteration 670 : 0.0045641278848052025
Loss at iteration 680 : 0.009887180291116238
Loss at iteration 690 : 0.0068710786290466785
Loss at iteration 700 : 0.00862699281424284
Loss at iteration 710 : 0.008783268742263317
Loss at iteration 720 : 0.013542959466576576
Loss at iteration 730 : 0.008010107092559338
Loss at iteration 740 : 0.008724935352802277
Loss at iteration 750 : 0.013233068399131298
Loss at iteration 760 : 0.008916113525629044
Loss at iteration 770 : 0.015356605872511864
Loss at iteration 780 : 0.008886419236660004
Loss at iteration 790 : 0.009760289452970028
Loss at iteration 800 : 0.011837710626423359
Loss at iteration 810 : 0.00824183039367199
Loss at iteration 820 : 0.017434095963835716
Loss at iteration 830 : 0.014065215364098549
Loss at iteration 840 : 0.011060889810323715
Loss at iteration 850 : 0.011362763121724129
Loss at iteration 860 : 0.007757487706840038
Loss at iteration 870 : 0.014616649597883224
Loss at iteration 880 : 0.0098660197108984
Loss at iteration 890 : 0.008732957765460014
Loss at iteration 900 : 0.005719034466892481
Loss at iteration 910 : 0.0062695154920220375
Loss at iteration 920 : 0.010137936100363731
Loss at iteration 930 : 0.013054069131612778
Loss at iteration 940 : 0.014266440644860268
Loss at iteration 950 : 0.008914162404835224
Loss at iteration 960 : 0.009786452166736126
Loss at iteration 970 : 0.005127623677253723
Loss at iteration 980 : 0.009721078909933567
Loss at iteration 990 : 0.014411784708499908
Loss at iteration 1000 : 0.014114964753389359
Loss at iteration 1010 : 0.009541754610836506
Loss at iteration 1020 : 0.013036572374403477
Loss at iteration 1030 : 0.010854430496692657
Loss at iteration 1040 : 0.007019830401986837
Loss at iteration 1050 : 0.007125167176127434
Loss at iteration 1060 : 0.011323840357363224
Loss at iteration 1070 : 0.010204318910837173
Loss at iteration 1080 : 0.009248342365026474
Loss at iteration 1090 : 0.011050479486584663
Loss at iteration 1100 : 0.018027273938059807
Loss at iteration 1110 : 0.015653565526008606
Loss at iteration 1120 : 0.011622700840234756
Loss at iteration 1130 : 0.005946317687630653
Loss at iteration 1140 : 0.008955479599535465
Loss at iteration 1150 : 0.01372238527983427
Loss at iteration 1160 : 0.007276878692209721
Loss at iteration 1170 : 0.01608995907008648
Loss at iteration 1180 : 0.012890076264739037
Loss at iteration 1190 : 0.011040850542485714
Loss at iteration 1200 : 0.00737921753898263
Loss at iteration 1210 : 0.013267715461552143
The SSIM Value is: 0.7968705336252848
The PSNR Value is: 17.945496877034504
the epoch is: 133
Loss at iteration 10 : 0.01039398368448019
Loss at iteration 20 : 0.014111547730863094
Loss at iteration 30 : 0.010915101505815983
Loss at iteration 40 : 0.012494252994656563
Loss at iteration 50 : 0.01546988170593977
Loss at iteration 60 : 0.009217953309416771
Loss at iteration 70 : 0.011044137179851532
Loss at iteration 80 : 0.009438223205506802
Loss at iteration 90 : 0.01251780055463314
Loss at iteration 100 : 0.010658709332346916
Loss at iteration 110 : 0.015910116955637932
Loss at iteration 120 : 0.00890645943582058
Loss at iteration 130 : 0.013245330192148685
Loss at iteration 140 : 0.014582468196749687
Loss at iteration 150 : 0.01409903448075056
Loss at iteration 160 : 0.009682553820312023
Loss at iteration 170 : 0.011444667354226112
Loss at iteration 180 : 0.007777228485792875
Loss at iteration 190 : 0.007981558330357075
Loss at iteration 200 : 0.008891075849533081
Loss at iteration 210 : 0.013784155249595642
Loss at iteration 220 : 0.01035452913492918
Loss at iteration 230 : 0.009805954992771149
Loss at iteration 240 : 0.009255392476916313
Loss at iteration 250 : 0.011603247374296188
Loss at iteration 260 : 0.014019094407558441
Loss at iteration 270 : 0.01261595543473959
Loss at iteration 280 : 0.011639941483736038
Loss at iteration 290 : 0.0073911575600504875
Loss at iteration 300 : 0.01361256092786789
Loss at iteration 310 : 0.014612735249102116
Loss at iteration 320 : 0.011307342909276485
Loss at iteration 330 : 0.00868713203817606
Loss at iteration 340 : 0.013028385117650032
Loss at iteration 350 : 0.00696813128888607
Loss at iteration 360 : 0.011195886880159378
Loss at iteration 370 : 0.017197884619235992
Loss at iteration 380 : 0.0070663802325725555
Loss at iteration 390 : 0.00835576094686985
Loss at iteration 400 : 0.012227880768477917
Loss at iteration 410 : 0.007878215052187443
Loss at iteration 420 : 0.01689758710563183
Loss at iteration 430 : 0.015904463827610016
Loss at iteration 440 : 0.00922977365553379
Loss at iteration 450 : 0.00987748522311449
Loss at iteration 460 : 0.00718639837577939
Loss at iteration 470 : 0.011481007561087608
Loss at iteration 480 : 0.0072138505056500435
Loss at iteration 490 : 0.006175829563289881
Loss at iteration 500 : 0.010301369242370129
Loss at iteration 510 : 0.011300923302769661
Loss at iteration 520 : 0.013287612237036228
Loss at iteration 530 : 0.010590530931949615
Loss at iteration 540 : 0.009177185595035553
Loss at iteration 550 : 0.010858909226953983
Loss at iteration 560 : 0.012301209382712841
Loss at iteration 570 : 0.008787034079432487
Loss at iteration 580 : 0.014965297654271126
Loss at iteration 590 : 0.011763084679841995
Loss at iteration 600 : 0.007241562940180302
Loss at iteration 610 : 0.007023919373750687
Loss at iteration 620 : 0.01440386101603508
Loss at iteration 630 : 0.013060014694929123
Loss at iteration 640 : 0.0091255409643054
Loss at iteration 650 : 0.0069768233224749565
Loss at iteration 660 : 0.006735511124134064
Loss at iteration 670 : 0.006535479798913002
Loss at iteration 680 : 0.00968843325972557
Loss at iteration 690 : 0.009964076802134514
Loss at iteration 700 : 0.014000148512423038
Loss at iteration 710 : 0.012196528725326061
Loss at iteration 720 : 0.014613128267228603
Loss at iteration 730 : 0.005202094558626413
Loss at iteration 740 : 0.007973164319992065
Loss at iteration 750 : 0.009235542267560959
Loss at iteration 760 : 0.013283684849739075
Loss at iteration 770 : 0.01153379026800394
Loss at iteration 780 : 0.013485148549079895
Loss at iteration 790 : 0.017042197287082672
Loss at iteration 800 : 0.010996917262673378
Loss at iteration 810 : 0.011639025993645191
Loss at iteration 820 : 0.0112645598128438
Loss at iteration 830 : 0.006526764947921038
Loss at iteration 840 : 0.013292098417878151
Loss at iteration 850 : 0.011570269241929054
Loss at iteration 860 : 0.017337104305624962
Loss at iteration 870 : 0.012819568626582623
Loss at iteration 880 : 0.008099116384983063
Loss at iteration 890 : 0.007718734908849001
Loss at iteration 900 : 0.009760632179677486
Loss at iteration 910 : 0.009922566823661327
Loss at iteration 920 : 0.023225702345371246
Loss at iteration 930 : 0.006849008612334728
Loss at iteration 940 : 0.010595333762466908
Loss at iteration 950 : 0.010768897831439972
Loss at iteration 960 : 0.01216062530875206
Loss at iteration 970 : 0.010801253840327263
Loss at iteration 980 : 0.010330487973988056
Loss at iteration 990 : 0.008544044569134712
Loss at iteration 1000 : 0.011938916519284248
Loss at iteration 1010 : 0.00599953206256032
Loss at iteration 1020 : 0.009002365171909332
Loss at iteration 1030 : 0.008402426727116108
Loss at iteration 1040 : 0.014456052333116531
Loss at iteration 1050 : 0.007856395095586777
Loss at iteration 1060 : 0.005209643859416246
Loss at iteration 1070 : 0.00873098149895668
Loss at iteration 1080 : 0.012184150516986847
Loss at iteration 1090 : 0.010434320196509361
Loss at iteration 1100 : 0.014026928693056107
Loss at iteration 1110 : 0.012422877363860607
Loss at iteration 1120 : 0.009065968915820122
Loss at iteration 1130 : 0.012238336727023125
Loss at iteration 1140 : 0.010274223983287811
Loss at iteration 1150 : 0.010684628039598465
Loss at iteration 1160 : 0.012526475824415684
Loss at iteration 1170 : 0.008956590667366982
Loss at iteration 1180 : 0.008548308163881302
Loss at iteration 1190 : 0.010169344954192638
Loss at iteration 1200 : 0.011591671034693718
Loss at iteration 1210 : 0.00971345603466034
The SSIM Value is: 0.8043821096420288
The PSNR Value is: 18.636014684041342
the epoch is: 134
Loss at iteration 10 : 0.008781889453530312
Loss at iteration 20 : 0.011590169742703438
Loss at iteration 30 : 0.009106114506721497
Loss at iteration 40 : 0.012548036873340607
Loss at iteration 50 : 0.008526129648089409
Loss at iteration 60 : 0.007535913959145546
Loss at iteration 70 : 0.014279598370194435
Loss at iteration 80 : 0.012632033787667751
Loss at iteration 90 : 0.011351450346410275
Loss at iteration 100 : 0.008617657236754894
Loss at iteration 110 : 0.009481500834226608
Loss at iteration 120 : 0.011065313592553139
Loss at iteration 130 : 0.010282574221491814
Loss at iteration 140 : 0.005503183696419001
Loss at iteration 150 : 0.008121322840452194
Loss at iteration 160 : 0.012680793181061745
Loss at iteration 170 : 0.014759369194507599
Loss at iteration 180 : 0.008683972992002964
Loss at iteration 190 : 0.010112250223755836
Loss at iteration 200 : 0.014449906535446644
Loss at iteration 210 : 0.010779449716210365
Loss at iteration 220 : 0.004247485194355249
Loss at iteration 230 : 0.023658636957406998
Loss at iteration 240 : 0.009798843413591385
Loss at iteration 250 : 0.0069524310529232025
Loss at iteration 260 : 0.011801118031144142
Loss at iteration 270 : 0.010357915423810482
Loss at iteration 280 : 0.012068669311702251
Loss at iteration 290 : 0.007643110118806362
Loss at iteration 300 : 0.012563598342239857
Loss at iteration 310 : 0.008761144243180752
Loss at iteration 320 : 0.012353850528597832
Loss at iteration 330 : 0.017713457345962524
Loss at iteration 340 : 0.011037146672606468
Loss at iteration 350 : 0.012819492258131504
Loss at iteration 360 : 0.011128434911370277
Loss at iteration 370 : 0.00983385369181633
Loss at iteration 380 : 0.012104094959795475
Loss at iteration 390 : 0.010248396545648575
Loss at iteration 400 : 0.011357629671692848
Loss at iteration 410 : 0.01414257287979126
Loss at iteration 420 : 0.0073422533459961414
Loss at iteration 430 : 0.008990030735731125
Loss at iteration 440 : 0.011979200877249241
Loss at iteration 450 : 0.011908575892448425
Loss at iteration 460 : 0.009545454755425453
Loss at iteration 470 : 0.010106202214956284
Loss at iteration 480 : 0.00954424124211073
Loss at iteration 490 : 0.015197408385574818
Loss at iteration 500 : 0.010471360757946968
Loss at iteration 510 : 0.011012280359864235
Loss at iteration 520 : 0.011857887730002403
Loss at iteration 530 : 0.006756502669304609
Loss at iteration 540 : 0.0072880699299275875
Loss at iteration 550 : 0.013895726762712002
Loss at iteration 560 : 0.008992194198071957
Loss at iteration 570 : 0.012178094126284122
Loss at iteration 580 : 0.006703774444758892
Loss at iteration 590 : 0.023139094933867455
Loss at iteration 600 : 0.010203320533037186
Loss at iteration 610 : 0.006315777078270912
Loss at iteration 620 : 0.013541722670197487
Loss at iteration 630 : 0.01199953444302082
Loss at iteration 640 : 0.008105719462037086
Loss at iteration 650 : 0.01085930597037077
Loss at iteration 660 : 0.008583296090364456
Loss at iteration 670 : 0.008400199934840202
Loss at iteration 680 : 0.01050646137446165
Loss at iteration 690 : 0.005340941715985537
Loss at iteration 700 : 0.014945343136787415
Loss at iteration 710 : 0.0156572125852108
Loss at iteration 720 : 0.01213281974196434
Loss at iteration 730 : 0.0191970095038414
Loss at iteration 740 : 0.018005328252911568
Loss at iteration 750 : 0.013832826167345047
Loss at iteration 760 : 0.00818891916424036
Loss at iteration 770 : 0.008457893505692482
Loss at iteration 780 : 0.01160964835435152
Loss at iteration 790 : 0.008820363320410252
Loss at iteration 800 : 0.009130963124334812
Loss at iteration 810 : 0.010354497469961643
Loss at iteration 820 : 0.013089941814541817
Loss at iteration 830 : 0.011709164828062057
Loss at iteration 840 : 0.008379639126360416
Loss at iteration 850 : 0.009637373499572277
Loss at iteration 860 : 0.009683197364211082
Loss at iteration 870 : 0.011254207231104374
Loss at iteration 880 : 0.010017846710979939
Loss at iteration 890 : 0.02659275382757187
Loss at iteration 900 : 0.008146876469254494
Loss at iteration 910 : 0.00882124062627554
Loss at iteration 920 : 0.010797746479511261
Loss at iteration 930 : 0.01081027276813984
Loss at iteration 940 : 0.011670277453958988
Loss at iteration 950 : 0.008961424231529236
Loss at iteration 960 : 0.0069676414132118225
Loss at iteration 970 : 0.008628414943814278
Loss at iteration 980 : 0.0142452921718359
Loss at iteration 990 : 0.005862455349415541
Loss at iteration 1000 : 0.008295442909002304
Loss at iteration 1010 : 0.008941377513110638
Loss at iteration 1020 : 0.009267639368772507
Loss at iteration 1030 : 0.013635260052978992
Loss at iteration 1040 : 0.00560852512717247
Loss at iteration 1050 : 0.0070708030834794044
Loss at iteration 1060 : 0.00909801758825779
Loss at iteration 1070 : 0.009221946820616722
Loss at iteration 1080 : 0.00766389025375247
Loss at iteration 1090 : 0.011234456673264503
Loss at iteration 1100 : 0.007386323064565659
Loss at iteration 1110 : 0.009899241849780083
Loss at iteration 1120 : 0.01052628643810749
Loss at iteration 1130 : 0.008627589792013168
Loss at iteration 1140 : 0.009401055052876472
Loss at iteration 1150 : 0.006226710509508848
Loss at iteration 1160 : 0.014485353603959084
Loss at iteration 1170 : 0.011129280552268028
Loss at iteration 1180 : 0.009805524721741676
Loss at iteration 1190 : 0.013392770662903786
Loss at iteration 1200 : 0.009547159075737
Loss at iteration 1210 : 0.011815706267952919
The SSIM Value is: 0.8118280013402303
The PSNR Value is: 19.00208829243978
the epoch is: 135
Loss at iteration 10 : 0.01101559866219759
Loss at iteration 20 : 0.00862921867519617
Loss at iteration 30 : 0.012373441830277443
Loss at iteration 40 : 0.017452379688620567
Loss at iteration 50 : 0.010321042500436306
Loss at iteration 60 : 0.012004917487502098
Loss at iteration 70 : 0.012201755307614803
Loss at iteration 80 : 0.009263686835765839
Loss at iteration 90 : 0.015170915052294731
Loss at iteration 100 : 0.01160635519772768
Loss at iteration 110 : 0.014920818619430065
Loss at iteration 120 : 0.011754225008189678
Loss at iteration 130 : 0.008776014670729637
Loss at iteration 140 : 0.008444838225841522
Loss at iteration 150 : 0.009541810490190983
Loss at iteration 160 : 0.009558387100696564
Loss at iteration 170 : 0.007650778628885746
Loss at iteration 180 : 0.009182652458548546
Loss at iteration 190 : 0.01301599107682705
Loss at iteration 200 : 0.009653640910983086
Loss at iteration 210 : 0.009952384978532791
Loss at iteration 220 : 0.0117095448076725
Loss at iteration 230 : 0.018553476780653
Loss at iteration 240 : 0.013389654457569122
Loss at iteration 250 : 0.01155689638108015
Loss at iteration 260 : 0.011157583445310593
Loss at iteration 270 : 0.01147305779159069
Loss at iteration 280 : 0.013049247674643993
Loss at iteration 290 : 0.01125271711498499
Loss at iteration 300 : 0.009961914271116257
Loss at iteration 310 : 0.014495373703539371
Loss at iteration 320 : 0.004609133582562208
Loss at iteration 330 : 0.012166762724518776
Loss at iteration 340 : 0.00973883643746376
Loss at iteration 350 : 0.011292792856693268
Loss at iteration 360 : 0.00809246301651001
Loss at iteration 370 : 0.019968122243881226
Loss at iteration 380 : 0.005825569853186607
Loss at iteration 390 : 0.005888455081731081
Loss at iteration 400 : 0.010544538497924805
Loss at iteration 410 : 0.017700232565402985
Loss at iteration 420 : 0.00684562511742115
Loss at iteration 430 : 0.00791577622294426
Loss at iteration 440 : 0.008584690280258656
Loss at iteration 450 : 0.01372715923935175
Loss at iteration 460 : 0.007336759008467197
Loss at iteration 470 : 0.010529590770602226
Loss at iteration 480 : 0.01575986109673977
Loss at iteration 490 : 0.00836994219571352
Loss at iteration 500 : 0.01290145143866539
Loss at iteration 510 : 0.009042104706168175
Loss at iteration 520 : 0.017664244398474693
Loss at iteration 530 : 0.010394549928605556
Loss at iteration 540 : 0.005992263555526733
Loss at iteration 550 : 0.012000801041722298
Loss at iteration 560 : 0.015861008316278458
Loss at iteration 570 : 0.016654739156365395
Loss at iteration 580 : 0.008261911571025848
Loss at iteration 590 : 0.006065392401069403
Loss at iteration 600 : 0.009481769986450672
Loss at iteration 610 : 0.009104019962251186
Loss at iteration 620 : 0.013050148263573647
Loss at iteration 630 : 0.011564316228032112
Loss at iteration 640 : 0.012025452218949795
Loss at iteration 650 : 0.007891010493040085
Loss at iteration 660 : 0.006942511536180973
Loss at iteration 670 : 0.00694690179079771
Loss at iteration 680 : 0.007239155936986208
Loss at iteration 690 : 0.008356014266610146
Loss at iteration 700 : 0.014027688652276993
Loss at iteration 710 : 0.006443713791668415
Loss at iteration 720 : 0.004053974524140358
Loss at iteration 730 : 0.007617149502038956
Loss at iteration 740 : 0.014844831079244614
Loss at iteration 750 : 0.015137137845158577
Loss at iteration 760 : 0.009949009865522385
Loss at iteration 770 : 0.011383924633264542
Loss at iteration 780 : 0.006975454278290272
Loss at iteration 790 : 0.010802481323480606
Loss at iteration 800 : 0.011672364547848701
Loss at iteration 810 : 0.009977923706173897
Loss at iteration 820 : 0.013178408145904541
Loss at iteration 830 : 0.008522555232048035
Loss at iteration 840 : 0.007541117258369923
Loss at iteration 850 : 0.01248699426651001
Loss at iteration 860 : 0.009200864471495152
Loss at iteration 870 : 0.011448539793491364
Loss at iteration 880 : 0.020174378529191017
Loss at iteration 890 : 0.011125436052680016
Loss at iteration 900 : 0.009937994182109833
Loss at iteration 910 : 0.015624196268618107
Loss at iteration 920 : 0.012266688048839569
Loss at iteration 930 : 0.007666395045816898
Loss at iteration 940 : 0.008415806107223034
Loss at iteration 950 : 0.00784111674875021
Loss at iteration 960 : 0.013955045491456985
Loss at iteration 970 : 0.012690420262515545
Loss at iteration 980 : 0.00861586257815361
Loss at iteration 990 : 0.01115168072283268
Loss at iteration 1000 : 0.01466049812734127
Loss at iteration 1010 : 0.009011556394398212
Loss at iteration 1020 : 0.012585125863552094
Loss at iteration 1030 : 0.012956050224602222
Loss at iteration 1040 : 0.010579323396086693
Loss at iteration 1050 : 0.01166860293596983
Loss at iteration 1060 : 0.010723067447543144
Loss at iteration 1070 : 0.005756464786827564
Loss at iteration 1080 : 0.007421841379255056
Loss at iteration 1090 : 0.0163577813655138
Loss at iteration 1100 : 0.011797408573329449
Loss at iteration 1110 : 0.010685473680496216
Loss at iteration 1120 : 0.010333874262869358
Loss at iteration 1130 : 0.02582845278084278
Loss at iteration 1140 : 0.006489508785307407
Loss at iteration 1150 : 0.012062577530741692
Loss at iteration 1160 : 0.00855246838182211
Loss at iteration 1170 : 0.009270114824175835
Loss at iteration 1180 : 0.010384074412286282
Loss at iteration 1190 : 0.006862262729555368
Loss at iteration 1200 : 0.007137882988899946
Loss at iteration 1210 : 0.010968048125505447
The SSIM Value is: 0.8066074848175049
The PSNR Value is: 18.62295430501302
the epoch is: 136
Loss at iteration 10 : 0.007996199652552605
Loss at iteration 20 : 0.007124088238924742
Loss at iteration 30 : 0.010513149201869965
Loss at iteration 40 : 0.007557657081633806
Loss at iteration 50 : 0.010905293747782707
Loss at iteration 60 : 0.0077558234333992004
Loss at iteration 70 : 0.004727161023765802
Loss at iteration 80 : 0.018626617267727852
Loss at iteration 90 : 0.009280618280172348
Loss at iteration 100 : 0.010016298852860928
Loss at iteration 110 : 0.015840617939829826
Loss at iteration 120 : 0.011214821599423885
Loss at iteration 130 : 0.009824179112911224
Loss at iteration 140 : 0.010977189987897873
Loss at iteration 150 : 0.015478583984076977
Loss at iteration 160 : 0.012455029413104057
Loss at iteration 170 : 0.01509268768131733
Loss at iteration 180 : 0.008936779573559761
Loss at iteration 190 : 0.006840249989181757
Loss at iteration 200 : 0.008503284305334091
Loss at iteration 210 : 0.0073430477641522884
Loss at iteration 220 : 0.0127066969871521
Loss at iteration 230 : 0.005673879757523537
Loss at iteration 240 : 0.008823365904390812
Loss at iteration 250 : 0.007655482739210129
Loss at iteration 260 : 0.0215347558259964
Loss at iteration 270 : 0.016625847667455673
Loss at iteration 280 : 0.018664760515093803
Loss at iteration 290 : 0.009821153245866299
Loss at iteration 300 : 0.008035264909267426
Loss at iteration 310 : 0.013047500513494015
Loss at iteration 320 : 0.01588701456785202
Loss at iteration 330 : 0.011877331882715225
Loss at iteration 340 : 0.013538221828639507
Loss at iteration 350 : 0.010034124366939068
Loss at iteration 360 : 0.009389504790306091
Loss at iteration 370 : 0.006662040948867798
Loss at iteration 380 : 0.00886029563844204
Loss at iteration 390 : 0.013855764642357826
Loss at iteration 400 : 0.009638055227696896
Loss at iteration 410 : 0.011698723770678043
Loss at iteration 420 : 0.012489579617977142
Loss at iteration 430 : 0.005571549292653799
Loss at iteration 440 : 0.005676909349858761
Loss at iteration 450 : 0.018257925286889076
Loss at iteration 460 : 0.012378714978694916
Loss at iteration 470 : 0.008464164100587368
Loss at iteration 480 : 0.007113222032785416
Loss at iteration 490 : 0.009235091507434845
Loss at iteration 500 : 0.005866618826985359
Loss at iteration 510 : 0.008320399560034275
Loss at iteration 520 : 0.008955788798630238
Loss at iteration 530 : 0.012584772892296314
Loss at iteration 540 : 0.010506254620850086
Loss at iteration 550 : 0.008884841576218605
Loss at iteration 560 : 0.009933228604495525
Loss at iteration 570 : 0.016340279951691628
Loss at iteration 580 : 0.0078001366928219795
Loss at iteration 590 : 0.009208829142153263
Loss at iteration 600 : 0.01324344240128994
Loss at iteration 610 : 0.012963433749973774
Loss at iteration 620 : 0.015369882807135582
Loss at iteration 630 : 0.011606375686824322
Loss at iteration 640 : 0.0105140320956707
Loss at iteration 650 : 0.014708348549902439
Loss at iteration 660 : 0.012478825636208057
Loss at iteration 670 : 0.007399467751383781
Loss at iteration 680 : 0.0072039645165205
Loss at iteration 690 : 0.017621859908103943
Loss at iteration 700 : 0.016163263469934464
Loss at iteration 710 : 0.00897134281694889
Loss at iteration 720 : 0.018984463065862656
Loss at iteration 730 : 0.007143166847527027
Loss at iteration 740 : 0.008377079851925373
Loss at iteration 750 : 0.009896262548863888
Loss at iteration 760 : 0.013061817735433578
Loss at iteration 770 : 0.013707722537219524
Loss at iteration 780 : 0.009653105400502682
Loss at iteration 790 : 0.015415726229548454
Loss at iteration 800 : 0.00897926278412342
Loss at iteration 810 : 0.011752041056752205
Loss at iteration 820 : 0.010230530053377151
Loss at iteration 830 : 0.021823082119226456
Loss at iteration 840 : 0.007021190598607063
Loss at iteration 850 : 0.013841264881193638
Loss at iteration 860 : 0.010645744390785694
Loss at iteration 870 : 0.012536190450191498
Loss at iteration 880 : 0.009658880531787872
Loss at iteration 890 : 0.006214689463376999
Loss at iteration 900 : 0.0073492638766765594
Loss at iteration 910 : 0.010241403244435787
Loss at iteration 920 : 0.007050948683172464
Loss at iteration 930 : 0.012812664732336998
Loss at iteration 940 : 0.013586269691586494
Loss at iteration 950 : 0.00651159230619669
Loss at iteration 960 : 0.009271400980651379
Loss at iteration 970 : 0.012242058292031288
Loss at iteration 980 : 0.00792009849101305
Loss at iteration 990 : 0.008751344867050648
Loss at iteration 1000 : 0.005458042956888676
Loss at iteration 1010 : 0.0084410784766078
Loss at iteration 1020 : 0.011928948573768139
Loss at iteration 1030 : 0.015197931788861752
Loss at iteration 1040 : 0.016700224950909615
Loss at iteration 1050 : 0.008862348273396492
Loss at iteration 1060 : 0.012206478044390678
Loss at iteration 1070 : 0.008438150398433208
Loss at iteration 1080 : 0.015390650369226933
Loss at iteration 1090 : 0.011187887750566006
Loss at iteration 1100 : 0.015066642314195633
Loss at iteration 1110 : 0.0123689454048872
Loss at iteration 1120 : 0.010366193018853664
Loss at iteration 1130 : 0.007843848317861557
Loss at iteration 1140 : 0.006967190653085709
Loss at iteration 1150 : 0.008796069771051407
Loss at iteration 1160 : 0.007531702518463135
Loss at iteration 1170 : 0.013571104034781456
Loss at iteration 1180 : 0.005514288321137428
Loss at iteration 1190 : 0.02332446165382862
Loss at iteration 1200 : 0.010164177045226097
Loss at iteration 1210 : 0.011915919370949268
The SSIM Value is: 0.8019189675649007
The PSNR Value is: 18.239436276753743
the epoch is: 137
Loss at iteration 10 : 0.008710207417607307
Loss at iteration 20 : 0.016410479322075844
Loss at iteration 30 : 0.008659826591610909
Loss at iteration 40 : 0.008980872109532356
Loss at iteration 50 : 0.010296108201146126
Loss at iteration 60 : 0.00991651602089405
Loss at iteration 70 : 0.008693565614521503
Loss at iteration 80 : 0.008563440293073654
Loss at iteration 90 : 0.007435730192810297
Loss at iteration 100 : 0.011932998895645142
Loss at iteration 110 : 0.007359757553786039
Loss at iteration 120 : 0.010460790246725082
Loss at iteration 130 : 0.012477319687604904
Loss at iteration 140 : 0.008640987798571587
Loss at iteration 150 : 0.01152721606194973
Loss at iteration 160 : 0.014697627164423466
Loss at iteration 170 : 0.00828051008284092
Loss at iteration 180 : 0.01240612007677555
Loss at iteration 190 : 0.01732308603823185
Loss at iteration 200 : 0.009169099852442741
Loss at iteration 210 : 0.008440392091870308
Loss at iteration 220 : 0.01607586070895195
Loss at iteration 230 : 0.010191413573920727
Loss at iteration 240 : 0.008282550610601902
Loss at iteration 250 : 0.00939116533845663
Loss at iteration 260 : 0.0071345362812280655
Loss at iteration 270 : 0.009782134555280209
Loss at iteration 280 : 0.008650418370962143
Loss at iteration 290 : 0.01649278774857521
Loss at iteration 300 : 0.010225414298474789
Loss at iteration 310 : 0.009256314486265182
Loss at iteration 320 : 0.010473605245351791
Loss at iteration 330 : 0.017464274540543556
Loss at iteration 340 : 0.015348158776760101
Loss at iteration 350 : 0.011004863306879997
Loss at iteration 360 : 0.02669626660645008
Loss at iteration 370 : 0.016319844871759415
Loss at iteration 380 : 0.009283852763473988
Loss at iteration 390 : 0.016376903280615807
Loss at iteration 400 : 0.010693039745092392
Loss at iteration 410 : 0.006553951185196638
Loss at iteration 420 : 0.0118390629068017
Loss at iteration 430 : 0.015868766233325005
Loss at iteration 440 : 0.00856204517185688
Loss at iteration 450 : 0.021689461544156075
Loss at iteration 460 : 0.01106034405529499
Loss at iteration 470 : 0.00959730800241232
Loss at iteration 480 : 0.007886751554906368
Loss at iteration 490 : 0.017336787655949593
Loss at iteration 500 : 0.009334892965853214
Loss at iteration 510 : 0.008738459087908268
Loss at iteration 520 : 0.009155991487205029
Loss at iteration 530 : 0.011885501444339752
Loss at iteration 540 : 0.0062651545740664005
Loss at iteration 550 : 0.012328090146183968
Loss at iteration 560 : 0.01123904064297676
Loss at iteration 570 : 0.005805301479995251
Loss at iteration 580 : 0.011533619835972786
Loss at iteration 590 : 0.008430770598351955
Loss at iteration 600 : 0.008169821463525295
Loss at iteration 610 : 0.006757832132279873
Loss at iteration 620 : 0.00946250930428505
Loss at iteration 630 : 0.008245360106229782
Loss at iteration 640 : 0.013834187760949135
Loss at iteration 650 : 0.009445417672395706
Loss at iteration 660 : 0.007838815450668335
Loss at iteration 670 : 0.010585949756205082
Loss at iteration 680 : 0.0065328460186719894
Loss at iteration 690 : 0.00869031809270382
Loss at iteration 700 : 0.011188089847564697
Loss at iteration 710 : 0.007745278999209404
Loss at iteration 720 : 0.013499382883310318
Loss at iteration 730 : 0.012228623032569885
Loss at iteration 740 : 0.009801304899156094
Loss at iteration 750 : 0.00643624784424901
Loss at iteration 760 : 0.012899844907224178
Loss at iteration 770 : 0.012261075899004936
Loss at iteration 780 : 0.01747913286089897
Loss at iteration 790 : 0.009861337952315807
Loss at iteration 800 : 0.01703784056007862
Loss at iteration 810 : 0.010180652141571045
Loss at iteration 820 : 0.011604392901062965
Loss at iteration 830 : 0.008538927882909775
Loss at iteration 840 : 0.010660720989108086
Loss at iteration 850 : 0.011664826422929764
Loss at iteration 860 : 0.010406462475657463
Loss at iteration 870 : 0.011115394532680511
Loss at iteration 880 : 0.0073149241507053375
Loss at iteration 890 : 0.01369553804397583
Loss at iteration 900 : 0.015007536858320236
Loss at iteration 910 : 0.012394307181239128
Loss at iteration 920 : 0.013815284706652164
Loss at iteration 930 : 0.009543205611407757
Loss at iteration 940 : 0.01798935979604721
Loss at iteration 950 : 0.006222826428711414
Loss at iteration 960 : 0.012403211556375027
Loss at iteration 970 : 0.007766307331621647
Loss at iteration 980 : 0.0045374478213489056
Loss at iteration 990 : 0.015812084078788757
Loss at iteration 1000 : 0.01011184137314558
Loss at iteration 1010 : 0.013159984722733498
Loss at iteration 1020 : 0.010630633682012558
Loss at iteration 1030 : 0.013689951971173286
Loss at iteration 1040 : 0.007712370250374079
Loss at iteration 1050 : 0.016684051603078842
Loss at iteration 1060 : 0.009643319994211197
Loss at iteration 1070 : 0.01109475176781416
Loss at iteration 1080 : 0.00972041953355074
Loss at iteration 1090 : 0.004647570196539164
Loss at iteration 1100 : 0.014067652635276318
Loss at iteration 1110 : 0.009413971565663815
Loss at iteration 1120 : 0.012306144461035728
Loss at iteration 1130 : 0.01020350307226181
Loss at iteration 1140 : 0.012575551867485046
Loss at iteration 1150 : 0.007249795366078615
Loss at iteration 1160 : 0.007671494968235493
Loss at iteration 1170 : 0.013958233408629894
Loss at iteration 1180 : 0.006986101157963276
Loss at iteration 1190 : 0.0070374831557273865
Loss at iteration 1200 : 0.008639991283416748
Loss at iteration 1210 : 0.008504020050168037
The SSIM Value is: 0.8103322148323059
The PSNR Value is: 18.58900038401286
the epoch is: 138
Loss at iteration 10 : 0.013975443318486214
Loss at iteration 20 : 0.00807926245033741
Loss at iteration 30 : 0.012402490712702274
Loss at iteration 40 : 0.012854008004069328
Loss at iteration 50 : 0.018153147771954536
Loss at iteration 60 : 0.012247519567608833
Loss at iteration 70 : 0.011729788035154343
Loss at iteration 80 : 0.014069147408008575
Loss at iteration 90 : 0.009606823325157166
Loss at iteration 100 : 0.011482656002044678
Loss at iteration 110 : 0.010945508256554604
Loss at iteration 120 : 0.004694468341767788
Loss at iteration 130 : 0.005760508589446545
Loss at iteration 140 : 0.011597473174333572
Loss at iteration 150 : 0.009678853675723076
Loss at iteration 160 : 0.010948693379759789
Loss at iteration 170 : 0.011159280315041542
Loss at iteration 180 : 0.013651796616613865
Loss at iteration 190 : 0.01576106809079647
Loss at iteration 200 : 0.012964300811290741
Loss at iteration 210 : 0.005673870909959078
Loss at iteration 220 : 0.006218846421688795
Loss at iteration 230 : 0.008992083370685577
Loss at iteration 240 : 0.009564152918756008
Loss at iteration 250 : 0.011991513893008232
Loss at iteration 260 : 0.01582690328359604
Loss at iteration 270 : 0.010299433954060078
Loss at iteration 280 : 0.01445101574063301
Loss at iteration 290 : 0.013815455138683319
Loss at iteration 300 : 0.01062251627445221
Loss at iteration 310 : 0.011128860525786877
Loss at iteration 320 : 0.00989564135670662
Loss at iteration 330 : 0.007068978622555733
Loss at iteration 340 : 0.013386375270783901
Loss at iteration 350 : 0.01621090993285179
Loss at iteration 360 : 0.009336586110293865
Loss at iteration 370 : 0.011219882406294346
Loss at iteration 380 : 0.008424686267971992
Loss at iteration 390 : 0.015523001551628113
Loss at iteration 400 : 0.011788181029260159
Loss at iteration 410 : 0.012937970459461212
Loss at iteration 420 : 0.013771084137260914
Loss at iteration 430 : 0.009841296821832657
Loss at iteration 440 : 0.007277847267687321
Loss at iteration 450 : 0.00752867478877306
Loss at iteration 460 : 0.007746947929263115
Loss at iteration 470 : 0.009705370292067528
Loss at iteration 480 : 0.01019396260380745
Loss at iteration 490 : 0.009776417165994644
Loss at iteration 500 : 0.007386746816337109
Loss at iteration 510 : 0.005877247545868158
Loss at iteration 520 : 0.01284459512680769
Loss at iteration 530 : 0.019097276031970978
Loss at iteration 540 : 0.008190557360649109
Loss at iteration 550 : 0.004334502387791872
Loss at iteration 560 : 0.01324465125799179
Loss at iteration 570 : 0.0172453373670578
Loss at iteration 580 : 0.008298532105982304
Loss at iteration 590 : 0.013318907469511032
Loss at iteration 600 : 0.010195890441536903
Loss at iteration 610 : 0.018590252846479416
Loss at iteration 620 : 0.011769565753638744
Loss at iteration 630 : 0.02203328348696232
Loss at iteration 640 : 0.013351181522011757
Loss at iteration 650 : 0.005875314120203257
Loss at iteration 660 : 0.010496768169105053
Loss at iteration 670 : 0.009973104111850262
Loss at iteration 680 : 0.007843617349863052
Loss at iteration 690 : 0.008120733313262463
Loss at iteration 700 : 0.012566953897476196
Loss at iteration 710 : 0.008464138954877853
Loss at iteration 720 : 0.017639270052313805
Loss at iteration 730 : 0.009937252849340439
Loss at iteration 740 : 0.0161465872079134
Loss at iteration 750 : 0.01237519271671772
Loss at iteration 760 : 0.008822851814329624
Loss at iteration 770 : 0.008753514848649502
Loss at iteration 780 : 0.014410755597054958
Loss at iteration 790 : 0.015925657004117966
Loss at iteration 800 : 0.006311649922281504
Loss at iteration 810 : 0.010215818881988525
Loss at iteration 820 : 0.007797562517225742
Loss at iteration 830 : 0.007090585306286812
Loss at iteration 840 : 0.0053133065812289715
Loss at iteration 850 : 0.017453782260417938
Loss at iteration 860 : 0.00599970668554306
Loss at iteration 870 : 0.012186218053102493
Loss at iteration 880 : 0.00967361405491829
Loss at iteration 890 : 0.006910940166562796
Loss at iteration 900 : 0.007162328343838453
Loss at iteration 910 : 0.007696215063333511
Loss at iteration 920 : 0.00956881232559681
Loss at iteration 930 : 0.010213705711066723
Loss at iteration 940 : 0.01402001827955246
Loss at iteration 950 : 0.009654024615883827
Loss at iteration 960 : 0.011523869819939137
Loss at iteration 970 : 0.010673235170543194
Loss at iteration 980 : 0.011513743549585342
Loss at iteration 990 : 0.013018092140555382
Loss at iteration 1000 : 0.01332674641162157
Loss at iteration 1010 : 0.006492260843515396
Loss at iteration 1020 : 0.010636208578944206
Loss at iteration 1030 : 0.011189215816557407
Loss at iteration 1040 : 0.007932525128126144
Loss at iteration 1050 : 0.0108408248052001
Loss at iteration 1060 : 0.011983868665993214
Loss at iteration 1070 : 0.004844133276492357
Loss at iteration 1080 : 0.01820540986955166
Loss at iteration 1090 : 0.009715753607451916
Loss at iteration 1100 : 0.006388618610799313
Loss at iteration 1110 : 0.014165285974740982
Loss at iteration 1120 : 0.012196152471005917
Loss at iteration 1130 : 0.009916994720697403
Loss at iteration 1140 : 0.018267598003149033
Loss at iteration 1150 : 0.00851811096072197
Loss at iteration 1160 : 0.010477753356099129
Loss at iteration 1170 : 0.007615857291966677
Loss at iteration 1180 : 0.013177069835364819
Loss at iteration 1190 : 0.011967724189162254
Loss at iteration 1200 : 0.01000799611210823
Loss at iteration 1210 : 0.011961662210524082
The SSIM Value is: 0.7813784996668498
The PSNR Value is: 17.38245531717936
the epoch is: 139
Loss at iteration 10 : 0.008346004411578178
Loss at iteration 20 : 0.023563571274280548
Loss at iteration 30 : 0.008091777563095093
Loss at iteration 40 : 0.00941772572696209
Loss at iteration 50 : 0.011928956024348736
Loss at iteration 60 : 0.005821452010422945
Loss at iteration 70 : 0.011532949283719063
Loss at iteration 80 : 0.014520245604217052
Loss at iteration 90 : 0.011799621395766735
Loss at iteration 100 : 0.011836999095976353
Loss at iteration 110 : 0.00976652279496193
Loss at iteration 120 : 0.0069605158641934395
Loss at iteration 130 : 0.007052033208310604
Loss at iteration 140 : 0.0075905886478722095
Loss at iteration 150 : 0.006345126777887344
Loss at iteration 160 : 0.008142623119056225
Loss at iteration 170 : 0.008264738135039806
Loss at iteration 180 : 0.004174066707491875
Loss at iteration 190 : 0.009870610199868679
Loss at iteration 200 : 0.00909996684640646
Loss at iteration 210 : 0.013647089712321758
Loss at iteration 220 : 0.005832948721945286
Loss at iteration 230 : 0.01190424244850874
Loss at iteration 240 : 0.014805460348725319
Loss at iteration 250 : 0.013218218460679054
Loss at iteration 260 : 0.011428571306169033
Loss at iteration 270 : 0.009170372039079666
Loss at iteration 280 : 0.010056167840957642
Loss at iteration 290 : 0.006887264549732208
Loss at iteration 300 : 0.008791644126176834
Loss at iteration 310 : 0.006504035089164972
Loss at iteration 320 : 0.010196197777986526
Loss at iteration 330 : 0.01262456364929676
Loss at iteration 340 : 0.015607217326760292
Loss at iteration 350 : 0.009999364614486694
Loss at iteration 360 : 0.00769234262406826
Loss at iteration 370 : 0.009306195192039013
Loss at iteration 380 : 0.012740489095449448
Loss at iteration 390 : 0.012210804969072342
Loss at iteration 400 : 0.009463955648243427
Loss at iteration 410 : 0.009004544466733932
Loss at iteration 420 : 0.01131549384444952
Loss at iteration 430 : 0.005113460123538971
Loss at iteration 440 : 0.010258526541292667
Loss at iteration 450 : 0.011844227090477943
Loss at iteration 460 : 0.00826176255941391
Loss at iteration 470 : 0.012646282091736794
Loss at iteration 480 : 0.01705833710730076
Loss at iteration 490 : 0.008698279038071632
Loss at iteration 500 : 0.011941433884203434
Loss at iteration 510 : 0.007734771817922592
Loss at iteration 520 : 0.005913267843425274
Loss at iteration 530 : 0.01656041480600834
Loss at iteration 540 : 0.009798858314752579
Loss at iteration 550 : 0.010128295980393887
Loss at iteration 560 : 0.012515626847743988
Loss at iteration 570 : 0.01572798192501068
Loss at iteration 580 : 0.0083162821829319
Loss at iteration 590 : 0.010778910480439663
Loss at iteration 600 : 0.011295264586806297
Loss at iteration 610 : 0.00975583866238594
Loss at iteration 620 : 0.007370130158960819
Loss at iteration 630 : 0.017728138715028763
Loss at iteration 640 : 0.006444936618208885
Loss at iteration 650 : 0.008397744037210941
Loss at iteration 660 : 0.012128334492444992
Loss at iteration 670 : 0.017662137746810913
Loss at iteration 680 : 0.008619016036391258
Loss at iteration 690 : 0.010304886847734451
Loss at iteration 700 : 0.009355532005429268
Loss at iteration 710 : 0.008909040130674839
Loss at iteration 720 : 0.008166559971868992
Loss at iteration 730 : 0.016655664891004562
Loss at iteration 740 : 0.0132326390594244
Loss at iteration 750 : 0.012013398110866547
Loss at iteration 760 : 0.008091846480965614
Loss at iteration 770 : 0.012306228280067444
Loss at iteration 780 : 0.009097667410969734
Loss at iteration 790 : 0.02614225074648857
Loss at iteration 800 : 0.013619087636470795
Loss at iteration 810 : 0.012582870200276375
Loss at iteration 820 : 0.010143028572201729
Loss at iteration 830 : 0.00908622331917286
Loss at iteration 840 : 0.007748894859105349
Loss at iteration 850 : 0.009043112397193909
Loss at iteration 860 : 0.008855396881699562
Loss at iteration 870 : 0.007642816286534071
Loss at iteration 880 : 0.00930871069431305
Loss at iteration 890 : 0.011116168461740017
Loss at iteration 900 : 0.01223631203174591
Loss at iteration 910 : 0.009888093918561935
Loss at iteration 920 : 0.007318428251892328
Loss at iteration 930 : 0.009994680061936378
Loss at iteration 940 : 0.010732036083936691
Loss at iteration 950 : 0.009893701411783695
Loss at iteration 960 : 0.008371887728571892
Loss at iteration 970 : 0.007947956211864948
Loss at iteration 980 : 0.01754489727318287
Loss at iteration 990 : 0.007204720750451088
Loss at iteration 1000 : 0.008784256875514984
Loss at iteration 1010 : 0.007172953337430954
Loss at iteration 1020 : 0.014064613729715347
Loss at iteration 1030 : 0.013710256665945053
Loss at iteration 1040 : 0.007854956202208996
Loss at iteration 1050 : 0.011996295303106308
Loss at iteration 1060 : 0.005818244069814682
Loss at iteration 1070 : 0.005151801742613316
Loss at iteration 1080 : 0.008056564256548882
Loss at iteration 1090 : 0.007113360799849033
Loss at iteration 1100 : 0.005307439249008894
Loss at iteration 1110 : 0.014845350757241249
Loss at iteration 1120 : 0.010137059725821018
Loss at iteration 1130 : 0.009109030477702618
Loss at iteration 1140 : 0.017022661864757538
Loss at iteration 1150 : 0.008756674826145172
Loss at iteration 1160 : 0.005654859822243452
Loss at iteration 1170 : 0.009063820354640484
Loss at iteration 1180 : 0.01291370764374733
Loss at iteration 1190 : 0.006843259558081627
Loss at iteration 1200 : 0.008647710084915161
Loss at iteration 1210 : 0.01019871886819601
The SSIM Value is: 0.805463437239329
The PSNR Value is: 18.50658353169759
the epoch is: 140
Loss at iteration 10 : 0.00750570697709918
Loss at iteration 20 : 0.00941325444728136
Loss at iteration 30 : 0.010103770531713963
Loss at iteration 40 : 0.0054102628491818905
Loss at iteration 50 : 0.012653185054659843
Loss at iteration 60 : 0.01332574151456356
Loss at iteration 70 : 0.013953708112239838
Loss at iteration 80 : 0.010997829958796501
Loss at iteration 90 : 0.006962269078940153
Loss at iteration 100 : 0.00786995142698288
Loss at iteration 110 : 0.011172358877956867
Loss at iteration 120 : 0.0076012685894966125
Loss at iteration 130 : 0.005979941226541996
Loss at iteration 140 : 0.01174855139106512
Loss at iteration 150 : 0.006672872230410576
Loss at iteration 160 : 0.010193128138780594
Loss at iteration 170 : 0.010447884909808636
Loss at iteration 180 : 0.014526326209306717
Loss at iteration 190 : 0.005916191264986992
Loss at iteration 200 : 0.01073408778756857
Loss at iteration 210 : 0.006791615858674049
Loss at iteration 220 : 0.010121386498212814
Loss at iteration 230 : 0.011760994791984558
Loss at iteration 240 : 0.01088107842952013
Loss at iteration 250 : 0.010590992867946625
Loss at iteration 260 : 0.007101012393832207
Loss at iteration 270 : 0.012463768944144249
Loss at iteration 280 : 0.014663496986031532
Loss at iteration 290 : 0.013285267166793346
Loss at iteration 300 : 0.012387240305542946
Loss at iteration 310 : 0.009045684710144997
Loss at iteration 320 : 0.011199806816875935
Loss at iteration 330 : 0.00907834991812706
Loss at iteration 340 : 0.008628154173493385
Loss at iteration 350 : 0.017001094296574593
Loss at iteration 360 : 0.009800163097679615
Loss at iteration 370 : 0.005714741535484791
Loss at iteration 380 : 0.013569952920079231
Loss at iteration 390 : 0.009072101674973965
Loss at iteration 400 : 0.019856903702020645
Loss at iteration 410 : 0.010941483080387115
Loss at iteration 420 : 0.0132994269952178
Loss at iteration 430 : 0.00803425908088684
Loss at iteration 440 : 0.012228491716086864
Loss at iteration 450 : 0.0073837111704051495
Loss at iteration 460 : 0.011165274307131767
Loss at iteration 470 : 0.010347363539040089
Loss at iteration 480 : 0.0055085052736103535
Loss at iteration 490 : 0.008176267147064209
Loss at iteration 500 : 0.007069232873618603
Loss at iteration 510 : 0.009052730165421963
Loss at iteration 520 : 0.019038451835513115
Loss at iteration 530 : 0.01315988041460514
Loss at iteration 540 : 0.012008997611701488
Loss at iteration 550 : 0.016361933201551437
Loss at iteration 560 : 0.00521767558529973
Loss at iteration 570 : 0.007603652775287628
Loss at iteration 580 : 0.01317481230944395
Loss at iteration 590 : 0.010241266340017319
Loss at iteration 600 : 0.008956301026046276
Loss at iteration 610 : 0.016317710280418396
Loss at iteration 620 : 0.00703690480440855
Loss at iteration 630 : 0.009559212252497673
Loss at iteration 640 : 0.00876593217253685
Loss at iteration 650 : 0.016135821118950844
Loss at iteration 660 : 0.007160714827477932
Loss at iteration 670 : 0.009043318219482899
Loss at iteration 680 : 0.009305101819336414
Loss at iteration 690 : 0.012461059726774693
Loss at iteration 700 : 0.00798158161342144
Loss at iteration 710 : 0.009789320640265942
Loss at iteration 720 : 0.007036423776298761
Loss at iteration 730 : 0.00846173521131277
Loss at iteration 740 : 0.013459183275699615
Loss at iteration 750 : 0.007860496640205383
Loss at iteration 760 : 0.010853635147213936
Loss at iteration 770 : 0.008634408935904503
Loss at iteration 780 : 0.009346048347651958
Loss at iteration 790 : 0.010161913000047207
Loss at iteration 800 : 0.014955978840589523
Loss at iteration 810 : 0.011798163875937462
Loss at iteration 820 : 0.006648570764809847
Loss at iteration 830 : 0.006356454454362392
Loss at iteration 840 : 0.006938719656318426
Loss at iteration 850 : 0.01227548811584711
Loss at iteration 860 : 0.01153651811182499
Loss at iteration 870 : 0.014200744219124317
Loss at iteration 880 : 0.01859811693429947
Loss at iteration 890 : 0.014023181982338428
Loss at iteration 900 : 0.01647581160068512
Loss at iteration 910 : 0.007936136797070503
Loss at iteration 920 : 0.007602282799780369
Loss at iteration 930 : 0.0074961525388062
Loss at iteration 940 : 0.01119092758744955
Loss at iteration 950 : 0.004983735270798206
Loss at iteration 960 : 0.008423728868365288
Loss at iteration 970 : 0.008572202175855637
Loss at iteration 980 : 0.013968625105917454
Loss at iteration 990 : 0.01303375419229269
Loss at iteration 1000 : 0.007042546756565571
Loss at iteration 1010 : 0.011321073397994041
Loss at iteration 1020 : 0.012298868037760258
Loss at iteration 1030 : 0.014814266003668308
Loss at iteration 1040 : 0.00897953286767006
Loss at iteration 1050 : 0.010902860201895237
Loss at iteration 1060 : 0.004144231788814068
Loss at iteration 1070 : 0.008186371065676212
Loss at iteration 1080 : 0.020915288478136063
Loss at iteration 1090 : 0.014552652835845947
Loss at iteration 1100 : 0.010916240513324738
Loss at iteration 1110 : 0.01365634799003601
Loss at iteration 1120 : 0.017277538776397705
Loss at iteration 1130 : 0.011323018930852413
Loss at iteration 1140 : 0.01256751362234354
Loss at iteration 1150 : 0.013199174776673317
Loss at iteration 1160 : 0.006431785877794027
Loss at iteration 1170 : 0.010836800560355186
Loss at iteration 1180 : 0.013415748253464699
Loss at iteration 1190 : 0.010342690162360668
Loss at iteration 1200 : 0.013157595880329609
Loss at iteration 1210 : 0.013845586217939854
The SSIM Value is: 0.8187097907066345
The PSNR Value is: 19.597470410664876
the highest SSIM value is: 19.597470410664876
the epoch is: 141
Loss at iteration 10 : 0.008386755362153053
Loss at iteration 20 : 0.012234995141625404
Loss at iteration 30 : 0.008873959071934223
Loss at iteration 40 : 0.007755436468869448
Loss at iteration 50 : 0.01050661038607359
Loss at iteration 60 : 0.00644866144284606
Loss at iteration 70 : 0.00900309532880783
Loss at iteration 80 : 0.013412821106612682
Loss at iteration 90 : 0.010439100675284863
Loss at iteration 100 : 0.01078105065971613
Loss at iteration 110 : 0.010386323556303978
Loss at iteration 120 : 0.006340129300951958
Loss at iteration 130 : 0.0077754175290465355
Loss at iteration 140 : 0.006686969194561243
Loss at iteration 150 : 0.00984593853354454
Loss at iteration 160 : 0.009297199547290802
Loss at iteration 170 : 0.01142825372517109
Loss at iteration 180 : 0.007998279295861721
Loss at iteration 190 : 0.011301718652248383
Loss at iteration 200 : 0.006076555233448744
Loss at iteration 210 : 0.01293091382831335
Loss at iteration 220 : 0.009685197845101357
Loss at iteration 230 : 0.009665046818554401
Loss at iteration 240 : 0.01559760607779026
Loss at iteration 250 : 0.0077267056331038475
Loss at iteration 260 : 0.01673733815550804
Loss at iteration 270 : 0.007461402099579573
Loss at iteration 280 : 0.009303610771894455
Loss at iteration 290 : 0.007899974472820759
Loss at iteration 300 : 0.012409677729010582
Loss at iteration 310 : 0.0086964787915349
Loss at iteration 320 : 0.006914925761520863
Loss at iteration 330 : 0.03158990293741226
Loss at iteration 340 : 0.006618649698793888
Loss at iteration 350 : 0.008359799161553383
Loss at iteration 360 : 0.00579524040222168
Loss at iteration 370 : 0.017925487831234932
Loss at iteration 380 : 0.018176794052124023
Loss at iteration 390 : 0.011116932146251202
Loss at iteration 400 : 0.007027161307632923
Loss at iteration 410 : 0.01460220292210579
Loss at iteration 420 : 0.00685000978410244
Loss at iteration 430 : 0.015956779941916466
Loss at iteration 440 : 0.013390175998210907
Loss at iteration 450 : 0.010439335368573666
Loss at iteration 460 : 0.009439488872885704
Loss at iteration 470 : 0.01697872392833233
Loss at iteration 480 : 0.010488038882613182
Loss at iteration 490 : 0.013634975999593735
Loss at iteration 500 : 0.011303309351205826
Loss at iteration 510 : 0.009403176605701447
Loss at iteration 520 : 0.008654452860355377
Loss at iteration 530 : 0.005604512989521027
Loss at iteration 540 : 0.011072573252022266
Loss at iteration 550 : 0.01946977525949478
Loss at iteration 560 : 0.011479705572128296
Loss at iteration 570 : 0.009100168943405151
Loss at iteration 580 : 0.012669039890170097
Loss at iteration 590 : 0.00911610946059227
Loss at iteration 600 : 0.007642488926649094
Loss at iteration 610 : 0.00738750584423542
Loss at iteration 620 : 0.0142172547057271
Loss at iteration 630 : 0.01110597513616085
Loss at iteration 640 : 0.012595808133482933
Loss at iteration 650 : 0.007834569551050663
Loss at iteration 660 : 0.007887828163802624
Loss at iteration 670 : 0.009334921836853027
Loss at iteration 680 : 0.0070893471129238605
Loss at iteration 690 : 0.006771501153707504
Loss at iteration 700 : 0.011264354921877384
Loss at iteration 710 : 0.008866880089044571
Loss at iteration 720 : 0.008616033010184765
Loss at iteration 730 : 0.008488934487104416
Loss at iteration 740 : 0.009775116108357906
Loss at iteration 750 : 0.007257196586579084
Loss at iteration 760 : 0.0074869319796562195
Loss at iteration 770 : 0.0071219285018742085
Loss at iteration 780 : 0.009351743385195732
Loss at iteration 790 : 0.00840370636433363
Loss at iteration 800 : 0.004792060703039169
Loss at iteration 810 : 0.00884225033223629
Loss at iteration 820 : 0.01101491879671812
Loss at iteration 830 : 0.012059396132826805
Loss at iteration 840 : 0.009732801467180252
Loss at iteration 850 : 0.008689040318131447
Loss at iteration 860 : 0.007882185280323029
Loss at iteration 870 : 0.006134070456027985
Loss at iteration 880 : 0.010534119792282581
Loss at iteration 890 : 0.008721199817955494
Loss at iteration 900 : 0.01453455351293087
Loss at iteration 910 : 0.010737475007772446
Loss at iteration 920 : 0.007500068750232458
Loss at iteration 930 : 0.007081533782184124
Loss at iteration 940 : 0.01077902503311634
Loss at iteration 950 : 0.010279900394380093
Loss at iteration 960 : 0.01853271760046482
Loss at iteration 970 : 0.007960684597492218
Loss at iteration 980 : 0.006774383597075939
Loss at iteration 990 : 0.008957508951425552
Loss at iteration 1000 : 0.020667849108576775
Loss at iteration 1010 : 0.006873912177979946
Loss at iteration 1020 : 0.009372781962156296
Loss at iteration 1030 : 0.006567488424479961
Loss at iteration 1040 : 0.01736307144165039
Loss at iteration 1050 : 0.004852928686887026
Loss at iteration 1060 : 0.009618230164051056
Loss at iteration 1070 : 0.014388151466846466
Loss at iteration 1080 : 0.007142769638448954
Loss at iteration 1090 : 0.01109493337571621
Loss at iteration 1100 : 0.005691850557923317
Loss at iteration 1110 : 0.01633002795279026
Loss at iteration 1120 : 0.00920315645635128
Loss at iteration 1130 : 0.006824464537203312
Loss at iteration 1140 : 0.005937433801591396
Loss at iteration 1150 : 0.007864647544920444
Loss at iteration 1160 : 0.016065845265984535
Loss at iteration 1170 : 0.012346587143838406
Loss at iteration 1180 : 0.014514744281768799
Loss at iteration 1190 : 0.020654620602726936
Loss at iteration 1200 : 0.019571498036384583
Loss at iteration 1210 : 0.008408697322010994
The SSIM Value is: 0.7951123952865601
The PSNR Value is: 18.154320844014485
the epoch is: 142
Loss at iteration 10 : 0.013106267899274826
Loss at iteration 20 : 0.009587064385414124
Loss at iteration 30 : 0.005784770008176565
Loss at iteration 40 : 0.007217861246317625
Loss at iteration 50 : 0.00778600899502635
Loss at iteration 60 : 0.0077601647935807705
Loss at iteration 70 : 0.01096121221780777
Loss at iteration 80 : 0.009458489716053009
Loss at iteration 90 : 0.010556207038462162
Loss at iteration 100 : 0.010358123108744621
Loss at iteration 110 : 0.00785905122756958
Loss at iteration 120 : 0.021660856902599335
Loss at iteration 130 : 0.009502456523478031
Loss at iteration 140 : 0.00783125776797533
Loss at iteration 150 : 0.009185634553432465
Loss at iteration 160 : 0.009928468614816666
Loss at iteration 170 : 0.012326979078352451
Loss at iteration 180 : 0.019195985049009323
Loss at iteration 190 : 0.009204423055052757
Loss at iteration 200 : 0.007027850486338139
Loss at iteration 210 : 0.009580916725099087
Loss at iteration 220 : 0.00848735123872757
Loss at iteration 230 : 0.014258762821555138
Loss at iteration 240 : 0.00886068306863308
Loss at iteration 250 : 0.008812780492007732
Loss at iteration 260 : 0.0062101767398417
Loss at iteration 270 : 0.01005440391600132
Loss at iteration 280 : 0.008031743578612804
Loss at iteration 290 : 0.006742656230926514
Loss at iteration 300 : 0.008923148736357689
Loss at iteration 310 : 0.0102790966629982
Loss at iteration 320 : 0.006730543449521065
Loss at iteration 330 : 0.010114465840160847
Loss at iteration 340 : 0.009822268970310688
Loss at iteration 350 : 0.008335096761584282
Loss at iteration 360 : 0.008924417197704315
Loss at iteration 370 : 0.010386716574430466
Loss at iteration 380 : 0.011401128023862839
Loss at iteration 390 : 0.009500095620751381
Loss at iteration 400 : 0.012659293599426746
Loss at iteration 410 : 0.010152439586818218
Loss at iteration 420 : 0.010180482640862465
Loss at iteration 430 : 0.007496415637433529
Loss at iteration 440 : 0.007213548757135868
Loss at iteration 450 : 0.004384736064821482
Loss at iteration 460 : 0.007632532622665167
Loss at iteration 470 : 0.011901281774044037
Loss at iteration 480 : 0.011855106800794601
Loss at iteration 490 : 0.011737493798136711
Loss at iteration 500 : 0.010235317051410675
Loss at iteration 510 : 0.011308654211461544
Loss at iteration 520 : 0.013071379624307156
Loss at iteration 530 : 0.0073409248143434525
Loss at iteration 540 : 0.010728073306381702
Loss at iteration 550 : 0.010491466149687767
Loss at iteration 560 : 0.014573543332517147
Loss at iteration 570 : 0.014381912536919117
Loss at iteration 580 : 0.010290300473570824
Loss at iteration 590 : 0.005381423979997635
Loss at iteration 600 : 0.012923839502036572
Loss at iteration 610 : 0.011597374454140663
Loss at iteration 620 : 0.02082568034529686
Loss at iteration 630 : 0.008106335997581482
Loss at iteration 640 : 0.009633444249629974
Loss at iteration 650 : 0.014427809044718742
Loss at iteration 660 : 0.014385918155312538
Loss at iteration 670 : 0.011582517996430397
Loss at iteration 680 : 0.010954653844237328
Loss at iteration 690 : 0.008040552027523518
Loss at iteration 700 : 0.012899333611130714
Loss at iteration 710 : 0.017264248803257942
Loss at iteration 720 : 0.011928070336580276
Loss at iteration 730 : 0.007429545279592276
Loss at iteration 740 : 0.009481849148869514
Loss at iteration 750 : 0.005727187730371952
Loss at iteration 760 : 0.010123303160071373
Loss at iteration 770 : 0.006711332593113184
Loss at iteration 780 : 0.0156706590205431
Loss at iteration 790 : 0.009702811948955059
Loss at iteration 800 : 0.006951652467250824
Loss at iteration 810 : 0.013913733884692192
Loss at iteration 820 : 0.009681237861514091
Loss at iteration 830 : 0.007254031486809254
Loss at iteration 840 : 0.010150960646569729
Loss at iteration 850 : 0.0076209125109016895
Loss at iteration 860 : 0.011831536889076233
Loss at iteration 870 : 0.02261946350336075
Loss at iteration 880 : 0.01623830758035183
Loss at iteration 890 : 0.005135169252753258
Loss at iteration 900 : 0.014547512866556644
Loss at iteration 910 : 0.01021630596369505
Loss at iteration 920 : 0.006273828446865082
Loss at iteration 930 : 0.012180534191429615
Loss at iteration 940 : 0.007076852954924107
Loss at iteration 950 : 0.005377009976655245
Loss at iteration 960 : 0.008979667909443378
Loss at iteration 970 : 0.007660482544451952
Loss at iteration 980 : 0.008595136925578117
Loss at iteration 990 : 0.014172723516821861
Loss at iteration 1000 : 0.007889541797339916
Loss at iteration 1010 : 0.01589299365878105
Loss at iteration 1020 : 0.0142738688737154
Loss at iteration 1030 : 0.011272401548922062
Loss at iteration 1040 : 0.009631031192839146
Loss at iteration 1050 : 0.01127367839217186
Loss at iteration 1060 : 0.007557970006018877
Loss at iteration 1070 : 0.005780921317636967
Loss at iteration 1080 : 0.013464861549437046
Loss at iteration 1090 : 0.008077709935605526
Loss at iteration 1100 : 0.006820612121373415
Loss at iteration 1110 : 0.008514022454619408
Loss at iteration 1120 : 0.011050383560359478
Loss at iteration 1130 : 0.007505189627408981
Loss at iteration 1140 : 0.0064853099174797535
Loss at iteration 1150 : 0.007599974982440472
Loss at iteration 1160 : 0.0054443832486867905
Loss at iteration 1170 : 0.011130286380648613
Loss at iteration 1180 : 0.0071245357394218445
Loss at iteration 1190 : 0.007774529047310352
Loss at iteration 1200 : 0.009780511260032654
Loss at iteration 1210 : 0.00993665773421526
The SSIM Value is: 0.7948650121688843
The PSNR Value is: 18.023977025349936
the epoch is: 143
Loss at iteration 10 : 0.008601583540439606
Loss at iteration 20 : 0.009569728747010231
Loss at iteration 30 : 0.010242598131299019
Loss at iteration 40 : 0.010708119720220566
Loss at iteration 50 : 0.011094730347394943
Loss at iteration 60 : 0.016513466835021973
Loss at iteration 70 : 0.009731920436024666
Loss at iteration 80 : 0.010491297580301762
Loss at iteration 90 : 0.012703499756753445
Loss at iteration 100 : 0.008763820864260197
Loss at iteration 110 : 0.007320701610296965
Loss at iteration 120 : 0.007143991068005562
Loss at iteration 130 : 0.009760869666934013
Loss at iteration 140 : 0.014457306824624538
Loss at iteration 150 : 0.011720768176019192
Loss at iteration 160 : 0.00923075806349516
Loss at iteration 170 : 0.008497456088662148
Loss at iteration 180 : 0.011424155905842781
Loss at iteration 190 : 0.013843568041920662
Loss at iteration 200 : 0.008373583666980267
Loss at iteration 210 : 0.007434587925672531
Loss at iteration 220 : 0.012295004911720753
Loss at iteration 230 : 0.017864670604467392
Loss at iteration 240 : 0.010155264288187027
Loss at iteration 250 : 0.009696537628769875
Loss at iteration 260 : 0.007570477202534676
Loss at iteration 270 : 0.011525128036737442
Loss at iteration 280 : 0.011604724451899529
Loss at iteration 290 : 0.011654634028673172
Loss at iteration 300 : 0.006142245605587959
Loss at iteration 310 : 0.008370602503418922
Loss at iteration 320 : 0.009355701506137848
Loss at iteration 330 : 0.020238347351551056
Loss at iteration 340 : 0.009498229250311852
Loss at iteration 350 : 0.014026008546352386
Loss at iteration 360 : 0.008876608684659004
Loss at iteration 370 : 0.011236421763896942
Loss at iteration 380 : 0.007677361834794283
Loss at iteration 390 : 0.005551239475607872
Loss at iteration 400 : 0.011990695260465145
Loss at iteration 410 : 0.015826905146241188
Loss at iteration 420 : 0.02319922111928463
Loss at iteration 430 : 0.012352995574474335
Loss at iteration 440 : 0.012668738141655922
Loss at iteration 450 : 0.007168326526880264
Loss at iteration 460 : 0.016548670828342438
Loss at iteration 470 : 0.01622147113084793
Loss at iteration 480 : 0.013477864675223827
Loss at iteration 490 : 0.006091447081416845
Loss at iteration 500 : 0.011180362664163113
Loss at iteration 510 : 0.006353248842060566
Loss at iteration 520 : 0.0098538463935256
Loss at iteration 530 : 0.008472185581922531
Loss at iteration 540 : 0.009363248944282532
Loss at iteration 550 : 0.013583438470959663
Loss at iteration 560 : 0.01309931743890047
Loss at iteration 570 : 0.011565595865249634
Loss at iteration 580 : 0.011071352288126945
Loss at iteration 590 : 0.0130569813773036
Loss at iteration 600 : 0.011703379452228546
Loss at iteration 610 : 0.007121644448488951
Loss at iteration 620 : 0.015651218593120575
Loss at iteration 630 : 0.015671726316213608
Loss at iteration 640 : 0.007760317996144295
Loss at iteration 650 : 0.015927661210298538
Loss at iteration 660 : 0.010523947887122631
Loss at iteration 670 : 0.010116420686244965
Loss at iteration 680 : 0.013672319240868092
Loss at iteration 690 : 0.01300355140119791
Loss at iteration 700 : 0.008477836847305298
Loss at iteration 710 : 0.007544468156993389
Loss at iteration 720 : 0.013601139187812805
Loss at iteration 730 : 0.013832714408636093
Loss at iteration 740 : 0.010068139992654324
Loss at iteration 750 : 0.00755325797945261
Loss at iteration 760 : 0.010604609735310078
Loss at iteration 770 : 0.02235695719718933
Loss at iteration 780 : 0.00873298104852438
Loss at iteration 790 : 0.009682010859251022
Loss at iteration 800 : 0.013843635097146034
Loss at iteration 810 : 0.0077406251803040504
Loss at iteration 820 : 0.0059776813723146915
Loss at iteration 830 : 0.014111438766121864
Loss at iteration 840 : 0.011496326886117458
Loss at iteration 850 : 0.007349207065999508
Loss at iteration 860 : 0.011240348219871521
Loss at iteration 870 : 0.01058674044907093
Loss at iteration 880 : 0.01136168371886015
Loss at iteration 890 : 0.01876971125602722
Loss at iteration 900 : 0.023702142760157585
Loss at iteration 910 : 0.010824894532561302
Loss at iteration 920 : 0.007406502030789852
Loss at iteration 930 : 0.013978034257888794
Loss at iteration 940 : 0.013316245749592781
Loss at iteration 950 : 0.01791776344180107
Loss at iteration 960 : 0.019412193447351456
Loss at iteration 970 : 0.012335799634456635
Loss at iteration 980 : 0.007559420075267553
Loss at iteration 990 : 0.01114293560385704
Loss at iteration 1000 : 0.010340660810470581
Loss at iteration 1010 : 0.008042081259191036
Loss at iteration 1020 : 0.010894110426306725
Loss at iteration 1030 : 0.009768608957529068
Loss at iteration 1040 : 0.007895968854427338
Loss at iteration 1050 : 0.005619990639388561
Loss at iteration 1060 : 0.011586819775402546
Loss at iteration 1070 : 0.006485293619334698
Loss at iteration 1080 : 0.009033288806676865
Loss at iteration 1090 : 0.009781545028090477
Loss at iteration 1100 : 0.008888067677617073
Loss at iteration 1110 : 0.017716363072395325
Loss at iteration 1120 : 0.0054906257428228855
Loss at iteration 1130 : 0.01409476064145565
Loss at iteration 1140 : 0.007017116062343121
Loss at iteration 1150 : 0.007516753859817982
Loss at iteration 1160 : 0.024073999375104904
Loss at iteration 1170 : 0.00915005523711443
Loss at iteration 1180 : 0.006957724690437317
Loss at iteration 1190 : 0.009077344089746475
Loss at iteration 1200 : 0.0118279829621315
Loss at iteration 1210 : 0.010552858002483845
The SSIM Value is: 0.8000257968902588
The PSNR Value is: 18.205020268758137
the epoch is: 144
Loss at iteration 10 : 0.004683272913098335
Loss at iteration 20 : 0.00913160014897585
Loss at iteration 30 : 0.011269547045230865
Loss at iteration 40 : 0.019323963671922684
Loss at iteration 50 : 0.007003634702414274
Loss at iteration 60 : 0.00726452236995101
Loss at iteration 70 : 0.01613224484026432
Loss at iteration 80 : 0.017731355503201485
Loss at iteration 90 : 0.013040224090218544
Loss at iteration 100 : 0.007832102477550507
Loss at iteration 110 : 0.00861944817006588
Loss at iteration 120 : 0.014794107526540756
Loss at iteration 130 : 0.011351285502314568
Loss at iteration 140 : 0.005807668901979923
Loss at iteration 150 : 0.008363277651369572
Loss at iteration 160 : 0.009226853027939796
Loss at iteration 170 : 0.015049745328724384
Loss at iteration 180 : 0.012670894153416157
Loss at iteration 190 : 0.010104016400873661
Loss at iteration 200 : 0.012593405321240425
Loss at iteration 210 : 0.019008859992027283
Loss at iteration 220 : 0.012143068946897984
Loss at iteration 230 : 0.012610056437551975
Loss at iteration 240 : 0.009366197511553764
Loss at iteration 250 : 0.006182590965181589
Loss at iteration 260 : 0.011797044426202774
Loss at iteration 270 : 0.014342008158564568
Loss at iteration 280 : 0.015092050656676292
Loss at iteration 290 : 0.008918524719774723
Loss at iteration 300 : 0.014181602746248245
Loss at iteration 310 : 0.008618087507784367
Loss at iteration 320 : 0.010502570308744907
Loss at iteration 330 : 0.014655414037406445
Loss at iteration 340 : 0.011925114318728447
Loss at iteration 350 : 0.009911459870636463
Loss at iteration 360 : 0.00782777089625597
Loss at iteration 370 : 0.01046716421842575
Loss at iteration 380 : 0.009440400637686253
Loss at iteration 390 : 0.005577452015131712
Loss at iteration 400 : 0.010454384610056877
Loss at iteration 410 : 0.006514326669275761
Loss at iteration 420 : 0.013458207249641418
Loss at iteration 430 : 0.007782687898725271
Loss at iteration 440 : 0.008919090032577515
Loss at iteration 450 : 0.012003843672573566
Loss at iteration 460 : 0.007075081579387188
Loss at iteration 470 : 0.005920276045799255
Loss at iteration 480 : 0.011289987713098526
Loss at iteration 490 : 0.011250008828938007
Loss at iteration 500 : 0.01212247647345066
Loss at iteration 510 : 0.013680783100426197
Loss at iteration 520 : 0.014344551600515842
Loss at iteration 530 : 0.010698388330638409
Loss at iteration 540 : 0.007109924219548702
Loss at iteration 550 : 0.011233764700591564
Loss at iteration 560 : 0.006848247721791267
Loss at iteration 570 : 0.008621806278824806
Loss at iteration 580 : 0.01091351080685854
Loss at iteration 590 : 0.00954311341047287
Loss at iteration 600 : 0.009104421362280846
Loss at iteration 610 : 0.01331259310245514
Loss at iteration 620 : 0.010074712336063385
Loss at iteration 630 : 0.012009731493890285
Loss at iteration 640 : 0.011449022218585014
Loss at iteration 650 : 0.009134742431342602
Loss at iteration 660 : 0.013428403064608574
Loss at iteration 670 : 0.013410198502242565
Loss at iteration 680 : 0.0068559288047254086
Loss at iteration 690 : 0.007058114279061556
Loss at iteration 700 : 0.007714961189776659
Loss at iteration 710 : 0.006998318713158369
Loss at iteration 720 : 0.007060597185045481
Loss at iteration 730 : 0.013890371657907963
Loss at iteration 740 : 0.006920514162629843
Loss at iteration 750 : 0.015568762086331844
Loss at iteration 760 : 0.00673694210126996
Loss at iteration 770 : 0.00955682061612606
Loss at iteration 780 : 0.01346468273550272
Loss at iteration 790 : 0.011674372479319572
Loss at iteration 800 : 0.010813767090439796
Loss at iteration 810 : 0.012008428573608398
Loss at iteration 820 : 0.009220771491527557
Loss at iteration 830 : 0.009835485368967056
Loss at iteration 840 : 0.005616350099444389
Loss at iteration 850 : 0.010251982137560844
Loss at iteration 860 : 0.012846922501921654
Loss at iteration 870 : 0.018764469772577286
Loss at iteration 880 : 0.017570646479725838
Loss at iteration 890 : 0.00997422356158495
Loss at iteration 900 : 0.007574001792818308
Loss at iteration 910 : 0.011710310354828835
Loss at iteration 920 : 0.01037629321217537
Loss at iteration 930 : 0.01336759328842163
Loss at iteration 940 : 0.011296585202217102
Loss at iteration 950 : 0.01717088185250759
Loss at iteration 960 : 0.008162427693605423
Loss at iteration 970 : 0.014050498604774475
Loss at iteration 980 : 0.00778748607262969
Loss at iteration 990 : 0.008126990869641304
Loss at iteration 1000 : 0.01222088374197483
Loss at iteration 1010 : 0.009844250977039337
Loss at iteration 1020 : 0.013786401599645615
Loss at iteration 1030 : 0.009355559945106506
Loss at iteration 1040 : 0.008213566616177559
Loss at iteration 1050 : 0.008510757237672806
Loss at iteration 1060 : 0.00823486503213644
Loss at iteration 1070 : 0.012661588378250599
Loss at iteration 1080 : 0.0057861413806676865
Loss at iteration 1090 : 0.00677991658449173
Loss at iteration 1100 : 0.008600534871220589
Loss at iteration 1110 : 0.010848055593669415
Loss at iteration 1120 : 0.010634537786245346
Loss at iteration 1130 : 0.008505605161190033
Loss at iteration 1140 : 0.01187952235341072
Loss at iteration 1150 : 0.00564699899405241
Loss at iteration 1160 : 0.0063501703552901745
Loss at iteration 1170 : 0.007463731337338686
Loss at iteration 1180 : 0.010733827017247677
Loss at iteration 1190 : 0.009356778115034103
Loss at iteration 1200 : 0.009486088529229164
Loss at iteration 1210 : 0.012026002630591393
The SSIM Value is: 0.7877130389213562
The PSNR Value is: 17.547754605611164
the epoch is: 145
Loss at iteration 10 : 0.008919409476220608
Loss at iteration 20 : 0.010310756042599678
Loss at iteration 30 : 0.011721640825271606
Loss at iteration 40 : 0.016239991411566734
Loss at iteration 50 : 0.014975464902818203
Loss at iteration 60 : 0.007343233097344637
Loss at iteration 70 : 0.011198412626981735
Loss at iteration 80 : 0.007289681117981672
Loss at iteration 90 : 0.015529608353972435
Loss at iteration 100 : 0.016020197421312332
Loss at iteration 110 : 0.011411629617214203
Loss at iteration 120 : 0.007579195313155651
Loss at iteration 130 : 0.011220305226743221
Loss at iteration 140 : 0.011409450322389603
Loss at iteration 150 : 0.009665250778198242
Loss at iteration 160 : 0.010808811523020267
Loss at iteration 170 : 0.011185129173099995
Loss at iteration 180 : 0.016914494335651398
Loss at iteration 190 : 0.011932995170354843
Loss at iteration 200 : 0.01112140342593193
Loss at iteration 210 : 0.007573375478386879
Loss at iteration 220 : 0.007231301162391901
Loss at iteration 230 : 0.010313120670616627
Loss at iteration 240 : 0.006982172839343548
Loss at iteration 250 : 0.014558111317455769
Loss at iteration 260 : 0.008746141567826271
Loss at iteration 270 : 0.009981188923120499
Loss at iteration 280 : 0.006269840989261866
Loss at iteration 290 : 0.007001708727329969
Loss at iteration 300 : 0.012423764914274216
Loss at iteration 310 : 0.013910597190260887
Loss at iteration 320 : 0.006414853502064943
Loss at iteration 330 : 0.008940892294049263
Loss at iteration 340 : 0.01648758351802826
Loss at iteration 350 : 0.009145780466496944
Loss at iteration 360 : 0.011546892113983631
Loss at iteration 370 : 0.013752415776252747
Loss at iteration 380 : 0.01409417949616909
Loss at iteration 390 : 0.0090686846524477
Loss at iteration 400 : 0.00805366039276123
Loss at iteration 410 : 0.007277102675288916
Loss at iteration 420 : 0.008787479251623154
Loss at iteration 430 : 0.008553391322493553
Loss at iteration 440 : 0.00679459935054183
Loss at iteration 450 : 0.019126195460557938
Loss at iteration 460 : 0.008519398048520088
Loss at iteration 470 : 0.009388256818056107
Loss at iteration 480 : 0.01276138424873352
Loss at iteration 490 : 0.010656350292265415
Loss at iteration 500 : 0.01646963320672512
Loss at iteration 510 : 0.011066028848290443
Loss at iteration 520 : 0.007083140313625336
Loss at iteration 530 : 0.00869083870202303
Loss at iteration 540 : 0.01002836599946022
Loss at iteration 550 : 0.008577458560466766
Loss at iteration 560 : 0.00894187018275261
Loss at iteration 570 : 0.01072831079363823
Loss at iteration 580 : 0.017943421378731728
Loss at iteration 590 : 0.010791274718940258
Loss at iteration 600 : 0.012247668579220772
Loss at iteration 610 : 0.007694158237427473
Loss at iteration 620 : 0.007537546567618847
Loss at iteration 630 : 0.011031195521354675
Loss at iteration 640 : 0.011808662675321102
Loss at iteration 650 : 0.01239393837749958
Loss at iteration 660 : 0.011242356151342392
Loss at iteration 670 : 0.008448154665529728
Loss at iteration 680 : 0.00998380221426487
Loss at iteration 690 : 0.009132747538387775
Loss at iteration 700 : 0.011100774630904198
Loss at iteration 710 : 0.012787696905434132
Loss at iteration 720 : 0.007179034873843193
Loss at iteration 730 : 0.01061147078871727
Loss at iteration 740 : 0.010969612747430801
Loss at iteration 750 : 0.009637188166379929
Loss at iteration 760 : 0.012258936651051044
Loss at iteration 770 : 0.022584903985261917
Loss at iteration 780 : 0.011681313626468182
Loss at iteration 790 : 0.010793217457830906
Loss at iteration 800 : 0.010681554675102234
Loss at iteration 810 : 0.013654978014528751
Loss at iteration 820 : 0.008973955176770687
Loss at iteration 830 : 0.011661233380436897
Loss at iteration 840 : 0.006122504360973835
Loss at iteration 850 : 0.009029440581798553
Loss at iteration 860 : 0.007799306884407997
Loss at iteration 870 : 0.009681260213255882
Loss at iteration 880 : 0.011915668845176697
Loss at iteration 890 : 0.012954004108905792
Loss at iteration 900 : 0.006972246803343296
Loss at iteration 910 : 0.010226300917565823
Loss at iteration 920 : 0.009262307547032833
Loss at iteration 930 : 0.01886480301618576
Loss at iteration 940 : 0.00853884220123291
Loss at iteration 950 : 0.015688907355070114
Loss at iteration 960 : 0.010909182950854301
Loss at iteration 970 : 0.006487525068223476
Loss at iteration 980 : 0.009640518575906754
Loss at iteration 990 : 0.009037001989781857
Loss at iteration 1000 : 0.008294431492686272
Loss at iteration 1010 : 0.009032582864165306
Loss at iteration 1020 : 0.008732778020203114
Loss at iteration 1030 : 0.008046414703130722
Loss at iteration 1040 : 0.008501075208187103
Loss at iteration 1050 : 0.009724174626171589
Loss at iteration 1060 : 0.007357282564043999
Loss at iteration 1070 : 0.008092117495834827
Loss at iteration 1080 : 0.012209311127662659
Loss at iteration 1090 : 0.012278493493795395
Loss at iteration 1100 : 0.010052934288978577
Loss at iteration 1110 : 0.007995526306331158
Loss at iteration 1120 : 0.006550664082169533
Loss at iteration 1130 : 0.013477768748998642
Loss at iteration 1140 : 0.016432607546448708
Loss at iteration 1150 : 0.009666020050644875
Loss at iteration 1160 : 0.007544791325926781
Loss at iteration 1170 : 0.008296218700706959
Loss at iteration 1180 : 0.010574274696409702
Loss at iteration 1190 : 0.00975501723587513
Loss at iteration 1200 : 0.010778759606182575
Loss at iteration 1210 : 0.011582767590880394
The SSIM Value is: 0.8043607036272685
The PSNR Value is: 18.648881848653158
the epoch is: 146
Loss at iteration 10 : 0.010616306215524673
Loss at iteration 20 : 0.010599714703857899
Loss at iteration 30 : 0.005992867052555084
Loss at iteration 40 : 0.007882025092840195
Loss at iteration 50 : 0.008290927857160568
Loss at iteration 60 : 0.008256652392446995
Loss at iteration 70 : 0.01905575394630432
Loss at iteration 80 : 0.011975101195275784
Loss at iteration 90 : 0.012765403836965561
Loss at iteration 100 : 0.013540109619498253
Loss at iteration 110 : 0.007831967435777187
Loss at iteration 120 : 0.010831151157617569
Loss at iteration 130 : 0.012174208648502827
Loss at iteration 140 : 0.007987653836607933
Loss at iteration 150 : 0.015147027559578419
Loss at iteration 160 : 0.009819204919040203
Loss at iteration 170 : 0.01213496457785368
Loss at iteration 180 : 0.014326827600598335
Loss at iteration 190 : 0.007118264213204384
Loss at iteration 200 : 0.009810172021389008
Loss at iteration 210 : 0.006473215762525797
Loss at iteration 220 : 0.009913358837366104
Loss at iteration 230 : 0.006247145589441061
Loss at iteration 240 : 0.006283475086092949
Loss at iteration 250 : 0.012793714180588722
Loss at iteration 260 : 0.01065116561949253
Loss at iteration 270 : 0.015256570652127266
Loss at iteration 280 : 0.010322634130716324
Loss at iteration 290 : 0.007385612465441227
Loss at iteration 300 : 0.013628987595438957
Loss at iteration 310 : 0.01349618285894394
Loss at iteration 320 : 0.011419561691582203
Loss at iteration 330 : 0.010768156498670578
Loss at iteration 340 : 0.013399245217442513
Loss at iteration 350 : 0.01062796637415886
Loss at iteration 360 : 0.011346825398504734
Loss at iteration 370 : 0.013756085187196732
Loss at iteration 380 : 0.008139507845044136
Loss at iteration 390 : 0.008062046952545643
Loss at iteration 400 : 0.008143425919115543
Loss at iteration 410 : 0.007008448243141174
Loss at iteration 420 : 0.006782385520637035
Loss at iteration 430 : 0.00853799469769001
Loss at iteration 440 : 0.009491628035902977
Loss at iteration 450 : 0.008620062842965126
Loss at iteration 460 : 0.023092210292816162
Loss at iteration 470 : 0.013288951478898525
Loss at iteration 480 : 0.009568615816533566
Loss at iteration 490 : 0.012371988967061043
Loss at iteration 500 : 0.007369767874479294
Loss at iteration 510 : 0.006812140345573425
Loss at iteration 520 : 0.01197520550340414
Loss at iteration 530 : 0.015901118516921997
Loss at iteration 540 : 0.007951231673359871
Loss at iteration 550 : 0.008555266074836254
Loss at iteration 560 : 0.011188056319952011
Loss at iteration 570 : 0.017222056165337563
Loss at iteration 580 : 0.00889345072209835
Loss at iteration 590 : 0.01113963220268488
Loss at iteration 600 : 0.00861014612019062
Loss at iteration 610 : 0.005809143651276827
Loss at iteration 620 : 0.011339223012328148
Loss at iteration 630 : 0.013657737523317337
Loss at iteration 640 : 0.011509547010064125
Loss at iteration 650 : 0.007611304521560669
Loss at iteration 660 : 0.008863339200615883
Loss at iteration 670 : 0.008748592808842659
Loss at iteration 680 : 0.007693416438996792
Loss at iteration 690 : 0.01692943647503853
Loss at iteration 700 : 0.004728024825453758
Loss at iteration 710 : 0.006743415724486113
Loss at iteration 720 : 0.011675870977342129
Loss at iteration 730 : 0.004932311363518238
Loss at iteration 740 : 0.008511667139828205
Loss at iteration 750 : 0.011039219796657562
Loss at iteration 760 : 0.007636150345206261
Loss at iteration 770 : 0.00929954182356596
Loss at iteration 780 : 0.010252019390463829
Loss at iteration 790 : 0.01479228213429451
Loss at iteration 800 : 0.010534625500440598
Loss at iteration 810 : 0.011500694788992405
Loss at iteration 820 : 0.006851418875157833
Loss at iteration 830 : 0.012111707590520382
Loss at iteration 840 : 0.00584507267922163
Loss at iteration 850 : 0.008379234932363033
Loss at iteration 860 : 0.018008477985858917
Loss at iteration 870 : 0.008487442508339882
Loss at iteration 880 : 0.01016745064407587
Loss at iteration 890 : 0.009926963597536087
Loss at iteration 900 : 0.009529084898531437
Loss at iteration 910 : 0.013455703854560852
Loss at iteration 920 : 0.009481871500611305
Loss at iteration 930 : 0.008047353476285934
Loss at iteration 940 : 0.010247691534459591
Loss at iteration 950 : 0.007452199701219797
Loss at iteration 960 : 0.008071070536971092
Loss at iteration 970 : 0.0050997561775147915
Loss at iteration 980 : 0.013845190405845642
Loss at iteration 990 : 0.010196700692176819
Loss at iteration 1000 : 0.012189365923404694
Loss at iteration 1010 : 0.017127329483628273
Loss at iteration 1020 : 0.012343570590019226
Loss at iteration 1030 : 0.008340945467352867
Loss at iteration 1040 : 0.00758218253031373
Loss at iteration 1050 : 0.006504524499177933
Loss at iteration 1060 : 0.017776262015104294
Loss at iteration 1070 : 0.007253460586071014
Loss at iteration 1080 : 0.004830310121178627
Loss at iteration 1090 : 0.016431625932455063
Loss at iteration 1100 : 0.00951273925602436
Loss at iteration 1110 : 0.009293998591601849
Loss at iteration 1120 : 0.011799953877925873
Loss at iteration 1130 : 0.009119494818150997
Loss at iteration 1140 : 0.013602527789771557
Loss at iteration 1150 : 0.01189766451716423
Loss at iteration 1160 : 0.0083259716629982
Loss at iteration 1170 : 0.010422661900520325
Loss at iteration 1180 : 0.007640718016773462
Loss at iteration 1190 : 0.00828840397298336
Loss at iteration 1200 : 0.012452836148440838
Loss at iteration 1210 : 0.012383383698761463
The SSIM Value is: 0.778802627325058
The PSNR Value is: 17.18479849497477
the epoch is: 147
Loss at iteration 10 : 0.009820414707064629
Loss at iteration 20 : 0.008043094538152218
Loss at iteration 30 : 0.011067165061831474
Loss at iteration 40 : 0.00671722274273634
Loss at iteration 50 : 0.010586461052298546
Loss at iteration 60 : 0.007929312065243721
Loss at iteration 70 : 0.0086611183360219
Loss at iteration 80 : 0.01407634373754263
Loss at iteration 90 : 0.006144791375845671
Loss at iteration 100 : 0.014558468945324421
Loss at iteration 110 : 0.005297563504427671
Loss at iteration 120 : 0.010584864765405655
Loss at iteration 130 : 0.012706713750958443
Loss at iteration 140 : 0.01387808658182621
Loss at iteration 150 : 0.008758435025811195
Loss at iteration 160 : 0.008130598813295364
Loss at iteration 170 : 0.014259807765483856
Loss at iteration 180 : 0.009895049035549164
Loss at iteration 190 : 0.013088035397231579
Loss at iteration 200 : 0.013655012473464012
Loss at iteration 210 : 0.013714497908949852
Loss at iteration 220 : 0.008862138725817204
Loss at iteration 230 : 0.007274279836565256
Loss at iteration 240 : 0.010489420965313911
Loss at iteration 250 : 0.010018700733780861
Loss at iteration 260 : 0.007786410395056009
Loss at iteration 270 : 0.016472745686769485
Loss at iteration 280 : 0.006839234847575426
Loss at iteration 290 : 0.01238333061337471
Loss at iteration 300 : 0.008898629806935787
Loss at iteration 310 : 0.011036880314350128
Loss at iteration 320 : 0.011003057472407818
Loss at iteration 330 : 0.007215959019958973
Loss at iteration 340 : 0.011280438862740993
Loss at iteration 350 : 0.009226826950907707
Loss at iteration 360 : 0.015635265037417412
Loss at iteration 370 : 0.0137037243694067
Loss at iteration 380 : 0.014880678616464138
Loss at iteration 390 : 0.010842096991837025
Loss at iteration 400 : 0.006671237759292126
Loss at iteration 410 : 0.00722717447206378
Loss at iteration 420 : 0.009366491809487343
Loss at iteration 430 : 0.015196925960481167
Loss at iteration 440 : 0.008002737537026405
Loss at iteration 450 : 0.00945965014398098
Loss at iteration 460 : 0.0063995616510510445
Loss at iteration 470 : 0.007046643644571304
Loss at iteration 480 : 0.010036243125796318
Loss at iteration 490 : 0.010047422721982002
Loss at iteration 500 : 0.009957246482372284
Loss at iteration 510 : 0.006765628699213266
Loss at iteration 520 : 0.011149344965815544
Loss at iteration 530 : 0.007430765777826309
Loss at iteration 540 : 0.008551647886633873
Loss at iteration 550 : 0.008029692806303501
Loss at iteration 560 : 0.015894755721092224
Loss at iteration 570 : 0.00560853211209178
Loss at iteration 580 : 0.008213866502046585
Loss at iteration 590 : 0.00968335010111332
Loss at iteration 600 : 0.014089208096265793
Loss at iteration 610 : 0.008984070271253586
Loss at iteration 620 : 0.006664734799414873
Loss at iteration 630 : 0.012805936858057976
Loss at iteration 640 : 0.006328030023723841
Loss at iteration 650 : 0.01563408225774765
Loss at iteration 660 : 0.004593699239194393
Loss at iteration 670 : 0.009455920197069645
Loss at iteration 680 : 0.008449194952845573
Loss at iteration 690 : 0.009817153215408325
Loss at iteration 700 : 0.007769444491714239
Loss at iteration 710 : 0.011844100430607796
Loss at iteration 720 : 0.012878743931651115
Loss at iteration 730 : 0.009601345285773277
Loss at iteration 740 : 0.007860180921852589
Loss at iteration 750 : 0.010246526449918747
Loss at iteration 760 : 0.009435742162168026
Loss at iteration 770 : 0.0065087489783763885
Loss at iteration 780 : 0.009273224510252476
Loss at iteration 790 : 0.01057446375489235
Loss at iteration 800 : 0.00851893238723278
Loss at iteration 810 : 0.009580091573297977
Loss at iteration 820 : 0.012593732215464115
Loss at iteration 830 : 0.016199959442019463
Loss at iteration 840 : 0.006805892568081617
Loss at iteration 850 : 0.011163774877786636
Loss at iteration 860 : 0.009558305144309998
Loss at iteration 870 : 0.0078897625207901
Loss at iteration 880 : 0.00953509658575058
Loss at iteration 890 : 0.00808743480592966
Loss at iteration 900 : 0.010549948550760746
Loss at iteration 910 : 0.005224439315497875
Loss at iteration 920 : 0.010323449969291687
Loss at iteration 930 : 0.008837352506816387
Loss at iteration 940 : 0.015703346580266953
Loss at iteration 950 : 0.012786339968442917
Loss at iteration 960 : 0.014592986553907394
Loss at iteration 970 : 0.007953249849379063
Loss at iteration 980 : 0.01738838292658329
Loss at iteration 990 : 0.009218301624059677
Loss at iteration 1000 : 0.022465456277132034
Loss at iteration 1010 : 0.007722090929746628
Loss at iteration 1020 : 0.00788632407784462
Loss at iteration 1030 : 0.010262050665915012
Loss at iteration 1040 : 0.009251896291971207
Loss at iteration 1050 : 0.009343305602669716
Loss at iteration 1060 : 0.008945639245212078
Loss at iteration 1070 : 0.008151895366609097
Loss at iteration 1080 : 0.010480290278792381
Loss at iteration 1090 : 0.01266071293503046
Loss at iteration 1100 : 0.010786568745970726
Loss at iteration 1110 : 0.008014414459466934
Loss at iteration 1120 : 0.009661477990448475
Loss at iteration 1130 : 0.01197440642863512
Loss at iteration 1140 : 0.011804320849478245
Loss at iteration 1150 : 0.013667067512869835
Loss at iteration 1160 : 0.011196953244507313
Loss at iteration 1170 : 0.014291227795183659
Loss at iteration 1180 : 0.006674251984804869
Loss at iteration 1190 : 0.008389429189264774
Loss at iteration 1200 : 0.015179266221821308
Loss at iteration 1210 : 0.01377071626484394
The SSIM Value is: 0.8007857898871104
The PSNR Value is: 18.298656590779622
the epoch is: 148
Loss at iteration 10 : 0.006228837184607983
Loss at iteration 20 : 0.009345611557364464
Loss at iteration 30 : 0.012359559535980225
Loss at iteration 40 : 0.010220742784440517
Loss at iteration 50 : 0.008994809351861477
Loss at iteration 60 : 0.008178741671144962
Loss at iteration 70 : 0.00851560290902853
Loss at iteration 80 : 0.010333659127354622
Loss at iteration 90 : 0.007968857884407043
Loss at iteration 100 : 0.0056328559294342995
Loss at iteration 110 : 0.01188489980995655
Loss at iteration 120 : 0.022228922694921494
Loss at iteration 130 : 0.01216140016913414
Loss at iteration 140 : 0.005152849480509758
Loss at iteration 150 : 0.0066711739636957645
Loss at iteration 160 : 0.008515434339642525
Loss at iteration 170 : 0.009110850282013416
Loss at iteration 180 : 0.013679448515176773
Loss at iteration 190 : 0.00796707533299923
Loss at iteration 200 : 0.016145337373018265
Loss at iteration 210 : 0.00811729021370411
Loss at iteration 220 : 0.01099955290555954
Loss at iteration 230 : 0.011725974269211292
Loss at iteration 240 : 0.006033136043697596
Loss at iteration 250 : 0.011180419474840164
Loss at iteration 260 : 0.00634926650673151
Loss at iteration 270 : 0.005626762751489878
Loss at iteration 280 : 0.028357552364468575
Loss at iteration 290 : 0.018528012558817863
Loss at iteration 300 : 0.015915177762508392
Loss at iteration 310 : 0.01186219323426485
Loss at iteration 320 : 0.006671903654932976
Loss at iteration 330 : 0.00965127907693386
Loss at iteration 340 : 0.009933294728398323
Loss at iteration 350 : 0.019904127344489098
Loss at iteration 360 : 0.01148973498493433
Loss at iteration 370 : 0.013089541345834732
Loss at iteration 380 : 0.018459409475326538
Loss at iteration 390 : 0.009815344586968422
Loss at iteration 400 : 0.006912667769938707
Loss at iteration 410 : 0.012031039223074913
Loss at iteration 420 : 0.015535376965999603
Loss at iteration 430 : 0.0073364898562431335
Loss at iteration 440 : 0.011443054303526878
Loss at iteration 450 : 0.00535939633846283
Loss at iteration 460 : 0.018299374729394913
Loss at iteration 470 : 0.005996472202241421
Loss at iteration 480 : 0.009448644705116749
Loss at iteration 490 : 0.010825462639331818
Loss at iteration 500 : 0.01377231813967228
Loss at iteration 510 : 0.007647829595953226
Loss at iteration 520 : 0.010251177474856377
Loss at iteration 530 : 0.011524656787514687
Loss at iteration 540 : 0.008923666551709175
Loss at iteration 550 : 0.007091674022376537
Loss at iteration 560 : 0.011862391605973244
Loss at iteration 570 : 0.007963497191667557
Loss at iteration 580 : 0.011351200751960278
Loss at iteration 590 : 0.014411812648177147
Loss at iteration 600 : 0.00965929590165615
Loss at iteration 610 : 0.01727817952632904
Loss at iteration 620 : 0.008025385439395905
Loss at iteration 630 : 0.011417560279369354
Loss at iteration 640 : 0.011453998275101185
Loss at iteration 650 : 0.01220051571726799
Loss at iteration 660 : 0.0057769035920500755
Loss at iteration 670 : 0.006973637733608484
Loss at iteration 680 : 0.007726059760898352
Loss at iteration 690 : 0.026633115485310555
Loss at iteration 700 : 0.007981770671904087
Loss at iteration 710 : 0.008229098282754421
Loss at iteration 720 : 0.008771561086177826
Loss at iteration 730 : 0.011209250427782536
Loss at iteration 740 : 0.009551511146128178
Loss at iteration 750 : 0.02212405577301979
Loss at iteration 760 : 0.011278655380010605
Loss at iteration 770 : 0.023016666993498802
Loss at iteration 780 : 0.01104295626282692
Loss at iteration 790 : 0.006830193102359772
Loss at iteration 800 : 0.00813895184546709
Loss at iteration 810 : 0.008392035961151123
Loss at iteration 820 : 0.00900776032358408
Loss at iteration 830 : 0.012752720154821873
Loss at iteration 840 : 0.013418986462056637
Loss at iteration 850 : 0.011053431779146194
Loss at iteration 860 : 0.010057170875370502
Loss at iteration 870 : 0.009679236449301243
Loss at iteration 880 : 0.010856266133487225
Loss at iteration 890 : 0.011451276019215584
Loss at iteration 900 : 0.011744661256670952
Loss at iteration 910 : 0.009216622449457645
Loss at iteration 920 : 0.009811819531023502
Loss at iteration 930 : 0.00856468640267849
Loss at iteration 940 : 0.01031906995922327
Loss at iteration 950 : 0.01260814443230629
Loss at iteration 960 : 0.010094370692968369
Loss at iteration 970 : 0.012655730359256268
Loss at iteration 980 : 0.008058137260377407
Loss at iteration 990 : 0.008258011192083359
Loss at iteration 1000 : 0.010782836005091667
Loss at iteration 1010 : 0.019871214404702187
Loss at iteration 1020 : 0.015152303501963615
Loss at iteration 1030 : 0.012231608852744102
Loss at iteration 1040 : 0.0077628884464502335
Loss at iteration 1050 : 0.008041447959840298
Loss at iteration 1060 : 0.010556944645941257
Loss at iteration 1070 : 0.00920105166733265
Loss at iteration 1080 : 0.010234443470835686
Loss at iteration 1090 : 0.01012391410768032
Loss at iteration 1100 : 0.011337962001562119
Loss at iteration 1110 : 0.010856798849999905
Loss at iteration 1120 : 0.009596548974514008
Loss at iteration 1130 : 0.014886094257235527
Loss at iteration 1140 : 0.011459922417998314
Loss at iteration 1150 : 0.008638236671686172
Loss at iteration 1160 : 0.004793108440935612
Loss at iteration 1170 : 0.009620193392038345
Loss at iteration 1180 : 0.009083536453545094
Loss at iteration 1190 : 0.016860149800777435
Loss at iteration 1200 : 0.008032645098865032
Loss at iteration 1210 : 0.0077280448749661446
The SSIM Value is: 0.7985271771748861
The PSNR Value is: 18.48482189178467
the epoch is: 149
Loss at iteration 10 : 0.007181388325989246
Loss at iteration 20 : 0.014324536547064781
Loss at iteration 30 : 0.016087286174297333
Loss at iteration 40 : 0.013032084330916405
Loss at iteration 50 : 0.012118791230022907
Loss at iteration 60 : 0.010111500509083271
Loss at iteration 70 : 0.01691344752907753
Loss at iteration 80 : 0.011777841486036777
Loss at iteration 90 : 0.013681271113455296
Loss at iteration 100 : 0.009733926504850388
Loss at iteration 110 : 0.012181662023067474
Loss at iteration 120 : 0.01378548052161932
Loss at iteration 130 : 0.008494995534420013
Loss at iteration 140 : 0.01101528201252222
Loss at iteration 150 : 0.014443561434745789
Loss at iteration 160 : 0.011990094557404518
Loss at iteration 170 : 0.009172859601676464
Loss at iteration 180 : 0.012573921121656895
Loss at iteration 190 : 0.007937051355838776
Loss at iteration 200 : 0.00697151618078351
Loss at iteration 210 : 0.007809189613908529
Loss at iteration 220 : 0.013496508821845055
Loss at iteration 230 : 0.008816692978143692
Loss at iteration 240 : 0.012399655766785145
Loss at iteration 250 : 0.009798782877624035
Loss at iteration 260 : 0.00992826372385025
Loss at iteration 270 : 0.008021946996450424
Loss at iteration 280 : 0.007896417751908302
Loss at iteration 290 : 0.008420647121965885
Loss at iteration 300 : 0.010577093809843063
Loss at iteration 310 : 0.010280654765665531
Loss at iteration 320 : 0.009495130740106106
Loss at iteration 330 : 0.01308193989098072
Loss at iteration 340 : 0.012194378301501274
Loss at iteration 350 : 0.008992142975330353
Loss at iteration 360 : 0.008609337732195854
Loss at iteration 370 : 0.009138192050158978
Loss at iteration 380 : 0.007483511697500944
Loss at iteration 390 : 0.011567346751689911
Loss at iteration 400 : 0.007296717260032892
Loss at iteration 410 : 0.016211804002523422
Loss at iteration 420 : 0.005373240914195776
Loss at iteration 430 : 0.014666053466498852
Loss at iteration 440 : 0.012178118340671062
Loss at iteration 450 : 0.007106265053153038
Loss at iteration 460 : 0.008391466923058033
Loss at iteration 470 : 0.010961786843836308
Loss at iteration 480 : 0.00895974226295948
Loss at iteration 490 : 0.013254468329250813
Loss at iteration 500 : 0.014577245339751244
Loss at iteration 510 : 0.008860258385539055
Loss at iteration 520 : 0.008580579422414303
Loss at iteration 530 : 0.007706854492425919
Loss at iteration 540 : 0.013597259297966957
Loss at iteration 550 : 0.017436763271689415
Loss at iteration 560 : 0.0057654352858662605
Loss at iteration 570 : 0.011925701051950455
Loss at iteration 580 : 0.010960258543491364
Loss at iteration 590 : 0.006942264270037413
Loss at iteration 600 : 0.010926332324743271
Loss at iteration 610 : 0.009668173268437386
Loss at iteration 620 : 0.008284852840006351
Loss at iteration 630 : 0.011576728895306587
Loss at iteration 640 : 0.013795869424939156
Loss at iteration 650 : 0.010476753115653992
Loss at iteration 660 : 0.012148251757025719
Loss at iteration 670 : 0.012162180617451668
Loss at iteration 680 : 0.008242161013185978
Loss at iteration 690 : 0.011926583014428616
Loss at iteration 700 : 0.012868475168943405
Loss at iteration 710 : 0.012282023206353188
Loss at iteration 720 : 0.008065609261393547
Loss at iteration 730 : 0.011124775744974613
Loss at iteration 740 : 0.0140033308416605
Loss at iteration 750 : 0.017310423776507378
Loss at iteration 760 : 0.01860811561346054
Loss at iteration 770 : 0.012570451945066452
Loss at iteration 780 : 0.004584591835737228
Loss at iteration 790 : 0.01877371221780777
Loss at iteration 800 : 0.008511966094374657
Loss at iteration 810 : 0.006117374636232853
Loss at iteration 820 : 0.008301501162350178
Loss at iteration 830 : 0.009757383726537228
Loss at iteration 840 : 0.00877399928867817
Loss at iteration 850 : 0.00967445783317089
Loss at iteration 860 : 0.006841442547738552
Loss at iteration 870 : 0.008828004822134972
Loss at iteration 880 : 0.0164932943880558
Loss at iteration 890 : 0.006700311787426472
Loss at iteration 900 : 0.009029787965118885
Loss at iteration 910 : 0.008611876517534256
Loss at iteration 920 : 0.00937006063759327
Loss at iteration 930 : 0.01185845211148262
Loss at iteration 940 : 0.00816021766513586
Loss at iteration 950 : 0.011482530273497105
Loss at iteration 960 : 0.011962328106164932
Loss at iteration 970 : 0.009783809073269367
Loss at iteration 980 : 0.009391743689775467
Loss at iteration 990 : 0.009537527337670326
Loss at iteration 1000 : 0.010137875564396381
Loss at iteration 1010 : 0.01301947794854641
Loss at iteration 1020 : 0.006156120449304581
Loss at iteration 1030 : 0.01039564423263073
Loss at iteration 1040 : 0.010862184688448906
Loss at iteration 1050 : 0.007545669563114643
Loss at iteration 1060 : 0.007344535551965237
Loss at iteration 1070 : 0.011446268297731876
Loss at iteration 1080 : 0.008173341862857342
Loss at iteration 1090 : 0.011880608275532722
Loss at iteration 1100 : 0.01115725003182888
Loss at iteration 1110 : 0.010536504909396172
Loss at iteration 1120 : 0.008243586868047714
Loss at iteration 1130 : 0.011501084081828594
Loss at iteration 1140 : 0.01437403354793787
Loss at iteration 1150 : 0.015361526049673557
Loss at iteration 1160 : 0.008748512715101242
Loss at iteration 1170 : 0.008509526029229164
Loss at iteration 1180 : 0.012674680911004543
Loss at iteration 1190 : 0.013738056644797325
Loss at iteration 1200 : 0.012946823611855507
Loss at iteration 1210 : 0.007555866613984108
The SSIM Value is: 0.8064162174860636
The PSNR Value is: 18.240788459777832
the epoch is: 150
Loss at iteration 10 : 0.010931776836514473
Loss at iteration 20 : 0.012993613258004189
Loss at iteration 30 : 0.008097808808088303
Loss at iteration 40 : 0.013342808932065964
Loss at iteration 50 : 0.014558658935129642
Loss at iteration 60 : 0.01011377852410078
Loss at iteration 70 : 0.017496295273303986
Loss at iteration 80 : 0.012090119533240795
Loss at iteration 90 : 0.010905568487942219
Loss at iteration 100 : 0.008671676740050316
Loss at iteration 110 : 0.008936896920204163
Loss at iteration 120 : 0.011730420403182507
Loss at iteration 130 : 0.00948189664632082
Loss at iteration 140 : 0.014379994943737984
Loss at iteration 150 : 0.013122291304171085
Loss at iteration 160 : 0.012155355885624886
Loss at iteration 170 : 0.010977150872349739
Loss at iteration 180 : 0.01259184442460537
Loss at iteration 190 : 0.006138036493211985
Loss at iteration 200 : 0.008284717798233032
Loss at iteration 210 : 0.008232113905251026
Loss at iteration 220 : 0.005410110577940941
Loss at iteration 230 : 0.005828748922795057
Loss at iteration 240 : 0.008715384639799595
Loss at iteration 250 : 0.014475950971245766
Loss at iteration 260 : 0.011695441789925098
Loss at iteration 270 : 0.008089208975434303
Loss at iteration 280 : 0.008550399914383888
Loss at iteration 290 : 0.012691895477473736
Loss at iteration 300 : 0.009651925414800644
Loss at iteration 310 : 0.006653294432908297
Loss at iteration 320 : 0.013051223009824753
Loss at iteration 330 : 0.009023044258356094
Loss at iteration 340 : 0.009554584510624409
Loss at iteration 350 : 0.009273799136281013
Loss at iteration 360 : 0.009232882410287857
Loss at iteration 370 : 0.005271920934319496
Loss at iteration 380 : 0.009877000004053116
Loss at iteration 390 : 0.010561766102910042
Loss at iteration 400 : 0.007429850287735462
Loss at iteration 410 : 0.012982139363884926
Loss at iteration 420 : 0.01138655748218298
Loss at iteration 430 : 0.01196106057614088
Loss at iteration 440 : 0.011344635859131813
Loss at iteration 450 : 0.009875064715743065
Loss at iteration 460 : 0.011212772689759731
Loss at iteration 470 : 0.0172574445605278
Loss at iteration 480 : 0.008332114666700363
Loss at iteration 490 : 0.01148313656449318
Loss at iteration 500 : 0.011550335213541985
Loss at iteration 510 : 0.009893642738461494
Loss at iteration 520 : 0.013325436040759087
Loss at iteration 530 : 0.008748730644583702
Loss at iteration 540 : 0.005307486280798912
Loss at iteration 550 : 0.014735817909240723
Loss at iteration 560 : 0.007371978834271431
Loss at iteration 570 : 0.013781632296741009
Loss at iteration 580 : 0.014649586752057076
Loss at iteration 590 : 0.025956934317946434
Loss at iteration 600 : 0.007482416462153196
Loss at iteration 610 : 0.009806424379348755
Loss at iteration 620 : 0.009056548587977886
Loss at iteration 630 : 0.011352280154824257
Loss at iteration 640 : 0.007997856475412846
Loss at iteration 650 : 0.008285513147711754
Loss at iteration 660 : 0.0049585397355258465
Loss at iteration 670 : 0.006671877112239599
Loss at iteration 680 : 0.006585869938135147
Loss at iteration 690 : 0.009019125252962112
Loss at iteration 700 : 0.013330845162272453
Loss at iteration 710 : 0.010591121390461922
Loss at iteration 720 : 0.01325121521949768
Loss at iteration 730 : 0.01008644700050354
Loss at iteration 740 : 0.010487861931324005
Loss at iteration 750 : 0.012519881129264832
Loss at iteration 760 : 0.005785595625638962
Loss at iteration 770 : 0.006844458170235157
Loss at iteration 780 : 0.008937375620007515
Loss at iteration 790 : 0.01141821127384901
Loss at iteration 800 : 0.008072984404861927
Loss at iteration 810 : 0.006873318925499916
Loss at iteration 820 : 0.009168113581836224
Loss at iteration 830 : 0.007875341922044754
Loss at iteration 840 : 0.007708336226642132
Loss at iteration 850 : 0.010913863778114319
Loss at iteration 860 : 0.00750622246414423
Loss at iteration 870 : 0.00794422160834074
Loss at iteration 880 : 0.00957697257399559
Loss at iteration 890 : 0.004824792966246605
Loss at iteration 900 : 0.006015325430780649
Loss at iteration 910 : 0.012345677241683006
Loss at iteration 920 : 0.01305557694286108
Loss at iteration 930 : 0.004893176723271608
Loss at iteration 940 : 0.009392174892127514
Loss at iteration 950 : 0.010341979563236237
Loss at iteration 960 : 0.018040036782622337
Loss at iteration 970 : 0.011500604450702667
Loss at iteration 980 : 0.0067489007487893105
Loss at iteration 990 : 0.007382553070783615
Loss at iteration 1000 : 0.011094924062490463
Loss at iteration 1010 : 0.007753744255751371
Loss at iteration 1020 : 0.007541433908045292
Loss at iteration 1030 : 0.006422681268304586
Loss at iteration 1040 : 0.011670351959764957
Loss at iteration 1050 : 0.008214028552174568
Loss at iteration 1060 : 0.015268550254404545
Loss at iteration 1070 : 0.010042943060398102
Loss at iteration 1080 : 0.009154772385954857
Loss at iteration 1090 : 0.013210359029471874
Loss at iteration 1100 : 0.008108860813081264
Loss at iteration 1110 : 0.008188332431018353
Loss at iteration 1120 : 0.014108140952885151
Loss at iteration 1130 : 0.013130836188793182
Loss at iteration 1140 : 0.01143293734639883
Loss at iteration 1150 : 0.007147526368498802
Loss at iteration 1160 : 0.007032638415694237
Loss at iteration 1170 : 0.010962799191474915
Loss at iteration 1180 : 0.010133982636034489
Loss at iteration 1190 : 0.011469670571386814
Loss at iteration 1200 : 0.009208262898027897
Loss at iteration 1210 : 0.01410884503275156
The SSIM Value is: 0.8152344862620036
The PSNR Value is: 19.04674040476481
the epoch is: 151
Loss at iteration 10 : 0.007502942346036434
Loss at iteration 20 : 0.010127652436494827
Loss at iteration 30 : 0.010862622410058975
Loss at iteration 40 : 0.008710249327123165
Loss at iteration 50 : 0.006488456856459379
Loss at iteration 60 : 0.01491665281355381
Loss at iteration 70 : 0.010429845191538334
Loss at iteration 80 : 0.01192473154515028
Loss at iteration 90 : 0.018047742545604706
Loss at iteration 100 : 0.006940755527466536
Loss at iteration 110 : 0.010230232030153275
Loss at iteration 120 : 0.01203138381242752
Loss at iteration 130 : 0.012471931055188179
Loss at iteration 140 : 0.009635108523070812
Loss at iteration 150 : 0.010464729741215706
Loss at iteration 160 : 0.0098866056650877
Loss at iteration 170 : 0.011928854510188103
Loss at iteration 180 : 0.009098829701542854
Loss at iteration 190 : 0.009276743978261948
Loss at iteration 200 : 0.012926085852086544
Loss at iteration 210 : 0.01752519980072975
Loss at iteration 220 : 0.010763865895569324
Loss at iteration 230 : 0.008266336284577847
Loss at iteration 240 : 0.011994649656116962
Loss at iteration 250 : 0.01052958145737648
Loss at iteration 260 : 0.011087518185377121
Loss at iteration 270 : 0.010826782323420048
Loss at iteration 280 : 0.008271937258541584
Loss at iteration 290 : 0.009865671396255493
Loss at iteration 300 : 0.014984898269176483
Loss at iteration 310 : 0.007440982386469841
Loss at iteration 320 : 0.011254526674747467
Loss at iteration 330 : 0.015384706668555737
Loss at iteration 340 : 0.00584812555462122
Loss at iteration 350 : 0.0071414560079574585
Loss at iteration 360 : 0.010784623213112354
Loss at iteration 370 : 0.010277139954268932
Loss at iteration 380 : 0.015008971095085144
Loss at iteration 390 : 0.005594656337052584
Loss at iteration 400 : 0.010406218469142914
Loss at iteration 410 : 0.012553906068205833
Loss at iteration 420 : 0.008478430099785328
Loss at iteration 430 : 0.011228340677917004
Loss at iteration 440 : 0.010217205621302128
Loss at iteration 450 : 0.005476221442222595
Loss at iteration 460 : 0.013473334722220898
Loss at iteration 470 : 0.011196296662092209
Loss at iteration 480 : 0.007774092722684145
Loss at iteration 490 : 0.00916470680385828
Loss at iteration 500 : 0.010609779506921768
Loss at iteration 510 : 0.012789701111614704
Loss at iteration 520 : 0.012388949282467365
Loss at iteration 530 : 0.009436891414225101
Loss at iteration 540 : 0.008680752478539944
Loss at iteration 550 : 0.00967237539589405
Loss at iteration 560 : 0.006903411820530891
Loss at iteration 570 : 0.018465042114257812
Loss at iteration 580 : 0.009890588000416756
Loss at iteration 590 : 0.008824147284030914
Loss at iteration 600 : 0.009320612996816635
Loss at iteration 610 : 0.01187777891755104
Loss at iteration 620 : 0.012247275561094284
Loss at iteration 630 : 0.0073294625617563725
Loss at iteration 640 : 0.009102895855903625
Loss at iteration 650 : 0.013057042844593525
Loss at iteration 660 : 0.00850752741098404
Loss at iteration 670 : 0.006074693985283375
Loss at iteration 680 : 0.007973231375217438
Loss at iteration 690 : 0.010077748447656631
Loss at iteration 700 : 0.010273837484419346
Loss at iteration 710 : 0.00655828882008791
Loss at iteration 720 : 0.009484448470175266
Loss at iteration 730 : 0.01126854121685028
Loss at iteration 740 : 0.013907507993280888
Loss at iteration 750 : 0.005127103999257088
Loss at iteration 760 : 0.01121834758669138
Loss at iteration 770 : 0.01210480835288763
Loss at iteration 780 : 0.011724419891834259
Loss at iteration 790 : 0.00848359614610672
Loss at iteration 800 : 0.010611634701490402
Loss at iteration 810 : 0.024780115112662315
Loss at iteration 820 : 0.008218557573854923
Loss at iteration 830 : 0.008291381411254406
Loss at iteration 840 : 0.016076233237981796
Loss at iteration 850 : 0.015212765894830227
Loss at iteration 860 : 0.009140608832240105
Loss at iteration 870 : 0.013623594306409359
Loss at iteration 880 : 0.012454142794013023
Loss at iteration 890 : 0.012641233392059803
Loss at iteration 900 : 0.014108149334788322
Loss at iteration 910 : 0.010465502738952637
Loss at iteration 920 : 0.014806434512138367
Loss at iteration 930 : 0.006672618445008993
Loss at iteration 940 : 0.008944272994995117
Loss at iteration 950 : 0.011577109806239605
Loss at iteration 960 : 0.012086504139006138
Loss at iteration 970 : 0.007962909527122974
Loss at iteration 980 : 0.012983372434973717
Loss at iteration 990 : 0.00728810578584671
Loss at iteration 1000 : 0.0077903796918690205
Loss at iteration 1010 : 0.017225749790668488
Loss at iteration 1020 : 0.011934495531022549
Loss at iteration 1030 : 0.008501631207764149
Loss at iteration 1040 : 0.006778232753276825
Loss at iteration 1050 : 0.00989777036011219
Loss at iteration 1060 : 0.009625403210520744
Loss at iteration 1070 : 0.006395475007593632
Loss at iteration 1080 : 0.012662984430789948
Loss at iteration 1090 : 0.018919212743639946
Loss at iteration 1100 : 0.014030719175934792
Loss at iteration 1110 : 0.012135938741266727
Loss at iteration 1120 : 0.014212209731340408
Loss at iteration 1130 : 0.004107708111405373
Loss at iteration 1140 : 0.007427009753882885
Loss at iteration 1150 : 0.009338658303022385
Loss at iteration 1160 : 0.008983112871646881
Loss at iteration 1170 : 0.012712685391306877
Loss at iteration 1180 : 0.008907207287847996
Loss at iteration 1190 : 0.012419311329722404
Loss at iteration 1200 : 0.012991024181246758
Loss at iteration 1210 : 0.01134887058287859
The SSIM Value is: 0.8024949828783671
The PSNR Value is: 18.36818510691325
the epoch is: 152
Loss at iteration 10 : 0.009373795241117477
Loss at iteration 20 : 0.0062294588424265385
Loss at iteration 30 : 0.008131223730742931
Loss at iteration 40 : 0.006472740788012743
Loss at iteration 50 : 0.01149880513548851
Loss at iteration 60 : 0.012114054523408413
Loss at iteration 70 : 0.00787415076047182
Loss at iteration 80 : 0.012274743057787418
Loss at iteration 90 : 0.012446391396224499
Loss at iteration 100 : 0.00970612931996584
Loss at iteration 110 : 0.015118943527340889
Loss at iteration 120 : 0.01206352561712265
Loss at iteration 130 : 0.010860518552362919
Loss at iteration 140 : 0.013922196812927723
Loss at iteration 150 : 0.010689526796340942
Loss at iteration 160 : 0.008241690695285797
Loss at iteration 170 : 0.006903885398060083
Loss at iteration 180 : 0.008269005455076694
Loss at iteration 190 : 0.006656027864664793
Loss at iteration 200 : 0.010149992071092129
Loss at iteration 210 : 0.007167590782046318
Loss at iteration 220 : 0.009987259283661842
Loss at iteration 230 : 0.008371910080313683
Loss at iteration 240 : 0.009812365286052227
Loss at iteration 250 : 0.023040734231472015
Loss at iteration 260 : 0.007311618886888027
Loss at iteration 270 : 0.029887229204177856
Loss at iteration 280 : 0.012816470116376877
Loss at iteration 290 : 0.014158464968204498
Loss at iteration 300 : 0.0091048963367939
Loss at iteration 310 : 0.012051391415297985
Loss at iteration 320 : 0.00809483602643013
Loss at iteration 330 : 0.010335277765989304
Loss at iteration 340 : 0.011053553782403469
Loss at iteration 350 : 0.008249124512076378
Loss at iteration 360 : 0.011181078851222992
Loss at iteration 370 : 0.008843369781970978
Loss at iteration 380 : 0.006009845528751612
Loss at iteration 390 : 0.007651337888091803
Loss at iteration 400 : 0.008958010002970695
Loss at iteration 410 : 0.009126754477620125
Loss at iteration 420 : 0.009499848820269108
Loss at iteration 430 : 0.010314593091607094
Loss at iteration 440 : 0.009474007412791252
Loss at iteration 450 : 0.02729315683245659
Loss at iteration 460 : 0.008304883725941181
Loss at iteration 470 : 0.01260700635612011
Loss at iteration 480 : 0.009179836139082909
Loss at iteration 490 : 0.013667839579284191
Loss at iteration 500 : 0.01638590544462204
Loss at iteration 510 : 0.010544832795858383
Loss at iteration 520 : 0.011871288530528545
Loss at iteration 530 : 0.008907115086913109
Loss at iteration 540 : 0.011758912354707718
Loss at iteration 550 : 0.01805867999792099
Loss at iteration 560 : 0.013580705970525742
Loss at iteration 570 : 0.005376615561544895
Loss at iteration 580 : 0.008210936561226845
Loss at iteration 590 : 0.009457167237997055
Loss at iteration 600 : 0.011881479993462563
Loss at iteration 610 : 0.017192412167787552
Loss at iteration 620 : 0.01079700980335474
Loss at iteration 630 : 0.005145461298525333
Loss at iteration 640 : 0.004321947693824768
Loss at iteration 650 : 0.010824411176145077
Loss at iteration 660 : 0.011541858315467834
Loss at iteration 670 : 0.010312329046428204
Loss at iteration 680 : 0.010679705068469048
Loss at iteration 690 : 0.0159306563436985
Loss at iteration 700 : 0.008754017762839794
Loss at iteration 710 : 0.009918415918946266
Loss at iteration 720 : 0.009903728030622005
Loss at iteration 730 : 0.012371506541967392
Loss at iteration 740 : 0.017693180590867996
Loss at iteration 750 : 0.005191881209611893
Loss at iteration 760 : 0.007760289125144482
Loss at iteration 770 : 0.01137035246938467
Loss at iteration 780 : 0.008064955472946167
Loss at iteration 790 : 0.004470865707844496
Loss at iteration 800 : 0.00918143056333065
Loss at iteration 810 : 0.008495867252349854
Loss at iteration 820 : 0.004713120404630899
Loss at iteration 830 : 0.0065901558846235275
Loss at iteration 840 : 0.007362848613411188
Loss at iteration 850 : 0.014530959539115429
Loss at iteration 860 : 0.014268456026911736
Loss at iteration 870 : 0.018546033650636673
Loss at iteration 880 : 0.013086308725178242
Loss at iteration 890 : 0.009823080152273178
Loss at iteration 900 : 0.009314503520727158
Loss at iteration 910 : 0.01182413287460804
Loss at iteration 920 : 0.011575151234865189
Loss at iteration 930 : 0.008578022941946983
Loss at iteration 940 : 0.012994271703064442
Loss at iteration 950 : 0.010423215106129646
Loss at iteration 960 : 0.011413287371397018
Loss at iteration 970 : 0.009844784624874592
Loss at iteration 980 : 0.013745080679655075
Loss at iteration 990 : 0.008154512383043766
Loss at iteration 1000 : 0.0071127526462078094
Loss at iteration 1010 : 0.009760012850165367
Loss at iteration 1020 : 0.0095088304951787
Loss at iteration 1030 : 0.012670348398387432
Loss at iteration 1040 : 0.0075254132971167564
Loss at iteration 1050 : 0.015197576954960823
Loss at iteration 1060 : 0.010602354072034359
Loss at iteration 1070 : 0.007659259717911482
Loss at iteration 1080 : 0.012667357921600342
Loss at iteration 1090 : 0.011208443902432919
Loss at iteration 1100 : 0.0121645862236619
Loss at iteration 1110 : 0.012733693234622478
Loss at iteration 1120 : 0.014003943651914597
Loss at iteration 1130 : 0.012157214805483818
Loss at iteration 1140 : 0.010303640738129616
Loss at iteration 1150 : 0.014851734042167664
Loss at iteration 1160 : 0.008985185995697975
Loss at iteration 1170 : 0.006877378094941378
Loss at iteration 1180 : 0.008228791877627373
Loss at iteration 1190 : 0.0068654948845505714
Loss at iteration 1200 : 0.007054104469716549
Loss at iteration 1210 : 0.023394063115119934
The SSIM Value is: 0.8044533014297486
The PSNR Value is: 18.19097112019857
the epoch is: 153
Loss at iteration 10 : 0.009582452476024628
Loss at iteration 20 : 0.014112255536019802
Loss at iteration 30 : 0.011317383497953415
Loss at iteration 40 : 0.008611629717051983
Loss at iteration 50 : 0.009301644749939442
Loss at iteration 60 : 0.009724901989102364
Loss at iteration 70 : 0.010919923894107342
Loss at iteration 80 : 0.006328693591058254
Loss at iteration 90 : 0.007551094517111778
Loss at iteration 100 : 0.008488883264362812
Loss at iteration 110 : 0.009259762242436409
Loss at iteration 120 : 0.007424795068800449
Loss at iteration 130 : 0.009421797469258308
Loss at iteration 140 : 0.008618839085102081
Loss at iteration 150 : 0.014530884101986885
Loss at iteration 160 : 0.013602979481220245
Loss at iteration 170 : 0.011182527057826519
Loss at iteration 180 : 0.013159354217350483
Loss at iteration 190 : 0.010383626446127892
Loss at iteration 200 : 0.01175079308450222
Loss at iteration 210 : 0.011136634275317192
Loss at iteration 220 : 0.010976694524288177
Loss at iteration 230 : 0.011201196350157261
Loss at iteration 240 : 0.006018501240760088
Loss at iteration 250 : 0.01339645218104124
Loss at iteration 260 : 0.007021683733910322
Loss at iteration 270 : 0.011080348864197731
Loss at iteration 280 : 0.01777210272848606
Loss at iteration 290 : 0.014534377492964268
Loss at iteration 300 : 0.011260561645030975
Loss at iteration 310 : 0.011354141868650913
Loss at iteration 320 : 0.011684509925544262
Loss at iteration 330 : 0.013728460296988487
Loss at iteration 340 : 0.008340505883097649
Loss at iteration 350 : 0.015925120562314987
Loss at iteration 360 : 0.009786984883248806
Loss at iteration 370 : 0.008285420015454292
Loss at iteration 380 : 0.011796724982559681
Loss at iteration 390 : 0.006508531980216503
Loss at iteration 400 : 0.014831051230430603
Loss at iteration 410 : 0.013752330094575882
Loss at iteration 420 : 0.008146537467837334
Loss at iteration 430 : 0.010760198347270489
Loss at iteration 440 : 0.007505347020924091
Loss at iteration 450 : 0.011501618660986423
Loss at iteration 460 : 0.00819484144449234
Loss at iteration 470 : 0.011627083644270897
Loss at iteration 480 : 0.00844411551952362
Loss at iteration 490 : 0.007839052937924862
Loss at iteration 500 : 0.007512564305216074
Loss at iteration 510 : 0.01125420443713665
Loss at iteration 520 : 0.015335320495069027
Loss at iteration 530 : 0.023768261075019836
Loss at iteration 540 : 0.0072017996571958065
Loss at iteration 550 : 0.009005486033856869
Loss at iteration 560 : 0.011082633398473263
Loss at iteration 570 : 0.016277210786938667
Loss at iteration 580 : 0.009042411111295223
Loss at iteration 590 : 0.009383526630699635
Loss at iteration 600 : 0.011160857044160366
Loss at iteration 610 : 0.0065366486087441444
Loss at iteration 620 : 0.012248688377439976
Loss at iteration 630 : 0.008922666311264038
Loss at iteration 640 : 0.008644749410450459
Loss at iteration 650 : 0.008969947695732117
Loss at iteration 660 : 0.00958356261253357
Loss at iteration 670 : 0.01501220278441906
Loss at iteration 680 : 0.008903896436095238
Loss at iteration 690 : 0.018411319702863693
Loss at iteration 700 : 0.013114765286445618
Loss at iteration 710 : 0.013453179970383644
Loss at iteration 720 : 0.009206212125718594
Loss at iteration 730 : 0.026859112083911896
Loss at iteration 740 : 0.011859252117574215
Loss at iteration 750 : 0.011734936386346817
Loss at iteration 760 : 0.014027847908437252
Loss at iteration 770 : 0.010365257039666176
Loss at iteration 780 : 0.006426902022212744
Loss at iteration 790 : 0.009703951887786388
Loss at iteration 800 : 0.004951239097863436
Loss at iteration 810 : 0.0050575039349496365
Loss at iteration 820 : 0.010986130684614182
Loss at iteration 830 : 0.008767036721110344
Loss at iteration 840 : 0.010027002543210983
Loss at iteration 850 : 0.020467575639486313
Loss at iteration 860 : 0.009685046970844269
Loss at iteration 870 : 0.013644576072692871
Loss at iteration 880 : 0.009892898611724377
Loss at iteration 890 : 0.013446290977299213
Loss at iteration 900 : 0.009660737589001656
Loss at iteration 910 : 0.013158667832612991
Loss at iteration 920 : 0.011084572412073612
Loss at iteration 930 : 0.014752457849681377
Loss at iteration 940 : 0.020849663764238358
Loss at iteration 950 : 0.01109237875789404
Loss at iteration 960 : 0.011767544783651829
Loss at iteration 970 : 0.00985521636903286
Loss at iteration 980 : 0.016043661162257195
Loss at iteration 990 : 0.007700405549257994
Loss at iteration 1000 : 0.005605744197964668
Loss at iteration 1010 : 0.013072199188172817
Loss at iteration 1020 : 0.009098649024963379
Loss at iteration 1030 : 0.012396523728966713
Loss at iteration 1040 : 0.01250234991312027
Loss at iteration 1050 : 0.010561096481978893
Loss at iteration 1060 : 0.011858511716127396
Loss at iteration 1070 : 0.009256201796233654
Loss at iteration 1080 : 0.012070064432919025
Loss at iteration 1090 : 0.006017936393618584
Loss at iteration 1100 : 0.01162371039390564
Loss at iteration 1110 : 0.011877208016812801
Loss at iteration 1120 : 0.011181366629898548
Loss at iteration 1130 : 0.009145080111920834
Loss at iteration 1140 : 0.010409153997898102
Loss at iteration 1150 : 0.012549063190817833
Loss at iteration 1160 : 0.00847124308347702
Loss at iteration 1170 : 0.011923315934836864
Loss at iteration 1180 : 0.011483220383524895
Loss at iteration 1190 : 0.00754331611096859
Loss at iteration 1200 : 0.009166611358523369
Loss at iteration 1210 : 0.014514659531414509
The SSIM Value is: 0.8023564457893372
The PSNR Value is: 18.380772717793782
the epoch is: 154
