Namespace(gpu_id=0, img_path='/home/wsz/workspace/Data/LOLdataset/our485_patch/low/', img_val_path='/home/wsz/workspace/Data/LOLdataset/eval15/low/', batch_size=2, lr=0.0002, weight_decay=0, pretrain_dir=None, num_epochs=200, display_iter=10, snapshots_folder='workdirs/snapshots_folder_lol_v1_patch_mir2_20230221')
Total examples: 4850
Total examples: 15
the device is: cuda:0
######## Start IAT Training #########
the epoch is: 0
Loss at iteration 10 : 0.15312330424785614
Loss at iteration 20 : 0.08271093666553497
Loss at iteration 30 : 0.03544145077466965
Loss at iteration 40 : 0.04266568273305893
Loss at iteration 50 : 0.056639663875103
Loss at iteration 60 : 0.06700382381677628
Loss at iteration 70 : 0.048916079103946686
Loss at iteration 80 : 0.0480644516646862
Loss at iteration 90 : 0.1002144068479538
Loss at iteration 100 : 0.06770011782646179
Loss at iteration 110 : 0.04094477370381355
Loss at iteration 120 : 0.03526683896780014
Loss at iteration 130 : 0.04602861776947975
Loss at iteration 140 : 0.01714191772043705
Loss at iteration 150 : 0.08431162685155869
Loss at iteration 160 : 0.035212405025959015
Loss at iteration 170 : 0.024832718074321747
Loss at iteration 180 : 0.0742068886756897
Loss at iteration 190 : 0.0732119083404541
Loss at iteration 200 : 0.04418545216321945
Loss at iteration 210 : 0.1183786541223526
Loss at iteration 220 : 0.09130030870437622
Loss at iteration 230 : 0.049812883138656616
Loss at iteration 240 : 0.12944075465202332
Loss at iteration 250 : 0.05911700800061226
Loss at iteration 260 : 0.07168222963809967
Loss at iteration 270 : 0.0968712866306305
Loss at iteration 280 : 0.07679425179958344
Loss at iteration 290 : 0.06252314895391464
Loss at iteration 300 : 0.07515515387058258
Loss at iteration 310 : 0.03359953686594963
Loss at iteration 320 : 0.03924055024981499
Loss at iteration 330 : 0.06633822619915009
Loss at iteration 340 : 0.04031575471162796
Loss at iteration 350 : 0.025942698121070862
Loss at iteration 360 : 0.13184316456317902
Loss at iteration 370 : 0.05916783958673477
Loss at iteration 380 : 0.06642398983240128
Loss at iteration 390 : 0.03405763953924179
Loss at iteration 400 : 0.06466218084096909
Loss at iteration 410 : 0.05923430994153023
Loss at iteration 420 : 0.02482714131474495
Loss at iteration 430 : 0.0715450569987297
Loss at iteration 440 : 0.041113607585430145
Loss at iteration 450 : 0.03799311816692352
Loss at iteration 460 : 0.04490625113248825
Loss at iteration 470 : 0.0476418100297451
Loss at iteration 480 : 0.04240911453962326
Loss at iteration 490 : 0.04209863767027855
Loss at iteration 500 : 0.05295279622077942
Loss at iteration 510 : 0.026560671627521515
Loss at iteration 520 : 0.02819220721721649
Loss at iteration 530 : 0.016764875501394272
Loss at iteration 540 : 0.037925880402326584
Loss at iteration 550 : 0.049354419112205505
Loss at iteration 560 : 0.02367340959608555
Loss at iteration 570 : 0.05737568065524101
Loss at iteration 580 : 0.04911583289504051
Loss at iteration 590 : 0.015056226402521133
Loss at iteration 600 : 0.05258854478597641
Loss at iteration 610 : 0.03754178062081337
Loss at iteration 620 : 0.027361156418919563
Loss at iteration 630 : 0.017451412975788116
Loss at iteration 640 : 0.020413488149642944
Loss at iteration 650 : 0.019741598516702652
Loss at iteration 660 : 0.020974628627300262
Loss at iteration 670 : 0.033990971744060516
Loss at iteration 680 : 0.018173158168792725
Loss at iteration 690 : 0.033423006534576416
Loss at iteration 700 : 0.028348732739686966
Loss at iteration 710 : 0.017975106835365295
Loss at iteration 720 : 0.0396365150809288
Loss at iteration 730 : 0.029621271416544914
Loss at iteration 740 : 0.06705103814601898
Loss at iteration 750 : 0.04606961831450462
Loss at iteration 760 : 0.029173873364925385
Loss at iteration 770 : 0.027679193764925003
Loss at iteration 780 : 0.018875528126955032
Loss at iteration 790 : 0.02366456761956215
Loss at iteration 800 : 0.033497847616672516
Loss at iteration 810 : 0.0592188686132431
Loss at iteration 820 : 0.03704262152314186
Loss at iteration 830 : 0.03751087933778763
Loss at iteration 840 : 0.07139391452074051
Loss at iteration 850 : 0.017107043415308
Loss at iteration 860 : 0.026379849761724472
Loss at iteration 870 : 0.022099416702985764
Loss at iteration 880 : 0.033962950110435486
Loss at iteration 890 : 0.01587500050663948
Loss at iteration 900 : 0.022444456815719604
Loss at iteration 910 : 0.015160460025072098
Loss at iteration 920 : 0.03667118400335312
Loss at iteration 930 : 0.019366499036550522
Loss at iteration 940 : 0.031212909147143364
Loss at iteration 950 : 0.023705165833234787
Loss at iteration 960 : 0.01870056614279747
Loss at iteration 970 : 0.016543209552764893
Loss at iteration 980 : 0.01841442659497261
Loss at iteration 990 : 0.03544701635837555
Loss at iteration 1000 : 0.01956128142774105
Loss at iteration 1010 : 0.044769831001758575
Loss at iteration 1020 : 0.030237793922424316
Loss at iteration 1030 : 0.01129366084933281
Loss at iteration 1040 : 0.013373500667512417
Loss at iteration 1050 : 0.023927345871925354
Loss at iteration 1060 : 0.010519005358219147
Loss at iteration 1070 : 0.03467162325978279
Loss at iteration 1080 : 0.0302341990172863
Loss at iteration 1090 : 0.012790551409125328
Loss at iteration 1100 : 0.035972561687231064
Loss at iteration 1110 : 0.016834605485200882
Loss at iteration 1120 : 0.03464091569185257
Loss at iteration 1130 : 0.025992069393396378
Loss at iteration 1140 : 0.023236915469169617
Loss at iteration 1150 : 0.028692957013845444
Loss at iteration 1160 : 0.022724002599716187
Loss at iteration 1170 : 0.022191008552908897
Loss at iteration 1180 : 0.0173361636698246
Loss at iteration 1190 : 0.033717986196279526
Loss at iteration 1200 : 0.030090179294347763
Loss at iteration 1210 : 0.026821836829185486
Loss at iteration 1220 : 0.022914085537195206
Loss at iteration 1230 : 0.012336170300841331
Loss at iteration 1240 : 0.03021189011633396
Loss at iteration 1250 : 0.01599462889134884
Loss at iteration 1260 : 0.03933770954608917
Loss at iteration 1270 : 0.020294245332479477
Loss at iteration 1280 : 0.021297520026564598
Loss at iteration 1290 : 0.022801358252763748
Loss at iteration 1300 : 0.03334712237119675
Loss at iteration 1310 : 0.028875790536403656
Loss at iteration 1320 : 0.035449184477329254
Loss at iteration 1330 : 0.021245379000902176
Loss at iteration 1340 : 0.01349672768265009
Loss at iteration 1350 : 0.025552676990628242
Loss at iteration 1360 : 0.03255484998226166
Loss at iteration 1370 : 0.042735856026411057
Loss at iteration 1380 : 0.02925872430205345
Loss at iteration 1390 : 0.043398164212703705
Loss at iteration 1400 : 0.023623386397957802
Loss at iteration 1410 : 0.0290711410343647
Loss at iteration 1420 : 0.021859748288989067
Loss at iteration 1430 : 0.0212691817432642
Loss at iteration 1440 : 0.017923584207892418
Loss at iteration 1450 : 0.023028569296002388
Loss at iteration 1460 : 0.04621196538209915
Loss at iteration 1470 : 0.02150033414363861
Loss at iteration 1480 : 0.01667136326432228
Loss at iteration 1490 : 0.031593941152095795
Loss at iteration 1500 : 0.02507663518190384
Loss at iteration 1510 : 0.015065968036651611
Loss at iteration 1520 : 0.02671632543206215
Loss at iteration 1530 : 0.02343982830643654
Loss at iteration 1540 : 0.01649273931980133
Loss at iteration 1550 : 0.023035701364278793
Loss at iteration 1560 : 0.025630421936511993
Loss at iteration 1570 : 0.016430487856268883
Loss at iteration 1580 : 0.03443196415901184
Loss at iteration 1590 : 0.014405908063054085
Loss at iteration 1600 : 0.018496308475732803
Loss at iteration 1610 : 0.020165303722023964
Loss at iteration 1620 : 0.02154574543237686
Loss at iteration 1630 : 0.02797897905111313
Loss at iteration 1640 : 0.025036556646227837
Loss at iteration 1650 : 0.01445995457470417
Loss at iteration 1660 : 0.034088511019945145
Loss at iteration 1670 : 0.04704994335770607
Loss at iteration 1680 : 0.016186237335205078
Loss at iteration 1690 : 0.02881065011024475
Loss at iteration 1700 : 0.026056600734591484
Loss at iteration 1710 : 0.02088998444378376
Loss at iteration 1720 : 0.021398641169071198
Loss at iteration 1730 : 0.03462836891412735
Loss at iteration 1740 : 0.035358406603336334
Loss at iteration 1750 : 0.026880862191319466
Loss at iteration 1760 : 0.0362795852124691
Loss at iteration 1770 : 0.016453977674245834
Loss at iteration 1780 : 0.012075327336788177
Loss at iteration 1790 : 0.028973445296287537
Loss at iteration 1800 : 0.015345119871199131
Loss at iteration 1810 : 0.015694860368967056
Loss at iteration 1820 : 0.024707159027457237
Loss at iteration 1830 : 0.02098173089325428
Loss at iteration 1840 : 0.01735636778175831
Loss at iteration 1850 : 0.01631363108754158
Loss at iteration 1860 : 0.02153639681637287
Loss at iteration 1870 : 0.015625227242708206
Loss at iteration 1880 : 0.019429456442594528
Loss at iteration 1890 : 0.020271696150302887
Loss at iteration 1900 : 0.015583183616399765
Loss at iteration 1910 : 0.013347549363970757
Loss at iteration 1920 : 0.02249247394502163
Loss at iteration 1930 : 0.02169572375714779
Loss at iteration 1940 : 0.020065264776349068
Loss at iteration 1950 : 0.01691812463104725
Loss at iteration 1960 : 0.022331051528453827
Loss at iteration 1970 : 0.03945533558726311
Loss at iteration 1980 : 0.02575865387916565
Loss at iteration 1990 : 0.019884485751390457
Loss at iteration 2000 : 0.021361786872148514
Loss at iteration 2010 : 0.03540145233273506
Loss at iteration 2020 : 0.03172827139496803
Loss at iteration 2030 : 0.017269117757678032
Loss at iteration 2040 : 0.04696529358625412
Loss at iteration 2050 : 0.013863948173820972
Loss at iteration 2060 : 0.019266679883003235
Loss at iteration 2070 : 0.030710702762007713
Loss at iteration 2080 : 0.03023463487625122
Loss at iteration 2090 : 0.03342043608427048
Loss at iteration 2100 : 0.03366067260503769
Loss at iteration 2110 : 0.017736133188009262
Loss at iteration 2120 : 0.020862974226474762
Loss at iteration 2130 : 0.00990479625761509
Loss at iteration 2140 : 0.019537420943379402
Loss at iteration 2150 : 0.021298011764883995
Loss at iteration 2160 : 0.010573393665254116
Loss at iteration 2170 : 0.015208354219794273
Loss at iteration 2180 : 0.03992126137018204
Loss at iteration 2190 : 0.020565716549754143
Loss at iteration 2200 : 0.014281215146183968
Loss at iteration 2210 : 0.013910495676100254
Loss at iteration 2220 : 0.018398549407720566
Loss at iteration 2230 : 0.016334135085344315
Loss at iteration 2240 : 0.013776300475001335
Loss at iteration 2250 : 0.011993642896413803
Loss at iteration 2260 : 0.009319975972175598
Loss at iteration 2270 : 0.011294370517134666
Loss at iteration 2280 : 0.015511872246861458
Loss at iteration 2290 : 0.018665488809347153
Loss at iteration 2300 : 0.03339333087205887
Loss at iteration 2310 : 0.0427943579852581
Loss at iteration 2320 : 0.023561641573905945
Loss at iteration 2330 : 0.024885771796107292
Loss at iteration 2340 : 0.010916564613580704
Loss at iteration 2350 : 0.011007145047187805
Loss at iteration 2360 : 0.019016895443201065
Loss at iteration 2370 : 0.03646174073219299
Loss at iteration 2380 : 0.02541569247841835
Loss at iteration 2390 : 0.02798961102962494
Loss at iteration 2400 : 0.033531174063682556
Loss at iteration 2410 : 0.011135594919323921
Loss at iteration 2420 : 0.029994605109095573
The SSIM Value is: 0.7738447507222493
The PSNR Value is: 17.985524622599282
the highest SSIM value is: 17.985524622599282
the epoch is: 1
Loss at iteration 10 : 0.012907152064144611
Loss at iteration 20 : 0.03871080279350281
Loss at iteration 30 : 0.013733314350247383
Loss at iteration 40 : 0.018450606614351273
Loss at iteration 50 : 0.04687090218067169
Loss at iteration 60 : 0.014682912267744541
Loss at iteration 70 : 0.015089215710759163
Loss at iteration 80 : 0.018426138907670975
Loss at iteration 90 : 0.023083535954356194
Loss at iteration 100 : 0.01458651851862669
Loss at iteration 110 : 0.00877042580395937
Loss at iteration 120 : 0.026592306792736053
Loss at iteration 130 : 0.02767685428261757
Loss at iteration 140 : 0.015457225032150745
Loss at iteration 150 : 0.021287817507982254
Loss at iteration 160 : 0.019328169524669647
Loss at iteration 170 : 0.020082220435142517
Loss at iteration 180 : 0.0114810261875391
Loss at iteration 190 : 0.02207496389746666
Loss at iteration 200 : 0.021662015467882156
Loss at iteration 210 : 0.0210003349930048
Loss at iteration 220 : 0.030152209103107452
Loss at iteration 230 : 0.02776031382381916
Loss at iteration 240 : 0.020739994943141937
Loss at iteration 250 : 0.029640907421708107
Loss at iteration 260 : 0.018244000151753426
Loss at iteration 270 : 0.016415366902947426
Loss at iteration 280 : 0.01971752941608429
Loss at iteration 290 : 0.01994921639561653
Loss at iteration 300 : 0.022289667278528214
Loss at iteration 310 : 0.011762384325265884
Loss at iteration 320 : 0.00992361456155777
Loss at iteration 330 : 0.02902372181415558
Loss at iteration 340 : 0.014534150250256062
Loss at iteration 350 : 0.01756429672241211
Loss at iteration 360 : 0.022349396720528603
Loss at iteration 370 : 0.0247699785977602
Loss at iteration 380 : 0.024395005777478218
Loss at iteration 390 : 0.017479022964835167
Loss at iteration 400 : 0.017344320192933083
Loss at iteration 410 : 0.015894560143351555
Loss at iteration 420 : 0.03291704133152962
Loss at iteration 430 : 0.017678920179605484
Loss at iteration 440 : 0.020783815532922745
Loss at iteration 450 : 0.00846190843731165
Loss at iteration 460 : 0.03960496932268143
Loss at iteration 470 : 0.03176324814558029
Loss at iteration 480 : 0.01944557949900627
Loss at iteration 490 : 0.018904326483607292
Loss at iteration 500 : 0.03187618777155876
Loss at iteration 510 : 0.02417181059718132
Loss at iteration 520 : 0.017564505338668823
Loss at iteration 530 : 0.011340849101543427
Loss at iteration 540 : 0.01509246788918972
Loss at iteration 550 : 0.027671385556459427
Loss at iteration 560 : 0.019321439787745476
Loss at iteration 570 : 0.02589154988527298
Loss at iteration 580 : 0.02574457973241806
Loss at iteration 590 : 0.03271237015724182
Loss at iteration 600 : 0.019232500344514847
Loss at iteration 610 : 0.018131598830223083
Loss at iteration 620 : 0.015506111085414886
Loss at iteration 630 : 0.008999645709991455
Loss at iteration 640 : 0.019712187349796295
Loss at iteration 650 : 0.014939348213374615
Loss at iteration 660 : 0.01740879938006401
Loss at iteration 670 : 0.021129082888364792
Loss at iteration 680 : 0.0190715454518795
Loss at iteration 690 : 0.01522140298038721
Loss at iteration 700 : 0.01409866102039814
Loss at iteration 710 : 0.023004941642284393
Loss at iteration 720 : 0.015277773141860962
Loss at iteration 730 : 0.03696868568658829
Loss at iteration 740 : 0.03332195430994034
Loss at iteration 750 : 0.020976733416318893
Loss at iteration 760 : 0.02868846245110035
Loss at iteration 770 : 0.016708416864275932
Loss at iteration 780 : 0.015732642263174057
Loss at iteration 790 : 0.017635945230722427
Loss at iteration 800 : 0.019565537571907043
Loss at iteration 810 : 0.014386583119630814
Loss at iteration 820 : 0.015894602984189987
Loss at iteration 830 : 0.01962096616625786
Loss at iteration 840 : 0.027793683111667633
Loss at iteration 850 : 0.01695234701037407
Loss at iteration 860 : 0.022625144571065903
Loss at iteration 870 : 0.009038988500833511
Loss at iteration 880 : 0.024410411715507507
Loss at iteration 890 : 0.025927068665623665
Loss at iteration 900 : 0.016278129070997238
Loss at iteration 910 : 0.013551470823585987
Loss at iteration 920 : 0.03815726190805435
Loss at iteration 930 : 0.023951858282089233
Loss at iteration 940 : 0.01664077118039131
Loss at iteration 950 : 0.013491359539330006
Loss at iteration 960 : 0.01805100403726101
Loss at iteration 970 : 0.008913012221455574
Loss at iteration 980 : 0.02022712677717209
Loss at iteration 990 : 0.02644497901201248
Loss at iteration 1000 : 0.018980950117111206
Loss at iteration 1010 : 0.025662805885076523
Loss at iteration 1020 : 0.016164060682058334
Loss at iteration 1030 : 0.010932582430541515
Loss at iteration 1040 : 0.01917915605008602
Loss at iteration 1050 : 0.012905456125736237
Loss at iteration 1060 : 0.0257513877004385
Loss at iteration 1070 : 0.010500116273760796
Loss at iteration 1080 : 0.016658108681440353
Loss at iteration 1090 : 0.023373756557703018
Loss at iteration 1100 : 0.011889035813510418
Loss at iteration 1110 : 0.03351549059152603
Loss at iteration 1120 : 0.011525522917509079
Loss at iteration 1130 : 0.012891437858343124
Loss at iteration 1140 : 0.016323667019605637
Loss at iteration 1150 : 0.014619419351220131
Loss at iteration 1160 : 0.015668600797653198
Loss at iteration 1170 : 0.01137087307870388
Loss at iteration 1180 : 0.02160545624792576
Loss at iteration 1190 : 0.015693994238972664
Loss at iteration 1200 : 0.02582564577460289
Loss at iteration 1210 : 0.014501834288239479
Loss at iteration 1220 : 0.013281909748911858
Loss at iteration 1230 : 0.028830915689468384
Loss at iteration 1240 : 0.012377480044960976
Loss at iteration 1250 : 0.034764621406793594
Loss at iteration 1260 : 0.027623677626252174
Loss at iteration 1270 : 0.008937837556004524
Loss at iteration 1280 : 0.03101995587348938
Loss at iteration 1290 : 0.035812586545944214
Loss at iteration 1300 : 0.014197014272212982
Loss at iteration 1310 : 0.030026718974113464
Loss at iteration 1320 : 0.02686462551355362
Loss at iteration 1330 : 0.011064409278333187
Loss at iteration 1340 : 0.01627921871840954
Loss at iteration 1350 : 0.006919471547007561
Loss at iteration 1360 : 0.017322421073913574
Loss at iteration 1370 : 0.01337539590895176
Loss at iteration 1380 : 0.019161857664585114
Loss at iteration 1390 : 0.015033562667667866
Loss at iteration 1400 : 0.014248427003622055
Loss at iteration 1410 : 0.017590733245015144
Loss at iteration 1420 : 0.01406082883477211
Loss at iteration 1430 : 0.021500729024410248
Loss at iteration 1440 : 0.015205059200525284
Loss at iteration 1450 : 0.011321501806378365
Loss at iteration 1460 : 0.009004267863929272
Loss at iteration 1470 : 0.028231535106897354
Loss at iteration 1480 : 0.017875894904136658
Loss at iteration 1490 : 0.01535186730325222
Loss at iteration 1500 : 0.03360036015510559
Loss at iteration 1510 : 0.023505855351686478
Loss at iteration 1520 : 0.013208313845098019
Loss at iteration 1530 : 0.03112480603158474
Loss at iteration 1540 : 0.023191751912236214
Loss at iteration 1550 : 0.03569996356964111
Loss at iteration 1560 : 0.017385955899953842
Loss at iteration 1570 : 0.01350272074341774
Loss at iteration 1580 : 0.013572372496128082
Loss at iteration 1590 : 0.026125507429242134
Loss at iteration 1600 : 0.023988328874111176
Loss at iteration 1610 : 0.01812075451016426
Loss at iteration 1620 : 0.013247105292975903
Loss at iteration 1630 : 0.011362922377884388
Loss at iteration 1640 : 0.01217588596045971
Loss at iteration 1650 : 0.011129437014460564
Loss at iteration 1660 : 0.01883743517100811
Loss at iteration 1670 : 0.020724352449178696
Loss at iteration 1680 : 0.015041087754070759
Loss at iteration 1690 : 0.014064725488424301
Loss at iteration 1700 : 0.01849127747118473
Loss at iteration 1710 : 0.01926136016845703
Loss at iteration 1720 : 0.018672799691557884
Loss at iteration 1730 : 0.010036781430244446
Loss at iteration 1740 : 0.00998680479824543
Loss at iteration 1750 : 0.016072966158390045
Loss at iteration 1760 : 0.01380266435444355
Loss at iteration 1770 : 0.013914440758526325
Loss at iteration 1780 : 0.0247549656778574
Loss at iteration 1790 : 0.015244719572365284
Loss at iteration 1800 : 0.016988417133688927
Loss at iteration 1810 : 0.006114878226071596
Loss at iteration 1820 : 0.020775314420461655
Loss at iteration 1830 : 0.02520536258816719
Loss at iteration 1840 : 0.008628694340586662
Loss at iteration 1850 : 0.015023201704025269
Loss at iteration 1860 : 0.005100504029542208
Loss at iteration 1870 : 0.020244427025318146
Loss at iteration 1880 : 0.010844115167856216
Loss at iteration 1890 : 0.013221267610788345
Loss at iteration 1900 : 0.026205211877822876
Loss at iteration 1910 : 0.016709614545106888
Loss at iteration 1920 : 0.0088131632655859
Loss at iteration 1930 : 0.018706105649471283
Loss at iteration 1940 : 0.019986312836408615
Loss at iteration 1950 : 0.017182813957333565
Loss at iteration 1960 : 0.021268080919981003
Loss at iteration 1970 : 0.01968851312994957
Loss at iteration 1980 : 0.013127855956554413
Loss at iteration 1990 : 0.020113272592425346
Loss at iteration 2000 : 0.012253308668732643
Loss at iteration 2010 : 0.01612185500562191
Loss at iteration 2020 : 0.023515168577432632
Loss at iteration 2030 : 0.021187875419855118
Loss at iteration 2040 : 0.025353195145726204
Loss at iteration 2050 : 0.019042588770389557
Loss at iteration 2060 : 0.017093168571591377
Loss at iteration 2070 : 0.012482191435992718
Loss at iteration 2080 : 0.027057256549596786
Loss at iteration 2090 : 0.021264374256134033
Loss at iteration 2100 : 0.015353921800851822
Loss at iteration 2110 : 0.011148764751851559
Loss at iteration 2120 : 0.017436183989048004
Loss at iteration 2130 : 0.033074330538511276
Loss at iteration 2140 : 0.011692631989717484
Loss at iteration 2150 : 0.015552641823887825
Loss at iteration 2160 : 0.016280969604849815
Loss at iteration 2170 : 0.014302266761660576
Loss at iteration 2180 : 0.017104171216487885
Loss at iteration 2190 : 0.016870807856321335
Loss at iteration 2200 : 0.019757339730858803
Loss at iteration 2210 : 0.014843120239675045
Loss at iteration 2220 : 0.013080017641186714
Loss at iteration 2230 : 0.017790958285331726
Loss at iteration 2240 : 0.009309212677180767
Loss at iteration 2250 : 0.02002646215260029
Loss at iteration 2260 : 0.020169757306575775
Loss at iteration 2270 : 0.011112822219729424
Loss at iteration 2280 : 0.010452378541231155
Loss at iteration 2290 : 0.01112028956413269
Loss at iteration 2300 : 0.019591227173805237
Loss at iteration 2310 : 0.01301979087293148
Loss at iteration 2320 : 0.015608764253556728
Loss at iteration 2330 : 0.0069692740216851234
Loss at iteration 2340 : 0.025882335379719734
Loss at iteration 2350 : 0.029636770486831665
Loss at iteration 2360 : 0.00811210460960865
Loss at iteration 2370 : 0.022282378748059273
Loss at iteration 2380 : 0.017639603465795517
Loss at iteration 2390 : 0.014837229624390602
Loss at iteration 2400 : 0.010731291025876999
Loss at iteration 2410 : 0.01259700022637844
Loss at iteration 2420 : 0.01923898048698902
The SSIM Value is: 0.799346141020457
The PSNR Value is: 19.246812884012858
the highest SSIM value is: 19.246812884012858
the epoch is: 2
Loss at iteration 10 : 0.015139603987336159
Loss at iteration 20 : 0.024155735969543457
Loss at iteration 30 : 0.03512371703982353
Loss at iteration 40 : 0.018168320879340172
Loss at iteration 50 : 0.018241414800286293
Loss at iteration 60 : 0.007338547147810459
Loss at iteration 70 : 0.02629556879401207
Loss at iteration 80 : 0.01672973670065403
Loss at iteration 90 : 0.012301398441195488
Loss at iteration 100 : 0.022456716746091843
Loss at iteration 110 : 0.01891811564564705
Loss at iteration 120 : 0.020753372460603714
Loss at iteration 130 : 0.015215104445815086
Loss at iteration 140 : 0.012593956664204597
Loss at iteration 150 : 0.019980374723672867
Loss at iteration 160 : 0.008775854483246803
Loss at iteration 170 : 0.008059934712946415
Loss at iteration 180 : 0.025842834264039993
Loss at iteration 190 : 0.01691064052283764
Loss at iteration 200 : 0.011669271625578403
Loss at iteration 210 : 0.010334398597478867
Loss at iteration 220 : 0.015020359307527542
Loss at iteration 230 : 0.016863320022821426
Loss at iteration 240 : 0.01609065756201744
Loss at iteration 250 : 0.023045606911182404
Loss at iteration 260 : 0.031350668519735336
Loss at iteration 270 : 0.015075726434588432
Loss at iteration 280 : 0.016825519502162933
Loss at iteration 290 : 0.015094525180757046
Loss at iteration 300 : 0.00493836123496294
Loss at iteration 310 : 0.009758200496435165
Loss at iteration 320 : 0.01309350784868002
Loss at iteration 330 : 0.015044313855469227
Loss at iteration 340 : 0.020757798105478287
Loss at iteration 350 : 0.036824554204940796
Loss at iteration 360 : 0.015580721199512482
Loss at iteration 370 : 0.009772021323442459
Loss at iteration 380 : 0.03154023736715317
Loss at iteration 390 : 0.020820768550038338
Loss at iteration 400 : 0.020976215600967407
Loss at iteration 410 : 0.015486042946577072
Loss at iteration 420 : 0.019359469413757324
Loss at iteration 430 : 0.01704028993844986
Loss at iteration 440 : 0.009124325588345528
Loss at iteration 450 : 0.011649875901639462
Loss at iteration 460 : 0.00817907601594925
Loss at iteration 470 : 0.014581561088562012
Loss at iteration 480 : 0.013456346467137337
Loss at iteration 490 : 0.011505497619509697
Loss at iteration 500 : 0.006823599338531494
Loss at iteration 510 : 0.009974327869713306
Loss at iteration 520 : 0.018296323716640472
Loss at iteration 530 : 0.010632839985191822
Loss at iteration 540 : 0.01899525336921215
Loss at iteration 550 : 0.013469110243022442
Loss at iteration 560 : 0.003750219475477934
Loss at iteration 570 : 0.024021048098802567
Loss at iteration 580 : 0.02675725147128105
Loss at iteration 590 : 0.020765839144587517
Loss at iteration 600 : 0.00955395307391882
Loss at iteration 610 : 0.012884575873613358
Loss at iteration 620 : 0.020593736320734024
Loss at iteration 630 : 0.009783750399947166
Loss at iteration 640 : 0.02376059629023075
Loss at iteration 650 : 0.011155985295772552
Loss at iteration 660 : 0.012186179868876934
Loss at iteration 670 : 0.020632648840546608
Loss at iteration 680 : 0.014522030018270016
Loss at iteration 690 : 0.022029459476470947
Loss at iteration 700 : 0.006034656427800655
Loss at iteration 710 : 0.016122572124004364
Loss at iteration 720 : 0.016944674775004387
Loss at iteration 730 : 0.022924136370420456
Loss at iteration 740 : 0.028710832819342613
Loss at iteration 750 : 0.01553904078900814
Loss at iteration 760 : 0.017383147031068802
Loss at iteration 770 : 0.007418111432343721
Loss at iteration 780 : 0.02680211327970028
Loss at iteration 790 : 0.01006748341023922
Loss at iteration 800 : 0.016017355024814606
Loss at iteration 810 : 0.022669225931167603
Loss at iteration 820 : 0.029718682169914246
Loss at iteration 830 : 0.014788355678319931
Loss at iteration 840 : 0.013687996193766594
Loss at iteration 850 : 0.009611326269805431
Loss at iteration 860 : 0.025427265092730522
Loss at iteration 870 : 0.022489096969366074
Loss at iteration 880 : 0.025579821318387985
Loss at iteration 890 : 0.010799665004014969
Loss at iteration 900 : 0.03379032760858536
Loss at iteration 910 : 0.006657036952674389
Loss at iteration 920 : 0.03989982232451439
Loss at iteration 930 : 0.022964291274547577
Loss at iteration 940 : 0.011931288056075573
Loss at iteration 950 : 0.013418437913060188
Loss at iteration 960 : 0.018537085503339767
Loss at iteration 970 : 0.021720778197050095
Loss at iteration 980 : 0.01732121780514717
Loss at iteration 990 : 0.02337954193353653
Loss at iteration 1000 : 0.006416588090360165
Loss at iteration 1010 : 0.015119819901883602
Loss at iteration 1020 : 0.014355791732668877
Loss at iteration 1030 : 0.01358520332723856
Loss at iteration 1040 : 0.016596263274550438
Loss at iteration 1050 : 0.008944652043282986
Loss at iteration 1060 : 0.017058975994586945
Loss at iteration 1070 : 0.017071444541215897
Loss at iteration 1080 : 0.023307744413614273
Loss at iteration 1090 : 0.009007373824715614
Loss at iteration 1100 : 0.016335003077983856
Loss at iteration 1110 : 0.03372612223029137
Loss at iteration 1120 : 0.024141201749444008
Loss at iteration 1130 : 0.018818523734807968
Loss at iteration 1140 : 0.006866022013127804
Loss at iteration 1150 : 0.015935000032186508
Loss at iteration 1160 : 0.010987475514411926
Loss at iteration 1170 : 0.054165951907634735
Loss at iteration 1180 : 0.032898832112550735
Loss at iteration 1190 : 0.016044236719608307
Loss at iteration 1200 : 0.019330119714140892
Loss at iteration 1210 : 0.021766727790236473
Loss at iteration 1220 : 0.006345031782984734
Loss at iteration 1230 : 0.009089939296245575
Loss at iteration 1240 : 0.010401380248367786
Loss at iteration 1250 : 0.008923185989260674
Loss at iteration 1260 : 0.025661392137408257
Loss at iteration 1270 : 0.009578673169016838
Loss at iteration 1280 : 0.018207058310508728
Loss at iteration 1290 : 0.011165953241288662
Loss at iteration 1300 : 0.024998903274536133
Loss at iteration 1310 : 0.022918395698070526
Loss at iteration 1320 : 0.010529463179409504
Loss at iteration 1330 : 0.0431409552693367
Loss at iteration 1340 : 0.016106976196169853
Loss at iteration 1350 : 0.01729339174926281
Loss at iteration 1360 : 0.020208869129419327
Loss at iteration 1370 : 0.020197298377752304
Loss at iteration 1380 : 0.00803429540246725
Loss at iteration 1390 : 0.03134830296039581
Loss at iteration 1400 : 0.03276451304554939
Loss at iteration 1410 : 0.022887010127305984
Loss at iteration 1420 : 0.007510766852647066
Loss at iteration 1430 : 0.008721834048628807
Loss at iteration 1440 : 0.016260556876659393
Loss at iteration 1450 : 0.007926542311906815
Loss at iteration 1460 : 0.021492520347237587
Loss at iteration 1470 : 0.015759840607643127
Loss at iteration 1480 : 0.03254446014761925
Loss at iteration 1490 : 0.018727317452430725
Loss at iteration 1500 : 0.028303176164627075
Loss at iteration 1510 : 0.020421946421265602
Loss at iteration 1520 : 0.013510704971849918
Loss at iteration 1530 : 0.03462761640548706
Loss at iteration 1540 : 0.01301686093211174
Loss at iteration 1550 : 0.02193198725581169
Loss at iteration 1560 : 0.022197090089321136
Loss at iteration 1570 : 0.018893323838710785
Loss at iteration 1580 : 0.008718142285943031
Loss at iteration 1590 : 0.017871778458356857
Loss at iteration 1600 : 0.02355129085481167
Loss at iteration 1610 : 0.0313047431409359
Loss at iteration 1620 : 0.01516021229326725
Loss at iteration 1630 : 0.015849141404032707
Loss at iteration 1640 : 0.02262694202363491
Loss at iteration 1650 : 0.022980429232120514
Loss at iteration 1660 : 0.019195836037397385
Loss at iteration 1670 : 0.01291629672050476
Loss at iteration 1680 : 0.01249346137046814
Loss at iteration 1690 : 0.01234968937933445
Loss at iteration 1700 : 0.02737022191286087
Loss at iteration 1710 : 0.015121116302907467
Loss at iteration 1720 : 0.016619237139821053
Loss at iteration 1730 : 0.017253801226615906
Loss at iteration 1740 : 0.008091697469353676
Loss at iteration 1750 : 0.012488468550145626
Loss at iteration 1760 : 0.019999394193291664
Loss at iteration 1770 : 0.026777546852827072
Loss at iteration 1780 : 0.013280266895890236
Loss at iteration 1790 : 0.021055761724710464
Loss at iteration 1800 : 0.019268512725830078
Loss at iteration 1810 : 0.011964993551373482
Loss at iteration 1820 : 0.009948587976396084
Loss at iteration 1830 : 0.030783161520957947
Loss at iteration 1840 : 0.02091556414961815
Loss at iteration 1850 : 0.026361828669905663
Loss at iteration 1860 : 0.006461582146584988
Loss at iteration 1870 : 0.02545567788183689
Loss at iteration 1880 : 0.02068997360765934
Loss at iteration 1890 : 0.02239730767905712
Loss at iteration 1900 : 0.022279728204011917
Loss at iteration 1910 : 0.028751172125339508
Loss at iteration 1920 : 0.02290937304496765
Loss at iteration 1930 : 0.01260744221508503
Loss at iteration 1940 : 0.0265482347458601
Loss at iteration 1950 : 0.015347368083894253
Loss at iteration 1960 : 0.019029119983315468
Loss at iteration 1970 : 0.018455926328897476
Loss at iteration 1980 : 0.02726193144917488
Loss at iteration 1990 : 0.015241770073771477
Loss at iteration 2000 : 0.018138766288757324
Loss at iteration 2010 : 0.01480864267796278
Loss at iteration 2020 : 0.02306458167731762
Loss at iteration 2030 : 0.015746958553791046
Loss at iteration 2040 : 0.01296255737543106
Loss at iteration 2050 : 0.016330191865563393
Loss at iteration 2060 : 0.0161762572824955
Loss at iteration 2070 : 0.023752432316541672
Loss at iteration 2080 : 0.013170916587114334
Loss at iteration 2090 : 0.008610953576862812
Loss at iteration 2100 : 0.012371215038001537
Loss at iteration 2110 : 0.02301795780658722
Loss at iteration 2120 : 0.02171604335308075
Loss at iteration 2130 : 0.013125181198120117
Loss at iteration 2140 : 0.018407249823212624
Loss at iteration 2150 : 0.014475474134087563
Loss at iteration 2160 : 0.01115085557103157
Loss at iteration 2170 : 0.011874034069478512
Loss at iteration 2180 : 0.01457885280251503
Loss at iteration 2190 : 0.016997063532471657
Loss at iteration 2200 : 0.013637656345963478
Loss at iteration 2210 : 0.014991747215390205
Loss at iteration 2220 : 0.016949504613876343
Loss at iteration 2230 : 0.016984958201646805
Loss at iteration 2240 : 0.025138046592473984
Loss at iteration 2250 : 0.012630156241357327
Loss at iteration 2260 : 0.025958474725484848
Loss at iteration 2270 : 0.017292821779847145
Loss at iteration 2280 : 0.02376614511013031
Loss at iteration 2290 : 0.019987821578979492
Loss at iteration 2300 : 0.023629501461982727
Loss at iteration 2310 : 0.012675857171416283
Loss at iteration 2320 : 0.021109100431203842
Loss at iteration 2330 : 0.01941068097949028
Loss at iteration 2340 : 0.029872778803110123
Loss at iteration 2350 : 0.020570050925016403
Loss at iteration 2360 : 0.024468744173645973
Loss at iteration 2370 : 0.011552108451724052
Loss at iteration 2380 : 0.012835233472287655
Loss at iteration 2390 : 0.04085325449705124
Loss at iteration 2400 : 0.016156688332557678
Loss at iteration 2410 : 0.014069844968616962
Loss at iteration 2420 : 0.01743825152516365
The SSIM Value is: 0.8053473671277364
The PSNR Value is: 20.061562665303548
the highest SSIM value is: 20.061562665303548
the epoch is: 3
Loss at iteration 10 : 0.017557496204972267
Loss at iteration 20 : 0.024857059121131897
Loss at iteration 30 : 0.010441500693559647
Loss at iteration 40 : 0.025240864604711533
Loss at iteration 50 : 0.01444056537002325
Loss at iteration 60 : 0.01489074807614088
Loss at iteration 70 : 0.023624978959560394
Loss at iteration 80 : 0.02034170739352703
Loss at iteration 90 : 0.021483656018972397
Loss at iteration 100 : 0.006344824098050594
Loss at iteration 110 : 0.009743194095790386
Loss at iteration 120 : 0.013923438265919685
Loss at iteration 130 : 0.0123984320089221
Loss at iteration 140 : 0.01472218707203865
Loss at iteration 150 : 0.025152409449219704
Loss at iteration 160 : 0.023588771000504494
Loss at iteration 170 : 0.010606307536363602
Loss at iteration 180 : 0.012046251446008682
Loss at iteration 190 : 0.011245710775256157
Loss at iteration 200 : 0.003865924896672368
Loss at iteration 210 : 0.01964418590068817
Loss at iteration 220 : 0.011167997494339943
Loss at iteration 230 : 0.016916848719120026
Loss at iteration 240 : 0.02761288918554783
Loss at iteration 250 : 0.014460599981248379
Loss at iteration 260 : 0.017857296392321587
Loss at iteration 270 : 0.01651081070303917
Loss at iteration 280 : 0.013573981821537018
Loss at iteration 290 : 0.013495558872818947
Loss at iteration 300 : 0.012376219034194946
Loss at iteration 310 : 0.020782005041837692
Loss at iteration 320 : 0.015329889953136444
Loss at iteration 330 : 0.019980717450380325
Loss at iteration 340 : 0.02577854134142399
Loss at iteration 350 : 0.02053814008831978
Loss at iteration 360 : 0.02693086490035057
Loss at iteration 370 : 0.017836593091487885
Loss at iteration 380 : 0.029972746968269348
Loss at iteration 390 : 0.026590649038553238
Loss at iteration 400 : 0.008598383516073227
Loss at iteration 410 : 0.013580462895333767
Loss at iteration 420 : 0.016136549413204193
Loss at iteration 430 : 0.023206615820527077
Loss at iteration 440 : 0.02110162191092968
Loss at iteration 450 : 0.00901233684271574
Loss at iteration 460 : 0.00911349430680275
Loss at iteration 470 : 0.015201449394226074
Loss at iteration 480 : 0.006720276083797216
Loss at iteration 490 : 0.005066481418907642
Loss at iteration 500 : 0.012418574653565884
Loss at iteration 510 : 0.02151854708790779
Loss at iteration 520 : 0.014268479309976101
Loss at iteration 530 : 0.013712144456803799
Loss at iteration 540 : 0.019792381674051285
Loss at iteration 550 : 0.004516372457146645
Loss at iteration 560 : 0.005271610338240862
Loss at iteration 570 : 0.01569061540067196
Loss at iteration 580 : 0.017302080988883972
Loss at iteration 590 : 0.0047021545469760895
Loss at iteration 600 : 0.019563481211662292
Loss at iteration 610 : 0.010769499465823174
Loss at iteration 620 : 0.011963103897869587
Loss at iteration 630 : 0.007411547936499119
Loss at iteration 640 : 0.011352576315402985
Loss at iteration 650 : 0.015387455932796001
Loss at iteration 660 : 0.02262800931930542
Loss at iteration 670 : 0.015704333782196045
Loss at iteration 680 : 0.020343376323580742
Loss at iteration 690 : 0.017345473170280457
Loss at iteration 700 : 0.011448335833847523
Loss at iteration 710 : 0.036321308463811874
Loss at iteration 720 : 0.02179126814007759
Loss at iteration 730 : 0.02009129896759987
Loss at iteration 740 : 0.020938433706760406
Loss at iteration 750 : 0.036907196044921875
Loss at iteration 760 : 0.013153224252164364
Loss at iteration 770 : 0.031810592859983444
Loss at iteration 780 : 0.010653081350028515
Loss at iteration 790 : 0.007621662225574255
Loss at iteration 800 : 0.008984982967376709
Loss at iteration 810 : 0.016350872814655304
Loss at iteration 820 : 0.016856977716088295
Loss at iteration 830 : 0.015594767406582832
Loss at iteration 840 : 0.01837572082877159
Loss at iteration 850 : 0.017466992139816284
Loss at iteration 860 : 0.023616444319486618
Loss at iteration 870 : 0.011464645154774189
Loss at iteration 880 : 0.027030566707253456
Loss at iteration 890 : 0.011497357860207558
Loss at iteration 900 : 0.012293962761759758
Loss at iteration 910 : 0.012073465622961521
Loss at iteration 920 : 0.02201191708445549
Loss at iteration 930 : 0.008313890546560287
Loss at iteration 940 : 0.013937477953732014
Loss at iteration 950 : 0.0292506106197834
Loss at iteration 960 : 0.014841720461845398
Loss at iteration 970 : 0.010153165087103844
Loss at iteration 980 : 0.015770304948091507
Loss at iteration 990 : 0.03204762935638428
Loss at iteration 1000 : 0.024633631110191345
Loss at iteration 1010 : 0.01830863766372204
Loss at iteration 1020 : 0.014736426062881947
Loss at iteration 1030 : 0.022234410047531128
Loss at iteration 1040 : 0.00993362907320261
Loss at iteration 1050 : 0.012934651225805283
Loss at iteration 1060 : 0.011991472914814949
Loss at iteration 1070 : 0.01637120731174946
Loss at iteration 1080 : 0.012387799099087715
Loss at iteration 1090 : 0.015240976586937904
Loss at iteration 1100 : 0.018726252019405365
Loss at iteration 1110 : 0.02969130501151085
Loss at iteration 1120 : 0.03679072484374046
Loss at iteration 1130 : 0.010469002649188042
Loss at iteration 1140 : 0.011444322764873505
Loss at iteration 1150 : 0.020756125450134277
Loss at iteration 1160 : 0.01234591193497181
Loss at iteration 1170 : 0.0120698856189847
Loss at iteration 1180 : 0.010883674956858158
Loss at iteration 1190 : 0.024585656821727753
Loss at iteration 1200 : 0.01681237854063511
Loss at iteration 1210 : 0.021826112642884254
Loss at iteration 1220 : 0.011052398011088371
Loss at iteration 1230 : 0.016044234856963158
Loss at iteration 1240 : 0.03141455352306366
Loss at iteration 1250 : 0.02114732563495636
Loss at iteration 1260 : 0.04883719980716705
Loss at iteration 1270 : 0.01319517008960247
Loss at iteration 1280 : 0.025191843509674072
Loss at iteration 1290 : 0.00990745797753334
Loss at iteration 1300 : 0.019274987280368805
Loss at iteration 1310 : 0.020773813128471375
Loss at iteration 1320 : 0.0193185955286026
Loss at iteration 1330 : 0.015003222040832043
Loss at iteration 1340 : 0.008956979028880596
Loss at iteration 1350 : 0.026796720921993256
Loss at iteration 1360 : 0.013644702732563019
Loss at iteration 1370 : 0.005082443356513977
Loss at iteration 1380 : 0.017389528453350067
Loss at iteration 1390 : 0.005654364824295044
Loss at iteration 1400 : 0.02499542571604252
Loss at iteration 1410 : 0.024443738162517548
Loss at iteration 1420 : 0.013018155470490456
Loss at iteration 1430 : 0.018940208479762077
Loss at iteration 1440 : 0.010215986520051956
Loss at iteration 1450 : 0.019464313983917236
Loss at iteration 1460 : 0.007526197005063295
Loss at iteration 1470 : 0.01761087030172348
Loss at iteration 1480 : 0.01903468184173107
Loss at iteration 1490 : 0.011788842268288136
Loss at iteration 1500 : 0.015051214024424553
Loss at iteration 1510 : 0.01630391925573349
Loss at iteration 1520 : 0.036802127957344055
Loss at iteration 1530 : 0.007142118643969297
Loss at iteration 1540 : 0.01414916105568409
Loss at iteration 1550 : 0.01807738095521927
Loss at iteration 1560 : 0.016236063092947006
Loss at iteration 1570 : 0.017850395292043686
Loss at iteration 1580 : 0.011351261287927628
Loss at iteration 1590 : 0.011018559336662292
Loss at iteration 1600 : 0.018236244097352028
Loss at iteration 1610 : 0.013915295712649822
Loss at iteration 1620 : 0.0157484021037817
Loss at iteration 1630 : 0.01871405355632305
Loss at iteration 1640 : 0.011179275810718536
Loss at iteration 1650 : 0.009667469188570976
Loss at iteration 1660 : 0.01269932184368372
Loss at iteration 1670 : 0.014878453686833382
Loss at iteration 1680 : 0.02012692391872406
Loss at iteration 1690 : 0.010647354647517204
Loss at iteration 1700 : 0.019038721919059753
Loss at iteration 1710 : 0.025647969916462898
Loss at iteration 1720 : 0.014385746791958809
Loss at iteration 1730 : 0.0077582066878676414
Loss at iteration 1740 : 0.012599433772265911
Loss at iteration 1750 : 0.013673139736056328
Loss at iteration 1760 : 0.010334321297705173
Loss at iteration 1770 : 0.012717084027826786
Loss at iteration 1780 : 0.01779264025390148
Loss at iteration 1790 : 0.011428918689489365
Loss at iteration 1800 : 0.01274985633790493
Loss at iteration 1810 : 0.019873159006237984
Loss at iteration 1820 : 0.030663762241601944
Loss at iteration 1830 : 0.010965952649712563
Loss at iteration 1840 : 0.020453108474612236
Loss at iteration 1850 : 0.013997571542859077
Loss at iteration 1860 : 0.00995080266147852
Loss at iteration 1870 : 0.017118653282523155
Loss at iteration 1880 : 0.023337848484516144
Loss at iteration 1890 : 0.018053019419312477
Loss at iteration 1900 : 0.03706548735499382
Loss at iteration 1910 : 0.03181050717830658
Loss at iteration 1920 : 0.03332493454217911
Loss at iteration 1930 : 0.02101697400212288
Loss at iteration 1940 : 0.014729650691151619
Loss at iteration 1950 : 0.020495351403951645
Loss at iteration 1960 : 0.007069299463182688
Loss at iteration 1970 : 0.010409349575638771
Loss at iteration 1980 : 0.006796006113290787
Loss at iteration 1990 : 0.009105394594371319
Loss at iteration 2000 : 0.021273739635944366
Loss at iteration 2010 : 0.030253656208515167
Loss at iteration 2020 : 0.017056502401828766
Loss at iteration 2030 : 0.01619996875524521
Loss at iteration 2040 : 0.010712606832385063
Loss at iteration 2050 : 0.017646685242652893
Loss at iteration 2060 : 0.012532847933471203
Loss at iteration 2070 : 0.023082055151462555
Loss at iteration 2080 : 0.011267483234405518
Loss at iteration 2090 : 0.013167159631848335
Loss at iteration 2100 : 0.018435699865221977
Loss at iteration 2110 : 0.014156052842736244
Loss at iteration 2120 : 0.017830226570367813
Loss at iteration 2130 : 0.00859539583325386
Loss at iteration 2140 : 0.01042005605995655
Loss at iteration 2150 : 0.012637874111533165
Loss at iteration 2160 : 0.0294947512447834
Loss at iteration 2170 : 0.020018983632326126
Loss at iteration 2180 : 0.009180966764688492
Loss at iteration 2190 : 0.013964330777525902
Loss at iteration 2200 : 0.01268775574862957
Loss at iteration 2210 : 0.00769933732226491
Loss at iteration 2220 : 0.014262805692851543
Loss at iteration 2230 : 0.011784887872636318
Loss at iteration 2240 : 0.025212852284312248
Loss at iteration 2250 : 0.025509923696517944
Loss at iteration 2260 : 0.009993979707360268
Loss at iteration 2270 : 0.02039283700287342
Loss at iteration 2280 : 0.03326774388551712
Loss at iteration 2290 : 0.008950135670602322
Loss at iteration 2300 : 0.010387944057583809
Loss at iteration 2310 : 0.014047900214791298
Loss at iteration 2320 : 0.009299833327531815
Loss at iteration 2330 : 0.010150191374123096
Loss at iteration 2340 : 0.01306143682450056
Loss at iteration 2350 : 0.019163526594638824
Loss at iteration 2360 : 0.016910851001739502
Loss at iteration 2370 : 0.024344753473997116
Loss at iteration 2380 : 0.03087780252099037
Loss at iteration 2390 : 0.02299051359295845
Loss at iteration 2400 : 0.01750883087515831
Loss at iteration 2410 : 0.010299419984221458
Loss at iteration 2420 : 0.015406819060444832
The SSIM Value is: 0.8182691653569539
The PSNR Value is: 20.205790774027506
the highest SSIM value is: 20.205790774027506
the epoch is: 4
Loss at iteration 10 : 0.013792387209832668
Loss at iteration 20 : 0.01680540107190609
Loss at iteration 30 : 0.011409859172999859
Loss at iteration 40 : 0.022876450791954994
Loss at iteration 50 : 0.012030437588691711
Loss at iteration 60 : 0.025703079998493195
Loss at iteration 70 : 0.01115107350051403
Loss at iteration 80 : 0.013858983293175697
Loss at iteration 90 : 0.026795897632837296
Loss at iteration 100 : 0.019950658082962036
Loss at iteration 110 : 0.016805047169327736
Loss at iteration 120 : 0.014091599732637405
Loss at iteration 130 : 0.01832892745733261
Loss at iteration 140 : 0.01184253953397274
Loss at iteration 150 : 0.011937414295971394
Loss at iteration 160 : 0.015292109921574593
Loss at iteration 170 : 0.014606060460209846
Loss at iteration 180 : 0.011891347356140614
Loss at iteration 190 : 0.019076349213719368
Loss at iteration 200 : 0.01909731701016426
Loss at iteration 210 : 0.022257883101701736
Loss at iteration 220 : 0.018852954730391502
Loss at iteration 230 : 0.028706058859825134
Loss at iteration 240 : 0.006634566467255354
Loss at iteration 250 : 0.019817519932985306
Loss at iteration 260 : 0.008208826184272766
Loss at iteration 270 : 0.021532775834202766
Loss at iteration 280 : 0.014101201668381691
Loss at iteration 290 : 0.01672862097620964
Loss at iteration 300 : 0.01207025721669197
Loss at iteration 310 : 0.035807158797979355
Loss at iteration 320 : 0.014218985103070736
Loss at iteration 330 : 0.016674479469656944
Loss at iteration 340 : 0.016243191435933113
Loss at iteration 350 : 0.02022058330476284
Loss at iteration 360 : 0.02385643497109413
Loss at iteration 370 : 0.017803382128477097
Loss at iteration 380 : 0.017838438972830772
Loss at iteration 390 : 0.014146732166409492
Loss at iteration 400 : 0.00628948537632823
Loss at iteration 410 : 0.015698593109846115
Loss at iteration 420 : 0.006930680479854345
Loss at iteration 430 : 0.012344304472208023
Loss at iteration 440 : 0.01774451695382595
Loss at iteration 450 : 0.020968567579984665
Loss at iteration 460 : 0.01828658953309059
Loss at iteration 470 : 0.019321918487548828
Loss at iteration 480 : 0.005773273762315512
Loss at iteration 490 : 0.02038758620619774
Loss at iteration 500 : 0.011717144399881363
Loss at iteration 510 : 0.021250735968351364
Loss at iteration 520 : 0.015741858631372452
Loss at iteration 530 : 0.01039876788854599
Loss at iteration 540 : 0.01496660802513361
Loss at iteration 550 : 0.033426105976104736
Loss at iteration 560 : 0.015695903450250626
Loss at iteration 570 : 0.012829037383198738
Loss at iteration 580 : 0.01010767463594675
Loss at iteration 590 : 0.018055440858006477
Loss at iteration 600 : 0.00981119554489851
Loss at iteration 610 : 0.0229825209826231
Loss at iteration 620 : 0.013788707554340363
Loss at iteration 630 : 0.021745465695858
Loss at iteration 640 : 0.015262042172253132
Loss at iteration 650 : 0.02465590089559555
Loss at iteration 660 : 0.013984344899654388
Loss at iteration 670 : 0.0229044109582901
Loss at iteration 680 : 0.03067772462964058
Loss at iteration 690 : 0.03795962035655975
Loss at iteration 700 : 0.019630029797554016
Loss at iteration 710 : 0.020821567624807358
Loss at iteration 720 : 0.011292287148535252
Loss at iteration 730 : 0.024506743997335434
Loss at iteration 740 : 0.015852605924010277
Loss at iteration 750 : 0.013435479253530502
Loss at iteration 760 : 0.019222870469093323
Loss at iteration 770 : 0.008456302806735039
Loss at iteration 780 : 0.006183289922773838
Loss at iteration 790 : 0.007650114130228758
Loss at iteration 800 : 0.03004772588610649
Loss at iteration 810 : 0.0077695082873106
Loss at iteration 820 : 0.017906447872519493
Loss at iteration 830 : 0.01677856594324112
Loss at iteration 840 : 0.017836138606071472
Loss at iteration 850 : 0.008786272257566452
Loss at iteration 860 : 0.0168345607817173
Loss at iteration 870 : 0.013244410045444965
Loss at iteration 880 : 0.015413138084113598
Loss at iteration 890 : 0.03646770864725113
Loss at iteration 900 : 0.022568102926015854
Loss at iteration 910 : 0.020905571058392525
Loss at iteration 920 : 0.033077310770750046
Loss at iteration 930 : 0.014090923592448235
Loss at iteration 940 : 0.022071264684200287
Loss at iteration 950 : 0.016396403312683105
Loss at iteration 960 : 0.009174668230116367
Loss at iteration 970 : 0.009232966229319572
Loss at iteration 980 : 0.01852908730506897
Loss at iteration 990 : 0.035544998943805695
Loss at iteration 1000 : 0.0365876704454422
Loss at iteration 1010 : 0.01365729607641697
Loss at iteration 1020 : 0.020051447674632072
Loss at iteration 1030 : 0.014394763857126236
Loss at iteration 1040 : 0.022747179493308067
Loss at iteration 1050 : 0.0243912972509861
Loss at iteration 1060 : 0.008701173588633537
Loss at iteration 1070 : 0.02085239067673683
Loss at iteration 1080 : 0.014869548380374908
Loss at iteration 1090 : 0.008699261583387852
Loss at iteration 1100 : 0.011199099943041801
Loss at iteration 1110 : 0.016556231305003166
Loss at iteration 1120 : 0.014083463698625565
Loss at iteration 1130 : 0.02577935717999935
Loss at iteration 1140 : 0.011107631027698517
Loss at iteration 1150 : 0.01619499735534191
Loss at iteration 1160 : 0.011303522624075413
Loss at iteration 1170 : 0.006447643972933292
Loss at iteration 1180 : 0.023739179596304893
Loss at iteration 1190 : 0.006706888321787119
Loss at iteration 1200 : 0.020126258954405785
Loss at iteration 1210 : 0.016043487936258316
Loss at iteration 1220 : 0.00892584677785635
Loss at iteration 1230 : 0.014749468304216862
Loss at iteration 1240 : 0.010625789873301983
Loss at iteration 1250 : 0.01397574320435524
Loss at iteration 1260 : 0.016227688640356064
Loss at iteration 1270 : 0.013212375342845917
Loss at iteration 1280 : 0.011062764562666416
Loss at iteration 1290 : 0.022687654942274094
Loss at iteration 1300 : 0.014126318506896496
Loss at iteration 1310 : 0.029190395027399063
Loss at iteration 1320 : 0.013103062286973
Loss at iteration 1330 : 0.02331223152577877
Loss at iteration 1340 : 0.02432551421225071
Loss at iteration 1350 : 0.018567603081464767
Loss at iteration 1360 : 0.02012394554913044
Loss at iteration 1370 : 0.017201706767082214
Loss at iteration 1380 : 0.016156714409589767
Loss at iteration 1390 : 0.0256478451192379
Loss at iteration 1400 : 0.00811578519642353
Loss at iteration 1410 : 0.01341167651116848
Loss at iteration 1420 : 0.021397598087787628
Loss at iteration 1430 : 0.02218812331557274
Loss at iteration 1440 : 0.013915998861193657
Loss at iteration 1450 : 0.009487119503319263
Loss at iteration 1460 : 0.02663571760058403
Loss at iteration 1470 : 0.0075345272198319435
Loss at iteration 1480 : 0.01235511526465416
Loss at iteration 1490 : 0.014412199147045612
Loss at iteration 1500 : 0.012327633798122406
Loss at iteration 1510 : 0.024500520899891853
Loss at iteration 1520 : 0.007868057116866112
Loss at iteration 1530 : 0.011804282665252686
Loss at iteration 1540 : 0.008605612441897392
Loss at iteration 1550 : 0.013945989310741425
Loss at iteration 1560 : 0.016258034855127335
Loss at iteration 1570 : 0.01684749871492386
Loss at iteration 1580 : 0.018345633521676064
Loss at iteration 1590 : 0.009397010318934917
Loss at iteration 1600 : 0.028227077797055244
Loss at iteration 1610 : 0.003902620170265436
Loss at iteration 1620 : 0.015711968764662743
Loss at iteration 1630 : 0.00987362302839756
Loss at iteration 1640 : 0.015374455600976944
Loss at iteration 1650 : 0.012219416908919811
Loss at iteration 1660 : 0.017155427485704422
Loss at iteration 1670 : 0.023154746741056442
Loss at iteration 1680 : 0.006035798229277134
Loss at iteration 1690 : 0.009043296799063683
Loss at iteration 1700 : 0.00862461980432272
Loss at iteration 1710 : 0.007082395255565643
Loss at iteration 1720 : 0.025801891461014748
Loss at iteration 1730 : 0.013519885949790478
Loss at iteration 1740 : 0.019751902669668198
Loss at iteration 1750 : 0.005894084461033344
Loss at iteration 1760 : 0.010006068274378777
Loss at iteration 1770 : 0.012015992775559425
Loss at iteration 1780 : 0.017386194318532944
Loss at iteration 1790 : 0.01994357258081436
Loss at iteration 1800 : 0.016772665083408356
Loss at iteration 1810 : 0.010099044069647789
Loss at iteration 1820 : 0.02160615473985672
Loss at iteration 1830 : 0.0117062758654356
Loss at iteration 1840 : 0.009614160284399986
Loss at iteration 1850 : 0.02194315381348133
Loss at iteration 1860 : 0.008904429152607918
Loss at iteration 1870 : 0.02205907553434372
Loss at iteration 1880 : 0.016488634049892426
Loss at iteration 1890 : 0.010812828317284584
Loss at iteration 1900 : 0.011446094140410423
Loss at iteration 1910 : 0.017819810658693314
Loss at iteration 1920 : 0.020710017532110214
Loss at iteration 1930 : 0.011682035401463509
Loss at iteration 1940 : 0.011851714923977852
Loss at iteration 1950 : 0.018816716969013214
Loss at iteration 1960 : 0.016879785805940628
Loss at iteration 1970 : 0.010277831926941872
Loss at iteration 1980 : 0.018904227763414383
Loss at iteration 1990 : 0.015186235308647156
Loss at iteration 2000 : 0.01032217312604189
Loss at iteration 2010 : 0.011323490180075169
Loss at iteration 2020 : 0.019514014944434166
Loss at iteration 2030 : 0.005855417810380459
Loss at iteration 2040 : 0.01484842412173748
Loss at iteration 2050 : 0.025473598390817642
Loss at iteration 2060 : 0.01607200689613819
Loss at iteration 2070 : 0.012880631722509861
Loss at iteration 2080 : 0.018520552664995193
Loss at iteration 2090 : 0.02446271851658821
Loss at iteration 2100 : 0.02123118005692959
Loss at iteration 2110 : 0.010829685255885124
Loss at iteration 2120 : 0.013220144435763359
Loss at iteration 2130 : 0.020573463290929794
Loss at iteration 2140 : 0.02432023175060749
Loss at iteration 2150 : 0.010086089372634888
Loss at iteration 2160 : 0.010258696973323822
Loss at iteration 2170 : 0.009379602037370205
Loss at iteration 2180 : 0.012956184335052967
Loss at iteration 2190 : 0.007473776116967201
Loss at iteration 2200 : 0.013682876713573933
Loss at iteration 2210 : 0.013212034478783607
Loss at iteration 2220 : 0.015111234039068222
Loss at iteration 2230 : 0.006908241659402847
Loss at iteration 2240 : 0.034705549478530884
Loss at iteration 2250 : 0.012524444609880447
Loss at iteration 2260 : 0.009708120487630367
Loss at iteration 2270 : 0.007592422422021627
Loss at iteration 2280 : 0.01801573857665062
Loss at iteration 2290 : 0.01355205662548542
Loss at iteration 2300 : 0.012900050729513168
Loss at iteration 2310 : 0.01914462260901928
Loss at iteration 2320 : 0.008552778512239456
Loss at iteration 2330 : 0.014910096302628517
Loss at iteration 2340 : 0.011996928602457047
Loss at iteration 2350 : 0.014614361338317394
Loss at iteration 2360 : 0.00757204182446003
Loss at iteration 2370 : 0.011039835400879383
Loss at iteration 2380 : 0.018057560548186302
Loss at iteration 2390 : 0.023628922179341316
Loss at iteration 2400 : 0.010573620907962322
Loss at iteration 2410 : 0.03459655120968819
Loss at iteration 2420 : 0.014002838172018528
The SSIM Value is: 0.8213584224383036
The PSNR Value is: 20.82098331451416
the highest SSIM value is: 20.82098331451416
the epoch is: 5
Loss at iteration 10 : 0.015374275855720043
Loss at iteration 20 : 0.006262441631406546
Loss at iteration 30 : 0.011977729387581348
Loss at iteration 40 : 0.022443007677793503
Loss at iteration 50 : 0.018547113984823227
Loss at iteration 60 : 0.013291284441947937
Loss at iteration 70 : 0.02550230361521244
Loss at iteration 80 : 0.009649422951042652
Loss at iteration 90 : 0.018050599843263626
Loss at iteration 100 : 0.011299563571810722
Loss at iteration 110 : 0.016477061435580254
Loss at iteration 120 : 0.010135088115930557
Loss at iteration 130 : 0.013082344084978104
Loss at iteration 140 : 0.011570567265152931
Loss at iteration 150 : 0.007453700993210077
Loss at iteration 160 : 0.012383576482534409
Loss at iteration 170 : 0.009938457049429417
Loss at iteration 180 : 0.020599782466888428
Loss at iteration 190 : 0.006134094670414925
Loss at iteration 200 : 0.015197930857539177
Loss at iteration 210 : 0.014097749255597591
Loss at iteration 220 : 0.024328626692295074
Loss at iteration 230 : 0.016602423042058945
Loss at iteration 240 : 0.013871434144675732
Loss at iteration 250 : 0.016742555424571037
Loss at iteration 260 : 0.026459354907274246
Loss at iteration 270 : 0.008906617760658264
Loss at iteration 280 : 0.016125349327921867
Loss at iteration 290 : 0.025186650454998016
Loss at iteration 300 : 0.015279022045433521
Loss at iteration 310 : 0.006750570610165596
Loss at iteration 320 : 0.021038148552179337
Loss at iteration 330 : 0.019276803359389305
Loss at iteration 340 : 0.0051611983217298985
Loss at iteration 350 : 0.008108274079859257
Loss at iteration 360 : 0.03073582425713539
Loss at iteration 370 : 0.012948963791131973
Loss at iteration 380 : 0.01379675604403019
Loss at iteration 390 : 0.02743973210453987
Loss at iteration 400 : 0.003616905538365245
Loss at iteration 410 : 0.021142173558473587
Loss at iteration 420 : 0.012316752225160599
Loss at iteration 430 : 0.009378752671182156
Loss at iteration 440 : 0.02083679661154747
Loss at iteration 450 : 0.02431545779109001
Loss at iteration 460 : 0.012360746040940285
Loss at iteration 470 : 0.012274932116270065
Loss at iteration 480 : 0.008108734153211117
Loss at iteration 490 : 0.018742358312010765
Loss at iteration 500 : 0.0460612028837204
Loss at iteration 510 : 0.017438292503356934
Loss at iteration 520 : 0.012205475941300392
Loss at iteration 530 : 0.011488230898976326
Loss at iteration 540 : 0.005436832085251808
Loss at iteration 550 : 0.01636931486427784
Loss at iteration 560 : 0.012994738295674324
Loss at iteration 570 : 0.01791219413280487
Loss at iteration 580 : 0.014515512622892857
Loss at iteration 590 : 0.020454786717891693
Loss at iteration 600 : 0.0114203542470932
Loss at iteration 610 : 0.010761789046227932
Loss at iteration 620 : 0.015028764493763447
Loss at iteration 630 : 0.013399842195212841
Loss at iteration 640 : 0.015263245441019535
Loss at iteration 650 : 0.014563892967998981
Loss at iteration 660 : 0.018547767773270607
Loss at iteration 670 : 0.01531863771378994
Loss at iteration 680 : 0.009478462859988213
Loss at iteration 690 : 0.02222137525677681
Loss at iteration 700 : 0.008081518113613129
Loss at iteration 710 : 0.017847662791609764
Loss at iteration 720 : 0.014211084693670273
Loss at iteration 730 : 0.019227029755711555
Loss at iteration 740 : 0.0152616947889328
Loss at iteration 750 : 0.012232313863933086
Loss at iteration 760 : 0.010177765972912312
Loss at iteration 770 : 0.01112582441419363
Loss at iteration 780 : 0.013699134811758995
Loss at iteration 790 : 0.030953405424952507
Loss at iteration 800 : 0.021650493144989014
Loss at iteration 810 : 0.017219727858901024
Loss at iteration 820 : 0.012870426289737225
Loss at iteration 830 : 0.01076545286923647
Loss at iteration 840 : 0.009406190365552902
Loss at iteration 850 : 0.017628267407417297
Loss at iteration 860 : 0.009069256484508514
Loss at iteration 870 : 0.01317949965596199
Loss at iteration 880 : 0.017901141196489334
Loss at iteration 890 : 0.017824068665504456
Loss at iteration 900 : 0.012285900302231312
Loss at iteration 910 : 0.008752400055527687
Loss at iteration 920 : 0.018118277192115784
Loss at iteration 930 : 0.01975889876484871
Loss at iteration 940 : 0.009536830708384514
Loss at iteration 950 : 0.012904128059744835
Loss at iteration 960 : 0.021778536960482597
Loss at iteration 970 : 0.01532481424510479
Loss at iteration 980 : 0.022901849821209908
Loss at iteration 990 : 0.009680106304585934
Loss at iteration 1000 : 0.007816284894943237
Loss at iteration 1010 : 0.010248217731714249
Loss at iteration 1020 : 0.01286022923886776
Loss at iteration 1030 : 0.015137698501348495
Loss at iteration 1040 : 0.012969565577805042
Loss at iteration 1050 : 0.018133200705051422
Loss at iteration 1060 : 0.01803448610007763
Loss at iteration 1070 : 0.01940508559346199
Loss at iteration 1080 : 0.011175436899065971
Loss at iteration 1090 : 0.01731221191585064
Loss at iteration 1100 : 0.029126673936843872
Loss at iteration 1110 : 0.01290500070899725
Loss at iteration 1120 : 0.014088539406657219
Loss at iteration 1130 : 0.01488279365003109
Loss at iteration 1140 : 0.01220225915312767
Loss at iteration 1150 : 0.017597507685422897
Loss at iteration 1160 : 0.012051205150783062
Loss at iteration 1170 : 0.014674191363155842
Loss at iteration 1180 : 0.012519484385848045
Loss at iteration 1190 : 0.014775039628148079
Loss at iteration 1200 : 0.015921633690595627
Loss at iteration 1210 : 0.024899521842598915
Loss at iteration 1220 : 0.01619717851281166
Loss at iteration 1230 : 0.010618839412927628
Loss at iteration 1240 : 0.014959150925278664
Loss at iteration 1250 : 0.01528225652873516
Loss at iteration 1260 : 0.0030844982247799635
Loss at iteration 1270 : 0.01225152425467968
Loss at iteration 1280 : 0.01853066310286522
Loss at iteration 1290 : 0.015901897102594376
Loss at iteration 1300 : 0.01714286208152771
Loss at iteration 1310 : 0.012528400868177414
Loss at iteration 1320 : 0.014637824147939682
Loss at iteration 1330 : 0.050224997103214264
Loss at iteration 1340 : 0.011566312983632088
Loss at iteration 1350 : 0.013635958544909954
Loss at iteration 1360 : 0.013782935217022896
Loss at iteration 1370 : 0.02389528974890709
Loss at iteration 1380 : 0.011698732152581215
Loss at iteration 1390 : 0.0123763307929039
Loss at iteration 1400 : 0.012671126052737236
Loss at iteration 1410 : 0.01637265644967556
Loss at iteration 1420 : 0.033146169036626816
Loss at iteration 1430 : 0.01169820036739111
Loss at iteration 1440 : 0.014282077550888062
Loss at iteration 1450 : 0.011165836825966835
Loss at iteration 1460 : 0.01359385997056961
Loss at iteration 1470 : 0.03666070103645325
Loss at iteration 1480 : 0.01389181800186634
Loss at iteration 1490 : 0.024877116084098816
Loss at iteration 1500 : 0.02214386686682701
Loss at iteration 1510 : 0.016912508755922318
Loss at iteration 1520 : 0.015256773680448532
Loss at iteration 1530 : 0.017747361212968826
Loss at iteration 1540 : 0.011973457410931587
Loss at iteration 1550 : 0.029490720480680466
Loss at iteration 1560 : 0.01318618468940258
Loss at iteration 1570 : 0.0077165463007986546
Loss at iteration 1580 : 0.007091775070875883
Loss at iteration 1590 : 0.02033907175064087
Loss at iteration 1600 : 0.01605512946844101
Loss at iteration 1610 : 0.017667870968580246
Loss at iteration 1620 : 0.010294884443283081
Loss at iteration 1630 : 0.012131654657423496
Loss at iteration 1640 : 0.010752683505415916
Loss at iteration 1650 : 0.025728020817041397
Loss at iteration 1660 : 0.012449359521269798
Loss at iteration 1670 : 0.016490144655108452
Loss at iteration 1680 : 0.011164533905684948
Loss at iteration 1690 : 0.012442385777831078
Loss at iteration 1700 : 0.010603589005768299
Loss at iteration 1710 : 0.007708030752837658
Loss at iteration 1720 : 0.012383787892758846
Loss at iteration 1730 : 0.02252725325524807
Loss at iteration 1740 : 0.015656495466828346
Loss at iteration 1750 : 0.02680853195488453
Loss at iteration 1760 : 0.012539669871330261
Loss at iteration 1770 : 0.012044494040310383
Loss at iteration 1780 : 0.02542988955974579
Loss at iteration 1790 : 0.017361082136631012
Loss at iteration 1800 : 0.012813166715204716
Loss at iteration 1810 : 0.015331393107771873
Loss at iteration 1820 : 0.007281259633600712
Loss at iteration 1830 : 0.008575075305998325
Loss at iteration 1840 : 0.01591510884463787
Loss at iteration 1850 : 0.008692331612110138
Loss at iteration 1860 : 0.015361334197223186
Loss at iteration 1870 : 0.011301979422569275
Loss at iteration 1880 : 0.012234983965754509
Loss at iteration 1890 : 0.015986595302820206
Loss at iteration 1900 : 0.02394726872444153
Loss at iteration 1910 : 0.04052169248461723
Loss at iteration 1920 : 0.005783943925052881
Loss at iteration 1930 : 0.009618330746889114
Loss at iteration 1940 : 0.01981387287378311
Loss at iteration 1950 : 0.007361588068306446
Loss at iteration 1960 : 0.04100818932056427
Loss at iteration 1970 : 0.007433627266436815
Loss at iteration 1980 : 0.014602640643715858
Loss at iteration 1990 : 0.022515803575515747
Loss at iteration 2000 : 0.020643914118409157
Loss at iteration 2010 : 0.008388595655560493
Loss at iteration 2020 : 0.023746982216835022
Loss at iteration 2030 : 0.00952029787003994
Loss at iteration 2040 : 0.007581451442092657
Loss at iteration 2050 : 0.014721694402396679
Loss at iteration 2060 : 0.011390024796128273
Loss at iteration 2070 : 0.016253991052508354
Loss at iteration 2080 : 0.008142807520925999
Loss at iteration 2090 : 0.006559030618518591
Loss at iteration 2100 : 0.010838726535439491
Loss at iteration 2110 : 0.018292207270860672
Loss at iteration 2120 : 0.018809016793966293
Loss at iteration 2130 : 0.006452095694839954
Loss at iteration 2140 : 0.017000647261738777
Loss at iteration 2150 : 0.025787821039557457
Loss at iteration 2160 : 0.012240136042237282
Loss at iteration 2170 : 0.019495384767651558
Loss at iteration 2180 : 0.007919557392597198
Loss at iteration 2190 : 0.010441698133945465
Loss at iteration 2200 : 0.00731255766004324
Loss at iteration 2210 : 0.023169854655861855
Loss at iteration 2220 : 0.019555039703845978
Loss at iteration 2230 : 0.01398924645036459
Loss at iteration 2240 : 0.012615094892680645
Loss at iteration 2250 : 0.007732599042356014
Loss at iteration 2260 : 0.022926634177565575
Loss at iteration 2270 : 0.01687674969434738
Loss at iteration 2280 : 0.013255612924695015
Loss at iteration 2290 : 0.022201677784323692
Loss at iteration 2300 : 0.006612942088395357
Loss at iteration 2310 : 0.011442095041275024
Loss at iteration 2320 : 0.02505427598953247
Loss at iteration 2330 : 0.01239120401442051
Loss at iteration 2340 : 0.008946425281465054
Loss at iteration 2350 : 0.013806897215545177
Loss at iteration 2360 : 0.008809997700154781
Loss at iteration 2370 : 0.009749369695782661
Loss at iteration 2380 : 0.010355643928050995
Loss at iteration 2390 : 0.022345051169395447
Loss at iteration 2400 : 0.0185367614030838
Loss at iteration 2410 : 0.018767034634947777
Loss at iteration 2420 : 0.010835845023393631
The SSIM Value is: 0.8242339968681336
The PSNR Value is: 21.036349487304687
the highest SSIM value is: 21.036349487304687
the epoch is: 6
Loss at iteration 10 : 0.008670353330671787
Loss at iteration 20 : 0.01498202420771122
Loss at iteration 30 : 0.013814348727464676
Loss at iteration 40 : 0.00808834470808506
Loss at iteration 50 : 0.012898435816168785
Loss at iteration 60 : 0.0142392348498106
Loss at iteration 70 : 0.01070464588701725
Loss at iteration 80 : 0.009291209280490875
Loss at iteration 90 : 0.021934838965535164
Loss at iteration 100 : 0.006705988198518753
Loss at iteration 110 : 0.011384794488549232
Loss at iteration 120 : 0.015073554590344429
Loss at iteration 130 : 0.012937447987496853
Loss at iteration 140 : 0.008467291481792927
Loss at iteration 150 : 0.021078556776046753
Loss at iteration 160 : 0.015838302671909332
Loss at iteration 170 : 0.02248823083937168
Loss at iteration 180 : 0.015526295639574528
Loss at iteration 190 : 0.008912114426493645
Loss at iteration 200 : 0.006929417140781879
Loss at iteration 210 : 0.018842067569494247
Loss at iteration 220 : 0.01662314310669899
Loss at iteration 230 : 0.017373476177453995
Loss at iteration 240 : 0.01918048784136772
Loss at iteration 250 : 0.016918007284402847
Loss at iteration 260 : 0.015134341083467007
Loss at iteration 270 : 0.03983866050839424
Loss at iteration 280 : 0.010212174616754055
Loss at iteration 290 : 0.014601120725274086
Loss at iteration 300 : 0.01195462979376316
Loss at iteration 310 : 0.00708555756136775
Loss at iteration 320 : 0.011570921167731285
Loss at iteration 330 : 0.013136865571141243
Loss at iteration 340 : 0.016395840793848038
Loss at iteration 350 : 0.01753954589366913
Loss at iteration 360 : 0.009937330149114132
Loss at iteration 370 : 0.023412976413965225
Loss at iteration 380 : 0.01110462099313736
Loss at iteration 390 : 0.01044665277004242
Loss at iteration 400 : 0.017570363357663155
Loss at iteration 410 : 0.016359250992536545
Loss at iteration 420 : 0.01628141850233078
Loss at iteration 430 : 0.007047166116535664
Loss at iteration 440 : 0.01730714552104473
Loss at iteration 450 : 0.007118550594896078
Loss at iteration 460 : 0.011070400476455688
Loss at iteration 470 : 0.0140340905636549
Loss at iteration 480 : 0.011956763453781605
Loss at iteration 490 : 0.009190788492560387
Loss at iteration 500 : 0.004982582293450832
Loss at iteration 510 : 0.013523897156119347
Loss at iteration 520 : 0.013325373642146587
Loss at iteration 530 : 0.010859311558306217
Loss at iteration 540 : 0.009299874305725098
Loss at iteration 550 : 0.01985912397503853
Loss at iteration 560 : 0.013169975019991398
Loss at iteration 570 : 0.007991882972419262
Loss at iteration 580 : 0.017927855253219604
Loss at iteration 590 : 0.01077315304428339
Loss at iteration 600 : 0.02043222263455391
Loss at iteration 610 : 0.011387711390852928
Loss at iteration 620 : 0.011279263533651829
Loss at iteration 630 : 0.01308165118098259
Loss at iteration 640 : 0.01619257964193821
Loss at iteration 650 : 0.014354640617966652
Loss at iteration 660 : 0.018114829435944557
Loss at iteration 670 : 0.011604412458837032
Loss at iteration 680 : 0.025794245302677155
Loss at iteration 690 : 0.012087665498256683
Loss at iteration 700 : 0.012524021789431572
Loss at iteration 710 : 0.019998637959361076
Loss at iteration 720 : 0.012403473258018494
Loss at iteration 730 : 0.01646173745393753
Loss at iteration 740 : 0.01605280488729477
Loss at iteration 750 : 0.020256876945495605
Loss at iteration 760 : 0.014588304795324802
Loss at iteration 770 : 0.031479671597480774
Loss at iteration 780 : 0.014940079301595688
Loss at iteration 790 : 0.011120311915874481
Loss at iteration 800 : 0.01797010749578476
Loss at iteration 810 : 0.022499309852719307
Loss at iteration 820 : 0.018619846552610397
Loss at iteration 830 : 0.02008245512843132
Loss at iteration 840 : 0.015113644301891327
Loss at iteration 850 : 0.013817815110087395
Loss at iteration 860 : 0.015425793826580048
Loss at iteration 870 : 0.013051971793174744
Loss at iteration 880 : 0.009971218183636665
Loss at iteration 890 : 0.022455761209130287
Loss at iteration 900 : 0.01503852941095829
Loss at iteration 910 : 0.006401135586202145
Loss at iteration 920 : 0.010309259407222271
Loss at iteration 930 : 0.00937093049287796
Loss at iteration 940 : 0.015374395065009594
Loss at iteration 950 : 0.020918384194374084
Loss at iteration 960 : 0.017788546159863472
Loss at iteration 970 : 0.012906115502119064
Loss at iteration 980 : 0.012334784492850304
Loss at iteration 990 : 0.011402634903788567
Loss at iteration 1000 : 0.006892643868923187
Loss at iteration 1010 : 0.027113765478134155
Loss at iteration 1020 : 0.008289040997624397
Loss at iteration 1030 : 0.00895843654870987
Loss at iteration 1040 : 0.006985388230532408
Loss at iteration 1050 : 0.01702050492167473
Loss at iteration 1060 : 0.019247690215706825
Loss at iteration 1070 : 0.02470240741968155
Loss at iteration 1080 : 0.0158938430249691
Loss at iteration 1090 : 0.04689522087574005
Loss at iteration 1100 : 0.02001078985631466
Loss at iteration 1110 : 0.010426316410303116
Loss at iteration 1120 : 0.009527403861284256
Loss at iteration 1130 : 0.008073175325989723
Loss at iteration 1140 : 0.009429559111595154
Loss at iteration 1150 : 0.025863997638225555
Loss at iteration 1160 : 0.014249666593968868
Loss at iteration 1170 : 0.007658575661480427
Loss at iteration 1180 : 0.016600560396909714
Loss at iteration 1190 : 0.008162865415215492
Loss at iteration 1200 : 0.025268496945500374
Loss at iteration 1210 : 0.005444860551506281
Loss at iteration 1220 : 0.010729562491178513
Loss at iteration 1230 : 0.01062775682657957
Loss at iteration 1240 : 0.028039876371622086
Loss at iteration 1250 : 0.007615107111632824
Loss at iteration 1260 : 0.014710145071148872
Loss at iteration 1270 : 0.025727013126015663
Loss at iteration 1280 : 0.014865065924823284
Loss at iteration 1290 : 0.01364445872604847
Loss at iteration 1300 : 0.026351716369390488
Loss at iteration 1310 : 0.027593333274126053
Loss at iteration 1320 : 0.021801551803946495
Loss at iteration 1330 : 0.014098229818046093
Loss at iteration 1340 : 0.015359269455075264
Loss at iteration 1350 : 0.013539416715502739
Loss at iteration 1360 : 0.009390490129590034
Loss at iteration 1370 : 0.016218215227127075
Loss at iteration 1380 : 0.018381226807832718
Loss at iteration 1390 : 0.012366196140646935
Loss at iteration 1400 : 0.014958675019443035
Loss at iteration 1410 : 0.01478988490998745
Loss at iteration 1420 : 0.029797937721014023
Loss at iteration 1430 : 0.028378866612911224
Loss at iteration 1440 : 0.012612950056791306
Loss at iteration 1450 : 0.010579404421150684
Loss at iteration 1460 : 0.006258165929466486
Loss at iteration 1470 : 0.009468687698245049
Loss at iteration 1480 : 0.019232196733355522
Loss at iteration 1490 : 0.011180978268384933
Loss at iteration 1500 : 0.0099512729793787
Loss at iteration 1510 : 0.013865824788808823
Loss at iteration 1520 : 0.024261008948087692
Loss at iteration 1530 : 0.005343797616660595
Loss at iteration 1540 : 0.008475401438772678
Loss at iteration 1550 : 0.019937723875045776
Loss at iteration 1560 : 0.018673766404390335
Loss at iteration 1570 : 0.023754658177495003
Loss at iteration 1580 : 0.0178169347345829
Loss at iteration 1590 : 0.01190944667905569
Loss at iteration 1600 : 0.012435238808393478
Loss at iteration 1610 : 0.011674833483994007
Loss at iteration 1620 : 0.02002039924263954
Loss at iteration 1630 : 0.015017873607575893
Loss at iteration 1640 : 0.007656150031834841
Loss at iteration 1650 : 0.01631353050470352
Loss at iteration 1660 : 0.008163707330822945
Loss at iteration 1670 : 0.019988885149359703
Loss at iteration 1680 : 0.014259368181228638
Loss at iteration 1690 : 0.010157366283237934
Loss at iteration 1700 : 0.01274723932147026
Loss at iteration 1710 : 0.017422661185264587
Loss at iteration 1720 : 0.008640041574835777
Loss at iteration 1730 : 0.010419139638543129
Loss at iteration 1740 : 0.020825542509555817
Loss at iteration 1750 : 0.012327427044510841
Loss at iteration 1760 : 0.013795005157589912
Loss at iteration 1770 : 0.012954829260706902
Loss at iteration 1780 : 0.014562281779944897
Loss at iteration 1790 : 0.015999481081962585
Loss at iteration 1800 : 0.009423745796084404
Loss at iteration 1810 : 0.009718455374240875
Loss at iteration 1820 : 0.011898387223482132
Loss at iteration 1830 : 0.018421363085508347
Loss at iteration 1840 : 0.007458625361323357
Loss at iteration 1850 : 0.02770264260470867
Loss at iteration 1860 : 0.01132605317980051
Loss at iteration 1870 : 0.020847495645284653
Loss at iteration 1880 : 0.017619311809539795
Loss at iteration 1890 : 0.025219622999429703
Loss at iteration 1900 : 0.013426698744297028
Loss at iteration 1910 : 0.007457951083779335
Loss at iteration 1920 : 0.016982126981019974
Loss at iteration 1930 : 0.022790037095546722
Loss at iteration 1940 : 0.01248466782271862
Loss at iteration 1950 : 0.01076115109026432
Loss at iteration 1960 : 0.01917814090847969
Loss at iteration 1970 : 0.009744950570166111
Loss at iteration 1980 : 0.010140947066247463
Loss at iteration 1990 : 0.012561609968543053
Loss at iteration 2000 : 0.026977410539984703
Loss at iteration 2010 : 0.01570187881588936
Loss at iteration 2020 : 0.008476784452795982
Loss at iteration 2030 : 0.012587686069309711
Loss at iteration 2040 : 0.010260820388793945
Loss at iteration 2050 : 0.017793796956539154
Loss at iteration 2060 : 0.009780451655387878
Loss at iteration 2070 : 0.018461795523762703
Loss at iteration 2080 : 0.010576823726296425
Loss at iteration 2090 : 0.006167017854750156
Loss at iteration 2100 : 0.015820320695638657
Loss at iteration 2110 : 0.007704466115683317
Loss at iteration 2120 : 0.009317298419773579
Loss at iteration 2130 : 0.007056537549942732
Loss at iteration 2140 : 0.020611820742487907
Loss at iteration 2150 : 0.01410815678536892
Loss at iteration 2160 : 0.015453308820724487
Loss at iteration 2170 : 0.02058074250817299
Loss at iteration 2180 : 0.01605590060353279
Loss at iteration 2190 : 0.009561242535710335
Loss at iteration 2200 : 0.012195920571684837
Loss at iteration 2210 : 0.01628175377845764
Loss at iteration 2220 : 0.012461330741643906
Loss at iteration 2230 : 0.014653542079031467
Loss at iteration 2240 : 0.007927941158413887
Loss at iteration 2250 : 0.03017253428697586
Loss at iteration 2260 : 0.017363611608743668
Loss at iteration 2270 : 0.020348642021417618
Loss at iteration 2280 : 0.021896732971072197
Loss at iteration 2290 : 0.013277585618197918
Loss at iteration 2300 : 0.01336725428700447
Loss at iteration 2310 : 0.011627651751041412
Loss at iteration 2320 : 0.015923162922263145
Loss at iteration 2330 : 0.009896655566990376
Loss at iteration 2340 : 0.01105726882815361
Loss at iteration 2350 : 0.02108125574886799
Loss at iteration 2360 : 0.008637433871626854
Loss at iteration 2370 : 0.009300456382334232
Loss at iteration 2380 : 0.006118100136518478
Loss at iteration 2390 : 0.01535231713205576
Loss at iteration 2400 : 0.020766504108905792
Loss at iteration 2410 : 0.01907600276172161
Loss at iteration 2420 : 0.01337460894137621
The SSIM Value is: 0.8211979150772095
The PSNR Value is: 21.05450159708659
the highest SSIM value is: 21.05450159708659
the epoch is: 7
Loss at iteration 10 : 0.012515516951680183
Loss at iteration 20 : 0.0183503907173872
Loss at iteration 30 : 0.02651786059141159
Loss at iteration 40 : 0.009764861315488815
Loss at iteration 50 : 0.015107601881027222
Loss at iteration 60 : 0.02328205667436123
Loss at iteration 70 : 0.021649934351444244
Loss at iteration 80 : 0.01203952357172966
Loss at iteration 90 : 0.014674373902380466
Loss at iteration 100 : 0.015879226848483086
Loss at iteration 110 : 0.02019435353577137
Loss at iteration 120 : 0.007907950319349766
Loss at iteration 130 : 0.004656321369111538
Loss at iteration 140 : 0.017281904816627502
Loss at iteration 150 : 0.014233581721782684
Loss at iteration 160 : 0.005401024594902992
Loss at iteration 170 : 0.003174901008605957
Loss at iteration 180 : 0.015648366883397102
Loss at iteration 190 : 0.014217821881175041
Loss at iteration 200 : 0.020059820264577866
Loss at iteration 210 : 0.01701047271490097
Loss at iteration 220 : 0.010457802563905716
Loss at iteration 230 : 0.024418657645583153
Loss at iteration 240 : 0.0076074143871665
Loss at iteration 250 : 0.020517999306321144
Loss at iteration 260 : 0.006730931811034679
Loss at iteration 270 : 0.01200452446937561
Loss at iteration 280 : 0.018430491909384727
Loss at iteration 290 : 0.033294931054115295
Loss at iteration 300 : 0.025350511074066162
Loss at iteration 310 : 0.011198565363883972
Loss at iteration 320 : 0.01657770946621895
Loss at iteration 330 : 0.009686446748673916
Loss at iteration 340 : 0.01833353191614151
Loss at iteration 350 : 0.014524653553962708
Loss at iteration 360 : 0.020098339766263962
Loss at iteration 370 : 0.012970378622412682
Loss at iteration 380 : 0.015714867040514946
Loss at iteration 390 : 0.01663118787109852
Loss at iteration 400 : 0.017181620001792908
Loss at iteration 410 : 0.008046790957450867
Loss at iteration 420 : 0.009731653146445751
Loss at iteration 430 : 0.028483834117650986
Loss at iteration 440 : 0.012896816246211529
Loss at iteration 450 : 0.013458938337862492
Loss at iteration 460 : 0.014863998629152775
Loss at iteration 470 : 0.026680031791329384
Loss at iteration 480 : 0.01709376834332943
Loss at iteration 490 : 0.005112222861498594
Loss at iteration 500 : 0.015631353482604027
Loss at iteration 510 : 0.014545576646924019
Loss at iteration 520 : 0.012196081690490246
Loss at iteration 530 : 0.012213088572025299
Loss at iteration 540 : 0.015240912325680256
Loss at iteration 550 : 0.014710746705532074
Loss at iteration 560 : 0.020463332533836365
Loss at iteration 570 : 0.010431895032525063
Loss at iteration 580 : 0.009215587750077248
Loss at iteration 590 : 0.009249914437532425
Loss at iteration 600 : 0.01856495440006256
Loss at iteration 610 : 0.031221257522702217
Loss at iteration 620 : 0.03454183042049408
Loss at iteration 630 : 0.009321080520749092
Loss at iteration 640 : 0.02558790147304535
Loss at iteration 650 : 0.012291986495256424
Loss at iteration 660 : 0.015890099108219147
Loss at iteration 670 : 0.00709292758256197
Loss at iteration 680 : 0.0026455926708877087
Loss at iteration 690 : 0.012967242859303951
Loss at iteration 700 : 0.011752331629395485
Loss at iteration 710 : 0.02856404334306717
Loss at iteration 720 : 0.012123357504606247
Loss at iteration 730 : 0.023695731535553932
Loss at iteration 740 : 0.021928884088993073
Loss at iteration 750 : 0.01430441439151764
Loss at iteration 760 : 0.012854449450969696
Loss at iteration 770 : 0.013797682709991932
Loss at iteration 780 : 0.00968368910253048
Loss at iteration 790 : 0.006601604633033276
Loss at iteration 800 : 0.007524025160819292
Loss at iteration 810 : 0.023327145725488663
Loss at iteration 820 : 0.010402205400168896
Loss at iteration 830 : 0.01589229330420494
Loss at iteration 840 : 0.006999417208135128
Loss at iteration 850 : 0.02338143065571785
Loss at iteration 860 : 0.018655143678188324
Loss at iteration 870 : 0.011133568361401558
Loss at iteration 880 : 0.008627364411950111
Loss at iteration 890 : 0.011668823659420013
Loss at iteration 900 : 0.011747017502784729
Loss at iteration 910 : 0.016291948035359383
Loss at iteration 920 : 0.006730586290359497
Loss at iteration 930 : 0.023734062910079956
Loss at iteration 940 : 0.011739244684576988
Loss at iteration 950 : 0.014904456213116646
Loss at iteration 960 : 0.023587092757225037
Loss at iteration 970 : 0.006738034076988697
Loss at iteration 980 : 0.01640813983976841
Loss at iteration 990 : 0.01633138209581375
Loss at iteration 1000 : 0.013310766778886318
Loss at iteration 1010 : 0.008554595522582531
Loss at iteration 1020 : 0.017820117995142937
Loss at iteration 1030 : 0.00906415656208992
Loss at iteration 1040 : 0.010245101526379585
Loss at iteration 1050 : 0.011593886651098728
Loss at iteration 1060 : 0.012361465021967888
Loss at iteration 1070 : 0.013373062945902348
Loss at iteration 1080 : 0.011186737567186356
Loss at iteration 1090 : 0.011549004353582859
Loss at iteration 1100 : 0.017968185245990753
Loss at iteration 1110 : 0.009340879507362843
Loss at iteration 1120 : 0.013085870072245598
Loss at iteration 1130 : 0.02906707674264908
Loss at iteration 1140 : 0.006693982984870672
Loss at iteration 1150 : 0.00965956598520279
Loss at iteration 1160 : 0.015493592247366905
Loss at iteration 1170 : 0.010125570930540562
Loss at iteration 1180 : 0.009074520319700241
Loss at iteration 1190 : 0.011052176356315613
Loss at iteration 1200 : 0.013566575944423676
Loss at iteration 1210 : 0.011764947324991226
Loss at iteration 1220 : 0.006543976720422506
Loss at iteration 1230 : 0.009886435233056545
Loss at iteration 1240 : 0.02384703978896141
Loss at iteration 1250 : 0.008287345059216022
Loss at iteration 1260 : 0.0097717996686697
Loss at iteration 1270 : 0.005281964782625437
Loss at iteration 1280 : 0.009246955625712872
Loss at iteration 1290 : 0.03244728222489357
Loss at iteration 1300 : 0.013825155794620514
Loss at iteration 1310 : 0.012387193739414215
Loss at iteration 1320 : 0.01445336639881134
Loss at iteration 1330 : 0.024423852562904358
Loss at iteration 1340 : 0.009387756697833538
Loss at iteration 1350 : 0.008552197366952896
Loss at iteration 1360 : 0.020789574831724167
Loss at iteration 1370 : 0.011333184316754341
Loss at iteration 1380 : 0.010473912581801414
Loss at iteration 1390 : 0.021329620853066444
Loss at iteration 1400 : 0.00620619859546423
Loss at iteration 1410 : 0.017898738384246826
Loss at iteration 1420 : 0.00842240173369646
Loss at iteration 1430 : 0.014840377494692802
Loss at iteration 1440 : 0.018417485058307648
Loss at iteration 1450 : 0.01610467955470085
Loss at iteration 1460 : 0.023470714688301086
Loss at iteration 1470 : 0.012648699805140495
Loss at iteration 1480 : 0.015343816950917244
Loss at iteration 1490 : 0.010454080998897552
Loss at iteration 1500 : 0.014392172917723656
Loss at iteration 1510 : 0.010643311776220798
Loss at iteration 1520 : 0.006216146983206272
Loss at iteration 1530 : 0.00842372328042984
Loss at iteration 1540 : 0.009953845292329788
Loss at iteration 1550 : 0.018164003267884254
Loss at iteration 1560 : 0.016640393063426018
Loss at iteration 1570 : 0.015533974394202232
Loss at iteration 1580 : 0.010691422037780285
Loss at iteration 1590 : 0.009941227734088898
Loss at iteration 1600 : 0.022659732028841972
Loss at iteration 1610 : 0.023693161085247993
Loss at iteration 1620 : 0.01254037395119667
Loss at iteration 1630 : 0.01036463025957346
Loss at iteration 1640 : 0.018942484632134438
Loss at iteration 1650 : 0.006529219448566437
Loss at iteration 1660 : 0.016831858083605766
Loss at iteration 1670 : 0.01827853173017502
Loss at iteration 1680 : 0.010976282879710197
Loss at iteration 1690 : 0.011613329872488976
Loss at iteration 1700 : 0.02018784172832966
Loss at iteration 1710 : 0.013631507754325867
Loss at iteration 1720 : 0.014255617745220661
Loss at iteration 1730 : 0.038594238460063934
Loss at iteration 1740 : 0.012621119618415833
Loss at iteration 1750 : 0.015029676258563995
Loss at iteration 1760 : 0.00903873611241579
Loss at iteration 1770 : 0.0109320729970932
Loss at iteration 1780 : 0.014514422044157982
Loss at iteration 1790 : 0.015374885872006416
Loss at iteration 1800 : 0.013669502921402454
Loss at iteration 1810 : 0.014356782659888268
Loss at iteration 1820 : 0.01021871529519558
Loss at iteration 1830 : 0.0075975870713591576
Loss at iteration 1840 : 0.019920486956834793
Loss at iteration 1850 : 0.009380564093589783
Loss at iteration 1860 : 0.013403905555605888
Loss at iteration 1870 : 0.013083698228001595
Loss at iteration 1880 : 0.021862361580133438
Loss at iteration 1890 : 0.023071270436048508
Loss at iteration 1900 : 0.005905195139348507
Loss at iteration 1910 : 0.012224579229950905
Loss at iteration 1920 : 0.022020699456334114
Loss at iteration 1930 : 0.012207316234707832
Loss at iteration 1940 : 0.020692769438028336
Loss at iteration 1950 : 0.013628226704895496
Loss at iteration 1960 : 0.012312185950577259
Loss at iteration 1970 : 0.012244819663465023
Loss at iteration 1980 : 0.01642812043428421
Loss at iteration 1990 : 0.00893925316631794
Loss at iteration 2000 : 0.013184044510126114
Loss at iteration 2010 : 0.013387339189648628
Loss at iteration 2020 : 0.010523732751607895
Loss at iteration 2030 : 0.008966200053691864
Loss at iteration 2040 : 0.011922873556613922
Loss at iteration 2050 : 0.014462186954915524
Loss at iteration 2060 : 0.007580187637358904
Loss at iteration 2070 : 0.018396133556962013
Loss at iteration 2080 : 0.01074197981506586
Loss at iteration 2090 : 0.025844689458608627
Loss at iteration 2100 : 0.02473197504878044
Loss at iteration 2110 : 0.018447866663336754
Loss at iteration 2120 : 0.014649794436991215
Loss at iteration 2130 : 0.013150729238986969
Loss at iteration 2140 : 0.012666712515056133
Loss at iteration 2150 : 0.01610385626554489
Loss at iteration 2160 : 0.015088241547346115
Loss at iteration 2170 : 0.012993413023650646
Loss at iteration 2180 : 0.012867230921983719
Loss at iteration 2190 : 0.012938428670167923
Loss at iteration 2200 : 0.011420945636928082
Loss at iteration 2210 : 0.017097724601626396
Loss at iteration 2220 : 0.01870398223400116
Loss at iteration 2230 : 0.016537519171833992
Loss at iteration 2240 : 0.022241540253162384
Loss at iteration 2250 : 0.012208493426442146
Loss at iteration 2260 : 0.013885660097002983
Loss at iteration 2270 : 0.009357200935482979
Loss at iteration 2280 : 0.01592913642525673
Loss at iteration 2290 : 0.006787102669477463
Loss at iteration 2300 : 0.01182914525270462
Loss at iteration 2310 : 0.011919748038053513
Loss at iteration 2320 : 0.01738722436130047
Loss at iteration 2330 : 0.026373792439699173
Loss at iteration 2340 : 0.0070074982941150665
Loss at iteration 2350 : 0.009497089311480522
Loss at iteration 2360 : 0.015638301149010658
Loss at iteration 2370 : 0.012840215116739273
Loss at iteration 2380 : 0.01590762287378311
Loss at iteration 2390 : 0.015001600608229637
Loss at iteration 2400 : 0.009296922013163567
Loss at iteration 2410 : 0.011517984792590141
Loss at iteration 2420 : 0.011099963448941708
The SSIM Value is: 0.8254542350769043
The PSNR Value is: 20.867355410257975
the epoch is: 8
Loss at iteration 10 : 0.016113633289933205
Loss at iteration 20 : 0.00978770013898611
Loss at iteration 30 : 0.009710049256682396
Loss at iteration 40 : 0.02684512548148632
Loss at iteration 50 : 0.015119672752916813
Loss at iteration 60 : 0.02197135239839554
Loss at iteration 70 : 0.018703509122133255
Loss at iteration 80 : 0.009300957433879375
Loss at iteration 90 : 0.009179672226309776
Loss at iteration 100 : 0.013879899866878986
Loss at iteration 110 : 0.006198122166097164
Loss at iteration 120 : 0.014339002780616283
Loss at iteration 130 : 0.02826276607811451
Loss at iteration 140 : 0.013107860460877419
Loss at iteration 150 : 0.03013746626675129
Loss at iteration 160 : 0.013979827053844929
Loss at iteration 170 : 0.018213726580142975
Loss at iteration 180 : 0.012416768819093704
Loss at iteration 190 : 0.013442128896713257
Loss at iteration 200 : 0.023210231214761734
Loss at iteration 210 : 0.016896340996026993
Loss at iteration 220 : 0.016346406191587448
Loss at iteration 230 : 0.006701568141579628
Loss at iteration 240 : 0.01563924551010132
Loss at iteration 250 : 0.016481520608067513
Loss at iteration 260 : 0.018469203263521194
Loss at iteration 270 : 0.009129615500569344
Loss at iteration 280 : 0.02001591958105564
Loss at iteration 290 : 0.010574392043054104
Loss at iteration 300 : 0.009853851050138474
Loss at iteration 310 : 0.011825671419501305
Loss at iteration 320 : 0.031491898000240326
Loss at iteration 330 : 0.02257934957742691
Loss at iteration 340 : 0.03269039839506149
Loss at iteration 350 : 0.008784348145127296
Loss at iteration 360 : 0.006946857552975416
Loss at iteration 370 : 0.02421077899634838
Loss at iteration 380 : 0.008666527457535267
Loss at iteration 390 : 0.02528756856918335
Loss at iteration 400 : 0.011306256987154484
Loss at iteration 410 : 0.02396474778652191
Loss at iteration 420 : 0.016647987067699432
Loss at iteration 430 : 0.006218005903065205
Loss at iteration 440 : 0.005167577415704727
Loss at iteration 450 : 0.011503798887133598
Loss at iteration 460 : 0.012381399981677532
Loss at iteration 470 : 0.013623084872961044
Loss at iteration 480 : 0.010038943961262703
Loss at iteration 490 : 0.022224050015211105
Loss at iteration 500 : 0.012672875076532364
Loss at iteration 510 : 0.018375929445028305
Loss at iteration 520 : 0.012676041573286057
Loss at iteration 530 : 0.00877732876688242
Loss at iteration 540 : 0.010028778575360775
Loss at iteration 550 : 0.019403057172894478
Loss at iteration 560 : 0.014939517714083195
Loss at iteration 570 : 0.014300848357379436
Loss at iteration 580 : 0.017490342259407043
Loss at iteration 590 : 0.009786407463252544
Loss at iteration 600 : 0.01458568125963211
Loss at iteration 610 : 0.006955655291676521
Loss at iteration 620 : 0.015247644856572151
Loss at iteration 630 : 0.0043630474247038364
Loss at iteration 640 : 0.011020844802260399
Loss at iteration 650 : 0.017823712900280952
Loss at iteration 660 : 0.018994536250829697
Loss at iteration 670 : 0.015122909098863602
Loss at iteration 680 : 0.007728612050414085
Loss at iteration 690 : 0.013802560977637768
Loss at iteration 700 : 0.021160610020160675
Loss at iteration 710 : 0.015201999805867672
Loss at iteration 720 : 0.004563901107758284
Loss at iteration 730 : 0.005938869435340166
Loss at iteration 740 : 0.011973301880061626
Loss at iteration 750 : 0.014567435719072819
Loss at iteration 760 : 0.010400722734630108
Loss at iteration 770 : 0.0050887297838926315
Loss at iteration 780 : 0.005728569813072681
Loss at iteration 790 : 0.012529866769909859
Loss at iteration 800 : 0.0207976046949625
Loss at iteration 810 : 0.01464865542948246
Loss at iteration 820 : 0.019793350249528885
Loss at iteration 830 : 0.018658563494682312
Loss at iteration 840 : 0.011334555223584175
Loss at iteration 850 : 0.01563774049282074
Loss at iteration 860 : 0.010563086718320847
Loss at iteration 870 : 0.009391781874001026
Loss at iteration 880 : 0.004698865581303835
Loss at iteration 890 : 0.010540768504142761
Loss at iteration 900 : 0.008260443806648254
Loss at iteration 910 : 0.009825019165873528
Loss at iteration 920 : 0.008718442171812057
Loss at iteration 930 : 0.016298022121191025
Loss at iteration 940 : 0.009674228727817535
Loss at iteration 950 : 0.015224703587591648
Loss at iteration 960 : 0.013759862631559372
Loss at iteration 970 : 0.01630890741944313
Loss at iteration 980 : 0.016822833567857742
Loss at iteration 990 : 0.020768189802765846
Loss at iteration 1000 : 0.01143219880759716
Loss at iteration 1010 : 0.00895429402589798
Loss at iteration 1020 : 0.019852163270115852
Loss at iteration 1030 : 0.011165034025907516
Loss at iteration 1040 : 0.00873449444770813
Loss at iteration 1050 : 0.020612118765711784
Loss at iteration 1060 : 0.017352387309074402
Loss at iteration 1070 : 0.0191047340631485
Loss at iteration 1080 : 0.01179820578545332
Loss at iteration 1090 : 0.008955943398177624
Loss at iteration 1100 : 0.008028000593185425
Loss at iteration 1110 : 0.008935056626796722
Loss at iteration 1120 : 0.0051490264013409615
Loss at iteration 1130 : 0.012533530592918396
Loss at iteration 1140 : 0.01488968450576067
Loss at iteration 1150 : 0.008714011870324612
Loss at iteration 1160 : 0.010179061442613602
Loss at iteration 1170 : 0.01918695494532585
Loss at iteration 1180 : 0.014758537523448467
Loss at iteration 1190 : 0.009372387081384659
Loss at iteration 1200 : 0.006442710757255554
Loss at iteration 1210 : 0.009156479500234127
Loss at iteration 1220 : 0.008340349420905113
Loss at iteration 1230 : 0.0072526815347373486
Loss at iteration 1240 : 0.014524626545608044
Loss at iteration 1250 : 0.01242893747985363
Loss at iteration 1260 : 0.015123379416763783
Loss at iteration 1270 : 0.021007824689149857
Loss at iteration 1280 : 0.01533760316669941
Loss at iteration 1290 : 0.014237960800528526
Loss at iteration 1300 : 0.010323740541934967
Loss at iteration 1310 : 0.013163309544324875
Loss at iteration 1320 : 0.010349282994866371
Loss at iteration 1330 : 0.008119060657918453
Loss at iteration 1340 : 0.014422222971916199
Loss at iteration 1350 : 0.011125974357128143
Loss at iteration 1360 : 0.01497128140181303
Loss at iteration 1370 : 0.017939001321792603
Loss at iteration 1380 : 0.011192861013114452
Loss at iteration 1390 : 0.033187441527843475
Loss at iteration 1400 : 0.006629220210015774
Loss at iteration 1410 : 0.016966313123703003
Loss at iteration 1420 : 0.013136055320501328
Loss at iteration 1430 : 0.019679013639688492
Loss at iteration 1440 : 0.012859909795224667
Loss at iteration 1450 : 0.013398981653153896
Loss at iteration 1460 : 0.012480370700359344
Loss at iteration 1470 : 0.013237720355391502
Loss at iteration 1480 : 0.011132977902889252
Loss at iteration 1490 : 0.008380540646612644
Loss at iteration 1500 : 0.011029446497559547
Loss at iteration 1510 : 0.008379746228456497
Loss at iteration 1520 : 0.007583444006741047
Loss at iteration 1530 : 0.01183495856821537
Loss at iteration 1540 : 0.03133087605237961
Loss at iteration 1550 : 0.016254551708698273
Loss at iteration 1560 : 0.006708954460918903
Loss at iteration 1570 : 0.013826726004481316
Loss at iteration 1580 : 0.006503986194729805
Loss at iteration 1590 : 0.024580877274274826
Loss at iteration 1600 : 0.016706066206097603
Loss at iteration 1610 : 0.012383838184177876
Loss at iteration 1620 : 0.010652517899870872
Loss at iteration 1630 : 0.009750930592417717
Loss at iteration 1640 : 0.009116694331169128
Loss at iteration 1650 : 0.01124272495508194
Loss at iteration 1660 : 0.008711060509085655
Loss at iteration 1670 : 0.01096213050186634
Loss at iteration 1680 : 0.04396447166800499
Loss at iteration 1690 : 0.010758208110928535
Loss at iteration 1700 : 0.012546262703835964
Loss at iteration 1710 : 0.007170616649091244
Loss at iteration 1720 : 0.013752197846770287
Loss at iteration 1730 : 0.012531972490251064
Loss at iteration 1740 : 0.012100959196686745
Loss at iteration 1750 : 0.010965511202812195
Loss at iteration 1760 : 0.022793235257267952
Loss at iteration 1770 : 0.00730611989274621
Loss at iteration 1780 : 0.017456697300076485
Loss at iteration 1790 : 0.010872296057641506
Loss at iteration 1800 : 0.013565922155976295
Loss at iteration 1810 : 0.014717531390488148
Loss at iteration 1820 : 0.01208929531276226
Loss at iteration 1830 : 0.007660803385078907
Loss at iteration 1840 : 0.013229363597929478
Loss at iteration 1850 : 0.01367195975035429
Loss at iteration 1860 : 0.03760194405913353
Loss at iteration 1870 : 0.009838077239692211
Loss at iteration 1880 : 0.009293753653764725
Loss at iteration 1890 : 0.025318855419754982
Loss at iteration 1900 : 0.017308395355939865
Loss at iteration 1910 : 0.008139325305819511
Loss at iteration 1920 : 0.00523726362735033
Loss at iteration 1930 : 0.015037338249385357
Loss at iteration 1940 : 0.015321909449994564
Loss at iteration 1950 : 0.011337459087371826
Loss at iteration 1960 : 0.010037587024271488
Loss at iteration 1970 : 0.026245873421430588
Loss at iteration 1980 : 0.013108987361192703
Loss at iteration 1990 : 0.01977955549955368
Loss at iteration 2000 : 0.01325712725520134
Loss at iteration 2010 : 0.012479051947593689
Loss at iteration 2020 : 0.006148620042949915
Loss at iteration 2030 : 0.017274118959903717
Loss at iteration 2040 : 0.012980214320123196
Loss at iteration 2050 : 0.019852306693792343
Loss at iteration 2060 : 0.022295337170362473
Loss at iteration 2070 : 0.03135812655091286
Loss at iteration 2080 : 0.014869767241179943
Loss at iteration 2090 : 0.008173227310180664
Loss at iteration 2100 : 0.006735114846378565
Loss at iteration 2110 : 0.015694115310907364
Loss at iteration 2120 : 0.01844288595020771
Loss at iteration 2130 : 0.016559163108468056
Loss at iteration 2140 : 0.010340811684727669
Loss at iteration 2150 : 0.009070182219147682
Loss at iteration 2160 : 0.011105360463261604
Loss at iteration 2170 : 0.01684669218957424
Loss at iteration 2180 : 0.03189734369516373
Loss at iteration 2190 : 0.01792026497423649
Loss at iteration 2200 : 0.012115366756916046
Loss at iteration 2210 : 0.010911425575613976
Loss at iteration 2220 : 0.004685708321630955
Loss at iteration 2230 : 0.02839580550789833
Loss at iteration 2240 : 0.01164862047880888
Loss at iteration 2250 : 0.016623523086309433
Loss at iteration 2260 : 0.027658749371767044
Loss at iteration 2270 : 0.016155192628502846
Loss at iteration 2280 : 0.010089435614645481
Loss at iteration 2290 : 0.004998278804123402
Loss at iteration 2300 : 0.01931154355406761
Loss at iteration 2310 : 0.015583310276269913
Loss at iteration 2320 : 0.013448765501379967
Loss at iteration 2330 : 0.012400858104228973
Loss at iteration 2340 : 0.006224842742085457
Loss at iteration 2350 : 0.016936559230089188
Loss at iteration 2360 : 0.012517060153186321
Loss at iteration 2370 : 0.018128853291273117
Loss at iteration 2380 : 0.021685924381017685
Loss at iteration 2390 : 0.021133217960596085
Loss at iteration 2400 : 0.010290595702826977
Loss at iteration 2410 : 0.02010187692940235
Loss at iteration 2420 : 0.009202984161674976
The SSIM Value is: 0.8316299239794414
The PSNR Value is: 21.0719175974528
the highest SSIM value is: 21.0719175974528
the epoch is: 9
Loss at iteration 10 : 0.024005094543099403
Loss at iteration 20 : 0.010370482690632343
Loss at iteration 30 : 0.011649565771222115
Loss at iteration 40 : 0.012865697965025902
Loss at iteration 50 : 0.018030531704425812
Loss at iteration 60 : 0.015635451301932335
Loss at iteration 70 : 0.014560941606760025
Loss at iteration 80 : 0.01515111792832613
Loss at iteration 90 : 0.004876180551946163
Loss at iteration 100 : 0.010325895622372627
Loss at iteration 110 : 0.009814855642616749
Loss at iteration 120 : 0.007027312181890011
Loss at iteration 130 : 0.0031745019368827343
Loss at iteration 140 : 0.013149593025445938
Loss at iteration 150 : 0.015450341627001762
Loss at iteration 160 : 0.02439849264919758
Loss at iteration 170 : 0.013469446450471878
Loss at iteration 180 : 0.05339210107922554
Loss at iteration 190 : 0.010780214332044125
Loss at iteration 200 : 0.011507507413625717
Loss at iteration 210 : 0.0057967412285506725
Loss at iteration 220 : 0.024759305641055107
Loss at iteration 230 : 0.01331757940351963
Loss at iteration 240 : 0.013992061838507652
Loss at iteration 250 : 0.019309747964143753
Loss at iteration 260 : 0.015582320280373096
Loss at iteration 270 : 0.02489297091960907
Loss at iteration 280 : 0.011358173564076424
Loss at iteration 290 : 0.010656348429620266
Loss at iteration 300 : 0.0061565907672047615
Loss at iteration 310 : 0.022191796451807022
Loss at iteration 320 : 0.012335263192653656
Loss at iteration 330 : 0.01255602017045021
Loss at iteration 340 : 0.015018891543149948
Loss at iteration 350 : 0.00912506878376007
Loss at iteration 360 : 0.009813755750656128
Loss at iteration 370 : 0.01644018292427063
Loss at iteration 380 : 0.009349779225885868
Loss at iteration 390 : 0.00844157487154007
Loss at iteration 400 : 0.013661803677678108
Loss at iteration 410 : 0.01454535685479641
Loss at iteration 420 : 0.011915809474885464
Loss at iteration 430 : 0.013437660411000252
Loss at iteration 440 : 0.016802266240119934
Loss at iteration 450 : 0.025023112073540688
Loss at iteration 460 : 0.012864656746387482
Loss at iteration 470 : 0.01726987026631832
Loss at iteration 480 : 0.013577643781900406
Loss at iteration 490 : 0.010973405092954636
Loss at iteration 500 : 0.013744408264756203
Loss at iteration 510 : 0.012470017187297344
Loss at iteration 520 : 0.013191049918532372
Loss at iteration 530 : 0.017729124054312706
Loss at iteration 540 : 0.017222091555595398
Loss at iteration 550 : 0.011432906612753868
Loss at iteration 560 : 0.015521679073572159
Loss at iteration 570 : 0.01148590911179781
Loss at iteration 580 : 0.01969936117529869
Loss at iteration 590 : 0.01546682883054018
Loss at iteration 600 : 0.02153909206390381
Loss at iteration 610 : 0.013474619016051292
Loss at iteration 620 : 0.019821535795927048
Loss at iteration 630 : 0.01821432076394558
Loss at iteration 640 : 0.011650040745735168
Loss at iteration 650 : 0.012067750096321106
Loss at iteration 660 : 0.01834896393120289
Loss at iteration 670 : 0.014573795720934868
Loss at iteration 680 : 0.016387183219194412
Loss at iteration 690 : 0.009382250718772411
Loss at iteration 700 : 0.02495005540549755
Loss at iteration 710 : 0.014687458984553814
Loss at iteration 720 : 0.01692339777946472
Loss at iteration 730 : 0.011231585405766964
Loss at iteration 740 : 0.02025100588798523
Loss at iteration 750 : 0.009885989129543304
Loss at iteration 760 : 0.012430374510586262
Loss at iteration 770 : 0.010355371981859207
Loss at iteration 780 : 0.0044671581126749516
Loss at iteration 790 : 0.008697686716914177
Loss at iteration 800 : 0.00767115131020546
Loss at iteration 810 : 0.017089417204260826
Loss at iteration 820 : 0.010953657329082489
Loss at iteration 830 : 0.02611619606614113
Loss at iteration 840 : 0.011124538257718086
Loss at iteration 850 : 0.003012837842106819
Loss at iteration 860 : 0.010325824841856956
Loss at iteration 870 : 0.0176971647888422
Loss at iteration 880 : 0.011622678488492966
Loss at iteration 890 : 0.005640136543661356
Loss at iteration 900 : 0.007468370720744133
Loss at iteration 910 : 0.02421277016401291
Loss at iteration 920 : 0.024713940918445587
Loss at iteration 930 : 0.011265261098742485
Loss at iteration 940 : 0.042528342455625534
Loss at iteration 950 : 0.009100724942982197
Loss at iteration 960 : 0.014477946795523167
Loss at iteration 970 : 0.005772308446466923
Loss at iteration 980 : 0.011275270953774452
Loss at iteration 990 : 0.023604741320014
Loss at iteration 1000 : 0.012496489100158215
Loss at iteration 1010 : 0.023231342434883118
Loss at iteration 1020 : 0.022624220699071884
Loss at iteration 1030 : 0.010130004025995731
Loss at iteration 1040 : 0.013322289101779461
Loss at iteration 1050 : 0.014969587326049805
Loss at iteration 1060 : 0.027429843321442604
Loss at iteration 1070 : 0.020984653383493423
Loss at iteration 1080 : 0.008363272063434124
Loss at iteration 1090 : 0.018200000748038292
Loss at iteration 1100 : 0.013011838309466839
Loss at iteration 1110 : 0.022595297545194626
Loss at iteration 1120 : 0.011016305536031723
Loss at iteration 1130 : 0.007966202683746815
Loss at iteration 1140 : 0.023400824517011642
Loss at iteration 1150 : 0.014451536349952221
Loss at iteration 1160 : 0.010191204957664013
Loss at iteration 1170 : 0.012240378186106682
Loss at iteration 1180 : 0.007679007016122341
Loss at iteration 1190 : 0.01709660142660141
Loss at iteration 1200 : 0.007361138239502907
Loss at iteration 1210 : 0.009754626080393791
Loss at iteration 1220 : 0.01647176593542099
Loss at iteration 1230 : 0.017015203833580017
Loss at iteration 1240 : 0.018245074898004532
Loss at iteration 1250 : 0.013333490118384361
Loss at iteration 1260 : 0.011294919066131115
Loss at iteration 1270 : 0.009702109731733799
Loss at iteration 1280 : 0.0063719963654875755
Loss at iteration 1290 : 0.01192002184689045
Loss at iteration 1300 : 0.012696212157607079
Loss at iteration 1310 : 0.011579331010580063
Loss at iteration 1320 : 0.025867177173495293
Loss at iteration 1330 : 0.01905054785311222
Loss at iteration 1340 : 0.005973655730485916
Loss at iteration 1350 : 0.017923790961503983
Loss at iteration 1360 : 0.008798310533165932
Loss at iteration 1370 : 0.008099258877336979
Loss at iteration 1380 : 0.014182085171341896
Loss at iteration 1390 : 0.014844782650470734
Loss at iteration 1400 : 0.014285894110798836
Loss at iteration 1410 : 0.028007570654153824
Loss at iteration 1420 : 0.014142576605081558
Loss at iteration 1430 : 0.007810850627720356
Loss at iteration 1440 : 0.009227683767676353
Loss at iteration 1450 : 0.008027952164411545
Loss at iteration 1460 : 0.02096671611070633
Loss at iteration 1470 : 0.02834884449839592
Loss at iteration 1480 : 0.013394953683018684
Loss at iteration 1490 : 0.02020633965730667
Loss at iteration 1500 : 0.013817604631185532
Loss at iteration 1510 : 0.0064217569306492805
Loss at iteration 1520 : 0.011964457109570503
Loss at iteration 1530 : 0.018045371398329735
Loss at iteration 1540 : 0.023123623803257942
Loss at iteration 1550 : 0.013229801319539547
Loss at iteration 1560 : 0.009151453152298927
Loss at iteration 1570 : 0.00865548849105835
Loss at iteration 1580 : 0.016855427995324135
Loss at iteration 1590 : 0.009376471862196922
Loss at iteration 1600 : 0.009337001480162144
Loss at iteration 1610 : 0.011606656014919281
Loss at iteration 1620 : 0.010156175121665001
Loss at iteration 1630 : 0.008753132075071335
Loss at iteration 1640 : 0.011947467923164368
Loss at iteration 1650 : 0.012912575155496597
Loss at iteration 1660 : 0.014209559187293053
Loss at iteration 1670 : 0.01241016760468483
Loss at iteration 1680 : 0.01577354595065117
Loss at iteration 1690 : 0.032401636242866516
Loss at iteration 1700 : 0.01887013390660286
Loss at iteration 1710 : 0.004861422348767519
Loss at iteration 1720 : 0.003931931219995022
Loss at iteration 1730 : 0.010579759255051613
Loss at iteration 1740 : 0.0064225224778056145
Loss at iteration 1750 : 0.008479582145810127
Loss at iteration 1760 : 0.006368635222315788
Loss at iteration 1770 : 0.022170040756464005
Loss at iteration 1780 : 0.017087634652853012
Loss at iteration 1790 : 0.007701602764427662
Loss at iteration 1800 : 0.013370952568948269
Loss at iteration 1810 : 0.014270714484155178
Loss at iteration 1820 : 0.017153246328234673
Loss at iteration 1830 : 0.013567525893449783
Loss at iteration 1840 : 0.03001578524708748
Loss at iteration 1850 : 0.016244124621152878
Loss at iteration 1860 : 0.015818512067198753
Loss at iteration 1870 : 0.02166370302438736
Loss at iteration 1880 : 0.011647116392850876
Loss at iteration 1890 : 0.015303951688110828
Loss at iteration 1900 : 0.014794331975281239
Loss at iteration 1910 : 0.012887049466371536
Loss at iteration 1920 : 0.011984776705503464
Loss at iteration 1930 : 0.014774283394217491
Loss at iteration 1940 : 0.024232730269432068
Loss at iteration 1950 : 0.01661912351846695
Loss at iteration 1960 : 0.007374326698482037
Loss at iteration 1970 : 0.010149797424674034
Loss at iteration 1980 : 0.005337233655154705
Loss at iteration 1990 : 0.010271862149238586
Loss at iteration 2000 : 0.00680210767313838
Loss at iteration 2010 : 0.0276498980820179
Loss at iteration 2020 : 0.01352553628385067
Loss at iteration 2030 : 0.010916165076196194
Loss at iteration 2040 : 0.016665872186422348
Loss at iteration 2050 : 0.009233184158802032
Loss at iteration 2060 : 0.018663696944713593
Loss at iteration 2070 : 0.016281168907880783
Loss at iteration 2080 : 0.00751044787466526
Loss at iteration 2090 : 0.010566476732492447
Loss at iteration 2100 : 0.01458875834941864
Loss at iteration 2110 : 0.021171078085899353
Loss at iteration 2120 : 0.02481738105416298
Loss at iteration 2130 : 0.023119378834962845
Loss at iteration 2140 : 0.019679725170135498
Loss at iteration 2150 : 0.013101065531373024
Loss at iteration 2160 : 0.023657072335481644
Loss at iteration 2170 : 0.007904032245278358
Loss at iteration 2180 : 0.00765654444694519
Loss at iteration 2190 : 0.007072728127241135
Loss at iteration 2200 : 0.007884003221988678
Loss at iteration 2210 : 0.05162874609231949
Loss at iteration 2220 : 0.009968689642846584
Loss at iteration 2230 : 0.019939858466386795
Loss at iteration 2240 : 0.007382948882877827
Loss at iteration 2250 : 0.007909568026661873
Loss at iteration 2260 : 0.008520598523318768
Loss at iteration 2270 : 0.014328321442008018
Loss at iteration 2280 : 0.010158620774745941
Loss at iteration 2290 : 0.015239600092172623
Loss at iteration 2300 : 0.011217474937438965
Loss at iteration 2310 : 0.01783105917274952
Loss at iteration 2320 : 0.008628605864942074
Loss at iteration 2330 : 0.0164964497089386
Loss at iteration 2340 : 0.007406200282275677
Loss at iteration 2350 : 0.024082593619823456
Loss at iteration 2360 : 0.011056074872612953
Loss at iteration 2370 : 0.007020334713160992
Loss at iteration 2380 : 0.01345804426819086
Loss at iteration 2390 : 0.024598054587841034
Loss at iteration 2400 : 0.008820789866149426
Loss at iteration 2410 : 0.008544839918613434
Loss at iteration 2420 : 0.018476979807019234
The SSIM Value is: 0.8360002716382344
The PSNR Value is: 21.452326583862305
the highest SSIM value is: 21.452326583862305
the epoch is: 10
Loss at iteration 10 : 0.007063047029078007
Loss at iteration 20 : 0.01105479709804058
Loss at iteration 30 : 0.007096703629940748
Loss at iteration 40 : 0.01708197221159935
Loss at iteration 50 : 0.00809447281062603
Loss at iteration 60 : 0.0068069458939135075
Loss at iteration 70 : 0.010776244103908539
Loss at iteration 80 : 0.020213574171066284
Loss at iteration 90 : 0.03118084743618965
Loss at iteration 100 : 0.027697190642356873
Loss at iteration 110 : 0.005719820037484169
Loss at iteration 120 : 0.027638383209705353
Loss at iteration 130 : 0.00840710662305355
Loss at iteration 140 : 0.023312930017709732
Loss at iteration 150 : 0.00872998870909214
Loss at iteration 160 : 0.014673334546387196
Loss at iteration 170 : 0.018945541232824326
Loss at iteration 180 : 0.011782011017203331
Loss at iteration 190 : 0.020447537302970886
Loss at iteration 200 : 0.02404884621500969
Loss at iteration 210 : 0.008464844897389412
Loss at iteration 220 : 0.01789548248052597
Loss at iteration 230 : 0.018799304962158203
Loss at iteration 240 : 0.017422758042812347
Loss at iteration 250 : 0.011077526956796646
Loss at iteration 260 : 0.010602160356938839
Loss at iteration 270 : 0.017758969217538834
Loss at iteration 280 : 0.015297269448637962
Loss at iteration 290 : 0.007229070644825697
Loss at iteration 300 : 0.021480165421962738
Loss at iteration 310 : 0.0075621651485562325
Loss at iteration 320 : 0.007799346465617418
Loss at iteration 330 : 0.014606831595301628
Loss at iteration 340 : 0.018141580745577812
Loss at iteration 350 : 0.01625954359769821
Loss at iteration 360 : 0.006476985290646553
Loss at iteration 370 : 0.011275455355644226
Loss at iteration 380 : 0.01969268172979355
Loss at iteration 390 : 0.021490661427378654
Loss at iteration 400 : 0.011946732178330421
Loss at iteration 410 : 0.020433437079191208
Loss at iteration 420 : 0.0192115418612957
Loss at iteration 430 : 0.016925673931837082
Loss at iteration 440 : 0.011563332751393318
Loss at iteration 450 : 0.014664893969893456
Loss at iteration 460 : 0.016921158879995346
Loss at iteration 470 : 0.012450517155230045
Loss at iteration 480 : 0.030077233910560608
Loss at iteration 490 : 0.04040884971618652
Loss at iteration 500 : 0.014420745894312859
Loss at iteration 510 : 0.010570078156888485
Loss at iteration 520 : 0.009227165952324867
Loss at iteration 530 : 0.01356889121234417
Loss at iteration 540 : 0.02181212045252323
Loss at iteration 550 : 0.010656296275556087
Loss at iteration 560 : 0.022212855517864227
Loss at iteration 570 : 0.007700910791754723
Loss at iteration 580 : 0.00827073585242033
Loss at iteration 590 : 0.008023541420698166
Loss at iteration 600 : 0.006070998962968588
Loss at iteration 610 : 0.00823955424129963
Loss at iteration 620 : 0.022341500967741013
Loss at iteration 630 : 0.009978802874684334
Loss at iteration 640 : 0.009070276282727718
Loss at iteration 650 : 0.010491716675460339
Loss at iteration 660 : 0.007786384783685207
Loss at iteration 670 : 0.012097405269742012
Loss at iteration 680 : 0.012016951106488705
Loss at iteration 690 : 0.0067995148710906506
Loss at iteration 700 : 0.01207673642784357
Loss at iteration 710 : 0.010709704831242561
Loss at iteration 720 : 0.026625774800777435
Loss at iteration 730 : 0.011835502460598946
Loss at iteration 740 : 0.009993587620556355
Loss at iteration 750 : 0.013649147003889084
Loss at iteration 760 : 0.017586424946784973
Loss at iteration 770 : 0.011668994091451168
Loss at iteration 780 : 0.010581827722489834
Loss at iteration 790 : 0.006627210415899754
Loss at iteration 800 : 0.007469968870282173
Loss at iteration 810 : 0.0077630579471588135
Loss at iteration 820 : 0.015391869470477104
Loss at iteration 830 : 0.016386644914746284
Loss at iteration 840 : 0.008479992859065533
Loss at iteration 850 : 0.01392289623618126
Loss at iteration 860 : 0.021557115018367767
Loss at iteration 870 : 0.014038553461432457
Loss at iteration 880 : 0.00991377979516983
Loss at iteration 890 : 0.013812070712447166
Loss at iteration 900 : 0.00656867865473032
Loss at iteration 910 : 0.007013492751866579
Loss at iteration 920 : 0.013979972340166569
Loss at iteration 930 : 0.009539911523461342
Loss at iteration 940 : 0.021651409566402435
Loss at iteration 950 : 0.0072433375753462315
Loss at iteration 960 : 0.006871079560369253
Loss at iteration 970 : 0.004930400755256414
Loss at iteration 980 : 0.012314017862081528
Loss at iteration 990 : 0.007955698296427727
Loss at iteration 1000 : 0.015316411852836609
Loss at iteration 1010 : 0.020022429525852203
Loss at iteration 1020 : 0.006970637012273073
Loss at iteration 1030 : 0.012965063564479351
Loss at iteration 1040 : 0.00938793458044529
Loss at iteration 1050 : 0.008266132324934006
Loss at iteration 1060 : 0.01575559563934803
Loss at iteration 1070 : 0.011989342048764229
Loss at iteration 1080 : 0.008975185453891754
Loss at iteration 1090 : 0.01734476163983345
Loss at iteration 1100 : 0.012189872562885284
Loss at iteration 1110 : 0.012243609875440598
Loss at iteration 1120 : 0.013701092451810837
Loss at iteration 1130 : 0.014341268688440323
Loss at iteration 1140 : 0.014488480985164642
Loss at iteration 1150 : 0.009108726866543293
Loss at iteration 1160 : 0.012249259278178215
Loss at iteration 1170 : 0.02103942632675171
Loss at iteration 1180 : 0.003237288212403655
Loss at iteration 1190 : 0.02718719094991684
Loss at iteration 1200 : 0.011824561282992363
Loss at iteration 1210 : 0.016697591170668602
Loss at iteration 1220 : 0.007771012373268604
Loss at iteration 1230 : 0.016805093735456467
Loss at iteration 1240 : 0.010189603082835674
Loss at iteration 1250 : 0.012789217755198479
Loss at iteration 1260 : 0.011596454307436943
Loss at iteration 1270 : 0.017170894891023636
Loss at iteration 1280 : 0.0077636754140257835
Loss at iteration 1290 : 0.017988119274377823
Loss at iteration 1300 : 0.014720127917826176
Loss at iteration 1310 : 0.011770350858569145
Loss at iteration 1320 : 0.025469284504652023
Loss at iteration 1330 : 0.01247093640267849
Loss at iteration 1340 : 0.010776021517813206
Loss at iteration 1350 : 0.012246889993548393
Loss at iteration 1360 : 0.010294300504028797
Loss at iteration 1370 : 0.008622772991657257
Loss at iteration 1380 : 0.03021232783794403
Loss at iteration 1390 : 0.02384256199002266
Loss at iteration 1400 : 0.02485567331314087
Loss at iteration 1410 : 0.014681132510304451
Loss at iteration 1420 : 0.013035585172474384
Loss at iteration 1430 : 0.01268630288541317
Loss at iteration 1440 : 0.022334609180688858
Loss at iteration 1450 : 0.01638435572385788
Loss at iteration 1460 : 0.01732775941491127
Loss at iteration 1470 : 0.011564663611352444
Loss at iteration 1480 : 0.015165271237492561
Loss at iteration 1490 : 0.00971389189362526
Loss at iteration 1500 : 0.015035809017717838
Loss at iteration 1510 : 0.008239594288170338
Loss at iteration 1520 : 0.01009382028132677
Loss at iteration 1530 : 0.020115265622735023
Loss at iteration 1540 : 0.012514797039330006
Loss at iteration 1550 : 0.008704543113708496
Loss at iteration 1560 : 0.012409276328980923
Loss at iteration 1570 : 0.02000206708908081
Loss at iteration 1580 : 0.005948666948825121
Loss at iteration 1590 : 0.006639028899371624
Loss at iteration 1600 : 0.022318411618471146
Loss at iteration 1610 : 0.014882354997098446
Loss at iteration 1620 : 0.00872729066759348
Loss at iteration 1630 : 0.00947573408484459
Loss at iteration 1640 : 0.009038276970386505
Loss at iteration 1650 : 0.005941335111856461
Loss at iteration 1660 : 0.019047953188419342
Loss at iteration 1670 : 0.013033417984843254
Loss at iteration 1680 : 0.015445019118487835
Loss at iteration 1690 : 0.01591949723660946
Loss at iteration 1700 : 0.03253721073269844
Loss at iteration 1710 : 0.025498587638139725
Loss at iteration 1720 : 0.009603653103113174
Loss at iteration 1730 : 0.019307080656290054
Loss at iteration 1740 : 0.016232118010520935
Loss at iteration 1750 : 0.00766406487673521
Loss at iteration 1760 : 0.0063639478757977486
Loss at iteration 1770 : 0.02301163226366043
Loss at iteration 1780 : 0.015623518265783787
Loss at iteration 1790 : 0.013872219249606133
Loss at iteration 1800 : 0.019351866096258163
Loss at iteration 1810 : 0.01127332728356123
Loss at iteration 1820 : 0.013005062006413937
Loss at iteration 1830 : 0.009254053235054016
Loss at iteration 1840 : 0.015063686296343803
Loss at iteration 1850 : 0.007273131050169468
Loss at iteration 1860 : 0.011032264679670334
Loss at iteration 1870 : 0.022428682073950768
Loss at iteration 1880 : 0.022555716335773468
Loss at iteration 1890 : 0.018371742218732834
Loss at iteration 1900 : 0.012699661776423454
Loss at iteration 1910 : 0.009629503823816776
Loss at iteration 1920 : 0.01411728747189045
Loss at iteration 1930 : 0.01051171962171793
Loss at iteration 1940 : 0.01030950527638197
Loss at iteration 1950 : 0.014829827472567558
Loss at iteration 1960 : 0.010933710262179375
Loss at iteration 1970 : 0.011989503167569637
Loss at iteration 1980 : 0.007012982852756977
Loss at iteration 1990 : 0.041517119854688644
Loss at iteration 2000 : 0.014153199270367622
Loss at iteration 2010 : 0.009493537247180939
Loss at iteration 2020 : 0.012082052417099476
Loss at iteration 2030 : 0.018019717186689377
Loss at iteration 2040 : 0.014603848569095135
Loss at iteration 2050 : 0.031293835490942
Loss at iteration 2060 : 0.012539893388748169
Loss at iteration 2070 : 0.006636312231421471
Loss at iteration 2080 : 0.01371319591999054
Loss at iteration 2090 : 0.005228065419942141
Loss at iteration 2100 : 0.014078411273658276
Loss at iteration 2110 : 0.008637676015496254
Loss at iteration 2120 : 0.016404487192630768
Loss at iteration 2130 : 0.028641555458307266
Loss at iteration 2140 : 0.006326559465378523
Loss at iteration 2150 : 0.023882057517766953
Loss at iteration 2160 : 0.022568996995687485
Loss at iteration 2170 : 0.013944488018751144
Loss at iteration 2180 : 0.03238394111394882
Loss at iteration 2190 : 0.012160880491137505
Loss at iteration 2200 : 0.018243515864014626
Loss at iteration 2210 : 0.024893885478377342
Loss at iteration 2220 : 0.008982226252555847
Loss at iteration 2230 : 0.014913851395249367
Loss at iteration 2240 : 0.012366745620965958
Loss at iteration 2250 : 0.013046571053564548
Loss at iteration 2260 : 0.015988081693649292
Loss at iteration 2270 : 0.006339739076793194
Loss at iteration 2280 : 0.012910936959087849
Loss at iteration 2290 : 0.009412899613380432
Loss at iteration 2300 : 0.011808843351900578
Loss at iteration 2310 : 0.014109641313552856
Loss at iteration 2320 : 0.006622706539928913
Loss at iteration 2330 : 0.018617525696754456
Loss at iteration 2340 : 0.004719861783087254
Loss at iteration 2350 : 0.009582171216607094
Loss at iteration 2360 : 0.01871533878147602
Loss at iteration 2370 : 0.02639726549386978
Loss at iteration 2380 : 0.011712783016264439
Loss at iteration 2390 : 0.039510585367679596
Loss at iteration 2400 : 0.024983827024698257
Loss at iteration 2410 : 0.012749336659908295
Loss at iteration 2420 : 0.01741722784936428
The SSIM Value is: 0.8280699769655864
The PSNR Value is: 20.82916367848714
the epoch is: 11
Loss at iteration 10 : 0.0140013312920928
Loss at iteration 20 : 0.006041126325726509
Loss at iteration 30 : 0.013831852003932
Loss at iteration 40 : 0.020848235115408897
Loss at iteration 50 : 0.005552578717470169
Loss at iteration 60 : 0.04067637026309967
Loss at iteration 70 : 0.015674641355872154
Loss at iteration 80 : 0.0211426243185997
Loss at iteration 90 : 0.006971464026719332
Loss at iteration 100 : 0.02361762523651123
Loss at iteration 110 : 0.011578218080103397
Loss at iteration 120 : 0.020667951554059982
Loss at iteration 130 : 0.009987499564886093
Loss at iteration 140 : 0.01430128701031208
Loss at iteration 150 : 0.011634830385446548
Loss at iteration 160 : 0.013889867812395096
Loss at iteration 170 : 0.017636898905038834
Loss at iteration 180 : 0.014742127619683743
Loss at iteration 190 : 0.021632280200719833
Loss at iteration 200 : 0.023999281227588654
Loss at iteration 210 : 0.017325066030025482
Loss at iteration 220 : 0.007981940172612667
Loss at iteration 230 : 0.016493456438183784
Loss at iteration 240 : 0.013300428166985512
Loss at iteration 250 : 0.013018066994845867
Loss at iteration 260 : 0.012991888448596
Loss at iteration 270 : 0.01343708485364914
Loss at iteration 280 : 0.010806922800838947
Loss at iteration 290 : 0.010860221460461617
Loss at iteration 300 : 0.013187399134039879
Loss at iteration 310 : 0.01521536149084568
Loss at iteration 320 : 0.007810475770384073
Loss at iteration 330 : 0.029079776257276535
Loss at iteration 340 : 0.015644153580069542
Loss at iteration 350 : 0.014551403000950813
Loss at iteration 360 : 0.03160669654607773
Loss at iteration 370 : 0.010880938731133938
Loss at iteration 380 : 0.009605511091649532
Loss at iteration 390 : 0.0169596578925848
Loss at iteration 400 : 0.004053895361721516
Loss at iteration 410 : 0.024790938943624496
Loss at iteration 420 : 0.011853164061903954
Loss at iteration 430 : 0.009444226510822773
Loss at iteration 440 : 0.014218047261238098
Loss at iteration 450 : 0.00442908750846982
Loss at iteration 460 : 0.007749838754534721
Loss at iteration 470 : 0.023562733083963394
Loss at iteration 480 : 0.010749392211437225
Loss at iteration 490 : 0.011790759861469269
Loss at iteration 500 : 0.010217045433819294
Loss at iteration 510 : 0.017471544444561005
Loss at iteration 520 : 0.011583356186747551
Loss at iteration 530 : 0.018705599009990692
Loss at iteration 540 : 0.007950276136398315
Loss at iteration 550 : 0.0096944160759449
Loss at iteration 560 : 0.013367513194680214
Loss at iteration 570 : 0.019208770245313644
Loss at iteration 580 : 0.012629706412553787
Loss at iteration 590 : 0.011697816662490368
Loss at iteration 600 : 0.016889069229364395
Loss at iteration 610 : 0.013619370758533478
Loss at iteration 620 : 0.010310624726116657
Loss at iteration 630 : 0.013194922357797623
Loss at iteration 640 : 0.0082466509193182
Loss at iteration 650 : 0.007203863933682442
Loss at iteration 660 : 0.014300812035799026
Loss at iteration 670 : 0.018147015944123268
Loss at iteration 680 : 0.022051319479942322
Loss at iteration 690 : 0.029141660779714584
Loss at iteration 700 : 0.022429656237363815
Loss at iteration 710 : 0.011030089110136032
Loss at iteration 720 : 0.020199649035930634
Loss at iteration 730 : 0.023051656782627106
Loss at iteration 740 : 0.008749397471547127
Loss at iteration 750 : 0.009092519991099834
Loss at iteration 760 : 0.026736978441476822
Loss at iteration 770 : 0.017857274040579796
Loss at iteration 780 : 0.005763042718172073
Loss at iteration 790 : 0.011713186278939247
Loss at iteration 800 : 0.008331945165991783
Loss at iteration 810 : 0.012654525227844715
Loss at iteration 820 : 0.013230860233306885
Loss at iteration 830 : 0.01563449203968048
Loss at iteration 840 : 0.015849225223064423
Loss at iteration 850 : 0.02082497626543045
Loss at iteration 860 : 0.01325882039964199
Loss at iteration 870 : 0.005962179973721504
Loss at iteration 880 : 0.022526659071445465
Loss at iteration 890 : 0.0033368163276463747
Loss at iteration 900 : 0.0047107962891459465
Loss at iteration 910 : 0.013147339224815369
Loss at iteration 920 : 0.010525252670049667
Loss at iteration 930 : 0.01952095702290535
Loss at iteration 940 : 0.015038348734378815
Loss at iteration 950 : 0.007269277237355709
Loss at iteration 960 : 0.018461324274539948
Loss at iteration 970 : 0.021405521780252457
Loss at iteration 980 : 0.01980527862906456
Loss at iteration 990 : 0.01182599738240242
Loss at iteration 1000 : 0.014342931099236012
Loss at iteration 1010 : 0.012768225744366646
Loss at iteration 1020 : 0.017376262694597244
Loss at iteration 1030 : 0.025476282462477684
Loss at iteration 1040 : 0.025963792577385902
Loss at iteration 1050 : 0.02074485458433628
Loss at iteration 1060 : 0.017360854893922806
Loss at iteration 1070 : 0.006430656649172306
Loss at iteration 1080 : 0.015186812728643417
Loss at iteration 1090 : 0.014211535453796387
Loss at iteration 1100 : 0.017436042428016663
Loss at iteration 1110 : 0.01080201007425785
Loss at iteration 1120 : 0.024998940527439117
Loss at iteration 1130 : 0.02073127031326294
Loss at iteration 1140 : 0.008094757795333862
Loss at iteration 1150 : 0.018371010199189186
Loss at iteration 1160 : 0.01192538719624281
Loss at iteration 1170 : 0.020329387858510017
Loss at iteration 1180 : 0.0067018489353358746
Loss at iteration 1190 : 0.013041037134826183
Loss at iteration 1200 : 0.009998463094234467
Loss at iteration 1210 : 0.02419954165816307
Loss at iteration 1220 : 0.02495422214269638
Loss at iteration 1230 : 0.016251012682914734
Loss at iteration 1240 : 0.012681771069765091
Loss at iteration 1250 : 0.016123401001095772
Loss at iteration 1260 : 0.020331045612692833
Loss at iteration 1270 : 0.00972388219088316
Loss at iteration 1280 : 0.015269901603460312
Loss at iteration 1290 : 0.01594860851764679
Loss at iteration 1300 : 0.01832960918545723
Loss at iteration 1310 : 0.034002646803855896
Loss at iteration 1320 : 0.019028734415769577
Loss at iteration 1330 : 0.007492154836654663
Loss at iteration 1340 : 0.007453951984643936
Loss at iteration 1350 : 0.011470899917185307
Loss at iteration 1360 : 0.021676678210496902
Loss at iteration 1370 : 0.00881471298635006
Loss at iteration 1380 : 0.007071915548294783
Loss at iteration 1390 : 0.00961577519774437
Loss at iteration 1400 : 0.014090125449001789
Loss at iteration 1410 : 0.013655941933393478
Loss at iteration 1420 : 0.02322608418762684
Loss at iteration 1430 : 0.013463428243994713
Loss at iteration 1440 : 0.008996563032269478
Loss at iteration 1450 : 0.010796655900776386
Loss at iteration 1460 : 0.00839253980666399
Loss at iteration 1470 : 0.015651928260922432
Loss at iteration 1480 : 0.018371814861893654
Loss at iteration 1490 : 0.012049354612827301
Loss at iteration 1500 : 0.014584489166736603
Loss at iteration 1510 : 0.007545080967247486
Loss at iteration 1520 : 0.004794767126441002
Loss at iteration 1530 : 0.022771740332245827
Loss at iteration 1540 : 0.014630713500082493
Loss at iteration 1550 : 0.00802308227866888
Loss at iteration 1560 : 0.009396819397807121
Loss at iteration 1570 : 0.012075390666723251
Loss at iteration 1580 : 0.014011918567121029
Loss at iteration 1590 : 0.012553900480270386
Loss at iteration 1600 : 0.010146452113986015
Loss at iteration 1610 : 0.022994890809059143
Loss at iteration 1620 : 0.011872694827616215
Loss at iteration 1630 : 0.020921560004353523
Loss at iteration 1640 : 0.00887061096727848
Loss at iteration 1650 : 0.014635836705565453
Loss at iteration 1660 : 0.013245107606053352
Loss at iteration 1670 : 0.014940057881176472
Loss at iteration 1680 : 0.006775896996259689
Loss at iteration 1690 : 0.01916658692061901
Loss at iteration 1700 : 0.017232902348041534
Loss at iteration 1710 : 0.01007385179400444
Loss at iteration 1720 : 0.019182655960321426
Loss at iteration 1730 : 0.014943612739443779
Loss at iteration 1740 : 0.00990857370197773
Loss at iteration 1750 : 0.04446696117520332
Loss at iteration 1760 : 0.014946823939681053
Loss at iteration 1770 : 0.015982666984200478
Loss at iteration 1780 : 0.011158986948430538
Loss at iteration 1790 : 0.004460368771106005
Loss at iteration 1800 : 0.018269242718815804
Loss at iteration 1810 : 0.016026649624109268
Loss at iteration 1820 : 0.01192278228700161
Loss at iteration 1830 : 0.013305922038853168
Loss at iteration 1840 : 0.01366533525288105
Loss at iteration 1850 : 0.011692664586007595
Loss at iteration 1860 : 0.015534032136201859
Loss at iteration 1870 : 0.01996311917901039
Loss at iteration 1880 : 0.014112829230725765
Loss at iteration 1890 : 0.018651071935892105
Loss at iteration 1900 : 0.009738078340888023
Loss at iteration 1910 : 0.008059332147240639
Loss at iteration 1920 : 0.01622661016881466
Loss at iteration 1930 : 0.011119757778942585
Loss at iteration 1940 : 0.008686170913279057
Loss at iteration 1950 : 0.012860512360930443
Loss at iteration 1960 : 0.013628916814923286
Loss at iteration 1970 : 0.004303299821913242
Loss at iteration 1980 : 0.016283202916383743
Loss at iteration 1990 : 0.011772545985877514
Loss at iteration 2000 : 0.012013230472803116
Loss at iteration 2010 : 0.018019206821918488
Loss at iteration 2020 : 0.00957227498292923
Loss at iteration 2030 : 0.00982674304395914
Loss at iteration 2040 : 0.014991157688200474
Loss at iteration 2050 : 0.012503084726631641
Loss at iteration 2060 : 0.015705479308962822
Loss at iteration 2070 : 0.01938672736287117
Loss at iteration 2080 : 0.00857786275446415
Loss at iteration 2090 : 0.007809036411345005
Loss at iteration 2100 : 0.008327363058924675
Loss at iteration 2110 : 0.01550920307636261
Loss at iteration 2120 : 0.0069337692111730576
Loss at iteration 2130 : 0.016891134902834892
Loss at iteration 2140 : 0.018059272319078445
Loss at iteration 2150 : 0.01771741360425949
Loss at iteration 2160 : 0.010858729481697083
Loss at iteration 2170 : 0.015501163899898529
Loss at iteration 2180 : 0.015771977603435516
Loss at iteration 2190 : 0.010453721508383751
Loss at iteration 2200 : 0.011021418496966362
Loss at iteration 2210 : 0.010960088111460209
Loss at iteration 2220 : 0.010441303253173828
Loss at iteration 2230 : 0.01627923734486103
Loss at iteration 2240 : 0.028276337310671806
Loss at iteration 2250 : 0.015177730470895767
Loss at iteration 2260 : 0.016807083040475845
Loss at iteration 2270 : 0.016314556822180748
Loss at iteration 2280 : 0.006580546963959932
Loss at iteration 2290 : 0.05375461280345917
Loss at iteration 2300 : 0.011129673570394516
Loss at iteration 2310 : 0.013007815927267075
Loss at iteration 2320 : 0.021002285182476044
Loss at iteration 2330 : 0.018313923850655556
Loss at iteration 2340 : 0.01288303080946207
Loss at iteration 2350 : 0.010760853067040443
Loss at iteration 2360 : 0.014375592581927776
Loss at iteration 2370 : 0.018871530890464783
Loss at iteration 2380 : 0.027756158262491226
Loss at iteration 2390 : 0.015476343221962452
Loss at iteration 2400 : 0.01980086788535118
Loss at iteration 2410 : 0.01690184511244297
Loss at iteration 2420 : 0.015690188854932785
The SSIM Value is: 0.8359211484591166
The PSNR Value is: 21.317293167114258
the epoch is: 12
Loss at iteration 10 : 0.014358829706907272
Loss at iteration 20 : 0.00928855687379837
Loss at iteration 30 : 0.01945425197482109
Loss at iteration 40 : 0.006382423918694258
Loss at iteration 50 : 0.013631181791424751
Loss at iteration 60 : 0.0077275000512599945
Loss at iteration 70 : 0.010913649573922157
Loss at iteration 80 : 0.011023188009858131
Loss at iteration 90 : 0.009278731420636177
Loss at iteration 100 : 0.011067330837249756
Loss at iteration 110 : 0.018660712987184525
Loss at iteration 120 : 0.02133992314338684
Loss at iteration 130 : 0.005753963254392147
Loss at iteration 140 : 0.011488370597362518
Loss at iteration 150 : 0.018381690606474876
Loss at iteration 160 : 0.012484648264944553
Loss at iteration 170 : 0.0165609922260046
Loss at iteration 180 : 0.015251118689775467
Loss at iteration 190 : 0.008890140801668167
Loss at iteration 200 : 0.019378308206796646
Loss at iteration 210 : 0.01856386661529541
Loss at iteration 220 : 0.014537396840751171
Loss at iteration 230 : 0.012284331023693085
Loss at iteration 240 : 0.025777947157621384
Loss at iteration 250 : 0.005084668286144733
Loss at iteration 260 : 0.007906794548034668
Loss at iteration 270 : 0.011933151632547379
Loss at iteration 280 : 0.011336206458508968
Loss at iteration 290 : 0.006969928741455078
Loss at iteration 300 : 0.012401961721479893
Loss at iteration 310 : 0.009816174395382404
Loss at iteration 320 : 0.01239553652703762
Loss at iteration 330 : 0.023876270279288292
Loss at iteration 340 : 0.01693679764866829
Loss at iteration 350 : 0.017981190234422684
Loss at iteration 360 : 0.018471337854862213
Loss at iteration 370 : 0.008100733160972595
Loss at iteration 380 : 0.013694128021597862
Loss at iteration 390 : 0.00873937550932169
Loss at iteration 400 : 0.010762562043964863
Loss at iteration 410 : 0.012052525766193867
Loss at iteration 420 : 0.011635619215667248
Loss at iteration 430 : 0.015397973358631134
Loss at iteration 440 : 0.01211550273001194
Loss at iteration 450 : 0.010494701564311981
Loss at iteration 460 : 0.008231377229094505
Loss at iteration 470 : 0.0122557757422328
Loss at iteration 480 : 0.007049182429909706
Loss at iteration 490 : 0.012897888198494911
Loss at iteration 500 : 0.02560003101825714
Loss at iteration 510 : 0.010987844318151474
Loss at iteration 520 : 0.013352720998227596
Loss at iteration 530 : 0.013768487609922886
Loss at iteration 540 : 0.018942981958389282
Loss at iteration 550 : 0.020018484443426132
Loss at iteration 560 : 0.0196993388235569
Loss at iteration 570 : 0.011148227378726006
Loss at iteration 580 : 0.013588251546025276
Loss at iteration 590 : 0.014391749165952206
Loss at iteration 600 : 0.020037822425365448
Loss at iteration 610 : 0.016164766624569893
Loss at iteration 620 : 0.00944935530424118
Loss at iteration 630 : 0.01432705670595169
Loss at iteration 640 : 0.012204738333821297
Loss at iteration 650 : 0.008305423893034458
Loss at iteration 660 : 0.015506597235798836
Loss at iteration 670 : 0.02388870157301426
Loss at iteration 680 : 0.015641219913959503
Loss at iteration 690 : 0.0073523372411727905
Loss at iteration 700 : 0.009275736287236214
Loss at iteration 710 : 0.006953193806111813
Loss at iteration 720 : 0.010902379639446735
Loss at iteration 730 : 0.00928826816380024
Loss at iteration 740 : 0.008604643866419792
Loss at iteration 750 : 0.021006090566515923
Loss at iteration 760 : 0.012523958459496498
Loss at iteration 770 : 0.01287766732275486
Loss at iteration 780 : 0.010994916781783104
Loss at iteration 790 : 0.008138599805533886
Loss at iteration 800 : 0.008421056903898716
Loss at iteration 810 : 0.01596883125603199
Loss at iteration 820 : 0.006518162786960602
Loss at iteration 830 : 0.01493388507515192
Loss at iteration 840 : 0.015140836127102375
Loss at iteration 850 : 0.007646837271749973
Loss at iteration 860 : 0.023254606872797012
Loss at iteration 870 : 0.011610583402216434
Loss at iteration 880 : 0.007834075950086117
Loss at iteration 890 : 0.020077262073755264
Loss at iteration 900 : 0.015398632735013962
Loss at iteration 910 : 0.019873403012752533
Loss at iteration 920 : 0.022827282547950745
Loss at iteration 930 : 0.01830163039267063
Loss at iteration 940 : 0.008264003321528435
Loss at iteration 950 : 0.006240467075258493
Loss at iteration 960 : 0.015428690239787102
Loss at iteration 970 : 0.027498774230480194
Loss at iteration 980 : 0.013931524939835072
Loss at iteration 990 : 0.018414435908198357
Loss at iteration 1000 : 0.01797429285943508
Loss at iteration 1010 : 0.01589275151491165
Loss at iteration 1020 : 0.013317896053195
Loss at iteration 1030 : 0.01897362247109413
Loss at iteration 1040 : 0.018702536821365356
Loss at iteration 1050 : 0.012530595995485783
Loss at iteration 1060 : 0.015093164518475533
Loss at iteration 1070 : 0.02034555748105049
Loss at iteration 1080 : 0.014121567830443382
Loss at iteration 1090 : 0.021310169249773026
Loss at iteration 1100 : 0.012615821324288845
Loss at iteration 1110 : 0.015493236482143402
Loss at iteration 1120 : 0.009233582764863968
Loss at iteration 1130 : 0.016717176884412766
Loss at iteration 1140 : 0.02220933698117733
Loss at iteration 1150 : 0.01389105524867773
Loss at iteration 1160 : 0.01333482563495636
Loss at iteration 1170 : 0.018728163093328476
Loss at iteration 1180 : 0.007531350012868643
Loss at iteration 1190 : 0.011361870914697647
Loss at iteration 1200 : 0.014461972750723362
Loss at iteration 1210 : 0.008408820256590843
Loss at iteration 1220 : 0.011292952112853527
Loss at iteration 1230 : 0.007182864006608725
Loss at iteration 1240 : 0.022042125463485718
Loss at iteration 1250 : 0.015087216161191463
Loss at iteration 1260 : 0.012853104621171951
Loss at iteration 1270 : 0.021163539960980415
Loss at iteration 1280 : 0.01415180042386055
Loss at iteration 1290 : 0.009207346476614475
Loss at iteration 1300 : 0.005911917891353369
Loss at iteration 1310 : 0.009140917100012302
Loss at iteration 1320 : 0.015863917768001556
Loss at iteration 1330 : 0.010961825028061867
Loss at iteration 1340 : 0.014346259646117687
Loss at iteration 1350 : 0.012477092444896698
Loss at iteration 1360 : 0.01227211020886898
Loss at iteration 1370 : 0.013600091449916363
Loss at iteration 1380 : 0.010997993871569633
Loss at iteration 1390 : 0.029085174202919006
Loss at iteration 1400 : 0.01625899411737919
Loss at iteration 1410 : 0.008836427703499794
Loss at iteration 1420 : 0.029279392212629318
Loss at iteration 1430 : 0.005954163148999214
Loss at iteration 1440 : 0.00831518229097128
Loss at iteration 1450 : 0.0163351409137249
Loss at iteration 1460 : 0.014164148829877377
Loss at iteration 1470 : 0.013605980202555656
Loss at iteration 1480 : 0.021016273647546768
Loss at iteration 1490 : 0.00912968348711729
Loss at iteration 1500 : 0.00494586443528533
Loss at iteration 1510 : 0.010144729167222977
Loss at iteration 1520 : 0.004587855655699968
Loss at iteration 1530 : 0.009265901520848274
Loss at iteration 1540 : 0.0068742139264941216
Loss at iteration 1550 : 0.007165365386754274
Loss at iteration 1560 : 0.013055463321506977
Loss at iteration 1570 : 0.010171445086598396
Loss at iteration 1580 : 0.014092771336436272
Loss at iteration 1590 : 0.008146158419549465
Loss at iteration 1600 : 0.014658666215837002
Loss at iteration 1610 : 0.008987939916551113
Loss at iteration 1620 : 0.007885600440204144
Loss at iteration 1630 : 0.017257079482078552
Loss at iteration 1640 : 0.016096331179142
Loss at iteration 1650 : 0.007733438163995743
Loss at iteration 1660 : 0.012970810756087303
Loss at iteration 1670 : 0.014244943857192993
Loss at iteration 1680 : 0.010742119513452053
Loss at iteration 1690 : 0.011023564264178276
Loss at iteration 1700 : 0.008749590255320072
Loss at iteration 1710 : 0.00791628472507
Loss at iteration 1720 : 0.02802177704870701
Loss at iteration 1730 : 0.013760490342974663
Loss at iteration 1740 : 0.005735656246542931
Loss at iteration 1750 : 0.01163557730615139
Loss at iteration 1760 : 0.017793096601963043
Loss at iteration 1770 : 0.011503230780363083
Loss at iteration 1780 : 0.006312609650194645
Loss at iteration 1790 : 0.00760653056204319
Loss at iteration 1800 : 0.019201263785362244
Loss at iteration 1810 : 0.015012435615062714
Loss at iteration 1820 : 0.005572646856307983
Loss at iteration 1830 : 0.01883687824010849
Loss at iteration 1840 : 0.011146864853799343
Loss at iteration 1850 : 0.012800409458577633
Loss at iteration 1860 : 0.011051254346966743
Loss at iteration 1870 : 0.008812757208943367
Loss at iteration 1880 : 0.015240444801747799
Loss at iteration 1890 : 0.016489475965499878
Loss at iteration 1900 : 0.010216504335403442
Loss at iteration 1910 : 0.00904354639351368
Loss at iteration 1920 : 0.01270360592752695
Loss at iteration 1930 : 0.00837834645062685
Loss at iteration 1940 : 0.012396206147968769
Loss at iteration 1950 : 0.011149494908750057
Loss at iteration 1960 : 0.011309357360005379
Loss at iteration 1970 : 0.012687677517533302
Loss at iteration 1980 : 0.014749309048056602
Loss at iteration 1990 : 0.013207911513745785
Loss at iteration 2000 : 0.009934155270457268
Loss at iteration 2010 : 0.01227393839508295
Loss at iteration 2020 : 0.015188373625278473
Loss at iteration 2030 : 0.008387381210923195
Loss at iteration 2040 : 0.013238414190709591
Loss at iteration 2050 : 0.02028603106737137
Loss at iteration 2060 : 0.02717866748571396
Loss at iteration 2070 : 0.013659419491887093
Loss at iteration 2080 : 0.013788200914859772
Loss at iteration 2090 : 0.02344284951686859
Loss at iteration 2100 : 0.007828719913959503
Loss at iteration 2110 : 0.009462401270866394
Loss at iteration 2120 : 0.0228884294629097
Loss at iteration 2130 : 0.014147894456982613
Loss at iteration 2140 : 0.011086128652095795
Loss at iteration 2150 : 0.006162987090647221
Loss at iteration 2160 : 0.028616726398468018
Loss at iteration 2170 : 0.01309492252767086
Loss at iteration 2180 : 0.019556082785129547
Loss at iteration 2190 : 0.011714024469256401
Loss at iteration 2200 : 0.012364177033305168
Loss at iteration 2210 : 0.01168966107070446
Loss at iteration 2220 : 0.014385707676410675
Loss at iteration 2230 : 0.008728810586035252
Loss at iteration 2240 : 0.014286001212894917
Loss at iteration 2250 : 0.0168768223375082
Loss at iteration 2260 : 0.00878738984465599
Loss at iteration 2270 : 0.0167995635420084
Loss at iteration 2280 : 0.0060768285766243935
Loss at iteration 2290 : 0.009624636732041836
Loss at iteration 2300 : 0.013407247141003609
Loss at iteration 2310 : 0.009109780192375183
Loss at iteration 2320 : 0.011206265538930893
Loss at iteration 2330 : 0.012307981960475445
Loss at iteration 2340 : 0.012744619511067867
Loss at iteration 2350 : 0.015716344118118286
Loss at iteration 2360 : 0.01450472604483366
Loss at iteration 2370 : 0.01637251116335392
Loss at iteration 2380 : 0.015011409297585487
Loss at iteration 2390 : 0.011460656300187111
Loss at iteration 2400 : 0.012302722781896591
Loss at iteration 2410 : 0.012125145643949509
Loss at iteration 2420 : 0.016566459089517593
The SSIM Value is: 0.8396669626235962
The PSNR Value is: 21.865598678588867
the highest SSIM value is: 21.865598678588867
the epoch is: 13
Loss at iteration 10 : 0.011082710698246956
Loss at iteration 20 : 0.012628825381398201
Loss at iteration 30 : 0.018669309094548225
Loss at iteration 40 : 0.009594500064849854
Loss at iteration 50 : 0.007823646068572998
Loss at iteration 60 : 0.004719207063317299
Loss at iteration 70 : 0.00837278924882412
Loss at iteration 80 : 0.017911700531840324
Loss at iteration 90 : 0.013204511255025864
Loss at iteration 100 : 0.01745946705341339
Loss at iteration 110 : 0.008851485326886177
Loss at iteration 120 : 0.032255008816719055
Loss at iteration 130 : 0.01821576990187168
Loss at iteration 140 : 0.02187531255185604
Loss at iteration 150 : 0.026044070720672607
Loss at iteration 160 : 0.015297433361411095
Loss at iteration 170 : 0.024394437670707703
Loss at iteration 180 : 0.012777060270309448
Loss at iteration 190 : 0.01214873231947422
Loss at iteration 200 : 0.004689826630055904
Loss at iteration 210 : 0.016885386779904366
Loss at iteration 220 : 0.015955546870827675
Loss at iteration 230 : 0.02480446919798851
Loss at iteration 240 : 0.031094180420041084
Loss at iteration 250 : 0.005957481451332569
Loss at iteration 260 : 0.007601202931255102
Loss at iteration 270 : 0.015226438641548157
Loss at iteration 280 : 0.014186796732246876
Loss at iteration 290 : 0.01871132291853428
Loss at iteration 300 : 0.007051457185298204
Loss at iteration 310 : 0.01507488451898098
Loss at iteration 320 : 0.011687623336911201
Loss at iteration 330 : 0.016241108998656273
Loss at iteration 340 : 0.022991102188825607
Loss at iteration 350 : 0.018375316634774208
Loss at iteration 360 : 0.01615092344582081
Loss at iteration 370 : 0.0070513272657990456
Loss at iteration 380 : 0.02409151941537857
Loss at iteration 390 : 0.016167379915714264
Loss at iteration 400 : 0.013148201629519463
Loss at iteration 410 : 0.0574030727148056
Loss at iteration 420 : 0.015516500920057297
Loss at iteration 430 : 0.022959087044000626
Loss at iteration 440 : 0.011439272202551365
Loss at iteration 450 : 0.00998965185135603
Loss at iteration 460 : 0.006338464096188545
Loss at iteration 470 : 0.009878764860332012
Loss at iteration 480 : 0.022755466401576996
Loss at iteration 490 : 0.01482736598700285
Loss at iteration 500 : 0.012803185731172562
Loss at iteration 510 : 0.011216232553124428
Loss at iteration 520 : 0.011943120509386063
Loss at iteration 530 : 0.016477851197123528
Loss at iteration 540 : 0.011999957263469696
Loss at iteration 550 : 0.010116319172084332
Loss at iteration 560 : 0.011045966297388077
Loss at iteration 570 : 0.017280275002121925
Loss at iteration 580 : 0.010851247236132622
Loss at iteration 590 : 0.010258379392325878
Loss at iteration 600 : 0.021619364619255066
Loss at iteration 610 : 0.026404593139886856
Loss at iteration 620 : 0.014910219237208366
Loss at iteration 630 : 0.013304985128343105
Loss at iteration 640 : 0.016729988157749176
Loss at iteration 650 : 0.016035499051213264
Loss at iteration 660 : 0.01839538663625717
Loss at iteration 670 : 0.013705850578844547
Loss at iteration 680 : 0.022396106272935867
Loss at iteration 690 : 0.0175238698720932
Loss at iteration 700 : 0.01140767801553011
Loss at iteration 710 : 0.023984983563423157
Loss at iteration 720 : 0.011689363047480583
Loss at iteration 730 : 0.020958103239536285
Loss at iteration 740 : 0.010034509003162384
Loss at iteration 750 : 0.0053034815937280655
Loss at iteration 760 : 0.011921066790819168
Loss at iteration 770 : 0.01222534105181694
Loss at iteration 780 : 0.013644557446241379
Loss at iteration 790 : 0.013242801651358604
Loss at iteration 800 : 0.01653045415878296
Loss at iteration 810 : 0.027006758376955986
Loss at iteration 820 : 0.010092540644109249
Loss at iteration 830 : 0.0045349071733653545
Loss at iteration 840 : 0.012009792029857635
Loss at iteration 850 : 0.00842958688735962
Loss at iteration 860 : 0.009750149212777615
Loss at iteration 870 : 0.013716393150389194
Loss at iteration 880 : 0.019406400620937347
Loss at iteration 890 : 0.00894542969763279
Loss at iteration 900 : 0.011246923357248306
Loss at iteration 910 : 0.01148284412920475
Loss at iteration 920 : 0.014807319268584251
Loss at iteration 930 : 0.0077463481575250626
Loss at iteration 940 : 0.013159717433154583
Loss at iteration 950 : 0.015227727591991425
Loss at iteration 960 : 0.015916738659143448
Loss at iteration 970 : 0.015203166753053665
Loss at iteration 980 : 0.013339377008378506
Loss at iteration 990 : 0.010057972744107246
Loss at iteration 1000 : 0.00800352543592453
Loss at iteration 1010 : 0.012299593538045883
Loss at iteration 1020 : 0.01839466579258442
Loss at iteration 1030 : 0.016252685338258743
Loss at iteration 1040 : 0.010346310213208199
Loss at iteration 1050 : 0.015065690502524376
Loss at iteration 1060 : 0.005591052118688822
Loss at iteration 1070 : 0.013941710814833641
Loss at iteration 1080 : 0.003208326641470194
Loss at iteration 1090 : 0.005930534563958645
Loss at iteration 1100 : 0.009666104800999165
Loss at iteration 1110 : 0.01080336980521679
Loss at iteration 1120 : 0.010115220211446285
Loss at iteration 1130 : 0.009763266891241074
Loss at iteration 1140 : 0.017009299248456955
Loss at iteration 1150 : 0.008655428886413574
Loss at iteration 1160 : 0.006341140251606703
Loss at iteration 1170 : 0.020892901346087456
Loss at iteration 1180 : 0.012677431106567383
Loss at iteration 1190 : 0.010911514051258564
Loss at iteration 1200 : 0.012131045572459698
Loss at iteration 1210 : 0.00869404524564743
Loss at iteration 1220 : 0.012182384729385376
Loss at iteration 1230 : 0.00794979464262724
Loss at iteration 1240 : 0.016114937141537666
Loss at iteration 1250 : 0.03915516287088394
Loss at iteration 1260 : 0.013786276802420616
Loss at iteration 1270 : 0.008336282335221767
Loss at iteration 1280 : 0.018709085881710052
Loss at iteration 1290 : 0.013608354143798351
Loss at iteration 1300 : 0.014762934297323227
Loss at iteration 1310 : 0.012211531400680542
Loss at iteration 1320 : 0.023100150749087334
Loss at iteration 1330 : 0.010994352400302887
Loss at iteration 1340 : 0.022347813472151756
Loss at iteration 1350 : 0.007964620366692543
Loss at iteration 1360 : 0.019569450989365578
Loss at iteration 1370 : 0.02979385107755661
Loss at iteration 1380 : 0.005656689405441284
Loss at iteration 1390 : 0.014216652140021324
Loss at iteration 1400 : 0.004363433923572302
Loss at iteration 1410 : 0.0075791869312524796
Loss at iteration 1420 : 0.009999802336096764
Loss at iteration 1430 : 0.02654964104294777
Loss at iteration 1440 : 0.010130218230187893
Loss at iteration 1450 : 0.023693911731243134
Loss at iteration 1460 : 0.008311006240546703
Loss at iteration 1470 : 0.015230044722557068
Loss at iteration 1480 : 0.006762439385056496
Loss at iteration 1490 : 0.038561657071113586
Loss at iteration 1500 : 0.009274937212467194
Loss at iteration 1510 : 0.005719335749745369
Loss at iteration 1520 : 0.012778566218912601
Loss at iteration 1530 : 0.009176596999168396
Loss at iteration 1540 : 0.016349174082279205
Loss at iteration 1550 : 0.011792406439781189
Loss at iteration 1560 : 0.006760799326002598
Loss at iteration 1570 : 0.011982409283518791
Loss at iteration 1580 : 0.019190862774848938
Loss at iteration 1590 : 0.005207770969718695
Loss at iteration 1600 : 0.008196297101676464
Loss at iteration 1610 : 0.008592244237661362
Loss at iteration 1620 : 0.010009354911744595
Loss at iteration 1630 : 0.01140611432492733
Loss at iteration 1640 : 0.013496987521648407
Loss at iteration 1650 : 0.020095746964216232
Loss at iteration 1660 : 0.014761751517653465
Loss at iteration 1670 : 0.013652308844029903
Loss at iteration 1680 : 0.011077949777245522
Loss at iteration 1690 : 0.008450314402580261
Loss at iteration 1700 : 0.010684113949537277
Loss at iteration 1710 : 0.01351876836270094
Loss at iteration 1720 : 0.009846435859799385
Loss at iteration 1730 : 0.009837462566792965
Loss at iteration 1740 : 0.008519275113940239
Loss at iteration 1750 : 0.017152192071080208
Loss at iteration 1760 : 0.013871373608708382
Loss at iteration 1770 : 0.013401846401393414
Loss at iteration 1780 : 0.008482418954372406
Loss at iteration 1790 : 0.012196792289614677
Loss at iteration 1800 : 0.01607358828186989
Loss at iteration 1810 : 0.012832673266530037
Loss at iteration 1820 : 0.023557893931865692
Loss at iteration 1830 : 0.007275822572410107
Loss at iteration 1840 : 0.016530804336071014
Loss at iteration 1850 : 0.004750595428049564
Loss at iteration 1860 : 0.01207934133708477
Loss at iteration 1870 : 0.010177342221140862
Loss at iteration 1880 : 0.014822766184806824
Loss at iteration 1890 : 0.01571231707930565
Loss at iteration 1900 : 0.015253670513629913
Loss at iteration 1910 : 0.013633430004119873
Loss at iteration 1920 : 0.01347127091139555
Loss at iteration 1930 : 0.02276647463440895
Loss at iteration 1940 : 0.0063026538118720055
Loss at iteration 1950 : 0.023165946826338768
Loss at iteration 1960 : 0.004301819484680891
Loss at iteration 1970 : 0.01756366714835167
Loss at iteration 1980 : 0.014113557524979115
Loss at iteration 1990 : 0.008978120051324368
Loss at iteration 2000 : 0.008215484209358692
Loss at iteration 2010 : 0.0070725795812904835
Loss at iteration 2020 : 0.005273565649986267
Loss at iteration 2030 : 0.022417331114411354
Loss at iteration 2040 : 0.018442289903759956
Loss at iteration 2050 : 0.009688286110758781
Loss at iteration 2060 : 0.024296611547470093
Loss at iteration 2070 : 0.010417863726615906
Loss at iteration 2080 : 0.013930123299360275
Loss at iteration 2090 : 0.004540440626442432
Loss at iteration 2100 : 0.012434801086783409
Loss at iteration 2110 : 0.020609011873602867
Loss at iteration 2120 : 0.01763996109366417
Loss at iteration 2130 : 0.010614282451570034
Loss at iteration 2140 : 0.0038926065899431705
Loss at iteration 2150 : 0.01271386630833149
Loss at iteration 2160 : 0.021251581609249115
Loss at iteration 2170 : 0.024412933737039566
Loss at iteration 2180 : 0.025765426456928253
Loss at iteration 2190 : 0.016373157501220703
Loss at iteration 2200 : 0.00503897201269865
Loss at iteration 2210 : 0.006525235716253519
Loss at iteration 2220 : 0.014331614598631859
Loss at iteration 2230 : 0.013423111289739609
Loss at iteration 2240 : 0.010029183700680733
Loss at iteration 2250 : 0.015075202099978924
Loss at iteration 2260 : 0.01643798127770424
Loss at iteration 2270 : 0.020374026149511337
Loss at iteration 2280 : 0.01850089430809021
Loss at iteration 2290 : 0.008491339161992073
Loss at iteration 2300 : 0.010740993544459343
Loss at iteration 2310 : 0.0061166370287537575
Loss at iteration 2320 : 0.014443849213421345
Loss at iteration 2330 : 0.019266173243522644
Loss at iteration 2340 : 0.010103137232363224
Loss at iteration 2350 : 0.006023540161550045
Loss at iteration 2360 : 0.012950599193572998
Loss at iteration 2370 : 0.0067854044027626514
Loss at iteration 2380 : 0.007438053376972675
Loss at iteration 2390 : 0.014039942063391209
Loss at iteration 2400 : 0.00725101213902235
Loss at iteration 2410 : 0.026510555297136307
Loss at iteration 2420 : 0.008734261617064476
The SSIM Value is: 0.8204984863599142
The PSNR Value is: 19.628279622395834
the epoch is: 14
Loss at iteration 10 : 0.015950968489050865
Loss at iteration 20 : 0.008577847853302956
Loss at iteration 30 : 0.003489557420834899
Loss at iteration 40 : 0.022110771387815475
Loss at iteration 50 : 0.030416013672947884
Loss at iteration 60 : 0.015797287225723267
Loss at iteration 70 : 0.02293325960636139
Loss at iteration 80 : 0.01507987268269062
Loss at iteration 90 : 0.006773075088858604
Loss at iteration 100 : 0.010875551961362362
Loss at iteration 110 : 0.013359527103602886
Loss at iteration 120 : 0.019314685836434364
Loss at iteration 130 : 0.01855827122926712
Loss at iteration 140 : 0.01061791367828846
Loss at iteration 150 : 0.01826876774430275
Loss at iteration 160 : 0.009011387825012207
Loss at iteration 170 : 0.008973509073257446
Loss at iteration 180 : 0.008993225172162056
Loss at iteration 190 : 0.011687332764267921
Loss at iteration 200 : 0.012129135429859161
Loss at iteration 210 : 0.005325150676071644
Loss at iteration 220 : 0.009682080708444118
Loss at iteration 230 : 0.011900338344275951
Loss at iteration 240 : 0.011933345347642899
Loss at iteration 250 : 0.0116225341334939
Loss at iteration 260 : 0.018948255106806755
Loss at iteration 270 : 0.010753035545349121
Loss at iteration 280 : 0.011918018572032452
Loss at iteration 290 : 0.008104308508336544
Loss at iteration 300 : 0.02260316163301468
Loss at iteration 310 : 0.008194358088076115
Loss at iteration 320 : 0.02388792112469673
Loss at iteration 330 : 0.009071527048945427
Loss at iteration 340 : 0.017591889947652817
Loss at iteration 350 : 0.011243547312915325
Loss at iteration 360 : 0.022923873737454414
Loss at iteration 370 : 0.012600167654454708
Loss at iteration 380 : 0.010271485894918442
Loss at iteration 390 : 0.015340952202677727
Loss at iteration 400 : 0.01736963726580143
Loss at iteration 410 : 0.01678105816245079
Loss at iteration 420 : 0.006631173193454742
Loss at iteration 430 : 0.010879112407565117
Loss at iteration 440 : 0.00784653052687645
Loss at iteration 450 : 0.01807059720158577
Loss at iteration 460 : 0.015403226017951965
Loss at iteration 470 : 0.023148715496063232
Loss at iteration 480 : 0.010201526805758476
Loss at iteration 490 : 0.015767108649015427
Loss at iteration 500 : 0.020160865038633347
Loss at iteration 510 : 0.022074120119214058
Loss at iteration 520 : 0.013994118198752403
Loss at iteration 530 : 0.01460446696728468
Loss at iteration 540 : 0.01219801977276802
Loss at iteration 550 : 0.01783290132880211
Loss at iteration 560 : 0.009891190566122532
Loss at iteration 570 : 0.007850361987948418
Loss at iteration 580 : 0.03909054026007652
Loss at iteration 590 : 0.012634359300136566
Loss at iteration 600 : 0.016242455691099167
Loss at iteration 610 : 0.006967708468437195
Loss at iteration 620 : 0.007753838784992695
Loss at iteration 630 : 0.011826127767562866
Loss at iteration 640 : 0.0103781558573246
Loss at iteration 650 : 0.015030288137495518
Loss at iteration 660 : 0.018904078751802444
Loss at iteration 670 : 0.01255264226347208
Loss at iteration 680 : 0.013740946538746357
Loss at iteration 690 : 0.01283767819404602
Loss at iteration 700 : 0.016090737655758858
Loss at iteration 710 : 0.012147443369030952
Loss at iteration 720 : 0.006703777238726616
Loss at iteration 730 : 0.009728970937430859
Loss at iteration 740 : 0.015831129625439644
Loss at iteration 750 : 0.024074554443359375
Loss at iteration 760 : 0.008896879851818085
Loss at iteration 770 : 0.008775779977440834
Loss at iteration 780 : 0.021382668986916542
Loss at iteration 790 : 0.015176870860159397
Loss at iteration 800 : 0.02086964063346386
Loss at iteration 810 : 0.012816956266760826
Loss at iteration 820 : 0.024738680571317673
Loss at iteration 830 : 0.012832717038691044
Loss at iteration 840 : 0.014404814690351486
Loss at iteration 850 : 0.01010146178305149
Loss at iteration 860 : 0.017634358257055283
Loss at iteration 870 : 0.012417618185281754
Loss at iteration 880 : 0.00823916494846344
Loss at iteration 890 : 0.01651272363960743
Loss at iteration 900 : 0.011445166543126106
Loss at iteration 910 : 0.009684852324426174
Loss at iteration 920 : 0.00848095491528511
Loss at iteration 930 : 0.021450232714414597
Loss at iteration 940 : 0.015679925680160522
Loss at iteration 950 : 0.007587740663439035
Loss at iteration 960 : 0.015659991651773453
Loss at iteration 970 : 0.009347226470708847
Loss at iteration 980 : 0.009868821129202843
Loss at iteration 990 : 0.017044764012098312
Loss at iteration 1000 : 0.01479964330792427
Loss at iteration 1010 : 0.008615872822701931
Loss at iteration 1020 : 0.01311691664159298
Loss at iteration 1030 : 0.007928593084216118
Loss at iteration 1040 : 0.007111281622201204
Loss at iteration 1050 : 0.009945905767381191
Loss at iteration 1060 : 0.014569004066288471
Loss at iteration 1070 : 0.006880301050841808
Loss at iteration 1080 : 0.01602431945502758
Loss at iteration 1090 : 0.01566198468208313
Loss at iteration 1100 : 0.028716200962662697
Loss at iteration 1110 : 0.006780641619116068
Loss at iteration 1120 : 0.010383464395999908
Loss at iteration 1130 : 0.00587663147598505
Loss at iteration 1140 : 0.012780526652932167
Loss at iteration 1150 : 0.023861713707447052
Loss at iteration 1160 : 0.008717946708202362
Loss at iteration 1170 : 0.020449580624699593
Loss at iteration 1180 : 0.012504893355071545
Loss at iteration 1190 : 0.011942624114453793
Loss at iteration 1200 : 0.019024819135665894
Loss at iteration 1210 : 0.018868867307901382
Loss at iteration 1220 : 0.016844674944877625
Loss at iteration 1230 : 0.026743505150079727
Loss at iteration 1240 : 0.0150372926145792
Loss at iteration 1250 : 0.008264271542429924
Loss at iteration 1260 : 0.007794232573360205
Loss at iteration 1270 : 0.00912806298583746
Loss at iteration 1280 : 0.004908635281026363
Loss at iteration 1290 : 0.014610947109758854
Loss at iteration 1300 : 0.010192055255174637
Loss at iteration 1310 : 0.016411611810326576
Loss at iteration 1320 : 0.01866123080253601
Loss at iteration 1330 : 0.01848551630973816
Loss at iteration 1340 : 0.012132849544286728
Loss at iteration 1350 : 0.006476260256022215
Loss at iteration 1360 : 0.009005092084407806
Loss at iteration 1370 : 0.02497844398021698
Loss at iteration 1380 : 0.014418819919228554
Loss at iteration 1390 : 0.013054960407316685
Loss at iteration 1400 : 0.011027084663510323
Loss at iteration 1410 : 0.010916456580162048
Loss at iteration 1420 : 0.007880771532654762
Loss at iteration 1430 : 0.008980495855212212
Loss at iteration 1440 : 0.02147243544459343
Loss at iteration 1450 : 0.010067211464047432
Loss at iteration 1460 : 0.009008222259581089
Loss at iteration 1470 : 0.0076571255922317505
Loss at iteration 1480 : 0.009163068607449532
Loss at iteration 1490 : 0.022175682708621025
Loss at iteration 1500 : 0.009957823902368546
Loss at iteration 1510 : 0.011589456349611282
Loss at iteration 1520 : 0.01017303578555584
Loss at iteration 1530 : 0.011147133074700832
Loss at iteration 1540 : 0.019993573427200317
Loss at iteration 1550 : 0.025107458233833313
Loss at iteration 1560 : 0.005035444162786007
Loss at iteration 1570 : 0.016145609319210052
Loss at iteration 1580 : 0.015498673543334007
Loss at iteration 1590 : 0.006896732375025749
Loss at iteration 1600 : 0.013411875814199448
Loss at iteration 1610 : 0.010507442057132721
Loss at iteration 1620 : 0.01872805319726467
Loss at iteration 1630 : 0.010051817633211613
Loss at iteration 1640 : 0.022202320396900177
Loss at iteration 1650 : 0.012304672971367836
Loss at iteration 1660 : 0.013453196734189987
Loss at iteration 1670 : 0.013657800853252411
Loss at iteration 1680 : 0.010857190936803818
Loss at iteration 1690 : 0.012780381366610527
Loss at iteration 1700 : 0.0066488953307271
Loss at iteration 1710 : 0.009378384798765182
Loss at iteration 1720 : 0.009709667414426804
Loss at iteration 1730 : 0.020262258127331734
Loss at iteration 1740 : 0.01569465920329094
Loss at iteration 1750 : 0.017840931192040443
Loss at iteration 1760 : 0.011615562252700329
Loss at iteration 1770 : 0.011218436993658543
Loss at iteration 1780 : 0.006110168993473053
Loss at iteration 1790 : 0.011761362664401531
Loss at iteration 1800 : 0.016920603811740875
Loss at iteration 1810 : 0.017100080847740173
Loss at iteration 1820 : 0.01639971323311329
Loss at iteration 1830 : 0.01653103157877922
Loss at iteration 1840 : 0.01583748497068882
Loss at iteration 1850 : 0.01577279157936573
Loss at iteration 1860 : 0.010419841855764389
Loss at iteration 1870 : 0.0189268309623003
Loss at iteration 1880 : 0.00802607275545597
Loss at iteration 1890 : 0.02680201828479767
Loss at iteration 1900 : 0.014224021695554256
Loss at iteration 1910 : 0.010872891172766685
Loss at iteration 1920 : 0.002774239983409643
Loss at iteration 1930 : 0.010227651335299015
Loss at iteration 1940 : 0.00787369068711996
Loss at iteration 1950 : 0.018528006970882416
Loss at iteration 1960 : 0.010066044516861439
Loss at iteration 1970 : 0.009027684107422829
Loss at iteration 1980 : 0.010911794379353523
Loss at iteration 1990 : 0.014122460037469864
Loss at iteration 2000 : 0.010315394029021263
Loss at iteration 2010 : 0.02248195931315422
Loss at iteration 2020 : 0.01468738541007042
Loss at iteration 2030 : 0.00940597616136074
Loss at iteration 2040 : 0.00733592826873064
Loss at iteration 2050 : 0.018116021528840065
Loss at iteration 2060 : 0.012656849808990955
Loss at iteration 2070 : 0.028373651206493378
Loss at iteration 2080 : 0.008423767052590847
Loss at iteration 2090 : 0.007348831743001938
Loss at iteration 2100 : 0.009558441117405891
Loss at iteration 2110 : 0.028027325868606567
Loss at iteration 2120 : 0.005904995836317539
Loss at iteration 2130 : 0.02664060704410076
Loss at iteration 2140 : 0.022867703810334206
Loss at iteration 2150 : 0.01473290752619505
Loss at iteration 2160 : 0.011586317792534828
Loss at iteration 2170 : 0.018706711009144783
Loss at iteration 2180 : 0.006898139603435993
Loss at iteration 2190 : 0.018247241154313087
Loss at iteration 2200 : 0.013053497299551964
Loss at iteration 2210 : 0.010790066793560982
Loss at iteration 2220 : 0.012748681008815765
Loss at iteration 2230 : 0.007771582808345556
Loss at iteration 2240 : 0.02952774614095688
Loss at iteration 2250 : 0.014367572963237762
Loss at iteration 2260 : 0.011671854183077812
Loss at iteration 2270 : 0.016265664249658585
Loss at iteration 2280 : 0.014274430461227894
Loss at iteration 2290 : 0.005517891142517328
Loss at iteration 2300 : 0.0164030734449625
Loss at iteration 2310 : 0.024562625214457512
Loss at iteration 2320 : 0.012022240087389946
Loss at iteration 2330 : 0.008341683074831963
Loss at iteration 2340 : 0.010249811224639416
Loss at iteration 2350 : 0.008622323162853718
Loss at iteration 2360 : 0.017130214720964432
Loss at iteration 2370 : 0.017695274204015732
Loss at iteration 2380 : 0.007630560081452131
Loss at iteration 2390 : 0.013049406930804253
Loss at iteration 2400 : 0.010596980340778828
Loss at iteration 2410 : 0.026820411905646324
Loss at iteration 2420 : 0.01903006061911583
The SSIM Value is: 0.825491205851237
The PSNR Value is: 21.037711715698244
the epoch is: 15
Loss at iteration 10 : 0.009863417595624924
Loss at iteration 20 : 0.021268147975206375
Loss at iteration 30 : 0.012805702164769173
Loss at iteration 40 : 0.010592220351099968
Loss at iteration 50 : 0.009432458318769932
Loss at iteration 60 : 0.013340866193175316
Loss at iteration 70 : 0.012107091955840588
Loss at iteration 80 : 0.03268536552786827
Loss at iteration 90 : 0.022983046248555183
Loss at iteration 100 : 0.010664480738341808
Loss at iteration 110 : 0.0117215970531106
Loss at iteration 120 : 0.01048232987523079
Loss at iteration 130 : 0.009025093168020248
Loss at iteration 140 : 0.006313640158623457
Loss at iteration 150 : 0.012902419082820415
Loss at iteration 160 : 0.007291811518371105
Loss at iteration 170 : 0.013605702668428421
Loss at iteration 180 : 0.0030290691647678614
Loss at iteration 190 : 0.016939163208007812
Loss at iteration 200 : 0.013864986598491669
Loss at iteration 210 : 0.015387171879410744
Loss at iteration 220 : 0.010690230876207352
Loss at iteration 230 : 0.005942498333752155
Loss at iteration 240 : 0.016391567885875702
Loss at iteration 250 : 0.020484883338212967
Loss at iteration 260 : 0.009020690806210041
Loss at iteration 270 : 0.007280312012881041
Loss at iteration 280 : 0.010881571099162102
Loss at iteration 290 : 0.019118959084153175
Loss at iteration 300 : 0.027510151267051697
Loss at iteration 310 : 0.010153829120099545
Loss at iteration 320 : 0.008740732446312904
Loss at iteration 330 : 0.0249598640948534
Loss at iteration 340 : 0.008457263931632042
Loss at iteration 350 : 0.007515251636505127
Loss at iteration 360 : 0.016017448157072067
Loss at iteration 370 : 0.011043479666113853
Loss at iteration 380 : 0.010384749621152878
Loss at iteration 390 : 0.02448369562625885
Loss at iteration 400 : 0.006163910962641239
Loss at iteration 410 : 0.010318571701645851
Loss at iteration 420 : 0.013434145599603653
Loss at iteration 430 : 0.013178901746869087
Loss at iteration 440 : 0.011439911089837551
Loss at iteration 450 : 0.008896086364984512
Loss at iteration 460 : 0.004016435705125332
Loss at iteration 470 : 0.011519050225615501
Loss at iteration 480 : 0.012732796370983124
Loss at iteration 490 : 0.016200516372919083
Loss at iteration 500 : 0.01051679253578186
Loss at iteration 510 : 0.01297954935580492
Loss at iteration 520 : 0.011059596203267574
Loss at iteration 530 : 0.009394067339599133
Loss at iteration 540 : 0.019358888268470764
Loss at iteration 550 : 0.008469672873616219
Loss at iteration 560 : 0.007730820216238499
Loss at iteration 570 : 0.012575626373291016
Loss at iteration 580 : 0.01664123870432377
Loss at iteration 590 : 0.010945118963718414
Loss at iteration 600 : 0.00941061694175005
Loss at iteration 610 : 0.015820467844605446
Loss at iteration 620 : 0.00997229851782322
Loss at iteration 630 : 0.00831439346075058
Loss at iteration 640 : 0.016948863863945007
Loss at iteration 650 : 0.025602541863918304
Loss at iteration 660 : 0.014350412413477898
Loss at iteration 670 : 0.0082420464605093
Loss at iteration 680 : 0.008209280669689178
Loss at iteration 690 : 0.015738144516944885
Loss at iteration 700 : 0.010669374838471413
Loss at iteration 710 : 0.012485195882618427
Loss at iteration 720 : 0.0038924417458474636
Loss at iteration 730 : 0.01607193797826767
Loss at iteration 740 : 0.023614071309566498
Loss at iteration 750 : 0.026697352528572083
Loss at iteration 760 : 0.02359706163406372
Loss at iteration 770 : 0.010314667597413063
Loss at iteration 780 : 0.015087885782122612
Loss at iteration 790 : 0.010642442852258682
Loss at iteration 800 : 0.018764495849609375
Loss at iteration 810 : 0.02161799557507038
Loss at iteration 820 : 0.030466310679912567
Loss at iteration 830 : 0.019974909722805023
Loss at iteration 840 : 0.027208317071199417
Loss at iteration 850 : 0.022782988846302032
Loss at iteration 860 : 0.01236885879188776
Loss at iteration 870 : 0.00827061291784048
Loss at iteration 880 : 0.022318463772535324
Loss at iteration 890 : 0.01865183189511299
Loss at iteration 900 : 0.01648637279868126
Loss at iteration 910 : 0.012529042549431324
Loss at iteration 920 : 0.005978315137326717
Loss at iteration 930 : 0.011147167533636093
Loss at iteration 940 : 0.015280883759260178
Loss at iteration 950 : 0.009871267713606358
Loss at iteration 960 : 0.025432048365473747
Loss at iteration 970 : 0.0038452434819191694
Loss at iteration 980 : 0.010311674326658249
Loss at iteration 990 : 0.0075121792033314705
Loss at iteration 1000 : 0.016745159402489662
Loss at iteration 1010 : 0.006594142876565456
Loss at iteration 1020 : 0.00408165855333209
Loss at iteration 1030 : 0.0107406135648489
Loss at iteration 1040 : 0.013118905946612358
Loss at iteration 1050 : 0.009596848860383034
Loss at iteration 1060 : 0.022631529718637466
Loss at iteration 1070 : 0.02053447626531124
Loss at iteration 1080 : 0.011861752718687057
Loss at iteration 1090 : 0.010011056438088417
Loss at iteration 1100 : 0.014797871932387352
Loss at iteration 1110 : 0.014837360940873623
Loss at iteration 1120 : 0.013126261532306671
Loss at iteration 1130 : 0.007038697600364685
Loss at iteration 1140 : 0.009723242372274399
Loss at iteration 1150 : 0.012736392207443714
Loss at iteration 1160 : 0.00889804307371378
Loss at iteration 1170 : 0.009405761957168579
Loss at iteration 1180 : 0.012944458052515984
Loss at iteration 1190 : 0.010173174552619457
Loss at iteration 1200 : 0.011466270312666893
Loss at iteration 1210 : 0.015252362005412579
Loss at iteration 1220 : 0.009563677944242954
Loss at iteration 1230 : 0.004827162250876427
Loss at iteration 1240 : 0.01137500535696745
Loss at iteration 1250 : 0.021210525184869766
Loss at iteration 1260 : 0.011453455314040184
Loss at iteration 1270 : 0.025463134050369263
Loss at iteration 1280 : 0.011640973389148712
Loss at iteration 1290 : 0.014429325237870216
Loss at iteration 1300 : 0.021895984187722206
Loss at iteration 1310 : 0.023910176008939743
Loss at iteration 1320 : 0.012834852561354637
Loss at iteration 1330 : 0.005646590609103441
Loss at iteration 1340 : 0.013655445538461208
Loss at iteration 1350 : 0.014738987199962139
Loss at iteration 1360 : 0.025036145001649857
Loss at iteration 1370 : 0.023202257230877876
Loss at iteration 1380 : 0.0065329293720424175
Loss at iteration 1390 : 0.01250388752669096
Loss at iteration 1400 : 0.006288047414273024
Loss at iteration 1410 : 0.010041914880275726
Loss at iteration 1420 : 0.006261833943426609
Loss at iteration 1430 : 0.003967973403632641
Loss at iteration 1440 : 0.01611972227692604
Loss at iteration 1450 : 0.015568161383271217
Loss at iteration 1460 : 0.010534495115280151
Loss at iteration 1470 : 0.02721456252038479
Loss at iteration 1480 : 0.004594503436237574
Loss at iteration 1490 : 0.006089472211897373
Loss at iteration 1500 : 0.008404966443777084
Loss at iteration 1510 : 0.013813091441988945
Loss at iteration 1520 : 0.004724816419184208
Loss at iteration 1530 : 0.013321930542588234
Loss at iteration 1540 : 0.014093222096562386
Loss at iteration 1550 : 0.01134711317718029
Loss at iteration 1560 : 0.009546572342514992
Loss at iteration 1570 : 0.01816590502858162
Loss at iteration 1580 : 0.007779314182698727
Loss at iteration 1590 : 0.006456215865910053
Loss at iteration 1600 : 0.013147283345460892
Loss at iteration 1610 : 0.01469762995839119
Loss at iteration 1620 : 0.01386790070682764
Loss at iteration 1630 : 0.018368495628237724
Loss at iteration 1640 : 0.010846402496099472
Loss at iteration 1650 : 0.012448904104530811
Loss at iteration 1660 : 0.008786540478467941
Loss at iteration 1670 : 0.013643774203956127
Loss at iteration 1680 : 0.021080421283841133
Loss at iteration 1690 : 0.0059389411471784115
Loss at iteration 1700 : 0.007479693740606308
Loss at iteration 1710 : 0.015537275932729244
Loss at iteration 1720 : 0.01775348372757435
Loss at iteration 1730 : 0.008127414621412754
Loss at iteration 1740 : 0.008224749006330967
Loss at iteration 1750 : 0.015295177698135376
Loss at iteration 1760 : 0.0066149234771728516
Loss at iteration 1770 : 0.01440336275845766
Loss at iteration 1780 : 0.01429099403321743
Loss at iteration 1790 : 0.014862972311675549
Loss at iteration 1800 : 0.008098138496279716
Loss at iteration 1810 : 0.011364870704710484
Loss at iteration 1820 : 0.017529580742120743
Loss at iteration 1830 : 0.011251531541347504
Loss at iteration 1840 : 0.007732841651886702
Loss at iteration 1850 : 0.017305761575698853
Loss at iteration 1860 : 0.0097800362855196
Loss at iteration 1870 : 0.024120796471834183
Loss at iteration 1880 : 0.007876846939325333
Loss at iteration 1890 : 0.013163106516003609
Loss at iteration 1900 : 0.014960003085434437
Loss at iteration 1910 : 0.016319388523697853
Loss at iteration 1920 : 0.014941619709134102
Loss at iteration 1930 : 0.01874130219221115
Loss at iteration 1940 : 0.016218164935708046
Loss at iteration 1950 : 0.02530837059020996
Loss at iteration 1960 : 0.02461577020585537
Loss at iteration 1970 : 0.013986198231577873
Loss at iteration 1980 : 0.015320886857807636
Loss at iteration 1990 : 0.008705688640475273
Loss at iteration 2000 : 0.008372928947210312
Loss at iteration 2010 : 0.009722176939249039
Loss at iteration 2020 : 0.011531110852956772
Loss at iteration 2030 : 0.013167468830943108
Loss at iteration 2040 : 0.008435750380158424
Loss at iteration 2050 : 0.006128242239356041
Loss at iteration 2060 : 0.02113817259669304
Loss at iteration 2070 : 0.009992958977818489
Loss at iteration 2080 : 0.011833067052066326
Loss at iteration 2090 : 0.008788066916167736
Loss at iteration 2100 : 0.005674108862876892
Loss at iteration 2110 : 0.019182978197932243
Loss at iteration 2120 : 0.013204511255025864
Loss at iteration 2130 : 0.0064909448847174644
Loss at iteration 2140 : 0.00829076673835516
Loss at iteration 2150 : 0.011852944269776344
Loss at iteration 2160 : 0.018809618428349495
Loss at iteration 2170 : 0.011169303208589554
Loss at iteration 2180 : 0.00923137180507183
Loss at iteration 2190 : 0.010173344053328037
Loss at iteration 2200 : 0.009885948151350021
Loss at iteration 2210 : 0.01582886278629303
Loss at iteration 2220 : 0.013884474523365498
Loss at iteration 2230 : 0.008478530682623386
Loss at iteration 2240 : 0.00821209792047739
Loss at iteration 2250 : 0.026399731636047363
Loss at iteration 2260 : 0.012063253670930862
Loss at iteration 2270 : 0.010582739487290382
Loss at iteration 2280 : 0.01241415273398161
Loss at iteration 2290 : 0.0057692257687449455
Loss at iteration 2300 : 0.00959911197423935
Loss at iteration 2310 : 0.012599128298461437
Loss at iteration 2320 : 0.007598141208291054
Loss at iteration 2330 : 0.008199748583137989
Loss at iteration 2340 : 0.008441346697509289
Loss at iteration 2350 : 0.020617887377738953
Loss at iteration 2360 : 0.011769788339734077
Loss at iteration 2370 : 0.015425402671098709
Loss at iteration 2380 : 0.008186200633645058
Loss at iteration 2390 : 0.013168146833777428
Loss at iteration 2400 : 0.007867220789194107
Loss at iteration 2410 : 0.00902045238763094
Loss at iteration 2420 : 0.009709750302135944
The SSIM Value is: 0.8340045849482218
The PSNR Value is: 21.025706354777018
the epoch is: 16
Loss at iteration 10 : 0.012646703980863094
Loss at iteration 20 : 0.011109243147075176
Loss at iteration 30 : 0.011282582767307758
Loss at iteration 40 : 0.016756553202867508
Loss at iteration 50 : 0.01515626348555088
Loss at iteration 60 : 0.008844999596476555
Loss at iteration 70 : 0.008163574151694775
Loss at iteration 80 : 0.026005418971180916
Loss at iteration 90 : 0.00395889300853014
Loss at iteration 100 : 0.01550840213894844
Loss at iteration 110 : 0.011680906638503075
Loss at iteration 120 : 0.010922104120254517
Loss at iteration 130 : 0.019988110288977623
Loss at iteration 140 : 0.008297283202409744
Loss at iteration 150 : 0.007331650238484144
Loss at iteration 160 : 0.00797436386346817
Loss at iteration 170 : 0.007935729809105396
Loss at iteration 180 : 0.010934879072010517
Loss at iteration 190 : 0.007883444428443909
Loss at iteration 200 : 0.018465036526322365
Loss at iteration 210 : 0.025775639340281487
Loss at iteration 220 : 0.01536720059812069
Loss at iteration 230 : 0.01764230988919735
Loss at iteration 240 : 0.014955524355173111
Loss at iteration 250 : 0.008785838261246681
Loss at iteration 260 : 0.02187209017574787
Loss at iteration 270 : 0.00707678496837616
Loss at iteration 280 : 0.022961176931858063
Loss at iteration 290 : 0.006380684673786163
Loss at iteration 300 : 0.021222613751888275
Loss at iteration 310 : 0.01220555230975151
Loss at iteration 320 : 0.0198767501860857
Loss at iteration 330 : 0.006448850035667419
Loss at iteration 340 : 0.007908499799668789
Loss at iteration 350 : 0.007450258359313011
Loss at iteration 360 : 0.012643182650208473
Loss at iteration 370 : 0.019262926653027534
Loss at iteration 380 : 0.01778551936149597
Loss at iteration 390 : 0.010410466231405735
Loss at iteration 400 : 0.01682363450527191
Loss at iteration 410 : 0.011991431005299091
Loss at iteration 420 : 0.011168300174176693
Loss at iteration 430 : 0.02680288814008236
Loss at iteration 440 : 0.017610512673854828
Loss at iteration 450 : 0.012484272941946983
Loss at iteration 460 : 0.013729382306337357
Loss at iteration 470 : 0.01861249841749668
Loss at iteration 480 : 0.009231376461684704
Loss at iteration 490 : 0.010018343105912209
Loss at iteration 500 : 0.019825488328933716
Loss at iteration 510 : 0.008403749205172062
Loss at iteration 520 : 0.022706463932991028
Loss at iteration 530 : 0.007530654780566692
Loss at iteration 540 : 0.013313819654285908
Loss at iteration 550 : 0.010507983155548573
Loss at iteration 560 : 0.00764166284352541
Loss at iteration 570 : 0.012801938690245152
Loss at iteration 580 : 0.008896315470337868
Loss at iteration 590 : 0.03123387321829796
Loss at iteration 600 : 0.020779293030500412
Loss at iteration 610 : 0.010042732581496239
Loss at iteration 620 : 0.009552590548992157
Loss at iteration 630 : 0.008361347019672394
Loss at iteration 640 : 0.013278588652610779
Loss at iteration 650 : 0.014162123203277588
Loss at iteration 660 : 0.01480238325893879
Loss at iteration 670 : 0.013650519773364067
Loss at iteration 680 : 0.008175794966518879
Loss at iteration 690 : 0.010114866308867931
Loss at iteration 700 : 0.014728966169059277
Loss at iteration 710 : 0.02132900059223175
Loss at iteration 720 : 0.028493732213974
Loss at iteration 730 : 0.014268836006522179
Loss at iteration 740 : 0.019238464534282684
Loss at iteration 750 : 0.007353050634264946
Loss at iteration 760 : 0.006601184140890837
Loss at iteration 770 : 0.02533482387661934
Loss at iteration 780 : 0.012622312642633915
Loss at iteration 790 : 0.008751362562179565
Loss at iteration 800 : 0.01276184618473053
Loss at iteration 810 : 0.02214987762272358
Loss at iteration 820 : 0.022421207278966904
Loss at iteration 830 : 0.012239024043083191
Loss at iteration 840 : 0.012711264193058014
Loss at iteration 850 : 0.017847495153546333
Loss at iteration 860 : 0.011473417282104492
Loss at iteration 870 : 0.016851123422384262
Loss at iteration 880 : 0.020897164940834045
Loss at iteration 890 : 0.013286198489367962
Loss at iteration 900 : 0.022525865584611893
Loss at iteration 910 : 0.006553998216986656
Loss at iteration 920 : 0.014730012975633144
Loss at iteration 930 : 0.02043258212506771
Loss at iteration 940 : 0.009966312907636166
Loss at iteration 950 : 0.013483988121151924
Loss at iteration 960 : 0.011367922648787498
Loss at iteration 970 : 0.00491821113973856
Loss at iteration 980 : 0.0256410650908947
Loss at iteration 990 : 0.00854527298361063
Loss at iteration 1000 : 0.009492715820670128
Loss at iteration 1010 : 0.008833236061036587
Loss at iteration 1020 : 0.013325218111276627
Loss at iteration 1030 : 0.02551770582795143
Loss at iteration 1040 : 0.006464952602982521
Loss at iteration 1050 : 0.020794779062271118
Loss at iteration 1060 : 0.01826421543955803
Loss at iteration 1070 : 0.007977651432156563
Loss at iteration 1080 : 0.022195979952812195
Loss at iteration 1090 : 0.013441536575555801
Loss at iteration 1100 : 0.023298244923353195
Loss at iteration 1110 : 0.01126014068722725
Loss at iteration 1120 : 0.011059021577239037
Loss at iteration 1130 : 0.010096980258822441
Loss at iteration 1140 : 0.014006409794092178
Loss at iteration 1150 : 0.004876986611634493
Loss at iteration 1160 : 0.01335865631699562
Loss at iteration 1170 : 0.006379975005984306
Loss at iteration 1180 : 0.003202056046575308
Loss at iteration 1190 : 0.012268193997442722
Loss at iteration 1200 : 0.019766828045248985
Loss at iteration 1210 : 0.011928580701351166
Loss at iteration 1220 : 0.005496148951351643
Loss at iteration 1230 : 0.012909986078739166
Loss at iteration 1240 : 0.011919891461730003
Loss at iteration 1250 : 0.0037157016340643167
Loss at iteration 1260 : 0.01608460023999214
Loss at iteration 1270 : 0.009041824378073215
Loss at iteration 1280 : 0.01567455567419529
Loss at iteration 1290 : 0.03191296383738518
Loss at iteration 1300 : 0.0248277485370636
Loss at iteration 1310 : 0.0063978820107877254
Loss at iteration 1320 : 0.016393892467021942
Loss at iteration 1330 : 0.019286135211586952
Loss at iteration 1340 : 0.01547257974743843
Loss at iteration 1350 : 0.009598138742148876
Loss at iteration 1360 : 0.01448310911655426
Loss at iteration 1370 : 0.016583479940891266
Loss at iteration 1380 : 0.011356784030795097
Loss at iteration 1390 : 0.010553568601608276
Loss at iteration 1400 : 0.016866955906152725
Loss at iteration 1410 : 0.01750503107905388
Loss at iteration 1420 : 0.0060587250627577305
Loss at iteration 1430 : 0.013153227046132088
Loss at iteration 1440 : 0.01432822085916996
Loss at iteration 1450 : 0.00732477055862546
Loss at iteration 1460 : 0.007444269955158234
Loss at iteration 1470 : 0.015819372609257698
Loss at iteration 1480 : 0.007495494559407234
Loss at iteration 1490 : 0.006678307428956032
Loss at iteration 1500 : 0.0062887705862522125
Loss at iteration 1510 : 0.010467625223100185
Loss at iteration 1520 : 0.015501129440963268
Loss at iteration 1530 : 0.027142394334077835
Loss at iteration 1540 : 0.004190692212432623
Loss at iteration 1550 : 0.008842023089528084
Loss at iteration 1560 : 0.015215586870908737
Loss at iteration 1570 : 0.013242565095424652
Loss at iteration 1580 : 0.009309441782534122
Loss at iteration 1590 : 0.016390230506658554
Loss at iteration 1600 : 0.013718982227146626
Loss at iteration 1610 : 0.010574419051408768
Loss at iteration 1620 : 0.008016781881451607
Loss at iteration 1630 : 0.008443274535238743
Loss at iteration 1640 : 0.012064391747117043
Loss at iteration 1650 : 0.012671121396124363
Loss at iteration 1660 : 0.011941153556108475
Loss at iteration 1670 : 0.013718143105506897
Loss at iteration 1680 : 0.01293610967695713
Loss at iteration 1690 : 0.005521079991012812
Loss at iteration 1700 : 0.007836701348423958
Loss at iteration 1710 : 0.016065359115600586
Loss at iteration 1720 : 0.011604685336351395
Loss at iteration 1730 : 0.00848856195807457
Loss at iteration 1740 : 0.013885424472391605
Loss at iteration 1750 : 0.024358274415135384
Loss at iteration 1760 : 0.019216978922486305
Loss at iteration 1770 : 0.012224564328789711
Loss at iteration 1780 : 0.009254537522792816
Loss at iteration 1790 : 0.01014620903879404
Loss at iteration 1800 : 0.03052159771323204
Loss at iteration 1810 : 0.015066361054778099
Loss at iteration 1820 : 0.005752387456595898
Loss at iteration 1830 : 0.00499532837420702
Loss at iteration 1840 : 0.012757683172821999
Loss at iteration 1850 : 0.006419315002858639
Loss at iteration 1860 : 0.023097818717360497
Loss at iteration 1870 : 0.010149413719773293
Loss at iteration 1880 : 0.007677469868212938
Loss at iteration 1890 : 0.012454768642783165
Loss at iteration 1900 : 0.016577281057834625
Loss at iteration 1910 : 0.011277986690402031
Loss at iteration 1920 : 0.010058391839265823
Loss at iteration 1930 : 0.015706030651926994
Loss at iteration 1940 : 0.009133314713835716
Loss at iteration 1950 : 0.01013832725584507
Loss at iteration 1960 : 0.012361068278551102
Loss at iteration 1970 : 0.01481989398598671
Loss at iteration 1980 : 0.008653340861201286
Loss at iteration 1990 : 0.009284192696213722
Loss at iteration 2000 : 0.013655333779752254
Loss at iteration 2010 : 0.0048681218177080154
Loss at iteration 2020 : 0.01663435995578766
Loss at iteration 2030 : 0.008382859639823437
Loss at iteration 2040 : 0.013562172651290894
Loss at iteration 2050 : 0.014644951559603214
Loss at iteration 2060 : 0.010085814632475376
Loss at iteration 2070 : 0.03586774691939354
Loss at iteration 2080 : 0.024047307670116425
Loss at iteration 2090 : 0.013732371851801872
Loss at iteration 2100 : 0.016759958118200302
Loss at iteration 2110 : 0.012752704322338104
Loss at iteration 2120 : 0.01894248276948929
Loss at iteration 2130 : 0.01200373936444521
Loss at iteration 2140 : 0.007535272277891636
Loss at iteration 2150 : 0.010924942791461945
Loss at iteration 2160 : 0.00637332396581769
Loss at iteration 2170 : 0.017844371497631073
Loss at iteration 2180 : 0.016239263117313385
Loss at iteration 2190 : 0.015186246484518051
Loss at iteration 2200 : 0.0072899870574474335
Loss at iteration 2210 : 0.011074934154748917
Loss at iteration 2220 : 0.04049459099769592
Loss at iteration 2230 : 0.006746088154613972
Loss at iteration 2240 : 0.009673090651631355
Loss at iteration 2250 : 0.01133465301245451
Loss at iteration 2260 : 0.01635962724685669
Loss at iteration 2270 : 0.010820656083524227
Loss at iteration 2280 : 0.020278621464967728
Loss at iteration 2290 : 0.017759695649147034
Loss at iteration 2300 : 0.005302909761667252
Loss at iteration 2310 : 0.008125068619847298
Loss at iteration 2320 : 0.009734895080327988
Loss at iteration 2330 : 0.008153317496180534
Loss at iteration 2340 : 0.00995245948433876
Loss at iteration 2350 : 0.009753083810210228
Loss at iteration 2360 : 0.013560483232140541
Loss at iteration 2370 : 0.009950978681445122
Loss at iteration 2380 : 0.010915628634393215
Loss at iteration 2390 : 0.011334946379065514
Loss at iteration 2400 : 0.025770068168640137
Loss at iteration 2410 : 0.016805261373519897
Loss at iteration 2420 : 0.009044767357409
The SSIM Value is: 0.8392702102661133
The PSNR Value is: 21.51845016479492
the epoch is: 17
Loss at iteration 10 : 0.006759616080671549
Loss at iteration 20 : 0.009774906560778618
Loss at iteration 30 : 0.008920217864215374
Loss at iteration 40 : 0.006519325077533722
Loss at iteration 50 : 0.010089716874063015
Loss at iteration 60 : 0.010850107297301292
Loss at iteration 70 : 0.006237255409359932
Loss at iteration 80 : 0.01412044744938612
Loss at iteration 90 : 0.012750661931931973
Loss at iteration 100 : 0.009796629659831524
Loss at iteration 110 : 0.008762644603848457
Loss at iteration 120 : 0.032677918672561646
Loss at iteration 130 : 0.02143278159201145
Loss at iteration 140 : 0.018222548067569733
Loss at iteration 150 : 0.008897915482521057
Loss at iteration 160 : 0.00808362103998661
Loss at iteration 170 : 0.012399932369589806
Loss at iteration 180 : 0.020906345918774605
Loss at iteration 190 : 0.018306169658899307
Loss at iteration 200 : 0.009808977134525776
Loss at iteration 210 : 0.008735915645956993
Loss at iteration 220 : 0.005849579814821482
Loss at iteration 230 : 0.013457468710839748
Loss at iteration 240 : 0.015636034309864044
Loss at iteration 250 : 0.015735724940896034
Loss at iteration 260 : 0.007695760112255812
Loss at iteration 270 : 0.01026897132396698
Loss at iteration 280 : 0.007889533415436745
Loss at iteration 290 : 0.004571836441755295
Loss at iteration 300 : 0.00805837381631136
Loss at iteration 310 : 0.009862993843853474
Loss at iteration 320 : 0.01224309392273426
Loss at iteration 330 : 0.013195415958762169
Loss at iteration 340 : 0.00979209877550602
Loss at iteration 350 : 0.006491841748356819
Loss at iteration 360 : 0.013664470985531807
Loss at iteration 370 : 0.007588846608996391
Loss at iteration 380 : 0.01821042224764824
Loss at iteration 390 : 0.019371019676327705
Loss at iteration 400 : 0.009454363957047462
Loss at iteration 410 : 0.007820453494787216
Loss at iteration 420 : 0.010193164460361004
Loss at iteration 430 : 0.010123895481228828
Loss at iteration 440 : 0.011656481772661209
Loss at iteration 450 : 0.023005720227956772
Loss at iteration 460 : 0.010235143825411797
Loss at iteration 470 : 0.011270524933934212
Loss at iteration 480 : 0.012664726935327053
Loss at iteration 490 : 0.01109853945672512
Loss at iteration 500 : 0.01643255352973938
Loss at iteration 510 : 0.014567341655492783
Loss at iteration 520 : 0.010343685746192932
Loss at iteration 530 : 0.010692361742258072
Loss at iteration 540 : 0.012815643101930618
Loss at iteration 550 : 0.011587779968976974
Loss at iteration 560 : 0.01941380649805069
Loss at iteration 570 : 0.008562127128243446
Loss at iteration 580 : 0.011991378851234913
Loss at iteration 590 : 0.008057871833443642
Loss at iteration 600 : 0.01148721482604742
Loss at iteration 610 : 0.0068501196801662445
Loss at iteration 620 : 0.01848582923412323
Loss at iteration 630 : 0.015877623111009598
Loss at iteration 640 : 0.021129216998815536
Loss at iteration 650 : 0.006300763227045536
Loss at iteration 660 : 0.008258056826889515
Loss at iteration 670 : 0.011096509173512459
Loss at iteration 680 : 0.016350196674466133
Loss at iteration 690 : 0.0047028763219714165
Loss at iteration 700 : 0.011625753715634346
Loss at iteration 710 : 0.012990819290280342
Loss at iteration 720 : 0.008922726847231388
Loss at iteration 730 : 0.009212106466293335
Loss at iteration 740 : 0.012413006275892258
Loss at iteration 750 : 0.011353734880685806
Loss at iteration 760 : 0.0112019507214427
Loss at iteration 770 : 0.021700387820601463
Loss at iteration 780 : 0.017211657017469406
Loss at iteration 790 : 0.01736951805651188
Loss at iteration 800 : 0.019441772252321243
Loss at iteration 810 : 0.017388883978128433
Loss at iteration 820 : 0.015433134511113167
Loss at iteration 830 : 0.015292510390281677
Loss at iteration 840 : 0.008298133499920368
Loss at iteration 850 : 0.014148795045912266
Loss at iteration 860 : 0.012310604564845562
Loss at iteration 870 : 0.007132838945835829
Loss at iteration 880 : 0.02133747935295105
Loss at iteration 890 : 0.00668376125395298
Loss at iteration 900 : 0.017427951097488403
Loss at iteration 910 : 0.010214163921773434
Loss at iteration 920 : 0.01908273622393608
Loss at iteration 930 : 0.009557070210576057
Loss at iteration 940 : 0.009324245154857635
Loss at iteration 950 : 0.02520916797220707
Loss at iteration 960 : 0.019285717979073524
Loss at iteration 970 : 0.011739498004317284
Loss at iteration 980 : 0.009596893563866615
Loss at iteration 990 : 0.013007460162043571
Loss at iteration 1000 : 0.0146121671423316
Loss at iteration 1010 : 0.006984609179198742
Loss at iteration 1020 : 0.012255823239684105
Loss at iteration 1030 : 0.006215226370841265
Loss at iteration 1040 : 0.01739511452615261
Loss at iteration 1050 : 0.007917728275060654
Loss at iteration 1060 : 0.00509442575275898
Loss at iteration 1070 : 0.018629031255841255
Loss at iteration 1080 : 0.011274788528680801
Loss at iteration 1090 : 0.008823512122035027
Loss at iteration 1100 : 0.011327904649078846
Loss at iteration 1110 : 0.014181332662701607
Loss at iteration 1120 : 0.031473852694034576
Loss at iteration 1130 : 0.013559442944824696
Loss at iteration 1140 : 0.021458899602293968
Loss at iteration 1150 : 0.015561969950795174
Loss at iteration 1160 : 0.014678466133773327
Loss at iteration 1170 : 0.021297834813594818
Loss at iteration 1180 : 0.03419281542301178
Loss at iteration 1190 : 0.015441935509443283
Loss at iteration 1200 : 0.014280478470027447
Loss at iteration 1210 : 0.011327940970659256
Loss at iteration 1220 : 0.016428662464022636
Loss at iteration 1230 : 0.01953325979411602
Loss at iteration 1240 : 0.01184622012078762
Loss at iteration 1250 : 0.022914942353963852
Loss at iteration 1260 : 0.014521247707307339
Loss at iteration 1270 : 0.021659748628735542
Loss at iteration 1280 : 0.01614977791905403
Loss at iteration 1290 : 0.010532014071941376
Loss at iteration 1300 : 0.02027977630496025
Loss at iteration 1310 : 0.009582286700606346
Loss at iteration 1320 : 0.009451803751289845
Loss at iteration 1330 : 0.01660124771296978
Loss at iteration 1340 : 0.015751780942082405
Loss at iteration 1350 : 0.020431041717529297
Loss at iteration 1360 : 0.012337744235992432
Loss at iteration 1370 : 0.01648874580860138
Loss at iteration 1380 : 0.02260678820312023
Loss at iteration 1390 : 0.016549183055758476
Loss at iteration 1400 : 0.005606199614703655
Loss at iteration 1410 : 0.011160691268742085
Loss at iteration 1420 : 0.019160466268658638
Loss at iteration 1430 : 0.011177536100149155
Loss at iteration 1440 : 0.02416379749774933
Loss at iteration 1450 : 0.019616879522800446
Loss at iteration 1460 : 0.02427949756383896
Loss at iteration 1470 : 0.00844027753919363
Loss at iteration 1480 : 0.0070987725630402565
Loss at iteration 1490 : 0.020379826426506042
Loss at iteration 1500 : 0.018129821866750717
Loss at iteration 1510 : 0.019051071256399155
Loss at iteration 1520 : 0.004676109179854393
Loss at iteration 1530 : 0.02150985598564148
Loss at iteration 1540 : 0.009700125083327293
Loss at iteration 1550 : 0.013335105963051319
Loss at iteration 1560 : 0.008852751925587654
Loss at iteration 1570 : 0.020826809108257294
Loss at iteration 1580 : 0.009329534135758877
Loss at iteration 1590 : 0.011515159159898758
Loss at iteration 1600 : 0.012273507192730904
Loss at iteration 1610 : 0.02277412638068199
Loss at iteration 1620 : 0.01355653814971447
Loss at iteration 1630 : 0.013101615011692047
Loss at iteration 1640 : 0.013125507161021233
Loss at iteration 1650 : 0.017679065465927124
Loss at iteration 1660 : 0.007949073798954487
Loss at iteration 1670 : 0.0074096256867051125
Loss at iteration 1680 : 0.019344210624694824
Loss at iteration 1690 : 0.020225344225764275
Loss at iteration 1700 : 0.006414953153580427
Loss at iteration 1710 : 0.013177519664168358
Loss at iteration 1720 : 0.009331857785582542
Loss at iteration 1730 : 0.022836286574602127
Loss at iteration 1740 : 0.015484564006328583
Loss at iteration 1750 : 0.006638778373599052
Loss at iteration 1760 : 0.016221465542912483
Loss at iteration 1770 : 0.01244512852281332
Loss at iteration 1780 : 0.010446939617395401
Loss at iteration 1790 : 0.010842636227607727
Loss at iteration 1800 : 0.013200156390666962
Loss at iteration 1810 : 0.019806791096925735
Loss at iteration 1820 : 0.011724356561899185
Loss at iteration 1830 : 0.005442728754132986
Loss at iteration 1840 : 0.012731654569506645
Loss at iteration 1850 : 0.013907677493989468
Loss at iteration 1860 : 0.013130302540957928
Loss at iteration 1870 : 0.009593287482857704
Loss at iteration 1880 : 0.006366894114762545
Loss at iteration 1890 : 0.009537162259221077
Loss at iteration 1900 : 0.017482396215200424
Loss at iteration 1910 : 0.01476954948157072
Loss at iteration 1920 : 0.01436567958444357
Loss at iteration 1930 : 0.010290151461958885
Loss at iteration 1940 : 0.014112052507698536
Loss at iteration 1950 : 0.011722009629011154
Loss at iteration 1960 : 0.012090511620044708
Loss at iteration 1970 : 0.01725190505385399
Loss at iteration 1980 : 0.015472552739083767
Loss at iteration 1990 : 0.01577569730579853
Loss at iteration 2000 : 0.023294705897569656
Loss at iteration 2010 : 0.009336070157587528
Loss at iteration 2020 : 0.013901203870773315
Loss at iteration 2030 : 0.013621492311358452
Loss at iteration 2040 : 0.023201987147331238
Loss at iteration 2050 : 0.011022958904504776
Loss at iteration 2060 : 0.014213421382009983
Loss at iteration 2070 : 0.017236070707440376
Loss at iteration 2080 : 0.008570981211960316
Loss at iteration 2090 : 0.013200083747506142
Loss at iteration 2100 : 0.012517810799181461
Loss at iteration 2110 : 0.012100676074624062
Loss at iteration 2120 : 0.009050259366631508
Loss at iteration 2130 : 0.008442171849310398
Loss at iteration 2140 : 0.01854650303721428
Loss at iteration 2150 : 0.015392409637570381
Loss at iteration 2160 : 0.014740461483597755
Loss at iteration 2170 : 0.0052909934893250465
Loss at iteration 2180 : 0.013974045403301716
Loss at iteration 2190 : 0.01531272567808628
Loss at iteration 2200 : 0.011743909679353237
Loss at iteration 2210 : 0.010924356058239937
Loss at iteration 2220 : 0.018162325024604797
Loss at iteration 2230 : 0.015510676428675652
Loss at iteration 2240 : 0.015287896618247032
Loss at iteration 2250 : 0.012734176591038704
Loss at iteration 2260 : 0.00532662495970726
Loss at iteration 2270 : 0.01101772766560316
Loss at iteration 2280 : 0.01505311205983162
Loss at iteration 2290 : 0.013694874942302704
Loss at iteration 2300 : 0.00653645908460021
Loss at iteration 2310 : 0.010308906435966492
Loss at iteration 2320 : 0.011302059516310692
Loss at iteration 2330 : 0.028475288301706314
Loss at iteration 2340 : 0.010729829780757427
Loss at iteration 2350 : 0.02025800198316574
Loss at iteration 2360 : 0.02173428423702717
Loss at iteration 2370 : 0.01493032369762659
Loss at iteration 2380 : 0.01128438487648964
Loss at iteration 2390 : 0.008006271906197071
Loss at iteration 2400 : 0.011008989065885544
Loss at iteration 2410 : 0.014308232814073563
Loss at iteration 2420 : 0.013668535277247429
The SSIM Value is: 0.8363420287768046
The PSNR Value is: 21.066900952657065
the epoch is: 18
Loss at iteration 10 : 0.009680524468421936
Loss at iteration 20 : 0.00894910003989935
Loss at iteration 30 : 0.010907132178544998
Loss at iteration 40 : 0.014250791631639004
Loss at iteration 50 : 0.027958331629633904
Loss at iteration 60 : 0.021227633580565453
Loss at iteration 70 : 0.010481220670044422
Loss at iteration 80 : 0.014042212627828121
Loss at iteration 90 : 0.008759170770645142
Loss at iteration 100 : 0.0047967806458473206
Loss at iteration 110 : 0.021316224709153175
Loss at iteration 120 : 0.007054437417536974
Loss at iteration 130 : 0.012449145317077637
Loss at iteration 140 : 0.007376903668045998
Loss at iteration 150 : 0.00593244144693017
Loss at iteration 160 : 0.017222097143530846
Loss at iteration 170 : 0.013432120904326439
Loss at iteration 180 : 0.01795453578233719
Loss at iteration 190 : 0.004948558285832405
Loss at iteration 200 : 0.008430893532931805
Loss at iteration 210 : 0.01152765192091465
Loss at iteration 220 : 0.011798623949289322
Loss at iteration 230 : 0.008369422517716885
Loss at iteration 240 : 0.014165439642965794
Loss at iteration 250 : 0.021181877702474594
Loss at iteration 260 : 0.010853627696633339
Loss at iteration 270 : 0.012525713071227074
Loss at iteration 280 : 0.006344560533761978
Loss at iteration 290 : 0.008506521582603455
Loss at iteration 300 : 0.014334314502775669
Loss at iteration 310 : 0.007771885022521019
Loss at iteration 320 : 0.015048075467348099
Loss at iteration 330 : 0.009197257459163666
Loss at iteration 340 : 0.02506536804139614
Loss at iteration 350 : 0.022319715470075607
Loss at iteration 360 : 0.01318348664790392
Loss at iteration 370 : 0.016238708049058914
Loss at iteration 380 : 0.025194182991981506
Loss at iteration 390 : 0.027715133503079414
Loss at iteration 400 : 0.016954656690359116
Loss at iteration 410 : 0.01461266539990902
Loss at iteration 420 : 0.010110622271895409
Loss at iteration 430 : 0.014105669222772121
Loss at iteration 440 : 0.01857632026076317
Loss at iteration 450 : 0.011592908762395382
Loss at iteration 460 : 0.011209629476070404
Loss at iteration 470 : 0.008122732862830162
Loss at iteration 480 : 0.01038428582251072
Loss at iteration 490 : 0.006287903990596533
Loss at iteration 500 : 0.009438039734959602
Loss at iteration 510 : 0.009023400023579597
Loss at iteration 520 : 0.017171431332826614
Loss at iteration 530 : 0.005743136629462242
Loss at iteration 540 : 0.00930176954716444
Loss at iteration 550 : 0.018110990524291992
Loss at iteration 560 : 0.010365679860115051
Loss at iteration 570 : 0.018291201442480087
Loss at iteration 580 : 0.009639924392104149
Loss at iteration 590 : 0.006840463727712631
Loss at iteration 600 : 0.0058149839751422405
Loss at iteration 610 : 0.014588722959160805
Loss at iteration 620 : 0.007120200898498297
Loss at iteration 630 : 0.018447395414114
Loss at iteration 640 : 0.008984945714473724
Loss at iteration 650 : 0.01158530730754137
Loss at iteration 660 : 0.022896219044923782
Loss at iteration 670 : 0.003717046231031418
Loss at iteration 680 : 0.017920004203915596
Loss at iteration 690 : 0.008542176336050034
Loss at iteration 700 : 0.009473134763538837
Loss at iteration 710 : 0.010706125758588314
Loss at iteration 720 : 0.0036385804414749146
Loss at iteration 730 : 0.007948502898216248
Loss at iteration 740 : 0.011821987107396126
Loss at iteration 750 : 0.011565031483769417
Loss at iteration 760 : 0.004869633354246616
Loss at iteration 770 : 0.014883068390190601
Loss at iteration 780 : 0.011656196787953377
Loss at iteration 790 : 0.01591978780925274
Loss at iteration 800 : 0.021701250225305557
Loss at iteration 810 : 0.003410791978240013
Loss at iteration 820 : 0.024580594152212143
Loss at iteration 830 : 0.010177060961723328
Loss at iteration 840 : 0.006938295438885689
Loss at iteration 850 : 0.013777329586446285
Loss at iteration 860 : 0.021131593734025955
Loss at iteration 870 : 0.01492907665669918
Loss at iteration 880 : 0.02156774140894413
Loss at iteration 890 : 0.006174027919769287
Loss at iteration 900 : 0.009350513108074665
Loss at iteration 910 : 0.01567167229950428
Loss at iteration 920 : 0.0066715930588543415
Loss at iteration 930 : 0.00970640778541565
Loss at iteration 940 : 0.013374870643019676
Loss at iteration 950 : 0.044542402029037476
Loss at iteration 960 : 0.00625610863789916
Loss at iteration 970 : 0.012929640710353851
Loss at iteration 980 : 0.00907902792096138
Loss at iteration 990 : 0.00598189327865839
Loss at iteration 1000 : 0.011261528357863426
Loss at iteration 1010 : 0.02075362205505371
Loss at iteration 1020 : 0.010651243850588799
Loss at iteration 1030 : 0.00496703339740634
Loss at iteration 1040 : 0.010277352295815945
Loss at iteration 1050 : 0.011807691305875778
Loss at iteration 1060 : 0.015210958197712898
Loss at iteration 1070 : 0.006637020502239466
Loss at iteration 1080 : 0.010984206572175026
Loss at iteration 1090 : 0.008520363830029964
Loss at iteration 1100 : 0.018430981785058975
Loss at iteration 1110 : 0.021454179659485817
Loss at iteration 1120 : 0.013093038462102413
Loss at iteration 1130 : 0.009878618642687798
Loss at iteration 1140 : 0.006209057290107012
Loss at iteration 1150 : 0.018022257834672928
Loss at iteration 1160 : 0.013322354294359684
Loss at iteration 1170 : 0.013406212441623211
Loss at iteration 1180 : 0.008770503103733063
Loss at iteration 1190 : 0.01209238450974226
Loss at iteration 1200 : 0.016080260276794434
Loss at iteration 1210 : 0.013609536923468113
Loss at iteration 1220 : 0.008224563673138618
Loss at iteration 1230 : 0.016450170427560806
Loss at iteration 1240 : 0.019252214580774307
Loss at iteration 1250 : 0.00971542950719595
Loss at iteration 1260 : 0.014722411520779133
Loss at iteration 1270 : 0.008724820800125599
Loss at iteration 1280 : 0.007326257415115833
Loss at iteration 1290 : 0.008905254304409027
Loss at iteration 1300 : 0.007974950596690178
Loss at iteration 1310 : 0.005764724686741829
Loss at iteration 1320 : 0.018135277554392815
Loss at iteration 1330 : 0.011303246021270752
Loss at iteration 1340 : 0.014795903116464615
Loss at iteration 1350 : 0.01346338726580143
Loss at iteration 1360 : 0.012099653482437134
Loss at iteration 1370 : 0.025261109694838524
Loss at iteration 1380 : 0.009012017399072647
Loss at iteration 1390 : 0.005741868633776903
Loss at iteration 1400 : 0.008738109841942787
Loss at iteration 1410 : 0.012871715240180492
Loss at iteration 1420 : 0.010371502488851547
Loss at iteration 1430 : 0.01568925753235817
Loss at iteration 1440 : 0.009748812764883041
Loss at iteration 1450 : 0.01181547436863184
Loss at iteration 1460 : 0.023314395919442177
Loss at iteration 1470 : 0.010090441443026066
Loss at iteration 1480 : 0.010472327470779419
Loss at iteration 1490 : 0.01147130224853754
Loss at iteration 1500 : 0.014580581337213516
Loss at iteration 1510 : 0.009825458750128746
Loss at iteration 1520 : 0.007004475686699152
Loss at iteration 1530 : 0.01590637117624283
Loss at iteration 1540 : 0.003815912874415517
Loss at iteration 1550 : 0.01323741115629673
Loss at iteration 1560 : 0.012438716366887093
Loss at iteration 1570 : 0.012274045497179031
Loss at iteration 1580 : 0.025422044098377228
Loss at iteration 1590 : 0.018324892967939377
Loss at iteration 1600 : 0.012570906430482864
Loss at iteration 1610 : 0.01699240133166313
Loss at iteration 1620 : 0.007465175352990627
Loss at iteration 1630 : 0.010015935637056828
Loss at iteration 1640 : 0.018443096429109573
Loss at iteration 1650 : 0.009676927700638771
Loss at iteration 1660 : 0.009530163370072842
Loss at iteration 1670 : 0.040264859795570374
Loss at iteration 1680 : 0.00877963937819004
Loss at iteration 1690 : 0.007804210763424635
Loss at iteration 1700 : 0.010428456589579582
Loss at iteration 1710 : 0.014041369780898094
Loss at iteration 1720 : 0.012707656249403954
Loss at iteration 1730 : 0.016864441335201263
Loss at iteration 1740 : 0.008528627455234528
Loss at iteration 1750 : 0.012585340067744255
Loss at iteration 1760 : 0.019315233454108238
Loss at iteration 1770 : 0.009019767865538597
Loss at iteration 1780 : 0.01246719155460596
Loss at iteration 1790 : 0.00942949391901493
Loss at iteration 1800 : 0.009178265929222107
Loss at iteration 1810 : 0.014142538420855999
Loss at iteration 1820 : 0.00991196371614933
Loss at iteration 1830 : 0.010788071900606155
Loss at iteration 1840 : 0.006950760260224342
Loss at iteration 1850 : 0.0063689230009913445
Loss at iteration 1860 : 0.004423385486006737
Loss at iteration 1870 : 0.005504217930138111
Loss at iteration 1880 : 0.006407618522644043
Loss at iteration 1890 : 0.009414538741111755
Loss at iteration 1900 : 0.0067545040510594845
Loss at iteration 1910 : 0.019710656255483627
Loss at iteration 1920 : 0.029127657413482666
Loss at iteration 1930 : 0.018189826980233192
Loss at iteration 1940 : 0.009616917930543423
Loss at iteration 1950 : 0.02238846942782402
Loss at iteration 1960 : 0.008492674678564072
Loss at iteration 1970 : 0.01602562516927719
Loss at iteration 1980 : 0.013183270581066608
Loss at iteration 1990 : 0.017467645928263664
Loss at iteration 2000 : 0.011151318438351154
Loss at iteration 2010 : 0.017068050801753998
Loss at iteration 2020 : 0.025036804378032684
Loss at iteration 2030 : 0.00506290327757597
Loss at iteration 2040 : 0.0134690897539258
Loss at iteration 2050 : 0.03369806706905365
Loss at iteration 2060 : 0.009481141343712807
Loss at iteration 2070 : 0.006188640370965004
Loss at iteration 2080 : 0.041752927005290985
Loss at iteration 2090 : 0.01437120046466589
Loss at iteration 2100 : 0.0188981331884861
Loss at iteration 2110 : 0.02271806076169014
Loss at iteration 2120 : 0.005785632878541946
Loss at iteration 2130 : 0.005882208701223135
Loss at iteration 2140 : 0.009311995469033718
Loss at iteration 2150 : 0.014197677373886108
Loss at iteration 2160 : 0.012377733364701271
Loss at iteration 2170 : 0.010780000127851963
Loss at iteration 2180 : 0.007094913627952337
Loss at iteration 2190 : 0.006336780730634928
Loss at iteration 2200 : 0.013352408073842525
Loss at iteration 2210 : 0.008351068012416363
Loss at iteration 2220 : 0.014132615178823471
Loss at iteration 2230 : 0.015278653241693974
Loss at iteration 2240 : 0.004468211904168129
Loss at iteration 2250 : 0.013425027951598167
Loss at iteration 2260 : 0.012165420688688755
Loss at iteration 2270 : 0.023156411945819855
Loss at iteration 2280 : 0.008730188012123108
Loss at iteration 2290 : 0.015700601041316986
Loss at iteration 2300 : 0.012700808234512806
Loss at iteration 2310 : 0.009672937914729118
Loss at iteration 2320 : 0.011487666517496109
Loss at iteration 2330 : 0.005103521980345249
Loss at iteration 2340 : 0.016946062445640564
Loss at iteration 2350 : 0.006431766785681248
Loss at iteration 2360 : 0.015601709485054016
Loss at iteration 2370 : 0.009799005463719368
Loss at iteration 2380 : 0.025665095075964928
Loss at iteration 2390 : 0.012146875262260437
Loss at iteration 2400 : 0.011931387707591057
Loss at iteration 2410 : 0.008215349167585373
Loss at iteration 2420 : 0.011549153365194798
The SSIM Value is: 0.8304831345876058
The PSNR Value is: 22.075115712483726
the highest SSIM value is: 22.075115712483726
the epoch is: 19
Loss at iteration 10 : 0.008918661624193192
Loss at iteration 20 : 0.005723719019442797
Loss at iteration 30 : 0.009038163349032402
Loss at iteration 40 : 0.009249626658856869
Loss at iteration 50 : 0.005416784435510635
Loss at iteration 60 : 0.013835642486810684
Loss at iteration 70 : 0.01072155311703682
Loss at iteration 80 : 0.007654165383428335
Loss at iteration 90 : 0.01106683537364006
Loss at iteration 100 : 0.012972256168723106
Loss at iteration 110 : 0.030532825738191605
Loss at iteration 120 : 0.013185404241085052
Loss at iteration 130 : 0.018634498119354248
Loss at iteration 140 : 0.01508943922817707
Loss at iteration 150 : 0.014114008285105228
Loss at iteration 160 : 0.009784692898392677
Loss at iteration 170 : 0.013514991849660873
Loss at iteration 180 : 0.008996238000690937
Loss at iteration 190 : 0.01741124875843525
Loss at iteration 200 : 0.00496968487277627
Loss at iteration 210 : 0.01185610517859459
Loss at iteration 220 : 0.007853249087929726
Loss at iteration 230 : 0.01742466539144516
Loss at iteration 240 : 0.010020991787314415
Loss at iteration 250 : 0.014005276374518871
Loss at iteration 260 : 0.008887597359716892
Loss at iteration 270 : 0.009974728338420391
Loss at iteration 280 : 0.008144037798047066
Loss at iteration 290 : 0.007720851339399815
Loss at iteration 300 : 0.009819315746426582
Loss at iteration 310 : 0.008142225444316864
Loss at iteration 320 : 0.007479706313461065
Loss at iteration 330 : 0.005606323946267366
Loss at iteration 340 : 0.018177669495344162
Loss at iteration 350 : 0.01565135270357132
Loss at iteration 360 : 0.011553154326975346
Loss at iteration 370 : 0.013413487933576107
Loss at iteration 380 : 0.0059846267104148865
Loss at iteration 390 : 0.011225983500480652
Loss at iteration 400 : 0.01620851457118988
Loss at iteration 410 : 0.0069677759893238544
Loss at iteration 420 : 0.009592466987669468
Loss at iteration 430 : 0.013220379129052162
Loss at iteration 440 : 0.013439234346151352
Loss at iteration 450 : 0.010612990707159042
Loss at iteration 460 : 0.02008052170276642
Loss at iteration 470 : 0.009770108386874199
Loss at iteration 480 : 0.008801252581179142
Loss at iteration 490 : 0.01235300861299038
Loss at iteration 500 : 0.009753955528140068
Loss at iteration 510 : 0.005432912148535252
Loss at iteration 520 : 0.01107542123645544
Loss at iteration 530 : 0.008437865413725376
Loss at iteration 540 : 0.00915701687335968
Loss at iteration 550 : 0.013211844488978386
Loss at iteration 560 : 0.017071373760700226
Loss at iteration 570 : 0.008688878268003464
Loss at iteration 580 : 0.011014120653271675
Loss at iteration 590 : 0.009502355009317398
Loss at iteration 600 : 0.019689207896590233
Loss at iteration 610 : 0.00828552432358265
Loss at iteration 620 : 0.007099769078195095
Loss at iteration 630 : 0.009608069434762001
Loss at iteration 640 : 0.01681694947183132
Loss at iteration 650 : 0.016655562445521355
Loss at iteration 660 : 0.009121439419686794
Loss at iteration 670 : 0.02001226134598255
Loss at iteration 680 : 0.018278980627655983
Loss at iteration 690 : 0.00268696341663599
Loss at iteration 700 : 0.012899789959192276
Loss at iteration 710 : 0.01553933322429657
Loss at iteration 720 : 0.008303754031658173
Loss at iteration 730 : 0.009044625796377659
Loss at iteration 740 : 0.01377321407198906
Loss at iteration 750 : 0.011180277913808823
Loss at iteration 760 : 0.00737448874861002
Loss at iteration 770 : 0.008506083860993385
Loss at iteration 780 : 0.015236090868711472
Loss at iteration 790 : 0.010732726193964481
Loss at iteration 800 : 0.011836424469947815
Loss at iteration 810 : 0.016785182058811188
Loss at iteration 820 : 0.051676809787750244
Loss at iteration 830 : 0.008249852806329727
Loss at iteration 840 : 0.011151701211929321
Loss at iteration 850 : 0.005403381772339344
Loss at iteration 860 : 0.011936020106077194
Loss at iteration 870 : 0.010539820417761803
Loss at iteration 880 : 0.014221462421119213
Loss at iteration 890 : 0.0107119707390666
Loss at iteration 900 : 0.01429339125752449
Loss at iteration 910 : 0.006067206617444754
Loss at iteration 920 : 0.009317212738096714
Loss at iteration 930 : 0.012131229043006897
Loss at iteration 940 : 0.008318671025335789
Loss at iteration 950 : 0.01602800004184246
Loss at iteration 960 : 0.008475388400256634
Loss at iteration 970 : 0.004373467992991209
Loss at iteration 980 : 0.011881649494171143
Loss at iteration 990 : 0.021191436797380447
Loss at iteration 1000 : 0.01392470020800829
Loss at iteration 1010 : 0.01080990955233574
Loss at iteration 1020 : 0.011789191514253616
Loss at iteration 1030 : 0.007983804680407047
Loss at iteration 1040 : 0.011734362691640854
Loss at iteration 1050 : 0.0059617492370307446
Loss at iteration 1060 : 0.005678166635334492
Loss at iteration 1070 : 0.008251093327999115
Loss at iteration 1080 : 0.012355683371424675
Loss at iteration 1090 : 0.01050068624317646
Loss at iteration 1100 : 0.013430322520434856
Loss at iteration 1110 : 0.019367434084415436
Loss at iteration 1120 : 0.010144805535674095
Loss at iteration 1130 : 0.02546689845621586
Loss at iteration 1140 : 0.007929634302854538
Loss at iteration 1150 : 0.010691603645682335
Loss at iteration 1160 : 0.009783154353499413
Loss at iteration 1170 : 0.012728534638881683
Loss at iteration 1180 : 0.010434627532958984
Loss at iteration 1190 : 0.012189116328954697
Loss at iteration 1200 : 0.010996152646839619
Loss at iteration 1210 : 0.008360275067389011
Loss at iteration 1220 : 0.025061428546905518
Loss at iteration 1230 : 0.011598030105233192
Loss at iteration 1240 : 0.015805551782250404
Loss at iteration 1250 : 0.00795016810297966
Loss at iteration 1260 : 0.00992623157799244
Loss at iteration 1270 : 0.011523963883519173
Loss at iteration 1280 : 0.026367247104644775
Loss at iteration 1290 : 0.009407587349414825
Loss at iteration 1300 : 0.02919200249016285
Loss at iteration 1310 : 0.012910641729831696
Loss at iteration 1320 : 0.010233856737613678
Loss at iteration 1330 : 0.017150621861219406
Loss at iteration 1340 : 0.007726194802671671
Loss at iteration 1350 : 0.004490853752940893
Loss at iteration 1360 : 0.021668896079063416
Loss at iteration 1370 : 0.015121528878808022
Loss at iteration 1380 : 0.01226632297039032
Loss at iteration 1390 : 0.017601806670427322
Loss at iteration 1400 : 0.005834619514644146
Loss at iteration 1410 : 0.008780553936958313
Loss at iteration 1420 : 0.019656261429190636
Loss at iteration 1430 : 0.016562752425670624
Loss at iteration 1440 : 0.012783161364495754
Loss at iteration 1450 : 0.008013105019927025
Loss at iteration 1460 : 0.02195674553513527
Loss at iteration 1470 : 0.008318869397044182
Loss at iteration 1480 : 0.009422741830348969
Loss at iteration 1490 : 0.01308518461883068
Loss at iteration 1500 : 0.014009007252752781
Loss at iteration 1510 : 0.019078519195318222
Loss at iteration 1520 : 0.018004750832915306
Loss at iteration 1530 : 0.017097026109695435
Loss at iteration 1540 : 0.012835700064897537
Loss at iteration 1550 : 0.010004603303968906
Loss at iteration 1560 : 0.012369525618851185
Loss at iteration 1570 : 0.00471337977796793
Loss at iteration 1580 : 0.00952903926372528
Loss at iteration 1590 : 0.013382002711296082
Loss at iteration 1600 : 0.009889219887554646
Loss at iteration 1610 : 0.012050792574882507
Loss at iteration 1620 : 0.010309912264347076
Loss at iteration 1630 : 0.007706323638558388
Loss at iteration 1640 : 0.006591807119548321
Loss at iteration 1650 : 0.008256275206804276
Loss at iteration 1660 : 0.011305904015898705
Loss at iteration 1670 : 0.011711782775819302
Loss at iteration 1680 : 0.008869795128703117
Loss at iteration 1690 : 0.01775439642369747
Loss at iteration 1700 : 0.00742673734202981
Loss at iteration 1710 : 0.008306154981255531
Loss at iteration 1720 : 0.009928151033818722
Loss at iteration 1730 : 0.007976504042744637
Loss at iteration 1740 : 0.01195848174393177
Loss at iteration 1750 : 0.024530693888664246
Loss at iteration 1760 : 0.01725328154861927
Loss at iteration 1770 : 0.009993068873882294
Loss at iteration 1780 : 0.010809474624693394
Loss at iteration 1790 : 0.018868332728743553
Loss at iteration 1800 : 0.016025252640247345
Loss at iteration 1810 : 0.009485520422458649
Loss at iteration 1820 : 0.013011264614760876
Loss at iteration 1830 : 0.01669425517320633
Loss at iteration 1840 : 0.012595944106578827
Loss at iteration 1850 : 0.01461130753159523
Loss at iteration 1860 : 0.005044476129114628
Loss at iteration 1870 : 0.015526954084634781
Loss at iteration 1880 : 0.01050863228738308
Loss at iteration 1890 : 0.011236347258090973
Loss at iteration 1900 : 0.0060512772761285305
Loss at iteration 1910 : 0.009624727070331573
Loss at iteration 1920 : 0.015823163092136383
Loss at iteration 1930 : 0.003761805361136794
Loss at iteration 1940 : 0.0074990601278841496
Loss at iteration 1950 : 0.012067713774740696
Loss at iteration 1960 : 0.021124547347426414
Loss at iteration 1970 : 0.01054802443832159
Loss at iteration 1980 : 0.019106199964880943
Loss at iteration 1990 : 0.013588202185928822
Loss at iteration 2000 : 0.006162777077406645
Loss at iteration 2010 : 0.014835303649306297
Loss at iteration 2020 : 0.005937511567026377
Loss at iteration 2030 : 0.005790591239929199
Loss at iteration 2040 : 0.008230130188167095
Loss at iteration 2050 : 0.016373571008443832
Loss at iteration 2060 : 0.009623607620596886
Loss at iteration 2070 : 0.006787335034459829
Loss at iteration 2080 : 0.016352400183677673
Loss at iteration 2090 : 0.005810954608023167
Loss at iteration 2100 : 0.014881348237395287
Loss at iteration 2110 : 0.005759012885391712
Loss at iteration 2120 : 0.015471765771508217
Loss at iteration 2130 : 0.015352068468928337
Loss at iteration 2140 : 0.01438726857304573
Loss at iteration 2150 : 0.00780215859413147
Loss at iteration 2160 : 0.010088274255394936
Loss at iteration 2170 : 0.010716142132878304
Loss at iteration 2180 : 0.008517321199178696
Loss at iteration 2190 : 0.008030178025364876
Loss at iteration 2200 : 0.005475099664181471
Loss at iteration 2210 : 0.011393632739782333
Loss at iteration 2220 : 0.004562828224152327
Loss at iteration 2230 : 0.019747532904148102
Loss at iteration 2240 : 0.007442613132297993
Loss at iteration 2250 : 0.012658365070819855
Loss at iteration 2260 : 0.009279126301407814
Loss at iteration 2270 : 0.016866158694028854
Loss at iteration 2280 : 0.012182521633803844
Loss at iteration 2290 : 0.010794093832373619
Loss at iteration 2300 : 0.014021739363670349
Loss at iteration 2310 : 0.009875170886516571
Loss at iteration 2320 : 0.006617320701479912
Loss at iteration 2330 : 0.01386506762355566
Loss at iteration 2340 : 0.00757219223305583
Loss at iteration 2350 : 0.015834610909223557
Loss at iteration 2360 : 0.030788734555244446
Loss at iteration 2370 : 0.00972540583461523
Loss at iteration 2380 : 0.014556670561432838
Loss at iteration 2390 : 0.006440768484026194
Loss at iteration 2400 : 0.017667248845100403
Loss at iteration 2410 : 0.01548138540238142
Loss at iteration 2420 : 0.01958334632217884
The SSIM Value is: 0.831439757347107
The PSNR Value is: 21.14578940073649
the epoch is: 20
Loss at iteration 10 : 0.00695596681907773
Loss at iteration 20 : 0.009956663474440575
Loss at iteration 30 : 0.008359180763363838
Loss at iteration 40 : 0.010532273910939693
Loss at iteration 50 : 0.01916912943124771
Loss at iteration 60 : 0.014829411171376705
Loss at iteration 70 : 0.017240501940250397
Loss at iteration 80 : 0.0077582309022545815
Loss at iteration 90 : 0.008701374754309654
Loss at iteration 100 : 0.0067656938917934895
Loss at iteration 110 : 0.012619160115718842
Loss at iteration 120 : 0.0063990261405706406
Loss at iteration 130 : 0.008753553032875061
Loss at iteration 140 : 0.007606855593621731
Loss at iteration 150 : 0.011660155840218067
Loss at iteration 160 : 0.015466595068573952
Loss at iteration 170 : 0.011324623599648476
Loss at iteration 180 : 0.013077577576041222
Loss at iteration 190 : 0.012043647468090057
Loss at iteration 200 : 0.007828090339899063
Loss at iteration 210 : 0.01940951496362686
Loss at iteration 220 : 0.022819796577095985
Loss at iteration 230 : 0.006503589451313019
Loss at iteration 240 : 0.014276971109211445
Loss at iteration 250 : 0.012758363969624043
Loss at iteration 260 : 0.014299596659839153
Loss at iteration 270 : 0.004156945738941431
Loss at iteration 280 : 0.010367077775299549
Loss at iteration 290 : 0.011267783120274544
Loss at iteration 300 : 0.01648937165737152
Loss at iteration 310 : 0.009215496480464935
Loss at iteration 320 : 0.017167948186397552
Loss at iteration 330 : 0.007275576703250408
Loss at iteration 340 : 0.007205384783446789
Loss at iteration 350 : 0.0063719237223267555
Loss at iteration 360 : 0.016029195860028267
Loss at iteration 370 : 0.010129106231033802
Loss at iteration 380 : 0.008146274834871292
Loss at iteration 390 : 0.016175653785467148
Loss at iteration 400 : 0.009487444534897804
Loss at iteration 410 : 0.013600006699562073
Loss at iteration 420 : 0.011581665836274624
Loss at iteration 430 : 0.013436248525977135
Loss at iteration 440 : 0.006316258572041988
Loss at iteration 450 : 0.006501241587102413
Loss at iteration 460 : 0.013245679438114166
Loss at iteration 470 : 0.005287894047796726
Loss at iteration 480 : 0.002914218232035637
Loss at iteration 490 : 0.00861628819257021
Loss at iteration 500 : 0.00397520512342453
Loss at iteration 510 : 0.011205000802874565
Loss at iteration 520 : 0.019686758518218994
Loss at iteration 530 : 0.013864627107977867
Loss at iteration 540 : 0.01629185862839222
Loss at iteration 550 : 0.0155481593683362
Loss at iteration 560 : 0.0023821364156901836
Loss at iteration 570 : 0.01290099136531353
Loss at iteration 580 : 0.008207947015762329
Loss at iteration 590 : 0.009535891935229301
Loss at iteration 600 : 0.014747001230716705
Loss at iteration 610 : 0.011468618176877499
Loss at iteration 620 : 0.015328075736761093
Loss at iteration 630 : 0.012352504767477512
Loss at iteration 640 : 0.008900880813598633
Loss at iteration 650 : 0.021317623555660248
Loss at iteration 660 : 0.010026121512055397
Loss at iteration 670 : 0.01521397940814495
Loss at iteration 680 : 0.010729300789535046
Loss at iteration 690 : 0.01979028433561325
Loss at iteration 700 : 0.018190905451774597
Loss at iteration 710 : 0.02869218960404396
Loss at iteration 720 : 0.01737399958074093
Loss at iteration 730 : 0.011070823296904564
Loss at iteration 740 : 0.024543317034840584
Loss at iteration 750 : 0.020039768889546394
Loss at iteration 760 : 0.008457940071821213
Loss at iteration 770 : 0.015512645244598389
Loss at iteration 780 : 0.01380715798586607
Loss at iteration 790 : 0.00595135148614645
Loss at iteration 800 : 0.008180318400263786
Loss at iteration 810 : 0.01967821829020977
Loss at iteration 820 : 0.012586617842316628
Loss at iteration 830 : 0.021472036838531494
Loss at iteration 840 : 0.016290901228785515
Loss at iteration 850 : 0.0045030084438622
Loss at iteration 860 : 0.008748792111873627
Loss at iteration 870 : 0.010494404472410679
Loss at iteration 880 : 0.013066813349723816
Loss at iteration 890 : 0.011228082701563835
Loss at iteration 900 : 0.012016373686492443
Loss at iteration 910 : 0.009183471091091633
Loss at iteration 920 : 0.018967371433973312
Loss at iteration 930 : 0.006865866482257843
Loss at iteration 940 : 0.03246154263615608
Loss at iteration 950 : 0.004885212983936071
Loss at iteration 960 : 0.014422373846173286
Loss at iteration 970 : 0.008705253712832928
Loss at iteration 980 : 0.011962974444031715
Loss at iteration 990 : 0.017783883959054947
Loss at iteration 1000 : 0.015597766265273094
Loss at iteration 1010 : 0.022874221205711365
Loss at iteration 1020 : 0.004753677174448967
Loss at iteration 1030 : 0.013587091118097305
Loss at iteration 1040 : 0.011613696813583374
Loss at iteration 1050 : 0.015140494331717491
Loss at iteration 1060 : 0.014322645962238312
Loss at iteration 1070 : 0.014569365419447422
Loss at iteration 1080 : 0.0126505047082901
Loss at iteration 1090 : 0.011666827835142612
Loss at iteration 1100 : 0.019952621310949326
Loss at iteration 1110 : 0.016814986243844032
Loss at iteration 1120 : 0.019118770956993103
Loss at iteration 1130 : 0.01085544191300869
Loss at iteration 1140 : 0.012197661213576794
Loss at iteration 1150 : 0.01325709093362093
Loss at iteration 1160 : 0.00800371915102005
Loss at iteration 1170 : 0.01653323695063591
Loss at iteration 1180 : 0.013429686427116394
Loss at iteration 1190 : 0.008216305635869503
Loss at iteration 1200 : 0.013812540099024773
Loss at iteration 1210 : 0.01561434380710125
Loss at iteration 1220 : 0.01150558702647686
Loss at iteration 1230 : 0.021632634103298187
Loss at iteration 1240 : 0.005551767535507679
Loss at iteration 1250 : 0.015605774708092213
Loss at iteration 1260 : 0.006267881952226162
Loss at iteration 1270 : 0.012707564979791641
Loss at iteration 1280 : 0.020572148263454437
Loss at iteration 1290 : 0.009996450506150723
Loss at iteration 1300 : 0.008214622735977173
Loss at iteration 1310 : 0.004451247863471508
Loss at iteration 1320 : 0.008986549451947212
Loss at iteration 1330 : 0.012454199604690075
Loss at iteration 1340 : 0.016008533537387848
Loss at iteration 1350 : 0.026097863912582397
Loss at iteration 1360 : 0.006908045616000891
Loss at iteration 1370 : 0.01987832970917225
Loss at iteration 1380 : 0.010577547363936901
Loss at iteration 1390 : 0.007484579458832741
Loss at iteration 1400 : 0.01855621486902237
Loss at iteration 1410 : 0.012419729493558407
Loss at iteration 1420 : 0.01001761481165886
Loss at iteration 1430 : 0.010924299247562885
Loss at iteration 1440 : 0.007504713721573353
Loss at iteration 1450 : 0.011544428765773773
Loss at iteration 1460 : 0.005635715089738369
Loss at iteration 1470 : 0.00881862174719572
Loss at iteration 1480 : 0.002812835155054927
Loss at iteration 1490 : 0.017945528030395508
Loss at iteration 1500 : 0.010603544302284718
Loss at iteration 1510 : 0.009271292015910149
Loss at iteration 1520 : 0.012518277391791344
Loss at iteration 1530 : 0.01061338186264038
Loss at iteration 1540 : 0.030297713354229927
Loss at iteration 1550 : 0.014440948143601418
Loss at iteration 1560 : 0.02392287738621235
Loss at iteration 1570 : 0.021598298102617264
Loss at iteration 1580 : 0.010424748063087463
Loss at iteration 1590 : 0.0161751601845026
Loss at iteration 1600 : 0.008021301589906216
Loss at iteration 1610 : 0.01314551755785942
Loss at iteration 1620 : 0.0063509754836559296
Loss at iteration 1630 : 0.024197187274694443
Loss at iteration 1640 : 0.013002357445657253
Loss at iteration 1650 : 0.006719612516462803
Loss at iteration 1660 : 0.0049608564004302025
Loss at iteration 1670 : 0.008797675371170044
Loss at iteration 1680 : 0.006602010689675808
Loss at iteration 1690 : 0.00785905309021473
Loss at iteration 1700 : 0.015023673884570599
Loss at iteration 1710 : 0.00990482047200203
Loss at iteration 1720 : 0.011847390793263912
Loss at iteration 1730 : 0.012722615152597427
Loss at iteration 1740 : 0.01657891273498535
Loss at iteration 1750 : 0.012058441527187824
Loss at iteration 1760 : 0.009120929054915905
Loss at iteration 1770 : 0.010866673663258553
Loss at iteration 1780 : 0.009093507193028927
Loss at iteration 1790 : 0.008389688096940517
Loss at iteration 1800 : 0.02529681846499443
Loss at iteration 1810 : 0.010807815939188004
Loss at iteration 1820 : 0.01172081008553505
Loss at iteration 1830 : 0.011741261929273605
Loss at iteration 1840 : 0.008023368194699287
Loss at iteration 1850 : 0.020160529762506485
Loss at iteration 1860 : 0.024586878716945648
Loss at iteration 1870 : 0.009159605018794537
Loss at iteration 1880 : 0.009085200726985931
Loss at iteration 1890 : 0.008309746161103249
Loss at iteration 1900 : 0.016136620193719864
Loss at iteration 1910 : 0.008379540406167507
Loss at iteration 1920 : 0.011021400801837444
Loss at iteration 1930 : 0.018488863483071327
Loss at iteration 1940 : 0.014103752560913563
Loss at iteration 1950 : 0.01900355890393257
Loss at iteration 1960 : 0.022379230707883835
Loss at iteration 1970 : 0.019147975370287895
Loss at iteration 1980 : 0.0112773971632123
Loss at iteration 1990 : 0.011823806911706924
Loss at iteration 2000 : 0.01156629715114832
Loss at iteration 2010 : 0.005763314664363861
Loss at iteration 2020 : 0.008042993023991585
Loss at iteration 2030 : 0.01136496476829052
Loss at iteration 2040 : 0.009038727730512619
Loss at iteration 2050 : 0.00904674269258976
Loss at iteration 2060 : 0.008480475284159184
Loss at iteration 2070 : 0.01209043525159359
Loss at iteration 2080 : 0.009902933612465858
Loss at iteration 2090 : 0.016178496181964874
Loss at iteration 2100 : 0.008470847271382809
Loss at iteration 2110 : 0.014230810105800629
Loss at iteration 2120 : 0.019247427582740784
Loss at iteration 2130 : 0.011675208806991577
Loss at iteration 2140 : 0.0050687300972640514
Loss at iteration 2150 : 0.016788974404335022
Loss at iteration 2160 : 0.011932159774005413
Loss at iteration 2170 : 0.014149082824587822
Loss at iteration 2180 : 0.03305216133594513
Loss at iteration 2190 : 0.008283836767077446
Loss at iteration 2200 : 0.009768269956111908
Loss at iteration 2210 : 0.00752594880759716
Loss at iteration 2220 : 0.002302393550053239
Loss at iteration 2230 : 0.023608142510056496
Loss at iteration 2240 : 0.01633673906326294
Loss at iteration 2250 : 0.008478338830173016
Loss at iteration 2260 : 0.011865193024277687
Loss at iteration 2270 : 0.02329379878938198
Loss at iteration 2280 : 0.013900887221097946
Loss at iteration 2290 : 0.0163097120821476
Loss at iteration 2300 : 0.017819715663790703
Loss at iteration 2310 : 0.008905465714633465
Loss at iteration 2320 : 0.00861683115363121
Loss at iteration 2330 : 0.013617613352835178
Loss at iteration 2340 : 0.010760869830846786
Loss at iteration 2350 : 0.023669419810175896
Loss at iteration 2360 : 0.017912888899445534
Loss at iteration 2370 : 0.01591019332408905
Loss at iteration 2380 : 0.02596278488636017
Loss at iteration 2390 : 0.019255774095654488
Loss at iteration 2400 : 0.02029692381620407
Loss at iteration 2410 : 0.016155604273080826
Loss at iteration 2420 : 0.026360923424363136
The SSIM Value is: 0.8315637350082398
The PSNR Value is: 21.492469278971353
the epoch is: 21
Loss at iteration 10 : 0.008192097768187523
Loss at iteration 20 : 0.016350604593753815
Loss at iteration 30 : 0.016682704910635948
Loss at iteration 40 : 0.007224614731967449
Loss at iteration 50 : 0.01022700872272253
Loss at iteration 60 : 0.01543334499001503
Loss at iteration 70 : 0.009746437892317772
Loss at iteration 80 : 0.0051603177562355995
Loss at iteration 90 : 0.012685026973485947
Loss at iteration 100 : 0.009637171402573586
Loss at iteration 110 : 0.008358140476047993
Loss at iteration 120 : 0.008886096067726612
Loss at iteration 130 : 0.013344435021281242
Loss at iteration 140 : 0.01656435988843441
Loss at iteration 150 : 0.006281822454184294
Loss at iteration 160 : 0.007548378314822912
Loss at iteration 170 : 0.006733843125402927
Loss at iteration 180 : 0.011590341106057167
Loss at iteration 190 : 0.012648767791688442
Loss at iteration 200 : 0.014345211908221245
Loss at iteration 210 : 0.008304586634039879
Loss at iteration 220 : 0.00807035993784666
Loss at iteration 230 : 0.008804497309029102
Loss at iteration 240 : 0.01746070198714733
Loss at iteration 250 : 0.0075432127341628075
Loss at iteration 260 : 0.011770964600145817
Loss at iteration 270 : 0.011820618063211441
Loss at iteration 280 : 0.014336113817989826
Loss at iteration 290 : 0.010339162312448025
Loss at iteration 300 : 0.009771854616701603
Loss at iteration 310 : 0.016613544896245003
Loss at iteration 320 : 0.011961862444877625
Loss at iteration 330 : 0.005693071521818638
Loss at iteration 340 : 0.011736433021724224
Loss at iteration 350 : 0.008216029964387417
Loss at iteration 360 : 0.02304461970925331
Loss at iteration 370 : 0.00898097362369299
Loss at iteration 380 : 0.011115789413452148
Loss at iteration 390 : 0.0054502226412296295
Loss at iteration 400 : 0.006245517171919346
Loss at iteration 410 : 0.024241778999567032
Loss at iteration 420 : 0.006628341041505337
Loss at iteration 430 : 0.005897657945752144
Loss at iteration 440 : 0.010021267458796501
Loss at iteration 450 : 0.021211300045251846
Loss at iteration 460 : 0.01745062880218029
Loss at iteration 470 : 0.012138742953538895
Loss at iteration 480 : 0.00575310317799449
Loss at iteration 490 : 0.00792522169649601
Loss at iteration 500 : 0.014855485409498215
Loss at iteration 510 : 0.0075064669363200665
Loss at iteration 520 : 0.009171037003397942
Loss at iteration 530 : 0.010063115507364273
Loss at iteration 540 : 0.021325912326574326
Loss at iteration 550 : 0.018966127187013626
Loss at iteration 560 : 0.011658044531941414
Loss at iteration 570 : 0.010220318101346493
Loss at iteration 580 : 0.007856510579586029
Loss at iteration 590 : 0.014531400986015797
Loss at iteration 600 : 0.025083038955926895
Loss at iteration 610 : 0.010325461626052856
Loss at iteration 620 : 0.007684727199375629
Loss at iteration 630 : 0.02252388373017311
Loss at iteration 640 : 0.008743148297071457
Loss at iteration 650 : 0.01270812377333641
Loss at iteration 660 : 0.012663465924561024
Loss at iteration 670 : 0.010438460856676102
Loss at iteration 680 : 0.02143281139433384
Loss at iteration 690 : 0.009596909396350384
Loss at iteration 700 : 0.005565575789660215
Loss at iteration 710 : 0.007957079447805882
Loss at iteration 720 : 0.01872059889137745
Loss at iteration 730 : 0.00804152712225914
Loss at iteration 740 : 0.015371973626315594
Loss at iteration 750 : 0.017603281885385513
Loss at iteration 760 : 0.02149534597992897
Loss at iteration 770 : 0.010784631595015526
Loss at iteration 780 : 0.017012709751725197
Loss at iteration 790 : 0.020447826012969017
Loss at iteration 800 : 0.015712451189756393
Loss at iteration 810 : 0.0030285981483757496
Loss at iteration 820 : 0.013832343742251396
Loss at iteration 830 : 0.004527228884398937
Loss at iteration 840 : 0.007521714549511671
Loss at iteration 850 : 0.012790631502866745
Loss at iteration 860 : 0.009226176887750626
Loss at iteration 870 : 0.005357296671718359
Loss at iteration 880 : 0.008993647061288357
Loss at iteration 890 : 0.011890921741724014
Loss at iteration 900 : 0.00857779011130333
Loss at iteration 910 : 0.007175551727414131
Loss at iteration 920 : 0.01582137867808342
Loss at iteration 930 : 0.017026158049702644
Loss at iteration 940 : 0.028504587709903717
Loss at iteration 950 : 0.018925238400697708
Loss at iteration 960 : 0.012748746201395988
Loss at iteration 970 : 0.01045645959675312
Loss at iteration 980 : 0.0045653642155230045
Loss at iteration 990 : 0.015575094148516655
Loss at iteration 1000 : 0.026143159717321396
Loss at iteration 1010 : 0.010292869061231613
Loss at iteration 1020 : 0.019149575382471085
Loss at iteration 1030 : 0.010380430147051811
Loss at iteration 1040 : 0.005987988784909248
Loss at iteration 1050 : 0.005059287417680025
Loss at iteration 1060 : 0.023203041404485703
Loss at iteration 1070 : 0.021316535770893097
Loss at iteration 1080 : 0.008468560874462128
Loss at iteration 1090 : 0.012987653724849224
Loss at iteration 1100 : 0.014494240283966064
Loss at iteration 1110 : 0.008373154327273369
Loss at iteration 1120 : 0.007479037158191204
Loss at iteration 1130 : 0.009112630970776081
Loss at iteration 1140 : 0.016105549409985542
Loss at iteration 1150 : 0.004732710309326649
Loss at iteration 1160 : 0.0047989496961236
Loss at iteration 1170 : 0.009867994114756584
Loss at iteration 1180 : 0.010674701072275639
Loss at iteration 1190 : 0.015868287533521652
Loss at iteration 1200 : 0.018092110753059387
Loss at iteration 1210 : 0.010931944474577904
Loss at iteration 1220 : 0.010782536119222641
Loss at iteration 1230 : 0.021135982125997543
Loss at iteration 1240 : 0.008927256800234318
Loss at iteration 1250 : 0.023207463324069977
Loss at iteration 1260 : 0.011343768797814846
Loss at iteration 1270 : 0.012616836465895176
Loss at iteration 1280 : 0.005845723208039999
Loss at iteration 1290 : 0.017165470868349075
Loss at iteration 1300 : 0.008417954668402672
Loss at iteration 1310 : 0.009638945572078228
Loss at iteration 1320 : 0.007067747414112091
Loss at iteration 1330 : 0.02274228259921074
Loss at iteration 1340 : 0.006520755123347044
Loss at iteration 1350 : 0.013338985852897167
Loss at iteration 1360 : 0.015677200630307198
Loss at iteration 1370 : 0.010182608850300312
Loss at iteration 1380 : 0.012134549207985401
Loss at iteration 1390 : 0.01705312356352806
Loss at iteration 1400 : 0.0059932866133749485
Loss at iteration 1410 : 0.008985737338662148
Loss at iteration 1420 : 0.01234872080385685
Loss at iteration 1430 : 0.011675943620502949
Loss at iteration 1440 : 0.01016669999808073
Loss at iteration 1450 : 0.007986839860677719
Loss at iteration 1460 : 0.004217084497213364
Loss at iteration 1470 : 0.006130363326519728
Loss at iteration 1480 : 0.006536412984132767
Loss at iteration 1490 : 0.01461785938590765
Loss at iteration 1500 : 0.010866070166230202
Loss at iteration 1510 : 0.008979701437056065
Loss at iteration 1520 : 0.009683223441243172
Loss at iteration 1530 : 0.012735091149806976
Loss at iteration 1540 : 0.009459199383854866
Loss at iteration 1550 : 0.009099644608795643
Loss at iteration 1560 : 0.007649224251508713
Loss at iteration 1570 : 0.019121870398521423
Loss at iteration 1580 : 0.007276517804712057
Loss at iteration 1590 : 0.010099566541612148
Loss at iteration 1600 : 0.011367903091013432
Loss at iteration 1610 : 0.021934643387794495
Loss at iteration 1620 : 0.03182820975780487
Loss at iteration 1630 : 0.014675281010568142
Loss at iteration 1640 : 0.013900967314839363
Loss at iteration 1650 : 0.007166505791246891
Loss at iteration 1660 : 0.015021205879747868
Loss at iteration 1670 : 0.017299149185419083
Loss at iteration 1680 : 0.005336096044629812
Loss at iteration 1690 : 0.004188382998108864
Loss at iteration 1700 : 0.013679983094334602
Loss at iteration 1710 : 0.010851364582777023
Loss at iteration 1720 : 0.018170157447457314
Loss at iteration 1730 : 0.010637214407324791
Loss at iteration 1740 : 0.012103782035410404
Loss at iteration 1750 : 0.01945631019771099
Loss at iteration 1760 : 0.01901484653353691
Loss at iteration 1770 : 0.007280032150447369
Loss at iteration 1780 : 0.02675708942115307
Loss at iteration 1790 : 0.016882674768567085
Loss at iteration 1800 : 0.007758660241961479
Loss at iteration 1810 : 0.008935343474149704
Loss at iteration 1820 : 0.010749902576208115
Loss at iteration 1830 : 0.005598893389105797
Loss at iteration 1840 : 0.007351078558713198
Loss at iteration 1850 : 0.00833808071911335
Loss at iteration 1860 : 0.008335765451192856
Loss at iteration 1870 : 0.010549018159508705
Loss at iteration 1880 : 0.009909938089549541
Loss at iteration 1890 : 0.01762111857533455
Loss at iteration 1900 : 0.01263782475143671
Loss at iteration 1910 : 0.013719232752919197
Loss at iteration 1920 : 0.012116915546357632
Loss at iteration 1930 : 0.00538130896165967
Loss at iteration 1940 : 0.016138605773448944
Loss at iteration 1950 : 0.008774927817285061
Loss at iteration 1960 : 0.009616280905902386
Loss at iteration 1970 : 0.009680529125034809
Loss at iteration 1980 : 0.014312800951302052
Loss at iteration 1990 : 0.010751258581876755
Loss at iteration 2000 : 0.006903802044689655
Loss at iteration 2010 : 0.01164014171808958
Loss at iteration 2020 : 0.011260666884481907
Loss at iteration 2030 : 0.006791631691157818
Loss at iteration 2040 : 0.010364403016865253
Loss at iteration 2050 : 0.013184966519474983
Loss at iteration 2060 : 0.011583259329199791
Loss at iteration 2070 : 0.014784367755055428
Loss at iteration 2080 : 0.005412379279732704
Loss at iteration 2090 : 0.01193205825984478
Loss at iteration 2100 : 0.011889356188476086
Loss at iteration 2110 : 0.015480836853384972
Loss at iteration 2120 : 0.011685776524245739
Loss at iteration 2130 : 0.017115717753767967
Loss at iteration 2140 : 0.013077820651233196
Loss at iteration 2150 : 0.015189522877335548
Loss at iteration 2160 : 0.0041379984468221664
Loss at iteration 2170 : 0.007927538827061653
Loss at iteration 2180 : 0.005117412656545639
Loss at iteration 2190 : 0.008471252396702766
Loss at iteration 2200 : 0.012770299799740314
Loss at iteration 2210 : 0.015107709914445877
Loss at iteration 2220 : 0.008563077077269554
Loss at iteration 2230 : 0.0065742237493395805
Loss at iteration 2240 : 0.026594582945108414
Loss at iteration 2250 : 0.01821712963283062
Loss at iteration 2260 : 0.013639876618981361
Loss at iteration 2270 : 0.012797544710338116
Loss at iteration 2280 : 0.0036999648436903954
Loss at iteration 2290 : 0.009017405100166798
Loss at iteration 2300 : 0.017836257815361023
Loss at iteration 2310 : 0.008185017853975296
Loss at iteration 2320 : 0.010505493730306625
Loss at iteration 2330 : 0.005408639088273048
Loss at iteration 2340 : 0.02170373499393463
Loss at iteration 2350 : 0.02014603652060032
Loss at iteration 2360 : 0.00537210563197732
Loss at iteration 2370 : 0.007698182947933674
Loss at iteration 2380 : 0.011837582103908062
Loss at iteration 2390 : 0.009092231281101704
Loss at iteration 2400 : 0.010286877863109112
Loss at iteration 2410 : 0.027865465730428696
Loss at iteration 2420 : 0.016194311901926994
The SSIM Value is: 0.8402005314826966
The PSNR Value is: 21.870698547363283
the epoch is: 22
Loss at iteration 10 : 0.023168183863162994
Loss at iteration 20 : 0.00667569087818265
Loss at iteration 30 : 0.005223539192229509
Loss at iteration 40 : 0.006169682368636131
Loss at iteration 50 : 0.006891738623380661
Loss at iteration 60 : 0.015948757529258728
Loss at iteration 70 : 0.012579553760588169
Loss at iteration 80 : 0.016627978533506393
Loss at iteration 90 : 0.01054640393704176
Loss at iteration 100 : 0.010967393405735493
Loss at iteration 110 : 0.014582093805074692
Loss at iteration 120 : 0.01716439612209797
Loss at iteration 130 : 0.008956881240010262
Loss at iteration 140 : 0.009814832359552383
Loss at iteration 150 : 0.005684792064130306
Loss at iteration 160 : 0.014274070039391518
Loss at iteration 170 : 0.011178510263562202
Loss at iteration 180 : 0.015438800677657127
Loss at iteration 190 : 0.007654896937310696
Loss at iteration 200 : 0.012666093185544014
Loss at iteration 210 : 0.01234739925712347
Loss at iteration 220 : 0.00857462827116251
Loss at iteration 230 : 0.017568863928318024
Loss at iteration 240 : 0.010295036248862743
Loss at iteration 250 : 0.026529690250754356
Loss at iteration 260 : 0.010543717071413994
Loss at iteration 270 : 0.008674690499901772
Loss at iteration 280 : 0.008021975867450237
Loss at iteration 290 : 0.010734358802437782
Loss at iteration 300 : 0.01011501532047987
Loss at iteration 310 : 0.009328086860477924
Loss at iteration 320 : 0.00951722078025341
Loss at iteration 330 : 0.015328830108046532
Loss at iteration 340 : 0.006748196668922901
Loss at iteration 350 : 0.01737474836409092
Loss at iteration 360 : 0.010944301262497902
Loss at iteration 370 : 0.015881523489952087
Loss at iteration 380 : 0.013497801497578621
Loss at iteration 390 : 0.009279103949666023
Loss at iteration 400 : 0.02005620487034321
Loss at iteration 410 : 0.01998872309923172
Loss at iteration 420 : 0.012455309741199017
Loss at iteration 430 : 0.012066218070685863
Loss at iteration 440 : 0.01380557008087635
Loss at iteration 450 : 0.018348125740885735
Loss at iteration 460 : 0.006847681477665901
Loss at iteration 470 : 0.005807804875075817
Loss at iteration 480 : 0.01387169398367405
Loss at iteration 490 : 0.018114527687430382
Loss at iteration 500 : 0.03480144962668419
Loss at iteration 510 : 0.011831899173557758
Loss at iteration 520 : 0.006552817299962044
Loss at iteration 530 : 0.00944261159747839
Loss at iteration 540 : 0.024640122428536415
Loss at iteration 550 : 0.009737113490700722
Loss at iteration 560 : 0.01289471983909607
Loss at iteration 570 : 0.009129132144153118
Loss at iteration 580 : 0.010693082585930824
Loss at iteration 590 : 0.00970340147614479
Loss at iteration 600 : 0.012570635415613651
Loss at iteration 610 : 0.012986944057047367
Loss at iteration 620 : 0.014643781818449497
Loss at iteration 630 : 0.013441378250718117
Loss at iteration 640 : 0.009560984559357166
Loss at iteration 650 : 0.025575987994670868
Loss at iteration 660 : 0.016751281917095184
Loss at iteration 670 : 0.025469783693552017
Loss at iteration 680 : 0.013924427330493927
Loss at iteration 690 : 0.02488940954208374
Loss at iteration 700 : 0.04048397019505501
Loss at iteration 710 : 0.017746049910783768
Loss at iteration 720 : 0.007107481826096773
Loss at iteration 730 : 0.013745641335844994
Loss at iteration 740 : 0.01565581001341343
Loss at iteration 750 : 0.01849757507443428
Loss at iteration 760 : 0.009765170514583588
Loss at iteration 770 : 0.007367958780378103
Loss at iteration 780 : 0.011593489907681942
Loss at iteration 790 : 0.008783800527453423
Loss at iteration 800 : 0.008719343692064285
Loss at iteration 810 : 0.006457969546318054
Loss at iteration 820 : 0.01584819331765175
Loss at iteration 830 : 0.016950733959674835
Loss at iteration 840 : 0.009524434804916382
Loss at iteration 850 : 0.004089838825166225
Loss at iteration 860 : 0.017031945288181305
Loss at iteration 870 : 0.01264527440071106
Loss at iteration 880 : 0.01375216618180275
Loss at iteration 890 : 0.015467765741050243
Loss at iteration 900 : 0.018899522721767426
Loss at iteration 910 : 0.014580713585019112
Loss at iteration 920 : 0.012809167616069317
Loss at iteration 930 : 0.010022541508078575
Loss at iteration 940 : 0.006968931760638952
Loss at iteration 950 : 0.010884920135140419
Loss at iteration 960 : 0.008260449394583702
Loss at iteration 970 : 0.012646065093576908
Loss at iteration 980 : 0.00982513464987278
Loss at iteration 990 : 0.010007861070334911
Loss at iteration 1000 : 0.011698082089424133
Loss at iteration 1010 : 0.00821148231625557
Loss at iteration 1020 : 0.022579744458198547
Loss at iteration 1030 : 0.008783337660133839
Loss at iteration 1040 : 0.013283267617225647
Loss at iteration 1050 : 0.02235301397740841
Loss at iteration 1060 : 0.014003441669046879
Loss at iteration 1070 : 0.00648759538307786
Loss at iteration 1080 : 0.018072284758090973
Loss at iteration 1090 : 0.006810392718762159
Loss at iteration 1100 : 0.010004408657550812
Loss at iteration 1110 : 0.007242412306368351
Loss at iteration 1120 : 0.013284498825669289
Loss at iteration 1130 : 0.010932349599897861
Loss at iteration 1140 : 0.014079343527555466
Loss at iteration 1150 : 0.03227373585104942
Loss at iteration 1160 : 0.00822819396853447
Loss at iteration 1170 : 0.00621254974976182
Loss at iteration 1180 : 0.012781217694282532
Loss at iteration 1190 : 0.024496495723724365
Loss at iteration 1200 : 0.008037572726607323
Loss at iteration 1210 : 0.011138401925563812
Loss at iteration 1220 : 0.0071983058005571365
Loss at iteration 1230 : 0.006847713608294725
Loss at iteration 1240 : 0.009211587719619274
Loss at iteration 1250 : 0.006791080813854933
Loss at iteration 1260 : 0.01329568400979042
Loss at iteration 1270 : 0.011952726170420647
Loss at iteration 1280 : 0.005680023692548275
Loss at iteration 1290 : 0.010452352464199066
Loss at iteration 1300 : 0.0173640139400959
Loss at iteration 1310 : 0.011015953496098518
Loss at iteration 1320 : 0.009173406288027763
Loss at iteration 1330 : 0.009334595873951912
Loss at iteration 1340 : 0.016512449830770493
Loss at iteration 1350 : 0.004765732679516077
Loss at iteration 1360 : 0.017634902149438858
Loss at iteration 1370 : 0.015545496717095375
Loss at iteration 1380 : 0.014598775655031204
Loss at iteration 1390 : 0.016345463693141937
Loss at iteration 1400 : 0.012646331451833248
Loss at iteration 1410 : 0.01139990147203207
Loss at iteration 1420 : 0.02173076756298542
Loss at iteration 1430 : 0.01878334954380989
Loss at iteration 1440 : 0.0166020430624485
Loss at iteration 1450 : 0.01640104316174984
Loss at iteration 1460 : 0.008708926849067211
Loss at iteration 1470 : 0.005447858944535255
Loss at iteration 1480 : 0.008211348205804825
Loss at iteration 1490 : 0.009215671569108963
Loss at iteration 1500 : 0.016086824238300323
Loss at iteration 1510 : 0.0075718252919614315
Loss at iteration 1520 : 0.008192399516701698
Loss at iteration 1530 : 0.03576197102665901
Loss at iteration 1540 : 0.011168664321303368
Loss at iteration 1550 : 0.013642992824316025
Loss at iteration 1560 : 0.007420091889798641
Loss at iteration 1570 : 0.012721525505185127
Loss at iteration 1580 : 0.02034289948642254
Loss at iteration 1590 : 0.011361992917954922
Loss at iteration 1600 : 0.011213377118110657
Loss at iteration 1610 : 0.009439877234399319
Loss at iteration 1620 : 0.004934870637953281
Loss at iteration 1630 : 0.016919177025556564
Loss at iteration 1640 : 0.011769764125347137
Loss at iteration 1650 : 0.012720303609967232
Loss at iteration 1660 : 0.006434665992856026
Loss at iteration 1670 : 0.008603915572166443
Loss at iteration 1680 : 0.01042139157652855
Loss at iteration 1690 : 0.007401349954307079
Loss at iteration 1700 : 0.007253550924360752
Loss at iteration 1710 : 0.024694256484508514
Loss at iteration 1720 : 0.006991729140281677
Loss at iteration 1730 : 0.005711284466087818
Loss at iteration 1740 : 0.005650617647916079
Loss at iteration 1750 : 0.016335591673851013
Loss at iteration 1760 : 0.01204638835042715
Loss at iteration 1770 : 0.009834873490035534
Loss at iteration 1780 : 0.02639748901128769
Loss at iteration 1790 : 0.008477393537759781
Loss at iteration 1800 : 0.008996689692139626
Loss at iteration 1810 : 0.022242549806833267
Loss at iteration 1820 : 0.006418586242944002
Loss at iteration 1830 : 0.01758253015577793
Loss at iteration 1840 : 0.010772869922220707
Loss at iteration 1850 : 0.00956396758556366
Loss at iteration 1860 : 0.007583138532936573
Loss at iteration 1870 : 0.011931140907108784
Loss at iteration 1880 : 0.025726009160280228
Loss at iteration 1890 : 0.00854001846164465
Loss at iteration 1900 : 0.022727666422724724
Loss at iteration 1910 : 0.015877172350883484
Loss at iteration 1920 : 0.006401241756975651
Loss at iteration 1930 : 0.013050559908151627
Loss at iteration 1940 : 0.012143610045313835
Loss at iteration 1950 : 0.01429426483809948
Loss at iteration 1960 : 0.011793166399002075
Loss at iteration 1970 : 0.008762631565332413
Loss at iteration 1980 : 0.013665135949850082
Loss at iteration 1990 : 0.007000275421887636
Loss at iteration 2000 : 0.013730097562074661
Loss at iteration 2010 : 0.01185641996562481
Loss at iteration 2020 : 0.0083099864423275
Loss at iteration 2030 : 0.009651917032897472
Loss at iteration 2040 : 0.024509988725185394
Loss at iteration 2050 : 0.011001814156770706
Loss at iteration 2060 : 0.018487485125660896
Loss at iteration 2070 : 0.0053300391882658005
Loss at iteration 2080 : 0.010380284860730171
Loss at iteration 2090 : 0.013679380528628826
Loss at iteration 2100 : 0.015559435822069645
Loss at iteration 2110 : 0.011640354990959167
Loss at iteration 2120 : 0.01311447937041521
Loss at iteration 2130 : 0.01205373089760542
Loss at iteration 2140 : 0.01882063038647175
Loss at iteration 2150 : 0.011501993052661419
Loss at iteration 2160 : 0.008936120197176933
Loss at iteration 2170 : 0.008833272382616997
Loss at iteration 2180 : 0.010495562106370926
Loss at iteration 2190 : 0.016464080661535263
Loss at iteration 2200 : 0.01016224641352892
Loss at iteration 2210 : 0.010693428106606007
Loss at iteration 2220 : 0.0103453379124403
Loss at iteration 2230 : 0.01407572254538536
Loss at iteration 2240 : 0.012796394526958466
Loss at iteration 2250 : 0.02900066040456295
Loss at iteration 2260 : 0.010519983246922493
Loss at iteration 2270 : 0.008805371820926666
Loss at iteration 2280 : 0.012720744125545025
Loss at iteration 2290 : 0.007460195571184158
Loss at iteration 2300 : 0.011065332219004631
Loss at iteration 2310 : 0.011486965231597424
Loss at iteration 2320 : 0.029211556538939476
Loss at iteration 2330 : 0.019150834530591965
Loss at iteration 2340 : 0.007623443379998207
Loss at iteration 2350 : 0.008732433430850506
Loss at iteration 2360 : 0.009149109944701195
Loss at iteration 2370 : 0.011065604165196419
Loss at iteration 2380 : 0.0041713104583323
Loss at iteration 2390 : 0.023609958589076996
Loss at iteration 2400 : 0.017715727910399437
Loss at iteration 2410 : 0.006978713441640139
Loss at iteration 2420 : 0.010517764836549759
The SSIM Value is: 0.8358313957850139
The PSNR Value is: 21.603859011332194
the epoch is: 23
Loss at iteration 10 : 0.014132866635918617
Loss at iteration 20 : 0.011462868191301823
Loss at iteration 30 : 0.009823515079915524
Loss at iteration 40 : 0.007824016734957695
Loss at iteration 50 : 0.015931207686662674
Loss at iteration 60 : 0.0073619713075459
Loss at iteration 70 : 0.010001410730183125
Loss at iteration 80 : 0.012641599401831627
Loss at iteration 90 : 0.006563860923051834
Loss at iteration 100 : 0.01667482778429985
Loss at iteration 110 : 0.009595347568392754
Loss at iteration 120 : 0.01198397297412157
Loss at iteration 130 : 0.013269798830151558
Loss at iteration 140 : 0.016716836020350456
Loss at iteration 150 : 0.01336964312940836
Loss at iteration 160 : 0.008883344009518623
Loss at iteration 170 : 0.017163019627332687
Loss at iteration 180 : 0.015896659344434738
Loss at iteration 190 : 0.009964589960873127
Loss at iteration 200 : 0.0077442931942641735
Loss at iteration 210 : 0.00884912721812725
Loss at iteration 220 : 0.010478707030415535
Loss at iteration 230 : 0.012664517387747765
Loss at iteration 240 : 0.02015501819550991
Loss at iteration 250 : 0.009163297712802887
Loss at iteration 260 : 0.016248716041445732
Loss at iteration 270 : 0.022571120411157608
Loss at iteration 280 : 0.006723707541823387
Loss at iteration 290 : 0.009927249513566494
Loss at iteration 300 : 0.01740468665957451
Loss at iteration 310 : 0.006993508897721767
Loss at iteration 320 : 0.020108986645936966
Loss at iteration 330 : 0.003823306877166033
Loss at iteration 340 : 0.008806773461401463
Loss at iteration 350 : 0.005640505813062191
Loss at iteration 360 : 0.00792872253805399
Loss at iteration 370 : 0.00908938329666853
Loss at iteration 380 : 0.011950945481657982
Loss at iteration 390 : 0.01866230182349682
Loss at iteration 400 : 0.018671073019504547
Loss at iteration 410 : 0.012358244508504868
Loss at iteration 420 : 0.008206445723772049
Loss at iteration 430 : 0.006440197117626667
Loss at iteration 440 : 0.004554769955575466
Loss at iteration 450 : 0.013934013433754444
Loss at iteration 460 : 0.005457875318825245
Loss at iteration 470 : 0.009309712797403336
Loss at iteration 480 : 0.018365036696195602
Loss at iteration 490 : 0.00369378924369812
Loss at iteration 500 : 0.00904318317770958
Loss at iteration 510 : 0.006697953678667545
Loss at iteration 520 : 0.004804122261703014
Loss at iteration 530 : 0.015849368646740913
Loss at iteration 540 : 0.009405108168721199
Loss at iteration 550 : 0.01435895636677742
Loss at iteration 560 : 0.006784692872315645
Loss at iteration 570 : 0.01135721243917942
Loss at iteration 580 : 0.008434291929006577
Loss at iteration 590 : 0.017628278583288193
Loss at iteration 600 : 0.017368551343679428
Loss at iteration 610 : 0.008140507154166698
Loss at iteration 620 : 0.012916572391986847
Loss at iteration 630 : 0.010021913796663284
Loss at iteration 640 : 0.007685315795242786
Loss at iteration 650 : 0.0037535622250288725
Loss at iteration 660 : 0.003768333699554205
Loss at iteration 670 : 0.013601895421743393
Loss at iteration 680 : 0.016042577102780342
Loss at iteration 690 : 0.006994018331170082
Loss at iteration 700 : 0.02477278560400009
Loss at iteration 710 : 0.008115855976939201
Loss at iteration 720 : 0.012640634551644325
Loss at iteration 730 : 0.016308065503835678
Loss at iteration 740 : 0.005408864933997393
Loss at iteration 750 : 0.014784153550863266
Loss at iteration 760 : 0.010068858042359352
Loss at iteration 770 : 0.014556352980434895
Loss at iteration 780 : 0.01870420016348362
Loss at iteration 790 : 0.0029650055803358555
Loss at iteration 800 : 0.02027115970849991
Loss at iteration 810 : 0.008881155401468277
Loss at iteration 820 : 0.0109542366117239
Loss at iteration 830 : 0.007086919620633125
Loss at iteration 840 : 0.01054218877106905
Loss at iteration 850 : 0.020407885313034058
Loss at iteration 860 : 0.007188037503510714
Loss at iteration 870 : 0.010804891586303711
Loss at iteration 880 : 0.017706232145428658
Loss at iteration 890 : 0.0035866503603756428
Loss at iteration 900 : 0.01080002449452877
Loss at iteration 910 : 0.004369539674371481
Loss at iteration 920 : 0.006977294571697712
Loss at iteration 930 : 0.012385422363877296
Loss at iteration 940 : 0.015368703752756119
Loss at iteration 950 : 0.011081934906542301
Loss at iteration 960 : 0.011179730296134949
Loss at iteration 970 : 0.002528863027691841
Loss at iteration 980 : 0.005525294225662947
Loss at iteration 990 : 0.01423615962266922
Loss at iteration 1000 : 0.014471707865595818
Loss at iteration 1010 : 0.004027426242828369
Loss at iteration 1020 : 0.015064699575304985
Loss at iteration 1030 : 0.01867326721549034
Loss at iteration 1040 : 0.008742101490497589
Loss at iteration 1050 : 0.012721002101898193
Loss at iteration 1060 : 0.017505373805761337
Loss at iteration 1070 : 0.0098116435110569
Loss at iteration 1080 : 0.007317599840462208
Loss at iteration 1090 : 0.024106908589601517
Loss at iteration 1100 : 0.00597305316478014
Loss at iteration 1110 : 0.00867942813783884
Loss at iteration 1120 : 0.009550194256007671
Loss at iteration 1130 : 0.010627026669681072
Loss at iteration 1140 : 0.01158837042748928
Loss at iteration 1150 : 0.01842438615858555
Loss at iteration 1160 : 0.0067404345609247684
Loss at iteration 1170 : 0.012425597757101059
Loss at iteration 1180 : 0.01808736100792885
Loss at iteration 1190 : 0.02552046626806259
Loss at iteration 1200 : 0.01571792922914028
Loss at iteration 1210 : 0.011113656684756279
Loss at iteration 1220 : 0.00842031929641962
Loss at iteration 1230 : 0.014015056192874908
Loss at iteration 1240 : 0.018384240567684174
Loss at iteration 1250 : 0.009632980450987816
Loss at iteration 1260 : 0.026355361565947533
Loss at iteration 1270 : 0.008265155367553234
Loss at iteration 1280 : 0.013860984705388546
Loss at iteration 1290 : 0.007974524050951004
Loss at iteration 1300 : 0.011160619556903839
Loss at iteration 1310 : 0.009863230399787426
Loss at iteration 1320 : 0.010149447247385979
Loss at iteration 1330 : 0.004592839628458023
Loss at iteration 1340 : 0.0101202093064785
Loss at iteration 1350 : 0.013257337734103203
Loss at iteration 1360 : 0.00701457355171442
Loss at iteration 1370 : 0.01132233627140522
Loss at iteration 1380 : 0.022383056581020355
Loss at iteration 1390 : 0.004871671088039875
Loss at iteration 1400 : 0.009944606572389603
Loss at iteration 1410 : 0.007253990042954683
Loss at iteration 1420 : 0.008793652057647705
Loss at iteration 1430 : 0.012460396625101566
Loss at iteration 1440 : 0.0157522801309824
Loss at iteration 1450 : 0.008156882598996162
Loss at iteration 1460 : 0.023819439113140106
Loss at iteration 1470 : 0.016993718221783638
Loss at iteration 1480 : 0.007033587899059057
Loss at iteration 1490 : 0.006671793758869171
Loss at iteration 1500 : 0.012591752223670483
Loss at iteration 1510 : 0.021863732486963272
Loss at iteration 1520 : 0.014499563723802567
Loss at iteration 1530 : 0.028247110545635223
Loss at iteration 1540 : 0.007546079345047474
Loss at iteration 1550 : 0.019251542165875435
Loss at iteration 1560 : 0.007495411671698093
Loss at iteration 1570 : 0.009785872884094715
Loss at iteration 1580 : 0.005214724689722061
Loss at iteration 1590 : 0.010994819924235344
Loss at iteration 1600 : 0.011238688603043556
Loss at iteration 1610 : 0.01787109486758709
Loss at iteration 1620 : 0.01542628649622202
Loss at iteration 1630 : 0.008122863247990608
Loss at iteration 1640 : 0.016059748828411102
Loss at iteration 1650 : 0.011420365422964096
Loss at iteration 1660 : 0.006963779218494892
Loss at iteration 1670 : 0.012658169493079185
Loss at iteration 1680 : 0.009472970850765705
Loss at iteration 1690 : 0.019571859389543533
Loss at iteration 1700 : 0.009696736000478268
Loss at iteration 1710 : 0.012794051319360733
Loss at iteration 1720 : 0.010295276530086994
Loss at iteration 1730 : 0.01209246926009655
Loss at iteration 1740 : 0.010167157277464867
Loss at iteration 1750 : 0.008077062666416168
Loss at iteration 1760 : 0.007090817205607891
Loss at iteration 1770 : 0.02359071560204029
Loss at iteration 1780 : 0.0207182876765728
Loss at iteration 1790 : 0.017843224108219147
Loss at iteration 1800 : 0.0049175089225173
Loss at iteration 1810 : 0.012156875804066658
Loss at iteration 1820 : 0.014207716099917889
Loss at iteration 1830 : 0.0042877160012722015
Loss at iteration 1840 : 0.004540605936199427
Loss at iteration 1850 : 0.018969880416989326
Loss at iteration 1860 : 0.015055108815431595
Loss at iteration 1870 : 0.010171455331146717
Loss at iteration 1880 : 0.010254669934511185
Loss at iteration 1890 : 0.017552465200424194
Loss at iteration 1900 : 0.02718871459364891
Loss at iteration 1910 : 0.01849900186061859
Loss at iteration 1920 : 0.010220915079116821
Loss at iteration 1930 : 0.007995126768946648
Loss at iteration 1940 : 0.007753260433673859
Loss at iteration 1950 : 0.016947142779827118
Loss at iteration 1960 : 0.014845470897853374
Loss at iteration 1970 : 0.03327544778585434
Loss at iteration 1980 : 0.006765278056263924
Loss at iteration 1990 : 0.017760885879397392
Loss at iteration 2000 : 0.005524712149053812
Loss at iteration 2010 : 0.024575473740696907
Loss at iteration 2020 : 0.011786529794335365
Loss at iteration 2030 : 0.01135536003857851
Loss at iteration 2040 : 0.011830059811472893
Loss at iteration 2050 : 0.010235060006380081
Loss at iteration 2060 : 0.018961720168590546
Loss at iteration 2070 : 0.016437754034996033
Loss at iteration 2080 : 0.008108085952699184
Loss at iteration 2090 : 0.014488216489553452
Loss at iteration 2100 : 0.01431707851588726
Loss at iteration 2110 : 0.00905564334243536
Loss at iteration 2120 : 0.006713697221130133
Loss at iteration 2130 : 0.008627407252788544
Loss at iteration 2140 : 0.006849158089607954
Loss at iteration 2150 : 0.01615513302385807
Loss at iteration 2160 : 0.014199536293745041
Loss at iteration 2170 : 0.0060080913826823235
Loss at iteration 2180 : 0.01095568761229515
Loss at iteration 2190 : 0.006699956487864256
Loss at iteration 2200 : 0.017511848360300064
Loss at iteration 2210 : 0.005344062112271786
Loss at iteration 2220 : 0.016593314707279205
Loss at iteration 2230 : 0.007617727387696505
Loss at iteration 2240 : 0.004417226649820805
Loss at iteration 2250 : 0.01222506444901228
Loss at iteration 2260 : 0.01327060628682375
Loss at iteration 2270 : 0.007985102944076061
Loss at iteration 2280 : 0.009358156472444534
Loss at iteration 2290 : 0.017512064427137375
Loss at iteration 2300 : 0.013519523665308952
Loss at iteration 2310 : 0.009527640417218208
Loss at iteration 2320 : 0.012588778510689735
Loss at iteration 2330 : 0.009018230251967907
Loss at iteration 2340 : 0.008946436457335949
Loss at iteration 2350 : 0.02105090394616127
Loss at iteration 2360 : 0.006909297779202461
Loss at iteration 2370 : 0.016709107905626297
Loss at iteration 2380 : 0.011465349234640598
Loss at iteration 2390 : 0.00730204489082098
Loss at iteration 2400 : 0.007086152210831642
Loss at iteration 2410 : 0.005028787534683943
Loss at iteration 2420 : 0.019641920924186707
The SSIM Value is: 0.839410932858785
The PSNR Value is: 21.843259811401367
the epoch is: 24
Loss at iteration 10 : 0.015423707664012909
Loss at iteration 20 : 0.014467012137174606
Loss at iteration 30 : 0.009328948333859444
Loss at iteration 40 : 0.009978864341974258
Loss at iteration 50 : 0.010611324571073055
Loss at iteration 60 : 0.013167837634682655
Loss at iteration 70 : 0.007162633817642927
Loss at iteration 80 : 0.02664608135819435
Loss at iteration 90 : 0.01750274933874607
Loss at iteration 100 : 0.009894763119518757
Loss at iteration 110 : 0.006080750375986099
Loss at iteration 120 : 0.006037466693669558
Loss at iteration 130 : 0.014208854176104069
Loss at iteration 140 : 0.0051746973767876625
Loss at iteration 150 : 0.01757897436618805
Loss at iteration 160 : 0.010925953276455402
Loss at iteration 170 : 0.010326149873435497
Loss at iteration 180 : 0.01941223070025444
Loss at iteration 190 : 0.015893692150712013
Loss at iteration 200 : 0.011075543239712715
Loss at iteration 210 : 0.024242360144853592
Loss at iteration 220 : 0.011576969176530838
Loss at iteration 230 : 0.009234197437763214
Loss at iteration 240 : 0.010897868312895298
Loss at iteration 250 : 0.005489315837621689
Loss at iteration 260 : 0.010668384842574596
Loss at iteration 270 : 0.023876864463090897
Loss at iteration 280 : 0.013620728626847267
Loss at iteration 290 : 0.014192720875144005
Loss at iteration 300 : 0.01009693369269371
Loss at iteration 310 : 0.008650144562125206
Loss at iteration 320 : 0.018724199384450912
Loss at iteration 330 : 0.017820637673139572
Loss at iteration 340 : 0.013436639681458473
Loss at iteration 350 : 0.01136007159948349
Loss at iteration 360 : 0.007715157233178616
Loss at iteration 370 : 0.010864131152629852
Loss at iteration 380 : 0.013219938613474369
Loss at iteration 390 : 0.010707654058933258
Loss at iteration 400 : 0.006144764833152294
Loss at iteration 410 : 0.020502129569649696
Loss at iteration 420 : 0.021356046199798584
Loss at iteration 430 : 0.014432080090045929
Loss at iteration 440 : 0.003370721125975251
Loss at iteration 450 : 0.018562747165560722
Loss at iteration 460 : 0.0056826393119990826
Loss at iteration 470 : 0.01336674764752388
Loss at iteration 480 : 0.007213731296360493
Loss at iteration 490 : 0.004895471967756748
Loss at iteration 500 : 0.01138480007648468
Loss at iteration 510 : 0.004921811632812023
Loss at iteration 520 : 0.012777792289853096
Loss at iteration 530 : 0.01113229151815176
Loss at iteration 540 : 0.014231412671506405
Loss at iteration 550 : 0.011514239013195038
Loss at iteration 560 : 0.006524262949824333
Loss at iteration 570 : 0.012533269822597504
Loss at iteration 580 : 0.02135602943599224
Loss at iteration 590 : 0.010388350114226341
Loss at iteration 600 : 0.013175858184695244
Loss at iteration 610 : 0.011461102403700352
Loss at iteration 620 : 0.004417107440531254
Loss at iteration 630 : 0.030809931457042694
Loss at iteration 640 : 0.02122531831264496
Loss at iteration 650 : 0.014623774215579033
Loss at iteration 660 : 0.005133256781846285
Loss at iteration 670 : 0.01762404292821884
Loss at iteration 680 : 0.007772212848067284
Loss at iteration 690 : 0.011406226083636284
Loss at iteration 700 : 0.012829047627747059
Loss at iteration 710 : 0.008297937922179699
Loss at iteration 720 : 0.008131761103868484
Loss at iteration 730 : 0.016471225768327713
Loss at iteration 740 : 0.009554251097142696
Loss at iteration 750 : 0.008631501346826553
Loss at iteration 760 : 0.006336198188364506
Loss at iteration 770 : 0.005816617049276829
Loss at iteration 780 : 0.016126416623592377
Loss at iteration 790 : 0.021404005587100983
Loss at iteration 800 : 0.015431619249284267
Loss at iteration 810 : 0.011520947329699993
Loss at iteration 820 : 0.016897207126021385
Loss at iteration 830 : 0.009836112149059772
Loss at iteration 840 : 0.007971026934683323
Loss at iteration 850 : 0.01847245544195175
Loss at iteration 860 : 0.008881992660462856
Loss at iteration 870 : 0.013966277241706848
Loss at iteration 880 : 0.009440835565328598
Loss at iteration 890 : 0.008678201586008072
Loss at iteration 900 : 0.008599207736551762
Loss at iteration 910 : 0.02003566175699234
Loss at iteration 920 : 0.006489481311291456
Loss at iteration 930 : 0.009732333943247795
Loss at iteration 940 : 0.012275008484721184
Loss at iteration 950 : 0.011198442429304123
Loss at iteration 960 : 0.00852621253579855
Loss at iteration 970 : 0.0213669091463089
Loss at iteration 980 : 0.009149288758635521
Loss at iteration 990 : 0.020172659307718277
Loss at iteration 1000 : 0.013036228716373444
Loss at iteration 1010 : 0.009315084666013718
Loss at iteration 1020 : 0.012086623348295689
Loss at iteration 1030 : 0.014761107042431831
Loss at iteration 1040 : 0.011540770530700684
Loss at iteration 1050 : 0.00796358659863472
Loss at iteration 1060 : 0.017978610470891
Loss at iteration 1070 : 0.017510609701275826
Loss at iteration 1080 : 0.01506715640425682
Loss at iteration 1090 : 0.017513686791062355
Loss at iteration 1100 : 0.008933410979807377
Loss at iteration 1110 : 0.006222857162356377
Loss at iteration 1120 : 0.032317567616701126
Loss at iteration 1130 : 0.011413844302296638
Loss at iteration 1140 : 0.008576294407248497
Loss at iteration 1150 : 0.017209628596901894
Loss at iteration 1160 : 0.008346304297447205
Loss at iteration 1170 : 0.019110701978206635
Loss at iteration 1180 : 0.005153244826942682
Loss at iteration 1190 : 0.010825191624462605
Loss at iteration 1200 : 0.005113197490572929
Loss at iteration 1210 : 0.010160326957702637
Loss at iteration 1220 : 0.006752170622348785
Loss at iteration 1230 : 0.01908300444483757
Loss at iteration 1240 : 0.003724583424627781
Loss at iteration 1250 : 0.00919828750193119
Loss at iteration 1260 : 0.008008869364857674
Loss at iteration 1270 : 0.010862872004508972
Loss at iteration 1280 : 0.013049052096903324
Loss at iteration 1290 : 0.01553194597363472
Loss at iteration 1300 : 0.01492391899228096
Loss at iteration 1310 : 0.024466654285788536
Loss at iteration 1320 : 0.014677241444587708
Loss at iteration 1330 : 0.007082675583660603
Loss at iteration 1340 : 0.01288352906703949
Loss at iteration 1350 : 0.016602303832769394
Loss at iteration 1360 : 0.015061160549521446
Loss at iteration 1370 : 0.010827881284058094
Loss at iteration 1380 : 0.00929342582821846
Loss at iteration 1390 : 0.009910905733704567
Loss at iteration 1400 : 0.007059695199131966
Loss at iteration 1410 : 0.01503753662109375
Loss at iteration 1420 : 0.009057695046067238
Loss at iteration 1430 : 0.016678331419825554
Loss at iteration 1440 : 0.013602368533611298
Loss at iteration 1450 : 0.01616489142179489
Loss at iteration 1460 : 0.01496327668428421
Loss at iteration 1470 : 0.009217223152518272
Loss at iteration 1480 : 0.007466819137334824
Loss at iteration 1490 : 0.013170139864087105
Loss at iteration 1500 : 0.010047036223113537
Loss at iteration 1510 : 0.00949021615087986
Loss at iteration 1520 : 0.005905913654714823
Loss at iteration 1530 : 0.006486258935183287
Loss at iteration 1540 : 0.00725310854613781
Loss at iteration 1550 : 0.007865538820624352
Loss at iteration 1560 : 0.005025471094995737
Loss at iteration 1570 : 0.005271770525723696
Loss at iteration 1580 : 0.007776604034006596
Loss at iteration 1590 : 0.018885362893342972
Loss at iteration 1600 : 0.008124420419335365
Loss at iteration 1610 : 0.023357147350907326
Loss at iteration 1620 : 0.01018590573221445
Loss at iteration 1630 : 0.010538237169384956
Loss at iteration 1640 : 0.007325300946831703
Loss at iteration 1650 : 0.005541282705962658
Loss at iteration 1660 : 0.02252361923456192
Loss at iteration 1670 : 0.013887729495763779
Loss at iteration 1680 : 0.006355723366141319
Loss at iteration 1690 : 0.011895015835762024
Loss at iteration 1700 : 0.018497716635465622
Loss at iteration 1710 : 0.03407420217990875
Loss at iteration 1720 : 0.015232152305543423
Loss at iteration 1730 : 0.016774138435721397
Loss at iteration 1740 : 0.011302321217954159
Loss at iteration 1750 : 0.014137964695692062
Loss at iteration 1760 : 0.014488943852484226
Loss at iteration 1770 : 0.024614330381155014
Loss at iteration 1780 : 0.01986846886575222
Loss at iteration 1790 : 0.01085222139954567
Loss at iteration 1800 : 0.012616661377251148
Loss at iteration 1810 : 0.007911316119134426
Loss at iteration 1820 : 0.013622166588902473
Loss at iteration 1830 : 0.0026414573658257723
Loss at iteration 1840 : 0.00745499599725008
Loss at iteration 1850 : 0.01450294442474842
Loss at iteration 1860 : 0.01259736530482769
Loss at iteration 1870 : 0.007747754920274019
Loss at iteration 1880 : 0.00750095397233963
Loss at iteration 1890 : 0.004565717652440071
Loss at iteration 1900 : 0.013718673959374428
Loss at iteration 1910 : 0.008933795616030693
Loss at iteration 1920 : 0.021831408143043518
Loss at iteration 1930 : 0.0107846325263381
Loss at iteration 1940 : 0.007243345025926828
Loss at iteration 1950 : 0.02063532918691635
Loss at iteration 1960 : 0.00835429597645998
Loss at iteration 1970 : 0.007686822675168514
Loss at iteration 1980 : 0.012396462261676788
Loss at iteration 1990 : 0.008216707035899162
Loss at iteration 2000 : 0.011649226769804955
Loss at iteration 2010 : 0.01423163153231144
Loss at iteration 2020 : 0.005163764581084251
Loss at iteration 2030 : 0.003387665608897805
Loss at iteration 2040 : 0.013512327335774899
Loss at iteration 2050 : 0.01150884572416544
Loss at iteration 2060 : 0.017349030822515488
Loss at iteration 2070 : 0.006927867885679007
Loss at iteration 2080 : 0.010110259987413883
Loss at iteration 2090 : 0.0077563500963151455
Loss at iteration 2100 : 0.009467493742704391
Loss at iteration 2110 : 0.0043536461889743805
Loss at iteration 2120 : 0.011639803647994995
Loss at iteration 2130 : 0.010415280237793922
Loss at iteration 2140 : 0.013990803621709347
Loss at iteration 2150 : 0.006874091923236847
Loss at iteration 2160 : 0.020044803619384766
Loss at iteration 2170 : 0.016404325142502785
Loss at iteration 2180 : 0.010606653988361359
Loss at iteration 2190 : 0.012723692692816257
Loss at iteration 2200 : 0.015523821115493774
Loss at iteration 2210 : 0.014133419841527939
Loss at iteration 2220 : 0.007060897536575794
Loss at iteration 2230 : 0.01698637753725052
Loss at iteration 2240 : 0.008979707956314087
Loss at iteration 2250 : 0.021498220041394234
Loss at iteration 2260 : 0.013440277427434921
Loss at iteration 2270 : 0.01710955612361431
Loss at iteration 2280 : 0.01289319433271885
Loss at iteration 2290 : 0.03219018504023552
Loss at iteration 2300 : 0.00662314472720027
Loss at iteration 2310 : 0.028250277042388916
Loss at iteration 2320 : 0.0056284344755113125
Loss at iteration 2330 : 0.009835169650614262
Loss at iteration 2340 : 0.006364811211824417
Loss at iteration 2350 : 0.009327969513833523
Loss at iteration 2360 : 0.017129546031355858
Loss at iteration 2370 : 0.008101366460323334
Loss at iteration 2380 : 0.0042406730353832245
Loss at iteration 2390 : 0.006853287573903799
Loss at iteration 2400 : 0.009618007577955723
Loss at iteration 2410 : 0.013152801431715488
Loss at iteration 2420 : 0.017783697694540024
The SSIM Value is: 0.8427946170171102
The PSNR Value is: 22.07732302347819
the highest SSIM value is: 22.07732302347819
the epoch is: 25
Loss at iteration 10 : 0.007108055055141449
Loss at iteration 20 : 0.005110043566673994
Loss at iteration 30 : 0.01232009194791317
Loss at iteration 40 : 0.005165678448975086
Loss at iteration 50 : 0.00890218187123537
Loss at iteration 60 : 0.010769043117761612
Loss at iteration 70 : 0.004956055898219347
Loss at iteration 80 : 0.005083783529698849
Loss at iteration 90 : 0.017041346058249474
Loss at iteration 100 : 0.014381603337824345
Loss at iteration 110 : 0.004799624904990196
Loss at iteration 120 : 0.02102367952466011
Loss at iteration 130 : 0.0033412124030292034
Loss at iteration 140 : 0.011694087646901608
Loss at iteration 150 : 0.010738938115537167
Loss at iteration 160 : 0.007135234773159027
Loss at iteration 170 : 0.012866610661149025
Loss at iteration 180 : 0.022832006216049194
Loss at iteration 190 : 0.012674585916101933
Loss at iteration 200 : 0.008730028755962849
Loss at iteration 210 : 0.013784678652882576
Loss at iteration 220 : 0.007315860129892826
Loss at iteration 230 : 0.014952328987419605
Loss at iteration 240 : 0.01855609007179737
Loss at iteration 250 : 0.009136034175753593
Loss at iteration 260 : 0.014981354586780071
Loss at iteration 270 : 0.018735084682703018
Loss at iteration 280 : 0.014108506962656975
Loss at iteration 290 : 0.015197845175862312
Loss at iteration 300 : 0.01315021701157093
Loss at iteration 310 : 0.012976282276213169
Loss at iteration 320 : 0.003415072103962302
Loss at iteration 330 : 0.014694067649543285
Loss at iteration 340 : 0.007535459473729134
Loss at iteration 350 : 0.011399713344871998
Loss at iteration 360 : 0.006692836061120033
Loss at iteration 370 : 0.006943166255950928
Loss at iteration 380 : 0.015650123357772827
Loss at iteration 390 : 0.010484854690730572
Loss at iteration 400 : 0.009675199165940285
Loss at iteration 410 : 0.008959311060607433
Loss at iteration 420 : 0.008845249190926552
Loss at iteration 430 : 0.006460131146013737
Loss at iteration 440 : 0.013137578964233398
Loss at iteration 450 : 0.007467763498425484
Loss at iteration 460 : 0.005010705906897783
Loss at iteration 470 : 0.032637640833854675
Loss at iteration 480 : 0.013488118536770344
Loss at iteration 490 : 0.005938635673373938
Loss at iteration 500 : 0.027805615216493607
Loss at iteration 510 : 0.0163929034024477
Loss at iteration 520 : 0.011553511954843998
Loss at iteration 530 : 0.011133147403597832
Loss at iteration 540 : 0.009508728981018066
Loss at iteration 550 : 0.01331079751253128
Loss at iteration 560 : 0.012402782216668129
Loss at iteration 570 : 0.016704391688108444
Loss at iteration 580 : 0.010845617391169071
Loss at iteration 590 : 0.02043195255100727
Loss at iteration 600 : 0.017758959904313087
Loss at iteration 610 : 0.016119038686156273
Loss at iteration 620 : 0.01225370168685913
Loss at iteration 630 : 0.01040119118988514
Loss at iteration 640 : 0.009719309397041798
Loss at iteration 650 : 0.022445984184741974
Loss at iteration 660 : 0.007640117313712835
Loss at iteration 670 : 0.007396327797323465
Loss at iteration 680 : 0.013602334074676037
Loss at iteration 690 : 0.017349012196063995
Loss at iteration 700 : 0.01038505882024765
Loss at iteration 710 : 0.006615214981138706
Loss at iteration 720 : 0.009586438536643982
Loss at iteration 730 : 0.018326524645090103
Loss at iteration 740 : 0.012487501837313175
Loss at iteration 750 : 0.017965691164135933
Loss at iteration 760 : 0.007790481671690941
Loss at iteration 770 : 0.016550397500395775
Loss at iteration 780 : 0.018214914947748184
Loss at iteration 790 : 0.010890372097492218
Loss at iteration 800 : 0.006349957548081875
Loss at iteration 810 : 0.03887447714805603
Loss at iteration 820 : 0.005425299517810345
Loss at iteration 830 : 0.015154705382883549
Loss at iteration 840 : 0.008665546774864197
Loss at iteration 850 : 0.01141393929719925
Loss at iteration 860 : 0.011300252750515938
Loss at iteration 870 : 0.016429781913757324
Loss at iteration 880 : 0.009307123720645905
Loss at iteration 890 : 0.015743788331747055
Loss at iteration 900 : 0.02669304609298706
Loss at iteration 910 : 0.017453812062740326
Loss at iteration 920 : 0.00608022278174758
Loss at iteration 930 : 0.01529624406248331
Loss at iteration 940 : 0.007474787533283234
Loss at iteration 950 : 0.008906088769435883
Loss at iteration 960 : 0.011073742061853409
Loss at iteration 970 : 0.006445017643272877
Loss at iteration 980 : 0.008866176940500736
Loss at iteration 990 : 0.01449610199779272
Loss at iteration 1000 : 0.008174687623977661
Loss at iteration 1010 : 0.011873608455061913
Loss at iteration 1020 : 0.00530246552079916
Loss at iteration 1030 : 0.014757214114069939
Loss at iteration 1040 : 0.018271539360284805
Loss at iteration 1050 : 0.02013132907450199
Loss at iteration 1060 : 0.009814850986003876
Loss at iteration 1070 : 0.006133026909083128
Loss at iteration 1080 : 0.015023797750473022
Loss at iteration 1090 : 0.008067460730671883
Loss at iteration 1100 : 0.024485990405082703
Loss at iteration 1110 : 0.010959899052977562
Loss at iteration 1120 : 0.007279121782630682
Loss at iteration 1130 : 0.0048630256205797195
Loss at iteration 1140 : 0.012837951071560383
Loss at iteration 1150 : 0.01921658031642437
Loss at iteration 1160 : 0.01484766136854887
Loss at iteration 1170 : 0.0036256967578083277
Loss at iteration 1180 : 0.00921774934977293
Loss at iteration 1190 : 0.010106307454407215
Loss at iteration 1200 : 0.009318667463958263
Loss at iteration 1210 : 0.013173617422580719
Loss at iteration 1220 : 0.0169210284948349
Loss at iteration 1230 : 0.015076722949743271
Loss at iteration 1240 : 0.01848224364221096
Loss at iteration 1250 : 0.007892304100096226
Loss at iteration 1260 : 0.007525337859988213
Loss at iteration 1270 : 0.01601794734597206
Loss at iteration 1280 : 0.01360197365283966
Loss at iteration 1290 : 0.012857885099947453
Loss at iteration 1300 : 0.018960505723953247
Loss at iteration 1310 : 0.007412291131913662
Loss at iteration 1320 : 0.00593156460672617
Loss at iteration 1330 : 0.01483315508812666
Loss at iteration 1340 : 0.01891406439244747
Loss at iteration 1350 : 0.010882397182285786
Loss at iteration 1360 : 0.012362442910671234
Loss at iteration 1370 : 0.013405347242951393
Loss at iteration 1380 : 0.009626941755414009
Loss at iteration 1390 : 0.01963689550757408
Loss at iteration 1400 : 0.008146721869707108
Loss at iteration 1410 : 0.020714443176984787
Loss at iteration 1420 : 0.0061408160254359245
Loss at iteration 1430 : 0.008027439005672932
Loss at iteration 1440 : 0.006358362268656492
Loss at iteration 1450 : 0.021943148225545883
Loss at iteration 1460 : 0.0048532341606915
Loss at iteration 1470 : 0.01994129829108715
Loss at iteration 1480 : 0.019632158800959587
Loss at iteration 1490 : 0.013175947591662407
Loss at iteration 1500 : 0.008516049943864346
Loss at iteration 1510 : 0.007221829146146774
Loss at iteration 1520 : 0.009451179765164852
Loss at iteration 1530 : 0.006485249847173691
Loss at iteration 1540 : 0.009112918749451637
Loss at iteration 1550 : 0.009025239385664463
Loss at iteration 1560 : 0.005994968116283417
Loss at iteration 1570 : 0.013795215636491776
Loss at iteration 1580 : 0.010862407274544239
Loss at iteration 1590 : 0.0056296056136488914
Loss at iteration 1600 : 0.017159704118967056
Loss at iteration 1610 : 0.015032623894512653
Loss at iteration 1620 : 0.009818919003009796
Loss at iteration 1630 : 0.010636796243488789
Loss at iteration 1640 : 0.009970221668481827
Loss at iteration 1650 : 0.009791897609829903
Loss at iteration 1660 : 0.008685793727636337
Loss at iteration 1670 : 0.016948021948337555
Loss at iteration 1680 : 0.016573309898376465
Loss at iteration 1690 : 0.011272596195340157
Loss at iteration 1700 : 0.016207849606871605
Loss at iteration 1710 : 0.014210840687155724
Loss at iteration 1720 : 0.018005715683102608
Loss at iteration 1730 : 0.012455390766263008
Loss at iteration 1740 : 0.025936879217624664
Loss at iteration 1750 : 0.00984937883913517
Loss at iteration 1760 : 0.00969371572136879
Loss at iteration 1770 : 0.006887007970362902
Loss at iteration 1780 : 0.00631384551525116
Loss at iteration 1790 : 0.01572340540587902
Loss at iteration 1800 : 0.009154317900538445
Loss at iteration 1810 : 0.011991804465651512
Loss at iteration 1820 : 0.013842999003827572
Loss at iteration 1830 : 0.007919400930404663
Loss at iteration 1840 : 0.022138791158795357
Loss at iteration 1850 : 0.007942307740449905
Loss at iteration 1860 : 0.00803836714476347
Loss at iteration 1870 : 0.005673578474670649
Loss at iteration 1880 : 0.010174568742513657
Loss at iteration 1890 : 0.009138141758739948
Loss at iteration 1900 : 0.004966402892023325
Loss at iteration 1910 : 0.009261640720069408
Loss at iteration 1920 : 0.009382909163832664
Loss at iteration 1930 : 0.008503088727593422
Loss at iteration 1940 : 0.008317212574183941
Loss at iteration 1950 : 0.006813238374888897
Loss at iteration 1960 : 0.01426031906157732
Loss at iteration 1970 : 0.008948514237999916
Loss at iteration 1980 : 0.025649946182966232
Loss at iteration 1990 : 0.0029226590413600206
Loss at iteration 2000 : 0.015838559716939926
Loss at iteration 2010 : 0.011289186775684357
Loss at iteration 2020 : 0.021850649267435074
Loss at iteration 2030 : 0.005275261122733355
Loss at iteration 2040 : 0.008762567304074764
Loss at iteration 2050 : 0.006230485625565052
Loss at iteration 2060 : 0.006095137447118759
Loss at iteration 2070 : 0.024767424911260605
Loss at iteration 2080 : 0.007538557983934879
Loss at iteration 2090 : 0.0034418923314660788
Loss at iteration 2100 : 0.014415048062801361
Loss at iteration 2110 : 0.024801596999168396
Loss at iteration 2120 : 0.005360767245292664
Loss at iteration 2130 : 0.015143416821956635
Loss at iteration 2140 : 0.008105176500976086
Loss at iteration 2150 : 0.009997534565627575
Loss at iteration 2160 : 0.011743951588869095
Loss at iteration 2170 : 0.012919044122099876
Loss at iteration 2180 : 0.01771954819560051
Loss at iteration 2190 : 0.011060145683586597
Loss at iteration 2200 : 0.018030602484941483
Loss at iteration 2210 : 0.011040478944778442
Loss at iteration 2220 : 0.0183847788721323
Loss at iteration 2230 : 0.010665055364370346
Loss at iteration 2240 : 0.009911862201988697
Loss at iteration 2250 : 0.016088781878352165
Loss at iteration 2260 : 0.016917891800403595
Loss at iteration 2270 : 0.012231431901454926
Loss at iteration 2280 : 0.019430484622716904
Loss at iteration 2290 : 0.023993927985429764
Loss at iteration 2300 : 0.007043124176561832
Loss at iteration 2310 : 0.007687832694500685
Loss at iteration 2320 : 0.009893335402011871
Loss at iteration 2330 : 0.009511604905128479
Loss at iteration 2340 : 0.011327498592436314
Loss at iteration 2350 : 0.008244442753493786
Loss at iteration 2360 : 0.012163156643509865
Loss at iteration 2370 : 0.010300209745764732
Loss at iteration 2380 : 0.01241216529160738
Loss at iteration 2390 : 0.00950317271053791
Loss at iteration 2400 : 0.013169902376830578
Loss at iteration 2410 : 0.01369098573923111
Loss at iteration 2420 : 0.013319456949830055
The SSIM Value is: 0.8452985167503357
The PSNR Value is: 22.735370254516603
the highest SSIM value is: 22.735370254516603
the epoch is: 26
Loss at iteration 10 : 0.009654784575104713
Loss at iteration 20 : 0.0239332877099514
Loss at iteration 30 : 0.01043936051428318
Loss at iteration 40 : 0.007748207543045282
Loss at iteration 50 : 0.004357621539384127
Loss at iteration 60 : 0.010583553463220596
Loss at iteration 70 : 0.011307905428111553
Loss at iteration 80 : 0.011878272518515587
Loss at iteration 90 : 0.023115020245313644
Loss at iteration 100 : 0.008027888834476471
Loss at iteration 110 : 0.020490113645792007
Loss at iteration 120 : 0.012411754578351974
Loss at iteration 130 : 0.011013820767402649
Loss at iteration 140 : 0.005657216999679804
Loss at iteration 150 : 0.01990753784775734
Loss at iteration 160 : 0.003466543974354863
Loss at iteration 170 : 0.022236280143260956
Loss at iteration 180 : 0.006305304355919361
Loss at iteration 190 : 0.008358939550817013
Loss at iteration 200 : 0.013718077912926674
Loss at iteration 210 : 0.01841137558221817
Loss at iteration 220 : 0.01778186298906803
Loss at iteration 230 : 0.009806978516280651
Loss at iteration 240 : 0.014656256884336472
Loss at iteration 250 : 0.008183450438082218
Loss at iteration 260 : 0.011871116235852242
Loss at iteration 270 : 0.02001495473086834
Loss at iteration 280 : 0.02325308695435524
Loss at iteration 290 : 0.010732547380030155
Loss at iteration 300 : 0.016760678961873055
Loss at iteration 310 : 0.01380409486591816
Loss at iteration 320 : 0.009706632234156132
Loss at iteration 330 : 0.014068026095628738
Loss at iteration 340 : 0.011620879173278809
Loss at iteration 350 : 0.015288397669792175
Loss at iteration 360 : 0.011042963713407516
Loss at iteration 370 : 0.0052697244100272655
Loss at iteration 380 : 0.013077600859105587
Loss at iteration 390 : 0.01135263405740261
Loss at iteration 400 : 0.006940682418644428
Loss at iteration 410 : 0.008692353963851929
Loss at iteration 420 : 0.014094271697103977
Loss at iteration 430 : 0.0045080240815877914
Loss at iteration 440 : 0.016274791210889816
Loss at iteration 450 : 0.00649294862523675
Loss at iteration 460 : 0.004116922616958618
Loss at iteration 470 : 0.018082456663250923
Loss at iteration 480 : 0.004251922946423292
Loss at iteration 490 : 0.008342338725924492
Loss at iteration 500 : 0.016060883179306984
Loss at iteration 510 : 0.04038098827004433
Loss at iteration 520 : 0.008006874471902847
Loss at iteration 530 : 0.009720847941935062
Loss at iteration 540 : 0.010964038781821728
Loss at iteration 550 : 0.010429106652736664
Loss at iteration 560 : 0.016551557928323746
Loss at iteration 570 : 0.03597702831029892
Loss at iteration 580 : 0.01794450357556343
Loss at iteration 590 : 0.013082676567137241
Loss at iteration 600 : 0.009381093084812164
Loss at iteration 610 : 0.009989938698709011
Loss at iteration 620 : 0.015829212963581085
Loss at iteration 630 : 0.007279861718416214
Loss at iteration 640 : 0.017675820738077164
Loss at iteration 650 : 0.015707679092884064
Loss at iteration 660 : 0.008779408410191536
Loss at iteration 670 : 0.01038697361946106
Loss at iteration 680 : 0.011088913306593895
Loss at iteration 690 : 0.011457275599241257
Loss at iteration 700 : 0.032558880746364594
Loss at iteration 710 : 0.027582749724388123
Loss at iteration 720 : 0.015542196109890938
Loss at iteration 730 : 0.01314772479236126
Loss at iteration 740 : 0.009729256853461266
Loss at iteration 750 : 0.018650468438863754
Loss at iteration 760 : 0.005385173484683037
Loss at iteration 770 : 0.019147861748933792
Loss at iteration 780 : 0.00659631984308362
Loss at iteration 790 : 0.051029592752456665
Loss at iteration 800 : 0.012574851512908936
Loss at iteration 810 : 0.01168252993375063
Loss at iteration 820 : 0.01909342035651207
Loss at iteration 830 : 0.010626371949911118
Loss at iteration 840 : 0.016825957223773003
Loss at iteration 850 : 0.009346513077616692
Loss at iteration 860 : 0.014185349456965923
Loss at iteration 870 : 0.009579652920365334
Loss at iteration 880 : 0.016773302108049393
Loss at iteration 890 : 0.01810029149055481
Loss at iteration 900 : 0.007417287677526474
Loss at iteration 910 : 0.01054314710199833
Loss at iteration 920 : 0.018115855753421783
Loss at iteration 930 : 0.008969268761575222
Loss at iteration 940 : 0.008195667527616024
Loss at iteration 950 : 0.013511937111616135
Loss at iteration 960 : 0.00674546929076314
Loss at iteration 970 : 0.013355275616049767
Loss at iteration 980 : 0.030290968716144562
Loss at iteration 990 : 0.012005607597529888
Loss at iteration 1000 : 0.0079807685688138
Loss at iteration 1010 : 0.024716738611459732
Loss at iteration 1020 : 0.012421520426869392
Loss at iteration 1030 : 0.010944729670882225
Loss at iteration 1040 : 0.006939475424587727
Loss at iteration 1050 : 0.020103691145777702
Loss at iteration 1060 : 0.006089873146265745
Loss at iteration 1070 : 0.014435401186347008
Loss at iteration 1080 : 0.013093560934066772
Loss at iteration 1090 : 0.007234138436615467
Loss at iteration 1100 : 0.024624615907669067
Loss at iteration 1110 : 0.015358145348727703
Loss at iteration 1120 : 0.01265723630785942
Loss at iteration 1130 : 0.008949480950832367
Loss at iteration 1140 : 0.008008330129086971
Loss at iteration 1150 : 0.016850832849740982
Loss at iteration 1160 : 0.014889182522892952
Loss at iteration 1170 : 0.010871239006519318
Loss at iteration 1180 : 0.0076081408187747
Loss at iteration 1190 : 0.006319163367152214
Loss at iteration 1200 : 0.009058959782123566
Loss at iteration 1210 : 0.009583041071891785
Loss at iteration 1220 : 0.005938003305345774
Loss at iteration 1230 : 0.0034768725745379925
Loss at iteration 1240 : 0.00794246420264244
Loss at iteration 1250 : 0.008145259693264961
Loss at iteration 1260 : 0.00739337457343936
Loss at iteration 1270 : 0.021469132974743843
Loss at iteration 1280 : 0.009386821649968624
Loss at iteration 1290 : 0.005505886860191822
Loss at iteration 1300 : 0.018583234399557114
Loss at iteration 1310 : 0.016012921929359436
Loss at iteration 1320 : 0.011931415647268295
Loss at iteration 1330 : 0.015403088182210922
Loss at iteration 1340 : 0.016534538939595222
Loss at iteration 1350 : 0.01549320388585329
Loss at iteration 1360 : 0.02777070179581642
Loss at iteration 1370 : 0.008764879778027534
Loss at iteration 1380 : 0.016257677227258682
Loss at iteration 1390 : 0.008981367573142052
Loss at iteration 1400 : 0.0069963037967681885
Loss at iteration 1410 : 0.011290738359093666
Loss at iteration 1420 : 0.016553698107600212
Loss at iteration 1430 : 0.009395284578204155
Loss at iteration 1440 : 0.021576572209596634
Loss at iteration 1450 : 0.010351566597819328
Loss at iteration 1460 : 0.00876626092940569
Loss at iteration 1470 : 0.006458076182752848
Loss at iteration 1480 : 0.014102977700531483
Loss at iteration 1490 : 0.010987157002091408
Loss at iteration 1500 : 0.005772327538579702
Loss at iteration 1510 : 0.006336849182844162
Loss at iteration 1520 : 0.00891834031790495
Loss at iteration 1530 : 0.014027601107954979
Loss at iteration 1540 : 0.0063973963260650635
Loss at iteration 1550 : 0.010011003352701664
Loss at iteration 1560 : 0.012217814102768898
Loss at iteration 1570 : 0.00843735784292221
Loss at iteration 1580 : 0.011836846359074116
Loss at iteration 1590 : 0.008256008848547935
Loss at iteration 1600 : 0.011129640974104404
Loss at iteration 1610 : 0.014621204696595669
Loss at iteration 1620 : 0.016618892550468445
Loss at iteration 1630 : 0.008426323533058167
Loss at iteration 1640 : 0.009103705175220966
Loss at iteration 1650 : 0.012501668184995651
Loss at iteration 1660 : 0.016264867037534714
Loss at iteration 1670 : 0.010278790257871151
Loss at iteration 1680 : 0.010236035101115704
Loss at iteration 1690 : 0.006487627048045397
Loss at iteration 1700 : 0.00918915867805481
Loss at iteration 1710 : 0.01390753872692585
Loss at iteration 1720 : 0.012318037450313568
Loss at iteration 1730 : 0.007054880261421204
Loss at iteration 1740 : 0.007819093763828278
Loss at iteration 1750 : 0.01113879308104515
Loss at iteration 1760 : 0.016723332926630974
Loss at iteration 1770 : 0.02288109064102173
Loss at iteration 1780 : 0.0053972480818629265
Loss at iteration 1790 : 0.005680350586771965
Loss at iteration 1800 : 0.00988355465233326
Loss at iteration 1810 : 0.011714146472513676
Loss at iteration 1820 : 0.012666055001318455
Loss at iteration 1830 : 0.015228291973471642
Loss at iteration 1840 : 0.00844908319413662
Loss at iteration 1850 : 0.0148451067507267
Loss at iteration 1860 : 0.01222198735922575
Loss at iteration 1870 : 0.0224123764783144
Loss at iteration 1880 : 0.008154167793691158
Loss at iteration 1890 : 0.0054353708401322365
Loss at iteration 1900 : 0.012840952724218369
Loss at iteration 1910 : 0.014598163776099682
Loss at iteration 1920 : 0.007013021968305111
Loss at iteration 1930 : 0.008501723408699036
Loss at iteration 1940 : 0.01345188170671463
Loss at iteration 1950 : 0.006545837968587875
Loss at iteration 1960 : 0.012843219563364983
Loss at iteration 1970 : 0.008560855872929096
Loss at iteration 1980 : 0.01055085938423872
Loss at iteration 1990 : 0.008478411473333836
Loss at iteration 2000 : 0.010553242638707161
Loss at iteration 2010 : 0.00978369265794754
Loss at iteration 2020 : 0.016604352742433548
Loss at iteration 2030 : 0.0037395793478935957
Loss at iteration 2040 : 0.009953256696462631
Loss at iteration 2050 : 0.012281876057386398
Loss at iteration 2060 : 0.019014645367860794
Loss at iteration 2070 : 0.014788812026381493
Loss at iteration 2080 : 0.013574260286986828
Loss at iteration 2090 : 0.01420935895293951
Loss at iteration 2100 : 0.010386665351688862
Loss at iteration 2110 : 0.010963954962790012
Loss at iteration 2120 : 0.013669565320014954
Loss at iteration 2130 : 0.0039879498071968555
Loss at iteration 2140 : 0.006987623870372772
Loss at iteration 2150 : 0.007625642232596874
Loss at iteration 2160 : 0.013795793987810612
Loss at iteration 2170 : 0.014283960685133934
Loss at iteration 2180 : 0.015092886984348297
Loss at iteration 2190 : 0.01167321391403675
Loss at iteration 2200 : 0.014453529380261898
Loss at iteration 2210 : 0.016111057251691818
Loss at iteration 2220 : 0.004740899428725243
Loss at iteration 2230 : 0.014220962300896645
Loss at iteration 2240 : 0.014623046852648258
Loss at iteration 2250 : 0.011401770636439323
Loss at iteration 2260 : 0.010123040527105331
Loss at iteration 2270 : 0.009830929338932037
Loss at iteration 2280 : 0.01307554543018341
Loss at iteration 2290 : 0.0077656954526901245
Loss at iteration 2300 : 0.007118736393749714
Loss at iteration 2310 : 0.008422420360147953
Loss at iteration 2320 : 0.01579780876636505
Loss at iteration 2330 : 0.012597775086760521
Loss at iteration 2340 : 0.010394361801445484
Loss at iteration 2350 : 0.014118689112365246
Loss at iteration 2360 : 0.005896246992051601
Loss at iteration 2370 : 0.009225340560078621
Loss at iteration 2380 : 0.012885263189673424
Loss at iteration 2390 : 0.023413214832544327
Loss at iteration 2400 : 0.01003577746450901
Loss at iteration 2410 : 0.009309478104114532
Loss at iteration 2420 : 0.011111180298030376
The SSIM Value is: 0.8416346430778503
The PSNR Value is: 22.109147389729817
the epoch is: 27
Loss at iteration 10 : 0.008538403548300266
Loss at iteration 20 : 0.012276258319616318
Loss at iteration 30 : 0.007618235889822245
Loss at iteration 40 : 0.0074157193303108215
Loss at iteration 50 : 0.007311960682272911
Loss at iteration 60 : 0.007926109246909618
Loss at iteration 70 : 0.013466723263263702
Loss at iteration 80 : 0.005079746246337891
Loss at iteration 90 : 0.005609706975519657
Loss at iteration 100 : 0.015011037699878216
Loss at iteration 110 : 0.01646067574620247
Loss at iteration 120 : 0.02279019169509411
Loss at iteration 130 : 0.01973244547843933
Loss at iteration 140 : 0.01123783178627491
Loss at iteration 150 : 0.01156090572476387
Loss at iteration 160 : 0.020661091431975365
Loss at iteration 170 : 0.006495539098978043
Loss at iteration 180 : 0.010247478261590004
Loss at iteration 190 : 0.011698475107550621
Loss at iteration 200 : 0.004686601459980011
Loss at iteration 210 : 0.01371932402253151
Loss at iteration 220 : 0.007698356173932552
Loss at iteration 230 : 0.01726452074944973
Loss at iteration 240 : 0.010793427936732769
Loss at iteration 250 : 0.0175681971013546
Loss at iteration 260 : 0.007582060061395168
Loss at iteration 270 : 0.014439010992646217
Loss at iteration 280 : 0.01958409883081913
Loss at iteration 290 : 0.014704366214573383
Loss at iteration 300 : 0.010435055941343307
Loss at iteration 310 : 0.011887890286743641
Loss at iteration 320 : 0.015545407310128212
Loss at iteration 330 : 0.010735287331044674
Loss at iteration 340 : 0.01135150995105505
Loss at iteration 350 : 0.007784920744597912
Loss at iteration 360 : 0.013190708123147488
Loss at iteration 370 : 0.021740596741437912
Loss at iteration 380 : 0.0060382261872291565
Loss at iteration 390 : 0.012049318291246891
Loss at iteration 400 : 0.01658494584262371
Loss at iteration 410 : 0.005391786806285381
Loss at iteration 420 : 0.009824718348681927
Loss at iteration 430 : 0.007942885160446167
Loss at iteration 440 : 0.007272977381944656
Loss at iteration 450 : 0.009490804746747017
Loss at iteration 460 : 0.01219760999083519
Loss at iteration 470 : 0.02142459526658058
Loss at iteration 480 : 0.006378891412168741
Loss at iteration 490 : 0.010296686552464962
Loss at iteration 500 : 0.010678960010409355
Loss at iteration 510 : 0.015481940470635891
Loss at iteration 520 : 0.0076284888200461864
Loss at iteration 530 : 0.013830669224262238
Loss at iteration 540 : 0.012494823895394802
Loss at iteration 550 : 0.015793083235621452
Loss at iteration 560 : 0.012064274400472641
Loss at iteration 570 : 0.0048618009313941
Loss at iteration 580 : 0.011484596878290176
Loss at iteration 590 : 0.021838271990418434
Loss at iteration 600 : 0.010393300093710423
Loss at iteration 610 : 0.009451624006032944
Loss at iteration 620 : 0.004790330771356821
Loss at iteration 630 : 0.007863789796829224
Loss at iteration 640 : 0.01084179151803255
Loss at iteration 650 : 0.013911214657127857
Loss at iteration 660 : 0.011068655177950859
Loss at iteration 670 : 0.01638696901500225
Loss at iteration 680 : 0.008137429133057594
Loss at iteration 690 : 0.015495648607611656
Loss at iteration 700 : 0.00923810712993145
Loss at iteration 710 : 0.00820220448076725
Loss at iteration 720 : 0.027795841917395592
Loss at iteration 730 : 0.00699995132163167
Loss at iteration 740 : 0.010070308111608028
Loss at iteration 750 : 0.02442721277475357
Loss at iteration 760 : 0.007818395271897316
Loss at iteration 770 : 0.012599831447005272
Loss at iteration 780 : 0.00608318205922842
Loss at iteration 790 : 0.005903749726712704
Loss at iteration 800 : 0.00894672516733408
Loss at iteration 810 : 0.013625009916722775
Loss at iteration 820 : 0.008100021630525589
Loss at iteration 830 : 0.015185944736003876
Loss at iteration 840 : 0.01072915643453598
Loss at iteration 850 : 0.00788754504173994
Loss at iteration 860 : 0.012139529921114445
Loss at iteration 870 : 0.01230960339307785
Loss at iteration 880 : 0.012656886130571365
Loss at iteration 890 : 0.006536123342812061
Loss at iteration 900 : 0.0209734495729208
Loss at iteration 910 : 0.012707113288342953
Loss at iteration 920 : 0.010709170252084732
Loss at iteration 930 : 0.007831836119294167
Loss at iteration 940 : 0.01238976325839758
Loss at iteration 950 : 0.006435823626816273
Loss at iteration 960 : 0.009475933387875557
Loss at iteration 970 : 0.00704383198171854
Loss at iteration 980 : 0.010981437750160694
Loss at iteration 990 : 0.004638624843209982
Loss at iteration 1000 : 0.009263129904866219
Loss at iteration 1010 : 0.017509428784251213
Loss at iteration 1020 : 0.00844166986644268
Loss at iteration 1030 : 0.020668458193540573
Loss at iteration 1040 : 0.009197423234581947
Loss at iteration 1050 : 0.009039805270731449
Loss at iteration 1060 : 0.009277150966227055
Loss at iteration 1070 : 0.00566432811319828
Loss at iteration 1080 : 0.01192073430866003
Loss at iteration 1090 : 0.005934795364737511
Loss at iteration 1100 : 0.015779035165905952
Loss at iteration 1110 : 0.008641073480248451
Loss at iteration 1120 : 0.01554404478520155
Loss at iteration 1130 : 0.011445100419223309
Loss at iteration 1140 : 0.007373844273388386
Loss at iteration 1150 : 0.017881255596876144
Loss at iteration 1160 : 0.01423401664942503
Loss at iteration 1170 : 0.009862316772341728
Loss at iteration 1180 : 0.015260325744748116
Loss at iteration 1190 : 0.02385902963578701
Loss at iteration 1200 : 0.008479992859065533
Loss at iteration 1210 : 0.005468127317726612
Loss at iteration 1220 : 0.012515033595263958
Loss at iteration 1230 : 0.020952928811311722
Loss at iteration 1240 : 0.0078072636388242245
Loss at iteration 1250 : 0.009317160584032536
Loss at iteration 1260 : 0.00608423538506031
Loss at iteration 1270 : 0.00952809490263462
Loss at iteration 1280 : 0.02183382585644722
Loss at iteration 1290 : 0.006518237292766571
Loss at iteration 1300 : 0.011660756543278694
Loss at iteration 1310 : 0.019840005785226822
Loss at iteration 1320 : 0.010192365385591984
Loss at iteration 1330 : 0.0031474903225898743
Loss at iteration 1340 : 0.017947960644960403
Loss at iteration 1350 : 0.013799509033560753
Loss at iteration 1360 : 0.015051119960844517
Loss at iteration 1370 : 0.016252554953098297
Loss at iteration 1380 : 0.012525522150099277
Loss at iteration 1390 : 0.04757539555430412
Loss at iteration 1400 : 0.005795267876237631
Loss at iteration 1410 : 0.009051283821463585
Loss at iteration 1420 : 0.015067191794514656
Loss at iteration 1430 : 0.01374271884560585
Loss at iteration 1440 : 0.009715784341096878
Loss at iteration 1450 : 0.013769062235951424
Loss at iteration 1460 : 0.014627772383391857
Loss at iteration 1470 : 0.00615585595369339
Loss at iteration 1480 : 0.009176758117973804
Loss at iteration 1490 : 0.008795209228992462
Loss at iteration 1500 : 0.00920776091516018
Loss at iteration 1510 : 0.012896194122731686
Loss at iteration 1520 : 0.007839077152311802
Loss at iteration 1530 : 0.011539535596966743
Loss at iteration 1540 : 0.010476337745785713
Loss at iteration 1550 : 0.014637223444879055
Loss at iteration 1560 : 0.006696407683193684
Loss at iteration 1570 : 0.005708829965442419
Loss at iteration 1580 : 0.017008960247039795
Loss at iteration 1590 : 0.010085362941026688
Loss at iteration 1600 : 0.005903930403292179
Loss at iteration 1610 : 0.013768274337053299
Loss at iteration 1620 : 0.005873208399862051
Loss at iteration 1630 : 0.021347323432564735
Loss at iteration 1640 : 0.011855418793857098
Loss at iteration 1650 : 0.014986289665102959
Loss at iteration 1660 : 0.007522197440266609
Loss at iteration 1670 : 0.013412600383162498
Loss at iteration 1680 : 0.013366022147238255
Loss at iteration 1690 : 0.013271075673401356
Loss at iteration 1700 : 0.01598827913403511
Loss at iteration 1710 : 0.01835651323199272
Loss at iteration 1720 : 0.010687297210097313
Loss at iteration 1730 : 0.01309805829077959
Loss at iteration 1740 : 0.010504275560379028
Loss at iteration 1750 : 0.02259133756160736
Loss at iteration 1760 : 0.013123663142323494
Loss at iteration 1770 : 0.0042975666001439095
Loss at iteration 1780 : 0.008915435522794724
Loss at iteration 1790 : 0.007832339964807034
Loss at iteration 1800 : 0.02503882721066475
Loss at iteration 1810 : 0.01030697301030159
Loss at iteration 1820 : 0.01280296966433525
Loss at iteration 1830 : 0.02234080247581005
Loss at iteration 1840 : 0.004643329419195652
Loss at iteration 1850 : 0.012382112443447113
Loss at iteration 1860 : 0.009995796717703342
Loss at iteration 1870 : 0.011885624378919601
Loss at iteration 1880 : 0.013901423662900925
Loss at iteration 1890 : 0.006322070024907589
Loss at iteration 1900 : 0.013416578993201256
Loss at iteration 1910 : 0.025346806272864342
Loss at iteration 1920 : 0.0176687091588974
Loss at iteration 1930 : 0.011872602626681328
Loss at iteration 1940 : 0.007702894043177366
Loss at iteration 1950 : 0.012195456773042679
Loss at iteration 1960 : 0.01211380586028099
Loss at iteration 1970 : 0.009261926636099815
Loss at iteration 1980 : 0.016983769834041595
Loss at iteration 1990 : 0.021221013739705086
Loss at iteration 2000 : 0.009508315473794937
Loss at iteration 2010 : 0.01010836847126484
Loss at iteration 2020 : 0.011361867189407349
Loss at iteration 2030 : 0.010123670101165771
Loss at iteration 2040 : 0.008977835066616535
Loss at iteration 2050 : 0.01000332459807396
Loss at iteration 2060 : 0.016301674768328667
Loss at iteration 2070 : 0.016192926093935966
Loss at iteration 2080 : 0.014976156875491142
Loss at iteration 2090 : 0.013065468519926071
Loss at iteration 2100 : 0.008689808659255505
Loss at iteration 2110 : 0.008590223267674446
Loss at iteration 2120 : 0.012578895315527916
Loss at iteration 2130 : 0.014438699930906296
Loss at iteration 2140 : 0.007399901747703552
Loss at iteration 2150 : 0.020856140181422234
Loss at iteration 2160 : 0.010812489315867424
Loss at iteration 2170 : 0.02655860036611557
Loss at iteration 2180 : 0.011502185836434364
Loss at iteration 2190 : 0.012838774360716343
Loss at iteration 2200 : 0.013114603236317635
Loss at iteration 2210 : 0.007722385693341494
Loss at iteration 2220 : 0.008037541061639786
Loss at iteration 2230 : 0.008887596428394318
Loss at iteration 2240 : 0.008080841042101383
Loss at iteration 2250 : 0.008415555581450462
Loss at iteration 2260 : 0.01840854436159134
Loss at iteration 2270 : 0.008208689279854298
Loss at iteration 2280 : 0.006641784217208624
Loss at iteration 2290 : 0.008138064295053482
Loss at iteration 2300 : 0.009675031527876854
Loss at iteration 2310 : 0.007656899280846119
Loss at iteration 2320 : 0.012199806049466133
Loss at iteration 2330 : 0.009151635691523552
Loss at iteration 2340 : 0.006360845640301704
Loss at iteration 2350 : 0.014829108491539955
Loss at iteration 2360 : 0.012537508271634579
Loss at iteration 2370 : 0.009070386178791523
Loss at iteration 2380 : 0.005598049145191908
Loss at iteration 2390 : 0.014777995645999908
Loss at iteration 2400 : 0.022526856511831284
Loss at iteration 2410 : 0.011217040941119194
Loss at iteration 2420 : 0.011216143146157265
The SSIM Value is: 0.8493741949399313
The PSNR Value is: 22.776203028361003
the highest SSIM value is: 22.776203028361003
the epoch is: 28
Loss at iteration 10 : 0.00334441801533103
Loss at iteration 20 : 0.005281193181872368
Loss at iteration 30 : 0.010314562357962132
Loss at iteration 40 : 0.012168072164058685
Loss at iteration 50 : 0.01265704445540905
Loss at iteration 60 : 0.007891159504652023
Loss at iteration 70 : 0.021981963887810707
Loss at iteration 80 : 0.01776166446506977
Loss at iteration 90 : 0.011389106512069702
Loss at iteration 100 : 0.01902054436504841
Loss at iteration 110 : 0.013188837096095085
Loss at iteration 120 : 0.016115523874759674
Loss at iteration 130 : 0.010686932131648064
Loss at iteration 140 : 0.031302809715270996
Loss at iteration 150 : 0.012802701443433762
Loss at iteration 160 : 0.009362258017063141
Loss at iteration 170 : 0.010033247992396355
Loss at iteration 180 : 0.017971333116292953
Loss at iteration 190 : 0.007014045491814613
Loss at iteration 200 : 0.007580334320664406
Loss at iteration 210 : 0.013805310241878033
Loss at iteration 220 : 0.00676066754385829
Loss at iteration 230 : 0.012720500119030476
Loss at iteration 240 : 0.006524260155856609
Loss at iteration 250 : 0.014185184612870216
Loss at iteration 260 : 0.008335267193615437
Loss at iteration 270 : 0.02393537573516369
Loss at iteration 280 : 0.007783470209687948
Loss at iteration 290 : 0.015483962371945381
Loss at iteration 300 : 0.007500824518501759
Loss at iteration 310 : 0.009321524761617184
Loss at iteration 320 : 0.011390512809157372
Loss at iteration 330 : 0.022756416350603104
Loss at iteration 340 : 0.009712422266602516
Loss at iteration 350 : 0.025284618139266968
Loss at iteration 360 : 0.014696944504976273
Loss at iteration 370 : 0.006702397018671036
Loss at iteration 380 : 0.00930924341082573
Loss at iteration 390 : 0.0179998017847538
Loss at iteration 400 : 0.015286343172192574
Loss at iteration 410 : 0.0035568459425121546
Loss at iteration 420 : 0.009557848796248436
Loss at iteration 430 : 0.008041496388614178
Loss at iteration 440 : 0.0037427591159939766
Loss at iteration 450 : 0.008122124709188938
Loss at iteration 460 : 0.010500771924853325
Loss at iteration 470 : 0.012753970921039581
Loss at iteration 480 : 0.023977551609277725
Loss at iteration 490 : 0.007779047358781099
Loss at iteration 500 : 0.02237323485314846
Loss at iteration 510 : 0.022666361182928085
Loss at iteration 520 : 0.012992922216653824
Loss at iteration 530 : 0.022836465388536453
Loss at iteration 540 : 0.021986287087202072
Loss at iteration 550 : 0.008956240490078926
Loss at iteration 560 : 0.020556416362524033
Loss at iteration 570 : 0.014891127124428749
Loss at iteration 580 : 0.012697353959083557
Loss at iteration 590 : 0.021443311125040054
Loss at iteration 600 : 0.020382709801197052
Loss at iteration 610 : 0.012712663039565086
Loss at iteration 620 : 0.006426648236811161
Loss at iteration 630 : 0.00579844880849123
Loss at iteration 640 : 0.010949370451271534
Loss at iteration 650 : 0.018935343250632286
Loss at iteration 660 : 0.012819255702197552
Loss at iteration 670 : 0.007628605701029301
Loss at iteration 680 : 0.004945001099258661
Loss at iteration 690 : 0.012120332568883896
Loss at iteration 700 : 0.03352023661136627
Loss at iteration 710 : 0.006828253157436848
Loss at iteration 720 : 0.012994833290576935
Loss at iteration 730 : 0.0068340604193508625
Loss at iteration 740 : 0.023272907361388206
Loss at iteration 750 : 0.003924648743122816
Loss at iteration 760 : 0.005441472865641117
Loss at iteration 770 : 0.012345332652330399
Loss at iteration 780 : 0.010693158954381943
Loss at iteration 790 : 0.01134428195655346
Loss at iteration 800 : 0.01666785590350628
Loss at iteration 810 : 0.012529434636235237
Loss at iteration 820 : 0.020460888743400574
Loss at iteration 830 : 0.009230753406882286
Loss at iteration 840 : 0.012518969364464283
Loss at iteration 850 : 0.030558735132217407
Loss at iteration 860 : 0.005900789052248001
Loss at iteration 870 : 0.004903346765786409
Loss at iteration 880 : 0.025921812281012535
Loss at iteration 890 : 0.014161128550767899
Loss at iteration 900 : 0.01158426608890295
Loss at iteration 910 : 0.014529659412801266
Loss at iteration 920 : 0.015953943133354187
Loss at iteration 930 : 0.009301966056227684
Loss at iteration 940 : 0.008951724506914616
Loss at iteration 950 : 0.010013433173298836
Loss at iteration 960 : 0.009574679657816887
Loss at iteration 970 : 0.005722024478018284
Loss at iteration 980 : 0.00683453306555748
Loss at iteration 990 : 0.010383086279034615
Loss at iteration 1000 : 0.007239188998937607
Loss at iteration 1010 : 0.013124119490385056
Loss at iteration 1020 : 0.010182753205299377
Loss at iteration 1030 : 0.011923170648515224
Loss at iteration 1040 : 0.009852818213403225
Loss at iteration 1050 : 0.007905486971139908
Loss at iteration 1060 : 0.014648390002548695
Loss at iteration 1070 : 0.013348963111639023
Loss at iteration 1080 : 0.009289903566241264
Loss at iteration 1090 : 0.005482790060341358
Loss at iteration 1100 : 0.012152324430644512
Loss at iteration 1110 : 0.009937109425663948
Loss at iteration 1120 : 0.009453510865569115
Loss at iteration 1130 : 0.00712098041549325
Loss at iteration 1140 : 0.014929816126823425
Loss at iteration 1150 : 0.022654788568615913
Loss at iteration 1160 : 0.008830848149955273
Loss at iteration 1170 : 0.006872948724776506
Loss at iteration 1180 : 0.014100267551839352
Loss at iteration 1190 : 0.007087566889822483
Loss at iteration 1200 : 0.01181758102029562
Loss at iteration 1210 : 0.009320626966655254
Loss at iteration 1220 : 0.00511358305811882
Loss at iteration 1230 : 0.012076960876584053
Loss at iteration 1240 : 0.00694276811555028
Loss at iteration 1250 : 0.009023788385093212
Loss at iteration 1260 : 0.008615332655608654
Loss at iteration 1270 : 0.005496346857398748
Loss at iteration 1280 : 0.011017450131475925
Loss at iteration 1290 : 0.009684327058494091
Loss at iteration 1300 : 0.009220852516591549
Loss at iteration 1310 : 0.011542035266757011
Loss at iteration 1320 : 0.01092233881354332
Loss at iteration 1330 : 0.010713323950767517
Loss at iteration 1340 : 0.010894072242081165
Loss at iteration 1350 : 0.004038713406771421
Loss at iteration 1360 : 0.005157658830285072
Loss at iteration 1370 : 0.010881735943257809
Loss at iteration 1380 : 0.016375232487916946
Loss at iteration 1390 : 0.0050273253582417965
Loss at iteration 1400 : 0.016937080770730972
Loss at iteration 1410 : 0.03466577082872391
Loss at iteration 1420 : 0.011175521649420261
Loss at iteration 1430 : 0.006824078969657421
Loss at iteration 1440 : 0.010028159245848656
Loss at iteration 1450 : 0.007651853375136852
Loss at iteration 1460 : 0.013163559138774872
Loss at iteration 1470 : 0.012606906704604626
Loss at iteration 1480 : 0.012992722913622856
Loss at iteration 1490 : 0.011622074991464615
Loss at iteration 1500 : 0.005626237951219082
Loss at iteration 1510 : 0.014641731977462769
Loss at iteration 1520 : 0.005531341303139925
Loss at iteration 1530 : 0.0085129514336586
Loss at iteration 1540 : 0.007776784710586071
Loss at iteration 1550 : 0.004245119635015726
Loss at iteration 1560 : 0.02370164915919304
Loss at iteration 1570 : 0.004454329609870911
Loss at iteration 1580 : 0.015765860676765442
Loss at iteration 1590 : 0.013012184761464596
Loss at iteration 1600 : 0.005868351086974144
Loss at iteration 1610 : 0.008731253445148468
Loss at iteration 1620 : 0.005512334406375885
Loss at iteration 1630 : 0.01644856669008732
Loss at iteration 1640 : 0.011254169046878815
Loss at iteration 1650 : 0.0071493168361485004
Loss at iteration 1660 : 0.01104880403727293
Loss at iteration 1670 : 0.01498422771692276
Loss at iteration 1680 : 0.012685702182352543
Loss at iteration 1690 : 0.010922018438577652
Loss at iteration 1700 : 0.010396692901849747
Loss at iteration 1710 : 0.010475996881723404
Loss at iteration 1720 : 0.020603856071829796
Loss at iteration 1730 : 0.012197921983897686
Loss at iteration 1740 : 0.011022356338799
Loss at iteration 1750 : 0.012293966487050056
Loss at iteration 1760 : 0.008665362372994423
Loss at iteration 1770 : 0.013964620418846607
Loss at iteration 1780 : 0.003601008327677846
Loss at iteration 1790 : 0.005285296123474836
Loss at iteration 1800 : 0.02092665247619152
Loss at iteration 1810 : 0.008658080361783504
Loss at iteration 1820 : 0.00786806270480156
Loss at iteration 1830 : 0.0095819141715765
Loss at iteration 1840 : 0.009384473785758018
Loss at iteration 1850 : 0.010931801050901413
Loss at iteration 1860 : 0.010205172933638096
Loss at iteration 1870 : 0.013335628435015678
Loss at iteration 1880 : 0.013623621314764023
Loss at iteration 1890 : 0.018476111814379692
Loss at iteration 1900 : 0.004818088840693235
Loss at iteration 1910 : 0.007358909118920565
Loss at iteration 1920 : 0.014636363834142685
Loss at iteration 1930 : 0.01318580936640501
Loss at iteration 1940 : 0.004586904309689999
Loss at iteration 1950 : 0.005954249296337366
Loss at iteration 1960 : 0.010714742355048656
Loss at iteration 1970 : 0.007653877139091492
Loss at iteration 1980 : 0.009036615490913391
Loss at iteration 1990 : 0.012568788602948189
Loss at iteration 2000 : 0.02656405419111252
Loss at iteration 2010 : 0.015758292749524117
Loss at iteration 2020 : 0.008833750151097775
Loss at iteration 2030 : 0.00661228783428669
Loss at iteration 2040 : 0.008306138217449188
Loss at iteration 2050 : 0.007038274314254522
Loss at iteration 2060 : 0.0040061636827886105
Loss at iteration 2070 : 0.009669242426753044
Loss at iteration 2080 : 0.008165876381099224
Loss at iteration 2090 : 0.011564595624804497
Loss at iteration 2100 : 0.011979984119534492
Loss at iteration 2110 : 0.013415276072919369
Loss at iteration 2120 : 0.014488168992102146
Loss at iteration 2130 : 0.007743115536868572
Loss at iteration 2140 : 0.017916612327098846
Loss at iteration 2150 : 0.02562500722706318
Loss at iteration 2160 : 0.018909163773059845
Loss at iteration 2170 : 0.006181660573929548
Loss at iteration 2180 : 0.03448433056473732
Loss at iteration 2190 : 0.01134190522134304
Loss at iteration 2200 : 0.011117633432149887
Loss at iteration 2210 : 0.013806985691189766
Loss at iteration 2220 : 0.011861460283398628
Loss at iteration 2230 : 0.008506392128765583
Loss at iteration 2240 : 0.011343211866915226
Loss at iteration 2250 : 0.012640119530260563
Loss at iteration 2260 : 0.00772120151668787
Loss at iteration 2270 : 0.007840595208108425
Loss at iteration 2280 : 0.024710064753890038
Loss at iteration 2290 : 0.01254743617027998
Loss at iteration 2300 : 0.009726296178996563
Loss at iteration 2310 : 0.010180491954088211
Loss at iteration 2320 : 0.01518704742193222
Loss at iteration 2330 : 0.006127833388745785
Loss at iteration 2340 : 0.009963493794202805
Loss at iteration 2350 : 0.008961664512753487
Loss at iteration 2360 : 0.012272784486413002
Loss at iteration 2370 : 0.01033615693449974
Loss at iteration 2380 : 0.00717808585613966
Loss at iteration 2390 : 0.010003631934523582
Loss at iteration 2400 : 0.0059163630940020084
Loss at iteration 2410 : 0.016025029122829437
Loss at iteration 2420 : 0.017218060791492462
The SSIM Value is: 0.8325968623161316
The PSNR Value is: 21.61263109842936
the epoch is: 29
Loss at iteration 10 : 0.009764309972524643
Loss at iteration 20 : 0.005169416777789593
Loss at iteration 30 : 0.019226908683776855
Loss at iteration 40 : 0.008187320083379745
Loss at iteration 50 : 0.013866342604160309
Loss at iteration 60 : 0.007462549488991499
Loss at iteration 70 : 0.010401037521660328
Loss at iteration 80 : 0.010195963084697723
Loss at iteration 90 : 0.00931487139314413
Loss at iteration 100 : 0.015231950208544731
Loss at iteration 110 : 0.006390679627656937
Loss at iteration 120 : 0.005107360891997814
Loss at iteration 130 : 0.008851783350110054
Loss at iteration 140 : 0.003995962906628847
Loss at iteration 150 : 0.009469316340982914
Loss at iteration 160 : 0.004576897714287043
Loss at iteration 170 : 0.005617322400212288
Loss at iteration 180 : 0.02187846042215824
Loss at iteration 190 : 0.018079079687595367
Loss at iteration 200 : 0.011143060401082039
Loss at iteration 210 : 0.007624701596796513
Loss at iteration 220 : 0.0055021243169903755
Loss at iteration 230 : 0.0056678554974496365
Loss at iteration 240 : 0.014617985114455223
Loss at iteration 250 : 0.015068400651216507
Loss at iteration 260 : 0.00802528951317072
Loss at iteration 270 : 0.009366216138005257
Loss at iteration 280 : 0.010342016816139221
Loss at iteration 290 : 0.01008243765681982
Loss at iteration 300 : 0.006896140985190868
Loss at iteration 310 : 0.017534371465444565
Loss at iteration 320 : 0.010752532631158829
Loss at iteration 330 : 0.0060663665644824505
Loss at iteration 340 : 0.017301637679338455
Loss at iteration 350 : 0.008403937332332134
Loss at iteration 360 : 0.012138260528445244
Loss at iteration 370 : 0.005960674956440926
Loss at iteration 380 : 0.010785268619656563
Loss at iteration 390 : 0.014129343442618847
Loss at iteration 400 : 0.010094917379319668
Loss at iteration 410 : 0.006092739757150412
Loss at iteration 420 : 0.007545588072389364
Loss at iteration 430 : 0.02642150968313217
Loss at iteration 440 : 0.013577867299318314
Loss at iteration 450 : 0.026043064892292023
Loss at iteration 460 : 0.008071614429354668
Loss at iteration 470 : 0.007087093312293291
Loss at iteration 480 : 0.0065326509065926075
Loss at iteration 490 : 0.009982005693018436
Loss at iteration 500 : 0.017207030206918716
Loss at iteration 510 : 0.003960777539759874
Loss at iteration 520 : 0.013521384447813034
Loss at iteration 530 : 0.007764866109937429
Loss at iteration 540 : 0.01981988176703453
Loss at iteration 550 : 0.01749274879693985
Loss at iteration 560 : 0.013689099811017513
Loss at iteration 570 : 0.005091420374810696
Loss at iteration 580 : 0.01884308084845543
Loss at iteration 590 : 0.013687022030353546
Loss at iteration 600 : 0.010300291702151299
Loss at iteration 610 : 0.00794167909771204
Loss at iteration 620 : 0.006485581863671541
Loss at iteration 630 : 0.008390501141548157
Loss at iteration 640 : 0.008936833590269089
Loss at iteration 650 : 0.012587574310600758
Loss at iteration 660 : 0.012856115587055683
Loss at iteration 670 : 0.010755808092653751
Loss at iteration 680 : 0.006740518379956484
Loss at iteration 690 : 0.00714916130527854
Loss at iteration 700 : 0.012194220907986164
Loss at iteration 710 : 0.016966085880994797
Loss at iteration 720 : 0.004067684523761272
Loss at iteration 730 : 0.013399515300989151
Loss at iteration 740 : 0.012289651669561863
Loss at iteration 750 : 0.015043271705508232
Loss at iteration 760 : 0.017754562199115753
Loss at iteration 770 : 0.005128229968249798
Loss at iteration 780 : 0.005495510529726744
Loss at iteration 790 : 0.006839798763394356
Loss at iteration 800 : 0.010000727139413357
Loss at iteration 810 : 0.018774207681417465
Loss at iteration 820 : 0.009346331469714642
Loss at iteration 830 : 0.01094649825245142
Loss at iteration 840 : 0.018104908987879753
Loss at iteration 850 : 0.0051186587661504745
Loss at iteration 860 : 0.008139255456626415
Loss at iteration 870 : 0.015224779024720192
Loss at iteration 880 : 0.02004094235599041
Loss at iteration 890 : 0.016331875696778297
Loss at iteration 900 : 0.01630544476211071
Loss at iteration 910 : 0.0135202556848526
Loss at iteration 920 : 0.009198484010994434
Loss at iteration 930 : 0.014155295677483082
Loss at iteration 940 : 0.02116386964917183
Loss at iteration 950 : 0.017113778740167618
Loss at iteration 960 : 0.009693415835499763
Loss at iteration 970 : 0.013808172196149826
Loss at iteration 980 : 0.010171208530664444
Loss at iteration 990 : 0.015338698402047157
Loss at iteration 1000 : 0.0184782762080431
Loss at iteration 1010 : 0.008711196482181549
Loss at iteration 1020 : 0.01099837850779295
Loss at iteration 1030 : 0.009394390508532524
Loss at iteration 1040 : 0.012830940075218678
Loss at iteration 1050 : 0.017801271751523018
Loss at iteration 1060 : 0.008261029608547688
Loss at iteration 1070 : 0.005466154310852289
Loss at iteration 1080 : 0.010830244049429893
Loss at iteration 1090 : 0.008196976035833359
Loss at iteration 1100 : 0.008259154856204987
Loss at iteration 1110 : 0.005995981395244598
Loss at iteration 1120 : 0.00967221800237894
Loss at iteration 1130 : 0.010095072910189629
Loss at iteration 1140 : 0.004313355777412653
Loss at iteration 1150 : 0.011067777872085571
Loss at iteration 1160 : 0.007404136937111616
Loss at iteration 1170 : 0.0065301088616251945
Loss at iteration 1180 : 0.014273414388298988
Loss at iteration 1190 : 0.01280706562101841
Loss at iteration 1200 : 0.016346683725714684
Loss at iteration 1210 : 0.01094321720302105
Loss at iteration 1220 : 0.008492368273437023
Loss at iteration 1230 : 0.008731693029403687
Loss at iteration 1240 : 0.015657545998692513
Loss at iteration 1250 : 0.014673625119030476
Loss at iteration 1260 : 0.007385953329503536
Loss at iteration 1270 : 0.008103562518954277
Loss at iteration 1280 : 0.012937987223267555
Loss at iteration 1290 : 0.011698047630488873
Loss at iteration 1300 : 0.010006705299019814
Loss at iteration 1310 : 0.007068565580993891
Loss at iteration 1320 : 0.012724124826490879
Loss at iteration 1330 : 0.006715807598084211
Loss at iteration 1340 : 0.011766565963625908
Loss at iteration 1350 : 0.01227492280304432
Loss at iteration 1360 : 0.018945865333080292
Loss at iteration 1370 : 0.022109173238277435
Loss at iteration 1380 : 0.008186230435967445
Loss at iteration 1390 : 0.013369813561439514
Loss at iteration 1400 : 0.010962309315800667
Loss at iteration 1410 : 0.007866338826715946
Loss at iteration 1420 : 0.0048497640527784824
Loss at iteration 1430 : 0.0066308518871665
Loss at iteration 1440 : 0.009931746870279312
Loss at iteration 1450 : 0.015136633068323135
Loss at iteration 1460 : 0.018010996282100677
Loss at iteration 1470 : 0.011062992736697197
Loss at iteration 1480 : 0.008093422278761864
Loss at iteration 1490 : 0.004424991086125374
Loss at iteration 1500 : 0.008949614129960537
Loss at iteration 1510 : 0.011903015896677971
Loss at iteration 1520 : 0.008834886364638805
Loss at iteration 1530 : 0.004401399753987789
Loss at iteration 1540 : 0.011366905644536018
Loss at iteration 1550 : 0.010288283228874207
Loss at iteration 1560 : 0.009521756321191788
Loss at iteration 1570 : 0.013352143578231335
Loss at iteration 1580 : 0.023780712857842445
Loss at iteration 1590 : 0.006964623928070068
Loss at iteration 1600 : 0.015491591766476631
Loss at iteration 1610 : 0.017317159101366997
Loss at iteration 1620 : 0.008169328793883324
Loss at iteration 1630 : 0.042984213680028915
Loss at iteration 1640 : 0.014531954191625118
Loss at iteration 1650 : 0.008136746473610401
Loss at iteration 1660 : 0.009151152335107327
Loss at iteration 1670 : 0.010717180557549
Loss at iteration 1680 : 0.011765219271183014
Loss at iteration 1690 : 0.018178367987275124
Loss at iteration 1700 : 0.0034400699660182
Loss at iteration 1710 : 0.01684744656085968
Loss at iteration 1720 : 0.010789398103952408
Loss at iteration 1730 : 0.009860348887741566
Loss at iteration 1740 : 0.009747328236699104
Loss at iteration 1750 : 0.01020326092839241
Loss at iteration 1760 : 0.017767399549484253
Loss at iteration 1770 : 0.006816104054450989
Loss at iteration 1780 : 0.0059903645887970924
Loss at iteration 1790 : 0.014752351678907871
Loss at iteration 1800 : 0.007303254678845406
Loss at iteration 1810 : 0.008255261927843094
Loss at iteration 1820 : 0.012822139076888561
Loss at iteration 1830 : 0.005827892106026411
Loss at iteration 1840 : 0.01588190346956253
Loss at iteration 1850 : 0.004263009410351515
Loss at iteration 1860 : 0.015050944872200489
Loss at iteration 1870 : 0.007654732093214989
Loss at iteration 1880 : 0.008594289422035217
Loss at iteration 1890 : 0.0077127814292907715
Loss at iteration 1900 : 0.011398028582334518
Loss at iteration 1910 : 0.010261346586048603
Loss at iteration 1920 : 0.007904618978500366
Loss at iteration 1930 : 0.009973795153200626
Loss at iteration 1940 : 0.017555415630340576
Loss at iteration 1950 : 0.006950769107788801
Loss at iteration 1960 : 0.009309868328273296
Loss at iteration 1970 : 0.016030332073569298
Loss at iteration 1980 : 0.013023938052356243
Loss at iteration 1990 : 0.004605549853295088
Loss at iteration 2000 : 0.007623597979545593
Loss at iteration 2010 : 0.009426440112292767
Loss at iteration 2020 : 0.01951209083199501
Loss at iteration 2030 : 0.015134869143366814
Loss at iteration 2040 : 0.006432606838643551
Loss at iteration 2050 : 0.0033801314420998096
Loss at iteration 2060 : 0.013392486609518528
Loss at iteration 2070 : 0.00982434581965208
Loss at iteration 2080 : 0.006599132902920246
Loss at iteration 2090 : 0.011726614087820053
Loss at iteration 2100 : 0.018091104924678802
Loss at iteration 2110 : 0.011780776083469391
Loss at iteration 2120 : 0.010337385348975658
Loss at iteration 2130 : 0.012541599571704865
Loss at iteration 2140 : 0.012409516610205173
Loss at iteration 2150 : 0.003605031408369541
Loss at iteration 2160 : 0.013218152336776257
Loss at iteration 2170 : 0.013283963315188885
Loss at iteration 2180 : 0.0077308062463998795
Loss at iteration 2190 : 0.015049368143081665
Loss at iteration 2200 : 0.02454260364174843
Loss at iteration 2210 : 0.009889819659292698
Loss at iteration 2220 : 0.014347082935273647
Loss at iteration 2230 : 0.0052933720871806145
Loss at iteration 2240 : 0.009769463911652565
Loss at iteration 2250 : 0.006613332312554121
Loss at iteration 2260 : 0.010835764929652214
Loss at iteration 2270 : 0.008479975163936615
Loss at iteration 2280 : 0.023437438532710075
Loss at iteration 2290 : 0.010189976543188095
Loss at iteration 2300 : 0.020974548533558846
Loss at iteration 2310 : 0.012658122926950455
Loss at iteration 2320 : 0.012822998687624931
Loss at iteration 2330 : 0.013760773465037346
Loss at iteration 2340 : 0.010272566229104996
Loss at iteration 2350 : 0.008376033045351505
Loss at iteration 2360 : 0.02026638388633728
Loss at iteration 2370 : 0.008719340898096561
Loss at iteration 2380 : 0.008118871599435806
Loss at iteration 2390 : 0.013137240894138813
Loss at iteration 2400 : 0.01180655974894762
Loss at iteration 2410 : 0.016619032248854637
Loss at iteration 2420 : 0.015135416761040688
The SSIM Value is: 0.8343913992245992
The PSNR Value is: 20.59420394897461
the epoch is: 30
Loss at iteration 10 : 0.00922891404479742
Loss at iteration 20 : 0.015470469370484352
Loss at iteration 30 : 0.007182239089161158
Loss at iteration 40 : 0.006830709055066109
Loss at iteration 50 : 0.023031195625662804
Loss at iteration 60 : 0.005643033422529697
Loss at iteration 70 : 0.010791199281811714
Loss at iteration 80 : 0.013621242716908455
Loss at iteration 90 : 0.010436933487653732
Loss at iteration 100 : 0.016454730182886124
Loss at iteration 110 : 0.012832269072532654
Loss at iteration 120 : 0.006006718147546053
Loss at iteration 130 : 0.017838116735219955
Loss at iteration 140 : 0.007843845523893833
Loss at iteration 150 : 0.021664265543222427
Loss at iteration 160 : 0.014578353613615036
Loss at iteration 170 : 0.011164383962750435
Loss at iteration 180 : 0.00800452008843422
Loss at iteration 190 : 0.00713442312553525
Loss at iteration 200 : 0.007612193934619427
Loss at iteration 210 : 0.010827425867319107
Loss at iteration 220 : 0.006678242236375809
Loss at iteration 230 : 0.011819046922028065
Loss at iteration 240 : 0.007112486287951469
Loss at iteration 250 : 0.007278168573975563
Loss at iteration 260 : 0.011607177555561066
Loss at iteration 270 : 0.010584274306893349
Loss at iteration 280 : 0.009606270119547844
Loss at iteration 290 : 0.006880155764520168
Loss at iteration 300 : 0.010950535535812378
Loss at iteration 310 : 0.008333738893270493
Loss at iteration 320 : 0.0057672904804348946
Loss at iteration 330 : 0.016426842659711838
Loss at iteration 340 : 0.008812266401946545
Loss at iteration 350 : 0.018692713230848312
Loss at iteration 360 : 0.007333919405937195
Loss at iteration 370 : 0.004424701910465956
Loss at iteration 380 : 0.019493795931339264
Loss at iteration 390 : 0.0231632087379694
Loss at iteration 400 : 0.009824834764003754
Loss at iteration 410 : 0.017154069617390633
Loss at iteration 420 : 0.007209490053355694
Loss at iteration 430 : 0.009297102689743042
Loss at iteration 440 : 0.017698366194963455
Loss at iteration 450 : 0.02261391654610634
Loss at iteration 460 : 0.012420015409588814
Loss at iteration 470 : 0.009967162273824215
Loss at iteration 480 : 0.006010059267282486
Loss at iteration 490 : 0.007975242100656033
Loss at iteration 500 : 0.011006218381226063
Loss at iteration 510 : 0.015884995460510254
Loss at iteration 520 : 0.007965506985783577
Loss at iteration 530 : 0.00988555047661066
Loss at iteration 540 : 0.008170794695615768
Loss at iteration 550 : 0.012665817514061928
Loss at iteration 560 : 0.0076781949028372765
Loss at iteration 570 : 0.016789501532912254
Loss at iteration 580 : 0.012606232427060604
Loss at iteration 590 : 0.010383106768131256
Loss at iteration 600 : 0.014994092285633087
Loss at iteration 610 : 0.013106029480695724
Loss at iteration 620 : 0.021266214549541473
Loss at iteration 630 : 0.00772700272500515
Loss at iteration 640 : 0.017459385097026825
Loss at iteration 650 : 0.003301608841866255
Loss at iteration 660 : 0.012293858453631401
Loss at iteration 670 : 0.008544464595615864
Loss at iteration 680 : 0.007283410057425499
Loss at iteration 690 : 0.007710738573223352
Loss at iteration 700 : 0.010451056063175201
Loss at iteration 710 : 0.017588378861546516
Loss at iteration 720 : 0.006995173171162605
Loss at iteration 730 : 0.0030354447662830353
Loss at iteration 740 : 0.011300265789031982
Loss at iteration 750 : 0.01796545274555683
Loss at iteration 760 : 0.0077362037263810635
Loss at iteration 770 : 0.00848676823079586
Loss at iteration 780 : 0.012373830191791058
Loss at iteration 790 : 0.00920100323855877
Loss at iteration 800 : 0.017568182200193405
Loss at iteration 810 : 0.008769613690674305
Loss at iteration 820 : 0.01622396893799305
Loss at iteration 830 : 0.01652788370847702
Loss at iteration 840 : 0.004789568018168211
Loss at iteration 850 : 0.014645684510469437
Loss at iteration 860 : 0.011364332400262356
Loss at iteration 870 : 0.016772229224443436
Loss at iteration 880 : 0.011398855596780777
Loss at iteration 890 : 0.015801841393113136
Loss at iteration 900 : 0.0077674295753240585
Loss at iteration 910 : 0.02456507459282875
Loss at iteration 920 : 0.012426585890352726
Loss at iteration 930 : 0.014376994222402573
Loss at iteration 940 : 0.0072909086011350155
Loss at iteration 950 : 0.01802573725581169
Loss at iteration 960 : 0.015730058774352074
Loss at iteration 970 : 0.009754141792654991
Loss at iteration 980 : 0.014140183106064796
Loss at iteration 990 : 0.022724367678165436
Loss at iteration 1000 : 0.009589673951268196
Loss at iteration 1010 : 0.006632446311414242
Loss at iteration 1020 : 0.005661105737090111
Loss at iteration 1030 : 0.013600023463368416
Loss at iteration 1040 : 0.008531339466571808
Loss at iteration 1050 : 0.011701640672981739
Loss at iteration 1060 : 0.015938851982355118
Loss at iteration 1070 : 0.01041895616799593
Loss at iteration 1080 : 0.01028565876185894
Loss at iteration 1090 : 0.010038974694907665
Loss at iteration 1100 : 0.00843932293355465
Loss at iteration 1110 : 0.004036915488541126
Loss at iteration 1120 : 0.019384469836950302
Loss at iteration 1130 : 0.006506389006972313
Loss at iteration 1140 : 0.011321157217025757
Loss at iteration 1150 : 0.01954730600118637
Loss at iteration 1160 : 0.007555260322988033
Loss at iteration 1170 : 0.018437549471855164
Loss at iteration 1180 : 0.01421718392521143
Loss at iteration 1190 : 0.007032960187643766
Loss at iteration 1200 : 0.028347497805953026
Loss at iteration 1210 : 0.01698397472500801
Loss at iteration 1220 : 0.011443373747169971
Loss at iteration 1230 : 0.014337830245494843
Loss at iteration 1240 : 0.034675609320402145
Loss at iteration 1250 : 0.00774123752489686
Loss at iteration 1260 : 0.034319303929805756
Loss at iteration 1270 : 0.015265267342329025
Loss at iteration 1280 : 0.012253211811184883
Loss at iteration 1290 : 0.01923801191151142
Loss at iteration 1300 : 0.022496597841382027
Loss at iteration 1310 : 0.00708801532164216
Loss at iteration 1320 : 0.00932453665882349
Loss at iteration 1330 : 0.010637735947966576
Loss at iteration 1340 : 0.016484592109918594
Loss at iteration 1350 : 0.010047291405498981
Loss at iteration 1360 : 0.0070449598133563995
Loss at iteration 1370 : 0.014197288081049919
Loss at iteration 1380 : 0.009920528158545494
Loss at iteration 1390 : 0.01751789264380932
Loss at iteration 1400 : 0.004629575181752443
Loss at iteration 1410 : 0.012593326158821583
Loss at iteration 1420 : 0.017111733555793762
Loss at iteration 1430 : 0.0099794315174222
Loss at iteration 1440 : 0.009958421811461449
Loss at iteration 1450 : 0.005419217050075531
Loss at iteration 1460 : 0.010506683960556984
Loss at iteration 1470 : 0.016482148319482803
Loss at iteration 1480 : 0.009064266458153725
Loss at iteration 1490 : 0.022523080930113792
Loss at iteration 1500 : 0.010227023623883724
Loss at iteration 1510 : 0.013668243773281574
Loss at iteration 1520 : 0.006186603102833033
Loss at iteration 1530 : 0.013397244736552238
Loss at iteration 1540 : 0.004119543358683586
Loss at iteration 1550 : 0.01251380518078804
Loss at iteration 1560 : 0.021929536014795303
Loss at iteration 1570 : 0.012633675709366798
Loss at iteration 1580 : 0.0064324019476771355
Loss at iteration 1590 : 0.005767950788140297
Loss at iteration 1600 : 0.009548952803015709
Loss at iteration 1610 : 0.008875376544892788
Loss at iteration 1620 : 0.02214750461280346
Loss at iteration 1630 : 0.010894712060689926
Loss at iteration 1640 : 0.020702838897705078
Loss at iteration 1650 : 0.011795219965279102
Loss at iteration 1660 : 0.012753976508975029
Loss at iteration 1670 : 0.012581279501318932
Loss at iteration 1680 : 0.009608863852918148
Loss at iteration 1690 : 0.0113728241994977
Loss at iteration 1700 : 0.012523291632533073
Loss at iteration 1710 : 0.010188385844230652
Loss at iteration 1720 : 0.021053263917565346
Loss at iteration 1730 : 0.01302250288426876
Loss at iteration 1740 : 0.005725450813770294
Loss at iteration 1750 : 0.0079793781042099
Loss at iteration 1760 : 0.0075700352899730206
Loss at iteration 1770 : 0.00715304259210825
Loss at iteration 1780 : 0.018425675109028816
Loss at iteration 1790 : 0.009577087126672268
Loss at iteration 1800 : 0.009453089907765388
Loss at iteration 1810 : 0.012665504589676857
Loss at iteration 1820 : 0.022863520309329033
Loss at iteration 1830 : 0.008851144462823868
Loss at iteration 1840 : 0.014972317963838577
Loss at iteration 1850 : 0.0069593144580721855
Loss at iteration 1860 : 0.009187771007418633
Loss at iteration 1870 : 0.008962392807006836
Loss at iteration 1880 : 0.012163056060671806
Loss at iteration 1890 : 0.01083786878734827
Loss at iteration 1900 : 0.01699637994170189
Loss at iteration 1910 : 0.006334921810775995
Loss at iteration 1920 : 0.008586278185248375
Loss at iteration 1930 : 0.007370736449956894
Loss at iteration 1940 : 0.005621311254799366
Loss at iteration 1950 : 0.004389805253595114
Loss at iteration 1960 : 0.004301668610423803
Loss at iteration 1970 : 0.00859556533396244
Loss at iteration 1980 : 0.014312488958239555
Loss at iteration 1990 : 0.01152973435819149
Loss at iteration 2000 : 0.003857849631458521
Loss at iteration 2010 : 0.018378615379333496
Loss at iteration 2020 : 0.009962941519916058
Loss at iteration 2030 : 0.007091343402862549
Loss at iteration 2040 : 0.012254960834980011
Loss at iteration 2050 : 0.012485593557357788
Loss at iteration 2060 : 0.008375787176191807
Loss at iteration 2070 : 0.01631573960185051
Loss at iteration 2080 : 0.014233670197427273
Loss at iteration 2090 : 0.009759669192135334
Loss at iteration 2100 : 0.00417008250951767
Loss at iteration 2110 : 0.01066385954618454
Loss at iteration 2120 : 0.00908667128533125
Loss at iteration 2130 : 0.008250606246292591
Loss at iteration 2140 : 0.011864328756928444
Loss at iteration 2150 : 0.013525499030947685
Loss at iteration 2160 : 0.007868676446378231
Loss at iteration 2170 : 0.008717957884073257
Loss at iteration 2180 : 0.004816856700927019
Loss at iteration 2190 : 0.03224126249551773
Loss at iteration 2200 : 0.006128103472292423
Loss at iteration 2210 : 0.01876469887793064
Loss at iteration 2220 : 0.009103263728320599
Loss at iteration 2230 : 0.0043720765970647335
Loss at iteration 2240 : 0.01562834531068802
Loss at iteration 2250 : 0.008149340748786926
Loss at iteration 2260 : 0.020173147320747375
Loss at iteration 2270 : 0.03476107120513916
Loss at iteration 2280 : 0.009666749276220798
Loss at iteration 2290 : 0.018029868602752686
Loss at iteration 2300 : 0.021980296820402145
Loss at iteration 2310 : 0.018377553671598434
Loss at iteration 2320 : 0.0068487427197396755
Loss at iteration 2330 : 0.010679537430405617
Loss at iteration 2340 : 0.010472514666616917
Loss at iteration 2350 : 0.013197786174714565
Loss at iteration 2360 : 0.008581601083278656
Loss at iteration 2370 : 0.014415701851248741
Loss at iteration 2380 : 0.006027597934007645
Loss at iteration 2390 : 0.011894755065441132
Loss at iteration 2400 : 0.010725323110818863
Loss at iteration 2410 : 0.01024695672094822
Loss at iteration 2420 : 0.006110350601375103
The SSIM Value is: 0.8257935563723247
The PSNR Value is: 20.38918596903483
the epoch is: 31
Loss at iteration 10 : 0.015608934685587883
Loss at iteration 20 : 0.016830777749419212
Loss at iteration 30 : 0.011534882709383965
Loss at iteration 40 : 0.025122523307800293
Loss at iteration 50 : 0.012797288596630096
Loss at iteration 60 : 0.015950314700603485
Loss at iteration 70 : 0.011052917689085007
Loss at iteration 80 : 0.0075003765523433685
Loss at iteration 90 : 0.008099034428596497
Loss at iteration 100 : 0.01416508387774229
Loss at iteration 110 : 0.015460414811968803
Loss at iteration 120 : 0.014922145754098892
Loss at iteration 130 : 0.008464359678328037
Loss at iteration 140 : 0.011141413822770119
Loss at iteration 150 : 0.018009411171078682
Loss at iteration 160 : 0.00867218617349863
Loss at iteration 170 : 0.010737178847193718
Loss at iteration 180 : 0.007843856699764729
Loss at iteration 190 : 0.01230534352362156
Loss at iteration 200 : 0.011153444647789001
Loss at iteration 210 : 0.008739788085222244
Loss at iteration 220 : 0.011647030711174011
Loss at iteration 230 : 0.011918577365577221
Loss at iteration 240 : 0.009803550317883492
Loss at iteration 250 : 0.011723760515451431
Loss at iteration 260 : 0.014675140380859375
Loss at iteration 270 : 0.008526120334863663
Loss at iteration 280 : 0.010911291465163231
Loss at iteration 290 : 0.010378177277743816
Loss at iteration 300 : 0.007563549559563398
Loss at iteration 310 : 0.009161589667201042
Loss at iteration 320 : 0.015214834362268448
Loss at iteration 330 : 0.010726138949394226
Loss at iteration 340 : 0.01070988830178976
Loss at iteration 350 : 0.01264733262360096
Loss at iteration 360 : 0.0097865154966712
Loss at iteration 370 : 0.011303594335913658
Loss at iteration 380 : 0.008751173503696918
Loss at iteration 390 : 0.011863566935062408
Loss at iteration 400 : 0.018899668008089066
Loss at iteration 410 : 0.021164659410715103
Loss at iteration 420 : 0.01213849987834692
Loss at iteration 430 : 0.005674641579389572
Loss at iteration 440 : 0.011841464787721634
Loss at iteration 450 : 0.006433445494621992
Loss at iteration 460 : 0.007876548916101456
Loss at iteration 470 : 0.01589924283325672
Loss at iteration 480 : 0.00840641651302576
Loss at iteration 490 : 0.01253223605453968
Loss at iteration 500 : 0.01368256751447916
Loss at iteration 510 : 0.014074924401938915
Loss at iteration 520 : 0.014987509697675705
Loss at iteration 530 : 0.007484297268092632
Loss at iteration 540 : 0.010058622807264328
Loss at iteration 550 : 0.0162604209035635
Loss at iteration 560 : 0.016604680567979813
Loss at iteration 570 : 0.010976049117743969
Loss at iteration 580 : 0.010127238929271698
Loss at iteration 590 : 0.008550689555704594
Loss at iteration 600 : 0.010278929956257343
Loss at iteration 610 : 0.012948887422680855
Loss at iteration 620 : 0.0041998908855021
Loss at iteration 630 : 0.013637691736221313
Loss at iteration 640 : 0.02119322679936886
Loss at iteration 650 : 0.020182861015200615
Loss at iteration 660 : 0.006795366760343313
Loss at iteration 670 : 0.0032392702996730804
Loss at iteration 680 : 0.004620793275535107
Loss at iteration 690 : 0.019526740536093712
Loss at iteration 700 : 0.013279438018798828
Loss at iteration 710 : 0.009862925857305527
Loss at iteration 720 : 0.0041928524151444435
Loss at iteration 730 : 0.007675898261368275
Loss at iteration 740 : 0.010703453794121742
Loss at iteration 750 : 0.007469985634088516
Loss at iteration 760 : 0.006253674626350403
Loss at iteration 770 : 0.006629761774092913
Loss at iteration 780 : 0.009038858115673065
Loss at iteration 790 : 0.009709782898426056
Loss at iteration 800 : 0.006122316233813763
Loss at iteration 810 : 0.02876250445842743
Loss at iteration 820 : 0.009655401110649109
Loss at iteration 830 : 0.00903487391769886
Loss at iteration 840 : 0.010652076452970505
Loss at iteration 850 : 0.005761576350778341
Loss at iteration 860 : 0.008491327054798603
Loss at iteration 870 : 0.017610210925340652
Loss at iteration 880 : 0.007548691239207983
Loss at iteration 890 : 0.007312466390430927
Loss at iteration 900 : 0.00804927758872509
Loss at iteration 910 : 0.009274187497794628
Loss at iteration 920 : 0.014695278368890285
Loss at iteration 930 : 0.012769361957907677
Loss at iteration 940 : 0.012122228741645813
Loss at iteration 950 : 0.008284060284495354
Loss at iteration 960 : 0.009061014279723167
Loss at iteration 970 : 0.01006382331252098
Loss at iteration 980 : 0.005507409106940031
Loss at iteration 990 : 0.010307029820978642
Loss at iteration 1000 : 0.0067939674481749535
Loss at iteration 1010 : 0.00811421126127243
Loss at iteration 1020 : 0.018383648246526718
Loss at iteration 1030 : 0.005555007141083479
Loss at iteration 1040 : 0.016451070085167885
Loss at iteration 1050 : 0.004849888384342194
Loss at iteration 1060 : 0.012151245959103107
Loss at iteration 1070 : 0.010393016040325165
Loss at iteration 1080 : 0.011770389974117279
Loss at iteration 1090 : 0.014633554965257645
Loss at iteration 1100 : 0.019336961209774017
Loss at iteration 1110 : 0.012978991493582726
Loss at iteration 1120 : 0.012141916900873184
Loss at iteration 1130 : 0.015795990824699402
Loss at iteration 1140 : 0.02149932272732258
Loss at iteration 1150 : 0.007660951465368271
Loss at iteration 1160 : 0.00851832702755928
Loss at iteration 1170 : 0.004277217201888561
Loss at iteration 1180 : 0.015425089746713638
Loss at iteration 1190 : 0.009446674026548862
Loss at iteration 1200 : 0.014331867918372154
Loss at iteration 1210 : 0.006354333832859993
Loss at iteration 1220 : 0.0159648135304451
Loss at iteration 1230 : 0.009153843857347965
Loss at iteration 1240 : 0.011838247999548912
Loss at iteration 1250 : 0.006859239190816879
Loss at iteration 1260 : 0.017534272745251656
Loss at iteration 1270 : 0.013086702674627304
Loss at iteration 1280 : 0.011811193078756332
Loss at iteration 1290 : 0.011535851284861565
Loss at iteration 1300 : 0.004714944865554571
Loss at iteration 1310 : 0.014096368104219437
Loss at iteration 1320 : 0.011653123423457146
Loss at iteration 1330 : 0.010083626955747604
Loss at iteration 1340 : 0.007769649848341942
Loss at iteration 1350 : 0.007553290110081434
Loss at iteration 1360 : 0.013441458344459534
Loss at iteration 1370 : 0.011251294985413551
Loss at iteration 1380 : 0.008620216511189938
Loss at iteration 1390 : 0.009244782850146294
Loss at iteration 1400 : 0.018739838153123856
Loss at iteration 1410 : 0.014317063614726067
Loss at iteration 1420 : 0.0190871749073267
Loss at iteration 1430 : 0.03059668466448784
Loss at iteration 1440 : 0.010428747162222862
Loss at iteration 1450 : 0.013767414726316929
Loss at iteration 1460 : 0.006203433033078909
Loss at iteration 1470 : 0.006827354431152344
Loss at iteration 1480 : 0.0104839988052845
Loss at iteration 1490 : 0.013145138509571552
Loss at iteration 1500 : 0.010138949379324913
Loss at iteration 1510 : 0.012689490802586079
Loss at iteration 1520 : 0.008197350427508354
Loss at iteration 1530 : 0.007711241953074932
Loss at iteration 1540 : 0.020988930016756058
Loss at iteration 1550 : 0.00704007875174284
Loss at iteration 1560 : 0.012986302375793457
Loss at iteration 1570 : 0.009029467590153217
Loss at iteration 1580 : 0.013997863046824932
Loss at iteration 1590 : 0.009565886110067368
Loss at iteration 1600 : 0.011094664223492146
Loss at iteration 1610 : 0.010474160313606262
Loss at iteration 1620 : 0.024409160017967224
Loss at iteration 1630 : 0.00769287021830678
Loss at iteration 1640 : 0.01128329150378704
Loss at iteration 1650 : 0.009688200429081917
Loss at iteration 1660 : 0.00652898708358407
Loss at iteration 1670 : 0.00728409830480814
Loss at iteration 1680 : 0.013252869248390198
Loss at iteration 1690 : 0.013758471235632896
Loss at iteration 1700 : 0.014846036210656166
Loss at iteration 1710 : 0.009171773679554462
Loss at iteration 1720 : 0.0054960716515779495
Loss at iteration 1730 : 0.007238488644361496
Loss at iteration 1740 : 0.012804970145225525
Loss at iteration 1750 : 0.014943892136216164
Loss at iteration 1760 : 0.01055360771715641
Loss at iteration 1770 : 0.009874112904071808
Loss at iteration 1780 : 0.007778405677527189
Loss at iteration 1790 : 0.009124984964728355
Loss at iteration 1800 : 0.007484447211027145
Loss at iteration 1810 : 0.007977355271577835
Loss at iteration 1820 : 0.007583583239465952
Loss at iteration 1830 : 0.007873539812862873
Loss at iteration 1840 : 0.020053602755069733
Loss at iteration 1850 : 0.010566233657300472
Loss at iteration 1860 : 0.013186071068048477
Loss at iteration 1870 : 0.014524322934448719
Loss at iteration 1880 : 0.01144399493932724
Loss at iteration 1890 : 0.014866959303617477
Loss at iteration 1900 : 0.003647906705737114
Loss at iteration 1910 : 0.009708749130368233
Loss at iteration 1920 : 0.006625322625041008
Loss at iteration 1930 : 0.013846872374415398
Loss at iteration 1940 : 0.008546700701117516
Loss at iteration 1950 : 0.015348738059401512
Loss at iteration 1960 : 0.018366387113928795
Loss at iteration 1970 : 0.016086112707853317
Loss at iteration 1980 : 0.012788098305463791
Loss at iteration 1990 : 0.011318294331431389
Loss at iteration 2000 : 0.02046947553753853
Loss at iteration 2010 : 0.008725875057280064
Loss at iteration 2020 : 0.0189368799328804
Loss at iteration 2030 : 0.014288533478975296
Loss at iteration 2040 : 0.012769889086484909
Loss at iteration 2050 : 0.01371551863849163
Loss at iteration 2060 : 0.01251869648694992
Loss at iteration 2070 : 0.01990322582423687
Loss at iteration 2080 : 0.014178866520524025
Loss at iteration 2090 : 0.021726476028561592
Loss at iteration 2100 : 0.011221956461668015
Loss at iteration 2110 : 0.009605234488844872
Loss at iteration 2120 : 0.004129690118134022
Loss at iteration 2130 : 0.012357555329799652
Loss at iteration 2140 : 0.010474247857928276
Loss at iteration 2150 : 0.02034503035247326
Loss at iteration 2160 : 0.007858794182538986
Loss at iteration 2170 : 0.004648752044886351
Loss at iteration 2180 : 0.01816810667514801
Loss at iteration 2190 : 0.004717718344181776
Loss at iteration 2200 : 0.0070248860865831375
Loss at iteration 2210 : 0.011767415329813957
Loss at iteration 2220 : 0.007047690916806459
Loss at iteration 2230 : 0.006530801299959421
Loss at iteration 2240 : 0.005785219371318817
Loss at iteration 2250 : 0.01666874811053276
Loss at iteration 2260 : 0.005700215697288513
Loss at iteration 2270 : 0.008604939095675945
Loss at iteration 2280 : 0.017779560759663582
Loss at iteration 2290 : 0.011566129513084888
Loss at iteration 2300 : 0.0055809421464800835
Loss at iteration 2310 : 0.010883543640375137
Loss at iteration 2320 : 0.008398592472076416
Loss at iteration 2330 : 0.0076727597042918205
Loss at iteration 2340 : 0.007967336103320122
Loss at iteration 2350 : 0.013127081096172333
Loss at iteration 2360 : 0.007487573195248842
Loss at iteration 2370 : 0.02537975087761879
Loss at iteration 2380 : 0.006010170094668865
Loss at iteration 2390 : 0.015268265269696712
Loss at iteration 2400 : 0.015423567965626717
Loss at iteration 2410 : 0.0038424930535256863
Loss at iteration 2420 : 0.00838814489543438
The SSIM Value is: 0.83649582862854
The PSNR Value is: 21.190961392720542
the epoch is: 32
Loss at iteration 10 : 0.010413644835352898
Loss at iteration 20 : 0.008097385056316853
Loss at iteration 30 : 0.013370583765208721
Loss at iteration 40 : 0.004676257260143757
Loss at iteration 50 : 0.007897637784481049
Loss at iteration 60 : 0.006050835829228163
Loss at iteration 70 : 0.009139594621956348
Loss at iteration 80 : 0.012251644395291805
Loss at iteration 90 : 0.012377521954476833
Loss at iteration 100 : 0.017237916588783264
Loss at iteration 110 : 0.00757585559040308
Loss at iteration 120 : 0.010559591464698315
Loss at iteration 130 : 0.00859053898602724
Loss at iteration 140 : 0.03450103849172592
Loss at iteration 150 : 0.008104352280497551
Loss at iteration 160 : 0.00741036981344223
Loss at iteration 170 : 0.017463108524680138
Loss at iteration 180 : 0.006776666268706322
Loss at iteration 190 : 0.004998109303414822
Loss at iteration 200 : 0.006062310189008713
Loss at iteration 210 : 0.011501733213663101
Loss at iteration 220 : 0.02631896547973156
Loss at iteration 230 : 0.015806350857019424
Loss at iteration 240 : 0.011399365961551666
Loss at iteration 250 : 0.005296487361192703
Loss at iteration 260 : 0.008764192461967468
Loss at iteration 270 : 0.004442813340574503
Loss at iteration 280 : 0.016511419788002968
Loss at iteration 290 : 0.018786516040563583
Loss at iteration 300 : 0.021904990077018738
Loss at iteration 310 : 0.004444159101694822
Loss at iteration 320 : 0.015302710235118866
Loss at iteration 330 : 0.015500778332352638
Loss at iteration 340 : 0.003746067639440298
Loss at iteration 350 : 0.008468516170978546
Loss at iteration 360 : 0.020129825919866562
Loss at iteration 370 : 0.010092240758240223
Loss at iteration 380 : 0.009248295798897743
Loss at iteration 390 : 0.010423056781291962
Loss at iteration 400 : 0.006172972731292248
Loss at iteration 410 : 0.008461891673505306
Loss at iteration 420 : 0.01293875277042389
Loss at iteration 430 : 0.008213957771658897
Loss at iteration 440 : 0.012268020771443844
Loss at iteration 450 : 0.010002342984080315
Loss at iteration 460 : 0.008473111316561699
Loss at iteration 470 : 0.022063586860895157
Loss at iteration 480 : 0.013822702690958977
Loss at iteration 490 : 0.006042373366653919
Loss at iteration 500 : 0.010692909359931946
Loss at iteration 510 : 0.006323326379060745
Loss at iteration 520 : 0.009137384593486786
Loss at iteration 530 : 0.005573751404881477
Loss at iteration 540 : 0.012493113987147808
Loss at iteration 550 : 0.022752365097403526
Loss at iteration 560 : 0.005475869867950678
Loss at iteration 570 : 0.013265537098050117
Loss at iteration 580 : 0.010275408625602722
Loss at iteration 590 : 0.005332908593118191
Loss at iteration 600 : 0.008823401294648647
Loss at iteration 610 : 0.009142003953456879
Loss at iteration 620 : 0.007461452856659889
Loss at iteration 630 : 0.01161741092801094
Loss at iteration 640 : 0.01383200567215681
Loss at iteration 650 : 0.004403441678732634
Loss at iteration 660 : 0.008650841191411018
Loss at iteration 670 : 0.016810309141874313
Loss at iteration 680 : 0.012624469585716724
Loss at iteration 690 : 0.006750799715518951
Loss at iteration 700 : 0.010569529607892036
Loss at iteration 710 : 0.015483750030398369
Loss at iteration 720 : 0.011829383671283722
Loss at iteration 730 : 0.013569269329309464
Loss at iteration 740 : 0.013510316610336304
Loss at iteration 750 : 0.008213097229599953
Loss at iteration 760 : 0.007519105449318886
Loss at iteration 770 : 0.01215555053204298
Loss at iteration 780 : 0.01912815496325493
Loss at iteration 790 : 0.025662831962108612
Loss at iteration 800 : 0.011774588376283646
Loss at iteration 810 : 0.007138978224247694
Loss at iteration 820 : 0.008787775412201881
Loss at iteration 830 : 0.022105220705270767
Loss at iteration 840 : 0.008150562644004822
Loss at iteration 850 : 0.020502299070358276
Loss at iteration 860 : 0.00678278598934412
Loss at iteration 870 : 0.004703140817582607
Loss at iteration 880 : 0.005532821640372276
Loss at iteration 890 : 0.012934809550642967
Loss at iteration 900 : 0.005307653918862343
Loss at iteration 910 : 0.004512932151556015
Loss at iteration 920 : 0.003073010127991438
Loss at iteration 930 : 0.011042697355151176
Loss at iteration 940 : 0.02938075177371502
Loss at iteration 950 : 0.018865851685404778
Loss at iteration 960 : 0.008441132493317127
Loss at iteration 970 : 0.013035297393798828
Loss at iteration 980 : 0.004776223562657833
Loss at iteration 990 : 0.008266843855381012
Loss at iteration 1000 : 0.009599985554814339
Loss at iteration 1010 : 0.011509069241583347
Loss at iteration 1020 : 0.00885394774377346
Loss at iteration 1030 : 0.014972135424613953
Loss at iteration 1040 : 0.014706154353916645
Loss at iteration 1050 : 0.007832460105419159
Loss at iteration 1060 : 0.012911075726151466
Loss at iteration 1070 : 0.006768481805920601
Loss at iteration 1080 : 0.0242418572306633
Loss at iteration 1090 : 0.011462574824690819
Loss at iteration 1100 : 0.00908280536532402
Loss at iteration 1110 : 0.012754944153130054
Loss at iteration 1120 : 0.011351728811860085
Loss at iteration 1130 : 0.012448351830244064
Loss at iteration 1140 : 0.01825590431690216
Loss at iteration 1150 : 0.010562741197645664
Loss at iteration 1160 : 0.018734943121671677
Loss at iteration 1170 : 0.011328238993883133
Loss at iteration 1180 : 0.003610798856243491
Loss at iteration 1190 : 0.008502719923853874
Loss at iteration 1200 : 0.016040746122598648
Loss at iteration 1210 : 0.025465061888098717
Loss at iteration 1220 : 0.02277960628271103
Loss at iteration 1230 : 0.008346045389771461
Loss at iteration 1240 : 0.008530124090611935
Loss at iteration 1250 : 0.008969432674348354
Loss at iteration 1260 : 0.008191574364900589
Loss at iteration 1270 : 0.015452021732926369
Loss at iteration 1280 : 0.012739859521389008
Loss at iteration 1290 : 0.009859752841293812
Loss at iteration 1300 : 0.011855600401759148
Loss at iteration 1310 : 0.013546764850616455
Loss at iteration 1320 : 0.011651702225208282
Loss at iteration 1330 : 0.007103022653609514
Loss at iteration 1340 : 0.007211174815893173
Loss at iteration 1350 : 0.005332462023943663
Loss at iteration 1360 : 0.015671778470277786
Loss at iteration 1370 : 0.011853784322738647
Loss at iteration 1380 : 0.00888960063457489
Loss at iteration 1390 : 0.00946049764752388
Loss at iteration 1400 : 0.004139615688472986
Loss at iteration 1410 : 0.017534423619508743
Loss at iteration 1420 : 0.011368788778781891
Loss at iteration 1430 : 0.007409396581351757
Loss at iteration 1440 : 0.006571007892489433
Loss at iteration 1450 : 0.010174233466386795
Loss at iteration 1460 : 0.010436713695526123
Loss at iteration 1470 : 0.006413391791284084
Loss at iteration 1480 : 0.01175409834831953
Loss at iteration 1490 : 0.011867235414683819
Loss at iteration 1500 : 0.008645246736705303
Loss at iteration 1510 : 0.014081847853958607
Loss at iteration 1520 : 0.01349052507430315
Loss at iteration 1530 : 0.008307280018925667
Loss at iteration 1540 : 0.007405498996376991
Loss at iteration 1550 : 0.01127906795591116
Loss at iteration 1560 : 0.02222564071416855
Loss at iteration 1570 : 0.017044954001903534
Loss at iteration 1580 : 0.014635678380727768
Loss at iteration 1590 : 0.010361867025494576
Loss at iteration 1600 : 0.008206007070839405
Loss at iteration 1610 : 0.005615144036710262
Loss at iteration 1620 : 0.012256225571036339
Loss at iteration 1630 : 0.016020966693758965
Loss at iteration 1640 : 0.01649259403347969
Loss at iteration 1650 : 0.009582187049090862
Loss at iteration 1660 : 0.023080965504050255
Loss at iteration 1670 : 0.006852829363197088
Loss at iteration 1680 : 0.010231229476630688
Loss at iteration 1690 : 0.004400771111249924
Loss at iteration 1700 : 0.015709584578871727
Loss at iteration 1710 : 0.010873718187212944
Loss at iteration 1720 : 0.018236326053738594
Loss at iteration 1730 : 0.018398426473140717
Loss at iteration 1740 : 0.031801410019397736
Loss at iteration 1750 : 0.009610360488295555
Loss at iteration 1760 : 0.0067824143916368484
Loss at iteration 1770 : 0.007082799449563026
Loss at iteration 1780 : 0.015380704775452614
Loss at iteration 1790 : 0.007974760606884956
Loss at iteration 1800 : 0.006703830324113369
Loss at iteration 1810 : 0.011947792023420334
Loss at iteration 1820 : 0.01590898260474205
Loss at iteration 1830 : 0.012404520064592361
Loss at iteration 1840 : 0.007871735841035843
Loss at iteration 1850 : 0.00940590351819992
Loss at iteration 1860 : 0.007488529197871685
Loss at iteration 1870 : 0.020037084817886353
Loss at iteration 1880 : 0.007520045153796673
Loss at iteration 1890 : 0.008896265178918839
Loss at iteration 1900 : 0.009478876367211342
Loss at iteration 1910 : 0.009397921152412891
Loss at iteration 1920 : 0.004630894400179386
Loss at iteration 1930 : 0.0073728254064917564
Loss at iteration 1940 : 0.007669808343052864
Loss at iteration 1950 : 0.01097351498901844
Loss at iteration 1960 : 0.007722659036517143
Loss at iteration 1970 : 0.011694910936057568
Loss at iteration 1980 : 0.008313816040754318
Loss at iteration 1990 : 0.010415913537144661
Loss at iteration 2000 : 0.015116875059902668
Loss at iteration 2010 : 0.008248214609920979
Loss at iteration 2020 : 0.012692100368440151
Loss at iteration 2030 : 0.012321527116000652
Loss at iteration 2040 : 0.00930262915790081
Loss at iteration 2050 : 0.009197602979838848
Loss at iteration 2060 : 0.009309204295277596
Loss at iteration 2070 : 0.012943871319293976
Loss at iteration 2080 : 0.01687213033437729
Loss at iteration 2090 : 0.005037541501224041
Loss at iteration 2100 : 0.013687754049897194
Loss at iteration 2110 : 0.006827490869909525
Loss at iteration 2120 : 0.01343436911702156
Loss at iteration 2130 : 0.010999057441949844
Loss at iteration 2140 : 0.03468121588230133
Loss at iteration 2150 : 0.006257432512938976
Loss at iteration 2160 : 0.01202140562236309
Loss at iteration 2170 : 0.007462888024747372
Loss at iteration 2180 : 0.02076621726155281
Loss at iteration 2190 : 0.02117275632917881
Loss at iteration 2200 : 0.012001918628811836
Loss at iteration 2210 : 0.017623592168092728
Loss at iteration 2220 : 0.010793408378958702
Loss at iteration 2230 : 0.009445869363844395
Loss at iteration 2240 : 0.008972791954874992
Loss at iteration 2250 : 0.00481400778517127
Loss at iteration 2260 : 0.014460265636444092
Loss at iteration 2270 : 0.01659046858549118
Loss at iteration 2280 : 0.007324965205043554
Loss at iteration 2290 : 0.022081267088651657
Loss at iteration 2300 : 0.017122073099017143
Loss at iteration 2310 : 0.0055635105818510056
Loss at iteration 2320 : 0.018118534237146378
Loss at iteration 2330 : 0.021824510768055916
Loss at iteration 2340 : 0.009682916104793549
Loss at iteration 2350 : 0.012911299243569374
Loss at iteration 2360 : 0.01101851835846901
Loss at iteration 2370 : 0.005954256281256676
Loss at iteration 2380 : 0.005975186824798584
Loss at iteration 2390 : 0.007314045913517475
Loss at iteration 2400 : 0.017479708418250084
Loss at iteration 2410 : 0.006066686473786831
Loss at iteration 2420 : 0.011990850791335106
The SSIM Value is: 0.8421993215878805
The PSNR Value is: 21.32329813639323
the epoch is: 33
Loss at iteration 10 : 0.01275617629289627
Loss at iteration 20 : 0.012858632020652294
Loss at iteration 30 : 0.006853610742837191
Loss at iteration 40 : 0.010280057787895203
Loss at iteration 50 : 0.00708247534930706
Loss at iteration 60 : 0.011255658231675625
Loss at iteration 70 : 0.009058383293449879
Loss at iteration 80 : 0.017684094607830048
Loss at iteration 90 : 0.018405677750706673
Loss at iteration 100 : 0.008764686062932014
Loss at iteration 110 : 0.03406926989555359
Loss at iteration 120 : 0.007064384408295155
Loss at iteration 130 : 0.0037932470440864563
Loss at iteration 140 : 0.015951089560985565
Loss at iteration 150 : 0.013610916212201118
Loss at iteration 160 : 0.018557395786046982
Loss at iteration 170 : 0.006822417490184307
Loss at iteration 180 : 0.012511905282735825
Loss at iteration 190 : 0.010641176253557205
Loss at iteration 200 : 0.015321001410484314
Loss at iteration 210 : 0.008147338405251503
Loss at iteration 220 : 0.006266053766012192
Loss at iteration 230 : 0.012093236669898033
Loss at iteration 240 : 0.005561542697250843
Loss at iteration 250 : 0.009390544146299362
Loss at iteration 260 : 0.007483021356165409
Loss at iteration 270 : 0.008100843988358974
Loss at iteration 280 : 0.003642059862613678
Loss at iteration 290 : 0.010342363268136978
Loss at iteration 300 : 0.014857292175292969
Loss at iteration 310 : 0.01072890218347311
Loss at iteration 320 : 0.008598452433943748
Loss at iteration 330 : 0.003973694052547216
Loss at iteration 340 : 0.009581314399838448
Loss at iteration 350 : 0.015873147174715996
Loss at iteration 360 : 0.01232110895216465
Loss at iteration 370 : 0.017463523894548416
Loss at iteration 380 : 0.008683420717716217
Loss at iteration 390 : 0.02115144208073616
Loss at iteration 400 : 0.01234256848692894
Loss at iteration 410 : 0.024643968790769577
Loss at iteration 420 : 0.00447554886341095
Loss at iteration 430 : 0.01216210424900055
Loss at iteration 440 : 0.0215362049639225
Loss at iteration 450 : 0.008748043328523636
Loss at iteration 460 : 0.014091715216636658
Loss at iteration 470 : 0.009366797283291817
Loss at iteration 480 : 0.006861933507025242
Loss at iteration 490 : 0.021157018840312958
Loss at iteration 500 : 0.014632709324359894
Loss at iteration 510 : 0.012423906475305557
Loss at iteration 520 : 0.006447444204241037
Loss at iteration 530 : 0.008254364132881165
Loss at iteration 540 : 0.01575084961950779
Loss at iteration 550 : 0.016598356887698174
Loss at iteration 560 : 0.008840869180858135
Loss at iteration 570 : 0.006955686025321484
Loss at iteration 580 : 0.009980758652091026
Loss at iteration 590 : 0.011829612776637077
Loss at iteration 600 : 0.0049910652451217175
Loss at iteration 610 : 0.00396658293902874
Loss at iteration 620 : 0.006228243000805378
Loss at iteration 630 : 0.003737474326044321
Loss at iteration 640 : 0.01369001530110836
Loss at iteration 650 : 0.007789757568389177
Loss at iteration 660 : 0.013490352779626846
Loss at iteration 670 : 0.014321252703666687
Loss at iteration 680 : 0.010441564954817295
Loss at iteration 690 : 0.006125539541244507
Loss at iteration 700 : 0.011204750277101994
Loss at iteration 710 : 0.004975098185241222
Loss at iteration 720 : 0.01500017661601305
Loss at iteration 730 : 0.01371006853878498
Loss at iteration 740 : 0.007920583710074425
Loss at iteration 750 : 0.01101358700543642
Loss at iteration 760 : 0.013020013459026814
Loss at iteration 770 : 0.006262251641601324
Loss at iteration 780 : 0.016092143952846527
Loss at iteration 790 : 0.02458428405225277
Loss at iteration 800 : 0.005180848762392998
Loss at iteration 810 : 0.007349611725658178
Loss at iteration 820 : 0.007210158742964268
Loss at iteration 830 : 0.012533660978078842
Loss at iteration 840 : 0.011284730397164822
Loss at iteration 850 : 0.010830446146428585
Loss at iteration 860 : 0.013172976672649384
Loss at iteration 870 : 0.011266222223639488
Loss at iteration 880 : 0.007108937483280897
Loss at iteration 890 : 0.012991043739020824
Loss at iteration 900 : 0.010869856923818588
Loss at iteration 910 : 0.009318768046796322
Loss at iteration 920 : 0.009998384863138199
Loss at iteration 930 : 0.00994629692286253
Loss at iteration 940 : 0.018158234655857086
Loss at iteration 950 : 0.01000236812978983
Loss at iteration 960 : 0.008814065717160702
Loss at iteration 970 : 0.0064175426959991455
Loss at iteration 980 : 0.006107225548475981
Loss at iteration 990 : 0.017489811405539513
Loss at iteration 1000 : 0.011768973432481289
Loss at iteration 1010 : 0.006403536070138216
Loss at iteration 1020 : 0.011879542842507362
Loss at iteration 1030 : 0.01703573390841484
Loss at iteration 1040 : 0.03072759136557579
Loss at iteration 1050 : 0.007027062121778727
Loss at iteration 1060 : 0.006153874099254608
Loss at iteration 1070 : 0.009016638621687889
Loss at iteration 1080 : 0.016528591513633728
Loss at iteration 1090 : 0.009175451472401619
Loss at iteration 1100 : 0.017196983098983765
Loss at iteration 1110 : 0.0212184377014637
Loss at iteration 1120 : 0.011509392410516739
Loss at iteration 1130 : 0.015119784511625767
Loss at iteration 1140 : 0.009516183286905289
Loss at iteration 1150 : 0.01885807141661644
Loss at iteration 1160 : 0.02783084474503994
Loss at iteration 1170 : 0.019542643800377846
Loss at iteration 1180 : 0.0068638017401099205
Loss at iteration 1190 : 0.010112675838172436
Loss at iteration 1200 : 0.009750299155712128
Loss at iteration 1210 : 0.010867233388125896
Loss at iteration 1220 : 0.01688320003449917
Loss at iteration 1230 : 0.008221667259931564
Loss at iteration 1240 : 0.00834210030734539
Loss at iteration 1250 : 0.015507131814956665
Loss at iteration 1260 : 0.009110964834690094
Loss at iteration 1270 : 0.003486056113615632
Loss at iteration 1280 : 0.020639969035983086
Loss at iteration 1290 : 0.036652661859989166
Loss at iteration 1300 : 0.006958262529224157
Loss at iteration 1310 : 0.006219933275133371
Loss at iteration 1320 : 0.008743183687329292
Loss at iteration 1330 : 0.01774883083999157
Loss at iteration 1340 : 0.020365234464406967
Loss at iteration 1350 : 0.01192947756499052
Loss at iteration 1360 : 0.011892746202647686
Loss at iteration 1370 : 0.021401982754468918
Loss at iteration 1380 : 0.008156770840287209
Loss at iteration 1390 : 0.005383919458836317
Loss at iteration 1400 : 0.011155537329614162
Loss at iteration 1410 : 0.006083515472710133
Loss at iteration 1420 : 0.00806331355124712
Loss at iteration 1430 : 0.010572695173323154
Loss at iteration 1440 : 0.009118427522480488
Loss at iteration 1450 : 0.012771536596119404
Loss at iteration 1460 : 0.015371984802186489
Loss at iteration 1470 : 0.006338439416140318
Loss at iteration 1480 : 0.007808569353073835
Loss at iteration 1490 : 0.02735200524330139
Loss at iteration 1500 : 0.010785617865622044
Loss at iteration 1510 : 0.011274751275777817
Loss at iteration 1520 : 0.007501487620174885
Loss at iteration 1530 : 0.008375827223062515
Loss at iteration 1540 : 0.011391865089535713
Loss at iteration 1550 : 0.010147672146558762
Loss at iteration 1560 : 0.011866702698171139
Loss at iteration 1570 : 0.00806398130953312
Loss at iteration 1580 : 0.01910022273659706
Loss at iteration 1590 : 0.013743143528699875
Loss at iteration 1600 : 0.010776055976748466
Loss at iteration 1610 : 0.00846067350357771
Loss at iteration 1620 : 0.009000981226563454
Loss at iteration 1630 : 0.014125805348157883
Loss at iteration 1640 : 0.016983605921268463
Loss at iteration 1650 : 0.009947886690497398
Loss at iteration 1660 : 0.013719231821596622
Loss at iteration 1670 : 0.01897354982793331
Loss at iteration 1680 : 0.01259231474250555
Loss at iteration 1690 : 0.019067293033003807
Loss at iteration 1700 : 0.031242871657013893
Loss at iteration 1710 : 0.01174092199653387
Loss at iteration 1720 : 0.00965999998152256
Loss at iteration 1730 : 0.017550114542245865
Loss at iteration 1740 : 0.009033428505063057
Loss at iteration 1750 : 0.025839917361736298
Loss at iteration 1760 : 0.011343920603394508
Loss at iteration 1770 : 0.00832128245383501
Loss at iteration 1780 : 0.01107124425470829
Loss at iteration 1790 : 0.012473119422793388
Loss at iteration 1800 : 0.01980387046933174
Loss at iteration 1810 : 0.009411098435521126
Loss at iteration 1820 : 0.006085025612264872
Loss at iteration 1830 : 0.005327926948666573
Loss at iteration 1840 : 0.00577976368367672
Loss at iteration 1850 : 0.004787489306181669
Loss at iteration 1860 : 0.019467411562800407
Loss at iteration 1870 : 0.010055676102638245
Loss at iteration 1880 : 0.01174076646566391
Loss at iteration 1890 : 0.006182885263115168
Loss at iteration 1900 : 0.0097505496814847
Loss at iteration 1910 : 0.00776308961212635
Loss at iteration 1920 : 0.009423913434147835
Loss at iteration 1930 : 0.01776074804365635
Loss at iteration 1940 : 0.009611593559384346
Loss at iteration 1950 : 0.011654661037027836
Loss at iteration 1960 : 0.012226080521941185
Loss at iteration 1970 : 0.01610678806900978
Loss at iteration 1980 : 0.010790854692459106
Loss at iteration 1990 : 0.009078111499547958
Loss at iteration 2000 : 0.008069116622209549
Loss at iteration 2010 : 0.014902619644999504
Loss at iteration 2020 : 0.013578347861766815
Loss at iteration 2030 : 0.01787259429693222
Loss at iteration 2040 : 0.013346581719815731
Loss at iteration 2050 : 0.010395216755568981
Loss at iteration 2060 : 0.01618405617773533
Loss at iteration 2070 : 0.019731570035219193
Loss at iteration 2080 : 0.016958676278591156
Loss at iteration 2090 : 0.012962670996785164
Loss at iteration 2100 : 0.0052686044946312904
Loss at iteration 2110 : 0.008638527244329453
Loss at iteration 2120 : 0.0060804435051977634
Loss at iteration 2130 : 0.02349865436553955
Loss at iteration 2140 : 0.00544109707698226
Loss at iteration 2150 : 0.009182492271065712
Loss at iteration 2160 : 0.0128721222281456
Loss at iteration 2170 : 0.007900775410234928
Loss at iteration 2180 : 0.010531371459364891
Loss at iteration 2190 : 0.010183552280068398
Loss at iteration 2200 : 0.007962911389768124
Loss at iteration 2210 : 0.004863510839641094
Loss at iteration 2220 : 0.011409508995711803
Loss at iteration 2230 : 0.012269444763660431
Loss at iteration 2240 : 0.009590143337845802
Loss at iteration 2250 : 0.011649535968899727
Loss at iteration 2260 : 0.01343710906803608
Loss at iteration 2270 : 0.00828978419303894
Loss at iteration 2280 : 0.009356633760035038
Loss at iteration 2290 : 0.024094536900520325
Loss at iteration 2300 : 0.020756589248776436
Loss at iteration 2310 : 0.02446754090487957
Loss at iteration 2320 : 0.024007799103856087
Loss at iteration 2330 : 0.007621475029736757
Loss at iteration 2340 : 0.010191576555371284
Loss at iteration 2350 : 0.004820297472178936
Loss at iteration 2360 : 0.006410658359527588
Loss at iteration 2370 : 0.018354516476392746
Loss at iteration 2380 : 0.007743511348962784
Loss at iteration 2390 : 0.014776555821299553
Loss at iteration 2400 : 0.011608571745455265
Loss at iteration 2410 : 0.015125520527362823
Loss at iteration 2420 : 0.02033427357673645
The SSIM Value is: 0.8396360198656718
The PSNR Value is: 21.800089391072593
the epoch is: 34
Loss at iteration 10 : 0.007934920489788055
Loss at iteration 20 : 0.021014120429754257
Loss at iteration 30 : 0.03025425411760807
Loss at iteration 40 : 0.018118634819984436
Loss at iteration 50 : 0.01426246203482151
Loss at iteration 60 : 0.009268009103834629
Loss at iteration 70 : 0.016553234308958054
Loss at iteration 80 : 0.020302053540945053
Loss at iteration 90 : 0.015282271429896355
Loss at iteration 100 : 0.010592358186841011
Loss at iteration 110 : 0.009819095954298973
Loss at iteration 120 : 0.010706230998039246
Loss at iteration 130 : 0.009826112538576126
Loss at iteration 140 : 0.005472121760249138
Loss at iteration 150 : 0.007655447814613581
Loss at iteration 160 : 0.01654127612709999
Loss at iteration 170 : 0.0072775473818182945
Loss at iteration 180 : 0.009356362745165825
Loss at iteration 190 : 0.010999256744980812
Loss at iteration 200 : 0.013529863208532333
Loss at iteration 210 : 0.007608260493725538
Loss at iteration 220 : 0.008544162847101688
Loss at iteration 230 : 0.009207017719745636
Loss at iteration 240 : 0.006223120726644993
Loss at iteration 250 : 0.007979067042469978
Loss at iteration 260 : 0.02009613811969757
Loss at iteration 270 : 0.010372292250394821
Loss at iteration 280 : 0.007628405932337046
Loss at iteration 290 : 0.005789529532194138
Loss at iteration 300 : 0.018870914354920387
Loss at iteration 310 : 0.018987394869327545
Loss at iteration 320 : 0.0058160084299743176
Loss at iteration 330 : 0.018313901498913765
Loss at iteration 340 : 0.0160648413002491
Loss at iteration 350 : 0.006695695221424103
Loss at iteration 360 : 0.013242855668067932
Loss at iteration 370 : 0.00797057244926691
Loss at iteration 380 : 0.0037664733827114105
Loss at iteration 390 : 0.012616567313671112
Loss at iteration 400 : 0.011337168514728546
Loss at iteration 410 : 0.02412499487400055
Loss at iteration 420 : 0.010799739509820938
Loss at iteration 430 : 0.003928044345229864
Loss at iteration 440 : 0.008260508067905903
Loss at iteration 450 : 0.013269459828734398
Loss at iteration 460 : 0.013650085777044296
Loss at iteration 470 : 0.010330301709473133
Loss at iteration 480 : 0.006394926458597183
Loss at iteration 490 : 0.01003898773342371
Loss at iteration 500 : 0.014370019547641277
Loss at iteration 510 : 0.0053772274404764175
Loss at iteration 520 : 0.008662493899464607
Loss at iteration 530 : 0.005017782561480999
Loss at iteration 540 : 0.016630586236715317
Loss at iteration 550 : 0.013955798000097275
Loss at iteration 560 : 0.014536862261593342
Loss at iteration 570 : 0.020382985472679138
Loss at iteration 580 : 0.016205627471208572
Loss at iteration 590 : 0.007383589632809162
Loss at iteration 600 : 0.0079683568328619
Loss at iteration 610 : 0.009371379390358925
Loss at iteration 620 : 0.00855615921318531
Loss at iteration 630 : 0.024527547881007195
Loss at iteration 640 : 0.007266470696777105
Loss at iteration 650 : 0.019281072542071342
Loss at iteration 660 : 0.012557374313473701
Loss at iteration 670 : 0.014161655679345131
Loss at iteration 680 : 0.005085478536784649
Loss at iteration 690 : 0.005645338445901871
Loss at iteration 700 : 0.005688125733286142
Loss at iteration 710 : 0.01667320914566517
Loss at iteration 720 : 0.0158693790435791
Loss at iteration 730 : 0.0167311392724514
Loss at iteration 740 : 0.008766916580498219
Loss at iteration 750 : 0.0098457345739007
Loss at iteration 760 : 0.004653060808777809
Loss at iteration 770 : 0.011362615041434765
Loss at iteration 780 : 0.007627072278410196
Loss at iteration 790 : 0.00749055715277791
Loss at iteration 800 : 0.013249644078314304
Loss at iteration 810 : 0.006454091519117355
Loss at iteration 820 : 0.012846367433667183
Loss at iteration 830 : 0.010460828430950642
Loss at iteration 840 : 0.011544859036803246
Loss at iteration 850 : 0.012880823574960232
Loss at iteration 860 : 0.013105827383697033
Loss at iteration 870 : 0.007291118614375591
Loss at iteration 880 : 0.02058504894375801
Loss at iteration 890 : 0.006825890392065048
Loss at iteration 900 : 0.012611154466867447
Loss at iteration 910 : 0.005168437026441097
Loss at iteration 920 : 0.010578026995062828
Loss at iteration 930 : 0.012808004394173622
Loss at iteration 940 : 0.011569199152290821
Loss at iteration 950 : 0.01294622477144003
Loss at iteration 960 : 0.008251595310866833
Loss at iteration 970 : 0.014914163388311863
Loss at iteration 980 : 0.008217050693929195
Loss at iteration 990 : 0.005381899420171976
Loss at iteration 1000 : 0.012026477605104446
Loss at iteration 1010 : 0.013989444822072983
Loss at iteration 1020 : 0.01558955479413271
Loss at iteration 1030 : 0.018443046137690544
Loss at iteration 1040 : 0.009908666834235191
Loss at iteration 1050 : 0.008695613592863083
Loss at iteration 1060 : 0.011313308961689472
Loss at iteration 1070 : 0.015579529106616974
Loss at iteration 1080 : 0.007126144599169493
Loss at iteration 1090 : 0.007273879833519459
Loss at iteration 1100 : 0.007486984133720398
Loss at iteration 1110 : 0.003831463400274515
Loss at iteration 1120 : 0.012080632150173187
Loss at iteration 1130 : 0.0063816336914896965
Loss at iteration 1140 : 0.02165357768535614
Loss at iteration 1150 : 0.005676480941474438
Loss at iteration 1160 : 0.008661279454827309
Loss at iteration 1170 : 0.004742024466395378
Loss at iteration 1180 : 0.008311813697218895
Loss at iteration 1190 : 0.011794239282608032
Loss at iteration 1200 : 0.007765890099108219
Loss at iteration 1210 : 0.0128983985632658
Loss at iteration 1220 : 0.014843580313026905
Loss at iteration 1230 : 0.013920851051807404
Loss at iteration 1240 : 0.002237103646621108
Loss at iteration 1250 : 0.006093624979257584
Loss at iteration 1260 : 0.00850958377122879
Loss at iteration 1270 : 0.00610507233068347
Loss at iteration 1280 : 0.01377801038324833
Loss at iteration 1290 : 0.011396372690796852
Loss at iteration 1300 : 0.011935689486563206
Loss at iteration 1310 : 0.009825671091675758
Loss at iteration 1320 : 0.010632863268256187
Loss at iteration 1330 : 0.006495039910078049
Loss at iteration 1340 : 0.003933623433113098
Loss at iteration 1350 : 0.00782067608088255
Loss at iteration 1360 : 0.009711496531963348
Loss at iteration 1370 : 0.012509286403656006
Loss at iteration 1380 : 0.012235145084559917
Loss at iteration 1390 : 0.010227090679109097
Loss at iteration 1400 : 0.023174986243247986
Loss at iteration 1410 : 0.0050628166645765305
Loss at iteration 1420 : 0.003478194586932659
Loss at iteration 1430 : 0.013766107149422169
Loss at iteration 1440 : 0.010562869720160961
Loss at iteration 1450 : 0.02270454913377762
Loss at iteration 1460 : 0.0118169616907835
Loss at iteration 1470 : 0.007611564360558987
Loss at iteration 1480 : 0.006538433022797108
Loss at iteration 1490 : 0.012574856169521809
Loss at iteration 1500 : 0.010212341323494911
Loss at iteration 1510 : 0.008083455264568329
Loss at iteration 1520 : 0.010912919417023659
Loss at iteration 1530 : 0.014052122831344604
Loss at iteration 1540 : 0.010190675966441631
Loss at iteration 1550 : 0.009100730530917645
Loss at iteration 1560 : 0.010175483301281929
Loss at iteration 1570 : 0.01293092779815197
Loss at iteration 1580 : 0.02186749503016472
Loss at iteration 1590 : 0.014237280935049057
Loss at iteration 1600 : 0.007417603395879269
Loss at iteration 1610 : 0.014562897384166718
Loss at iteration 1620 : 0.002617564285174012
Loss at iteration 1630 : 0.009875924326479435
Loss at iteration 1640 : 0.007883893325924873
Loss at iteration 1650 : 0.007354344706982374
Loss at iteration 1660 : 0.008879052475094795
Loss at iteration 1670 : 0.027315577492117882
Loss at iteration 1680 : 0.007133744657039642
Loss at iteration 1690 : 0.01681087352335453
Loss at iteration 1700 : 0.010011224076151848
Loss at iteration 1710 : 0.0062699089758098125
Loss at iteration 1720 : 0.009264779277145863
Loss at iteration 1730 : 0.007519837934523821
Loss at iteration 1740 : 0.011339276097714901
Loss at iteration 1750 : 0.020071614533662796
Loss at iteration 1760 : 0.01794769987463951
Loss at iteration 1770 : 0.009554954245686531
Loss at iteration 1780 : 0.005615629255771637
Loss at iteration 1790 : 0.02045067958533764
Loss at iteration 1800 : 0.0048913052305579185
Loss at iteration 1810 : 0.013763622380793095
Loss at iteration 1820 : 0.007770064286887646
Loss at iteration 1830 : 0.02844056859612465
Loss at iteration 1840 : 0.010992821305990219
Loss at iteration 1850 : 0.011115530505776405
Loss at iteration 1860 : 0.0042699286714196205
Loss at iteration 1870 : 0.009916387498378754
Loss at iteration 1880 : 0.016265476122498512
Loss at iteration 1890 : 0.007532250136137009
Loss at iteration 1900 : 0.02790141850709915
Loss at iteration 1910 : 0.011607672087848186
Loss at iteration 1920 : 0.008116277866065502
Loss at iteration 1930 : 0.01051254104822874
Loss at iteration 1940 : 0.007195413112640381
Loss at iteration 1950 : 0.006696122232824564
Loss at iteration 1960 : 0.010033980011940002
Loss at iteration 1970 : 0.013177323155105114
Loss at iteration 1980 : 0.015840064734220505
Loss at iteration 1990 : 0.010856307111680508
Loss at iteration 2000 : 0.00484905019402504
Loss at iteration 2010 : 0.0073575908318161964
Loss at iteration 2020 : 0.012787899933755398
Loss at iteration 2030 : 0.009967777878046036
Loss at iteration 2040 : 0.01232051569968462
Loss at iteration 2050 : 0.014429525472223759
Loss at iteration 2060 : 0.008067827671766281
Loss at iteration 2070 : 0.022968776524066925
Loss at iteration 2080 : 0.009647396393120289
Loss at iteration 2090 : 0.008589239791035652
Loss at iteration 2100 : 0.005042706150561571
Loss at iteration 2110 : 0.02091524377465248
Loss at iteration 2120 : 0.011500341817736626
Loss at iteration 2130 : 0.004990731831640005
Loss at iteration 2140 : 0.00994850043207407
Loss at iteration 2150 : 0.007752461824566126
Loss at iteration 2160 : 0.006071413867175579
Loss at iteration 2170 : 0.012449603527784348
Loss at iteration 2180 : 0.0050162216648459435
Loss at iteration 2190 : 0.005022663623094559
Loss at iteration 2200 : 0.009527917951345444
Loss at iteration 2210 : 0.006832105107605457
Loss at iteration 2220 : 0.006982872728258371
Loss at iteration 2230 : 0.002170816995203495
Loss at iteration 2240 : 0.006619518622756004
Loss at iteration 2250 : 0.006678957492113113
Loss at iteration 2260 : 0.009048759937286377
Loss at iteration 2270 : 0.008904866874217987
Loss at iteration 2280 : 0.014140239916741848
Loss at iteration 2290 : 0.01178752351552248
Loss at iteration 2300 : 0.012007894925773144
Loss at iteration 2310 : 0.007217051927000284
Loss at iteration 2320 : 0.008496652357280254
Loss at iteration 2330 : 0.007925186306238174
Loss at iteration 2340 : 0.011941393837332726
Loss at iteration 2350 : 0.011496614664793015
Loss at iteration 2360 : 0.008874828927218914
Loss at iteration 2370 : 0.010135207325220108
Loss at iteration 2380 : 0.011218937113881111
Loss at iteration 2390 : 0.008988562040030956
Loss at iteration 2400 : 0.011339375749230385
Loss at iteration 2410 : 0.010373211465775967
Loss at iteration 2420 : 0.011433091945946217
The SSIM Value is: 0.8391546090443929
The PSNR Value is: 21.85552895863851
the epoch is: 35
Loss at iteration 10 : 0.0107857221737504
Loss at iteration 20 : 0.010685546323657036
Loss at iteration 30 : 0.021699517965316772
Loss at iteration 40 : 0.005038359202444553
Loss at iteration 50 : 0.006762675009667873
Loss at iteration 60 : 0.01934128999710083
Loss at iteration 70 : 0.00871272012591362
Loss at iteration 80 : 0.006524512078613043
Loss at iteration 90 : 0.009235708974301815
Loss at iteration 100 : 0.012059615924954414
Loss at iteration 110 : 0.01097985077649355
Loss at iteration 120 : 0.006838276982307434
Loss at iteration 130 : 0.011764632537961006
Loss at iteration 140 : 0.008592069149017334
Loss at iteration 150 : 0.004771851468831301
Loss at iteration 160 : 0.015799636021256447
Loss at iteration 170 : 0.007555888965725899
Loss at iteration 180 : 0.006006419658660889
Loss at iteration 190 : 0.006310921162366867
Loss at iteration 200 : 0.008395334705710411
Loss at iteration 210 : 0.008430462330579758
Loss at iteration 220 : 0.004434581845998764
Loss at iteration 230 : 0.006174601148813963
Loss at iteration 240 : 0.030892949551343918
Loss at iteration 250 : 0.02810932882130146
Loss at iteration 260 : 0.00745878741145134
Loss at iteration 270 : 0.0203570444136858
Loss at iteration 280 : 0.024196386337280273
Loss at iteration 290 : 0.0034145801328122616
Loss at iteration 300 : 0.012497276067733765
Loss at iteration 310 : 0.02180830016732216
Loss at iteration 320 : 0.013809205032885075
Loss at iteration 330 : 0.009695304557681084
Loss at iteration 340 : 0.008136959746479988
Loss at iteration 350 : 0.008339370600879192
Loss at iteration 360 : 0.011286569759249687
Loss at iteration 370 : 0.006600717548280954
Loss at iteration 380 : 0.006578713655471802
Loss at iteration 390 : 0.005502571351826191
Loss at iteration 400 : 0.01191101036965847
Loss at iteration 410 : 0.010917635634541512
Loss at iteration 420 : 0.009966157376766205
Loss at iteration 430 : 0.010985716246068478
Loss at iteration 440 : 0.009081381373107433
Loss at iteration 450 : 0.01321091502904892
Loss at iteration 460 : 0.0061093904078006744
Loss at iteration 470 : 0.012192144989967346
Loss at iteration 480 : 0.012660284526646137
Loss at iteration 490 : 0.02175264060497284
Loss at iteration 500 : 0.012497887015342712
Loss at iteration 510 : 0.008352686651051044
Loss at iteration 520 : 0.006905979942530394
Loss at iteration 530 : 0.01909327134490013
Loss at iteration 540 : 0.014133812859654427
Loss at iteration 550 : 0.007048977538943291
Loss at iteration 560 : 0.007970760576426983
Loss at iteration 570 : 0.008868202567100525
Loss at iteration 580 : 0.02071302756667137
Loss at iteration 590 : 0.008438619785010815
Loss at iteration 600 : 0.013943512924015522
Loss at iteration 610 : 0.03607013821601868
Loss at iteration 620 : 0.0071212113834917545
Loss at iteration 630 : 0.013540845364332199
Loss at iteration 640 : 0.007463747635483742
Loss at iteration 650 : 0.007100458722561598
Loss at iteration 660 : 0.0068382807075977325
Loss at iteration 670 : 0.010423681698739529
Loss at iteration 680 : 0.01610286720097065
Loss at iteration 690 : 0.0072722602635622025
Loss at iteration 700 : 0.007452845573425293
Loss at iteration 710 : 0.00955124944448471
Loss at iteration 720 : 0.030480345711112022
Loss at iteration 730 : 0.006789336912333965
Loss at iteration 740 : 0.01699490286409855
Loss at iteration 750 : 0.01179361343383789
Loss at iteration 760 : 0.007308118976652622
Loss at iteration 770 : 0.013862034305930138
Loss at iteration 780 : 0.018008800223469734
Loss at iteration 790 : 0.019601210951805115
Loss at iteration 800 : 0.01605798862874508
Loss at iteration 810 : 0.007921263575553894
Loss at iteration 820 : 0.005996388848870993
Loss at iteration 830 : 0.014440465718507767
Loss at iteration 840 : 0.022173572331666946
Loss at iteration 850 : 0.00847407802939415
Loss at iteration 860 : 0.007535917218774557
Loss at iteration 870 : 0.01188044436275959
Loss at iteration 880 : 0.005519650876522064
Loss at iteration 890 : 0.009086002595722675
Loss at iteration 900 : 0.01303785014897585
Loss at iteration 910 : 0.011445784009993076
Loss at iteration 920 : 0.0053278785198926926
Loss at iteration 930 : 0.009349299594759941
Loss at iteration 940 : 0.01735765114426613
Loss at iteration 950 : 0.006419910117983818
Loss at iteration 960 : 0.00791106652468443
Loss at iteration 970 : 0.017748452723026276
Loss at iteration 980 : 0.009257744997739792
Loss at iteration 990 : 0.010934924706816673
Loss at iteration 1000 : 0.006682391278445721
Loss at iteration 1010 : 0.01837129145860672
Loss at iteration 1020 : 0.0078031159937381744
Loss at iteration 1030 : 0.017189279198646545
Loss at iteration 1040 : 0.008363800123333931
Loss at iteration 1050 : 0.00787992775440216
Loss at iteration 1060 : 0.005932038649916649
Loss at iteration 1070 : 0.009296152740716934
Loss at iteration 1080 : 0.018066225573420525
Loss at iteration 1090 : 0.010020071640610695
Loss at iteration 1100 : 0.00978639256209135
Loss at iteration 1110 : 0.009274549782276154
Loss at iteration 1120 : 0.005889911204576492
Loss at iteration 1130 : 0.009988333098590374
Loss at iteration 1140 : 0.020653557032346725
Loss at iteration 1150 : 0.012259481474757195
Loss at iteration 1160 : 0.021035853773355484
Loss at iteration 1170 : 0.009426005184650421
Loss at iteration 1180 : 0.007660524919629097
Loss at iteration 1190 : 0.0061840638518333435
Loss at iteration 1200 : 0.014854343608021736
Loss at iteration 1210 : 0.004034606274217367
Loss at iteration 1220 : 0.024192839860916138
Loss at iteration 1230 : 0.007103797979652882
Loss at iteration 1240 : 0.00887590553611517
Loss at iteration 1250 : 0.014063859358429909
Loss at iteration 1260 : 0.0110884765163064
Loss at iteration 1270 : 0.005988382268697023
Loss at iteration 1280 : 0.014743581414222717
Loss at iteration 1290 : 0.017077242955565453
Loss at iteration 1300 : 0.01180710457265377
Loss at iteration 1310 : 0.006711701862514019
Loss at iteration 1320 : 0.008600272238254547
Loss at iteration 1330 : 0.01210726611316204
Loss at iteration 1340 : 0.01575726829469204
Loss at iteration 1350 : 0.00834633782505989
Loss at iteration 1360 : 0.01574864238500595
Loss at iteration 1370 : 0.005722095724195242
Loss at iteration 1380 : 0.012093687430024147
Loss at iteration 1390 : 0.019615819677710533
Loss at iteration 1400 : 0.010111774317920208
Loss at iteration 1410 : 0.007905693724751472
Loss at iteration 1420 : 0.009983113966882229
Loss at iteration 1430 : 0.009486958384513855
Loss at iteration 1440 : 0.008530756458640099
Loss at iteration 1450 : 0.010257244110107422
Loss at iteration 1460 : 0.008601196110248566
Loss at iteration 1470 : 0.012263642624020576
Loss at iteration 1480 : 0.013604864478111267
Loss at iteration 1490 : 0.014549006707966328
Loss at iteration 1500 : 0.0058853039517998695
Loss at iteration 1510 : 0.00800954271107912
Loss at iteration 1520 : 0.013109033927321434
Loss at iteration 1530 : 0.01564405858516693
Loss at iteration 1540 : 0.021153688430786133
Loss at iteration 1550 : 0.005496700294315815
Loss at iteration 1560 : 0.016374241560697556
Loss at iteration 1570 : 0.006684127263724804
Loss at iteration 1580 : 0.016334770247340202
Loss at iteration 1590 : 0.015623318962752819
Loss at iteration 1600 : 0.01270361803472042
Loss at iteration 1610 : 0.03126528486609459
Loss at iteration 1620 : 0.013276452198624611
Loss at iteration 1630 : 0.01933053880929947
Loss at iteration 1640 : 0.011871419847011566
Loss at iteration 1650 : 0.01335417851805687
Loss at iteration 1660 : 0.008231333456933498
Loss at iteration 1670 : 0.011894674971699715
Loss at iteration 1680 : 0.010934939607977867
Loss at iteration 1690 : 0.014201123267412186
Loss at iteration 1700 : 0.007366197183728218
Loss at iteration 1710 : 0.010564739815890789
Loss at iteration 1720 : 0.0068057021126151085
Loss at iteration 1730 : 0.006645094603300095
Loss at iteration 1740 : 0.01123444177210331
Loss at iteration 1750 : 0.009002037346363068
Loss at iteration 1760 : 0.01188365463167429
Loss at iteration 1770 : 0.010981936007738113
Loss at iteration 1780 : 0.006775049027055502
Loss at iteration 1790 : 0.006604358088225126
Loss at iteration 1800 : 0.014429129660129547
Loss at iteration 1810 : 0.00968411099165678
Loss at iteration 1820 : 0.009495217353105545
Loss at iteration 1830 : 0.016581814736127853
Loss at iteration 1840 : 0.014671381562948227
Loss at iteration 1850 : 0.008547400124371052
Loss at iteration 1860 : 0.014083264395594597
Loss at iteration 1870 : 0.010095709934830666
Loss at iteration 1880 : 0.006804822012782097
Loss at iteration 1890 : 0.010331633500754833
Loss at iteration 1900 : 0.006095020100474358
Loss at iteration 1910 : 0.0033945441246032715
Loss at iteration 1920 : 0.006306605879217386
Loss at iteration 1930 : 0.008804176934063435
Loss at iteration 1940 : 0.007010317407548428
Loss at iteration 1950 : 0.01609986461699009
Loss at iteration 1960 : 0.015176310203969479
Loss at iteration 1970 : 0.010705962777137756
Loss at iteration 1980 : 0.023372799158096313
Loss at iteration 1990 : 0.01332891546189785
Loss at iteration 2000 : 0.009271339513361454
Loss at iteration 2010 : 0.015107812359929085
Loss at iteration 2020 : 0.009532422758638859
Loss at iteration 2030 : 0.019766470417380333
Loss at iteration 2040 : 0.010491213761270046
Loss at iteration 2050 : 0.004890751093626022
Loss at iteration 2060 : 0.006346366833895445
Loss at iteration 2070 : 0.011169921606779099
Loss at iteration 2080 : 0.01214471273124218
Loss at iteration 2090 : 0.012546169571578503
Loss at iteration 2100 : 0.005578112788498402
Loss at iteration 2110 : 0.009192677214741707
Loss at iteration 2120 : 0.0173992570489645
Loss at iteration 2130 : 0.00866910070180893
Loss at iteration 2140 : 0.01680035889148712
Loss at iteration 2150 : 0.008072045631706715
Loss at iteration 2160 : 0.005054648034274578
Loss at iteration 2170 : 0.009394326247274876
Loss at iteration 2180 : 0.007841046899557114
Loss at iteration 2190 : 0.009546086192131042
Loss at iteration 2200 : 0.030571620911359787
Loss at iteration 2210 : 0.008370042778551579
Loss at iteration 2220 : 0.005819809623062611
Loss at iteration 2230 : 0.008666006848216057
Loss at iteration 2240 : 0.007904772646725178
Loss at iteration 2250 : 0.008700808510184288
Loss at iteration 2260 : 0.0034526786766946316
Loss at iteration 2270 : 0.004600645042955875
Loss at iteration 2280 : 0.013067198917269707
Loss at iteration 2290 : 0.011567037552595139
Loss at iteration 2300 : 0.017520690336823463
Loss at iteration 2310 : 0.025649916380643845
Loss at iteration 2320 : 0.005422575864940882
Loss at iteration 2330 : 0.011502435430884361
Loss at iteration 2340 : 0.007621414959430695
Loss at iteration 2350 : 0.009476900100708008
Loss at iteration 2360 : 0.029018089175224304
Loss at iteration 2370 : 0.008157542906701565
Loss at iteration 2380 : 0.005337184760719538
Loss at iteration 2390 : 0.012900473549962044
Loss at iteration 2400 : 0.009016415104269981
Loss at iteration 2410 : 0.009407615289092064
Loss at iteration 2420 : 0.01649913191795349
The SSIM Value is: 0.8362658977508545
The PSNR Value is: 21.23235975901286
the epoch is: 36
Loss at iteration 10 : 0.007024833466857672
Loss at iteration 20 : 0.01412948314100504
Loss at iteration 30 : 0.009237460792064667
Loss at iteration 40 : 0.004753546789288521
Loss at iteration 50 : 0.006278590764850378
Loss at iteration 60 : 0.007930105552077293
Loss at iteration 70 : 0.007269436493515968
Loss at iteration 80 : 0.012801834382116795
Loss at iteration 90 : 0.00625406950712204
Loss at iteration 100 : 0.00324620702303946
Loss at iteration 110 : 0.011851188726723194
Loss at iteration 120 : 0.003903111908584833
Loss at iteration 130 : 0.009079204872250557
Loss at iteration 140 : 0.006445994600653648
Loss at iteration 150 : 0.015134342014789581
Loss at iteration 160 : 0.010157600976526737
Loss at iteration 170 : 0.00841887854039669
Loss at iteration 180 : 0.005936726927757263
Loss at iteration 190 : 0.00957503728568554
Loss at iteration 200 : 0.01108521781861782
Loss at iteration 210 : 0.01392337679862976
Loss at iteration 220 : 0.03183446079492569
Loss at iteration 230 : 0.012180669233202934
Loss at iteration 240 : 0.012707606889307499
Loss at iteration 250 : 0.009449267759919167
Loss at iteration 260 : 0.021145131438970566
Loss at iteration 270 : 0.016228944063186646
Loss at iteration 280 : 0.009731357917189598
Loss at iteration 290 : 0.011126268655061722
Loss at iteration 300 : 0.016815882176160812
Loss at iteration 310 : 0.0038961824029684067
Loss at iteration 320 : 0.002128800842911005
Loss at iteration 330 : 0.014019308611750603
Loss at iteration 340 : 0.009723246097564697
Loss at iteration 350 : 0.017179224640130997
Loss at iteration 360 : 0.014883926138281822
Loss at iteration 370 : 0.006839963607490063
Loss at iteration 380 : 0.014696390368044376
Loss at iteration 390 : 0.013915102928876877
Loss at iteration 400 : 0.010395443066954613
Loss at iteration 410 : 0.009816233068704605
Loss at iteration 420 : 0.010674461722373962
Loss at iteration 430 : 0.01301602553576231
Loss at iteration 440 : 0.016657544299960136
Loss at iteration 450 : 0.006879393942654133
Loss at iteration 460 : 0.006436586380004883
Loss at iteration 470 : 0.009727959521114826
Loss at iteration 480 : 0.004752213601022959
Loss at iteration 490 : 0.005140975583344698
Loss at iteration 500 : 0.013203359209001064
Loss at iteration 510 : 0.005341188982129097
Loss at iteration 520 : 0.01246604323387146
Loss at iteration 530 : 0.03455520421266556
Loss at iteration 540 : 0.015552782453596592
Loss at iteration 550 : 0.0022363667376339436
Loss at iteration 560 : 0.005442844703793526
Loss at iteration 570 : 0.017595037817955017
Loss at iteration 580 : 0.007373843342065811
Loss at iteration 590 : 0.01798246242105961
Loss at iteration 600 : 0.009236329235136509
Loss at iteration 610 : 0.006843329407274723
Loss at iteration 620 : 0.006035332567989826
Loss at iteration 630 : 0.015291820280253887
Loss at iteration 640 : 0.007127292454242706
Loss at iteration 650 : 0.015834888443350792
Loss at iteration 660 : 0.007215153891593218
Loss at iteration 670 : 0.010488409548997879
Loss at iteration 680 : 0.004335999488830566
Loss at iteration 690 : 0.014234676957130432
Loss at iteration 700 : 0.00997375138103962
Loss at iteration 710 : 0.013374860398471355
Loss at iteration 720 : 0.022556649520993233
Loss at iteration 730 : 0.014415556564927101
Loss at iteration 740 : 0.009480814449489117
Loss at iteration 750 : 0.01235702820122242
Loss at iteration 760 : 0.0067128390073776245
Loss at iteration 770 : 0.0053504412062466145
Loss at iteration 780 : 0.008886203169822693
Loss at iteration 790 : 0.015570699237287045
Loss at iteration 800 : 0.005912291817367077
Loss at iteration 810 : 0.010945739224553108
Loss at iteration 820 : 0.013068486005067825
Loss at iteration 830 : 0.0044803498312830925
Loss at iteration 840 : 0.006029533222317696
Loss at iteration 850 : 0.010362633503973484
Loss at iteration 860 : 0.01292521320283413
Loss at iteration 870 : 0.011234463192522526
Loss at iteration 880 : 0.016459809616208076
Loss at iteration 890 : 0.004142973572015762
Loss at iteration 900 : 0.007104718126356602
Loss at iteration 910 : 0.011147262528538704
Loss at iteration 920 : 0.010345111601054668
Loss at iteration 930 : 0.007133531384170055
Loss at iteration 940 : 0.009201640263199806
Loss at iteration 950 : 0.004609384573996067
Loss at iteration 960 : 0.0036258825566619635
Loss at iteration 970 : 0.008206258527934551
Loss at iteration 980 : 0.009025937877595425
Loss at iteration 990 : 0.008815214037895203
Loss at iteration 1000 : 0.012723036110401154
Loss at iteration 1010 : 0.007821948267519474
Loss at iteration 1020 : 0.008210703730583191
Loss at iteration 1030 : 0.00883292593061924
Loss at iteration 1040 : 0.011421939358115196
Loss at iteration 1050 : 0.014265663921833038
Loss at iteration 1060 : 0.018142729997634888
Loss at iteration 1070 : 0.019828416407108307
Loss at iteration 1080 : 0.020716261118650436
Loss at iteration 1090 : 0.017408445477485657
Loss at iteration 1100 : 0.007727732416242361
Loss at iteration 1110 : 0.010025150142610073
Loss at iteration 1120 : 0.006611847784370184
Loss at iteration 1130 : 0.010706618428230286
Loss at iteration 1140 : 0.01625015214085579
Loss at iteration 1150 : 0.022534852847456932
Loss at iteration 1160 : 0.02092605084180832
Loss at iteration 1170 : 0.017109569162130356
Loss at iteration 1180 : 0.008341904729604721
Loss at iteration 1190 : 0.015900615602731705
Loss at iteration 1200 : 0.017869701609015465
Loss at iteration 1210 : 0.012766363099217415
Loss at iteration 1220 : 0.008180459961295128
Loss at iteration 1230 : 0.02421664446592331
Loss at iteration 1240 : 0.01656678318977356
Loss at iteration 1250 : 0.006872964091598988
Loss at iteration 1260 : 0.008367796428501606
Loss at iteration 1270 : 0.002802393864840269
Loss at iteration 1280 : 0.012532975524663925
Loss at iteration 1290 : 0.011654206551611423
Loss at iteration 1300 : 0.004774076864123344
Loss at iteration 1310 : 0.012347031384706497
Loss at iteration 1320 : 0.014764077961444855
Loss at iteration 1330 : 0.005877551157027483
Loss at iteration 1340 : 0.013257335871458054
Loss at iteration 1350 : 0.014203950762748718
Loss at iteration 1360 : 0.011533129960298538
Loss at iteration 1370 : 0.017187798395752907
Loss at iteration 1380 : 0.013855907134711742
Loss at iteration 1390 : 0.007037376519292593
Loss at iteration 1400 : 0.008747688494622707
Loss at iteration 1410 : 0.007746760733425617
Loss at iteration 1420 : 0.014772026799619198
Loss at iteration 1430 : 0.005703294649720192
Loss at iteration 1440 : 0.009664200246334076
Loss at iteration 1450 : 0.010211387649178505
Loss at iteration 1460 : 0.003907252103090286
Loss at iteration 1470 : 0.015219493769109249
Loss at iteration 1480 : 0.008676467463374138
Loss at iteration 1490 : 0.0086806146427989
Loss at iteration 1500 : 0.01811026781797409
Loss at iteration 1510 : 0.012077953666448593
Loss at iteration 1520 : 0.007029473781585693
Loss at iteration 1530 : 0.012401103042066097
Loss at iteration 1540 : 0.01558336429297924
Loss at iteration 1550 : 0.019468776881694794
Loss at iteration 1560 : 0.006225608754903078
Loss at iteration 1570 : 0.02058323472738266
Loss at iteration 1580 : 0.01375498529523611
Loss at iteration 1590 : 0.012261159718036652
Loss at iteration 1600 : 0.006349620409309864
Loss at iteration 1610 : 0.006491297855973244
Loss at iteration 1620 : 0.009062637574970722
Loss at iteration 1630 : 0.009404980577528477
Loss at iteration 1640 : 0.013957802206277847
Loss at iteration 1650 : 0.008487441577017307
Loss at iteration 1660 : 0.01308616902679205
Loss at iteration 1670 : 0.01059479359537363
Loss at iteration 1680 : 0.01321733184158802
Loss at iteration 1690 : 0.005536981392651796
Loss at iteration 1700 : 0.00867503136396408
Loss at iteration 1710 : 0.005892751272767782
Loss at iteration 1720 : 0.010508970357477665
Loss at iteration 1730 : 0.011604414321482182
Loss at iteration 1740 : 0.014372906647622585
Loss at iteration 1750 : 0.015543750487267971
Loss at iteration 1760 : 0.008844198659062386
Loss at iteration 1770 : 0.010524505749344826
Loss at iteration 1780 : 0.008551180362701416
Loss at iteration 1790 : 0.010753443464636803
Loss at iteration 1800 : 0.008426705375313759
Loss at iteration 1810 : 0.011135457083582878
Loss at iteration 1820 : 0.014156404882669449
Loss at iteration 1830 : 0.014916673302650452
Loss at iteration 1840 : 0.004477806854993105
Loss at iteration 1850 : 0.0044291699305176735
Loss at iteration 1860 : 0.006147641222923994
Loss at iteration 1870 : 0.004738701973110437
Loss at iteration 1880 : 0.019841082394123077
Loss at iteration 1890 : 0.016105199232697487
Loss at iteration 1900 : 0.010572278872132301
Loss at iteration 1910 : 0.01815924234688282
Loss at iteration 1920 : 0.01967902109026909
Loss at iteration 1930 : 0.0059095825999975204
Loss at iteration 1940 : 0.011281067505478859
Loss at iteration 1950 : 0.021721914410591125
Loss at iteration 1960 : 0.010950477793812752
Loss at iteration 1970 : 0.01632438786327839
Loss at iteration 1980 : 0.004652439616620541
Loss at iteration 1990 : 0.011377066373825073
Loss at iteration 2000 : 0.00991189107298851
Loss at iteration 2010 : 0.007186717353761196
Loss at iteration 2020 : 0.015147533267736435
Loss at iteration 2030 : 0.008667020127177238
Loss at iteration 2040 : 0.01445075124502182
Loss at iteration 2050 : 0.012047627940773964
Loss at iteration 2060 : 0.01899728924036026
Loss at iteration 2070 : 0.005620306357741356
Loss at iteration 2080 : 0.012828340753912926
Loss at iteration 2090 : 0.02217276766896248
Loss at iteration 2100 : 0.007532152812927961
Loss at iteration 2110 : 0.014221718534827232
Loss at iteration 2120 : 0.006108223460614681
Loss at iteration 2130 : 0.015108074061572552
Loss at iteration 2140 : 0.007348731160163879
Loss at iteration 2150 : 0.01768377423286438
Loss at iteration 2160 : 0.01213433314114809
Loss at iteration 2170 : 0.009612730704247952
Loss at iteration 2180 : 0.008776414208114147
Loss at iteration 2190 : 0.010305169969797134
Loss at iteration 2200 : 0.017441485077142715
Loss at iteration 2210 : 0.013371272943913937
Loss at iteration 2220 : 0.006021305453032255
Loss at iteration 2230 : 0.013848722912371159
Loss at iteration 2240 : 0.00993763655424118
Loss at iteration 2250 : 0.017624348402023315
Loss at iteration 2260 : 0.0045484923757612705
Loss at iteration 2270 : 0.011628511361777782
Loss at iteration 2280 : 0.013985930010676384
Loss at iteration 2290 : 0.008482180535793304
Loss at iteration 2300 : 0.006412165239453316
Loss at iteration 2310 : 0.013888206332921982
Loss at iteration 2320 : 0.009635220281779766
Loss at iteration 2330 : 0.01258815173059702
Loss at iteration 2340 : 0.014498787000775337
Loss at iteration 2350 : 0.01358032412827015
Loss at iteration 2360 : 0.00969607662409544
Loss at iteration 2370 : 0.01735951006412506
Loss at iteration 2380 : 0.015921054407954216
Loss at iteration 2390 : 0.0078152259811759
Loss at iteration 2400 : 0.01078005600720644
Loss at iteration 2410 : 0.0048704203218221664
Loss at iteration 2420 : 0.01111453678458929
The SSIM Value is: 0.8412964105606079
The PSNR Value is: 21.379718081156412
the epoch is: 37
Loss at iteration 10 : 0.008266855031251907
Loss at iteration 20 : 0.006939495913684368
Loss at iteration 30 : 0.003465321846306324
Loss at iteration 40 : 0.008226136676967144
Loss at iteration 50 : 0.010563882067799568
Loss at iteration 60 : 0.017596300691366196
Loss at iteration 70 : 0.0054796067997813225
Loss at iteration 80 : 0.008369332179427147
Loss at iteration 90 : 0.009276009164750576
Loss at iteration 100 : 0.01063813641667366
Loss at iteration 110 : 0.014322055503726006
Loss at iteration 120 : 0.010577920824289322
Loss at iteration 130 : 0.012538447044789791
Loss at iteration 140 : 0.011682242155075073
Loss at iteration 150 : 0.006116276606917381
Loss at iteration 160 : 0.007066878955811262
Loss at iteration 170 : 0.01372239924967289
Loss at iteration 180 : 0.0325421504676342
Loss at iteration 190 : 0.011080684140324593
Loss at iteration 200 : 0.008634880185127258
Loss at iteration 210 : 0.013642248697578907
Loss at iteration 220 : 0.021463073790073395
Loss at iteration 230 : 0.036150012165308
Loss at iteration 240 : 0.02053230255842209
Loss at iteration 250 : 0.010054077953100204
Loss at iteration 260 : 0.008134224452078342
Loss at iteration 270 : 0.011107615195214748
Loss at iteration 280 : 0.018862582743167877
Loss at iteration 290 : 0.0066331420093774796
Loss at iteration 300 : 0.02328965999186039
Loss at iteration 310 : 0.004618716426193714
Loss at iteration 320 : 0.018488140776753426
Loss at iteration 330 : 0.014867287129163742
Loss at iteration 340 : 0.00814364105463028
Loss at iteration 350 : 0.007489691022783518
Loss at iteration 360 : 0.009558537043631077
Loss at iteration 370 : 0.008644334971904755
Loss at iteration 380 : 0.006997706368565559
Loss at iteration 390 : 0.014445427805185318
Loss at iteration 400 : 0.016374638304114342
Loss at iteration 410 : 0.005843887105584145
Loss at iteration 420 : 0.005429311189800501
Loss at iteration 430 : 0.014863256365060806
Loss at iteration 440 : 0.009451698511838913
Loss at iteration 450 : 0.008477562107145786
Loss at iteration 460 : 0.006303491070866585
Loss at iteration 470 : 0.0066933175548911095
Loss at iteration 480 : 0.016489803791046143
Loss at iteration 490 : 0.00987742654979229
Loss at iteration 500 : 0.02103760652244091
Loss at iteration 510 : 0.019055763259530067
Loss at iteration 520 : 0.011526744812726974
Loss at iteration 530 : 0.008111701346933842
Loss at iteration 540 : 0.00750337541103363
Loss at iteration 550 : 0.0101088285446167
Loss at iteration 560 : 0.013198976404964924
Loss at iteration 570 : 0.006335162092000246
Loss at iteration 580 : 0.008568508550524712
Loss at iteration 590 : 0.027411311864852905
Loss at iteration 600 : 0.006806616205722094
Loss at iteration 610 : 0.012896906584501266
Loss at iteration 620 : 0.018277915194630623
Loss at iteration 630 : 0.01647866703569889
Loss at iteration 640 : 0.016123514622449875
Loss at iteration 650 : 0.008408406749367714
Loss at iteration 660 : 0.019928794354200363
Loss at iteration 670 : 0.02319098636507988
Loss at iteration 680 : 0.01773647591471672
Loss at iteration 690 : 0.008151103742420673
Loss at iteration 700 : 0.014965148642659187
Loss at iteration 710 : 0.019642990082502365
Loss at iteration 720 : 0.009948373772203922
Loss at iteration 730 : 0.01111488975584507
Loss at iteration 740 : 0.010288655757904053
Loss at iteration 750 : 0.010363511741161346
Loss at iteration 760 : 0.012291571125388145
Loss at iteration 770 : 0.008327284827828407
Loss at iteration 780 : 0.012263250537216663
Loss at iteration 790 : 0.009374259039759636
Loss at iteration 800 : 0.01137491874396801
Loss at iteration 810 : 0.009968658909201622
Loss at iteration 820 : 0.010690690018236637
Loss at iteration 830 : 0.0071777282282710075
Loss at iteration 840 : 0.014882347546517849
Loss at iteration 850 : 0.012340991757810116
Loss at iteration 860 : 0.010905413888394833
Loss at iteration 870 : 0.007772877812385559
Loss at iteration 880 : 0.01741475984454155
Loss at iteration 890 : 0.01304566953331232
Loss at iteration 900 : 0.0043045524507761
Loss at iteration 910 : 0.004365372471511364
Loss at iteration 920 : 0.005985163617879152
Loss at iteration 930 : 0.014819271862506866
Loss at iteration 940 : 0.009278993122279644
Loss at iteration 950 : 0.018578320741653442
Loss at iteration 960 : 0.009158026427030563
Loss at iteration 970 : 0.008200915530323982
Loss at iteration 980 : 0.010012657381594181
Loss at iteration 990 : 0.01409294456243515
Loss at iteration 1000 : 0.006336122285574675
Loss at iteration 1010 : 0.0037272307090461254
Loss at iteration 1020 : 0.009791888296604156
Loss at iteration 1030 : 0.01228149514645338
Loss at iteration 1040 : 0.015714723616838455
Loss at iteration 1050 : 0.016517873853445053
Loss at iteration 1060 : 0.015852589160203934
Loss at iteration 1070 : 0.005535365082323551
Loss at iteration 1080 : 0.011634888127446175
Loss at iteration 1090 : 0.009996115230023861
Loss at iteration 1100 : 0.010846514254808426
Loss at iteration 1110 : 0.013730169273912907
Loss at iteration 1120 : 0.010008924640715122
Loss at iteration 1130 : 0.01782751828432083
Loss at iteration 1140 : 0.01876109652221203
Loss at iteration 1150 : 0.0075006019324064255
Loss at iteration 1160 : 0.004678070545196533
Loss at iteration 1170 : 0.013000018894672394
Loss at iteration 1180 : 0.008816839195787907
Loss at iteration 1190 : 0.006962261162698269
Loss at iteration 1200 : 0.030335616320371628
Loss at iteration 1210 : 0.009037785232067108
Loss at iteration 1220 : 0.008288626559078693
Loss at iteration 1230 : 0.009705623611807823
Loss at iteration 1240 : 0.005235770717263222
Loss at iteration 1250 : 0.009100465103983879
Loss at iteration 1260 : 0.006262493319809437
Loss at iteration 1270 : 0.01358410157263279
Loss at iteration 1280 : 0.009630218148231506
Loss at iteration 1290 : 0.011541617102921009
Loss at iteration 1300 : 0.011843103915452957
Loss at iteration 1310 : 0.011038574390113354
Loss at iteration 1320 : 0.01779237389564514
Loss at iteration 1330 : 0.017918230965733528
Loss at iteration 1340 : 0.014118704944849014
Loss at iteration 1350 : 0.01310785487294197
Loss at iteration 1360 : 0.007095429114997387
Loss at iteration 1370 : 0.007776515558362007
Loss at iteration 1380 : 0.005809498019516468
Loss at iteration 1390 : 0.01883261650800705
Loss at iteration 1400 : 0.014053143560886383
Loss at iteration 1410 : 0.013821372762322426
Loss at iteration 1420 : 0.0063588679768145084
Loss at iteration 1430 : 0.005422964692115784
Loss at iteration 1440 : 0.03747968003153801
Loss at iteration 1450 : 0.004449973348528147
Loss at iteration 1460 : 0.01187854539602995
Loss at iteration 1470 : 0.007315806578844786
Loss at iteration 1480 : 0.008496983908116817
Loss at iteration 1490 : 0.009413763880729675
Loss at iteration 1500 : 0.004151313565671444
Loss at iteration 1510 : 0.023493899032473564
Loss at iteration 1520 : 0.0126727856695652
Loss at iteration 1530 : 0.011591571383178234
Loss at iteration 1540 : 0.02245941199362278
Loss at iteration 1550 : 0.005529184825718403
Loss at iteration 1560 : 0.04020893573760986
Loss at iteration 1570 : 0.008454084396362305
Loss at iteration 1580 : 0.011772509664297104
Loss at iteration 1590 : 0.013304634019732475
Loss at iteration 1600 : 0.012464077211916447
Loss at iteration 1610 : 0.011713426560163498
Loss at iteration 1620 : 0.009228008799254894
Loss at iteration 1630 : 0.007890932261943817
Loss at iteration 1640 : 0.004325687885284424
Loss at iteration 1650 : 0.007117327302694321
Loss at iteration 1660 : 0.01080339401960373
Loss at iteration 1670 : 0.016323452815413475
Loss at iteration 1680 : 0.014451282098889351
Loss at iteration 1690 : 0.012284408323466778
Loss at iteration 1700 : 0.014346511103212833
Loss at iteration 1710 : 0.00507650151848793
Loss at iteration 1720 : 0.00691133551299572
Loss at iteration 1730 : 0.0057548703625798225
Loss at iteration 1740 : 0.004349247086793184
Loss at iteration 1750 : 0.007199228275567293
Loss at iteration 1760 : 0.016780801117420197
Loss at iteration 1770 : 0.0346427783370018
Loss at iteration 1780 : 0.01956915855407715
Loss at iteration 1790 : 0.011027267202734947
Loss at iteration 1800 : 0.017807813361287117
Loss at iteration 1810 : 0.006769523955881596
Loss at iteration 1820 : 0.023850709199905396
Loss at iteration 1830 : 0.012582981958985329
Loss at iteration 1840 : 0.009226927533745766
Loss at iteration 1850 : 0.010341519489884377
Loss at iteration 1860 : 0.006822867318987846
Loss at iteration 1870 : 0.020428504794836044
Loss at iteration 1880 : 0.013345508836209774
Loss at iteration 1890 : 0.007153062149882317
Loss at iteration 1900 : 0.012767121195793152
Loss at iteration 1910 : 0.01753164827823639
Loss at iteration 1920 : 0.00802383478730917
Loss at iteration 1930 : 0.006814810447394848
Loss at iteration 1940 : 0.01477297767996788
Loss at iteration 1950 : 0.019234132021665573
Loss at iteration 1960 : 0.01575692556798458
Loss at iteration 1970 : 0.005853367503732443
Loss at iteration 1980 : 0.005219553597271442
Loss at iteration 1990 : 0.00856449268758297
Loss at iteration 2000 : 0.013043368235230446
Loss at iteration 2010 : 0.003459587227553129
Loss at iteration 2020 : 0.005028180778026581
Loss at iteration 2030 : 0.00755565520375967
Loss at iteration 2040 : 0.014471333473920822
Loss at iteration 2050 : 0.021102985367178917
Loss at iteration 2060 : 0.015641439706087112
Loss at iteration 2070 : 0.009021528996527195
Loss at iteration 2080 : 0.0118772704154253
Loss at iteration 2090 : 0.013058517128229141
Loss at iteration 2100 : 0.005062652751803398
Loss at iteration 2110 : 0.010058272629976273
Loss at iteration 2120 : 0.008596666157245636
Loss at iteration 2130 : 0.0235552117228508
Loss at iteration 2140 : 0.0064785717986524105
Loss at iteration 2150 : 0.01592780277132988
Loss at iteration 2160 : 0.008123298175632954
Loss at iteration 2170 : 0.00877467356622219
Loss at iteration 2180 : 0.002405982930213213
Loss at iteration 2190 : 0.012631408870220184
Loss at iteration 2200 : 0.011011021211743355
Loss at iteration 2210 : 0.009627638384699821
Loss at iteration 2220 : 0.009356670081615448
Loss at iteration 2230 : 0.004665787797421217
Loss at iteration 2240 : 0.012672591023147106
Loss at iteration 2250 : 0.00855880044400692
Loss at iteration 2260 : 0.0056827981024980545
Loss at iteration 2270 : 0.007420639507472515
Loss at iteration 2280 : 0.027419554069638252
Loss at iteration 2290 : 0.02345525100827217
Loss at iteration 2300 : 0.006636287551373243
Loss at iteration 2310 : 0.013426996767520905
Loss at iteration 2320 : 0.007439516484737396
Loss at iteration 2330 : 0.005298195872455835
Loss at iteration 2340 : 0.019696954637765884
Loss at iteration 2350 : 0.005684968549758196
Loss at iteration 2360 : 0.009146785363554955
Loss at iteration 2370 : 0.013018210418522358
Loss at iteration 2380 : 0.013107816688716412
Loss at iteration 2390 : 0.003239354817196727
Loss at iteration 2400 : 0.02128419280052185
Loss at iteration 2410 : 0.01091329101473093
Loss at iteration 2420 : 0.005937228910624981
The SSIM Value is: 0.8410648187001546
The PSNR Value is: 22.148646291097005
the epoch is: 38
Loss at iteration 10 : 0.007643016986548901
Loss at iteration 20 : 0.005346252117305994
Loss at iteration 30 : 0.011335309594869614
Loss at iteration 40 : 0.014815496280789375
Loss at iteration 50 : 0.006538999266922474
Loss at iteration 60 : 0.010102984495460987
Loss at iteration 70 : 0.013234106823801994
Loss at iteration 80 : 0.004349864087998867
Loss at iteration 90 : 0.01876772753894329
Loss at iteration 100 : 0.006187645718455315
Loss at iteration 110 : 0.008231621235609055
Loss at iteration 120 : 0.00996670126914978
Loss at iteration 130 : 0.01556119043380022
Loss at iteration 140 : 0.006666342727839947
Loss at iteration 150 : 0.00800372939556837
Loss at iteration 160 : 0.014768388122320175
Loss at iteration 170 : 0.005903844255954027
Loss at iteration 180 : 0.0165594182908535
Loss at iteration 190 : 0.008323278278112411
Loss at iteration 200 : 0.010392071679234505
Loss at iteration 210 : 0.007303487043827772
Loss at iteration 220 : 0.009507114998996258
Loss at iteration 230 : 0.012229213491082191
Loss at iteration 240 : 0.013458031229674816
Loss at iteration 250 : 0.0047140419483184814
Loss at iteration 260 : 0.008879092521965504
Loss at iteration 270 : 0.010162773542106152
Loss at iteration 280 : 0.012677629478275776
Loss at iteration 290 : 0.013033644296228886
Loss at iteration 300 : 0.022694386541843414
Loss at iteration 310 : 0.010963420383632183
Loss at iteration 320 : 0.006158679723739624
Loss at iteration 330 : 0.008433058857917786
Loss at iteration 340 : 0.009836819022893906
Loss at iteration 350 : 0.007517392747104168
Loss at iteration 360 : 0.015526922419667244
Loss at iteration 370 : 0.013768570497632027
Loss at iteration 380 : 0.026300406083464622
Loss at iteration 390 : 0.01949406787753105
Loss at iteration 400 : 0.006435456685721874
Loss at iteration 410 : 0.0032398896291851997
Loss at iteration 420 : 0.014298520982265472
Loss at iteration 430 : 0.006330149248242378
Loss at iteration 440 : 0.013020964339375496
Loss at iteration 450 : 0.010023116134107113
Loss at iteration 460 : 0.015229105949401855
Loss at iteration 470 : 0.015316970646381378
Loss at iteration 480 : 0.00577890407294035
Loss at iteration 490 : 0.009730104357004166
Loss at iteration 500 : 0.010082662105560303
Loss at iteration 510 : 0.022659216076135635
Loss at iteration 520 : 0.009847125969827175
Loss at iteration 530 : 0.008048772811889648
Loss at iteration 540 : 0.007183892652392387
Loss at iteration 550 : 0.007918864488601685
Loss at iteration 560 : 0.0068675982765853405
Loss at iteration 570 : 0.016431741416454315
Loss at iteration 580 : 0.015237729996442795
Loss at iteration 590 : 0.006830262485891581
Loss at iteration 600 : 0.0098135806620121
Loss at iteration 610 : 0.00838671624660492
Loss at iteration 620 : 0.013272956945002079
Loss at iteration 630 : 0.012843422591686249
Loss at iteration 640 : 0.0051361192017793655
Loss at iteration 650 : 0.007837838493287563
Loss at iteration 660 : 0.0046781618148088455
Loss at iteration 670 : 0.008196552284061909
Loss at iteration 680 : 0.02304944023489952
Loss at iteration 690 : 0.011555034667253494
Loss at iteration 700 : 0.011175946332514286
Loss at iteration 710 : 0.005269796587526798
Loss at iteration 720 : 0.024385659024119377
Loss at iteration 730 : 0.008209849707782269
Loss at iteration 740 : 0.012679116800427437
Loss at iteration 750 : 0.013195151463150978
Loss at iteration 760 : 0.008703337982296944
Loss at iteration 770 : 0.009763510897755623
Loss at iteration 780 : 0.011487852782011032
Loss at iteration 790 : 0.00966213271021843
Loss at iteration 800 : 0.010025756433606148
Loss at iteration 810 : 0.013841110281646252
Loss at iteration 820 : 0.0072563402354717255
Loss at iteration 830 : 0.01109227817505598
Loss at iteration 840 : 0.018812142312526703
Loss at iteration 850 : 0.007732121739536524
Loss at iteration 860 : 0.021965384483337402
Loss at iteration 870 : 0.005499041639268398
Loss at iteration 880 : 0.012915150262415409
Loss at iteration 890 : 0.006114063784480095
Loss at iteration 900 : 0.007922537624835968
Loss at iteration 910 : 0.0105784572660923
Loss at iteration 920 : 0.006886630319058895
Loss at iteration 930 : 0.022444017231464386
Loss at iteration 940 : 0.01061033271253109
Loss at iteration 950 : 0.002886531176045537
Loss at iteration 960 : 0.00716843456029892
Loss at iteration 970 : 0.010927192866802216
Loss at iteration 980 : 0.005418742075562477
Loss at iteration 990 : 0.006122745107859373
Loss at iteration 1000 : 0.0068389070220291615
Loss at iteration 1010 : 0.00773485004901886
Loss at iteration 1020 : 0.012769336812198162
Loss at iteration 1030 : 0.00945081003010273
Loss at iteration 1040 : 0.010366339236497879
Loss at iteration 1050 : 0.013496987521648407
Loss at iteration 1060 : 0.002737122355028987
Loss at iteration 1070 : 0.004538410343229771
Loss at iteration 1080 : 0.016576668247580528
Loss at iteration 1090 : 0.006311498116701841
Loss at iteration 1100 : 0.009633893147110939
Loss at iteration 1110 : 0.010454997420310974
Loss at iteration 1120 : 0.012766517698764801
Loss at iteration 1130 : 0.008516086265444756
Loss at iteration 1140 : 0.013873422518372536
Loss at iteration 1150 : 0.00556339044123888
Loss at iteration 1160 : 0.032697729766368866
Loss at iteration 1170 : 0.011019363068044186
Loss at iteration 1180 : 0.01772361993789673
Loss at iteration 1190 : 0.00982278399169445
Loss at iteration 1200 : 0.016736188903450966
Loss at iteration 1210 : 0.010234497487545013
Loss at iteration 1220 : 0.015106681734323502
Loss at iteration 1230 : 0.009698810055851936
Loss at iteration 1240 : 0.016605405136942863
Loss at iteration 1250 : 0.012789337895810604
Loss at iteration 1260 : 0.010038435459136963
Loss at iteration 1270 : 0.01627531461417675
Loss at iteration 1280 : 0.011423307470977306
Loss at iteration 1290 : 0.023175310343503952
Loss at iteration 1300 : 0.012053418904542923
Loss at iteration 1310 : 0.0034466907382011414
Loss at iteration 1320 : 0.009743675589561462
Loss at iteration 1330 : 0.01326143927872181
Loss at iteration 1340 : 0.018622146919369698
Loss at iteration 1350 : 0.00600338913500309
Loss at iteration 1360 : 0.006711798720061779
Loss at iteration 1370 : 0.019057832658290863
Loss at iteration 1380 : 0.012757553718984127
Loss at iteration 1390 : 0.006175574846565723
Loss at iteration 1400 : 0.023997971788048744
Loss at iteration 1410 : 0.012720663100481033
Loss at iteration 1420 : 0.0069678244180977345
Loss at iteration 1430 : 0.014320781454443932
Loss at iteration 1440 : 0.012359356507658958
Loss at iteration 1450 : 0.0066173383966088295
Loss at iteration 1460 : 0.005151675082743168
Loss at iteration 1470 : 0.01254146359860897
Loss at iteration 1480 : 0.005806349217891693
Loss at iteration 1490 : 0.007089389953762293
Loss at iteration 1500 : 0.005714581348001957
Loss at iteration 1510 : 0.010956170968711376
Loss at iteration 1520 : 0.007212582975625992
Loss at iteration 1530 : 0.02213994227349758
Loss at iteration 1540 : 0.015249400399625301
Loss at iteration 1550 : 0.007369764149188995
Loss at iteration 1560 : 0.012802978977560997
Loss at iteration 1570 : 0.004027919843792915
Loss at iteration 1580 : 0.015529480762779713
Loss at iteration 1590 : 0.025124821811914444
Loss at iteration 1600 : 0.005476552061736584
Loss at iteration 1610 : 0.00896366499364376
Loss at iteration 1620 : 0.008954058401286602
Loss at iteration 1630 : 0.010981268249452114
Loss at iteration 1640 : 0.01182069443166256
Loss at iteration 1650 : 0.010014751926064491
Loss at iteration 1660 : 0.020104095339775085
Loss at iteration 1670 : 0.006339574698358774
Loss at iteration 1680 : 0.0048379190266132355
Loss at iteration 1690 : 0.013235446065664291
Loss at iteration 1700 : 0.008670207113027573
Loss at iteration 1710 : 0.006783242337405682
Loss at iteration 1720 : 0.00944566074758768
Loss at iteration 1730 : 0.009700782597064972
Loss at iteration 1740 : 0.007557754870504141
Loss at iteration 1750 : 0.013100778684020042
Loss at iteration 1760 : 0.0037699441891163588
Loss at iteration 1770 : 0.015132211148738861
Loss at iteration 1780 : 0.015612123534083366
Loss at iteration 1790 : 0.012643243186175823
Loss at iteration 1800 : 0.00879694614559412
Loss at iteration 1810 : 0.016027316451072693
Loss at iteration 1820 : 0.00819756556302309
Loss at iteration 1830 : 0.02313573658466339
Loss at iteration 1840 : 0.017351791262626648
Loss at iteration 1850 : 0.007871780544519424
Loss at iteration 1860 : 0.00830874964594841
Loss at iteration 1870 : 0.005764942616224289
Loss at iteration 1880 : 0.007673443295061588
Loss at iteration 1890 : 0.02121156081557274
Loss at iteration 1900 : 0.011895347386598587
Loss at iteration 1910 : 0.013166604563593864
Loss at iteration 1920 : 0.0063336752355098724
Loss at iteration 1930 : 0.014790397137403488
Loss at iteration 1940 : 0.013845235109329224
Loss at iteration 1950 : 0.006537104025483131
Loss at iteration 1960 : 0.008930439129471779
Loss at iteration 1970 : 0.004910420160740614
Loss at iteration 1980 : 0.010738547891378403
Loss at iteration 1990 : 0.01309562660753727
Loss at iteration 2000 : 0.016621943563222885
Loss at iteration 2010 : 0.005073703825473785
Loss at iteration 2020 : 0.00912313349545002
Loss at iteration 2030 : 0.005968309473246336
Loss at iteration 2040 : 0.005971345119178295
Loss at iteration 2050 : 0.007754689082503319
Loss at iteration 2060 : 0.009563902392983437
Loss at iteration 2070 : 0.016053974628448486
Loss at iteration 2080 : 0.007693735882639885
Loss at iteration 2090 : 0.008227599784731865
Loss at iteration 2100 : 0.014047693461179733
Loss at iteration 2110 : 0.006650989875197411
Loss at iteration 2120 : 0.011290944181382656
Loss at iteration 2130 : 0.017870139330625534
Loss at iteration 2140 : 0.028267255052924156
Loss at iteration 2150 : 0.010958787053823471
Loss at iteration 2160 : 0.012916861101984978
Loss at iteration 2170 : 0.008514579385519028
Loss at iteration 2180 : 0.009462356567382812
Loss at iteration 2190 : 0.0069338311441242695
Loss at iteration 2200 : 0.0074661970138549805
Loss at iteration 2210 : 0.007287187501788139
Loss at iteration 2220 : 0.008759593591094017
Loss at iteration 2230 : 0.00588684156537056
Loss at iteration 2240 : 0.010600479319691658
Loss at iteration 2250 : 0.017531737685203552
Loss at iteration 2260 : 0.011383036151528358
Loss at iteration 2270 : 0.004176623187959194
Loss at iteration 2280 : 0.014702362939715385
Loss at iteration 2290 : 0.0314154252409935
Loss at iteration 2300 : 0.009564343839883804
Loss at iteration 2310 : 0.019118787720799446
Loss at iteration 2320 : 0.011259126476943493
Loss at iteration 2330 : 0.009636017493903637
Loss at iteration 2340 : 0.0065338751301169395
Loss at iteration 2350 : 0.008641345426440239
Loss at iteration 2360 : 0.007424551993608475
Loss at iteration 2370 : 0.01548691838979721
Loss at iteration 2380 : 0.007848633453249931
Loss at iteration 2390 : 0.009062275290489197
Loss at iteration 2400 : 0.011658934876322746
Loss at iteration 2410 : 0.008217350579798222
Loss at iteration 2420 : 0.015261003747582436
The SSIM Value is: 0.8430636525154114
The PSNR Value is: 22.547698974609375
the epoch is: 39
Loss at iteration 10 : 0.009982316754758358
Loss at iteration 20 : 0.012902015820145607
Loss at iteration 30 : 0.004223390016704798
Loss at iteration 40 : 0.007661971263587475
Loss at iteration 50 : 0.010728634893894196
Loss at iteration 60 : 0.004441163502633572
Loss at iteration 70 : 0.00887050200253725
Loss at iteration 80 : 0.012220874428749084
Loss at iteration 90 : 0.00844656117260456
Loss at iteration 100 : 0.016864541918039322
Loss at iteration 110 : 0.0027294354513287544
Loss at iteration 120 : 0.009725464507937431
Loss at iteration 130 : 0.010790819302201271
Loss at iteration 140 : 0.008843810297548771
Loss at iteration 150 : 0.0025927468668669462
Loss at iteration 160 : 0.014848151244223118
Loss at iteration 170 : 0.00852296408265829
Loss at iteration 180 : 0.009658691473305225
Loss at iteration 190 : 0.02151373028755188
Loss at iteration 200 : 0.016400588676333427
Loss at iteration 210 : 0.011483870446681976
Loss at iteration 220 : 0.011235234327614307
Loss at iteration 230 : 0.008400162681937218
Loss at iteration 240 : 0.007296157535165548
Loss at iteration 250 : 0.016582760959863663
Loss at iteration 260 : 0.023546861484646797
Loss at iteration 270 : 0.009921221993863583
Loss at iteration 280 : 0.013203456066548824
Loss at iteration 290 : 0.009839754551649094
Loss at iteration 300 : 0.018460186198353767
Loss at iteration 310 : 0.012700134888291359
Loss at iteration 320 : 0.0082082599401474
Loss at iteration 330 : 0.0075669181533157825
Loss at iteration 340 : 0.011539028957486153
Loss at iteration 350 : 0.009541776962578297
Loss at iteration 360 : 0.011616119183599949
Loss at iteration 370 : 0.009966447949409485
Loss at iteration 380 : 0.010292395018041134
Loss at iteration 390 : 0.005356676410883665
Loss at iteration 400 : 0.008444450795650482
Loss at iteration 410 : 0.010444446466863155
Loss at iteration 420 : 0.00647282600402832
Loss at iteration 430 : 0.008909754455089569
Loss at iteration 440 : 0.010936249047517776
Loss at iteration 450 : 0.011111484840512276
Loss at iteration 460 : 0.012568586505949497
Loss at iteration 470 : 0.0087048951536417
Loss at iteration 480 : 0.006072148215025663
Loss at iteration 490 : 0.009230569936335087
Loss at iteration 500 : 0.007694120518863201
Loss at iteration 510 : 0.0062886374071240425
Loss at iteration 520 : 0.012057419866323471
Loss at iteration 530 : 0.011077817529439926
Loss at iteration 540 : 0.005817781668156385
Loss at iteration 550 : 0.01669297181069851
Loss at iteration 560 : 0.013221236877143383
Loss at iteration 570 : 0.016783539205789566
Loss at iteration 580 : 0.008990857750177383
Loss at iteration 590 : 0.012237409129738808
Loss at iteration 600 : 0.00912269577383995
Loss at iteration 610 : 0.007495766971260309
Loss at iteration 620 : 0.00884238537400961
Loss at iteration 630 : 0.009737316519021988
Loss at iteration 640 : 0.0027139526791870594
Loss at iteration 650 : 0.014955270104110241
Loss at iteration 660 : 0.011410372331738472
Loss at iteration 670 : 0.012552312575280666
Loss at iteration 680 : 0.007417330052703619
Loss at iteration 690 : 0.008271567523479462
Loss at iteration 700 : 0.01804448664188385
Loss at iteration 710 : 0.009653141722083092
Loss at iteration 720 : 0.01277222577482462
Loss at iteration 730 : 0.010499252006411552
Loss at iteration 740 : 0.0216028094291687
Loss at iteration 750 : 0.008038490079343319
Loss at iteration 760 : 0.0065199509263038635
Loss at iteration 770 : 0.012960382737219334
Loss at iteration 780 : 0.016993343830108643
Loss at iteration 790 : 0.004861420951783657
Loss at iteration 800 : 0.015005286782979965
Loss at iteration 810 : 0.015699658542871475
Loss at iteration 820 : 0.009337146766483784
Loss at iteration 830 : 0.006020619533956051
Loss at iteration 840 : 0.022573092952370644
Loss at iteration 850 : 0.013257356360554695
Loss at iteration 860 : 0.007464340887963772
Loss at iteration 870 : 0.01304621808230877
Loss at iteration 880 : 0.008403328247368336
Loss at iteration 890 : 0.010894134640693665
Loss at iteration 900 : 0.025358673185110092
Loss at iteration 910 : 0.008905496448278427
Loss at iteration 920 : 0.01374935731291771
Loss at iteration 930 : 0.008588752709329128
Loss at iteration 940 : 0.01002667285501957
Loss at iteration 950 : 0.01144410204142332
Loss at iteration 960 : 0.01098482683300972
Loss at iteration 970 : 0.010337053798139095
Loss at iteration 980 : 0.013636939227581024
Loss at iteration 990 : 0.015165133401751518
Loss at iteration 1000 : 0.01725519821047783
Loss at iteration 1010 : 0.011756859719753265
Loss at iteration 1020 : 0.011654829606413841
Loss at iteration 1030 : 0.007493368349969387
Loss at iteration 1040 : 0.011311996728181839
Loss at iteration 1050 : 0.007508020382374525
Loss at iteration 1060 : 0.009363558143377304
Loss at iteration 1070 : 0.016313133761286736
Loss at iteration 1080 : 0.009840589016675949
Loss at iteration 1090 : 0.0032690842635929585
Loss at iteration 1100 : 0.0064744725823402405
Loss at iteration 1110 : 0.009453559294342995
Loss at iteration 1120 : 0.01413183193653822
Loss at iteration 1130 : 0.009047452360391617
Loss at iteration 1140 : 0.0111624076962471
Loss at iteration 1150 : 0.010492317378520966
Loss at iteration 1160 : 0.01649271696805954
Loss at iteration 1170 : 0.012710007838904858
Loss at iteration 1180 : 0.012513726949691772
Loss at iteration 1190 : 0.013793007470667362
Loss at iteration 1200 : 0.009161416441202164
Loss at iteration 1210 : 0.009426139295101166
Loss at iteration 1220 : 0.012178340926766396
Loss at iteration 1230 : 0.007648556958884001
Loss at iteration 1240 : 0.011588356457650661
Loss at iteration 1250 : 0.007005424238741398
Loss at iteration 1260 : 0.011362295597791672
Loss at iteration 1270 : 0.02054542861878872
Loss at iteration 1280 : 0.006471266038715839
Loss at iteration 1290 : 0.015437961556017399
Loss at iteration 1300 : 0.011469002813100815
Loss at iteration 1310 : 0.011787930503487587
Loss at iteration 1320 : 0.009556667879223824
Loss at iteration 1330 : 0.013754311017692089
Loss at iteration 1340 : 0.030174991115927696
Loss at iteration 1350 : 0.00929347611963749
Loss at iteration 1360 : 0.01975027471780777
Loss at iteration 1370 : 0.010363908484578133
Loss at iteration 1380 : 0.007403576280921698
Loss at iteration 1390 : 0.01208878867328167
Loss at iteration 1400 : 0.009153539314866066
Loss at iteration 1410 : 0.008313655853271484
Loss at iteration 1420 : 0.02362314984202385
Loss at iteration 1430 : 0.009328940883278847
Loss at iteration 1440 : 0.012424510903656483
Loss at iteration 1450 : 0.015566386282444
Loss at iteration 1460 : 0.01876715198159218
Loss at iteration 1470 : 0.010211721062660217
Loss at iteration 1480 : 0.014447305351495743
Loss at iteration 1490 : 0.009545172564685345
Loss at iteration 1500 : 0.011063630692660809
Loss at iteration 1510 : 0.008921717293560505
Loss at iteration 1520 : 0.013104327023029327
Loss at iteration 1530 : 0.01639188639819622
Loss at iteration 1540 : 0.01762356236577034
Loss at iteration 1550 : 0.010030039586126804
Loss at iteration 1560 : 0.010206352919340134
Loss at iteration 1570 : 0.010558560490608215
Loss at iteration 1580 : 0.011514229699969292
Loss at iteration 1590 : 0.008469988591969013
Loss at iteration 1600 : 0.015450721606612206
Loss at iteration 1610 : 0.007438110187649727
Loss at iteration 1620 : 0.012806503102183342
Loss at iteration 1630 : 0.009692958556115627
Loss at iteration 1640 : 0.00842677429318428
Loss at iteration 1650 : 0.009660142473876476
Loss at iteration 1660 : 0.01244862750172615
Loss at iteration 1670 : 0.010007879696786404
Loss at iteration 1680 : 0.01863115094602108
Loss at iteration 1690 : 0.017882222309708595
Loss at iteration 1700 : 0.009359199553728104
Loss at iteration 1710 : 0.010281522758305073
Loss at iteration 1720 : 0.005716131068766117
Loss at iteration 1730 : 0.015182267874479294
Loss at iteration 1740 : 0.009920010343194008
Loss at iteration 1750 : 0.008215620182454586
Loss at iteration 1760 : 0.009906194172799587
Loss at iteration 1770 : 0.010494700632989407
Loss at iteration 1780 : 0.019044412299990654
Loss at iteration 1790 : 0.009625473991036415
Loss at iteration 1800 : 0.013286992907524109
Loss at iteration 1810 : 0.006637495942413807
Loss at iteration 1820 : 0.006651255767792463
Loss at iteration 1830 : 0.010733427479863167
Loss at iteration 1840 : 0.013233300298452377
Loss at iteration 1850 : 0.01088768057525158
Loss at iteration 1860 : 0.006565863266587257
Loss at iteration 1870 : 0.0096451286226511
Loss at iteration 1880 : 0.01604253239929676
Loss at iteration 1890 : 0.006138790398836136
Loss at iteration 1900 : 0.03072930872440338
Loss at iteration 1910 : 0.016575206071138382
Loss at iteration 1920 : 0.012342380359768867
Loss at iteration 1930 : 0.009774108417332172
Loss at iteration 1940 : 0.0043112607672810555
Loss at iteration 1950 : 0.005081282928586006
Loss at iteration 1960 : 0.008010108955204487
Loss at iteration 1970 : 0.006091689690947533
Loss at iteration 1980 : 0.01187918521463871
Loss at iteration 1990 : 0.008403490297496319
Loss at iteration 2000 : 0.0053745461627841
Loss at iteration 2010 : 0.018284350633621216
Loss at iteration 2020 : 0.013075794093310833
Loss at iteration 2030 : 0.011942200362682343
Loss at iteration 2040 : 0.007239161990582943
Loss at iteration 2050 : 0.01033684704452753
Loss at iteration 2060 : 0.010909795761108398
Loss at iteration 2070 : 0.008828508667647839
Loss at iteration 2080 : 0.01847282238304615
Loss at iteration 2090 : 0.011726558208465576
Loss at iteration 2100 : 0.007176680956035852
Loss at iteration 2110 : 0.004280547611415386
Loss at iteration 2120 : 0.011582731269299984
Loss at iteration 2130 : 0.008212930522859097
Loss at iteration 2140 : 0.004467985592782497
Loss at iteration 2150 : 0.015819545835256577
Loss at iteration 2160 : 0.007542130071669817
Loss at iteration 2170 : 0.011791735887527466
Loss at iteration 2180 : 0.017947252839803696
Loss at iteration 2190 : 0.0056167724542319775
Loss at iteration 2200 : 0.006798349320888519
Loss at iteration 2210 : 0.020334141328930855
Loss at iteration 2220 : 0.010861817747354507
Loss at iteration 2230 : 0.018289851024746895
Loss at iteration 2240 : 0.01071648858487606
Loss at iteration 2250 : 0.00728635024279356
Loss at iteration 2260 : 0.01291967649012804
Loss at iteration 2270 : 0.005846100859344006
Loss at iteration 2280 : 0.029598664492368698
Loss at iteration 2290 : 0.012016990222036839
Loss at iteration 2300 : 0.005466753616929054
Loss at iteration 2310 : 0.01276400126516819
Loss at iteration 2320 : 0.012129445560276508
Loss at iteration 2330 : 0.009544715285301208
Loss at iteration 2340 : 0.022126179188489914
Loss at iteration 2350 : 0.019075561314821243
Loss at iteration 2360 : 0.0049151405692100525
Loss at iteration 2370 : 0.016111988574266434
Loss at iteration 2380 : 0.008895586244761944
Loss at iteration 2390 : 0.013492302969098091
Loss at iteration 2400 : 0.004969097673892975
Loss at iteration 2410 : 0.00560221541672945
Loss at iteration 2420 : 0.0061756763607263565
The SSIM Value is: 0.8464298764864604
The PSNR Value is: 22.378681564331053
the epoch is: 40
Loss at iteration 10 : 0.009481390938162804
Loss at iteration 20 : 0.01274421252310276
Loss at iteration 30 : 0.01796330325305462
Loss at iteration 40 : 0.005221636034548283
Loss at iteration 50 : 0.010379446670413017
Loss at iteration 60 : 0.009146938100457191
Loss at iteration 70 : 0.0075365277007222176
Loss at iteration 80 : 0.013686863705515862
Loss at iteration 90 : 0.00779348611831665
Loss at iteration 100 : 0.01573803275823593
Loss at iteration 110 : 0.013671699911355972
Loss at iteration 120 : 0.0063400669023394585
Loss at iteration 130 : 0.00946508627384901
Loss at iteration 140 : 0.00802791677415371
Loss at iteration 150 : 0.004732629284262657
Loss at iteration 160 : 0.0069310469552874565
Loss at iteration 170 : 0.013592042028903961
Loss at iteration 180 : 0.009437387809157372
Loss at iteration 190 : 0.02428736351430416
Loss at iteration 200 : 0.0029761961195617914
Loss at iteration 210 : 0.010229918174445629
Loss at iteration 220 : 0.017503129318356514
Loss at iteration 230 : 0.01177113875746727
Loss at iteration 240 : 0.013215934857726097
Loss at iteration 250 : 0.018869727849960327
Loss at iteration 260 : 0.007780255749821663
Loss at iteration 270 : 0.013626957312226295
Loss at iteration 280 : 0.0211047250777483
Loss at iteration 290 : 0.008968867361545563
Loss at iteration 300 : 0.02604743093252182
Loss at iteration 310 : 0.011668642051517963
Loss at iteration 320 : 0.007476374972611666
Loss at iteration 330 : 0.01143038459122181
Loss at iteration 340 : 0.005693159997463226
Loss at iteration 350 : 0.007194576784968376
Loss at iteration 360 : 0.011647841893136501
Loss at iteration 370 : 0.009042713791131973
Loss at iteration 380 : 0.009429724887013435
Loss at iteration 390 : 0.009744103997945786
Loss at iteration 400 : 0.016150150448083878
Loss at iteration 410 : 0.01277622114866972
Loss at iteration 420 : 0.008004510775208473
Loss at iteration 430 : 0.01777842827141285
Loss at iteration 440 : 0.002607821486890316
Loss at iteration 450 : 0.010820521973073483
Loss at iteration 460 : 0.0100546320900321
Loss at iteration 470 : 0.02067018672823906
Loss at iteration 480 : 0.009343856945633888
Loss at iteration 490 : 0.010775450617074966
Loss at iteration 500 : 0.009199574589729309
Loss at iteration 510 : 0.007362609263509512
Loss at iteration 520 : 0.012032320722937584
Loss at iteration 530 : 0.011540509760379791
Loss at iteration 540 : 0.007191840559244156
Loss at iteration 550 : 0.0024118181318044662
Loss at iteration 560 : 0.009023372083902359
Loss at iteration 570 : 0.005442224442958832
Loss at iteration 580 : 0.007162293419241905
Loss at iteration 590 : 0.01241692528128624
Loss at iteration 600 : 0.006517772097140551
Loss at iteration 610 : 0.009466100484132767
Loss at iteration 620 : 0.005740154068917036
Loss at iteration 630 : 0.005476469174027443
Loss at iteration 640 : 0.010236218571662903
Loss at iteration 650 : 0.012522896751761436
Loss at iteration 660 : 0.014820775017142296
Loss at iteration 670 : 0.01702370122075081
Loss at iteration 680 : 0.009198344312608242
Loss at iteration 690 : 0.015610698610544205
Loss at iteration 700 : 0.011639581993222237
Loss at iteration 710 : 0.010124124586582184
Loss at iteration 720 : 0.007650223560631275
Loss at iteration 730 : 0.01250447891652584
Loss at iteration 740 : 0.01050796639174223
Loss at iteration 750 : 0.008620357140898705
Loss at iteration 760 : 0.007357646711170673
Loss at iteration 770 : 0.01251985877752304
Loss at iteration 780 : 0.012809913605451584
Loss at iteration 790 : 0.016647055745124817
Loss at iteration 800 : 0.009026303887367249
Loss at iteration 810 : 0.009906443767249584
Loss at iteration 820 : 0.009372442960739136
Loss at iteration 830 : 0.018294578418135643
Loss at iteration 840 : 0.009837660007178783
Loss at iteration 850 : 0.01422840915620327
Loss at iteration 860 : 0.007440974470227957
Loss at iteration 870 : 0.005835769698023796
Loss at iteration 880 : 0.017777401953935623
Loss at iteration 890 : 0.005976843647658825
Loss at iteration 900 : 0.017128337174654007
Loss at iteration 910 : 0.013880698941648006
Loss at iteration 920 : 0.015308074653148651
Loss at iteration 930 : 0.00972117017954588
Loss at iteration 940 : 0.006396939978003502
Loss at iteration 950 : 0.0065843709744513035
Loss at iteration 960 : 0.00738501874729991
Loss at iteration 970 : 0.021590204909443855
Loss at iteration 980 : 0.01428590901196003
Loss at iteration 990 : 0.007836050353944302
Loss at iteration 1000 : 0.010397839359939098
Loss at iteration 1010 : 0.009805504232645035
Loss at iteration 1020 : 0.012008743360638618
Loss at iteration 1030 : 0.01299692876636982
Loss at iteration 1040 : 0.013711802661418915
Loss at iteration 1050 : 0.009966924786567688
Loss at iteration 1060 : 0.01332057174295187
Loss at iteration 1070 : 0.01141568087041378
Loss at iteration 1080 : 0.00670483848080039
Loss at iteration 1090 : 0.016637980937957764
Loss at iteration 1100 : 0.015360798686742783
Loss at iteration 1110 : 0.01386900432407856
Loss at iteration 1120 : 0.006851799786090851
Loss at iteration 1130 : 0.011537563987076283
Loss at iteration 1140 : 0.0159376822412014
Loss at iteration 1150 : 0.013990046456456184
Loss at iteration 1160 : 0.006454248446971178
Loss at iteration 1170 : 0.009470096789300442
Loss at iteration 1180 : 0.011996995657682419
Loss at iteration 1190 : 0.006995968986302614
Loss at iteration 1200 : 0.0029048400465399027
Loss at iteration 1210 : 0.006196348927915096
Loss at iteration 1220 : 0.005655305460095406
Loss at iteration 1230 : 0.007965411059558392
Loss at iteration 1240 : 0.014933748170733452
Loss at iteration 1250 : 0.010239385068416595
Loss at iteration 1260 : 0.009610116481781006
Loss at iteration 1270 : 0.011632399633526802
Loss at iteration 1280 : 0.015845665708184242
Loss at iteration 1290 : 0.0068751135841012
Loss at iteration 1300 : 0.01117315050214529
Loss at iteration 1310 : 0.007491190917789936
Loss at iteration 1320 : 0.009672868996858597
Loss at iteration 1330 : 0.017942002043128014
Loss at iteration 1340 : 0.010463904589414597
Loss at iteration 1350 : 0.005328764207661152
Loss at iteration 1360 : 0.008239392191171646
Loss at iteration 1370 : 0.017230896279215813
Loss at iteration 1380 : 0.0021654507145285606
Loss at iteration 1390 : 0.010604423470795155
Loss at iteration 1400 : 0.007082418072968721
Loss at iteration 1410 : 0.012926198542118073
Loss at iteration 1420 : 0.01326151005923748
Loss at iteration 1430 : 0.0062732333317399025
Loss at iteration 1440 : 0.020886946469545364
Loss at iteration 1450 : 0.011992565356194973
Loss at iteration 1460 : 0.007737439125776291
Loss at iteration 1470 : 0.014640390872955322
Loss at iteration 1480 : 0.023852992802858353
Loss at iteration 1490 : 0.015832921490073204
Loss at iteration 1500 : 0.012908626347780228
Loss at iteration 1510 : 0.00813256949186325
Loss at iteration 1520 : 0.00900365225970745
Loss at iteration 1530 : 0.008929717354476452
Loss at iteration 1540 : 0.024631962180137634
Loss at iteration 1550 : 0.0177594106644392
Loss at iteration 1560 : 0.011939087882637978
Loss at iteration 1570 : 0.016708267852663994
Loss at iteration 1580 : 0.0029277452267706394
Loss at iteration 1590 : 0.01064611878246069
Loss at iteration 1600 : 0.012474291026592255
Loss at iteration 1610 : 0.01168541144579649
Loss at iteration 1620 : 0.013242650777101517
Loss at iteration 1630 : 0.006233933847397566
Loss at iteration 1640 : 0.005586409475654364
Loss at iteration 1650 : 0.012217670679092407
Loss at iteration 1660 : 0.013084986247122288
Loss at iteration 1670 : 0.014722035266458988
Loss at iteration 1680 : 0.006454956252127886
Loss at iteration 1690 : 0.01284762192517519
Loss at iteration 1700 : 0.006965111941099167
Loss at iteration 1710 : 0.012275676243007183
Loss at iteration 1720 : 0.007654560264199972
Loss at iteration 1730 : 0.007401240523904562
Loss at iteration 1740 : 0.0078017450869083405
Loss at iteration 1750 : 0.013812026008963585
Loss at iteration 1760 : 0.011792331002652645
Loss at iteration 1770 : 0.011536980979144573
Loss at iteration 1780 : 0.011276191100478172
Loss at iteration 1790 : 0.017000477761030197
Loss at iteration 1800 : 0.024108748883008957
Loss at iteration 1810 : 0.029111314564943314
Loss at iteration 1820 : 0.004986309912055731
Loss at iteration 1830 : 0.007130207493901253
Loss at iteration 1840 : 0.01828731782734394
Loss at iteration 1850 : 0.01361810602247715
Loss at iteration 1860 : 0.004685346968472004
Loss at iteration 1870 : 0.011402703821659088
Loss at iteration 1880 : 0.011027960106730461
Loss at iteration 1890 : 0.006779092364013195
Loss at iteration 1900 : 0.010332845151424408
Loss at iteration 1910 : 0.009867058135569096
Loss at iteration 1920 : 0.011088558472692966
Loss at iteration 1930 : 0.007932835258543491
Loss at iteration 1940 : 0.013323646038770676
Loss at iteration 1950 : 0.011866249144077301
Loss at iteration 1960 : 0.009665271267294884
Loss at iteration 1970 : 0.01575474813580513
Loss at iteration 1980 : 0.009954915381968021
Loss at iteration 1990 : 0.009709682315587997
Loss at iteration 2000 : 0.007036651950329542
Loss at iteration 2010 : 0.011358547955751419
Loss at iteration 2020 : 0.008634982630610466
Loss at iteration 2030 : 0.010102247819304466
Loss at iteration 2040 : 0.00687389774248004
Loss at iteration 2050 : 0.01349041610956192
Loss at iteration 2060 : 0.018608516082167625
Loss at iteration 2070 : 0.006564349867403507
Loss at iteration 2080 : 0.009036529809236526
Loss at iteration 2090 : 0.0094336261972785
Loss at iteration 2100 : 0.010534972883760929
Loss at iteration 2110 : 0.013527266681194305
Loss at iteration 2120 : 0.013028007932007313
Loss at iteration 2130 : 0.01248263381421566
Loss at iteration 2140 : 0.006239351816475391
Loss at iteration 2150 : 0.013502590358257294
Loss at iteration 2160 : 0.008483663201332092
Loss at iteration 2170 : 0.011635566130280495
Loss at iteration 2180 : 0.017273949459195137
Loss at iteration 2190 : 0.010047324001789093
Loss at iteration 2200 : 0.012226209044456482
Loss at iteration 2210 : 0.009645969606935978
Loss at iteration 2220 : 0.021906249225139618
Loss at iteration 2230 : 0.009540066123008728
Loss at iteration 2240 : 0.009029921144247055
Loss at iteration 2250 : 0.023145031183958054
Loss at iteration 2260 : 0.006956118158996105
Loss at iteration 2270 : 0.020501935854554176
Loss at iteration 2280 : 0.010970912873744965
Loss at iteration 2290 : 0.012278644368052483
Loss at iteration 2300 : 0.011521421372890472
Loss at iteration 2310 : 0.016610419377684593
Loss at iteration 2320 : 0.018234606832265854
Loss at iteration 2330 : 0.009387205354869366
Loss at iteration 2340 : 0.007015726063400507
Loss at iteration 2350 : 0.008349569514393806
Loss at iteration 2360 : 0.00819547101855278
Loss at iteration 2370 : 0.005484646186232567
Loss at iteration 2380 : 0.014028187841176987
Loss at iteration 2390 : 0.01302932295948267
Loss at iteration 2400 : 0.006025288719683886
Loss at iteration 2410 : 0.015374909155070782
Loss at iteration 2420 : 0.005352318752557039
The SSIM Value is: 0.8411297917366027
The PSNR Value is: 21.96492036183675
the epoch is: 41
Loss at iteration 10 : 0.011554102413356304
Loss at iteration 20 : 0.011816173791885376
Loss at iteration 30 : 0.008260618895292282
Loss at iteration 40 : 0.004879683256149292
Loss at iteration 50 : 0.008495066314935684
Loss at iteration 60 : 0.012068391777575016
Loss at iteration 70 : 0.008214026689529419
Loss at iteration 80 : 0.008694188669323921
Loss at iteration 90 : 0.013220046646893024
Loss at iteration 100 : 0.011590180918574333
Loss at iteration 110 : 0.02069038897752762
Loss at iteration 120 : 0.014027422294020653
Loss at iteration 130 : 0.008054789155721664
Loss at iteration 140 : 0.018344637006521225
Loss at iteration 150 : 0.00831405259668827
Loss at iteration 160 : 0.011985343880951405
Loss at iteration 170 : 0.014975701458752155
Loss at iteration 180 : 0.007526387460529804
Loss at iteration 190 : 0.01244267076253891
Loss at iteration 200 : 0.005522249732166529
Loss at iteration 210 : 0.009436994791030884
Loss at iteration 220 : 0.01023067720234394
Loss at iteration 230 : 0.011679349467158318
Loss at iteration 240 : 0.012949574738740921
Loss at iteration 250 : 0.007492233999073505
Loss at iteration 260 : 0.008334260433912277
Loss at iteration 270 : 0.00971892848610878
Loss at iteration 280 : 0.0111489687114954
Loss at iteration 290 : 0.005092067178338766
Loss at iteration 300 : 0.01181731652468443
Loss at iteration 310 : 0.010593167506158352
Loss at iteration 320 : 0.014537747018039227
Loss at iteration 330 : 0.007211792748421431
Loss at iteration 340 : 0.011718583293259144
Loss at iteration 350 : 0.015453692525625229
Loss at iteration 360 : 0.01866333745419979
Loss at iteration 370 : 0.003949119709432125
Loss at iteration 380 : 0.012741794809699059
Loss at iteration 390 : 0.00423898221924901
Loss at iteration 400 : 0.011943276040256023
Loss at iteration 410 : 0.01381390169262886
Loss at iteration 420 : 0.00687300693243742
Loss at iteration 430 : 0.011298132129013538
Loss at iteration 440 : 0.0031936003360897303
Loss at iteration 450 : 0.011444298550486565
Loss at iteration 460 : 0.014141407795250416
Loss at iteration 470 : 0.013562795706093311
Loss at iteration 480 : 0.016141466796398163
Loss at iteration 490 : 0.009630638174712658
Loss at iteration 500 : 0.0195181742310524
Loss at iteration 510 : 0.008570987731218338
Loss at iteration 520 : 0.0074951727874577045
Loss at iteration 530 : 0.013318294659256935
Loss at iteration 540 : 0.008336872793734074
Loss at iteration 550 : 0.019445519894361496
Loss at iteration 560 : 0.006468296982347965
Loss at iteration 570 : 0.008110897615551949
Loss at iteration 580 : 0.0126528050750494
Loss at iteration 590 : 0.007100456394255161
Loss at iteration 600 : 0.008916566148400307
Loss at iteration 610 : 0.013245480135083199
Loss at iteration 620 : 0.009571224451065063
Loss at iteration 630 : 0.029293479397892952
Loss at iteration 640 : 0.015410443767905235
Loss at iteration 650 : 0.012427160516381264
Loss at iteration 660 : 0.005385336000472307
Loss at iteration 670 : 0.01443729642778635
Loss at iteration 680 : 0.009521668776869774
Loss at iteration 690 : 0.00560138700529933
Loss at iteration 700 : 0.003540222765877843
Loss at iteration 710 : 0.010945173911750317
Loss at iteration 720 : 0.013730229809880257
Loss at iteration 730 : 0.005027987062931061
Loss at iteration 740 : 0.01733558066189289
Loss at iteration 750 : 0.007281284313648939
Loss at iteration 760 : 0.011030524037778378
Loss at iteration 770 : 0.007371492683887482
Loss at iteration 780 : 0.005204582121223211
Loss at iteration 790 : 0.011012107133865356
Loss at iteration 800 : 0.007870207540690899
Loss at iteration 810 : 0.013111974112689495
Loss at iteration 820 : 0.01921088621020317
Loss at iteration 830 : 0.015299873426556587
Loss at iteration 840 : 0.005973286926746368
Loss at iteration 850 : 0.008312935009598732
Loss at iteration 860 : 0.0036748836282640696
Loss at iteration 870 : 0.008484993129968643
Loss at iteration 880 : 0.009018804877996445
Loss at iteration 890 : 0.008001243695616722
Loss at iteration 900 : 0.016598999500274658
Loss at iteration 910 : 0.013060805387794971
Loss at iteration 920 : 0.019524041563272476
Loss at iteration 930 : 0.010447679087519646
Loss at iteration 940 : 0.011799508705735207
Loss at iteration 950 : 0.011406248435378075
Loss at iteration 960 : 0.005216690711677074
Loss at iteration 970 : 0.007973982021212578
Loss at iteration 980 : 0.0030286447145044804
Loss at iteration 990 : 0.004518901463598013
Loss at iteration 1000 : 0.01853991113603115
Loss at iteration 1010 : 0.02179139293730259
Loss at iteration 1020 : 0.021313149482011795
Loss at iteration 1030 : 0.008959976956248283
Loss at iteration 1040 : 0.0062616728246212006
Loss at iteration 1050 : 0.019405394792556763
Loss at iteration 1060 : 0.005215034820139408
Loss at iteration 1070 : 0.008163773454725742
Loss at iteration 1080 : 0.0065245358273386955
Loss at iteration 1090 : 0.00810566358268261
Loss at iteration 1100 : 0.0055022756569087505
Loss at iteration 1110 : 0.027350718155503273
Loss at iteration 1120 : 0.01755666173994541
Loss at iteration 1130 : 0.015358219854533672
Loss at iteration 1140 : 0.021045897156000137
Loss at iteration 1150 : 0.010931327939033508
Loss at iteration 1160 : 0.01148185320198536
Loss at iteration 1170 : 0.014569750055670738
Loss at iteration 1180 : 0.007261646445840597
Loss at iteration 1190 : 0.009528031572699547
Loss at iteration 1200 : 0.015615987591445446
Loss at iteration 1210 : 0.0063547976315021515
Loss at iteration 1220 : 0.009362269192934036
Loss at iteration 1230 : 0.00747615285217762
Loss at iteration 1240 : 0.008911359123885632
Loss at iteration 1250 : 0.006594650447368622
Loss at iteration 1260 : 0.002713424852117896
Loss at iteration 1270 : 0.007343249395489693
Loss at iteration 1280 : 0.017646711319684982
Loss at iteration 1290 : 0.01418822817504406
Loss at iteration 1300 : 0.012092558667063713
Loss at iteration 1310 : 0.006365204229950905
Loss at iteration 1320 : 0.01459735818207264
Loss at iteration 1330 : 0.017783258110284805
Loss at iteration 1340 : 0.012327847070991993
Loss at iteration 1350 : 0.014572234824299812
Loss at iteration 1360 : 0.009514909237623215
Loss at iteration 1370 : 0.02008224092423916
Loss at iteration 1380 : 0.012760700657963753
Loss at iteration 1390 : 0.013283655047416687
Loss at iteration 1400 : 0.009768234565854073
Loss at iteration 1410 : 0.00843282975256443
Loss at iteration 1420 : 0.0077483332715928555
Loss at iteration 1430 : 0.014168130233883858
Loss at iteration 1440 : 0.01536517683416605
Loss at iteration 1450 : 0.01602630317211151
Loss at iteration 1460 : 0.012182643637061119
Loss at iteration 1470 : 0.016260268166661263
Loss at iteration 1480 : 0.015308007597923279
Loss at iteration 1490 : 0.011673917062580585
Loss at iteration 1500 : 0.018311303108930588
Loss at iteration 1510 : 0.013120350427925587
Loss at iteration 1520 : 0.012305458076298237
Loss at iteration 1530 : 0.012445219792425632
Loss at iteration 1540 : 0.012247184291481972
Loss at iteration 1550 : 0.006429566070437431
Loss at iteration 1560 : 0.015415702015161514
Loss at iteration 1570 : 0.011703921481966972
Loss at iteration 1580 : 0.012483850121498108
Loss at iteration 1590 : 0.013988962396979332
Loss at iteration 1600 : 0.006738088093698025
Loss at iteration 1610 : 0.0055296760983765125
Loss at iteration 1620 : 0.008297188207507133
Loss at iteration 1630 : 0.007345193065702915
Loss at iteration 1640 : 0.011472126469016075
Loss at iteration 1650 : 0.008671950548887253
Loss at iteration 1660 : 0.016035323962569237
Loss at iteration 1670 : 0.0069794910959899426
Loss at iteration 1680 : 0.00709918886423111
Loss at iteration 1690 : 0.015478590503334999
Loss at iteration 1700 : 0.006701179314404726
Loss at iteration 1710 : 0.01214431133121252
Loss at iteration 1720 : 0.011895555071532726
Loss at iteration 1730 : 0.021109409630298615
Loss at iteration 1740 : 0.010434337891638279
Loss at iteration 1750 : 0.006811946630477905
Loss at iteration 1760 : 0.013508670032024384
Loss at iteration 1770 : 0.01950746402144432
Loss at iteration 1780 : 0.014338596723973751
Loss at iteration 1790 : 0.015370335429906845
Loss at iteration 1800 : 0.008352523669600487
Loss at iteration 1810 : 0.01241491362452507
Loss at iteration 1820 : 0.0032193767838180065
Loss at iteration 1830 : 0.006351638585329056
Loss at iteration 1840 : 0.00951994489878416
Loss at iteration 1850 : 0.013794410973787308
Loss at iteration 1860 : 0.014480646699666977
Loss at iteration 1870 : 0.016718044877052307
Loss at iteration 1880 : 0.009747229516506195
Loss at iteration 1890 : 0.008158572018146515
Loss at iteration 1900 : 0.017125744372606277
Loss at iteration 1910 : 0.011526431888341904
Loss at iteration 1920 : 0.011084613390266895
Loss at iteration 1930 : 0.015600775368511677
Loss at iteration 1940 : 0.00917137786746025
Loss at iteration 1950 : 0.021228071302175522
Loss at iteration 1960 : 0.009469959884881973
Loss at iteration 1970 : 0.011269866488873959
Loss at iteration 1980 : 0.013330385088920593
Loss at iteration 1990 : 0.007164292503148317
Loss at iteration 2000 : 0.0098700150847435
Loss at iteration 2010 : 0.01098580565303564
Loss at iteration 2020 : 0.006570915691554546
Loss at iteration 2030 : 0.010929044336080551
Loss at iteration 2040 : 0.009598477743566036
Loss at iteration 2050 : 0.013057450763881207
Loss at iteration 2060 : 0.00697924941778183
Loss at iteration 2070 : 0.018484100699424744
Loss at iteration 2080 : 0.007066413294523954
Loss at iteration 2090 : 0.016991429030895233
Loss at iteration 2100 : 0.01719348505139351
Loss at iteration 2110 : 0.0031897705048322678
Loss at iteration 2120 : 0.01800406724214554
Loss at iteration 2130 : 0.01741213910281658
Loss at iteration 2140 : 0.011479723267257214
Loss at iteration 2150 : 0.03768547996878624
Loss at iteration 2160 : 0.0053102485835552216
Loss at iteration 2170 : 0.010842637158930302
Loss at iteration 2180 : 0.0068869199603796005
Loss at iteration 2190 : 0.0064720213413238525
Loss at iteration 2200 : 0.009261088445782661
Loss at iteration 2210 : 0.009618731215596199
Loss at iteration 2220 : 0.010942721739411354
Loss at iteration 2230 : 0.006157085299491882
Loss at iteration 2240 : 0.015901247039437294
Loss at iteration 2250 : 0.008818086236715317
Loss at iteration 2260 : 0.020847417414188385
Loss at iteration 2270 : 0.021804925054311752
Loss at iteration 2280 : 0.013849562034010887
Loss at iteration 2290 : 0.004594769328832626
Loss at iteration 2300 : 0.011770328506827354
Loss at iteration 2310 : 0.01942967250943184
Loss at iteration 2320 : 0.013439012691378593
Loss at iteration 2330 : 0.013503152877092361
Loss at iteration 2340 : 0.006427970249205828
Loss at iteration 2350 : 0.012238024733960629
Loss at iteration 2360 : 0.013861668296158314
Loss at iteration 2370 : 0.005511000752449036
Loss at iteration 2380 : 0.002575531369075179
Loss at iteration 2390 : 0.038806572556495667
Loss at iteration 2400 : 0.010445904918015003
Loss at iteration 2410 : 0.01472535915672779
Loss at iteration 2420 : 0.008878736756742
The SSIM Value is: 0.8462141156196594
The PSNR Value is: 22.456947580973306
the epoch is: 42
Loss at iteration 10 : 0.004578364081680775
Loss at iteration 20 : 0.008876871317625046
Loss at iteration 30 : 0.009594634175300598
Loss at iteration 40 : 0.015235147438943386
Loss at iteration 50 : 0.008073856122791767
Loss at iteration 60 : 0.011260956525802612
Loss at iteration 70 : 0.021559886634349823
Loss at iteration 80 : 0.007385706529021263
Loss at iteration 90 : 0.008158395998179913
Loss at iteration 100 : 0.005629877559840679
Loss at iteration 110 : 0.006778091657906771
Loss at iteration 120 : 0.0302691962569952
Loss at iteration 130 : 0.013081585988402367
Loss at iteration 140 : 0.01488523744046688
Loss at iteration 150 : 0.010083788074553013
Loss at iteration 160 : 0.012951959855854511
Loss at iteration 170 : 0.025165529921650887
Loss at iteration 180 : 0.016712065786123276
Loss at iteration 190 : 0.01121087372303009
Loss at iteration 200 : 0.014475991018116474
Loss at iteration 210 : 0.0251802746206522
Loss at iteration 220 : 0.01499562431126833
Loss at iteration 230 : 0.00981359463185072
Loss at iteration 240 : 0.00711149163544178
Loss at iteration 250 : 0.00844569131731987
Loss at iteration 260 : 0.018149007111787796
Loss at iteration 270 : 0.007844464853405952
Loss at iteration 280 : 0.011660302989184856
Loss at iteration 290 : 0.007984709925949574
Loss at iteration 300 : 0.01456981711089611
Loss at iteration 310 : 0.013247789815068245
Loss at iteration 320 : 0.007824139669537544
Loss at iteration 330 : 0.004629833623766899
Loss at iteration 340 : 0.0076419152319431305
Loss at iteration 350 : 0.011123329401016235
Loss at iteration 360 : 0.014835375361144543
Loss at iteration 370 : 0.011402248404920101
Loss at iteration 380 : 0.005217123776674271
Loss at iteration 390 : 0.00445444555953145
Loss at iteration 400 : 0.011110660620033741
Loss at iteration 410 : 0.015191969461739063
Loss at iteration 420 : 0.014379092492163181
Loss at iteration 430 : 0.00670207291841507
Loss at iteration 440 : 0.012500321492552757
Loss at iteration 450 : 0.01072373241186142
Loss at iteration 460 : 0.01848028413951397
Loss at iteration 470 : 0.007263663690537214
Loss at iteration 480 : 0.010792752727866173
Loss at iteration 490 : 0.012096354737877846
Loss at iteration 500 : 0.020328663289546967
Loss at iteration 510 : 0.00687595596536994
Loss at iteration 520 : 0.020896093919873238
Loss at iteration 530 : 0.0196498092263937
Loss at iteration 540 : 0.010194052010774612
Loss at iteration 550 : 0.011712407693266869
Loss at iteration 560 : 0.008605189621448517
Loss at iteration 570 : 0.006457846611738205
Loss at iteration 580 : 0.007751785218715668
Loss at iteration 590 : 0.009028183296322823
Loss at iteration 600 : 0.01142786256968975
Loss at iteration 610 : 0.008970288559794426
Loss at iteration 620 : 0.012631002813577652
Loss at iteration 630 : 0.010782907716929913
Loss at iteration 640 : 0.008301893249154091
Loss at iteration 650 : 0.020563652738928795
Loss at iteration 660 : 0.016013942658901215
Loss at iteration 670 : 0.012342853471636772
Loss at iteration 680 : 0.009756963700056076
Loss at iteration 690 : 0.008306555449962616
Loss at iteration 700 : 0.020246028900146484
Loss at iteration 710 : 0.008762349374592304
Loss at iteration 720 : 0.007206132635474205
Loss at iteration 730 : 0.0142628513276577
Loss at iteration 740 : 0.007006109692156315
Loss at iteration 750 : 0.009403382427990437
Loss at iteration 760 : 0.009243953973054886
Loss at iteration 770 : 0.012248536571860313
Loss at iteration 780 : 0.0066686891950666904
Loss at iteration 790 : 0.0024455345701426268
Loss at iteration 800 : 0.009494229219853878
Loss at iteration 810 : 0.012977739796042442
Loss at iteration 820 : 0.012875617481768131
Loss at iteration 830 : 0.008119994774460793
Loss at iteration 840 : 0.007284699939191341
Loss at iteration 850 : 0.007778476923704147
Loss at iteration 860 : 0.005653319880366325
Loss at iteration 870 : 0.0030072396621108055
Loss at iteration 880 : 0.010134007781744003
Loss at iteration 890 : 0.013789542019367218
Loss at iteration 900 : 0.010008478537201881
Loss at iteration 910 : 0.01088944636285305
Loss at iteration 920 : 0.01492605172097683
Loss at iteration 930 : 0.012613251805305481
Loss at iteration 940 : 0.015113039873540401
Loss at iteration 950 : 0.022903060540556908
Loss at iteration 960 : 0.0053330110386013985
Loss at iteration 970 : 0.0037231002934277058
Loss at iteration 980 : 0.014438260346651077
Loss at iteration 990 : 0.016705168411135674
Loss at iteration 1000 : 0.0032970772590488195
Loss at iteration 1010 : 0.007922148331999779
Loss at iteration 1020 : 0.00960310734808445
Loss at iteration 1030 : 0.014792053028941154
Loss at iteration 1040 : 0.01607336662709713
Loss at iteration 1050 : 0.011928251013159752
Loss at iteration 1060 : 0.013915209099650383
Loss at iteration 1070 : 0.00284908851608634
Loss at iteration 1080 : 0.0127943130210042
Loss at iteration 1090 : 0.007128729950636625
Loss at iteration 1100 : 0.01180310919880867
Loss at iteration 1110 : 0.014881504699587822
Loss at iteration 1120 : 0.0067971996031701565
Loss at iteration 1130 : 0.012378179468214512
Loss at iteration 1140 : 0.006833805702626705
Loss at iteration 1150 : 0.0031643875408917665
Loss at iteration 1160 : 0.01323715690523386
Loss at iteration 1170 : 0.01379637885838747
Loss at iteration 1180 : 0.0049506197683513165
Loss at iteration 1190 : 0.008193465881049633
Loss at iteration 1200 : 0.008428271859884262
Loss at iteration 1210 : 0.010878469794988632
Loss at iteration 1220 : 0.012991899624466896
Loss at iteration 1230 : 0.009656262584030628
Loss at iteration 1240 : 0.008804358541965485
Loss at iteration 1250 : 0.008644605986773968
Loss at iteration 1260 : 0.009857683442533016
Loss at iteration 1270 : 0.007707752287387848
Loss at iteration 1280 : 0.004557587206363678
Loss at iteration 1290 : 0.01916096732020378
Loss at iteration 1300 : 0.011806231923401356
Loss at iteration 1310 : 0.017954997718334198
Loss at iteration 1320 : 0.015645025297999382
Loss at iteration 1330 : 0.008077871985733509
Loss at iteration 1340 : 0.014739340171217918
Loss at iteration 1350 : 0.007296786177903414
Loss at iteration 1360 : 0.014231341890990734
Loss at iteration 1370 : 0.006717229261994362
Loss at iteration 1380 : 0.009883586317300797
Loss at iteration 1390 : 0.00921033788472414
Loss at iteration 1400 : 0.023495303466916084
Loss at iteration 1410 : 0.005738059990108013
Loss at iteration 1420 : 0.01052464172244072
Loss at iteration 1430 : 0.00850909948348999
Loss at iteration 1440 : 0.016472304239869118
Loss at iteration 1450 : 0.009560778737068176
Loss at iteration 1460 : 0.008375819772481918
Loss at iteration 1470 : 0.011023716069757938
Loss at iteration 1480 : 0.011156744323670864
Loss at iteration 1490 : 0.008172746747732162
Loss at iteration 1500 : 0.009848898276686668
Loss at iteration 1510 : 0.00949421152472496
Loss at iteration 1520 : 0.011106684803962708
Loss at iteration 1530 : 0.006301912013441324
Loss at iteration 1540 : 0.0053799087181687355
Loss at iteration 1550 : 0.004731151275336742
Loss at iteration 1560 : 0.010669508948922157
Loss at iteration 1570 : 0.009713483974337578
Loss at iteration 1580 : 0.021330010145902634
Loss at iteration 1590 : 0.005980904214084148
Loss at iteration 1600 : 0.012390704825520515
Loss at iteration 1610 : 0.006469881162047386
Loss at iteration 1620 : 0.008546654134988785
Loss at iteration 1630 : 0.009004121646285057
Loss at iteration 1640 : 0.006905095186084509
Loss at iteration 1650 : 0.012185344472527504
Loss at iteration 1660 : 0.004986666142940521
Loss at iteration 1670 : 0.008187119849026203
Loss at iteration 1680 : 0.010036642663180828
Loss at iteration 1690 : 0.011533666402101517
Loss at iteration 1700 : 0.004678104538470507
Loss at iteration 1710 : 0.005204422399401665
Loss at iteration 1720 : 0.01044943742454052
Loss at iteration 1730 : 0.011678741313517094
Loss at iteration 1740 : 0.015734635293483734
Loss at iteration 1750 : 0.010610612109303474
Loss at iteration 1760 : 0.007160533219575882
Loss at iteration 1770 : 0.014937243424355984
Loss at iteration 1780 : 0.004230731166899204
Loss at iteration 1790 : 0.007842231541872025
Loss at iteration 1800 : 0.019524259492754936
Loss at iteration 1810 : 0.007109972648322582
Loss at iteration 1820 : 0.0076953512616455555
Loss at iteration 1830 : 0.030301447957754135
Loss at iteration 1840 : 0.009142722003161907
Loss at iteration 1850 : 0.012931182980537415
Loss at iteration 1860 : 0.02232351340353489
Loss at iteration 1870 : 0.008478831499814987
Loss at iteration 1880 : 0.01441563293337822
Loss at iteration 1890 : 0.014764116145670414
Loss at iteration 1900 : 0.011909463442862034
Loss at iteration 1910 : 0.007395174354314804
Loss at iteration 1920 : 0.008415539748966694
Loss at iteration 1930 : 0.013640952296555042
Loss at iteration 1940 : 0.008923357352614403
Loss at iteration 1950 : 0.006533599458634853
Loss at iteration 1960 : 0.018077652901411057
Loss at iteration 1970 : 0.007453573867678642
Loss at iteration 1980 : 0.011498898267745972
Loss at iteration 1990 : 0.01399892196059227
Loss at iteration 2000 : 0.011477116495370865
Loss at iteration 2010 : 0.01202415581792593
Loss at iteration 2020 : 0.01465517282485962
Loss at iteration 2030 : 0.008394457399845123
Loss at iteration 2040 : 0.012514669448137283
Loss at iteration 2050 : 0.015278881415724754
Loss at iteration 2060 : 0.009035734459757805
Loss at iteration 2070 : 0.00878590065985918
Loss at iteration 2080 : 0.007948216050863266
Loss at iteration 2090 : 0.006164000369608402
Loss at iteration 2100 : 0.006970197893679142
Loss at iteration 2110 : 0.005510538816452026
Loss at iteration 2120 : 0.011292137205600739
Loss at iteration 2130 : 0.009764841757714748
Loss at iteration 2140 : 0.006636937614530325
Loss at iteration 2150 : 0.010601541958749294
Loss at iteration 2160 : 0.006120794452726841
Loss at iteration 2170 : 0.012376926839351654
Loss at iteration 2180 : 0.010365950874984264
Loss at iteration 2190 : 0.019378986209630966
Loss at iteration 2200 : 0.013905270956456661
Loss at iteration 2210 : 0.008157091215252876
Loss at iteration 2220 : 0.010731978341937065
Loss at iteration 2230 : 0.008567972108721733
Loss at iteration 2240 : 0.003706844989210367
Loss at iteration 2250 : 0.01674558036029339
Loss at iteration 2260 : 0.010260947048664093
Loss at iteration 2270 : 0.008891666308045387
Loss at iteration 2280 : 0.0038330296520143747
Loss at iteration 2290 : 0.013615395873785019
Loss at iteration 2300 : 0.008419154211878777
Loss at iteration 2310 : 0.018544426187872887
Loss at iteration 2320 : 0.009940745308995247
Loss at iteration 2330 : 0.014025240205228329
Loss at iteration 2340 : 0.011409148573875427
Loss at iteration 2350 : 0.010664796456694603
Loss at iteration 2360 : 0.006159431766718626
Loss at iteration 2370 : 0.010727393440902233
Loss at iteration 2380 : 0.016893984749913216
Loss at iteration 2390 : 0.021192658692598343
Loss at iteration 2400 : 0.016536854207515717
Loss at iteration 2410 : 0.005321734584867954
Loss at iteration 2420 : 0.009703542105853558
The SSIM Value is: 0.8459258000055949
The PSNR Value is: 21.948981094360352
the epoch is: 43
Loss at iteration 10 : 0.007795052602887154
Loss at iteration 20 : 0.010893000289797783
Loss at iteration 30 : 0.006472273729741573
Loss at iteration 40 : 0.02119630016386509
Loss at iteration 50 : 0.008570089936256409
Loss at iteration 60 : 0.011166543699800968
Loss at iteration 70 : 0.013556482270359993
Loss at iteration 80 : 0.01023499108850956
Loss at iteration 90 : 0.008927050046622753
Loss at iteration 100 : 0.0045611681416630745
Loss at iteration 110 : 0.01199364848434925
Loss at iteration 120 : 0.007902475073933601
Loss at iteration 130 : 0.009726395830512047
Loss at iteration 140 : 0.01655227690935135
Loss at iteration 150 : 0.004199101123958826
Loss at iteration 160 : 0.009754395112395287
Loss at iteration 170 : 0.012886065989732742
Loss at iteration 180 : 0.00569005124270916
Loss at iteration 190 : 0.005873213056474924
Loss at iteration 200 : 0.010922348126769066
Loss at iteration 210 : 0.009035702794790268
Loss at iteration 220 : 0.017165595665574074
Loss at iteration 230 : 0.019984520971775055
Loss at iteration 240 : 0.010094725526869297
Loss at iteration 250 : 0.005045677535235882
Loss at iteration 260 : 0.0039022257551550865
Loss at iteration 270 : 0.016028007492423058
Loss at iteration 280 : 0.01908431202173233
Loss at iteration 290 : 0.008542576804757118
Loss at iteration 300 : 0.014966300688683987
Loss at iteration 310 : 0.018657583743333817
Loss at iteration 320 : 0.009114226326346397
Loss at iteration 330 : 0.004299528896808624
Loss at iteration 340 : 0.008026623167097569
Loss at iteration 350 : 0.016810741275548935
Loss at iteration 360 : 0.010345496237277985
Loss at iteration 370 : 0.00842589233070612
Loss at iteration 380 : 0.0121749397367239
Loss at iteration 390 : 0.009013013914227486
Loss at iteration 400 : 0.006234218366444111
Loss at iteration 410 : 0.012961342930793762
Loss at iteration 420 : 0.021750209853053093
Loss at iteration 430 : 0.00739005021750927
Loss at iteration 440 : 0.013962012715637684
Loss at iteration 450 : 0.008778704330325127
Loss at iteration 460 : 0.007411534897983074
Loss at iteration 470 : 0.009204138070344925
Loss at iteration 480 : 0.019400112330913544
Loss at iteration 490 : 0.0033251852728426456
Loss at iteration 500 : 0.008151812478899956
Loss at iteration 510 : 0.015319825150072575
Loss at iteration 520 : 0.01570664718747139
Loss at iteration 530 : 0.014447584748268127
Loss at iteration 540 : 0.00970076210796833
Loss at iteration 550 : 0.02080138772726059
Loss at iteration 560 : 0.014898878522217274
Loss at iteration 570 : 0.015721168369054794
Loss at iteration 580 : 0.008230802603065968
Loss at iteration 590 : 0.009467031806707382
Loss at iteration 600 : 0.014541594311594963
Loss at iteration 610 : 0.01509227603673935
Loss at iteration 620 : 0.006681928411126137
Loss at iteration 630 : 0.01589689962565899
Loss at iteration 640 : 0.008611510507762432
Loss at iteration 650 : 0.008027739822864532
Loss at iteration 660 : 0.007746381685137749
Loss at iteration 670 : 0.007833906449377537
Loss at iteration 680 : 0.01841038092970848
Loss at iteration 690 : 0.014066552743315697
Loss at iteration 700 : 0.011805126443505287
Loss at iteration 710 : 0.027069348841905594
Loss at iteration 720 : 0.008985918015241623
Loss at iteration 730 : 0.01141662523150444
Loss at iteration 740 : 0.013958366587758064
Loss at iteration 750 : 0.008029659278690815
Loss at iteration 760 : 0.007953191176056862
Loss at iteration 770 : 0.004772262182086706
Loss at iteration 780 : 0.009927740320563316
Loss at iteration 790 : 0.010346713475883007
Loss at iteration 800 : 0.004503270611166954
Loss at iteration 810 : 0.012186644598841667
Loss at iteration 820 : 0.007374715991318226
Loss at iteration 830 : 0.01006566733121872
Loss at iteration 840 : 0.007085245102643967
Loss at iteration 850 : 0.012867186218500137
Loss at iteration 860 : 0.003331520827487111
Loss at iteration 870 : 0.014219756238162518
Loss at iteration 880 : 0.011730283498764038
Loss at iteration 890 : 0.013556689023971558
Loss at iteration 900 : 0.017863303422927856
Loss at iteration 910 : 0.010157272219657898
Loss at iteration 920 : 0.008253386244177818
Loss at iteration 930 : 0.019114237278699875
Loss at iteration 940 : 0.02192077785730362
Loss at iteration 950 : 0.016595186665654182
Loss at iteration 960 : 0.007559765130281448
Loss at iteration 970 : 0.010821560397744179
Loss at iteration 980 : 0.01057618297636509
Loss at iteration 990 : 0.013744130730628967
Loss at iteration 1000 : 0.019219331443309784
Loss at iteration 1010 : 0.00842431839555502
Loss at iteration 1020 : 0.01834634505212307
Loss at iteration 1030 : 0.007119175978004932
Loss at iteration 1040 : 0.020573405548930168
Loss at iteration 1050 : 0.007137693930417299
Loss at iteration 1060 : 0.0051422929391264915
Loss at iteration 1070 : 0.03590724244713783
Loss at iteration 1080 : 0.0061860885471105576
Loss at iteration 1090 : 0.013175062835216522
Loss at iteration 1100 : 0.014198693446815014
Loss at iteration 1110 : 0.01120179146528244
Loss at iteration 1120 : 0.006576576270163059
Loss at iteration 1130 : 0.009876945056021214
Loss at iteration 1140 : 0.004583151079714298
Loss at iteration 1150 : 0.010120416060090065
Loss at iteration 1160 : 0.009352236986160278
Loss at iteration 1170 : 0.013419044204056263
Loss at iteration 1180 : 0.010607145726680756
Loss at iteration 1190 : 0.009033363312482834
Loss at iteration 1200 : 0.005391865037381649
Loss at iteration 1210 : 0.003350484184920788
Loss at iteration 1220 : 0.009051509201526642
Loss at iteration 1230 : 0.01037471555173397
Loss at iteration 1240 : 0.012664481066167355
Loss at iteration 1250 : 0.009000154212117195
Loss at iteration 1260 : 0.0034890605602413416
Loss at iteration 1270 : 0.005248461849987507
Loss at iteration 1280 : 0.008531585335731506
Loss at iteration 1290 : 0.01790132187306881
Loss at iteration 1300 : 0.005660110153257847
Loss at iteration 1310 : 0.007934634573757648
Loss at iteration 1320 : 0.012383723631501198
Loss at iteration 1330 : 0.008042959496378899
Loss at iteration 1340 : 0.010380356572568417
Loss at iteration 1350 : 0.007539174985140562
Loss at iteration 1360 : 0.016088515520095825
Loss at iteration 1370 : 0.009526717476546764
Loss at iteration 1380 : 0.009407641366124153
Loss at iteration 1390 : 0.015475280582904816
Loss at iteration 1400 : 0.01589757576584816
Loss at iteration 1410 : 0.004651700612157583
Loss at iteration 1420 : 0.010681292042136192
Loss at iteration 1430 : 0.013280240818858147
Loss at iteration 1440 : 0.006605407223105431
Loss at iteration 1450 : 0.013558397069573402
Loss at iteration 1460 : 0.013972263783216476
Loss at iteration 1470 : 0.008566886186599731
Loss at iteration 1480 : 0.0069108400493860245
Loss at iteration 1490 : 0.010954785160720348
Loss at iteration 1500 : 0.005227220710366964
Loss at iteration 1510 : 0.0028262382838875055
Loss at iteration 1520 : 0.024643894284963608
Loss at iteration 1530 : 0.01369219459593296
Loss at iteration 1540 : 0.010933639481663704
Loss at iteration 1550 : 0.006881830282509327
Loss at iteration 1560 : 0.02134731039404869
Loss at iteration 1570 : 0.010291852056980133
Loss at iteration 1580 : 0.007856512442231178
Loss at iteration 1590 : 0.005061682779341936
Loss at iteration 1600 : 0.008189071901142597
Loss at iteration 1610 : 0.009530904702842236
Loss at iteration 1620 : 0.010262378491461277
Loss at iteration 1630 : 0.014491090551018715
Loss at iteration 1640 : 0.00409311056137085
Loss at iteration 1650 : 0.006887384224683046
Loss at iteration 1660 : 0.0072467876598238945
Loss at iteration 1670 : 0.003347232937812805
Loss at iteration 1680 : 0.006893386598676443
Loss at iteration 1690 : 0.01676393859088421
Loss at iteration 1700 : 0.011842897161841393
Loss at iteration 1710 : 0.007599184289574623
Loss at iteration 1720 : 0.0260959230363369
Loss at iteration 1730 : 0.012615285813808441
Loss at iteration 1740 : 0.014064090326428413
Loss at iteration 1750 : 0.01399778388440609
Loss at iteration 1760 : 0.019589873030781746
Loss at iteration 1770 : 0.01228697132319212
Loss at iteration 1780 : 0.011839807033538818
Loss at iteration 1790 : 0.0069178021512925625
Loss at iteration 1800 : 0.00347531633451581
Loss at iteration 1810 : 0.009374483488500118
Loss at iteration 1820 : 0.009107716381549835
Loss at iteration 1830 : 0.00840127281844616
Loss at iteration 1840 : 0.005592706147581339
Loss at iteration 1850 : 0.004676102660596371
Loss at iteration 1860 : 0.006765179336071014
Loss at iteration 1870 : 0.010792069137096405
Loss at iteration 1880 : 0.009019527584314346
Loss at iteration 1890 : 0.007255318108946085
Loss at iteration 1900 : 0.00988644640892744
Loss at iteration 1910 : 0.008745953440666199
Loss at iteration 1920 : 0.006942925043404102
Loss at iteration 1930 : 0.008301159366965294
Loss at iteration 1940 : 0.008248958736658096
Loss at iteration 1950 : 0.01052040047943592
Loss at iteration 1960 : 0.00794859416782856
Loss at iteration 1970 : 0.00998947024345398
Loss at iteration 1980 : 0.019410300999879837
Loss at iteration 1990 : 0.009918821975588799
Loss at iteration 2000 : 0.013341324403882027
Loss at iteration 2010 : 0.01149437390267849
Loss at iteration 2020 : 0.022847704589366913
Loss at iteration 2030 : 0.00893850065767765
Loss at iteration 2040 : 0.011702240444719791
Loss at iteration 2050 : 0.009735899046063423
Loss at iteration 2060 : 0.01730487309396267
Loss at iteration 2070 : 0.00811352301388979
Loss at iteration 2080 : 0.010606168769299984
Loss at iteration 2090 : 0.003908658400177956
Loss at iteration 2100 : 0.00666162371635437
Loss at iteration 2110 : 0.010896760039031506
Loss at iteration 2120 : 0.008377885445952415
Loss at iteration 2130 : 0.011476456187665462
Loss at iteration 2140 : 0.015932386741042137
Loss at iteration 2150 : 0.018243733793497086
Loss at iteration 2160 : 0.007740182336419821
Loss at iteration 2170 : 0.0142782311886549
Loss at iteration 2180 : 0.0058401525020599365
Loss at iteration 2190 : 0.014561096206307411
Loss at iteration 2200 : 0.01297704502940178
Loss at iteration 2210 : 0.03300825506448746
Loss at iteration 2220 : 0.016492873430252075
Loss at iteration 2230 : 0.01016747485846281
Loss at iteration 2240 : 0.012260708957910538
Loss at iteration 2250 : 0.008064860478043556
Loss at iteration 2260 : 0.00764000928029418
Loss at iteration 2270 : 0.007105141878128052
Loss at iteration 2280 : 0.010905436240136623
Loss at iteration 2290 : 0.012363395653665066
Loss at iteration 2300 : 0.021051261574029922
Loss at iteration 2310 : 0.008755410090088844
Loss at iteration 2320 : 0.008539784699678421
Loss at iteration 2330 : 0.004446167498826981
Loss at iteration 2340 : 0.010415983386337757
Loss at iteration 2350 : 0.008878564462065697
Loss at iteration 2360 : 0.008495782501995564
Loss at iteration 2370 : 0.006761470343917608
Loss at iteration 2380 : 0.0105865728110075
Loss at iteration 2390 : 0.008638993836939335
Loss at iteration 2400 : 0.008180269971489906
Loss at iteration 2410 : 0.00613863579928875
Loss at iteration 2420 : 0.016559705138206482
The SSIM Value is: 0.835755447546641
The PSNR Value is: 21.13732935587565
the epoch is: 44
Loss at iteration 10 : 0.011103122495114803
Loss at iteration 20 : 0.009092411957681179
Loss at iteration 30 : 0.011411568149924278
Loss at iteration 40 : 0.017756186425685883
Loss at iteration 50 : 0.008989646099507809
Loss at iteration 60 : 0.007665175013244152
Loss at iteration 70 : 0.01567666605114937
Loss at iteration 80 : 0.0040880669839680195
Loss at iteration 90 : 0.01761225238442421
Loss at iteration 100 : 0.027637818828225136
Loss at iteration 110 : 0.013429279439151287
Loss at iteration 120 : 0.005430019460618496
Loss at iteration 130 : 0.009193569421768188
Loss at iteration 140 : 0.004884258843958378
Loss at iteration 150 : 0.018605943769216537
Loss at iteration 160 : 0.008241839706897736
Loss at iteration 170 : 0.009393909014761448
Loss at iteration 180 : 0.007074692286550999
Loss at iteration 190 : 0.01032522227615118
Loss at iteration 200 : 0.011431260965764523
Loss at iteration 210 : 0.014815516769886017
Loss at iteration 220 : 0.010013564489781857
Loss at iteration 230 : 0.006389571353793144
Loss at iteration 240 : 0.006232657469809055
Loss at iteration 250 : 0.004323528613895178
Loss at iteration 260 : 0.01231331005692482
Loss at iteration 270 : 0.01016499474644661
Loss at iteration 280 : 0.006000929046422243
Loss at iteration 290 : 0.007167857140302658
Loss at iteration 300 : 0.003682069480419159
Loss at iteration 310 : 0.008017010055482388
Loss at iteration 320 : 0.008926907554268837
Loss at iteration 330 : 0.006935269106179476
Loss at iteration 340 : 0.017637211829423904
Loss at iteration 350 : 0.01170414686203003
Loss at iteration 360 : 0.005796005483716726
Loss at iteration 370 : 0.012926694005727768
Loss at iteration 380 : 0.012176251038908958
Loss at iteration 390 : 0.015351753681898117
Loss at iteration 400 : 0.01620556227862835
Loss at iteration 410 : 0.010981746949255466
Loss at iteration 420 : 0.017332104966044426
Loss at iteration 430 : 0.004113475792109966
Loss at iteration 440 : 0.015581104904413223
Loss at iteration 450 : 0.005908230319619179
Loss at iteration 460 : 0.007602887228131294
Loss at iteration 470 : 0.010119599290192127
Loss at iteration 480 : 0.015523811802268028
Loss at iteration 490 : 0.010122694075107574
Loss at iteration 500 : 0.0257136058062315
Loss at iteration 510 : 0.00710540683940053
Loss at iteration 520 : 0.008414451964199543
Loss at iteration 530 : 0.01194918341934681
Loss at iteration 540 : 0.007395464926958084
Loss at iteration 550 : 0.019747186452150345
Loss at iteration 560 : 0.012053481303155422
Loss at iteration 570 : 0.008782245218753815
Loss at iteration 580 : 0.017163576558232307
Loss at iteration 590 : 0.019418053328990936
Loss at iteration 600 : 0.00710866367444396
Loss at iteration 610 : 0.005038069561123848
Loss at iteration 620 : 0.0047494941391050816
Loss at iteration 630 : 0.007888184860348701
Loss at iteration 640 : 0.01008747797459364
Loss at iteration 650 : 0.00789166335016489
Loss at iteration 660 : 0.010659819468855858
Loss at iteration 670 : 0.013529160991311073
Loss at iteration 680 : 0.006454347167164087
Loss at iteration 690 : 0.00888579897582531
Loss at iteration 700 : 0.006778436247259378
Loss at iteration 710 : 0.004940860439091921
Loss at iteration 720 : 0.00975776743143797
Loss at iteration 730 : 0.009079072624444962
Loss at iteration 740 : 0.00668336171656847
Loss at iteration 750 : 0.00826067104935646
Loss at iteration 760 : 0.008932349272072315
Loss at iteration 770 : 0.004265382885932922
Loss at iteration 780 : 0.015307152643799782
Loss at iteration 790 : 0.005714442580938339
Loss at iteration 800 : 0.010663848370313644
Loss at iteration 810 : 0.01172570325434208
Loss at iteration 820 : 0.011204919777810574
Loss at iteration 830 : 0.009521081112325191
Loss at iteration 840 : 0.015751823782920837
Loss at iteration 850 : 0.011646193452179432
Loss at iteration 860 : 0.006822184659540653
Loss at iteration 870 : 0.007573278155177832
Loss at iteration 880 : 0.018215782940387726
Loss at iteration 890 : 0.022260505706071854
Loss at iteration 900 : 0.011909272521734238
Loss at iteration 910 : 0.00989943090826273
Loss at iteration 920 : 0.010420757345855236
Loss at iteration 930 : 0.015624220483005047
Loss at iteration 940 : 0.008866218850016594
Loss at iteration 950 : 0.012167694047093391
Loss at iteration 960 : 0.003547524567693472
Loss at iteration 970 : 0.009274513460695744
Loss at iteration 980 : 0.004895126447081566
Loss at iteration 990 : 0.018664803355932236
Loss at iteration 1000 : 0.011347508057951927
Loss at iteration 1010 : 0.00822753831744194
Loss at iteration 1020 : 0.0071996599435806274
Loss at iteration 1030 : 0.008934036828577518
Loss at iteration 1040 : 0.01027777697890997
Loss at iteration 1050 : 0.008879631757736206
Loss at iteration 1060 : 0.018307387828826904
Loss at iteration 1070 : 0.012427937239408493
Loss at iteration 1080 : 0.007738661486655474
Loss at iteration 1090 : 0.017885636538267136
Loss at iteration 1100 : 0.009960804134607315
Loss at iteration 1110 : 0.012670103460550308
Loss at iteration 1120 : 0.016606124117970467
Loss at iteration 1130 : 0.011749355122447014
Loss at iteration 1140 : 0.007481119129806757
Loss at iteration 1150 : 0.01211533136665821
Loss at iteration 1160 : 0.008436339907348156
Loss at iteration 1170 : 0.009838669560849667
Loss at iteration 1180 : 0.022850224748253822
Loss at iteration 1190 : 0.006635605823248625
Loss at iteration 1200 : 0.009026281535625458
Loss at iteration 1210 : 0.007206029258668423
Loss at iteration 1220 : 0.006707529537379742
Loss at iteration 1230 : 0.012541534379124641
Loss at iteration 1240 : 0.004710281267762184
Loss at iteration 1250 : 0.016780968755483627
Loss at iteration 1260 : 0.011147065088152885
Loss at iteration 1270 : 0.021816927939653397
Loss at iteration 1280 : 0.010687469504773617
Loss at iteration 1290 : 0.016629012301564217
Loss at iteration 1300 : 0.009152021259069443
Loss at iteration 1310 : 0.014862241223454475
Loss at iteration 1320 : 0.012286528944969177
Loss at iteration 1330 : 0.016467038542032242
Loss at iteration 1340 : 0.012489838525652885
Loss at iteration 1350 : 0.010254072025418282
Loss at iteration 1360 : 0.009975219145417213
Loss at iteration 1370 : 0.010495567694306374
Loss at iteration 1380 : 0.026812033727765083
Loss at iteration 1390 : 0.015952937304973602
Loss at iteration 1400 : 0.007511679548770189
Loss at iteration 1410 : 0.004071827977895737
Loss at iteration 1420 : 0.0058776577934622765
Loss at iteration 1430 : 0.015230102464556694
Loss at iteration 1440 : 0.009535258635878563
Loss at iteration 1450 : 0.007931756787002087
Loss at iteration 1460 : 0.013284322805702686
Loss at iteration 1470 : 0.00441443407908082
Loss at iteration 1480 : 0.009343299083411694
Loss at iteration 1490 : 0.004659416154026985
Loss at iteration 1500 : 0.005713610909879208
Loss at iteration 1510 : 0.015631644055247307
Loss at iteration 1520 : 0.006332867778837681
Loss at iteration 1530 : 0.0116219911724329
Loss at iteration 1540 : 0.01327076181769371
Loss at iteration 1550 : 0.007588176056742668
Loss at iteration 1560 : 0.014528238214552402
Loss at iteration 1570 : 0.009558266960084438
Loss at iteration 1580 : 0.008064613677561283
Loss at iteration 1590 : 0.006692954804748297
Loss at iteration 1600 : 0.013033438473939896
Loss at iteration 1610 : 0.005667143501341343
Loss at iteration 1620 : 0.009507179260253906
Loss at iteration 1630 : 0.0059000784531235695
Loss at iteration 1640 : 0.0033900372218340635
Loss at iteration 1650 : 0.011158367618918419
Loss at iteration 1660 : 0.004661906976252794
Loss at iteration 1670 : 0.012330761179327965
Loss at iteration 1680 : 0.006100727245211601
Loss at iteration 1690 : 0.010229712352156639
Loss at iteration 1700 : 0.010296991094946861
Loss at iteration 1710 : 0.020367085933685303
Loss at iteration 1720 : 0.022289957851171494
Loss at iteration 1730 : 0.008115636184811592
Loss at iteration 1740 : 0.00996437668800354
Loss at iteration 1750 : 0.016773000359535217
Loss at iteration 1760 : 0.012725365348160267
Loss at iteration 1770 : 0.012627771124243736
Loss at iteration 1780 : 0.005866958759725094
Loss at iteration 1790 : 0.009927177801728249
Loss at iteration 1800 : 0.013463938608765602
Loss at iteration 1810 : 0.02427578903734684
Loss at iteration 1820 : 0.014262571930885315
Loss at iteration 1830 : 0.011009912006556988
Loss at iteration 1840 : 0.014957478269934654
Loss at iteration 1850 : 0.011373424902558327
Loss at iteration 1860 : 0.007995105348527431
Loss at iteration 1870 : 0.008593594655394554
Loss at iteration 1880 : 0.007064336445182562
Loss at iteration 1890 : 0.01649092696607113
Loss at iteration 1900 : 0.011456242762506008
Loss at iteration 1910 : 0.007649790495634079
Loss at iteration 1920 : 0.010826438665390015
Loss at iteration 1930 : 0.013119811192154884
Loss at iteration 1940 : 0.018181346356868744
Loss at iteration 1950 : 0.0075802067294716835
Loss at iteration 1960 : 0.008981872349977493
Loss at iteration 1970 : 0.002568046096712351
Loss at iteration 1980 : 0.011940598487854004
Loss at iteration 1990 : 0.013673078268766403
Loss at iteration 2000 : 0.009019249118864536
Loss at iteration 2010 : 0.006801367737352848
Loss at iteration 2020 : 0.0071610379964113235
Loss at iteration 2030 : 0.012263101525604725
Loss at iteration 2040 : 0.011792842298746109
Loss at iteration 2050 : 0.011689604260027409
Loss at iteration 2060 : 0.006043666508048773
Loss at iteration 2070 : 0.004317710176110268
Loss at iteration 2080 : 0.0106000155210495
Loss at iteration 2090 : 0.008029976859688759
Loss at iteration 2100 : 0.018070196732878685
Loss at iteration 2110 : 0.009292729198932648
Loss at iteration 2120 : 0.0057258871383965015
Loss at iteration 2130 : 0.010929407551884651
Loss at iteration 2140 : 0.008152236230671406
Loss at iteration 2150 : 0.014149896800518036
Loss at iteration 2160 : 0.020061468705534935
Loss at iteration 2170 : 0.00753836939111352
Loss at iteration 2180 : 0.01317391637712717
Loss at iteration 2190 : 0.012103700079023838
Loss at iteration 2200 : 0.009800363332033157
Loss at iteration 2210 : 0.005519633647054434
Loss at iteration 2220 : 0.010202290490269661
Loss at iteration 2230 : 0.01785540208220482
Loss at iteration 2240 : 0.013258558697998524
Loss at iteration 2250 : 0.010603554546833038
Loss at iteration 2260 : 0.019023722037672997
Loss at iteration 2270 : 0.007133763283491135
Loss at iteration 2280 : 0.008221441879868507
Loss at iteration 2290 : 0.012800967320799828
Loss at iteration 2300 : 0.011155729182064533
Loss at iteration 2310 : 0.011205852031707764
Loss at iteration 2320 : 0.024479307234287262
Loss at iteration 2330 : 0.004891044460237026
Loss at iteration 2340 : 0.008988729678094387
Loss at iteration 2350 : 0.0073100244626402855
Loss at iteration 2360 : 0.012901168316602707
Loss at iteration 2370 : 0.008052991703152657
Loss at iteration 2380 : 0.014088379219174385
Loss at iteration 2390 : 0.002595131751149893
Loss at iteration 2400 : 0.005844880826771259
Loss at iteration 2410 : 0.007532299961894751
Loss at iteration 2420 : 0.0103438850492239
The SSIM Value is: 0.8443410833676656
The PSNR Value is: 22.2180508295695
the epoch is: 45
Loss at iteration 10 : 0.021135106682777405
Loss at iteration 20 : 0.011604611761868
Loss at iteration 30 : 0.0076029375195503235
Loss at iteration 40 : 0.007178382948040962
Loss at iteration 50 : 0.01279844343662262
Loss at iteration 60 : 0.008990511298179626
Loss at iteration 70 : 0.008341358974575996
Loss at iteration 80 : 0.008764884434640408
Loss at iteration 90 : 0.004891505930572748
Loss at iteration 100 : 0.009788533672690392
Loss at iteration 110 : 0.005750992335379124
Loss at iteration 120 : 0.016414329409599304
Loss at iteration 130 : 0.0062078139744699
Loss at iteration 140 : 0.012055152095854282
Loss at iteration 150 : 0.012199987657368183
Loss at iteration 160 : 0.009822910651564598
Loss at iteration 170 : 0.008419914171099663
Loss at iteration 180 : 0.006515887100249529
Loss at iteration 190 : 0.007170329336076975
Loss at iteration 200 : 0.0054782684892416
Loss at iteration 210 : 0.013766046613454819
Loss at iteration 220 : 0.004696912597864866
Loss at iteration 230 : 0.01090896688401699
Loss at iteration 240 : 0.018774740397930145
Loss at iteration 250 : 0.011093131266534328
Loss at iteration 260 : 0.009635062888264656
Loss at iteration 270 : 0.012892486527562141
Loss at iteration 280 : 0.009680768474936485
Loss at iteration 290 : 0.014418108388781548
Loss at iteration 300 : 0.012109762988984585
Loss at iteration 310 : 0.013077501207590103
Loss at iteration 320 : 0.00746377557516098
Loss at iteration 330 : 0.006539368070662022
Loss at iteration 340 : 0.011093824170529842
Loss at iteration 350 : 0.01058373972773552
Loss at iteration 360 : 0.01195406261831522
Loss at iteration 370 : 0.009208152070641518
Loss at iteration 380 : 0.007481750100851059
Loss at iteration 390 : 0.008509699255228043
Loss at iteration 400 : 0.010440077632665634
Loss at iteration 410 : 0.007760924752801657
Loss at iteration 420 : 0.0059592570178210735
Loss at iteration 430 : 0.005258946679532528
Loss at iteration 440 : 0.006365722510963678
Loss at iteration 450 : 0.012301992624998093
Loss at iteration 460 : 0.006064119283109903
Loss at iteration 470 : 0.009365446865558624
Loss at iteration 480 : 0.006694566458463669
Loss at iteration 490 : 0.007752199191600084
Loss at iteration 500 : 0.009125769138336182
Loss at iteration 510 : 0.004541682079434395
Loss at iteration 520 : 0.014770455658435822
Loss at iteration 530 : 0.006452524568885565
Loss at iteration 540 : 0.005247619468718767
Loss at iteration 550 : 0.0201861672103405
Loss at iteration 560 : 0.013439289294183254
Loss at iteration 570 : 0.01993798278272152
Loss at iteration 580 : 0.010006259195506573
Loss at iteration 590 : 0.012555524706840515
Loss at iteration 600 : 0.011859871447086334
Loss at iteration 610 : 0.012662680819630623
Loss at iteration 620 : 0.016979439184069633
Loss at iteration 630 : 0.01058670599013567
Loss at iteration 640 : 0.01103655993938446
Loss at iteration 650 : 0.004832467529922724
Loss at iteration 660 : 0.01078173890709877
Loss at iteration 670 : 0.004262002184987068
Loss at iteration 680 : 0.009337812662124634
Loss at iteration 690 : 0.01093129813671112
Loss at iteration 700 : 0.0066175758838653564
Loss at iteration 710 : 0.014514937065541744
Loss at iteration 720 : 0.011741972528398037
Loss at iteration 730 : 0.007316640578210354
Loss at iteration 740 : 0.013239171355962753
Loss at iteration 750 : 0.007591479457914829
Loss at iteration 760 : 0.006473228335380554
Loss at iteration 770 : 0.013242913410067558
Loss at iteration 780 : 0.015443439595401287
Loss at iteration 790 : 0.00928221084177494
Loss at iteration 800 : 0.009420961141586304
Loss at iteration 810 : 0.013206744566559792
Loss at iteration 820 : 0.008071918040513992
Loss at iteration 830 : 0.00986261386424303
Loss at iteration 840 : 0.006880166474729776
Loss at iteration 850 : 0.008647815324366093
Loss at iteration 860 : 0.010016527026891708
Loss at iteration 870 : 0.004885784350335598
Loss at iteration 880 : 0.018765652552247047
Loss at iteration 890 : 0.011088332161307335
Loss at iteration 900 : 0.013168462552130222
Loss at iteration 910 : 0.018785985186696053
Loss at iteration 920 : 0.0097670191898942
Loss at iteration 930 : 0.014865469187498093
Loss at iteration 940 : 0.015621230937540531
Loss at iteration 950 : 0.007508229464292526
Loss at iteration 960 : 0.009723763912916183
Loss at iteration 970 : 0.016056396067142487
Loss at iteration 980 : 0.006503016222268343
Loss at iteration 990 : 0.010480082593858242
Loss at iteration 1000 : 0.007957367226481438
Loss at iteration 1010 : 0.005608404986560345
Loss at iteration 1020 : 0.010136027820408344
Loss at iteration 1030 : 0.011242445558309555
Loss at iteration 1040 : 0.009592884220182896
Loss at iteration 1050 : 0.013494553975760937
Loss at iteration 1060 : 0.013389931991696358
Loss at iteration 1070 : 0.00475922878831625
Loss at iteration 1080 : 0.021785162389278412
Loss at iteration 1090 : 0.010281377471983433
Loss at iteration 1100 : 0.006839270703494549
Loss at iteration 1110 : 0.011211705394089222
Loss at iteration 1120 : 0.009840785525739193
Loss at iteration 1130 : 0.005166179034858942
Loss at iteration 1140 : 0.008873041719198227
Loss at iteration 1150 : 0.015362181700766087
Loss at iteration 1160 : 0.010526767000555992
Loss at iteration 1170 : 0.01690809428691864
Loss at iteration 1180 : 0.007881253026425838
Loss at iteration 1190 : 0.004274132661521435
Loss at iteration 1200 : 0.012535751797258854
Loss at iteration 1210 : 0.012112083844840527
Loss at iteration 1220 : 0.004457714967429638
Loss at iteration 1230 : 0.007935643196105957
Loss at iteration 1240 : 0.01035591121762991
Loss at iteration 1250 : 0.014115582220256329
Loss at iteration 1260 : 0.005520536098629236
Loss at iteration 1270 : 0.020834626629948616
Loss at iteration 1280 : 0.014471018686890602
Loss at iteration 1290 : 0.005143066868185997
Loss at iteration 1300 : 0.008078403770923615
Loss at iteration 1310 : 0.0073353019542992115
Loss at iteration 1320 : 0.012541140429675579
Loss at iteration 1330 : 0.008846028707921505
Loss at iteration 1340 : 0.016016855835914612
Loss at iteration 1350 : 0.014384759590029716
Loss at iteration 1360 : 0.007076398003846407
Loss at iteration 1370 : 0.012491786852478981
Loss at iteration 1380 : 0.006684564985334873
Loss at iteration 1390 : 0.024278799071907997
Loss at iteration 1400 : 0.009185129776597023
Loss at iteration 1410 : 0.018861059099435806
Loss at iteration 1420 : 0.014004959724843502
Loss at iteration 1430 : 0.005369408056139946
Loss at iteration 1440 : 0.020832840353250504
Loss at iteration 1450 : 0.007197534199804068
Loss at iteration 1460 : 0.007444060407578945
Loss at iteration 1470 : 0.006281833164393902
Loss at iteration 1480 : 0.010452274233102798
Loss at iteration 1490 : 0.016268620267510414
Loss at iteration 1500 : 0.015095338225364685
Loss at iteration 1510 : 0.008248602971434593
Loss at iteration 1520 : 0.009239084087312222
Loss at iteration 1530 : 0.011427492834627628
Loss at iteration 1540 : 0.013840213418006897
Loss at iteration 1550 : 0.01628282107412815
Loss at iteration 1560 : 0.004222243092954159
Loss at iteration 1570 : 0.0054871439933776855
Loss at iteration 1580 : 0.008246848359704018
Loss at iteration 1590 : 0.010668471455574036
Loss at iteration 1600 : 0.007950786501169205
Loss at iteration 1610 : 0.013103442266583443
Loss at iteration 1620 : 0.015455019660294056
Loss at iteration 1630 : 0.014452466741204262
Loss at iteration 1640 : 0.009447027929127216
Loss at iteration 1650 : 0.026979148387908936
Loss at iteration 1660 : 0.008334660902619362
Loss at iteration 1670 : 0.005016519222408533
Loss at iteration 1680 : 0.007486873306334019
Loss at iteration 1690 : 0.012612639926373959
Loss at iteration 1700 : 0.008272680453956127
Loss at iteration 1710 : 0.005759688094258308
Loss at iteration 1720 : 0.011210720986127853
Loss at iteration 1730 : 0.007477991748601198
Loss at iteration 1740 : 0.011074062436819077
Loss at iteration 1750 : 0.015117770060896873
Loss at iteration 1760 : 0.003109591081738472
Loss at iteration 1770 : 0.01127384789288044
Loss at iteration 1780 : 0.0187038816511631
Loss at iteration 1790 : 0.010872647166252136
Loss at iteration 1800 : 0.009254008531570435
Loss at iteration 1810 : 0.006363267078995705
Loss at iteration 1820 : 0.013144253753125668
Loss at iteration 1830 : 0.010745356790721416
Loss at iteration 1840 : 0.007431402802467346
Loss at iteration 1850 : 0.007150852587074041
Loss at iteration 1860 : 0.004707746673375368
Loss at iteration 1870 : 0.014624610543251038
Loss at iteration 1880 : 0.010024357587099075
Loss at iteration 1890 : 0.00798828899860382
Loss at iteration 1900 : 0.012086975388228893
Loss at iteration 1910 : 0.010686485096812248
Loss at iteration 1920 : 0.007852116599678993
Loss at iteration 1930 : 0.009446232579648495
Loss at iteration 1940 : 0.008137733675539494
Loss at iteration 1950 : 0.013827674090862274
Loss at iteration 1960 : 0.012910876423120499
Loss at iteration 1970 : 0.010517132468521595
Loss at iteration 1980 : 0.014517135918140411
Loss at iteration 1990 : 0.008355874568223953
Loss at iteration 2000 : 0.011079235933721066
Loss at iteration 2010 : 0.011997196823358536
Loss at iteration 2020 : 0.009672744199633598
Loss at iteration 2030 : 0.010404492728412151
Loss at iteration 2040 : 0.01227569580078125
Loss at iteration 2050 : 0.017962487414479256
Loss at iteration 2060 : 0.01189191173762083
Loss at iteration 2070 : 0.03474772348999977
Loss at iteration 2080 : 0.010142628103494644
Loss at iteration 2090 : 0.01191883534193039
Loss at iteration 2100 : 0.012055886909365654
Loss at iteration 2110 : 0.010228751227259636
Loss at iteration 2120 : 0.003211219795048237
Loss at iteration 2130 : 0.003335796296596527
Loss at iteration 2140 : 0.011476434767246246
Loss at iteration 2150 : 0.008128393441438675
Loss at iteration 2160 : 0.019466767087578773
Loss at iteration 2170 : 0.007428891956806183
Loss at iteration 2180 : 0.01064283400774002
Loss at iteration 2190 : 0.008680642582476139
Loss at iteration 2200 : 0.01265781745314598
Loss at iteration 2210 : 0.010700568556785583
Loss at iteration 2220 : 0.006252962630242109
Loss at iteration 2230 : 0.011668386869132519
Loss at iteration 2240 : 0.009983438067138195
Loss at iteration 2250 : 0.006065587513148785
Loss at iteration 2260 : 0.011780914850533009
Loss at iteration 2270 : 0.008081821724772453
Loss at iteration 2280 : 0.010677749291062355
Loss at iteration 2290 : 0.004407044034451246
Loss at iteration 2300 : 0.013385804370045662
Loss at iteration 2310 : 0.0035254315007478
Loss at iteration 2320 : 0.01057417131960392
Loss at iteration 2330 : 0.012070250697433949
Loss at iteration 2340 : 0.0094328373670578
Loss at iteration 2350 : 0.0034705116413533688
Loss at iteration 2360 : 0.010280360467731953
Loss at iteration 2370 : 0.005804075393825769
Loss at iteration 2380 : 0.013757930137217045
Loss at iteration 2390 : 0.009351409040391445
Loss at iteration 2400 : 0.015648160129785538
Loss at iteration 2410 : 0.007039378862828016
Loss at iteration 2420 : 0.014159543439745903
The SSIM Value is: 0.8380290627479553
The PSNR Value is: 21.4466672261556
the epoch is: 46
Loss at iteration 10 : 0.02156497724354267
Loss at iteration 20 : 0.02079060673713684
Loss at iteration 30 : 0.00724664144217968
Loss at iteration 40 : 0.009994451887905598
Loss at iteration 50 : 0.003355019725859165
Loss at iteration 60 : 0.011823761276900768
Loss at iteration 70 : 0.009734569117426872
Loss at iteration 80 : 0.011557196266949177
Loss at iteration 90 : 0.012237109243869781
Loss at iteration 100 : 0.004626357927918434
Loss at iteration 110 : 0.017969399690628052
Loss at iteration 120 : 0.008354924619197845
Loss at iteration 130 : 0.006125796120613813
Loss at iteration 140 : 0.009188427589833736
Loss at iteration 150 : 0.015324093401432037
Loss at iteration 160 : 0.0083851283416152
Loss at iteration 170 : 0.011416953057050705
Loss at iteration 180 : 0.013025680556893349
Loss at iteration 190 : 0.014543660916388035
Loss at iteration 200 : 0.01297801360487938
Loss at iteration 210 : 0.006063262932002544
Loss at iteration 220 : 0.012095138430595398
Loss at iteration 230 : 0.016926376149058342
Loss at iteration 240 : 0.010440190322697163
Loss at iteration 250 : 0.013627501204609871
Loss at iteration 260 : 0.00901069212704897
Loss at iteration 270 : 0.003762622131034732
Loss at iteration 280 : 0.012899926863610744
Loss at iteration 290 : 0.009924139827489853
Loss at iteration 300 : 0.010210543870925903
Loss at iteration 310 : 0.004551445133984089
Loss at iteration 320 : 0.0037087900564074516
Loss at iteration 330 : 0.007370913866907358
Loss at iteration 340 : 0.01112258993089199
Loss at iteration 350 : 0.005864945240318775
Loss at iteration 360 : 0.012922332622110844
Loss at iteration 370 : 0.0057238140143454075
Loss at iteration 380 : 0.011537572368979454
Loss at iteration 390 : 0.009958372451364994
Loss at iteration 400 : 0.015297766774892807
Loss at iteration 410 : 0.008617323823273182
Loss at iteration 420 : 0.011315514333546162
Loss at iteration 430 : 0.005984385497868061
Loss at iteration 440 : 0.013648192398250103
Loss at iteration 450 : 0.01120635587722063
Loss at iteration 460 : 0.015063014812767506
Loss at iteration 470 : 0.014205928891897202
Loss at iteration 480 : 0.008750852197408676
Loss at iteration 490 : 0.021092070266604424
Loss at iteration 500 : 0.011513116769492626
Loss at iteration 510 : 0.01277921162545681
Loss at iteration 520 : 0.015736142173409462
Loss at iteration 530 : 0.011878602206707
Loss at iteration 540 : 0.02733946219086647
Loss at iteration 550 : 0.015092204324901104
Loss at iteration 560 : 0.0104846665635705
Loss at iteration 570 : 0.01071973331272602
Loss at iteration 580 : 0.012982282787561417
Loss at iteration 590 : 0.008426760323345661
Loss at iteration 600 : 0.013587245717644691
Loss at iteration 610 : 0.01816633529961109
Loss at iteration 620 : 0.01228942908346653
Loss at iteration 630 : 0.004439269192516804
Loss at iteration 640 : 0.018443981185555458
Loss at iteration 650 : 0.005536450073122978
Loss at iteration 660 : 0.008418677374720573
Loss at iteration 670 : 0.009188208729028702
Loss at iteration 680 : 0.005817628465592861
Loss at iteration 690 : 0.009812942706048489
Loss at iteration 700 : 0.01346378494054079
Loss at iteration 710 : 0.0030488769989460707
Loss at iteration 720 : 0.010676342993974686
Loss at iteration 730 : 0.010505066253244877
Loss at iteration 740 : 0.007889516651630402
Loss at iteration 750 : 0.01361792255192995
Loss at iteration 760 : 0.008645313791930676
Loss at iteration 770 : 0.005257440730929375
Loss at iteration 780 : 0.009859025478363037
Loss at iteration 790 : 0.014961324632167816
Loss at iteration 800 : 0.005508909001946449
Loss at iteration 810 : 0.005493966396898031
Loss at iteration 820 : 0.008703954517841339
Loss at iteration 830 : 0.007354476023465395
Loss at iteration 840 : 0.005822453647851944
Loss at iteration 850 : 0.010466860607266426
Loss at iteration 860 : 0.018168330192565918
Loss at iteration 870 : 0.007220899686217308
Loss at iteration 880 : 0.023240739479660988
Loss at iteration 890 : 0.011655718088150024
Loss at iteration 900 : 0.007346195634454489
Loss at iteration 910 : 0.011285838671028614
Loss at iteration 920 : 0.014420997351408005
Loss at iteration 930 : 0.014255341142416
Loss at iteration 940 : 0.004058564081788063
Loss at iteration 950 : 0.007043666671961546
Loss at iteration 960 : 0.004792391322553158
Loss at iteration 970 : 0.010625388473272324
Loss at iteration 980 : 0.004227128811180592
Loss at iteration 990 : 0.015214655548334122
Loss at iteration 1000 : 0.008566576987504959
Loss at iteration 1010 : 0.01765744760632515
Loss at iteration 1020 : 0.006656003184616566
Loss at iteration 1030 : 0.029522720724344254
Loss at iteration 1040 : 0.009833653457462788
Loss at iteration 1050 : 0.005242437589913607
Loss at iteration 1060 : 0.005286805797368288
Loss at iteration 1070 : 0.03150632977485657
Loss at iteration 1080 : 0.009976714849472046
Loss at iteration 1090 : 0.005894710775464773
Loss at iteration 1100 : 0.02115957997739315
Loss at iteration 1110 : 0.015366846695542336
Loss at iteration 1120 : 0.0107268700376153
Loss at iteration 1130 : 0.00791291892528534
Loss at iteration 1140 : 0.009134470485150814
Loss at iteration 1150 : 0.034745268523693085
Loss at iteration 1160 : 0.008450504392385483
Loss at iteration 1170 : 0.009965107776224613
Loss at iteration 1180 : 0.00646195188164711
Loss at iteration 1190 : 0.006698861718177795
Loss at iteration 1200 : 0.01721314527094364
Loss at iteration 1210 : 0.014046099968254566
Loss at iteration 1220 : 0.016141939908266068
Loss at iteration 1230 : 0.008812151849269867
Loss at iteration 1240 : 0.006822394207119942
Loss at iteration 1250 : 0.019858768209815025
Loss at iteration 1260 : 0.015253765508532524
Loss at iteration 1270 : 0.007409199140965939
Loss at iteration 1280 : 0.011900603771209717
Loss at iteration 1290 : 0.009917533956468105
Loss at iteration 1300 : 0.01190464198589325
Loss at iteration 1310 : 0.017273545265197754
Loss at iteration 1320 : 0.009751076810061932
Loss at iteration 1330 : 0.002746215322986245
Loss at iteration 1340 : 0.017010891810059547
Loss at iteration 1350 : 0.007859625853598118
Loss at iteration 1360 : 0.007593112997710705
Loss at iteration 1370 : 0.012531481683254242
Loss at iteration 1380 : 0.007688986603170633
Loss at iteration 1390 : 0.007208013907074928
Loss at iteration 1400 : 0.004073411226272583
Loss at iteration 1410 : 0.009285710752010345
Loss at iteration 1420 : 0.005347148980945349
Loss at iteration 1430 : 0.008120112121105194
Loss at iteration 1440 : 0.008159803226590157
Loss at iteration 1450 : 0.01628834381699562
Loss at iteration 1460 : 0.007103067822754383
Loss at iteration 1470 : 0.01485365629196167
Loss at iteration 1480 : 0.006182136945426464
Loss at iteration 1490 : 0.005605625919997692
Loss at iteration 1500 : 0.015393678098917007
Loss at iteration 1510 : 0.018044881522655487
Loss at iteration 1520 : 0.013482372276484966
Loss at iteration 1530 : 0.006702176295220852
Loss at iteration 1540 : 0.004511982202529907
Loss at iteration 1550 : 0.0037245245184749365
Loss at iteration 1560 : 0.008295269683003426
Loss at iteration 1570 : 0.005198583006858826
Loss at iteration 1580 : 0.01859832927584648
Loss at iteration 1590 : 0.0049740830436348915
Loss at iteration 1600 : 0.021471144631505013
Loss at iteration 1610 : 0.012265162542462349
Loss at iteration 1620 : 0.006838631350547075
Loss at iteration 1630 : 0.0077009499073028564
Loss at iteration 1640 : 0.025248557329177856
Loss at iteration 1650 : 0.008985362015664577
Loss at iteration 1660 : 0.010643484070897102
Loss at iteration 1670 : 0.011123452335596085
Loss at iteration 1680 : 0.008472668938338757
Loss at iteration 1690 : 0.03686714172363281
Loss at iteration 1700 : 0.010189704596996307
Loss at iteration 1710 : 0.0107808168977499
Loss at iteration 1720 : 0.010115880519151688
Loss at iteration 1730 : 0.015386447310447693
Loss at iteration 1740 : 0.02146208845078945
Loss at iteration 1750 : 0.015428957529366016
Loss at iteration 1760 : 0.006188719999045134
Loss at iteration 1770 : 0.01600036397576332
Loss at iteration 1780 : 0.007166504859924316
Loss at iteration 1790 : 0.012933065183460712
Loss at iteration 1800 : 0.010979097336530685
Loss at iteration 1810 : 0.01394033245742321
Loss at iteration 1820 : 0.007401772774755955
Loss at iteration 1830 : 0.00946044921875
Loss at iteration 1840 : 0.006022684276103973
Loss at iteration 1850 : 0.013027920387685299
Loss at iteration 1860 : 0.004559461493045092
Loss at iteration 1870 : 0.019871100783348083
Loss at iteration 1880 : 0.003996214363723993
Loss at iteration 1890 : 0.007731534540653229
Loss at iteration 1900 : 0.015771280974149704
Loss at iteration 1910 : 0.016259919852018356
Loss at iteration 1920 : 0.01074947603046894
Loss at iteration 1930 : 0.007483396679162979
Loss at iteration 1940 : 0.008422089740633965
Loss at iteration 1950 : 0.012407137081027031
Loss at iteration 1960 : 0.008474309928715229
Loss at iteration 1970 : 0.0059390198439359665
Loss at iteration 1980 : 0.008571075275540352
Loss at iteration 1990 : 0.011586418375372887
Loss at iteration 2000 : 0.010634749196469784
Loss at iteration 2010 : 0.006915937177836895
Loss at iteration 2020 : 0.011759655550122261
Loss at iteration 2030 : 0.009811869822442532
Loss at iteration 2040 : 0.008641614578664303
Loss at iteration 2050 : 0.018311576917767525
Loss at iteration 2060 : 0.015198629349470139
Loss at iteration 2070 : 0.006001283414661884
Loss at iteration 2080 : 0.014815605245530605
Loss at iteration 2090 : 0.011752020567655563
Loss at iteration 2100 : 0.009299049153923988
Loss at iteration 2110 : 0.006631006021052599
Loss at iteration 2120 : 0.016420913860201836
Loss at iteration 2130 : 0.01378070842474699
Loss at iteration 2140 : 0.008281135000288486
Loss at iteration 2150 : 0.0077439770102500916
Loss at iteration 2160 : 0.011493324302136898
Loss at iteration 2170 : 0.01335143856704235
Loss at iteration 2180 : 0.010927335359156132
Loss at iteration 2190 : 0.01192009262740612
Loss at iteration 2200 : 0.011804738081991673
Loss at iteration 2210 : 0.008894050493836403
Loss at iteration 2220 : 0.007764122914522886
Loss at iteration 2230 : 0.004486009478569031
Loss at iteration 2240 : 0.005329614505171776
Loss at iteration 2250 : 0.01744946837425232
Loss at iteration 2260 : 0.020517516881227493
Loss at iteration 2270 : 0.011649101972579956
Loss at iteration 2280 : 0.016471846029162407
Loss at iteration 2290 : 0.0052910372614860535
Loss at iteration 2300 : 0.01471692230552435
Loss at iteration 2310 : 0.01532258652150631
Loss at iteration 2320 : 0.009681371040642262
Loss at iteration 2330 : 0.019403722137212753
Loss at iteration 2340 : 0.008064120076596737
Loss at iteration 2350 : 0.013411812484264374
Loss at iteration 2360 : 0.009321941062808037
Loss at iteration 2370 : 0.010594948194921017
Loss at iteration 2380 : 0.009161008521914482
Loss at iteration 2390 : 0.011691940948367119
Loss at iteration 2400 : 0.022892603650689125
Loss at iteration 2410 : 0.00998949259519577
Loss at iteration 2420 : 0.01630619540810585
The SSIM Value is: 0.8327130873998007
The PSNR Value is: 20.470472462972005
the epoch is: 47
Loss at iteration 10 : 0.006923931185156107
Loss at iteration 20 : 0.012764409184455872
Loss at iteration 30 : 0.006545475218445063
Loss at iteration 40 : 0.006155562587082386
Loss at iteration 50 : 0.020733632147312164
Loss at iteration 60 : 0.013051415793597698
Loss at iteration 70 : 0.012308015488088131
Loss at iteration 80 : 0.016593236476182938
Loss at iteration 90 : 0.010307000018656254
Loss at iteration 100 : 0.017724666744470596
Loss at iteration 110 : 0.006431990768760443
Loss at iteration 120 : 0.017155500128865242
Loss at iteration 130 : 0.009946078062057495
Loss at iteration 140 : 0.009088069200515747
Loss at iteration 150 : 0.00972108542919159
Loss at iteration 160 : 0.007448877673596144
Loss at iteration 170 : 0.009619228541851044
Loss at iteration 180 : 0.013114798814058304
Loss at iteration 190 : 0.007409234531223774
Loss at iteration 200 : 0.007074580993503332
Loss at iteration 210 : 0.011561448685824871
Loss at iteration 220 : 0.009379821829497814
Loss at iteration 230 : 0.008779732510447502
Loss at iteration 240 : 0.005584688391536474
Loss at iteration 250 : 0.012929089367389679
Loss at iteration 260 : 0.007769390009343624
Loss at iteration 270 : 0.003813678864389658
Loss at iteration 280 : 0.010167069733142853
Loss at iteration 290 : 0.009519798681139946
Loss at iteration 300 : 0.008761880919337273
Loss at iteration 310 : 0.0058969007804989815
Loss at iteration 320 : 0.008074436336755753
Loss at iteration 330 : 0.01014862209558487
Loss at iteration 340 : 0.011496687307953835
Loss at iteration 350 : 0.016803784295916557
Loss at iteration 360 : 0.005463782697916031
Loss at iteration 370 : 0.00818859227001667
Loss at iteration 380 : 0.015249203890562057
Loss at iteration 390 : 0.008739026263356209
Loss at iteration 400 : 0.011201955378055573
Loss at iteration 410 : 0.010465770028531551
Loss at iteration 420 : 0.012556461617350578
Loss at iteration 430 : 0.007617452647536993
Loss at iteration 440 : 0.011274965479969978
Loss at iteration 450 : 0.013191644102334976
Loss at iteration 460 : 0.015556861646473408
Loss at iteration 470 : 0.009508735500276089
Loss at iteration 480 : 0.008665925823152065
Loss at iteration 490 : 0.011164679192006588
Loss at iteration 500 : 0.011668631806969643
Loss at iteration 510 : 0.013628258369863033
Loss at iteration 520 : 0.013330847956240177
Loss at iteration 530 : 0.012973431497812271
Loss at iteration 540 : 0.007981609553098679
Loss at iteration 550 : 0.006249335594475269
Loss at iteration 560 : 0.004682775121182203
Loss at iteration 570 : 0.011894472874701023
Loss at iteration 580 : 0.0027310969308018684
Loss at iteration 590 : 0.015395672991871834
Loss at iteration 600 : 0.012932347133755684
Loss at iteration 610 : 0.011855028569698334
Loss at iteration 620 : 0.009685300290584564
Loss at iteration 630 : 0.006801096256822348
Loss at iteration 640 : 0.013683289289474487
Loss at iteration 650 : 0.015145565383136272
Loss at iteration 660 : 0.01875251717865467
Loss at iteration 670 : 0.0069674234837293625
Loss at iteration 680 : 0.0163666270673275
Loss at iteration 690 : 0.006874474231153727
Loss at iteration 700 : 0.010324394330382347
Loss at iteration 710 : 0.009344280697405338
Loss at iteration 720 : 0.0066855414770543575
Loss at iteration 730 : 0.00923716276884079
Loss at iteration 740 : 0.011872959323227406
Loss at iteration 750 : 0.011452898383140564
Loss at iteration 760 : 0.014577323570847511
Loss at iteration 770 : 0.01701393723487854
Loss at iteration 780 : 0.010519222356379032
Loss at iteration 790 : 0.014949996024370193
Loss at iteration 800 : 0.00831032544374466
Loss at iteration 810 : 0.01289660669863224
Loss at iteration 820 : 0.014486473053693771
Loss at iteration 830 : 0.01324017345905304
Loss at iteration 840 : 0.01653369702398777
Loss at iteration 850 : 0.007053089793771505
Loss at iteration 860 : 0.016971543431282043
Loss at iteration 870 : 0.005800639279186726
Loss at iteration 880 : 0.012089005671441555
Loss at iteration 890 : 0.009118176996707916
Loss at iteration 900 : 0.011860276572406292
Loss at iteration 910 : 0.012639842927455902
Loss at iteration 920 : 0.012144183740019798
Loss at iteration 930 : 0.009569009765982628
Loss at iteration 940 : 0.01712273433804512
Loss at iteration 950 : 0.013410432264208794
Loss at iteration 960 : 0.008810523897409439
Loss at iteration 970 : 0.01397436298429966
Loss at iteration 980 : 0.006125055253505707
Loss at iteration 990 : 0.003963755909353495
Loss at iteration 1000 : 0.012547317892313004
Loss at iteration 1010 : 0.021811652928590775
Loss at iteration 1020 : 0.009939512237906456
Loss at iteration 1030 : 0.011850731447339058
Loss at iteration 1040 : 0.0050405762158334255
Loss at iteration 1050 : 0.013460194692015648
Loss at iteration 1060 : 0.017398545518517494
Loss at iteration 1070 : 0.009840765967965126
Loss at iteration 1080 : 0.016227873042225838
Loss at iteration 1090 : 0.011618263088166714
Loss at iteration 1100 : 0.010745452716946602
Loss at iteration 1110 : 0.011134913191199303
Loss at iteration 1120 : 0.0021765627898275852
Loss at iteration 1130 : 0.017953509464859962
Loss at iteration 1140 : 0.008808059617877007
Loss at iteration 1150 : 0.02011525258421898
Loss at iteration 1160 : 0.0074621145613491535
Loss at iteration 1170 : 0.011890397407114506
Loss at iteration 1180 : 0.012057138606905937
Loss at iteration 1190 : 0.007249132264405489
Loss at iteration 1200 : 0.016903813928365707
Loss at iteration 1210 : 0.006166476756334305
Loss at iteration 1220 : 0.01728774607181549
Loss at iteration 1230 : 0.007098257541656494
Loss at iteration 1240 : 0.012888403609395027
Loss at iteration 1250 : 0.007018723990768194
Loss at iteration 1260 : 0.006290932185947895
Loss at iteration 1270 : 0.013774527236819267
Loss at iteration 1280 : 0.013809723779559135
Loss at iteration 1290 : 0.008710894733667374
Loss at iteration 1300 : 0.01032248605042696
Loss at iteration 1310 : 0.007793937344104052
Loss at iteration 1320 : 0.003422501729801297
Loss at iteration 1330 : 0.008412031456828117
Loss at iteration 1340 : 0.010846280492842197
Loss at iteration 1350 : 0.011966953054070473
Loss at iteration 1360 : 0.005800027400255203
Loss at iteration 1370 : 0.006293893791735172
Loss at iteration 1380 : 0.008208644576370716
Loss at iteration 1390 : 0.004825099371373653
Loss at iteration 1400 : 0.009238907136023045
Loss at iteration 1410 : 0.007498826831579208
Loss at iteration 1420 : 0.008388316258788109
Loss at iteration 1430 : 0.007273499853909016
Loss at iteration 1440 : 0.013325379230082035
Loss at iteration 1450 : 0.01424529030919075
Loss at iteration 1460 : 0.010018283501267433
Loss at iteration 1470 : 0.009668407961726189
Loss at iteration 1480 : 0.008658838458359241
Loss at iteration 1490 : 0.009986285120248795
Loss at iteration 1500 : 0.01894276961684227
Loss at iteration 1510 : 0.012516411952674389
Loss at iteration 1520 : 0.0068887341767549515
Loss at iteration 1530 : 0.011913754977285862
Loss at iteration 1540 : 0.012171883136034012
Loss at iteration 1550 : 0.006669781636446714
Loss at iteration 1560 : 0.01097914669662714
Loss at iteration 1570 : 0.0061523402109742165
Loss at iteration 1580 : 0.005503904074430466
Loss at iteration 1590 : 0.012337465770542622
Loss at iteration 1600 : 0.011370092630386353
Loss at iteration 1610 : 0.012931855395436287
Loss at iteration 1620 : 0.016451535746455193
Loss at iteration 1630 : 0.015952957794070244
Loss at iteration 1640 : 0.010178430005908012
Loss at iteration 1650 : 0.015609271824359894
Loss at iteration 1660 : 0.012162352912127972
Loss at iteration 1670 : 0.009096812456846237
Loss at iteration 1680 : 0.012984022498130798
Loss at iteration 1690 : 0.01635216362774372
Loss at iteration 1700 : 0.006856076419353485
Loss at iteration 1710 : 0.006870772689580917
Loss at iteration 1720 : 0.010034743696451187
Loss at iteration 1730 : 0.0041978321969509125
Loss at iteration 1740 : 0.005210339091718197
Loss at iteration 1750 : 0.015805872157216072
Loss at iteration 1760 : 0.00860617309808731
Loss at iteration 1770 : 0.013976279646158218
Loss at iteration 1780 : 0.011043490841984749
Loss at iteration 1790 : 0.015832070261240005
Loss at iteration 1800 : 0.007652428466826677
Loss at iteration 1810 : 0.008705982938408852
Loss at iteration 1820 : 0.008237713016569614
Loss at iteration 1830 : 0.010584820061922073
Loss at iteration 1840 : 0.014729848131537437
Loss at iteration 1850 : 0.015619552694261074
Loss at iteration 1860 : 0.00689749326556921
Loss at iteration 1870 : 0.00951958354562521
Loss at iteration 1880 : 0.013009345158934593
Loss at iteration 1890 : 0.008513407781720161
Loss at iteration 1900 : 0.0038660080172121525
Loss at iteration 1910 : 0.009755361825227737
Loss at iteration 1920 : 0.01624477654695511
Loss at iteration 1930 : 0.010313721373677254
Loss at iteration 1940 : 0.005738504230976105
Loss at iteration 1950 : 0.0037631855811923742
Loss at iteration 1960 : 0.015108994208276272
Loss at iteration 1970 : 0.00964055024087429
Loss at iteration 1980 : 0.008513269945979118
Loss at iteration 1990 : 0.009616936556994915
Loss at iteration 2000 : 0.013465258292853832
Loss at iteration 2010 : 0.0071592205204069614
Loss at iteration 2020 : 0.016749205067753792
Loss at iteration 2030 : 0.00629893084987998
Loss at iteration 2040 : 0.00969703495502472
Loss at iteration 2050 : 0.007748716045171022
Loss at iteration 2060 : 0.012190500274300575
Loss at iteration 2070 : 0.005717101972550154
Loss at iteration 2080 : 0.011516794562339783
Loss at iteration 2090 : 0.016620635986328125
Loss at iteration 2100 : 0.01272510178387165
Loss at iteration 2110 : 0.026589058339595795
Loss at iteration 2120 : 0.010675275698304176
Loss at iteration 2130 : 0.00918178167194128
Loss at iteration 2140 : 0.018611181527376175
Loss at iteration 2150 : 0.020418822765350342
Loss at iteration 2160 : 0.011236591264605522
Loss at iteration 2170 : 0.011998942121863365
Loss at iteration 2180 : 0.01286381110548973
Loss at iteration 2190 : 0.008669789880514145
Loss at iteration 2200 : 0.014858318492770195
Loss at iteration 2210 : 0.005043793935328722
Loss at iteration 2220 : 0.005993591621518135
Loss at iteration 2230 : 0.013233544304966927
Loss at iteration 2240 : 0.014712320640683174
Loss at iteration 2250 : 0.014095927588641644
Loss at iteration 2260 : 0.007097465917468071
Loss at iteration 2270 : 0.007581556681543589
Loss at iteration 2280 : 0.005698272492736578
Loss at iteration 2290 : 0.005558639764785767
Loss at iteration 2300 : 0.011290417984127998
Loss at iteration 2310 : 0.009192339144647121
Loss at iteration 2320 : 0.008280279114842415
Loss at iteration 2330 : 0.009480329230427742
Loss at iteration 2340 : 0.012722035869956017
Loss at iteration 2350 : 0.007669547572731972
Loss at iteration 2360 : 0.008447650820016861
Loss at iteration 2370 : 0.015438126400113106
Loss at iteration 2380 : 0.006903216242790222
Loss at iteration 2390 : 0.011367096565663815
Loss at iteration 2400 : 0.018037203699350357
Loss at iteration 2410 : 0.0035343626514077187
Loss at iteration 2420 : 0.010888319462537766
The SSIM Value is: 0.8275472124417623
The PSNR Value is: 22.078001658121746
the epoch is: 48
Loss at iteration 10 : 0.00956934317946434
Loss at iteration 20 : 0.013376670889556408
Loss at iteration 30 : 0.020754367113113403
Loss at iteration 40 : 0.0059682391583919525
Loss at iteration 50 : 0.008361713960766792
Loss at iteration 60 : 0.012321054935455322
Loss at iteration 70 : 0.00702340342104435
Loss at iteration 80 : 0.00779747823253274
Loss at iteration 90 : 0.011821889318525791
Loss at iteration 100 : 0.004918430466204882
Loss at iteration 110 : 0.007366286590695381
Loss at iteration 120 : 0.006763014942407608
Loss at iteration 130 : 0.006050106603652239
Loss at iteration 140 : 0.014576150104403496
Loss at iteration 150 : 0.015331432223320007
Loss at iteration 160 : 0.007122669834643602
Loss at iteration 170 : 0.010253163054585457
Loss at iteration 180 : 0.008884439244866371
Loss at iteration 190 : 0.00845567137002945
Loss at iteration 200 : 0.0064863525331020355
Loss at iteration 210 : 0.01814255304634571
Loss at iteration 220 : 0.008102376945316792
Loss at iteration 230 : 0.00861065648496151
Loss at iteration 240 : 0.0065390681847929955
Loss at iteration 250 : 0.020932283252477646
Loss at iteration 260 : 0.006337238010019064
Loss at iteration 270 : 0.010565517470240593
Loss at iteration 280 : 0.006742712575942278
Loss at iteration 290 : 0.005963264033198357
Loss at iteration 300 : 0.016685131937265396
Loss at iteration 310 : 0.00995904952287674
Loss at iteration 320 : 0.006937270984053612
Loss at iteration 330 : 0.005912680644541979
Loss at iteration 340 : 0.002076679142192006
Loss at iteration 350 : 0.0070618391036987305
Loss at iteration 360 : 0.009042398072779179
Loss at iteration 370 : 0.010508310049772263
Loss at iteration 380 : 0.004397283308207989
Loss at iteration 390 : 0.011232550255954266
Loss at iteration 400 : 0.006236027926206589
Loss at iteration 410 : 0.006963410880416632
Loss at iteration 420 : 0.019712284207344055
Loss at iteration 430 : 0.00872433464974165
Loss at iteration 440 : 0.010916005820035934
Loss at iteration 450 : 0.00758007587864995
Loss at iteration 460 : 0.0023900591768324375
Loss at iteration 470 : 0.008929086849093437
Loss at iteration 480 : 0.007834027521312237
Loss at iteration 490 : 0.007379696238785982
Loss at iteration 500 : 0.017781613394618034
Loss at iteration 510 : 0.015336114913225174
Loss at iteration 520 : 0.0041863564401865005
Loss at iteration 530 : 0.006448772735893726
Loss at iteration 540 : 0.019032027572393417
Loss at iteration 550 : 0.003614050103351474
Loss at iteration 560 : 0.010930582880973816
Loss at iteration 570 : 0.010878358036279678
Loss at iteration 580 : 0.008422122336924076
Loss at iteration 590 : 0.0184572022408247
Loss at iteration 600 : 0.009946245700120926
Loss at iteration 610 : 0.011741535738110542
Loss at iteration 620 : 0.009221090003848076
Loss at iteration 630 : 0.005733640864491463
Loss at iteration 640 : 0.003110012970864773
Loss at iteration 650 : 0.01611059345304966
Loss at iteration 660 : 0.0057529183104634285
Loss at iteration 670 : 0.010208707302808762
Loss at iteration 680 : 0.009398901835083961
Loss at iteration 690 : 0.015961697325110435
Loss at iteration 700 : 0.007990303449332714
Loss at iteration 710 : 0.010456334799528122
Loss at iteration 720 : 0.010447440668940544
Loss at iteration 730 : 0.015977628529071808
Loss at iteration 740 : 0.0174559336155653
Loss at iteration 750 : 0.010322009213268757
Loss at iteration 760 : 0.008763736113905907
Loss at iteration 770 : 0.009756742045283318
Loss at iteration 780 : 0.01010923832654953
Loss at iteration 790 : 0.005112691782414913
Loss at iteration 800 : 0.01773587241768837
Loss at iteration 810 : 0.009705886244773865
Loss at iteration 820 : 0.0050253430381417274
Loss at iteration 830 : 0.01571553573012352
Loss at iteration 840 : 0.013472357764840126
Loss at iteration 850 : 0.011864520609378815
Loss at iteration 860 : 0.02901439741253853
Loss at iteration 870 : 0.013442348688840866
Loss at iteration 880 : 0.007557481061667204
Loss at iteration 890 : 0.007756943814456463
Loss at iteration 900 : 0.006783071905374527
Loss at iteration 910 : 0.005366144701838493
Loss at iteration 920 : 0.008858141489326954
Loss at iteration 930 : 0.010891644284129143
Loss at iteration 940 : 0.016398023813962936
Loss at iteration 950 : 0.003951761871576309
Loss at iteration 960 : 0.006155648734420538
Loss at iteration 970 : 0.006921809166669846
Loss at iteration 980 : 0.009622541256248951
Loss at iteration 990 : 0.008217405527830124
Loss at iteration 1000 : 0.005741880740970373
Loss at iteration 1010 : 0.011529017239809036
Loss at iteration 1020 : 0.007193373050540686
Loss at iteration 1030 : 0.011373990215361118
Loss at iteration 1040 : 0.009855177253484726
Loss at iteration 1050 : 0.0031722462736070156
Loss at iteration 1060 : 0.016739578917622566
Loss at iteration 1070 : 0.009012723341584206
Loss at iteration 1080 : 0.006578962318599224
Loss at iteration 1090 : 0.006329805590212345
Loss at iteration 1100 : 0.005380373448133469
Loss at iteration 1110 : 0.0072250086814165115
Loss at iteration 1120 : 0.014808736741542816
Loss at iteration 1130 : 0.006925191730260849
Loss at iteration 1140 : 0.009515886195003986
Loss at iteration 1150 : 0.00961108785122633
Loss at iteration 1160 : 0.006040417589247227
Loss at iteration 1170 : 0.005383968818932772
Loss at iteration 1180 : 0.00988680962473154
Loss at iteration 1190 : 0.010946881957352161
Loss at iteration 1200 : 0.0075814989395439625
Loss at iteration 1210 : 0.014176903292536736
Loss at iteration 1220 : 0.0146283358335495
Loss at iteration 1230 : 0.013955162838101387
Loss at iteration 1240 : 0.007767576724290848
Loss at iteration 1250 : 0.01887781172990799
Loss at iteration 1260 : 0.008729856461286545
Loss at iteration 1270 : 0.016655445098876953
Loss at iteration 1280 : 0.015598950907588005
Loss at iteration 1290 : 0.00728871114552021
Loss at iteration 1300 : 0.010163027793169022
Loss at iteration 1310 : 0.020361244678497314
Loss at iteration 1320 : 0.007187744602560997
Loss at iteration 1330 : 0.0065949154086411
Loss at iteration 1340 : 0.012719161808490753
Loss at iteration 1350 : 0.0045976582914590836
Loss at iteration 1360 : 0.00634080171585083
Loss at iteration 1370 : 0.003478370141237974
Loss at iteration 1380 : 0.005366037134081125
Loss at iteration 1390 : 0.01082107424736023
Loss at iteration 1400 : 0.010755788534879684
Loss at iteration 1410 : 0.006462958641350269
Loss at iteration 1420 : 0.013123799115419388
Loss at iteration 1430 : 0.0034078217577189207
Loss at iteration 1440 : 0.011724237352609634
Loss at iteration 1450 : 0.006920129992067814
Loss at iteration 1460 : 0.006386526394635439
Loss at iteration 1470 : 0.008100245147943497
Loss at iteration 1480 : 0.0070677511394023895
Loss at iteration 1490 : 0.0053676641546189785
Loss at iteration 1500 : 0.00711359828710556
Loss at iteration 1510 : 0.008447553962469101
Loss at iteration 1520 : 0.007192457094788551
Loss at iteration 1530 : 0.009958488866686821
Loss at iteration 1540 : 0.010372829623520374
Loss at iteration 1550 : 0.007388348691165447
Loss at iteration 1560 : 0.010271495208144188
Loss at iteration 1570 : 0.007252850569784641
Loss at iteration 1580 : 0.015574006363749504
Loss at iteration 1590 : 0.006972145289182663
Loss at iteration 1600 : 0.01525598019361496
Loss at iteration 1610 : 0.009946024045348167
Loss at iteration 1620 : 0.010106785222887993
Loss at iteration 1630 : 0.007085450924932957
Loss at iteration 1640 : 0.014642726629972458
Loss at iteration 1650 : 0.010593853890895844
Loss at iteration 1660 : 0.0200168639421463
Loss at iteration 1670 : 0.017854398116469383
Loss at iteration 1680 : 0.004703148268163204
Loss at iteration 1690 : 0.015393264591693878
Loss at iteration 1700 : 0.0032333876006305218
Loss at iteration 1710 : 0.008440986275672913
Loss at iteration 1720 : 0.01451040804386139
Loss at iteration 1730 : 0.012961401604115963
Loss at iteration 1740 : 0.019000425934791565
Loss at iteration 1750 : 0.004957491997629404
Loss at iteration 1760 : 0.00790912564843893
Loss at iteration 1770 : 0.011509386822581291
Loss at iteration 1780 : 0.01111965999007225
Loss at iteration 1790 : 0.00676053436473012
Loss at iteration 1800 : 0.007843738421797752
Loss at iteration 1810 : 0.003058740869164467
Loss at iteration 1820 : 0.014289428479969501
Loss at iteration 1830 : 0.017214596271514893
Loss at iteration 1840 : 0.013090655207633972
Loss at iteration 1850 : 0.01046334020793438
Loss at iteration 1860 : 0.008508526720106602
Loss at iteration 1870 : 0.00267495634034276
Loss at iteration 1880 : 0.017861273139715195
Loss at iteration 1890 : 0.011220240034162998
Loss at iteration 1900 : 0.003254904644563794
Loss at iteration 1910 : 0.0075185163877904415
Loss at iteration 1920 : 0.006312998943030834
Loss at iteration 1930 : 0.012153987772762775
Loss at iteration 1940 : 0.007272176444530487
Loss at iteration 1950 : 0.010930117219686508
Loss at iteration 1960 : 0.0056135039776563644
Loss at iteration 1970 : 0.014517862349748611
Loss at iteration 1980 : 0.006758273113518953
Loss at iteration 1990 : 0.007480236701667309
Loss at iteration 2000 : 0.00962594710290432
Loss at iteration 2010 : 0.009162124246358871
Loss at iteration 2020 : 0.012218330055475235
Loss at iteration 2030 : 0.016956886276602745
Loss at iteration 2040 : 0.013279028236865997
Loss at iteration 2050 : 0.007123592309653759
Loss at iteration 2060 : 0.010472200810909271
Loss at iteration 2070 : 0.007976580411195755
Loss at iteration 2080 : 0.0046608964912593365
Loss at iteration 2090 : 0.007773471996188164
Loss at iteration 2100 : 0.007949387654662132
Loss at iteration 2110 : 0.01962696574628353
Loss at iteration 2120 : 0.005863875150680542
Loss at iteration 2130 : 0.0046890960074961185
Loss at iteration 2140 : 0.010351517237722874
Loss at iteration 2150 : 0.014823216944932938
Loss at iteration 2160 : 0.007439023815095425
Loss at iteration 2170 : 0.004710438661277294
Loss at iteration 2180 : 0.004823612980544567
Loss at iteration 2190 : 0.01334935799241066
Loss at iteration 2200 : 0.013116038404405117
Loss at iteration 2210 : 0.004508909769356251
Loss at iteration 2220 : 0.006418882869184017
Loss at iteration 2230 : 0.01585710048675537
Loss at iteration 2240 : 0.008485443890094757
Loss at iteration 2250 : 0.011262524873018265
Loss at iteration 2260 : 0.009740002453327179
Loss at iteration 2270 : 0.006612388417124748
Loss at iteration 2280 : 0.007966463454067707
Loss at iteration 2290 : 0.009098852053284645
Loss at iteration 2300 : 0.006011483259499073
Loss at iteration 2310 : 0.006423868704587221
Loss at iteration 2320 : 0.005692766979336739
Loss at iteration 2330 : 0.013129026629030704
Loss at iteration 2340 : 0.011475606821477413
Loss at iteration 2350 : 0.008700814098119736
Loss at iteration 2360 : 0.01159009337425232
Loss at iteration 2370 : 0.03667508810758591
Loss at iteration 2380 : 0.00990714319050312
Loss at iteration 2390 : 0.03305765241384506
Loss at iteration 2400 : 0.010750328190624714
Loss at iteration 2410 : 0.019994858652353287
Loss at iteration 2420 : 0.016484063118696213
The SSIM Value is: 0.8184788624445597
The PSNR Value is: 19.916298802693685
the epoch is: 49
Loss at iteration 10 : 0.01786225289106369
Loss at iteration 20 : 0.006551537197083235
Loss at iteration 30 : 0.008187657222151756
Loss at iteration 40 : 0.011293095536530018
Loss at iteration 50 : 0.012151901610195637
Loss at iteration 60 : 0.009715039283037186
Loss at iteration 70 : 0.011039634235203266
Loss at iteration 80 : 0.018653325736522675
Loss at iteration 90 : 0.013365354388952255
Loss at iteration 100 : 0.011807380244135857
Loss at iteration 110 : 0.013156452216207981
Loss at iteration 120 : 0.0035114844795316458
Loss at iteration 130 : 0.009723037481307983
Loss at iteration 140 : 0.006322736851871014
Loss at iteration 150 : 0.008001535199582577
Loss at iteration 160 : 0.021069033071398735
Loss at iteration 170 : 0.012279843911528587
Loss at iteration 180 : 0.009113810956478119
Loss at iteration 190 : 0.004574351012706757
Loss at iteration 200 : 0.008147013373672962
Loss at iteration 210 : 0.010899277403950691
Loss at iteration 220 : 0.014344469644129276
Loss at iteration 230 : 0.008387010544538498
Loss at iteration 240 : 0.009792778640985489
Loss at iteration 250 : 0.008876306004822254
Loss at iteration 260 : 0.007548540364950895
Loss at iteration 270 : 0.01537530031055212
Loss at iteration 280 : 0.010734698735177517
Loss at iteration 290 : 0.018293242901563644
Loss at iteration 300 : 0.014260949566960335
Loss at iteration 310 : 0.009471188299357891
Loss at iteration 320 : 0.011694778688251972
Loss at iteration 330 : 0.010773226618766785
Loss at iteration 340 : 0.010302267968654633
Loss at iteration 350 : 0.011818780563771725
Loss at iteration 360 : 0.009419212117791176
Loss at iteration 370 : 0.012161612510681152
Loss at iteration 380 : 0.015478285029530525
Loss at iteration 390 : 0.006472937762737274
Loss at iteration 400 : 0.015659667551517487
Loss at iteration 410 : 0.017729755491018295
Loss at iteration 420 : 0.003730025142431259
Loss at iteration 430 : 0.004547541961073875
Loss at iteration 440 : 0.008604737929999828
Loss at iteration 450 : 0.0057226973585784435
Loss at iteration 460 : 0.006895787548273802
Loss at iteration 470 : 0.005773329641669989
Loss at iteration 480 : 0.010142209008336067
Loss at iteration 490 : 0.01425267569720745
Loss at iteration 500 : 0.0143442302942276
Loss at iteration 510 : 0.010131249204277992
Loss at iteration 520 : 0.011498287320137024
Loss at iteration 530 : 0.00691599166020751
Loss at iteration 540 : 0.012538713403046131
Loss at iteration 550 : 0.008625870570540428
Loss at iteration 560 : 0.00536753935739398
Loss at iteration 570 : 0.009889945387840271
Loss at iteration 580 : 0.013395208865404129
Loss at iteration 590 : 0.007483381778001785
Loss at iteration 600 : 0.010173662565648556
Loss at iteration 610 : 0.004278734792023897
Loss at iteration 620 : 0.01124290470033884
Loss at iteration 630 : 0.015271084383130074
Loss at iteration 640 : 0.03270334005355835
Loss at iteration 650 : 0.005238180048763752
Loss at iteration 660 : 0.007799264509230852
Loss at iteration 670 : 0.010209613479673862
Loss at iteration 680 : 0.008832125924527645
Loss at iteration 690 : 0.010512220673263073
Loss at iteration 700 : 0.012908765114843845
Loss at iteration 710 : 0.006217546295374632
Loss at iteration 720 : 0.010684593580663204
Loss at iteration 730 : 0.01937728002667427
Loss at iteration 740 : 0.013112936168909073
Loss at iteration 750 : 0.01209296751767397
Loss at iteration 760 : 0.008763876743614674
Loss at iteration 770 : 0.020079834386706352
Loss at iteration 780 : 0.010712978430092335
Loss at iteration 790 : 0.018789660185575485
Loss at iteration 800 : 0.01285521686077118
Loss at iteration 810 : 0.007514053490012884
Loss at iteration 820 : 0.011065119877457619
Loss at iteration 830 : 0.006288977339863777
Loss at iteration 840 : 0.008695089258253574
Loss at iteration 850 : 0.009436769410967827
Loss at iteration 860 : 0.0058208368718624115
Loss at iteration 870 : 0.00773104652762413
Loss at iteration 880 : 0.0133094796910882
Loss at iteration 890 : 0.0032736763823777437
Loss at iteration 900 : 0.008545249700546265
Loss at iteration 910 : 0.010224049910902977
Loss at iteration 920 : 0.011146938428282738
Loss at iteration 930 : 0.016028258949518204
Loss at iteration 940 : 0.012755894102156162
Loss at iteration 950 : 0.005804667714983225
Loss at iteration 960 : 0.003323080949485302
Loss at iteration 970 : 0.009635337628424168
Loss at iteration 980 : 0.002459455979987979
Loss at iteration 990 : 0.011782178655266762
Loss at iteration 1000 : 0.01718743145465851
Loss at iteration 1010 : 0.008366751484572887
Loss at iteration 1020 : 0.008501894772052765
Loss at iteration 1030 : 0.004804462660104036
Loss at iteration 1040 : 0.004830367397516966
Loss at iteration 1050 : 0.007894136011600494
Loss at iteration 1060 : 0.011328261345624924
Loss at iteration 1070 : 0.014334184117615223
Loss at iteration 1080 : 0.0063949814066290855
Loss at iteration 1090 : 0.005716294050216675
Loss at iteration 1100 : 0.012087066657841206
Loss at iteration 1110 : 0.0073503111489117146
Loss at iteration 1120 : 0.012214230373501778
Loss at iteration 1130 : 0.00877903401851654
Loss at iteration 1140 : 0.019685963168740273
Loss at iteration 1150 : 0.011308963410556316
Loss at iteration 1160 : 0.02285512164235115
Loss at iteration 1170 : 0.010383352637290955
Loss at iteration 1180 : 0.009569588117301464
Loss at iteration 1190 : 0.012138862162828445
Loss at iteration 1200 : 0.014232814311981201
Loss at iteration 1210 : 0.016912255436182022
Loss at iteration 1220 : 0.009990747086703777
Loss at iteration 1230 : 0.01139062363654375
Loss at iteration 1240 : 0.011639581993222237
Loss at iteration 1250 : 0.01543178129941225
Loss at iteration 1260 : 0.008155148476362228
Loss at iteration 1270 : 0.01484240498393774
Loss at iteration 1280 : 0.007248034700751305
Loss at iteration 1290 : 0.011352826841175556
Loss at iteration 1300 : 0.016168029978871346
Loss at iteration 1310 : 0.00885782390832901
Loss at iteration 1320 : 0.008313370868563652
Loss at iteration 1330 : 0.0070651015266776085
Loss at iteration 1340 : 0.00632070517167449
Loss at iteration 1350 : 0.008247295394539833
Loss at iteration 1360 : 0.008121997117996216
Loss at iteration 1370 : 0.017315763980150223
Loss at iteration 1380 : 0.003920446615666151
Loss at iteration 1390 : 0.009367146529257298
Loss at iteration 1400 : 0.010977787896990776
Loss at iteration 1410 : 0.00364562775939703
Loss at iteration 1420 : 0.007671507075428963
Loss at iteration 1430 : 0.008010904304683208
Loss at iteration 1440 : 0.005101533140987158
Loss at iteration 1450 : 0.006320920307189226
Loss at iteration 1460 : 0.015941128134727478
Loss at iteration 1470 : 0.005846374202519655
Loss at iteration 1480 : 0.015149900689721107
Loss at iteration 1490 : 0.008357573300600052
Loss at iteration 1500 : 0.015054568648338318
Loss at iteration 1510 : 0.012986029498279095
Loss at iteration 1520 : 0.009458212181925774
Loss at iteration 1530 : 0.012319044210016727
Loss at iteration 1540 : 0.014951381832361221
Loss at iteration 1550 : 0.00568415829911828
Loss at iteration 1560 : 0.006713173817843199
Loss at iteration 1570 : 0.014386466704308987
Loss at iteration 1580 : 0.01859235018491745
Loss at iteration 1590 : 0.006688116583973169
Loss at iteration 1600 : 0.006030625198036432
Loss at iteration 1610 : 0.016232015565037727
Loss at iteration 1620 : 0.010310201905667782
Loss at iteration 1630 : 0.02411438152194023
Loss at iteration 1640 : 0.010985167697072029
Loss at iteration 1650 : 0.01365665253251791
Loss at iteration 1660 : 0.01730261743068695
Loss at iteration 1670 : 0.005727245472371578
Loss at iteration 1680 : 0.011031205765902996
Loss at iteration 1690 : 0.01679867133498192
Loss at iteration 1700 : 0.019452393054962158
Loss at iteration 1710 : 0.007440728135406971
Loss at iteration 1720 : 0.013142756186425686
Loss at iteration 1730 : 0.004267571028321981
Loss at iteration 1740 : 0.007173500955104828
Loss at iteration 1750 : 0.0169091634452343
Loss at iteration 1760 : 0.0038146201986819506
Loss at iteration 1770 : 0.0032035436015576124
Loss at iteration 1780 : 0.008198056370019913
Loss at iteration 1790 : 0.00636859517544508
Loss at iteration 1800 : 0.00545289134606719
Loss at iteration 1810 : 0.0030652096029371023
Loss at iteration 1820 : 0.003780283499509096
Loss at iteration 1830 : 0.010364088229835033
Loss at iteration 1840 : 0.016523921862244606
Loss at iteration 1850 : 0.006267814431339502
Loss at iteration 1860 : 0.007327722385525703
Loss at iteration 1870 : 0.011565810069441795
Loss at iteration 1880 : 0.015088094398379326
Loss at iteration 1890 : 0.004124938510358334
Loss at iteration 1900 : 0.008968290872871876
Loss at iteration 1910 : 0.013748448342084885
Loss at iteration 1920 : 0.009994516149163246
Loss at iteration 1930 : 0.014575554989278316
Loss at iteration 1940 : 0.008105550892651081
Loss at iteration 1950 : 0.011494619771838188
Loss at iteration 1960 : 0.007939423434436321
Loss at iteration 1970 : 0.006526205688714981
Loss at iteration 1980 : 0.008698108606040478
Loss at iteration 1990 : 0.012095725163817406
Loss at iteration 2000 : 0.005579136312007904
Loss at iteration 2010 : 0.010256812907755375
Loss at iteration 2020 : 0.010094871744513512
Loss at iteration 2030 : 0.00849062018096447
Loss at iteration 2040 : 0.005566739942878485
Loss at iteration 2050 : 0.012913558632135391
Loss at iteration 2060 : 0.009549983777105808
Loss at iteration 2070 : 0.008235950022935867
Loss at iteration 2080 : 0.005758299492299557
Loss at iteration 2090 : 0.00946858711540699
Loss at iteration 2100 : 0.007914643734693527
Loss at iteration 2110 : 0.007110270205885172
Loss at iteration 2120 : 0.026765696704387665
Loss at iteration 2130 : 0.00926787219941616
Loss at iteration 2140 : 0.010923114605247974
Loss at iteration 2150 : 0.009083736687898636
Loss at iteration 2160 : 0.0076335459016263485
Loss at iteration 2170 : 0.008185266517102718
Loss at iteration 2180 : 0.011703447438776493
Loss at iteration 2190 : 0.012894856743514538
Loss at iteration 2200 : 0.011722459457814693
Loss at iteration 2210 : 0.010674149729311466
Loss at iteration 2220 : 0.010544678196310997
Loss at iteration 2230 : 0.01318050455302
Loss at iteration 2240 : 0.0030545175541192293
Loss at iteration 2250 : 0.004010056611150503
Loss at iteration 2260 : 0.01940527930855751
Loss at iteration 2270 : 0.011767374351620674
Loss at iteration 2280 : 0.023546230047941208
Loss at iteration 2290 : 0.011623416095972061
Loss at iteration 2300 : 0.010194703936576843
Loss at iteration 2310 : 0.009926507249474525
Loss at iteration 2320 : 0.006500978488475084
Loss at iteration 2330 : 0.010177419520914555
Loss at iteration 2340 : 0.008669428527355194
Loss at iteration 2350 : 0.009849924594163895
Loss at iteration 2360 : 0.005859962664544582
Loss at iteration 2370 : 0.017725665122270584
Loss at iteration 2380 : 0.00411536730825901
Loss at iteration 2390 : 0.009546974673867226
Loss at iteration 2400 : 0.003608180209994316
Loss at iteration 2410 : 0.009014362469315529
Loss at iteration 2420 : 0.006611774209886789
The SSIM Value is: 0.8414100011189779
The PSNR Value is: 22.24146048227946
the epoch is: 50
Loss at iteration 10 : 0.011876520700752735
Loss at iteration 20 : 0.005275425501167774
Loss at iteration 30 : 0.012109262868762016
Loss at iteration 40 : 0.012808759696781635
Loss at iteration 50 : 0.009758091531693935
Loss at iteration 60 : 0.009372454136610031
Loss at iteration 70 : 0.008923624642193317
Loss at iteration 80 : 0.008937752805650234
Loss at iteration 90 : 0.01772109605371952
Loss at iteration 100 : 0.008396193385124207
Loss at iteration 110 : 0.016430223360657692
Loss at iteration 120 : 0.010833672247827053
Loss at iteration 130 : 0.007302842102944851
Loss at iteration 140 : 0.016896188259124756
Loss at iteration 150 : 0.009503633715212345
Loss at iteration 160 : 0.00628502806648612
Loss at iteration 170 : 0.00632918206974864
Loss at iteration 180 : 0.014811146073043346
Loss at iteration 190 : 0.00965254008769989
Loss at iteration 200 : 0.014819452539086342
Loss at iteration 210 : 0.010564560070633888
Loss at iteration 220 : 0.007096334360539913
Loss at iteration 230 : 0.01104874350130558
Loss at iteration 240 : 0.011440170928835869
Loss at iteration 250 : 0.011506144888699055
Loss at iteration 260 : 0.010675706900656223
Loss at iteration 270 : 0.007157240994274616
Loss at iteration 280 : 0.008499366231262684
Loss at iteration 290 : 0.012567468918859959
Loss at iteration 300 : 0.006589196156710386
Loss at iteration 310 : 0.016776978969573975
Loss at iteration 320 : 0.014500260353088379
Loss at iteration 330 : 0.007030382286757231
Loss at iteration 340 : 0.0050983726978302
Loss at iteration 350 : 0.008882054127752781
Loss at iteration 360 : 0.010323114693164825
Loss at iteration 370 : 0.011326088570058346
Loss at iteration 380 : 0.021580921486020088
Loss at iteration 390 : 0.0024169080425053835
Loss at iteration 400 : 0.01091137807816267
Loss at iteration 410 : 0.006303607486188412
Loss at iteration 420 : 0.013709528371691704
Loss at iteration 430 : 0.011411427520215511
Loss at iteration 440 : 0.012908194214105606
Loss at iteration 450 : 0.007372068241238594
Loss at iteration 460 : 0.006937738042324781
Loss at iteration 470 : 0.012006268836557865
Loss at iteration 480 : 0.01656540296971798
Loss at iteration 490 : 0.010482080280780792
Loss at iteration 500 : 0.021008765324950218
Loss at iteration 510 : 0.02071864902973175
Loss at iteration 520 : 0.008397280238568783
Loss at iteration 530 : 0.008109653368592262
Loss at iteration 540 : 0.012274671345949173
Loss at iteration 550 : 0.009368713945150375
Loss at iteration 560 : 0.02114580199122429
Loss at iteration 570 : 0.017200782895088196
Loss at iteration 580 : 0.006241350434720516
Loss at iteration 590 : 0.004277704283595085
Loss at iteration 600 : 0.014651570469141006
Loss at iteration 610 : 0.008729896508157253
Loss at iteration 620 : 0.009118852205574512
Loss at iteration 630 : 0.007554004434496164
Loss at iteration 640 : 0.01266683079302311
Loss at iteration 650 : 0.008098272606730461
Loss at iteration 660 : 0.006397184915840626
Loss at iteration 670 : 0.005882658530026674
Loss at iteration 680 : 0.01005244255065918
Loss at iteration 690 : 0.008379869163036346
Loss at iteration 700 : 0.00773264653980732
Loss at iteration 710 : 0.011767566204071045
Loss at iteration 720 : 0.009131304919719696
Loss at iteration 730 : 0.01887533813714981
Loss at iteration 740 : 0.033314093947410583
Loss at iteration 750 : 0.015987716615200043
Loss at iteration 760 : 0.010084648616611958
Loss at iteration 770 : 0.010091007687151432
Loss at iteration 780 : 0.011765696108341217
Loss at iteration 790 : 0.012321479618549347
Loss at iteration 800 : 0.006787355523556471
Loss at iteration 810 : 0.008199996314942837
Loss at iteration 820 : 0.006434830836951733
Loss at iteration 830 : 0.007280812133103609
Loss at iteration 840 : 0.014167321845889091
Loss at iteration 850 : 0.010306233540177345
Loss at iteration 860 : 0.008254592306911945
Loss at iteration 870 : 0.01946738176047802
Loss at iteration 880 : 0.00973058957606554
Loss at iteration 890 : 0.0068488940596580505
Loss at iteration 900 : 0.015236815437674522
Loss at iteration 910 : 0.015823863446712494
Loss at iteration 920 : 0.00903669185936451
Loss at iteration 930 : 0.004190647974610329
Loss at iteration 940 : 0.007171970792114735
Loss at iteration 950 : 0.00789673626422882
Loss at iteration 960 : 0.011756647378206253
Loss at iteration 970 : 0.0055853333324193954
Loss at iteration 980 : 0.006945450324565172
Loss at iteration 990 : 0.004599819425493479
Loss at iteration 1000 : 0.009642970748245716
Loss at iteration 1010 : 0.016618814319372177
Loss at iteration 1020 : 0.007218522951006889
Loss at iteration 1030 : 0.008410920388996601
Loss at iteration 1040 : 0.003841397352516651
Loss at iteration 1050 : 0.00917761866003275
Loss at iteration 1060 : 0.008210275322198868
Loss at iteration 1070 : 0.010636377148330212
Loss at iteration 1080 : 0.011857409961521626
Loss at iteration 1090 : 0.010778187774121761
Loss at iteration 1100 : 0.005110323894768953
Loss at iteration 1110 : 0.010360918939113617
Loss at iteration 1120 : 0.015243282541632652
Loss at iteration 1130 : 0.006336061283946037
Loss at iteration 1140 : 0.012528259307146072
Loss at iteration 1150 : 0.008796721696853638
Loss at iteration 1160 : 0.019627884030342102
Loss at iteration 1170 : 0.007707762531936169
Loss at iteration 1180 : 0.006956685334444046
Loss at iteration 1190 : 0.007508858107030392
Loss at iteration 1200 : 0.006114238873124123
Loss at iteration 1210 : 0.013888467103242874
Loss at iteration 1220 : 0.015892010182142258
Loss at iteration 1230 : 0.008418130688369274
Loss at iteration 1240 : 0.008275783620774746
Loss at iteration 1250 : 0.007695414591580629
Loss at iteration 1260 : 0.007474291604012251
Loss at iteration 1270 : 0.009292198345065117
Loss at iteration 1280 : 0.005084650125354528
Loss at iteration 1290 : 0.005850295070558786
Loss at iteration 1300 : 0.003409909550100565
Loss at iteration 1310 : 0.004334207624197006
Loss at iteration 1320 : 0.010454450733959675
Loss at iteration 1330 : 0.016009267419576645
Loss at iteration 1340 : 0.006424931809306145
Loss at iteration 1350 : 0.019289862364530563
Loss at iteration 1360 : 0.003289798740297556
Loss at iteration 1370 : 0.010232623666524887
Loss at iteration 1380 : 0.010847755707800388
Loss at iteration 1390 : 0.010913996025919914
Loss at iteration 1400 : 0.0053698341362178326
Loss at iteration 1410 : 0.01898207701742649
Loss at iteration 1420 : 0.01017917599529028
Loss at iteration 1430 : 0.004852975718677044
Loss at iteration 1440 : 0.009960662573575974
Loss at iteration 1450 : 0.01201204489916563
Loss at iteration 1460 : 0.016799207776784897
Loss at iteration 1470 : 0.008674822747707367
Loss at iteration 1480 : 0.006109963171184063
Loss at iteration 1490 : 0.012287979945540428
Loss at iteration 1500 : 0.010355238802731037
Loss at iteration 1510 : 0.014067485928535461
Loss at iteration 1520 : 0.007098104804754257
Loss at iteration 1530 : 0.006402807310223579
Loss at iteration 1540 : 0.005858384072780609
Loss at iteration 1550 : 0.008464775048196316
Loss at iteration 1560 : 0.005848399363458157
Loss at iteration 1570 : 0.004754946567118168
Loss at iteration 1580 : 0.009050840511918068
Loss at iteration 1590 : 0.022819414734840393
Loss at iteration 1600 : 0.00884309783577919
Loss at iteration 1610 : 0.01834684982895851
Loss at iteration 1620 : 0.0077051762491464615
Loss at iteration 1630 : 0.008368141949176788
Loss at iteration 1640 : 0.006442129611968994
Loss at iteration 1650 : 0.008073686622083187
Loss at iteration 1660 : 0.0074276733212172985
Loss at iteration 1670 : 0.008402030915021896
Loss at iteration 1680 : 0.00760248489677906
Loss at iteration 1690 : 0.006681738421320915
Loss at iteration 1700 : 0.010942941531538963
Loss at iteration 1710 : 0.004447446204721928
Loss at iteration 1720 : 0.01340341754257679
Loss at iteration 1730 : 0.014407195150852203
Loss at iteration 1740 : 0.012732211500406265
Loss at iteration 1750 : 0.01898862048983574
Loss at iteration 1760 : 0.015207423828542233
Loss at iteration 1770 : 0.03629618138074875
Loss at iteration 1780 : 0.01407540775835514
Loss at iteration 1790 : 0.006519296206533909
Loss at iteration 1800 : 0.005743596237152815
Loss at iteration 1810 : 0.013167450204491615
Loss at iteration 1820 : 0.007277394644916058
Loss at iteration 1830 : 0.008929447270929813
Loss at iteration 1840 : 0.008202223107218742
Loss at iteration 1850 : 0.008208250626921654
Loss at iteration 1860 : 0.009464292787015438
Loss at iteration 1870 : 0.0052125416696071625
Loss at iteration 1880 : 0.004775487817823887
Loss at iteration 1890 : 0.011296486482024193
Loss at iteration 1900 : 0.02045302838087082
Loss at iteration 1910 : 0.014012149535119534
Loss at iteration 1920 : 0.004478792194277048
Loss at iteration 1930 : 0.018099766224622726
Loss at iteration 1940 : 0.00913932453840971
Loss at iteration 1950 : 0.013333410024642944
Loss at iteration 1960 : 0.018532590940594673
Loss at iteration 1970 : 0.009076733142137527
Loss at iteration 1980 : 0.011489138007164001
Loss at iteration 1990 : 0.013759110122919083
Loss at iteration 2000 : 0.01554509811103344
Loss at iteration 2010 : 0.01729249767959118
Loss at iteration 2020 : 0.01454904768615961
Loss at iteration 2030 : 0.010056985542178154
Loss at iteration 2040 : 0.01710245944559574
Loss at iteration 2050 : 0.006682688370347023
Loss at iteration 2060 : 0.007089347578585148
Loss at iteration 2070 : 0.006278245709836483
Loss at iteration 2080 : 0.008383006788790226
Loss at iteration 2090 : 0.0090983547270298
Loss at iteration 2100 : 0.017357168719172478
Loss at iteration 2110 : 0.011452656239271164
Loss at iteration 2120 : 0.0073534660041332245
Loss at iteration 2130 : 0.008219840005040169
Loss at iteration 2140 : 0.009900597855448723
Loss at iteration 2150 : 0.009078575298190117
Loss at iteration 2160 : 0.004745370242744684
Loss at iteration 2170 : 0.006574469618499279
Loss at iteration 2180 : 0.013891642913222313
Loss at iteration 2190 : 0.007360590621829033
Loss at iteration 2200 : 0.01863647811114788
Loss at iteration 2210 : 0.005317211151123047
Loss at iteration 2220 : 0.008448069915175438
Loss at iteration 2230 : 0.010531309992074966
Loss at iteration 2240 : 0.004001663066446781
Loss at iteration 2250 : 0.007791087031364441
Loss at iteration 2260 : 0.007354029454290867
Loss at iteration 2270 : 0.007617463357746601
Loss at iteration 2280 : 0.006394756957888603
Loss at iteration 2290 : 0.012853304855525494
Loss at iteration 2300 : 0.012922201305627823
Loss at iteration 2310 : 0.008314806967973709
Loss at iteration 2320 : 0.0054044052958488464
Loss at iteration 2330 : 0.010340690612792969
Loss at iteration 2340 : 0.014610325917601585
Loss at iteration 2350 : 0.012956688180565834
Loss at iteration 2360 : 0.008977241814136505
Loss at iteration 2370 : 0.013191238045692444
Loss at iteration 2380 : 0.012578398920595646
Loss at iteration 2390 : 0.01235475204885006
Loss at iteration 2400 : 0.005622485652565956
Loss at iteration 2410 : 0.004955916199833155
Loss at iteration 2420 : 0.014735419303178787
The SSIM Value is: 0.8451624552408854
The PSNR Value is: 22.330757077534994
the epoch is: 51
Loss at iteration 10 : 0.009398111142218113
Loss at iteration 20 : 0.011298075318336487
Loss at iteration 30 : 0.00365309976041317
Loss at iteration 40 : 0.011619754135608673
Loss at iteration 50 : 0.010695118457078934
Loss at iteration 60 : 0.00878707692027092
Loss at iteration 70 : 0.003127632662653923
Loss at iteration 80 : 0.004353461321443319
Loss at iteration 90 : 0.01570875570178032
Loss at iteration 100 : 0.018598489463329315
Loss at iteration 110 : 0.006972813978791237
Loss at iteration 120 : 0.015423203818500042
Loss at iteration 130 : 0.009136943146586418
Loss at iteration 140 : 0.006928643211722374
Loss at iteration 150 : 0.04091745615005493
Loss at iteration 160 : 0.015389764681458473
Loss at iteration 170 : 0.012144668027758598
Loss at iteration 180 : 0.006598498206585646
Loss at iteration 190 : 0.009523216634988785
Loss at iteration 200 : 0.014029300771653652
Loss at iteration 210 : 0.007668099366128445
Loss at iteration 220 : 0.006109773181378841
Loss at iteration 230 : 0.0064142486080527306
Loss at iteration 240 : 0.007869979366660118
Loss at iteration 250 : 0.013376053422689438
Loss at iteration 260 : 0.017627861350774765
Loss at iteration 270 : 0.008632407523691654
Loss at iteration 280 : 0.008225766941905022
Loss at iteration 290 : 0.01140024233609438
Loss at iteration 300 : 0.0075797890312969685
Loss at iteration 310 : 0.010014582425355911
Loss at iteration 320 : 0.015973830595612526
Loss at iteration 330 : 0.009189615026116371
Loss at iteration 340 : 0.023070909082889557
Loss at iteration 350 : 0.009526509791612625
Loss at iteration 360 : 0.011721370741724968
Loss at iteration 370 : 0.008614055812358856
Loss at iteration 380 : 0.009567337110638618
Loss at iteration 390 : 0.01393734011799097
Loss at iteration 400 : 0.007134380750358105
Loss at iteration 410 : 0.007613237947225571
Loss at iteration 420 : 0.00561871100217104
Loss at iteration 430 : 0.013640360906720161
Loss at iteration 440 : 0.00416706595569849
Loss at iteration 450 : 0.005996362306177616
Loss at iteration 460 : 0.018134530633687973
Loss at iteration 470 : 0.008652270771563053
Loss at iteration 480 : 0.013692570850253105
Loss at iteration 490 : 0.010118646547198296
Loss at iteration 500 : 0.006189578212797642
Loss at iteration 510 : 0.009070133790373802
Loss at iteration 520 : 0.024551793932914734
Loss at iteration 530 : 0.004463570658117533
Loss at iteration 540 : 0.01946696639060974
Loss at iteration 550 : 0.009440528228878975
Loss at iteration 560 : 0.008866420015692711
Loss at iteration 570 : 0.005684803240001202
Loss at iteration 580 : 0.007062916178256273
Loss at iteration 590 : 0.007096069864928722
Loss at iteration 600 : 0.010361927561461926
Loss at iteration 610 : 0.013853661715984344
Loss at iteration 620 : 0.007498089224100113
Loss at iteration 630 : 0.0072247907519340515
Loss at iteration 640 : 0.007475247606635094
Loss at iteration 650 : 0.013766763731837273
Loss at iteration 660 : 0.013372266665101051
Loss at iteration 670 : 0.005637495778501034
Loss at iteration 680 : 0.008348505944013596
Loss at iteration 690 : 0.008957792073488235
Loss at iteration 700 : 0.009649030864238739
Loss at iteration 710 : 0.009351706132292747
Loss at iteration 720 : 0.006900849286466837
Loss at iteration 730 : 0.011110888794064522
Loss at iteration 740 : 0.013854987919330597
Loss at iteration 750 : 0.009012431837618351
Loss at iteration 760 : 0.01440434530377388
Loss at iteration 770 : 0.012938815169036388
Loss at iteration 780 : 0.0049166325479745865
Loss at iteration 790 : 0.010281328111886978
Loss at iteration 800 : 0.015249112620949745
Loss at iteration 810 : 0.015221133828163147
Loss at iteration 820 : 0.006112370174378157
Loss at iteration 830 : 0.016973827034235
Loss at iteration 840 : 0.003018386196345091
Loss at iteration 850 : 0.005930556915700436
Loss at iteration 860 : 0.011482992209494114
Loss at iteration 870 : 0.0054952604696154594
Loss at iteration 880 : 0.006575099658221006
Loss at iteration 890 : 0.005571594927459955
Loss at iteration 900 : 0.026896532624959946
Loss at iteration 910 : 0.012661131098866463
Loss at iteration 920 : 0.006629561074078083
Loss at iteration 930 : 0.004109250381588936
Loss at iteration 940 : 0.00949915498495102
Loss at iteration 950 : 0.011945961974561214
Loss at iteration 960 : 0.008496006950736046
Loss at iteration 970 : 0.01351337879896164
Loss at iteration 980 : 0.008388648740947247
Loss at iteration 990 : 0.004441644065082073
Loss at iteration 1000 : 0.012447291985154152
Loss at iteration 1010 : 0.0052506085485219955
Loss at iteration 1020 : 0.012891439720988274
Loss at iteration 1030 : 0.01883404329419136
Loss at iteration 1040 : 0.007786254398524761
Loss at iteration 1050 : 0.007001075427979231
Loss at iteration 1060 : 0.007207195274531841
Loss at iteration 1070 : 0.00616088742390275
Loss at iteration 1080 : 0.005515809170901775
Loss at iteration 1090 : 0.011758532375097275
Loss at iteration 1100 : 0.010345758870244026
Loss at iteration 1110 : 0.011433405801653862
Loss at iteration 1120 : 0.010300745256245136
Loss at iteration 1130 : 0.0072076632641255856
Loss at iteration 1140 : 0.013640735298395157
Loss at iteration 1150 : 0.005111947655677795
Loss at iteration 1160 : 0.009479111060500145
Loss at iteration 1170 : 0.013262227177619934
Loss at iteration 1180 : 0.005697914864867926
Loss at iteration 1190 : 0.007486842572689056
Loss at iteration 1200 : 0.016410833224654198
Loss at iteration 1210 : 0.00386769394390285
Loss at iteration 1220 : 0.0061864242888987064
Loss at iteration 1230 : 0.011501407250761986
Loss at iteration 1240 : 0.011683458462357521
Loss at iteration 1250 : 0.012612652964890003
Loss at iteration 1260 : 0.01978212222456932
Loss at iteration 1270 : 0.0060358112677931786
Loss at iteration 1280 : 0.010923074558377266
Loss at iteration 1290 : 0.011363772675395012
Loss at iteration 1300 : 0.0127386674284935
Loss at iteration 1310 : 0.007379584480077028
Loss at iteration 1320 : 0.013406813144683838
Loss at iteration 1330 : 0.015448609367012978
Loss at iteration 1340 : 0.009727146476507187
Loss at iteration 1350 : 0.01108996570110321
Loss at iteration 1360 : 0.0148371746763587
Loss at iteration 1370 : 0.011646559461951256
Loss at iteration 1380 : 0.009553123265504837
Loss at iteration 1390 : 0.004172811284661293
Loss at iteration 1400 : 0.006783461198210716
Loss at iteration 1410 : 0.00969864521175623
Loss at iteration 1420 : 0.008525285869836807
Loss at iteration 1430 : 0.006866260431706905
Loss at iteration 1440 : 0.017216669395565987
Loss at iteration 1450 : 0.020811639726161957
Loss at iteration 1460 : 0.00883152149617672
Loss at iteration 1470 : 0.0033418850507587194
Loss at iteration 1480 : 0.009836295619606972
Loss at iteration 1490 : 0.009045678190886974
Loss at iteration 1500 : 0.014279274269938469
Loss at iteration 1510 : 0.00905428547412157
Loss at iteration 1520 : 0.00511035043746233
Loss at iteration 1530 : 0.007689759135246277
Loss at iteration 1540 : 0.006512521766126156
Loss at iteration 1550 : 0.012880217283964157
Loss at iteration 1560 : 0.006901677697896957
Loss at iteration 1570 : 0.013545418158173561
Loss at iteration 1580 : 0.011314616538584232
Loss at iteration 1590 : 0.006255290471017361
Loss at iteration 1600 : 0.026210539042949677
Loss at iteration 1610 : 0.013376682996749878
Loss at iteration 1620 : 0.013156009837985039
Loss at iteration 1630 : 0.015331369824707508
Loss at iteration 1640 : 0.012210091575980186
Loss at iteration 1650 : 0.009227093309164047
Loss at iteration 1660 : 0.016052739694714546
Loss at iteration 1670 : 0.007666347548365593
Loss at iteration 1680 : 0.010270272381603718
Loss at iteration 1690 : 0.012949371710419655
Loss at iteration 1700 : 0.009300620295107365
Loss at iteration 1710 : 0.020282093435525894
Loss at iteration 1720 : 0.003777542384341359
Loss at iteration 1730 : 0.006381948944181204
Loss at iteration 1740 : 0.0048654405400156975
Loss at iteration 1750 : 0.005939028225839138
Loss at iteration 1760 : 0.007275565527379513
Loss at iteration 1770 : 0.019840562716126442
Loss at iteration 1780 : 0.004912570118904114
Loss at iteration 1790 : 0.009508712217211723
Loss at iteration 1800 : 0.021918218582868576
Loss at iteration 1810 : 0.00989155936986208
Loss at iteration 1820 : 0.011137418448925018
Loss at iteration 1830 : 0.013126138597726822
Loss at iteration 1840 : 0.011732954531908035
Loss at iteration 1850 : 0.010894576087594032
Loss at iteration 1860 : 0.022153444588184357
Loss at iteration 1870 : 0.007236158475279808
Loss at iteration 1880 : 0.0184222012758255
Loss at iteration 1890 : 0.009537204168736935
Loss at iteration 1900 : 0.0033819295931607485
Loss at iteration 1910 : 0.012518048286437988
Loss at iteration 1920 : 0.015174627304077148
Loss at iteration 1930 : 0.0242720078676939
Loss at iteration 1940 : 0.0043602604418993
Loss at iteration 1950 : 0.014365723356604576
Loss at iteration 1960 : 0.00723292026668787
Loss at iteration 1970 : 0.008709371089935303
Loss at iteration 1980 : 0.010573942214250565
Loss at iteration 1990 : 0.008723095059394836
Loss at iteration 2000 : 0.020955435931682587
Loss at iteration 2010 : 0.010932279750704765
Loss at iteration 2020 : 0.012471259571611881
Loss at iteration 2030 : 0.008508197963237762
Loss at iteration 2040 : 0.0093231201171875
Loss at iteration 2050 : 0.007158402353525162
Loss at iteration 2060 : 0.018328379839658737
Loss at iteration 2070 : 0.012980829924345016
Loss at iteration 2080 : 0.014529766514897346
Loss at iteration 2090 : 0.0071036978624761105
Loss at iteration 2100 : 0.008110566064715385
Loss at iteration 2110 : 0.01049032248556614
Loss at iteration 2120 : 0.007713432889431715
Loss at iteration 2130 : 0.012338726781308651
Loss at iteration 2140 : 0.021526765078306198
Loss at iteration 2150 : 0.024240300059318542
Loss at iteration 2160 : 0.00948318187147379
Loss at iteration 2170 : 0.009696466848254204
Loss at iteration 2180 : 0.012177661061286926
Loss at iteration 2190 : 0.007893884554505348
Loss at iteration 2200 : 0.0102218734100461
Loss at iteration 2210 : 0.007214542478322983
Loss at iteration 2220 : 0.012126190587878227
Loss at iteration 2230 : 0.009589087218046188
Loss at iteration 2240 : 0.008406853303313255
Loss at iteration 2250 : 0.010178901255130768
Loss at iteration 2260 : 0.005311115179210901
Loss at iteration 2270 : 0.008083507418632507
Loss at iteration 2280 : 0.005140009336173534
Loss at iteration 2290 : 0.01377501618117094
Loss at iteration 2300 : 0.01169152557849884
Loss at iteration 2310 : 0.014196755364537239
Loss at iteration 2320 : 0.009494664147496223
Loss at iteration 2330 : 0.032756660133600235
Loss at iteration 2340 : 0.030453942716121674
Loss at iteration 2350 : 0.010417113080620766
Loss at iteration 2360 : 0.017089713364839554
Loss at iteration 2370 : 0.013083898462355137
Loss at iteration 2380 : 0.01073492132127285
Loss at iteration 2390 : 0.005737886764109135
Loss at iteration 2400 : 0.01802397333085537
Loss at iteration 2410 : 0.02016506902873516
Loss at iteration 2420 : 0.007068315055221319
The SSIM Value is: 0.8392049471537272
The PSNR Value is: 21.527503458658853
the epoch is: 52
Loss at iteration 10 : 0.009317537769675255
Loss at iteration 20 : 0.01652197726070881
Loss at iteration 30 : 0.011050995439291
Loss at iteration 40 : 0.009028004482388496
Loss at iteration 50 : 0.006762327626347542
Loss at iteration 60 : 0.004997369833290577
Loss at iteration 70 : 0.007773912511765957
Loss at iteration 80 : 0.012502948753535748
Loss at iteration 90 : 0.013444395735859871
Loss at iteration 100 : 0.004867780487984419
Loss at iteration 110 : 0.011377486400306225
Loss at iteration 120 : 0.006036869250237942
Loss at iteration 130 : 0.014079343527555466
Loss at iteration 140 : 0.014697637408971786
Loss at iteration 150 : 0.015956101939082146
Loss at iteration 160 : 0.012845507822930813
Loss at iteration 170 : 0.0066185081377625465
Loss at iteration 180 : 0.011058071628212929
Loss at iteration 190 : 0.018713943660259247
Loss at iteration 200 : 0.006982746999710798
Loss at iteration 210 : 0.015799440443515778
Loss at iteration 220 : 0.013870018534362316
Loss at iteration 230 : 0.012696651741862297
Loss at iteration 240 : 0.01600596308708191
Loss at iteration 250 : 0.009113825857639313
Loss at iteration 260 : 0.010175518691539764
Loss at iteration 270 : 0.006136460695415735
Loss at iteration 280 : 0.006988700944930315
Loss at iteration 290 : 0.01667078770697117
Loss at iteration 300 : 0.005825419444590807
Loss at iteration 310 : 0.008481071330606937
Loss at iteration 320 : 0.01103813387453556
Loss at iteration 330 : 0.010776563547551632
Loss at iteration 340 : 0.008281653746962547
Loss at iteration 350 : 0.012196499854326248
Loss at iteration 360 : 0.025430846959352493
Loss at iteration 370 : 0.0031281406991183758
Loss at iteration 380 : 0.01055949181318283
Loss at iteration 390 : 0.016398606821894646
Loss at iteration 400 : 0.005378312431275845
Loss at iteration 410 : 0.006432081572711468
Loss at iteration 420 : 0.014026720076799393
Loss at iteration 430 : 0.010962062515318394
Loss at iteration 440 : 0.021662713959813118
Loss at iteration 450 : 0.007216031663119793
Loss at iteration 460 : 0.008969370275735855
Loss at iteration 470 : 0.009751947596669197
Loss at iteration 480 : 0.008612418547272682
Loss at iteration 490 : 0.0047799376770854
Loss at iteration 500 : 0.006699551362544298
Loss at iteration 510 : 0.009055636823177338
Loss at iteration 520 : 0.008455302566289902
Loss at iteration 530 : 0.011521206237375736
Loss at iteration 540 : 0.014814716763794422
Loss at iteration 550 : 0.008946619927883148
Loss at iteration 560 : 0.006438180338591337
Loss at iteration 570 : 0.004541777074337006
Loss at iteration 580 : 0.01207774132490158
Loss at iteration 590 : 0.017940949648618698
Loss at iteration 600 : 0.007949231192469597
Loss at iteration 610 : 0.007835394702851772
Loss at iteration 620 : 0.015683865174651146
Loss at iteration 630 : 0.006039400584995747
Loss at iteration 640 : 0.01194822695106268
Loss at iteration 650 : 0.012683250941336155
Loss at iteration 660 : 0.010339371860027313
Loss at iteration 670 : 0.010282780975103378
Loss at iteration 680 : 0.010741857811808586
Loss at iteration 690 : 0.010084405541419983
Loss at iteration 700 : 0.007344427518546581
Loss at iteration 710 : 0.011626873165369034
Loss at iteration 720 : 0.012775376439094543
Loss at iteration 730 : 0.011112728156149387
Loss at iteration 740 : 0.006943337619304657
Loss at iteration 750 : 0.007316647097468376
Loss at iteration 760 : 0.00863070972263813
Loss at iteration 770 : 0.015913499519228935
Loss at iteration 780 : 0.011051388457417488
Loss at iteration 790 : 0.008035277016460896
Loss at iteration 800 : 0.007707411423325539
Loss at iteration 810 : 0.010961562395095825
Loss at iteration 820 : 0.012795310467481613
Loss at iteration 830 : 0.013361958786845207
Loss at iteration 840 : 0.0038292966783046722
Loss at iteration 850 : 0.006966392509639263
Loss at iteration 860 : 0.004382478538900614
Loss at iteration 870 : 0.014857502654194832
Loss at iteration 880 : 0.011409027501940727
Loss at iteration 890 : 0.007145868614315987
Loss at iteration 900 : 0.006105266511440277
Loss at iteration 910 : 0.0070985229685902596
Loss at iteration 920 : 0.008843686431646347
Loss at iteration 930 : 0.009288361296057701
Loss at iteration 940 : 0.010447870008647442
Loss at iteration 950 : 0.007160793989896774
Loss at iteration 960 : 0.004872104153037071
Loss at iteration 970 : 0.01015429012477398
Loss at iteration 980 : 0.008947709575295448
Loss at iteration 990 : 0.00752181326970458
Loss at iteration 1000 : 0.002415277063846588
Loss at iteration 1010 : 0.01738280989229679
Loss at iteration 1020 : 0.013763531111180782
Loss at iteration 1030 : 0.00898855458945036
Loss at iteration 1040 : 0.007006098981946707
Loss at iteration 1050 : 0.008443253114819527
Loss at iteration 1060 : 0.007383182179182768
Loss at iteration 1070 : 0.00855634268373251
Loss at iteration 1080 : 0.012469792738556862
Loss at iteration 1090 : 0.008244486525654793
Loss at iteration 1100 : 0.008878074586391449
Loss at iteration 1110 : 0.010345946066081524
Loss at iteration 1120 : 0.007957755587995052
Loss at iteration 1130 : 0.00475657731294632
Loss at iteration 1140 : 0.008040787652134895
Loss at iteration 1150 : 0.011762181296944618
Loss at iteration 1160 : 0.019700929522514343
Loss at iteration 1170 : 0.009696448221802711
Loss at iteration 1180 : 0.01255663949996233
Loss at iteration 1190 : 0.008272029459476471
Loss at iteration 1200 : 0.016072306782007217
Loss at iteration 1210 : 0.011874949559569359
Loss at iteration 1220 : 0.003920142073184252
Loss at iteration 1230 : 0.006918573752045631
Loss at iteration 1240 : 0.01246480830013752
Loss at iteration 1250 : 0.013353321701288223
Loss at iteration 1260 : 0.016917496919631958
Loss at iteration 1270 : 0.008154223673045635
Loss at iteration 1280 : 0.0048836395144462585
Loss at iteration 1290 : 0.006641819141805172
Loss at iteration 1300 : 0.008349348790943623
Loss at iteration 1310 : 0.008702486753463745
Loss at iteration 1320 : 0.012629086151719093
Loss at iteration 1330 : 0.007931707426905632
Loss at iteration 1340 : 0.0038539916276931763
Loss at iteration 1350 : 0.017114980146288872
Loss at iteration 1360 : 0.012526432052254677
Loss at iteration 1370 : 0.00826757587492466
Loss at iteration 1380 : 0.018964029848575592
Loss at iteration 1390 : 0.01235030684620142
Loss at iteration 1400 : 0.010529006831347942
Loss at iteration 1410 : 0.012690376490354538
Loss at iteration 1420 : 0.01064806804060936
Loss at iteration 1430 : 0.016190679743885994
Loss at iteration 1440 : 0.01399298571050167
Loss at iteration 1450 : 0.008487394079566002
Loss at iteration 1460 : 0.010077026672661304
Loss at iteration 1470 : 0.016238059848546982
Loss at iteration 1480 : 0.00956711731851101
Loss at iteration 1490 : 0.00893988274037838
Loss at iteration 1500 : 0.008916839957237244
Loss at iteration 1510 : 0.0078070503659546375
Loss at iteration 1520 : 0.004926776979118586
Loss at iteration 1530 : 0.012399179860949516
Loss at iteration 1540 : 0.007521674036979675
Loss at iteration 1550 : 0.008888187818229198
Loss at iteration 1560 : 0.009446537122130394
Loss at iteration 1570 : 0.015466371551156044
Loss at iteration 1580 : 0.009020302444696426
Loss at iteration 1590 : 0.011942812241613865
Loss at iteration 1600 : 0.019128333777189255
Loss at iteration 1610 : 0.007075553759932518
Loss at iteration 1620 : 0.006668680347502232
Loss at iteration 1630 : 0.011271188035607338
Loss at iteration 1640 : 0.00501001812517643
Loss at iteration 1650 : 0.011570575647056103
Loss at iteration 1660 : 0.009183489717543125
Loss at iteration 1670 : 0.011441287584602833
Loss at iteration 1680 : 0.009729484096169472
Loss at iteration 1690 : 0.007849402725696564
Loss at iteration 1700 : 0.008160971105098724
Loss at iteration 1710 : 0.008935874328017235
Loss at iteration 1720 : 0.004994872957468033
Loss at iteration 1730 : 0.017901059240102768
Loss at iteration 1740 : 0.012029333040118217
Loss at iteration 1750 : 0.008437973447144032
Loss at iteration 1760 : 0.004831144120544195
Loss at iteration 1770 : 0.013252317905426025
Loss at iteration 1780 : 0.01610509492456913
Loss at iteration 1790 : 0.006913175340741873
Loss at iteration 1800 : 0.011310605332255363
Loss at iteration 1810 : 0.007009124383330345
Loss at iteration 1820 : 0.004214201122522354
Loss at iteration 1830 : 0.008776839822530746
Loss at iteration 1840 : 0.009714039042592049
Loss at iteration 1850 : 0.014494321309030056
Loss at iteration 1860 : 0.005383931566029787
Loss at iteration 1870 : 0.006424447521567345
Loss at iteration 1880 : 0.008587713353335857
Loss at iteration 1890 : 0.0064965952187776566
Loss at iteration 1900 : 0.009356774389743805
Loss at iteration 1910 : 0.012235475704073906
Loss at iteration 1920 : 0.018186811357736588
Loss at iteration 1930 : 0.009628340601921082
Loss at iteration 1940 : 0.011451760306954384
Loss at iteration 1950 : 0.009144571609795094
Loss at iteration 1960 : 0.015745334327220917
Loss at iteration 1970 : 0.006069136783480644
Loss at iteration 1980 : 0.015599209815263748
Loss at iteration 1990 : 0.010310101322829723
Loss at iteration 2000 : 0.010671159252524376
Loss at iteration 2010 : 0.005580182187259197
Loss at iteration 2020 : 0.011671790853142738
Loss at iteration 2030 : 0.010611988604068756
Loss at iteration 2040 : 0.004723755642771721
Loss at iteration 2050 : 0.007112707942724228
Loss at iteration 2060 : 0.012227101251482964
Loss at iteration 2070 : 0.011510615237057209
Loss at iteration 2080 : 0.013387704268097878
Loss at iteration 2090 : 0.0072145527228713036
Loss at iteration 2100 : 0.004279423505067825
Loss at iteration 2110 : 0.009224269539117813
Loss at iteration 2120 : 0.012601406313478947
Loss at iteration 2130 : 0.01621808297932148
Loss at iteration 2140 : 0.005963060073554516
Loss at iteration 2150 : 0.01515189092606306
Loss at iteration 2160 : 0.01928986981511116
Loss at iteration 2170 : 0.009779020212590694
Loss at iteration 2180 : 0.012858711183071136
Loss at iteration 2190 : 0.013857437297701836
Loss at iteration 2200 : 0.016300415620207787
Loss at iteration 2210 : 0.012869282625615597
Loss at iteration 2220 : 0.004885287489742041
Loss at iteration 2230 : 0.004647810012102127
Loss at iteration 2240 : 0.011146493256092072
Loss at iteration 2250 : 0.01295818854123354
Loss at iteration 2260 : 0.006826316472142935
Loss at iteration 2270 : 0.008809329941868782
Loss at iteration 2280 : 0.016595255583524704
Loss at iteration 2290 : 0.007232155650854111
Loss at iteration 2300 : 0.01036352664232254
Loss at iteration 2310 : 0.010065106675028801
Loss at iteration 2320 : 0.006458683870732784
Loss at iteration 2330 : 0.011073742993175983
Loss at iteration 2340 : 0.006531069986522198
Loss at iteration 2350 : 0.0027490216307342052
Loss at iteration 2360 : 0.007614615373313427
Loss at iteration 2370 : 0.017905863001942635
Loss at iteration 2380 : 0.02368902415037155
Loss at iteration 2390 : 0.008898483589291573
Loss at iteration 2400 : 0.01785237342119217
Loss at iteration 2410 : 0.0027257194742560387
Loss at iteration 2420 : 0.0027916296385228634
The SSIM Value is: 0.8418166319529216
The PSNR Value is: 21.568385950724284
the epoch is: 53
Loss at iteration 10 : 0.007492187432944775
Loss at iteration 20 : 0.012430720031261444
Loss at iteration 30 : 0.010862995870411396
Loss at iteration 40 : 0.012213768437504768
Loss at iteration 50 : 0.006649747025221586
Loss at iteration 60 : 0.008225012570619583
Loss at iteration 70 : 0.010730673559010029
Loss at iteration 80 : 0.016227837651968002
Loss at iteration 90 : 0.008173227310180664
Loss at iteration 100 : 0.008302916772663593
Loss at iteration 110 : 0.022457830607891083
Loss at iteration 120 : 0.009920943528413773
Loss at iteration 130 : 0.007766874507069588
Loss at iteration 140 : 0.012628922238945961
Loss at iteration 150 : 0.009057829156517982
Loss at iteration 160 : 0.008566433563828468
Loss at iteration 170 : 0.004028741270303726
Loss at iteration 180 : 0.011476710438728333
Loss at iteration 190 : 0.007537185214459896
Loss at iteration 200 : 0.004869070835411549
Loss at iteration 210 : 0.008602453395724297
Loss at iteration 220 : 0.007647236343473196
Loss at iteration 230 : 0.014405063353478909
Loss at iteration 240 : 0.0025898669846355915
Loss at iteration 250 : 0.0063108522444963455
Loss at iteration 260 : 0.0065606739372015
Loss at iteration 270 : 0.01121344231069088
Loss at iteration 280 : 0.008795558474957943
Loss at iteration 290 : 0.01000894233584404
Loss at iteration 300 : 0.013666590675711632
Loss at iteration 310 : 0.007074862252920866
Loss at iteration 320 : 0.0053152660839259624
Loss at iteration 330 : 0.01669744960963726
Loss at iteration 340 : 0.012246210128068924
Loss at iteration 350 : 0.007272323127835989
Loss at iteration 360 : 0.006312099285423756
Loss at iteration 370 : 0.010953409597277641
Loss at iteration 380 : 0.007372144144028425
Loss at iteration 390 : 0.007085083983838558
Loss at iteration 400 : 0.014307118952274323
Loss at iteration 410 : 0.004433901980519295
Loss at iteration 420 : 0.006274042651057243
Loss at iteration 430 : 0.009764507412910461
Loss at iteration 440 : 0.008213666267693043
Loss at iteration 450 : 0.008583166636526585
Loss at iteration 460 : 0.012860557064414024
Loss at iteration 470 : 0.003847662825137377
Loss at iteration 480 : 0.009502232074737549
Loss at iteration 490 : 0.004669974558055401
Loss at iteration 500 : 0.008187366649508476
Loss at iteration 510 : 0.015469870530068874
Loss at iteration 520 : 0.011348173022270203
Loss at iteration 530 : 0.008249105885624886
Loss at iteration 540 : 0.006277264095842838
Loss at iteration 550 : 0.005815960466861725
Loss at iteration 560 : 0.014105964452028275
Loss at iteration 570 : 0.011592136695981026
Loss at iteration 580 : 0.011712401174008846
Loss at iteration 590 : 0.009755974635481834
Loss at iteration 600 : 0.008234934881329536
Loss at iteration 610 : 0.007369699887931347
Loss at iteration 620 : 0.01517082192003727
Loss at iteration 630 : 0.007672963663935661
Loss at iteration 640 : 0.015536573715507984
Loss at iteration 650 : 0.012014755979180336
Loss at iteration 660 : 0.017885910347104073
Loss at iteration 670 : 0.0031437298748642206
Loss at iteration 680 : 0.008214827626943588
Loss at iteration 690 : 0.013340592384338379
Loss at iteration 700 : 0.01778258942067623
Loss at iteration 710 : 0.00933120772242546
Loss at iteration 720 : 0.010479236952960491
Loss at iteration 730 : 0.004075069446116686
Loss at iteration 740 : 0.013738883659243584
Loss at iteration 750 : 0.01733020879328251
Loss at iteration 760 : 0.009901768527925014
Loss at iteration 770 : 0.010155592113733292
Loss at iteration 780 : 0.015596828423440456
Loss at iteration 790 : 0.012397067621350288
Loss at iteration 800 : 0.018232030794024467
Loss at iteration 810 : 0.011127570644021034
Loss at iteration 820 : 0.005329816602170467
Loss at iteration 830 : 0.01790495589375496
Loss at iteration 840 : 0.01051920372992754
Loss at iteration 850 : 0.00655386783182621
Loss at iteration 860 : 0.009535465389490128
Loss at iteration 870 : 0.0111517533659935
Loss at iteration 880 : 0.012921984307467937
Loss at iteration 890 : 0.002616212470456958
Loss at iteration 900 : 0.0051117572002112865
Loss at iteration 910 : 0.010398264043033123
Loss at iteration 920 : 0.013110168278217316
Loss at iteration 930 : 0.008233203552663326
Loss at iteration 940 : 0.0130387581884861
Loss at iteration 950 : 0.0074152047745883465
Loss at iteration 960 : 0.013146495446562767
Loss at iteration 970 : 0.0100497892126441
Loss at iteration 980 : 0.006155252922326326
Loss at iteration 990 : 0.005626361817121506
Loss at iteration 1000 : 0.018046488985419273
Loss at iteration 1010 : 0.005519258789718151
Loss at iteration 1020 : 0.006088211201131344
Loss at iteration 1030 : 0.009365877136588097
Loss at iteration 1040 : 0.016557876020669937
Loss at iteration 1050 : 0.017710436135530472
Loss at iteration 1060 : 0.008447567000985146
Loss at iteration 1070 : 0.010009021498262882
Loss at iteration 1080 : 0.010246457532048225
Loss at iteration 1090 : 0.013816149905323982
Loss at iteration 1100 : 0.01664874702692032
Loss at iteration 1110 : 0.006044769659638405
Loss at iteration 1120 : 0.012143110856413841
Loss at iteration 1130 : 0.012285588309168816
Loss at iteration 1140 : 0.015921909362077713
Loss at iteration 1150 : 0.008800532668828964
Loss at iteration 1160 : 0.014413345605134964
Loss at iteration 1170 : 0.011057306081056595
Loss at iteration 1180 : 0.017558224499225616
Loss at iteration 1190 : 0.014730848371982574
Loss at iteration 1200 : 0.007913803681731224
Loss at iteration 1210 : 0.010213048197329044
Loss at iteration 1220 : 0.006213837303221226
Loss at iteration 1230 : 0.015708232298493385
Loss at iteration 1240 : 0.010219510644674301
Loss at iteration 1250 : 0.00629096943885088
Loss at iteration 1260 : 0.008098877966403961
Loss at iteration 1270 : 0.005475438665598631
Loss at iteration 1280 : 0.01651448756456375
Loss at iteration 1290 : 0.01291248295456171
Loss at iteration 1300 : 0.008817341178655624
Loss at iteration 1310 : 0.025236105546355247
Loss at iteration 1320 : 0.009089451283216476
Loss at iteration 1330 : 0.011325628496706486
Loss at iteration 1340 : 0.008022794499993324
Loss at iteration 1350 : 0.008623909205198288
Loss at iteration 1360 : 0.009238582104444504
Loss at iteration 1370 : 0.011292599141597748
Loss at iteration 1380 : 0.005560924764722586
Loss at iteration 1390 : 0.010458886623382568
Loss at iteration 1400 : 0.007244590204209089
Loss at iteration 1410 : 0.006216594483703375
Loss at iteration 1420 : 0.009548758156597614
Loss at iteration 1430 : 0.0045733097940683365
Loss at iteration 1440 : 0.005470214877277613
Loss at iteration 1450 : 0.008168134838342667
Loss at iteration 1460 : 0.0021403678692877293
Loss at iteration 1470 : 0.02257552370429039
Loss at iteration 1480 : 0.01246574241667986
Loss at iteration 1490 : 0.009326993487775326
Loss at iteration 1500 : 0.0042045991867780685
Loss at iteration 1510 : 0.00776279903948307
Loss at iteration 1520 : 0.010472312569618225
Loss at iteration 1530 : 0.009577483870089054
Loss at iteration 1540 : 0.006509472616016865
Loss at iteration 1550 : 0.013715331442654133
Loss at iteration 1560 : 0.009254725649952888
Loss at iteration 1570 : 0.01587708853185177
Loss at iteration 1580 : 0.013562696054577827
Loss at iteration 1590 : 0.018626919016242027
Loss at iteration 1600 : 0.00621764874085784
Loss at iteration 1610 : 0.010340447537600994
Loss at iteration 1620 : 0.009127508848905563
Loss at iteration 1630 : 0.009438537061214447
Loss at iteration 1640 : 0.01613790914416313
Loss at iteration 1650 : 0.007596402429044247
Loss at iteration 1660 : 0.012046718038618565
Loss at iteration 1670 : 0.005473875906318426
Loss at iteration 1680 : 0.007930148392915726
Loss at iteration 1690 : 0.010073342360556126
Loss at iteration 1700 : 0.005062882788479328
Loss at iteration 1710 : 0.006422542966902256
Loss at iteration 1720 : 0.008983852341771126
Loss at iteration 1730 : 0.007273751776665449
Loss at iteration 1740 : 0.011702029965817928
Loss at iteration 1750 : 0.024770081043243408
Loss at iteration 1760 : 0.022621851414442062
Loss at iteration 1770 : 0.004358332138508558
Loss at iteration 1780 : 0.009727162308990955
Loss at iteration 1790 : 0.019084550440311432
Loss at iteration 1800 : 0.00979709718376398
Loss at iteration 1810 : 0.01280435360968113
Loss at iteration 1820 : 0.008212541230022907
Loss at iteration 1830 : 0.009084946475923061
Loss at iteration 1840 : 0.016831615939736366
Loss at iteration 1850 : 0.008313948288559914
Loss at iteration 1860 : 0.0058593484573066235
Loss at iteration 1870 : 0.013895349577069283
Loss at iteration 1880 : 0.002440085168927908
Loss at iteration 1890 : 0.00838482566177845
Loss at iteration 1900 : 0.03819998353719711
Loss at iteration 1910 : 0.02238484099507332
Loss at iteration 1920 : 0.028507167473435402
Loss at iteration 1930 : 0.013361943885684013
Loss at iteration 1940 : 0.01284569688141346
Loss at iteration 1950 : 0.008087028749287128
Loss at iteration 1960 : 0.018635569140315056
Loss at iteration 1970 : 0.008780473843216896
Loss at iteration 1980 : 0.011433213949203491
Loss at iteration 1990 : 0.011945229023694992
Loss at iteration 2000 : 0.013247630558907986
Loss at iteration 2010 : 0.009010175243020058
Loss at iteration 2020 : 0.006897691637277603
Loss at iteration 2030 : 0.011432969942688942
Loss at iteration 2040 : 0.007448687683790922
Loss at iteration 2050 : 0.01095316931605339
Loss at iteration 2060 : 0.006434149574488401
Loss at iteration 2070 : 0.00741868931800127
Loss at iteration 2080 : 0.012987673282623291
Loss at iteration 2090 : 0.008165092207491398
Loss at iteration 2100 : 0.012148337438702583
Loss at iteration 2110 : 0.008030946366488934
Loss at iteration 2120 : 0.004787404090166092
Loss at iteration 2130 : 0.005977491848170757
Loss at iteration 2140 : 0.004208770580589771
Loss at iteration 2150 : 0.01075019035488367
Loss at iteration 2160 : 0.005159642547369003
Loss at iteration 2170 : 0.00726976478472352
Loss at iteration 2180 : 0.010216162540018559
Loss at iteration 2190 : 0.0062797823920845985
Loss at iteration 2200 : 0.0080765625461936
Loss at iteration 2210 : 0.007983454503118992
Loss at iteration 2220 : 0.008309541270136833
Loss at iteration 2230 : 0.009686521254479885
Loss at iteration 2240 : 0.004869121126830578
Loss at iteration 2250 : 0.016467459499835968
Loss at iteration 2260 : 0.007827314548194408
Loss at iteration 2270 : 0.020958764478564262
Loss at iteration 2280 : 0.012037105858325958
Loss at iteration 2290 : 0.007290360052138567
Loss at iteration 2300 : 0.020958729088306427
Loss at iteration 2310 : 0.012310631573200226
Loss at iteration 2320 : 0.005771622993052006
Loss at iteration 2330 : 0.008599068969488144
Loss at iteration 2340 : 0.016894519329071045
Loss at iteration 2350 : 0.006231359206140041
Loss at iteration 2360 : 0.009761763736605644
Loss at iteration 2370 : 0.018635036423802376
Loss at iteration 2380 : 0.00535358302295208
Loss at iteration 2390 : 0.010914871469140053
Loss at iteration 2400 : 0.011753575876355171
Loss at iteration 2410 : 0.008315671235322952
Loss at iteration 2420 : 0.007421745918691158
The SSIM Value is: 0.8414000590642293
The PSNR Value is: 21.801313145955405
the epoch is: 54
Loss at iteration 10 : 0.004352657124400139
Loss at iteration 20 : 0.018414853140711784
Loss at iteration 30 : 0.009337046183645725
Loss at iteration 40 : 0.011072169989347458
Loss at iteration 50 : 0.013301813043653965
Loss at iteration 60 : 0.012793678790330887
Loss at iteration 70 : 0.010739346966147423
Loss at iteration 80 : 0.008749281987547874
Loss at iteration 90 : 0.01454510074108839
Loss at iteration 100 : 0.007559343706816435
Loss at iteration 110 : 0.004359094426035881
Loss at iteration 120 : 0.01078685000538826
Loss at iteration 130 : 0.00432353001087904
Loss at iteration 140 : 0.008919855579733849
Loss at iteration 150 : 0.009258904494345188
Loss at iteration 160 : 0.010677656158804893
Loss at iteration 170 : 0.009098620153963566
Loss at iteration 180 : 0.006232843268662691
Loss at iteration 190 : 0.007662282325327396
Loss at iteration 200 : 0.014498792588710785
Loss at iteration 210 : 0.0065856133587658405
Loss at iteration 220 : 0.010238940827548504
Loss at iteration 230 : 0.00791406724601984
Loss at iteration 240 : 0.005756034515798092
Loss at iteration 250 : 0.012183679267764091
Loss at iteration 260 : 0.009945491328835487
Loss at iteration 270 : 0.007614280097186565
Loss at iteration 280 : 0.008520730771124363
Loss at iteration 290 : 0.01319186296314001
Loss at iteration 300 : 0.006560611072927713
Loss at iteration 310 : 0.014924694783985615
Loss at iteration 320 : 0.005808168090879917
Loss at iteration 330 : 0.009265041910111904
Loss at iteration 340 : 0.010584020055830479
Loss at iteration 350 : 0.01126432977616787
Loss at iteration 360 : 0.005863976664841175
Loss at iteration 370 : 0.010273993946611881
Loss at iteration 380 : 0.013445314019918442
Loss at iteration 390 : 0.005756015423685312
Loss at iteration 400 : 0.004120143596082926
Loss at iteration 410 : 0.013846488669514656
Loss at iteration 420 : 0.00690106488764286
Loss at iteration 430 : 0.011226410046219826
Loss at iteration 440 : 0.007344662677496672
Loss at iteration 450 : 0.017536185681819916
Loss at iteration 460 : 0.007160876877605915
Loss at iteration 470 : 0.0037236588541418314
Loss at iteration 480 : 0.009627113118767738
Loss at iteration 490 : 0.009105467237532139
Loss at iteration 500 : 0.009395603090524673
Loss at iteration 510 : 0.007030062843114138
Loss at iteration 520 : 0.012659002095460892
Loss at iteration 530 : 0.00823193322867155
Loss at iteration 540 : 0.004387254361063242
Loss at iteration 550 : 0.008269070647656918
Loss at iteration 560 : 0.019081568345427513
Loss at iteration 570 : 0.006444224156439304
Loss at iteration 580 : 0.011585395783185959
Loss at iteration 590 : 0.0060395048931241035
Loss at iteration 600 : 0.01216892246156931
Loss at iteration 610 : 0.016650917008519173
Loss at iteration 620 : 0.011280439794063568
Loss at iteration 630 : 0.005859016440808773
Loss at iteration 640 : 0.010572243481874466
Loss at iteration 650 : 0.011712701991200447
Loss at iteration 660 : 0.015117581933736801
Loss at iteration 670 : 0.01198307890444994
Loss at iteration 680 : 0.01121597085148096
Loss at iteration 690 : 0.01223810762166977
Loss at iteration 700 : 0.014612255617976189
Loss at iteration 710 : 0.014828518033027649
Loss at iteration 720 : 0.010608174838125706
Loss at iteration 730 : 0.013647828251123428
Loss at iteration 740 : 0.00859659630805254
Loss at iteration 750 : 0.0034525012597441673
Loss at iteration 760 : 0.015377168543636799
Loss at iteration 770 : 0.008261281065642834
Loss at iteration 780 : 0.008239259012043476
Loss at iteration 790 : 0.014059394598007202
Loss at iteration 800 : 0.005087208468466997
Loss at iteration 810 : 0.012460671365261078
Loss at iteration 820 : 0.004895102698355913
Loss at iteration 830 : 0.007197118829935789
Loss at iteration 840 : 0.005483473185449839
Loss at iteration 850 : 0.004551128018647432
Loss at iteration 860 : 0.007313092704862356
Loss at iteration 870 : 0.005603055004030466
Loss at iteration 880 : 0.007763833738863468
Loss at iteration 890 : 0.007100862450897694
Loss at iteration 900 : 0.00779518811032176
Loss at iteration 910 : 0.014242682605981827
Loss at iteration 920 : 0.01820455677807331
Loss at iteration 930 : 0.0071747577749192715
Loss at iteration 940 : 0.006700597237795591
Loss at iteration 950 : 0.010812714695930481
Loss at iteration 960 : 0.006176435388624668
Loss at iteration 970 : 0.006410729605704546
Loss at iteration 980 : 0.0025575566105544567
Loss at iteration 990 : 0.013329822570085526
Loss at iteration 1000 : 0.0033524620812386274
Loss at iteration 1010 : 0.007203860208392143
Loss at iteration 1020 : 0.010352961719036102
Loss at iteration 1030 : 0.008125429041683674
Loss at iteration 1040 : 0.009621037170290947
Loss at iteration 1050 : 0.014979277737438679
Loss at iteration 1060 : 0.00732177309691906
Loss at iteration 1070 : 0.004910836461931467
Loss at iteration 1080 : 0.01671932451426983
Loss at iteration 1090 : 0.014738691970705986
Loss at iteration 1100 : 0.01288042776286602
Loss at iteration 1110 : 0.01035819947719574
Loss at iteration 1120 : 0.003098458284512162
Loss at iteration 1130 : 0.013589411973953247
Loss at iteration 1140 : 0.016746213659644127
Loss at iteration 1150 : 0.00726791936904192
Loss at iteration 1160 : 0.011682272888720036
Loss at iteration 1170 : 0.008616211824119091
Loss at iteration 1180 : 0.007599604781717062
Loss at iteration 1190 : 0.015381266362965107
Loss at iteration 1200 : 0.005593730602413416
Loss at iteration 1210 : 0.006095428019762039
Loss at iteration 1220 : 0.012580182403326035
Loss at iteration 1230 : 0.017019307240843773
Loss at iteration 1240 : 0.008346023969352245
Loss at iteration 1250 : 0.008185019716620445
Loss at iteration 1260 : 0.01944398134946823
Loss at iteration 1270 : 0.01625092700123787
Loss at iteration 1280 : 0.005561774596571922
Loss at iteration 1290 : 0.010462027043104172
Loss at iteration 1300 : 0.006348562892526388
Loss at iteration 1310 : 0.01039033941924572
Loss at iteration 1320 : 0.010626078583300114
Loss at iteration 1330 : 0.011003055609762669
Loss at iteration 1340 : 0.01136812660843134
Loss at iteration 1350 : 0.005609308369457722
Loss at iteration 1360 : 0.007911009714007378
Loss at iteration 1370 : 0.024726824834942818
Loss at iteration 1380 : 0.006272830534726381
Loss at iteration 1390 : 0.014559438452124596
Loss at iteration 1400 : 0.011348908767104149
Loss at iteration 1410 : 0.002228203695267439
Loss at iteration 1420 : 0.0076543488539755344
Loss at iteration 1430 : 0.01479567214846611
Loss at iteration 1440 : 0.0068606361746788025
Loss at iteration 1450 : 0.01255977712571621
Loss at iteration 1460 : 0.02733079344034195
Loss at iteration 1470 : 0.009645488113164902
Loss at iteration 1480 : 0.019152577966451645
Loss at iteration 1490 : 0.007866540923714638
Loss at iteration 1500 : 0.006587844341993332
Loss at iteration 1510 : 0.009357638657093048
Loss at iteration 1520 : 0.007676383014768362
Loss at iteration 1530 : 0.012498527765274048
Loss at iteration 1540 : 0.023362113162875175
Loss at iteration 1550 : 0.019451860338449478
Loss at iteration 1560 : 0.014744209125638008
Loss at iteration 1570 : 0.007441894616931677
Loss at iteration 1580 : 0.018801968544721603
Loss at iteration 1590 : 0.008243618533015251
Loss at iteration 1600 : 0.006756273098289967
Loss at iteration 1610 : 0.008984907530248165
Loss at iteration 1620 : 0.007765970192849636
Loss at iteration 1630 : 0.010982641018927097
Loss at iteration 1640 : 0.0066457586362957954
Loss at iteration 1650 : 0.006153462454676628
Loss at iteration 1660 : 0.010260609909892082
Loss at iteration 1670 : 0.005241072736680508
Loss at iteration 1680 : 0.009704092517495155
Loss at iteration 1690 : 0.009773895144462585
Loss at iteration 1700 : 0.015690891072154045
Loss at iteration 1710 : 0.013631324283778667
Loss at iteration 1720 : 0.004219644702970982
Loss at iteration 1730 : 0.013159173540771008
Loss at iteration 1740 : 0.009025726467370987
Loss at iteration 1750 : 0.00511022238060832
Loss at iteration 1760 : 0.014432277530431747
Loss at iteration 1770 : 0.02493024244904518
Loss at iteration 1780 : 0.007788617163896561
Loss at iteration 1790 : 0.010958569124341011
Loss at iteration 1800 : 0.003650716273114085
Loss at iteration 1810 : 0.008763909339904785
Loss at iteration 1820 : 0.01030441652983427
Loss at iteration 1830 : 0.014197170734405518
Loss at iteration 1840 : 0.008980533108115196
Loss at iteration 1850 : 0.017424561083316803
Loss at iteration 1860 : 0.00394606776535511
Loss at iteration 1870 : 0.01248236931860447
Loss at iteration 1880 : 0.01503167673945427
Loss at iteration 1890 : 0.01274372823536396
Loss at iteration 1900 : 0.009933240711688995
Loss at iteration 1910 : 0.025517316535115242
Loss at iteration 1920 : 0.016044938936829567
Loss at iteration 1930 : 0.005830255337059498
Loss at iteration 1940 : 0.006411866284906864
Loss at iteration 1950 : 0.009233701974153519
Loss at iteration 1960 : 0.013446486555039883
Loss at iteration 1970 : 0.005699248984456062
Loss at iteration 1980 : 0.013373272493481636
Loss at iteration 1990 : 0.012310604564845562
Loss at iteration 2000 : 0.011955667287111282
Loss at iteration 2010 : 0.006723206490278244
Loss at iteration 2020 : 0.003656135406345129
Loss at iteration 2030 : 0.009645665064454079
Loss at iteration 2040 : 0.008913129568099976
Loss at iteration 2050 : 0.010965378023684025
Loss at iteration 2060 : 0.004787137731909752
Loss at iteration 2070 : 0.005499081686139107
Loss at iteration 2080 : 0.010134240612387657
Loss at iteration 2090 : 0.010664165019989014
Loss at iteration 2100 : 0.00843294057995081
Loss at iteration 2110 : 0.01321327593177557
Loss at iteration 2120 : 0.0068772053346037865
Loss at iteration 2130 : 0.015863928943872452
Loss at iteration 2140 : 0.007722614333033562
Loss at iteration 2150 : 0.014996517449617386
Loss at iteration 2160 : 0.006286542396992445
Loss at iteration 2170 : 0.009438753128051758
Loss at iteration 2180 : 0.004588422831147909
Loss at iteration 2190 : 0.011237125843763351
Loss at iteration 2200 : 0.012687500566244125
Loss at iteration 2210 : 0.010480031371116638
Loss at iteration 2220 : 0.015400579199194908
Loss at iteration 2230 : 0.019838958978652954
Loss at iteration 2240 : 0.006779148243367672
Loss at iteration 2250 : 0.01246924139559269
Loss at iteration 2260 : 0.01080197375267744
Loss at iteration 2270 : 0.025631345808506012
Loss at iteration 2280 : 0.005921379663050175
Loss at iteration 2290 : 0.005478851497173309
Loss at iteration 2300 : 0.015529818832874298
Loss at iteration 2310 : 0.010912680067121983
Loss at iteration 2320 : 0.014250427484512329
Loss at iteration 2330 : 0.013659502379596233
Loss at iteration 2340 : 0.011679304763674736
Loss at iteration 2350 : 0.008859135210514069
Loss at iteration 2360 : 0.011216423474252224
Loss at iteration 2370 : 0.019341211766004562
Loss at iteration 2380 : 0.0027714320458471775
Loss at iteration 2390 : 0.013415424153208733
Loss at iteration 2400 : 0.010063793510198593
Loss at iteration 2410 : 0.010797608643770218
Loss at iteration 2420 : 0.010112790390849113
The SSIM Value is: 0.8432733217875162
The PSNR Value is: 21.662624422709147
the epoch is: 55
Loss at iteration 10 : 0.009867522865533829
Loss at iteration 20 : 0.011562233790755272
Loss at iteration 30 : 0.01504257321357727
Loss at iteration 40 : 0.009628205560147762
Loss at iteration 50 : 0.014471951872110367
Loss at iteration 60 : 0.019044216722249985
Loss at iteration 70 : 0.005034325644373894
Loss at iteration 80 : 0.005824992433190346
Loss at iteration 90 : 0.010571438819169998
Loss at iteration 100 : 0.00941730197519064
Loss at iteration 110 : 0.011356616392731667
Loss at iteration 120 : 0.01499606017023325
Loss at iteration 130 : 0.014916293323040009
Loss at iteration 140 : 0.015956735238432884
Loss at iteration 150 : 0.003506977576762438
Loss at iteration 160 : 0.0077192592434585094
Loss at iteration 170 : 0.023125842213630676
Loss at iteration 180 : 0.006789542734622955
Loss at iteration 190 : 0.009503517299890518
Loss at iteration 200 : 0.006092171650379896
Loss at iteration 210 : 0.013065340928733349
Loss at iteration 220 : 0.018073031678795815
Loss at iteration 230 : 0.007022964768111706
Loss at iteration 240 : 0.008904396556317806
Loss at iteration 250 : 0.01232708990573883
Loss at iteration 260 : 0.010210420936346054
Loss at iteration 270 : 0.012843179516494274
Loss at iteration 280 : 0.018862837925553322
Loss at iteration 290 : 0.016556281596422195
Loss at iteration 300 : 0.012097623199224472
Loss at iteration 310 : 0.009342256933450699
Loss at iteration 320 : 0.01006246916949749
Loss at iteration 330 : 0.008954336866736412
Loss at iteration 340 : 0.010603709146380424
Loss at iteration 350 : 0.006421357858926058
Loss at iteration 360 : 0.011724650859832764
Loss at iteration 370 : 0.014939555898308754
Loss at iteration 380 : 0.006139696575701237
Loss at iteration 390 : 0.013196522369980812
Loss at iteration 400 : 0.0038545909337699413
Loss at iteration 410 : 0.0061973221600055695
Loss at iteration 420 : 0.01120238658040762
Loss at iteration 430 : 0.011223350651562214
Loss at iteration 440 : 0.006152666173875332
Loss at iteration 450 : 0.01377671118825674
Loss at iteration 460 : 0.014334654435515404
Loss at iteration 470 : 0.01476758997887373
Loss at iteration 480 : 0.0124050909653306
Loss at iteration 490 : 0.01040586270391941
Loss at iteration 500 : 0.01428297907114029
Loss at iteration 510 : 0.011221298947930336
Loss at iteration 520 : 0.010294001549482346
Loss at iteration 530 : 0.0038208782207220793
Loss at iteration 540 : 0.017653200775384903
Loss at iteration 550 : 0.017803557217121124
Loss at iteration 560 : 0.02118125557899475
Loss at iteration 570 : 0.003943220712244511
Loss at iteration 580 : 0.004173416178673506
Loss at iteration 590 : 0.0052371639758348465
Loss at iteration 600 : 0.011688316240906715
Loss at iteration 610 : 0.015307152643799782
Loss at iteration 620 : 0.00926055945456028
Loss at iteration 630 : 0.008388624526560307
Loss at iteration 640 : 0.005508194677531719
Loss at iteration 650 : 0.008493095636367798
Loss at iteration 660 : 0.016252152621746063
Loss at iteration 670 : 0.01250701118260622
Loss at iteration 680 : 0.01470881886780262
Loss at iteration 690 : 0.014477773569524288
Loss at iteration 700 : 0.013981705531477928
Loss at iteration 710 : 0.03664514422416687
Loss at iteration 720 : 0.0181652270257473
Loss at iteration 730 : 0.008251819759607315
Loss at iteration 740 : 0.00932357832789421
Loss at iteration 750 : 0.008442411199212074
Loss at iteration 760 : 0.012259788811206818
Loss at iteration 770 : 0.00611810851842165
Loss at iteration 780 : 0.010612606070935726
Loss at iteration 790 : 0.012072887271642685
Loss at iteration 800 : 0.005999257788062096
Loss at iteration 810 : 0.006105771753937006
Loss at iteration 820 : 0.01491740345954895
Loss at iteration 830 : 0.003345572855323553
Loss at iteration 840 : 0.010359046049416065
Loss at iteration 850 : 0.005350284744054079
Loss at iteration 860 : 0.025363704189658165
Loss at iteration 870 : 0.0042616031132638454
Loss at iteration 880 : 0.011530552990734577
Loss at iteration 890 : 0.0060807280242443085
Loss at iteration 900 : 0.012380034662783146
Loss at iteration 910 : 0.012128278613090515
Loss at iteration 920 : 0.007864981889724731
Loss at iteration 930 : 0.007817094214260578
Loss at iteration 940 : 0.017746612429618835
Loss at iteration 950 : 0.007991609163582325
Loss at iteration 960 : 0.0027856500819325447
Loss at iteration 970 : 0.013265958055853844
Loss at iteration 980 : 0.012020417489111423
Loss at iteration 990 : 0.003957909997552633
Loss at iteration 1000 : 0.009352792985737324
Loss at iteration 1010 : 0.021411340683698654
Loss at iteration 1020 : 0.020236510783433914
Loss at iteration 1030 : 0.011830512434244156
Loss at iteration 1040 : 0.014588589780032635
Loss at iteration 1050 : 0.0056951092556118965
Loss at iteration 1060 : 0.016132917255163193
Loss at iteration 1070 : 0.005161321721971035
Loss at iteration 1080 : 0.026253284886479378
Loss at iteration 1090 : 0.0077689518220722675
Loss at iteration 1100 : 0.008543905802071095
Loss at iteration 1110 : 0.012744523584842682
Loss at iteration 1120 : 0.007128930650651455
Loss at iteration 1130 : 0.012373076751828194
Loss at iteration 1140 : 0.0028703659772872925
Loss at iteration 1150 : 0.007594650145620108
Loss at iteration 1160 : 0.007709970697760582
Loss at iteration 1170 : 0.01388310082256794
Loss at iteration 1180 : 0.011293328367173672
Loss at iteration 1190 : 0.011933083645999432
Loss at iteration 1200 : 0.008720437064766884
Loss at iteration 1210 : 0.02054927870631218
Loss at iteration 1220 : 0.005966924596577883
Loss at iteration 1230 : 0.0112783033400774
Loss at iteration 1240 : 0.01710142008960247
Loss at iteration 1250 : 0.007903683930635452
Loss at iteration 1260 : 0.00871452409774065
Loss at iteration 1270 : 0.00845886766910553
Loss at iteration 1280 : 0.013295392505824566
Loss at iteration 1290 : 0.006247298792004585
Loss at iteration 1300 : 0.005215339828282595
Loss at iteration 1310 : 0.008387058973312378
Loss at iteration 1320 : 0.0068855443969368935
Loss at iteration 1330 : 0.006623989902436733
Loss at iteration 1340 : 0.00987996719777584
Loss at iteration 1350 : 0.011307891458272934
Loss at iteration 1360 : 0.010198459960520267
Loss at iteration 1370 : 0.0066930982284247875
Loss at iteration 1380 : 0.007101423107087612
Loss at iteration 1390 : 0.016763389110565186
Loss at iteration 1400 : 0.007270368747413158
Loss at iteration 1410 : 0.0014946690062060952
Loss at iteration 1420 : 0.006093068514019251
Loss at iteration 1430 : 0.02610151469707489
Loss at iteration 1440 : 0.01269761472940445
Loss at iteration 1450 : 0.008691521361470222
Loss at iteration 1460 : 0.026678279042243958
Loss at iteration 1470 : 0.006910931784659624
Loss at iteration 1480 : 0.00788639672100544
Loss at iteration 1490 : 0.012976538389921188
Loss at iteration 1500 : 0.008466377854347229
Loss at iteration 1510 : 0.008760267868638039
Loss at iteration 1520 : 0.007872294634580612
Loss at iteration 1530 : 0.012091558426618576
Loss at iteration 1540 : 0.0071092345751821995
Loss at iteration 1550 : 0.010065780952572823
Loss at iteration 1560 : 0.009782442823052406
Loss at iteration 1570 : 0.0037942323833703995
Loss at iteration 1580 : 0.005037751980125904
Loss at iteration 1590 : 0.008474130183458328
Loss at iteration 1600 : 0.010789245367050171
Loss at iteration 1610 : 0.004248357843607664
Loss at iteration 1620 : 0.007231558207422495
Loss at iteration 1630 : 0.008106814697384834
Loss at iteration 1640 : 0.012177870608866215
Loss at iteration 1650 : 0.009655175730586052
Loss at iteration 1660 : 0.009029116481542587
Loss at iteration 1670 : 0.002777563175186515
Loss at iteration 1680 : 0.008189849555492401
Loss at iteration 1690 : 0.00757320923730731
Loss at iteration 1700 : 0.007393699139356613
Loss at iteration 1710 : 0.006668722722679377
Loss at iteration 1720 : 0.008123776875436306
Loss at iteration 1730 : 0.00851421244442463
Loss at iteration 1740 : 0.003160302760079503
Loss at iteration 1750 : 0.006585082970559597
Loss at iteration 1760 : 0.007825307548046112
Loss at iteration 1770 : 0.013676058501005173
Loss at iteration 1780 : 0.005516549106687307
Loss at iteration 1790 : 0.012291863560676575
Loss at iteration 1800 : 0.016431204974651337
Loss at iteration 1810 : 0.005961666814982891
Loss at iteration 1820 : 0.004828253295272589
Loss at iteration 1830 : 0.00935060903429985
Loss at iteration 1840 : 0.014678790234029293
Loss at iteration 1850 : 0.00554094510152936
Loss at iteration 1860 : 0.009888255968689919
Loss at iteration 1870 : 0.004008572082966566
Loss at iteration 1880 : 0.009537920355796814
Loss at iteration 1890 : 0.0064179422333836555
Loss at iteration 1900 : 0.007418020628392696
Loss at iteration 1910 : 0.009158462285995483
Loss at iteration 1920 : 0.00932366494089365
Loss at iteration 1930 : 0.00817272812128067
Loss at iteration 1940 : 0.004947961773723364
Loss at iteration 1950 : 0.008026323281228542
Loss at iteration 1960 : 0.01663084886968136
Loss at iteration 1970 : 0.010400721803307533
Loss at iteration 1980 : 0.02144910767674446
Loss at iteration 1990 : 0.015602909959852695
Loss at iteration 2000 : 0.0054819220677018166
Loss at iteration 2010 : 0.007562488317489624
Loss at iteration 2020 : 0.013925965875387192
Loss at iteration 2030 : 0.004485769663006067
Loss at iteration 2040 : 0.01276590209454298
Loss at iteration 2050 : 0.0020253427792340517
Loss at iteration 2060 : 0.009859747253358364
Loss at iteration 2070 : 0.007548732683062553
Loss at iteration 2080 : 0.010869914665818214
Loss at iteration 2090 : 0.007900113239884377
Loss at iteration 2100 : 0.01596241071820259
Loss at iteration 2110 : 0.010568326339125633
Loss at iteration 2120 : 0.011600236408412457
Loss at iteration 2130 : 0.015595527365803719
Loss at iteration 2140 : 0.006506902165710926
Loss at iteration 2150 : 0.01710084266960621
Loss at iteration 2160 : 0.007685557939112186
Loss at iteration 2170 : 0.011841115541756153
Loss at iteration 2180 : 0.016731366515159607
Loss at iteration 2190 : 0.005798604339361191
Loss at iteration 2200 : 0.009264418855309486
Loss at iteration 2210 : 0.026020025834441185
Loss at iteration 2220 : 0.008842039853334427
Loss at iteration 2230 : 0.01028678473085165
Loss at iteration 2240 : 0.012608418241143227
Loss at iteration 2250 : 0.008568067103624344
Loss at iteration 2260 : 0.004565739072859287
Loss at iteration 2270 : 0.012722508981823921
Loss at iteration 2280 : 0.010946139693260193
Loss at iteration 2290 : 0.01690318062901497
Loss at iteration 2300 : 0.010255367495119572
Loss at iteration 2310 : 0.006108184345066547
Loss at iteration 2320 : 0.011769005097448826
Loss at iteration 2330 : 0.012295669876039028
Loss at iteration 2340 : 0.009057627990841866
Loss at iteration 2350 : 0.010598455555737019
Loss at iteration 2360 : 0.008638929575681686
Loss at iteration 2370 : 0.00643131323158741
Loss at iteration 2380 : 0.011339004151523113
Loss at iteration 2390 : 0.012032033875584602
Loss at iteration 2400 : 0.0086972676217556
Loss at iteration 2410 : 0.010635118000209332
Loss at iteration 2420 : 0.012376263737678528
The SSIM Value is: 0.8441543777783712
The PSNR Value is: 22.137511189778646
the epoch is: 56
Loss at iteration 10 : 0.015083893202245235
Loss at iteration 20 : 0.01000174693763256
Loss at iteration 30 : 0.006173267029225826
Loss at iteration 40 : 0.02591489627957344
Loss at iteration 50 : 0.014925014227628708
Loss at iteration 60 : 0.012088902294635773
Loss at iteration 70 : 0.005884618032723665
Loss at iteration 80 : 0.006669771857559681
Loss at iteration 90 : 0.009127914905548096
Loss at iteration 100 : 0.017975274473428726
Loss at iteration 110 : 0.019757313653826714
Loss at iteration 120 : 0.00755657535046339
Loss at iteration 130 : 0.004548581317067146
Loss at iteration 140 : 0.02091825380921364
Loss at iteration 150 : 0.007267317734658718
Loss at iteration 160 : 0.011990884318947792
Loss at iteration 170 : 0.017098600044846535
Loss at iteration 180 : 0.00582833681255579
Loss at iteration 190 : 0.012155074626207352
Loss at iteration 200 : 0.006257219240069389
Loss at iteration 210 : 0.009760075248777866
Loss at iteration 220 : 0.018103275448083878
Loss at iteration 230 : 0.013522723689675331
Loss at iteration 240 : 0.013437132351100445
Loss at iteration 250 : 0.014794114977121353
Loss at iteration 260 : 0.016708459705114365
Loss at iteration 270 : 0.02406470477581024
Loss at iteration 280 : 0.012639295309782028
Loss at iteration 290 : 0.011124510318040848
Loss at iteration 300 : 0.013600245118141174
Loss at iteration 310 : 0.010018226690590382
Loss at iteration 320 : 0.00973604153841734
Loss at iteration 330 : 0.015026139095425606
Loss at iteration 340 : 0.013521842658519745
Loss at iteration 350 : 0.005283597856760025
Loss at iteration 360 : 0.02315232716500759
Loss at iteration 370 : 0.008634506724774837
Loss at iteration 380 : 0.012433245778083801
Loss at iteration 390 : 0.0053428648971021175
Loss at iteration 400 : 0.007364517077803612
Loss at iteration 410 : 0.014087293297052383
Loss at iteration 420 : 0.007489496376365423
Loss at iteration 430 : 0.012203223071992397
Loss at iteration 440 : 0.0031702411361038685
Loss at iteration 450 : 0.013278852216899395
Loss at iteration 460 : 0.006322526838630438
Loss at iteration 470 : 0.006124086212366819
Loss at iteration 480 : 0.016299176961183548
Loss at iteration 490 : 0.012110949493944645
Loss at iteration 500 : 0.012645932845771313
Loss at iteration 510 : 0.02048015221953392
Loss at iteration 520 : 0.009677354246377945
Loss at iteration 530 : 0.010160412639379501
Loss at iteration 540 : 0.007485062815248966
Loss at iteration 550 : 0.006414294708520174
Loss at iteration 560 : 0.014309038408100605
Loss at iteration 570 : 0.021096784621477127
Loss at iteration 580 : 0.012221974320709705
Loss at iteration 590 : 0.01904618926346302
Loss at iteration 600 : 0.04746297746896744
Loss at iteration 610 : 0.021960627287626266
Loss at iteration 620 : 0.024654099717736244
Loss at iteration 630 : 0.009863474406301975
Loss at iteration 640 : 0.011751902289688587
Loss at iteration 650 : 0.007339946925640106
Loss at iteration 660 : 0.005347799509763718
Loss at iteration 670 : 0.010661080479621887
Loss at iteration 680 : 0.0072132740169763565
Loss at iteration 690 : 0.012326637282967567
Loss at iteration 700 : 0.009184419177472591
Loss at iteration 710 : 0.011949519626796246
Loss at iteration 720 : 0.0202033631503582
Loss at iteration 730 : 0.01052679494023323
Loss at iteration 740 : 0.004215260036289692
Loss at iteration 750 : 0.007531875744462013
Loss at iteration 760 : 0.017030514776706696
Loss at iteration 770 : 0.009184755384922028
Loss at iteration 780 : 0.009246539324522018
Loss at iteration 790 : 0.007179331034421921
Loss at iteration 800 : 0.008836865425109863
Loss at iteration 810 : 0.015926050022244453
Loss at iteration 820 : 0.013230796903371811
Loss at iteration 830 : 0.009302017278969288
Loss at iteration 840 : 0.008007736876606941
Loss at iteration 850 : 0.014371787197887897
Loss at iteration 860 : 0.0062197064980864525
Loss at iteration 870 : 0.007205064408481121
Loss at iteration 880 : 0.017462898045778275
Loss at iteration 890 : 0.01137731596827507
Loss at iteration 900 : 0.013925918377935886
Loss at iteration 910 : 0.006421095225960016
Loss at iteration 920 : 0.005425130482763052
Loss at iteration 930 : 0.010913296602666378
Loss at iteration 940 : 0.009234776720404625
Loss at iteration 950 : 0.0033710540737956762
Loss at iteration 960 : 0.007473608944565058
Loss at iteration 970 : 0.00831227283924818
Loss at iteration 980 : 0.017618712037801743
Loss at iteration 990 : 0.0049185482785105705
Loss at iteration 1000 : 0.010360248386859894
Loss at iteration 1010 : 0.010030422359704971
Loss at iteration 1020 : 0.019376248121261597
Loss at iteration 1030 : 0.00879097543656826
Loss at iteration 1040 : 0.010280570015311241
Loss at iteration 1050 : 0.014325130730867386
Loss at iteration 1060 : 0.01125356275588274
Loss at iteration 1070 : 0.0074517917819321156
Loss at iteration 1080 : 0.005239664111286402
Loss at iteration 1090 : 0.013845068402588367
Loss at iteration 1100 : 0.013851716183125973
Loss at iteration 1110 : 0.005572665948420763
Loss at iteration 1120 : 0.009342579171061516
Loss at iteration 1130 : 0.015058059245347977
Loss at iteration 1140 : 0.005239543505012989
Loss at iteration 1150 : 0.006902594584971666
Loss at iteration 1160 : 0.009560556150972843
Loss at iteration 1170 : 0.009922103025019169
Loss at iteration 1180 : 0.0023092632181942463
Loss at iteration 1190 : 0.015043025836348534
Loss at iteration 1200 : 0.015312382951378822
Loss at iteration 1210 : 0.00431143818423152
Loss at iteration 1220 : 0.011439790017902851
Loss at iteration 1230 : 0.005947742145508528
Loss at iteration 1240 : 0.01056978665292263
Loss at iteration 1250 : 0.011942291632294655
Loss at iteration 1260 : 0.0077156005427241325
Loss at iteration 1270 : 0.011468743905425072
Loss at iteration 1280 : 0.017211589962244034
Loss at iteration 1290 : 0.01558014564216137
Loss at iteration 1300 : 0.005304449237883091
Loss at iteration 1310 : 0.0076981279999017715
Loss at iteration 1320 : 0.00591395003721118
Loss at iteration 1330 : 0.00729762390255928
Loss at iteration 1340 : 0.02130703628063202
Loss at iteration 1350 : 0.005752346478402615
Loss at iteration 1360 : 0.008418116718530655
Loss at iteration 1370 : 0.00717034749686718
Loss at iteration 1380 : 0.008615341037511826
Loss at iteration 1390 : 0.008865082636475563
Loss at iteration 1400 : 0.014911923557519913
Loss at iteration 1410 : 0.011878833174705505
Loss at iteration 1420 : 0.00920301303267479
Loss at iteration 1430 : 0.007811099290847778
Loss at iteration 1440 : 0.010501622222363949
Loss at iteration 1450 : 0.006370460614562035
Loss at iteration 1460 : 0.016040710732340813
Loss at iteration 1470 : 0.015300799161195755
Loss at iteration 1480 : 0.00988637562841177
Loss at iteration 1490 : 0.013585453853011131
Loss at iteration 1500 : 0.008199892938137054
Loss at iteration 1510 : 0.005015756003558636
Loss at iteration 1520 : 0.006879604887217283
Loss at iteration 1530 : 0.00681983632966876
Loss at iteration 1540 : 0.0038633830845355988
Loss at iteration 1550 : 0.004851083736866713
Loss at iteration 1560 : 0.010922171175479889
Loss at iteration 1570 : 0.004698233678936958
Loss at iteration 1580 : 0.006210381630808115
Loss at iteration 1590 : 0.018027734011411667
Loss at iteration 1600 : 0.01577058620750904
Loss at iteration 1610 : 0.011560668237507343
Loss at iteration 1620 : 0.004372036084532738
Loss at iteration 1630 : 0.008871037513017654
Loss at iteration 1640 : 0.0067873764783144
Loss at iteration 1650 : 0.005890487227588892
Loss at iteration 1660 : 0.02180250734090805
Loss at iteration 1670 : 0.004601318389177322
Loss at iteration 1680 : 0.005798378027975559
Loss at iteration 1690 : 0.006271340884268284
Loss at iteration 1700 : 0.011021597310900688
Loss at iteration 1710 : 0.008601178415119648
Loss at iteration 1720 : 0.005153121426701546
Loss at iteration 1730 : 0.008587115444242954
Loss at iteration 1740 : 0.011313707567751408
Loss at iteration 1750 : 0.013523252680897713
Loss at iteration 1760 : 0.012628966011106968
Loss at iteration 1770 : 0.005623186472803354
Loss at iteration 1780 : 0.00742750521749258
Loss at iteration 1790 : 0.013560278341174126
Loss at iteration 1800 : 0.009677786380052567
Loss at iteration 1810 : 0.013155261985957623
Loss at iteration 1820 : 0.0063741784542799
Loss at iteration 1830 : 0.010673889890313148
Loss at iteration 1840 : 0.013362123630940914
Loss at iteration 1850 : 0.014070244506001472
Loss at iteration 1860 : 0.01660715788602829
Loss at iteration 1870 : 0.01355810184031725
Loss at iteration 1880 : 0.004991989117115736
Loss at iteration 1890 : 0.015403005294501781
Loss at iteration 1900 : 0.01156880334019661
Loss at iteration 1910 : 0.011713596060872078
Loss at iteration 1920 : 0.008730398491024971
Loss at iteration 1930 : 0.006555324885994196
Loss at iteration 1940 : 0.0055451239459216595
Loss at iteration 1950 : 0.008179076947271824
Loss at iteration 1960 : 0.0076636881567537785
Loss at iteration 1970 : 0.0049468763172626495
Loss at iteration 1980 : 0.01050378568470478
Loss at iteration 1990 : 0.007496353704482317
Loss at iteration 2000 : 0.011162316426634789
Loss at iteration 2010 : 0.00698518194258213
Loss at iteration 2020 : 0.006188120227307081
Loss at iteration 2030 : 0.004093584138900042
Loss at iteration 2040 : 0.0053791808895766735
Loss at iteration 2050 : 0.005756153259426355
Loss at iteration 2060 : 0.025665797293186188
Loss at iteration 2070 : 0.008024057373404503
Loss at iteration 2080 : 0.014728277921676636
Loss at iteration 2090 : 0.008115630596876144
Loss at iteration 2100 : 0.011580459773540497
Loss at iteration 2110 : 0.01387324370443821
Loss at iteration 2120 : 0.004207718651741743
Loss at iteration 2130 : 0.00569098861888051
Loss at iteration 2140 : 0.005816933698952198
Loss at iteration 2150 : 0.00866575725376606
Loss at iteration 2160 : 0.009599150158464909
Loss at iteration 2170 : 0.011035301722586155
Loss at iteration 2180 : 0.002822574693709612
Loss at iteration 2190 : 0.005023999605327845
Loss at iteration 2200 : 0.016249187290668488
Loss at iteration 2210 : 0.007971817627549171
Loss at iteration 2220 : 0.011252932250499725
Loss at iteration 2230 : 0.007894422858953476
Loss at iteration 2240 : 0.0065780761651694775
Loss at iteration 2250 : 0.010036461055278778
Loss at iteration 2260 : 0.005012859590351582
Loss at iteration 2270 : 0.008604341186583042
Loss at iteration 2280 : 0.004260503686964512
Loss at iteration 2290 : 0.0105513297021389
Loss at iteration 2300 : 0.01285481359809637
Loss at iteration 2310 : 0.010436535812914371
Loss at iteration 2320 : 0.005053994245827198
Loss at iteration 2330 : 0.013871055096387863
Loss at iteration 2340 : 0.013235299848020077
Loss at iteration 2350 : 0.011136657558381557
Loss at iteration 2360 : 0.005916188936680555
Loss at iteration 2370 : 0.006829117890447378
Loss at iteration 2380 : 0.008800478652119637
Loss at iteration 2390 : 0.007893037050962448
Loss at iteration 2400 : 0.00437731109559536
Loss at iteration 2410 : 0.011073936708271503
Loss at iteration 2420 : 0.005800487473607063
The SSIM Value is: 0.8448910196622212
The PSNR Value is: 21.723217900594076
the epoch is: 57
Loss at iteration 10 : 0.013928050175309181
Loss at iteration 20 : 0.00798132922500372
Loss at iteration 30 : 0.005343130324035883
Loss at iteration 40 : 0.0064931949600577354
Loss at iteration 50 : 0.005744554102420807
Loss at iteration 60 : 0.012281603179872036
Loss at iteration 70 : 0.010483019053936005
Loss at iteration 80 : 0.003924625925719738
Loss at iteration 90 : 0.005180900916457176
Loss at iteration 100 : 0.00794227421283722
Loss at iteration 110 : 0.0033729407005012035
Loss at iteration 120 : 0.01791795901954174
Loss at iteration 130 : 0.008095734752714634
Loss at iteration 140 : 0.010038658045232296
Loss at iteration 150 : 0.012507934123277664
Loss at iteration 160 : 0.009165811352431774
Loss at iteration 170 : 0.00898428913205862
Loss at iteration 180 : 0.006902328692376614
Loss at iteration 190 : 0.007552247494459152
Loss at iteration 200 : 0.012648065574467182
Loss at iteration 210 : 0.019042328000068665
Loss at iteration 220 : 0.008724505081772804
Loss at iteration 230 : 0.006326093338429928
Loss at iteration 240 : 0.008419288322329521
Loss at iteration 250 : 0.005618625320494175
Loss at iteration 260 : 0.00991884432733059
Loss at iteration 270 : 0.014138298109173775
Loss at iteration 280 : 0.008514328859746456
Loss at iteration 290 : 0.008538490161299706
Loss at iteration 300 : 0.004553254693746567
Loss at iteration 310 : 0.011353977955877781
Loss at iteration 320 : 0.013590038754045963
Loss at iteration 330 : 0.0076440609991550446
Loss at iteration 340 : 0.011538359336555004
Loss at iteration 350 : 0.01774941384792328
Loss at iteration 360 : 0.008532034233212471
Loss at iteration 370 : 0.00891402829438448
Loss at iteration 380 : 0.011874780990183353
Loss at iteration 390 : 0.011974763125181198
Loss at iteration 400 : 0.009544399566948414
Loss at iteration 410 : 0.010499604977667332
Loss at iteration 420 : 0.013144265860319138
Loss at iteration 430 : 0.015435345470905304
Loss at iteration 440 : 0.0050480300560593605
Loss at iteration 450 : 0.006556820590049028
Loss at iteration 460 : 0.0034923614002764225
Loss at iteration 470 : 0.006018714979290962
Loss at iteration 480 : 0.0067441267892718315
Loss at iteration 490 : 0.006232816260308027
Loss at iteration 500 : 0.004580591805279255
Loss at iteration 510 : 0.012904029339551926
Loss at iteration 520 : 0.0075261881574988365
Loss at iteration 530 : 0.010492664761841297
Loss at iteration 540 : 0.007444943301379681
Loss at iteration 550 : 0.01144804060459137
Loss at iteration 560 : 0.013535674661397934
Loss at iteration 570 : 0.01451048068702221
Loss at iteration 580 : 0.015567479655146599
Loss at iteration 590 : 0.011031700298190117
Loss at iteration 600 : 0.015159646049141884
Loss at iteration 610 : 0.0037791780196130276
Loss at iteration 620 : 0.003891634987667203
Loss at iteration 630 : 0.004554583691060543
Loss at iteration 640 : 0.01012975350022316
Loss at iteration 650 : 0.0127736646682024
Loss at iteration 660 : 0.013876459561288357
Loss at iteration 670 : 0.008148550987243652
Loss at iteration 680 : 0.010980463586747646
Loss at iteration 690 : 0.015901140868663788
Loss at iteration 700 : 0.013964512385427952
Loss at iteration 710 : 0.011334332637488842
Loss at iteration 720 : 0.0076634446159005165
Loss at iteration 730 : 0.015538815408945084
Loss at iteration 740 : 0.003308364422991872
Loss at iteration 750 : 0.006718391086906195
Loss at iteration 760 : 0.012767644599080086
Loss at iteration 770 : 0.004422948230057955
Loss at iteration 780 : 0.00655764527618885
Loss at iteration 790 : 0.010147349908947945
Loss at iteration 800 : 0.008871964178979397
Loss at iteration 810 : 0.006009365897625685
Loss at iteration 820 : 0.013125667348504066
Loss at iteration 830 : 0.0031202887184917927
Loss at iteration 840 : 0.012250751256942749
Loss at iteration 850 : 0.012049573473632336
Loss at iteration 860 : 0.011838747188448906
Loss at iteration 870 : 0.014588436111807823
Loss at iteration 880 : 0.011063545942306519
Loss at iteration 890 : 0.00839401688426733
Loss at iteration 900 : 0.013685066252946854
Loss at iteration 910 : 0.0086620282381773
Loss at iteration 920 : 0.017631059512495995
Loss at iteration 930 : 0.0061837355606257915
Loss at iteration 940 : 0.009117637760937214
Loss at iteration 950 : 0.011546405963599682
Loss at iteration 960 : 0.009997136890888214
Loss at iteration 970 : 0.007308226078748703
Loss at iteration 980 : 0.014332027174532413
Loss at iteration 990 : 0.008082002401351929
Loss at iteration 1000 : 0.013436861336231232
Loss at iteration 1010 : 0.009549037553369999
Loss at iteration 1020 : 0.005920761730521917
Loss at iteration 1030 : 0.011138495989143848
Loss at iteration 1040 : 0.008935017511248589
Loss at iteration 1050 : 0.010859273374080658
Loss at iteration 1060 : 0.00767036247998476
Loss at iteration 1070 : 0.0075908987782895565
Loss at iteration 1080 : 0.011245696805417538
Loss at iteration 1090 : 0.005267798434942961
Loss at iteration 1100 : 0.009190762415528297
Loss at iteration 1110 : 0.010739268735051155
Loss at iteration 1120 : 0.005490816663950682
Loss at iteration 1130 : 0.016178980469703674
Loss at iteration 1140 : 0.006960222031921148
Loss at iteration 1150 : 0.0031780435238033533
Loss at iteration 1160 : 0.01611347496509552
Loss at iteration 1170 : 0.003766867332160473
Loss at iteration 1180 : 0.015682131052017212
Loss at iteration 1190 : 0.0046324110589921474
Loss at iteration 1200 : 0.009903224185109138
Loss at iteration 1210 : 0.01162576861679554
Loss at iteration 1220 : 0.013041289523243904
Loss at iteration 1230 : 0.013554155826568604
Loss at iteration 1240 : 0.0052069262601435184
Loss at iteration 1250 : 0.008555622771382332
Loss at iteration 1260 : 0.013712325133383274
Loss at iteration 1270 : 0.00821002759039402
Loss at iteration 1280 : 0.004073927644640207
Loss at iteration 1290 : 0.01765633001923561
Loss at iteration 1300 : 0.012958960607647896
Loss at iteration 1310 : 0.006893811747431755
Loss at iteration 1320 : 0.006982799153774977
Loss at iteration 1330 : 0.013004319742321968
Loss at iteration 1340 : 0.01185732614248991
Loss at iteration 1350 : 0.012394262477755547
Loss at iteration 1360 : 0.00799576286226511
Loss at iteration 1370 : 0.009462653659284115
Loss at iteration 1380 : 0.010742608457803726
Loss at iteration 1390 : 0.01096329651772976
Loss at iteration 1400 : 0.010749499313533306
Loss at iteration 1410 : 0.013084396719932556
Loss at iteration 1420 : 0.018922533839941025
Loss at iteration 1430 : 0.008137134835124016
Loss at iteration 1440 : 0.00625701854005456
Loss at iteration 1450 : 0.014088242314755917
Loss at iteration 1460 : 0.010594142600893974
Loss at iteration 1470 : 0.023609628900885582
Loss at iteration 1480 : 0.011563858017325401
Loss at iteration 1490 : 0.007385525852441788
Loss at iteration 1500 : 0.0037398613058030605
Loss at iteration 1510 : 0.0041676415130496025
Loss at iteration 1520 : 0.007200314663350582
Loss at iteration 1530 : 0.012607773765921593
Loss at iteration 1540 : 0.014172768220305443
Loss at iteration 1550 : 0.009985766373574734
Loss at iteration 1560 : 0.006211508996784687
Loss at iteration 1570 : 0.00971919298171997
Loss at iteration 1580 : 0.01442762091755867
Loss at iteration 1590 : 0.012447189539670944
Loss at iteration 1600 : 0.017843157052993774
Loss at iteration 1610 : 0.008047150447964668
Loss at iteration 1620 : 0.004812126513570547
Loss at iteration 1630 : 0.003725941525772214
Loss at iteration 1640 : 0.014733259566128254
Loss at iteration 1650 : 0.006198300048708916
Loss at iteration 1660 : 0.007878800854086876
Loss at iteration 1670 : 0.00932510569691658
Loss at iteration 1680 : 0.008374245837330818
Loss at iteration 1690 : 0.008641119115054607
Loss at iteration 1700 : 0.015140898525714874
Loss at iteration 1710 : 0.007978684268891811
Loss at iteration 1720 : 0.019129956141114235
Loss at iteration 1730 : 0.007652537431567907
Loss at iteration 1740 : 0.02362537570297718
Loss at iteration 1750 : 0.014139251783490181
Loss at iteration 1760 : 0.012604441493749619
Loss at iteration 1770 : 0.0031621300149708986
Loss at iteration 1780 : 0.0037805039901286364
Loss at iteration 1790 : 0.014155295677483082
Loss at iteration 1800 : 0.012456854805350304
Loss at iteration 1810 : 0.004640678875148296
Loss at iteration 1820 : 0.018760060891509056
Loss at iteration 1830 : 0.02793724089860916
Loss at iteration 1840 : 0.020099572837352753
Loss at iteration 1850 : 0.010686575435101986
Loss at iteration 1860 : 0.008012690581381321
Loss at iteration 1870 : 0.0183113943785429
Loss at iteration 1880 : 0.013778477907180786
Loss at iteration 1890 : 0.021530132740736008
Loss at iteration 1900 : 0.025011764839291573
Loss at iteration 1910 : 0.009195154532790184
Loss at iteration 1920 : 0.004713665693998337
Loss at iteration 1930 : 0.009920045733451843
Loss at iteration 1940 : 0.009126516059041023
Loss at iteration 1950 : 0.009551629424095154
Loss at iteration 1960 : 0.022866161540150642
Loss at iteration 1970 : 0.013514108955860138
Loss at iteration 1980 : 0.006643540225923061
Loss at iteration 1990 : 0.013430822640657425
Loss at iteration 2000 : 0.007222956977784634
Loss at iteration 2010 : 0.003907087258994579
Loss at iteration 2020 : 0.01974819041788578
Loss at iteration 2030 : 0.005504492204636335
Loss at iteration 2040 : 0.006133975461125374
Loss at iteration 2050 : 0.012374239973723888
Loss at iteration 2060 : 0.018748465925455093
Loss at iteration 2070 : 0.024167820811271667
Loss at iteration 2080 : 0.006380198057740927
Loss at iteration 2090 : 0.015770353376865387
Loss at iteration 2100 : 0.007971970364451408
Loss at iteration 2110 : 0.0027992124669253826
Loss at iteration 2120 : 0.012499567121267319
Loss at iteration 2130 : 0.007854128256440163
Loss at iteration 2140 : 0.002934626303613186
Loss at iteration 2150 : 0.009838540107011795
Loss at iteration 2160 : 0.005404246039688587
Loss at iteration 2170 : 0.013610013760626316
Loss at iteration 2180 : 0.012699265964329243
Loss at iteration 2190 : 0.004118932876735926
Loss at iteration 2200 : 0.00978129543364048
Loss at iteration 2210 : 0.013444756157696247
Loss at iteration 2220 : 0.01394297368824482
Loss at iteration 2230 : 0.010789592750370502
Loss at iteration 2240 : 0.016321614384651184
Loss at iteration 2250 : 0.008585844188928604
Loss at iteration 2260 : 0.01187208853662014
Loss at iteration 2270 : 0.011820580810308456
Loss at iteration 2280 : 0.006242180243134499
Loss at iteration 2290 : 0.005144154187291861
Loss at iteration 2300 : 0.007878167554736137
Loss at iteration 2310 : 0.0033195007126778364
Loss at iteration 2320 : 0.0065923226065933704
Loss at iteration 2330 : 0.007944783195853233
Loss at iteration 2340 : 0.005390448030084372
Loss at iteration 2350 : 0.009539904072880745
Loss at iteration 2360 : 0.006756164599210024
Loss at iteration 2370 : 0.008230507373809814
Loss at iteration 2380 : 0.011436263099312782
Loss at iteration 2390 : 0.01317947544157505
Loss at iteration 2400 : 0.010579081252217293
Loss at iteration 2410 : 0.01802963577210903
Loss at iteration 2420 : 0.007403719238936901
The SSIM Value is: 0.8376814166704813
The PSNR Value is: 21.61649856567383
the epoch is: 58
Loss at iteration 10 : 0.013578769750893116
Loss at iteration 20 : 0.030847270041704178
Loss at iteration 30 : 0.008800193667411804
Loss at iteration 40 : 0.00949098914861679
Loss at iteration 50 : 0.011044674552977085
Loss at iteration 60 : 0.010232354514300823
Loss at iteration 70 : 0.0027884291484951973
Loss at iteration 80 : 0.008402271196246147
Loss at iteration 90 : 0.01071767695248127
Loss at iteration 100 : 0.009314749389886856
Loss at iteration 110 : 0.01767881214618683
Loss at iteration 120 : 0.010609135031700134
Loss at iteration 130 : 0.0087223956361413
Loss at iteration 140 : 0.012328632175922394
Loss at iteration 150 : 0.013011617586016655
Loss at iteration 160 : 0.011676288209855556
Loss at iteration 170 : 0.015527456998825073
Loss at iteration 180 : 0.019104499369859695
Loss at iteration 190 : 0.0068381610326468945
Loss at iteration 200 : 0.013157470151782036
Loss at iteration 210 : 0.006413585506379604
Loss at iteration 220 : 0.013204225338995457
Loss at iteration 230 : 0.008825301192700863
Loss at iteration 240 : 0.01823425479233265
Loss at iteration 250 : 0.009596023708581924
Loss at iteration 260 : 0.010320885106921196
Loss at iteration 270 : 0.003414125181734562
Loss at iteration 280 : 0.007159333676099777
Loss at iteration 290 : 0.008704404346644878
Loss at iteration 300 : 0.008983655832707882
Loss at iteration 310 : 0.011579975485801697
Loss at iteration 320 : 0.008239954710006714
Loss at iteration 330 : 0.013115810230374336
Loss at iteration 340 : 0.008095921948552132
Loss at iteration 350 : 0.008981057442724705
Loss at iteration 360 : 0.010714340955018997
Loss at iteration 370 : 0.010023139417171478
Loss at iteration 380 : 0.016450932249426842
Loss at iteration 390 : 0.006650479044765234
Loss at iteration 400 : 0.006623826455324888
Loss at iteration 410 : 0.014804479666054249
Loss at iteration 420 : 0.01225280575454235
Loss at iteration 430 : 0.017155148088932037
Loss at iteration 440 : 0.00680105434730649
Loss at iteration 450 : 0.010854091495275497
Loss at iteration 460 : 0.005775695666670799
Loss at iteration 470 : 0.011692158877849579
Loss at iteration 480 : 0.0035394616425037384
Loss at iteration 490 : 0.02043411321938038
Loss at iteration 500 : 0.025997988879680634
Loss at iteration 510 : 0.012701871804893017
Loss at iteration 520 : 0.010693944990634918
Loss at iteration 530 : 0.012806258164346218
Loss at iteration 540 : 0.015826616436243057
Loss at iteration 550 : 0.00986639317125082
Loss at iteration 560 : 0.019266817718744278
Loss at iteration 570 : 0.007840313017368317
Loss at iteration 580 : 0.016862867400050163
Loss at iteration 590 : 0.009143287315964699
Loss at iteration 600 : 0.012599986046552658
Loss at iteration 610 : 0.011903463862836361
Loss at iteration 620 : 0.00786174088716507
Loss at iteration 630 : 0.007588137406855822
Loss at iteration 640 : 0.015017643570899963
Loss at iteration 650 : 0.016813425347208977
Loss at iteration 660 : 0.005662520881742239
Loss at iteration 670 : 0.007521739229559898
Loss at iteration 680 : 0.009854929521679878
Loss at iteration 690 : 0.016625244170427322
Loss at iteration 700 : 0.007933036424219608
Loss at iteration 710 : 0.006331974640488625
Loss at iteration 720 : 0.007587874308228493
Loss at iteration 730 : 0.007693666499108076
Loss at iteration 740 : 0.0073262364603579044
Loss at iteration 750 : 0.007783009670674801
Loss at iteration 760 : 0.023808427155017853
Loss at iteration 770 : 0.006588551681488752
Loss at iteration 780 : 0.005409757141023874
Loss at iteration 790 : 0.010345973074436188
Loss at iteration 800 : 0.013099031522870064
Loss at iteration 810 : 0.010265649296343327
Loss at iteration 820 : 0.011089777573943138
Loss at iteration 830 : 0.015048054046928883
Loss at iteration 840 : 0.006664271932095289
Loss at iteration 850 : 0.004644048400223255
Loss at iteration 860 : 0.0131079675629735
Loss at iteration 870 : 0.00965988077223301
Loss at iteration 880 : 0.019278014078736305
Loss at iteration 890 : 0.014192923903465271
Loss at iteration 900 : 0.005346783436834812
Loss at iteration 910 : 0.009206713177263737
Loss at iteration 920 : 0.01009465754032135
Loss at iteration 930 : 0.00715665752068162
Loss at iteration 940 : 0.012153484858572483
Loss at iteration 950 : 0.017893247306346893
Loss at iteration 960 : 0.012747918255627155
Loss at iteration 970 : 0.013816747814416885
Loss at iteration 980 : 0.015010800212621689
Loss at iteration 990 : 0.011295480653643608
Loss at iteration 1000 : 0.018325403332710266
Loss at iteration 1010 : 0.009173784404993057
Loss at iteration 1020 : 0.011232862249016762
Loss at iteration 1030 : 0.010337747633457184
Loss at iteration 1040 : 0.008663544431328773
Loss at iteration 1050 : 0.011010202579200268
Loss at iteration 1060 : 0.01435745321214199
Loss at iteration 1070 : 0.011700277216732502
Loss at iteration 1080 : 0.01003965549170971
Loss at iteration 1090 : 0.006392250303179026
Loss at iteration 1100 : 0.008872942999005318
Loss at iteration 1110 : 0.009695427492260933
Loss at iteration 1120 : 0.007169086951762438
Loss at iteration 1130 : 0.007568608038127422
Loss at iteration 1140 : 0.015609378926455975
Loss at iteration 1150 : 0.0075492821633815765
Loss at iteration 1160 : 0.008079749532043934
Loss at iteration 1170 : 0.01305355317890644
Loss at iteration 1180 : 0.017138034105300903
Loss at iteration 1190 : 0.004100517835468054
Loss at iteration 1200 : 0.006190482992678881
Loss at iteration 1210 : 0.011603830382227898
Loss at iteration 1220 : 0.007566685788333416
Loss at iteration 1230 : 0.007853088900446892
Loss at iteration 1240 : 0.021695487201213837
Loss at iteration 1250 : 0.01144449319690466
Loss at iteration 1260 : 0.011428583413362503
Loss at iteration 1270 : 0.008879756554961205
Loss at iteration 1280 : 0.005876603536307812
Loss at iteration 1290 : 0.01546570099890232
Loss at iteration 1300 : 0.012768944725394249
Loss at iteration 1310 : 0.016509342938661575
Loss at iteration 1320 : 0.01139030046761036
Loss at iteration 1330 : 0.003467640606686473
Loss at iteration 1340 : 0.007902096956968307
Loss at iteration 1350 : 0.021113321185112
Loss at iteration 1360 : 0.012398851104080677
Loss at iteration 1370 : 0.010273430496454239
Loss at iteration 1380 : 0.010489318519830704
Loss at iteration 1390 : 0.00895300880074501
Loss at iteration 1400 : 0.007681042421609163
Loss at iteration 1410 : 0.013414292596280575
Loss at iteration 1420 : 0.016675669699907303
Loss at iteration 1430 : 0.00802194606512785
Loss at iteration 1440 : 0.014616960659623146
Loss at iteration 1450 : 0.0121941938996315
Loss at iteration 1460 : 0.008162388578057289
Loss at iteration 1470 : 0.008707430213689804
Loss at iteration 1480 : 0.007679386995732784
Loss at iteration 1490 : 0.006565137766301632
Loss at iteration 1500 : 0.012304491363465786
Loss at iteration 1510 : 0.01740068383514881
Loss at iteration 1520 : 0.010281986556947231
Loss at iteration 1530 : 0.007778084836900234
Loss at iteration 1540 : 0.01462390273809433
Loss at iteration 1550 : 0.010921156965196133
Loss at iteration 1560 : 0.007833785377442837
Loss at iteration 1570 : 0.013125847093760967
Loss at iteration 1580 : 0.004920812323689461
Loss at iteration 1590 : 0.03128022700548172
Loss at iteration 1600 : 0.009520460851490498
Loss at iteration 1610 : 0.016560066491365433
Loss at iteration 1620 : 0.014842619188129902
Loss at iteration 1630 : 0.006859952583909035
Loss at iteration 1640 : 0.017126865684986115
Loss at iteration 1650 : 0.006995115429162979
Loss at iteration 1660 : 0.008851587772369385
Loss at iteration 1670 : 0.01100226677954197
Loss at iteration 1680 : 0.005560222081840038
Loss at iteration 1690 : 0.007685438264161348
Loss at iteration 1700 : 0.007983866147696972
Loss at iteration 1710 : 0.008980339393019676
Loss at iteration 1720 : 0.006304945796728134
Loss at iteration 1730 : 0.007430222351104021
Loss at iteration 1740 : 0.006334110163152218
Loss at iteration 1750 : 0.020163128152489662
Loss at iteration 1760 : 0.008909830823540688
Loss at iteration 1770 : 0.013688037171959877
Loss at iteration 1780 : 0.022213244810700417
Loss at iteration 1790 : 0.014511452987790108
Loss at iteration 1800 : 0.006830123718827963
Loss at iteration 1810 : 0.010102197527885437
Loss at iteration 1820 : 0.019128287211060524
Loss at iteration 1830 : 0.0076348320581018925
Loss at iteration 1840 : 0.02038540691137314
Loss at iteration 1850 : 0.014339784160256386
Loss at iteration 1860 : 0.006902159191668034
Loss at iteration 1870 : 0.011349096894264221
Loss at iteration 1880 : 0.008721062913537025
Loss at iteration 1890 : 0.019871477037668228
Loss at iteration 1900 : 0.006846442818641663
Loss at iteration 1910 : 0.008790331892669201
Loss at iteration 1920 : 0.006878037936985493
Loss at iteration 1930 : 0.012939244508743286
Loss at iteration 1940 : 0.007370084524154663
Loss at iteration 1950 : 0.004090516362339258
Loss at iteration 1960 : 0.007510158233344555
Loss at iteration 1970 : 0.008071964606642723
Loss at iteration 1980 : 0.007808490190654993
Loss at iteration 1990 : 0.008804739452898502
Loss at iteration 2000 : 0.004607784561812878
Loss at iteration 2010 : 0.009611056186258793
Loss at iteration 2020 : 0.0073794350028038025
Loss at iteration 2030 : 0.005226918496191502
Loss at iteration 2040 : 0.009447833523154259
Loss at iteration 2050 : 0.01299646683037281
Loss at iteration 2060 : 0.005200590007007122
Loss at iteration 2070 : 0.006924549117684364
Loss at iteration 2080 : 0.00757273193448782
Loss at iteration 2090 : 0.013001533225178719
Loss at iteration 2100 : 0.008372057229280472
Loss at iteration 2110 : 0.004354764707386494
Loss at iteration 2120 : 0.01384964119642973
Loss at iteration 2130 : 0.008531262166798115
Loss at iteration 2140 : 0.015537244267761707
Loss at iteration 2150 : 0.0072850389406085014
Loss at iteration 2160 : 0.032872386276721954
Loss at iteration 2170 : 0.006143870763480663
Loss at iteration 2180 : 0.012290215119719505
Loss at iteration 2190 : 0.005419288761913776
Loss at iteration 2200 : 0.007763574365526438
Loss at iteration 2210 : 0.004657441284507513
Loss at iteration 2220 : 0.012424563989043236
Loss at iteration 2230 : 0.006866290234029293
Loss at iteration 2240 : 0.008279280737042427
Loss at iteration 2250 : 0.008108160458505154
Loss at iteration 2260 : 0.011836477555334568
Loss at iteration 2270 : 0.01325641293078661
Loss at iteration 2280 : 0.02567199058830738
Loss at iteration 2290 : 0.015634994953870773
Loss at iteration 2300 : 0.013509431853890419
Loss at iteration 2310 : 0.004381207749247551
Loss at iteration 2320 : 0.012574349530041218
Loss at iteration 2330 : 0.020134227350354195
Loss at iteration 2340 : 0.015151286497712135
Loss at iteration 2350 : 0.011838030070066452
Loss at iteration 2360 : 0.010952792130410671
Loss at iteration 2370 : 0.010990310460329056
Loss at iteration 2380 : 0.004812923725694418
Loss at iteration 2390 : 0.002194702159613371
Loss at iteration 2400 : 0.007191891316324472
Loss at iteration 2410 : 0.008337733335793018
Loss at iteration 2420 : 0.005024118348956108
The SSIM Value is: 0.8403210520744324
The PSNR Value is: 21.702440579732258
the epoch is: 59
Loss at iteration 10 : 0.008305663242936134
Loss at iteration 20 : 0.009369615465402603
Loss at iteration 30 : 0.025717664510011673
Loss at iteration 40 : 0.006539500318467617
Loss at iteration 50 : 0.008129468187689781
Loss at iteration 60 : 0.022467652335762978
Loss at iteration 70 : 0.007776364218443632
Loss at iteration 80 : 0.01109618041664362
Loss at iteration 90 : 0.010525040328502655
Loss at iteration 100 : 0.011672401800751686
Loss at iteration 110 : 0.007298672571778297
Loss at iteration 120 : 0.010342457331717014
Loss at iteration 130 : 0.008597212843596935
Loss at iteration 140 : 0.016186662018299103
Loss at iteration 150 : 0.010942748747766018
Loss at iteration 160 : 0.017886502668261528
Loss at iteration 170 : 0.024973800405859947
Loss at iteration 180 : 0.00893482193350792
Loss at iteration 190 : 0.017514238134026527
Loss at iteration 200 : 0.006616674829274416
Loss at iteration 210 : 0.011144593358039856
Loss at iteration 220 : 0.012400566600263119
Loss at iteration 230 : 0.00826371368020773
Loss at iteration 240 : 0.00645252363756299
Loss at iteration 250 : 0.013344588689506054
Loss at iteration 260 : 0.017162788659334183
Loss at iteration 270 : 0.009829459711909294
Loss at iteration 280 : 0.014640958048403263
Loss at iteration 290 : 0.018365994095802307
Loss at iteration 300 : 0.013869959861040115
Loss at iteration 310 : 0.005923460237681866
Loss at iteration 320 : 0.007975295186042786
Loss at iteration 330 : 0.008436836302280426
Loss at iteration 340 : 0.010378707200288773
Loss at iteration 350 : 0.005239352583885193
Loss at iteration 360 : 0.003965918906033039
Loss at iteration 370 : 0.005093230400234461
Loss at iteration 380 : 0.009074775502085686
Loss at iteration 390 : 0.007313837762922049
Loss at iteration 400 : 0.008378185331821442
Loss at iteration 410 : 0.010248759761452675
Loss at iteration 420 : 0.008992474526166916
Loss at iteration 430 : 0.0079478919506073
Loss at iteration 440 : 0.0085682962089777
Loss at iteration 450 : 0.010394211858510971
Loss at iteration 460 : 0.010278711095452309
Loss at iteration 470 : 0.008579960092902184
Loss at iteration 480 : 0.010933163575828075
Loss at iteration 490 : 0.008358893916010857
Loss at iteration 500 : 0.01218305341899395
Loss at iteration 510 : 0.017320003360509872
Loss at iteration 520 : 0.003942341543734074
Loss at iteration 530 : 0.010782171040773392
Loss at iteration 540 : 0.011615676805377007
Loss at iteration 550 : 0.0150133753195405
Loss at iteration 560 : 0.010947157628834248
Loss at iteration 570 : 0.008154969662427902
Loss at iteration 580 : 0.015514889732003212
Loss at iteration 590 : 0.008510773070156574
Loss at iteration 600 : 0.012759414501488209
Loss at iteration 610 : 0.012730991467833519
Loss at iteration 620 : 0.004540544934570789
Loss at iteration 630 : 0.013351638801395893
Loss at iteration 640 : 0.00783579982817173
Loss at iteration 650 : 0.009878134354948997
Loss at iteration 660 : 0.012445040047168732
Loss at iteration 670 : 0.008733894675970078
Loss at iteration 680 : 0.01025485247373581
Loss at iteration 690 : 0.012068711221218109
Loss at iteration 700 : 0.01018807664513588
Loss at iteration 710 : 0.008308609947562218
Loss at iteration 720 : 0.013813075609505177
Loss at iteration 730 : 0.01750352792441845
Loss at iteration 740 : 0.008109120652079582
Loss at iteration 750 : 0.005768569186329842
Loss at iteration 760 : 0.007596036419272423
Loss at iteration 770 : 0.010251004248857498
Loss at iteration 780 : 0.01439946424216032
Loss at iteration 790 : 0.004383435472846031
Loss at iteration 800 : 0.009805668145418167
Loss at iteration 810 : 0.019811443984508514
Loss at iteration 820 : 0.010433795861899853
Loss at iteration 830 : 0.01167073380202055
Loss at iteration 840 : 0.006624480243772268
Loss at iteration 850 : 0.008190000429749489
Loss at iteration 860 : 0.013049094937741756
Loss at iteration 870 : 0.009405945427715778
Loss at iteration 880 : 0.010453273542225361
Loss at iteration 890 : 0.013351980596780777
Loss at iteration 900 : 0.005797986872494221
Loss at iteration 910 : 0.00569191062822938
Loss at iteration 920 : 0.006525506265461445
Loss at iteration 930 : 0.016825344413518906
Loss at iteration 940 : 0.007449283264577389
Loss at iteration 950 : 0.006311221048235893
Loss at iteration 960 : 0.009554628282785416
Loss at iteration 970 : 0.019517969340085983
Loss at iteration 980 : 0.0043991850689053535
Loss at iteration 990 : 0.009183269925415516
Loss at iteration 1000 : 0.012559344060719013
Loss at iteration 1010 : 0.007548837922513485
Loss at iteration 1020 : 0.0048624263145029545
Loss at iteration 1030 : 0.008769642561674118
Loss at iteration 1040 : 0.029889993369579315
Loss at iteration 1050 : 0.013596061617136002
Loss at iteration 1060 : 0.00617267144843936
Loss at iteration 1070 : 0.014016336761415005
Loss at iteration 1080 : 0.00618821382522583
Loss at iteration 1090 : 0.009980151429772377
Loss at iteration 1100 : 0.006317206658422947
Loss at iteration 1110 : 0.03267654776573181
Loss at iteration 1120 : 0.017241468653082848
Loss at iteration 1130 : 0.008294530212879181
Loss at iteration 1140 : 0.0043818149715662
Loss at iteration 1150 : 0.006656249985098839
Loss at iteration 1160 : 0.008002202957868576
Loss at iteration 1170 : 0.005031147506088018
Loss at iteration 1180 : 0.005059693939983845
Loss at iteration 1190 : 0.0061090197414159775
Loss at iteration 1200 : 0.003506696317344904
Loss at iteration 1210 : 0.008448449894785881
Loss at iteration 1220 : 0.006340647581964731
Loss at iteration 1230 : 0.005671157501637936
Loss at iteration 1240 : 0.004446919076144695
Loss at iteration 1250 : 0.018343942239880562
Loss at iteration 1260 : 0.004689900204539299
Loss at iteration 1270 : 0.004446522332727909
Loss at iteration 1280 : 0.007405741605907679
Loss at iteration 1290 : 0.00642727967351675
Loss at iteration 1300 : 0.00820507574826479
Loss at iteration 1310 : 0.009854994714260101
Loss at iteration 1320 : 0.03893691673874855
Loss at iteration 1330 : 0.012732931412756443
Loss at iteration 1340 : 0.011599157005548477
Loss at iteration 1350 : 0.01274957973510027
Loss at iteration 1360 : 0.0039412821643054485
Loss at iteration 1370 : 0.012438369914889336
Loss at iteration 1380 : 0.007504244334995747
Loss at iteration 1390 : 0.01682605966925621
Loss at iteration 1400 : 0.00880526378750801
Loss at iteration 1410 : 0.0033993450924754143
Loss at iteration 1420 : 0.006671625189483166
Loss at iteration 1430 : 0.006818525493144989
Loss at iteration 1440 : 0.0036355648189783096
Loss at iteration 1450 : 0.005394311621785164
Loss at iteration 1460 : 0.0061183469370007515
Loss at iteration 1470 : 0.007932140491902828
Loss at iteration 1480 : 0.013019911013543606
Loss at iteration 1490 : 0.005891905631870031
Loss at iteration 1500 : 0.007286255247890949
Loss at iteration 1510 : 0.014711013063788414
Loss at iteration 1520 : 0.014901408925652504
Loss at iteration 1530 : 0.005572802387177944
Loss at iteration 1540 : 0.006569894962012768
Loss at iteration 1550 : 0.006845225114375353
Loss at iteration 1560 : 0.010358372703194618
Loss at iteration 1570 : 0.0104664396494627
Loss at iteration 1580 : 0.012667396105825901
Loss at iteration 1590 : 0.011168407276272774
Loss at iteration 1600 : 0.004903017543256283
Loss at iteration 1610 : 0.006460045929998159
Loss at iteration 1620 : 0.014566757716238499
Loss at iteration 1630 : 0.011936480179429054
Loss at iteration 1640 : 0.007963722571730614
Loss at iteration 1650 : 0.004090412054210901
Loss at iteration 1660 : 0.008343375287950039
Loss at iteration 1670 : 0.011874540708959103
Loss at iteration 1680 : 0.012004513293504715
Loss at iteration 1690 : 0.0070236194878816605
Loss at iteration 1700 : 0.012050172314047813
Loss at iteration 1710 : 0.005018381867557764
Loss at iteration 1720 : 0.006158164236694574
Loss at iteration 1730 : 0.007162218913435936
Loss at iteration 1740 : 0.011057490482926369
Loss at iteration 1750 : 0.012898985296487808
Loss at iteration 1760 : 0.011206170544028282
Loss at iteration 1770 : 0.00968814454972744
Loss at iteration 1780 : 0.007369032595306635
Loss at iteration 1790 : 0.01074700802564621
Loss at iteration 1800 : 0.007085357327014208
Loss at iteration 1810 : 0.011351070366799831
Loss at iteration 1820 : 0.010962730273604393
Loss at iteration 1830 : 0.010295412503182888
Loss at iteration 1840 : 0.008687651716172695
Loss at iteration 1850 : 0.013655348680913448
Loss at iteration 1860 : 0.008554266765713692
Loss at iteration 1870 : 0.006554764229804277
Loss at iteration 1880 : 0.012175602838397026
Loss at iteration 1890 : 0.006878561805933714
Loss at iteration 1900 : 0.011969939805567265
Loss at iteration 1910 : 0.004284074530005455
Loss at iteration 1920 : 0.015179969370365143
Loss at iteration 1930 : 0.018967242911458015
Loss at iteration 1940 : 0.00804092176258564
Loss at iteration 1950 : 0.011445235460996628
Loss at iteration 1960 : 0.006448167376220226
Loss at iteration 1970 : 0.005876270588487387
Loss at iteration 1980 : 0.0055892374366521835
Loss at iteration 1990 : 0.011798614636063576
Loss at iteration 2000 : 0.007011163979768753
Loss at iteration 2010 : 0.007579409051686525
Loss at iteration 2020 : 0.011471359990537167
Loss at iteration 2030 : 0.006850969046354294
Loss at iteration 2040 : 0.015651177614927292
Loss at iteration 2050 : 0.00852449145168066
Loss at iteration 2060 : 0.0037306821905076504
Loss at iteration 2070 : 0.018511997535824776
Loss at iteration 2080 : 0.005521127954125404
Loss at iteration 2090 : 0.01254841685295105
Loss at iteration 2100 : 0.011080242693424225
Loss at iteration 2110 : 0.0043238261714577675
Loss at iteration 2120 : 0.014044656418263912
Loss at iteration 2130 : 0.013682711869478226
Loss at iteration 2140 : 0.02158200368285179
Loss at iteration 2150 : 0.031610894948244095
Loss at iteration 2160 : 0.009974360466003418
Loss at iteration 2170 : 0.008785455487668514
Loss at iteration 2180 : 0.009368178434669971
Loss at iteration 2190 : 0.008121365681290627
Loss at iteration 2200 : 0.003962462302297354
Loss at iteration 2210 : 0.00785115733742714
Loss at iteration 2220 : 0.009238315746188164
Loss at iteration 2230 : 0.01358385756611824
Loss at iteration 2240 : 0.009480755776166916
Loss at iteration 2250 : 0.010841043666005135
Loss at iteration 2260 : 0.014067484065890312
Loss at iteration 2270 : 0.009182730689644814
Loss at iteration 2280 : 0.008532539941370487
Loss at iteration 2290 : 0.011657506227493286
Loss at iteration 2300 : 0.008774085901677608
Loss at iteration 2310 : 0.010956110432744026
Loss at iteration 2320 : 0.007847916334867477
Loss at iteration 2330 : 0.004656476899981499
Loss at iteration 2340 : 0.007257851306349039
Loss at iteration 2350 : 0.011426819488406181
Loss at iteration 2360 : 0.005227761808782816
Loss at iteration 2370 : 0.005537150427699089
Loss at iteration 2380 : 0.007509562652558088
Loss at iteration 2390 : 0.009394470602273941
Loss at iteration 2400 : 0.005276711657643318
Loss at iteration 2410 : 0.010491103865206242
Loss at iteration 2420 : 0.010770520195364952
The SSIM Value is: 0.841224221388499
The PSNR Value is: 22.101614316304524
the epoch is: 60
Loss at iteration 10 : 0.003483137348666787
Loss at iteration 20 : 0.007989326491951942
Loss at iteration 30 : 0.005120484158396721
Loss at iteration 40 : 0.008297927677631378
Loss at iteration 50 : 0.013600379228591919
Loss at iteration 60 : 0.005564169958233833
Loss at iteration 70 : 0.006605370901525021
Loss at iteration 80 : 0.014218170195817947
Loss at iteration 90 : 0.006315091159194708
Loss at iteration 100 : 0.0037490944378077984
Loss at iteration 110 : 0.006991841364651918
Loss at iteration 120 : 0.0029579470865428448
Loss at iteration 130 : 0.019243882969021797
Loss at iteration 140 : 0.008621497079730034
Loss at iteration 150 : 0.008976507000625134
Loss at iteration 160 : 0.007049194537103176
Loss at iteration 170 : 0.01224491186439991
Loss at iteration 180 : 0.015038209035992622
Loss at iteration 190 : 0.01597498171031475
Loss at iteration 200 : 0.012360273860394955
Loss at iteration 210 : 0.009307391941547394
Loss at iteration 220 : 0.012665576301515102
Loss at iteration 230 : 0.011354471556842327
Loss at iteration 240 : 0.00667673209682107
Loss at iteration 250 : 0.022706788033246994
Loss at iteration 260 : 0.006063432432711124
Loss at iteration 270 : 0.005325315520167351
Loss at iteration 280 : 0.01904677413403988
Loss at iteration 290 : 0.014957215636968613
Loss at iteration 300 : 0.012093515135347843
Loss at iteration 310 : 0.010726505890488625
Loss at iteration 320 : 0.018894394859671593
Loss at iteration 330 : 0.011460110545158386
Loss at iteration 340 : 0.009909517131745815
Loss at iteration 350 : 0.0076292105950415134
Loss at iteration 360 : 0.008891971781849861
Loss at iteration 370 : 0.012340893968939781
Loss at iteration 380 : 0.004298590589314699
Loss at iteration 390 : 0.01141442358493805
Loss at iteration 400 : 0.011849426664412022
Loss at iteration 410 : 0.01476874016225338
Loss at iteration 420 : 0.009075438603758812
Loss at iteration 430 : 0.013383058831095695
Loss at iteration 440 : 0.0105109428986907
Loss at iteration 450 : 0.007527467794716358
Loss at iteration 460 : 0.0028838105499744415
Loss at iteration 470 : 0.013173962943255901
Loss at iteration 480 : 0.014233754947781563
Loss at iteration 490 : 0.002673931187018752
Loss at iteration 500 : 0.008698748424649239
Loss at iteration 510 : 0.013609720394015312
Loss at iteration 520 : 0.007912475615739822
Loss at iteration 530 : 0.012103472836315632
Loss at iteration 540 : 0.017917290329933167
Loss at iteration 550 : 0.015179263427853584
Loss at iteration 560 : 0.007119148038327694
Loss at iteration 570 : 0.006552889011800289
Loss at iteration 580 : 0.008396698161959648
Loss at iteration 590 : 0.010526353493332863
Loss at iteration 600 : 0.007096745073795319
Loss at iteration 610 : 0.00973665714263916
Loss at iteration 620 : 0.0088425287976861
Loss at iteration 630 : 0.007936089299619198
Loss at iteration 640 : 0.007633586414158344
Loss at iteration 650 : 0.011012088507413864
Loss at iteration 660 : 0.01079206820577383
Loss at iteration 670 : 0.011843426153063774
Loss at iteration 680 : 0.018386920914053917
Loss at iteration 690 : 0.01549435593187809
Loss at iteration 700 : 0.008552956394851208
Loss at iteration 710 : 0.014250226318836212
Loss at iteration 720 : 0.021737659350037575
Loss at iteration 730 : 0.003072082996368408
Loss at iteration 740 : 0.009066568687558174
Loss at iteration 750 : 0.005397165194153786
Loss at iteration 760 : 0.005200112238526344
Loss at iteration 770 : 0.016520177945494652
Loss at iteration 780 : 0.013884052634239197
Loss at iteration 790 : 0.010868989862501621
Loss at iteration 800 : 0.008254816755652428
Loss at iteration 810 : 0.008714674040675163
Loss at iteration 820 : 0.00964692234992981
Loss at iteration 830 : 0.008262588642537594
Loss at iteration 840 : 0.006410820409655571
Loss at iteration 850 : 0.010583163239061832
Loss at iteration 860 : 0.021042637526988983
Loss at iteration 870 : 0.012596354819834232
Loss at iteration 880 : 0.002708730986341834
Loss at iteration 890 : 0.016669731587171555
Loss at iteration 900 : 0.007571524940431118
Loss at iteration 910 : 0.01009801123291254
Loss at iteration 920 : 0.01279173418879509
Loss at iteration 930 : 0.014138718135654926
Loss at iteration 940 : 0.010545996949076653
Loss at iteration 950 : 0.012019067071378231
Loss at iteration 960 : 0.007349167950451374
Loss at iteration 970 : 0.007791711948812008
Loss at iteration 980 : 0.02292853221297264
Loss at iteration 990 : 0.008876743726432323
Loss at iteration 1000 : 0.012745615094900131
Loss at iteration 1010 : 0.022537607699632645
Loss at iteration 1020 : 0.007906756363809109
Loss at iteration 1030 : 0.005906577687710524
Loss at iteration 1040 : 0.006081339903175831
Loss at iteration 1050 : 0.007304151076823473
Loss at iteration 1060 : 0.011221589520573616
Loss at iteration 1070 : 0.006832437589764595
Loss at iteration 1080 : 0.005842972546815872
Loss at iteration 1090 : 0.007568731904029846
Loss at iteration 1100 : 0.010557477362453938
Loss at iteration 1110 : 0.00874430313706398
Loss at iteration 1120 : 0.010751249268651009
Loss at iteration 1130 : 0.00845032837241888
Loss at iteration 1140 : 0.009619717486202717
Loss at iteration 1150 : 0.0053415121510624886
Loss at iteration 1160 : 0.00940751563757658
Loss at iteration 1170 : 0.008672558702528477
Loss at iteration 1180 : 0.004201670177280903
Loss at iteration 1190 : 0.008266780525445938
Loss at iteration 1200 : 0.009256776422262192
Loss at iteration 1210 : 0.011063266545534134
Loss at iteration 1220 : 0.004001669120043516
Loss at iteration 1230 : 0.010359997861087322
Loss at iteration 1240 : 0.007440343499183655
Loss at iteration 1250 : 0.01660750061273575
Loss at iteration 1260 : 0.005196450278162956
Loss at iteration 1270 : 0.005436430685222149
Loss at iteration 1280 : 0.012676483020186424
Loss at iteration 1290 : 0.010077083483338356
Loss at iteration 1300 : 0.004859739914536476
Loss at iteration 1310 : 0.006497240159660578
Loss at iteration 1320 : 0.006863684393465519
Loss at iteration 1330 : 0.009041822515428066
Loss at iteration 1340 : 0.0036742882803082466
Loss at iteration 1350 : 0.008038862608373165
Loss at iteration 1360 : 0.008403926156461239
Loss at iteration 1370 : 0.007864642888307571
Loss at iteration 1380 : 0.008848100900650024
Loss at iteration 1390 : 0.008090787567198277
Loss at iteration 1400 : 0.007940538227558136
Loss at iteration 1410 : 0.013911359012126923
Loss at iteration 1420 : 0.003457987681031227
Loss at iteration 1430 : 0.020753949880599976
Loss at iteration 1440 : 0.008699335157871246
Loss at iteration 1450 : 0.009724571369588375
Loss at iteration 1460 : 0.014128068462014198
Loss at iteration 1470 : 0.008905009366571903
Loss at iteration 1480 : 0.007879579439759254
Loss at iteration 1490 : 0.012776289135217667
Loss at iteration 1500 : 0.008303280919790268
Loss at iteration 1510 : 0.008775444701313972
Loss at iteration 1520 : 0.00669084582477808
Loss at iteration 1530 : 0.005172909237444401
Loss at iteration 1540 : 0.012678274884819984
Loss at iteration 1550 : 0.0035932862665504217
Loss at iteration 1560 : 0.013196161948144436
Loss at iteration 1570 : 0.020833240821957588
Loss at iteration 1580 : 0.0021442945580929518
Loss at iteration 1590 : 0.010244714096188545
Loss at iteration 1600 : 0.004449944011867046
Loss at iteration 1610 : 0.0070429337210953236
Loss at iteration 1620 : 0.0065390607342123985
Loss at iteration 1630 : 0.01684139296412468
Loss at iteration 1640 : 0.01361891720443964
Loss at iteration 1650 : 0.011130276136100292
Loss at iteration 1660 : 0.007094335276633501
Loss at iteration 1670 : 0.004095239564776421
Loss at iteration 1680 : 0.008014623075723648
Loss at iteration 1690 : 0.008723950013518333
Loss at iteration 1700 : 0.00875336304306984
Loss at iteration 1710 : 0.01962750218808651
Loss at iteration 1720 : 0.007359395269304514
Loss at iteration 1730 : 0.008091537281870842
Loss at iteration 1740 : 0.004809113685041666
Loss at iteration 1750 : 0.011850361712276936
Loss at iteration 1760 : 0.011184332892298698
Loss at iteration 1770 : 0.007485656533390284
Loss at iteration 1780 : 0.013216963037848473
Loss at iteration 1790 : 0.011055655777454376
Loss at iteration 1800 : 0.010161333717405796
Loss at iteration 1810 : 0.018759187310934067
Loss at iteration 1820 : 0.0077379061840474606
Loss at iteration 1830 : 0.013107849285006523
Loss at iteration 1840 : 0.004096925258636475
Loss at iteration 1850 : 0.013744908384978771
Loss at iteration 1860 : 0.007596934214234352
Loss at iteration 1870 : 0.003445266978815198
Loss at iteration 1880 : 0.007345972117036581
Loss at iteration 1890 : 0.007271332200616598
Loss at iteration 1900 : 0.0072323475033044815
Loss at iteration 1910 : 0.011666314676404
Loss at iteration 1920 : 0.014851514250040054
Loss at iteration 1930 : 0.011237949132919312
Loss at iteration 1940 : 0.005048505496233702
Loss at iteration 1950 : 0.004906094167381525
Loss at iteration 1960 : 0.014721987769007683
Loss at iteration 1970 : 0.01667957194149494
Loss at iteration 1980 : 0.005405397154390812
Loss at iteration 1990 : 0.00991789624094963
Loss at iteration 2000 : 0.012648622505366802
Loss at iteration 2010 : 0.007837535813450813
Loss at iteration 2020 : 0.0065073599107563496
Loss at iteration 2030 : 0.006954360753297806
Loss at iteration 2040 : 0.004594678990542889
Loss at iteration 2050 : 0.006698519457131624
Loss at iteration 2060 : 0.00840467307716608
Loss at iteration 2070 : 0.013354821130633354
Loss at iteration 2080 : 0.010455571115016937
Loss at iteration 2090 : 0.015879042446613312
Loss at iteration 2100 : 0.006094526499509811
Loss at iteration 2110 : 0.02125798538327217
Loss at iteration 2120 : 0.005125049035996199
Loss at iteration 2130 : 0.010958770290017128
Loss at iteration 2140 : 0.02179696038365364
Loss at iteration 2150 : 0.016175448894500732
Loss at iteration 2160 : 0.004712165333330631
Loss at iteration 2170 : 0.011286603286862373
Loss at iteration 2180 : 0.013590777292847633
Loss at iteration 2190 : 0.00949346274137497
Loss at iteration 2200 : 0.009399292059242725
Loss at iteration 2210 : 0.014691382646560669
Loss at iteration 2220 : 0.0030776606872677803
Loss at iteration 2230 : 0.011131616309285164
Loss at iteration 2240 : 0.011492401361465454
Loss at iteration 2250 : 0.010355069302022457
Loss at iteration 2260 : 0.00859525054693222
Loss at iteration 2270 : 0.009842507541179657
Loss at iteration 2280 : 0.011063787154853344
Loss at iteration 2290 : 0.012638915330171585
Loss at iteration 2300 : 0.0074812909588217735
Loss at iteration 2310 : 0.009274402633309364
Loss at iteration 2320 : 0.00760630052536726
Loss at iteration 2330 : 0.013157603330910206
Loss at iteration 2340 : 0.008052390068769455
Loss at iteration 2350 : 0.012975817546248436
Loss at iteration 2360 : 0.019583504647016525
Loss at iteration 2370 : 0.011338401585817337
Loss at iteration 2380 : 0.005911809392273426
Loss at iteration 2390 : 0.008649585768580437
Loss at iteration 2400 : 0.014067662879824638
Loss at iteration 2410 : 0.0073521495796740055
Loss at iteration 2420 : 0.012497342191636562
The SSIM Value is: 0.8362502654393514
The PSNR Value is: 21.598702049255373
the epoch is: 61
Loss at iteration 10 : 0.011680599302053452
Loss at iteration 20 : 0.009620869532227516
Loss at iteration 30 : 0.016156453639268875
Loss at iteration 40 : 0.011773974634706974
Loss at iteration 50 : 0.003223913488909602
Loss at iteration 60 : 0.010072289034724236
Loss at iteration 70 : 0.012276590801775455
Loss at iteration 80 : 0.006471267435699701
Loss at iteration 90 : 0.0055495379492640495
Loss at iteration 100 : 0.009789913892745972
Loss at iteration 110 : 0.012297997251152992
Loss at iteration 120 : 0.016384998336434364
Loss at iteration 130 : 0.006401511840522289
Loss at iteration 140 : 0.007685528602451086
Loss at iteration 150 : 0.004744488745927811
Loss at iteration 160 : 0.007853413000702858
Loss at iteration 170 : 0.007912839762866497
Loss at iteration 180 : 0.025466429069638252
Loss at iteration 190 : 0.007500945124775171
Loss at iteration 200 : 0.011721749790012836
Loss at iteration 210 : 0.008104708045721054
Loss at iteration 220 : 0.024418292567133904
Loss at iteration 230 : 0.008229927159845829
Loss at iteration 240 : 0.0075050825253129005
Loss at iteration 250 : 0.0026762967463582754
Loss at iteration 260 : 0.004285853821784258
Loss at iteration 270 : 0.008771209977567196
Loss at iteration 280 : 0.008805189281702042
Loss at iteration 290 : 0.015262340195477009
Loss at iteration 300 : 0.01117042824625969
Loss at iteration 310 : 0.0076454440131783485
Loss at iteration 320 : 0.009161597117781639
Loss at iteration 330 : 0.007288658060133457
Loss at iteration 340 : 0.008743783459067345
Loss at iteration 350 : 0.00963347963988781
Loss at iteration 360 : 0.010724815540015697
Loss at iteration 370 : 0.005150485783815384
Loss at iteration 380 : 0.02148820273578167
Loss at iteration 390 : 0.006263997871428728
Loss at iteration 400 : 0.005078219808638096
Loss at iteration 410 : 0.01494741439819336
Loss at iteration 420 : 0.0102915083989501
Loss at iteration 430 : 0.008594168350100517
Loss at iteration 440 : 0.006402189377695322
Loss at iteration 450 : 0.009373581036925316
Loss at iteration 460 : 0.014160901308059692
Loss at iteration 470 : 0.007531646639108658
Loss at iteration 480 : 0.011403458192944527
Loss at iteration 490 : 0.00685427151620388
Loss at iteration 500 : 0.01763041689991951
Loss at iteration 510 : 0.011263514868915081
Loss at iteration 520 : 0.0048600658774375916
Loss at iteration 530 : 0.02015257254242897
Loss at iteration 540 : 0.007738851942121983
Loss at iteration 550 : 0.009813182055950165
Loss at iteration 560 : 0.013309920206665993
Loss at iteration 570 : 0.015644073486328125
Loss at iteration 580 : 0.009002989158034325
Loss at iteration 590 : 0.01838161051273346
Loss at iteration 600 : 0.011772796511650085
Loss at iteration 610 : 0.010792694985866547
Loss at iteration 620 : 0.009292921051383018
Loss at iteration 630 : 0.005431243218481541
Loss at iteration 640 : 0.006033030338585377
Loss at iteration 650 : 0.0048758541233837605
Loss at iteration 660 : 0.003287947503849864
Loss at iteration 670 : 0.01331162266433239
Loss at iteration 680 : 0.0026691914536058903
Loss at iteration 690 : 0.010963857173919678
Loss at iteration 700 : 0.011297095566987991
Loss at iteration 710 : 0.004557731095701456
Loss at iteration 720 : 0.005374668166041374
Loss at iteration 730 : 0.008299280889332294
Loss at iteration 740 : 0.0052204011008143425
Loss at iteration 750 : 0.013722488656640053
Loss at iteration 760 : 0.009487424977123737
Loss at iteration 770 : 0.0020533318165689707
Loss at iteration 780 : 0.007883906364440918
Loss at iteration 790 : 0.004406170919537544
Loss at iteration 800 : 0.00931395124644041
Loss at iteration 810 : 0.0076588476076722145
Loss at iteration 820 : 0.00826416164636612
Loss at iteration 830 : 0.01866709254682064
Loss at iteration 840 : 0.014655951410531998
Loss at iteration 850 : 0.0097047733142972
Loss at iteration 860 : 0.005897975526750088
Loss at iteration 870 : 0.016224855557084084
Loss at iteration 880 : 0.01649663969874382
Loss at iteration 890 : 0.017947863787412643
Loss at iteration 900 : 0.014786229468882084
Loss at iteration 910 : 0.005990279838442802
Loss at iteration 920 : 0.010138671845197678
Loss at iteration 930 : 0.02000114694237709
Loss at iteration 940 : 0.0100434310734272
Loss at iteration 950 : 0.012949821539223194
Loss at iteration 960 : 0.009737232699990273
Loss at iteration 970 : 0.006271928548812866
Loss at iteration 980 : 0.01006584707647562
Loss at iteration 990 : 0.008990725502371788
Loss at iteration 1000 : 0.009825002402067184
Loss at iteration 1010 : 0.011785181239247322
Loss at iteration 1020 : 0.00727159483358264
Loss at iteration 1030 : 0.009267570450901985
Loss at iteration 1040 : 0.007706933654844761
Loss at iteration 1050 : 0.007175746373832226
Loss at iteration 1060 : 0.010665807873010635
Loss at iteration 1070 : 0.0166647806763649
Loss at iteration 1080 : 0.01724352315068245
Loss at iteration 1090 : 0.007200633175671101
Loss at iteration 1100 : 0.0066912369802594185
Loss at iteration 1110 : 0.006655627861618996
Loss at iteration 1120 : 0.004636999219655991
Loss at iteration 1130 : 0.014042574912309647
Loss at iteration 1140 : 0.013766656629741192
Loss at iteration 1150 : 0.007324213162064552
Loss at iteration 1160 : 0.010796986520290375
Loss at iteration 1170 : 0.012516540475189686
Loss at iteration 1180 : 0.010312674567103386
Loss at iteration 1190 : 0.008810896426439285
Loss at iteration 1200 : 0.008496953174471855
Loss at iteration 1210 : 0.006738618016242981
Loss at iteration 1220 : 0.014994297176599503
Loss at iteration 1230 : 0.009369531646370888
Loss at iteration 1240 : 0.008547131903469563
Loss at iteration 1250 : 0.008068193681538105
Loss at iteration 1260 : 0.026221279054880142
Loss at iteration 1270 : 0.009202759712934494
Loss at iteration 1280 : 0.011986203491687775
Loss at iteration 1290 : 0.01184002310037613
Loss at iteration 1300 : 0.012081305496394634
Loss at iteration 1310 : 0.007624267600476742
Loss at iteration 1320 : 0.01034902036190033
Loss at iteration 1330 : 0.003447299124673009
Loss at iteration 1340 : 0.01194348931312561
Loss at iteration 1350 : 0.01413492951542139
Loss at iteration 1360 : 0.007942179217934608
Loss at iteration 1370 : 0.011038007214665413
Loss at iteration 1380 : 0.014032425358891487
Loss at iteration 1390 : 0.014847427606582642
Loss at iteration 1400 : 0.01194863673299551
Loss at iteration 1410 : 0.011083517223596573
Loss at iteration 1420 : 0.015078096650540829
Loss at iteration 1430 : 0.0040045022033154964
Loss at iteration 1440 : 0.011337719857692719
Loss at iteration 1450 : 0.013233182951807976
Loss at iteration 1460 : 0.00527281453832984
Loss at iteration 1470 : 0.005244800820946693
Loss at iteration 1480 : 0.009763030335307121
Loss at iteration 1490 : 0.012437712401151657
Loss at iteration 1500 : 0.011253026314079762
Loss at iteration 1510 : 0.009027405641973019
Loss at iteration 1520 : 0.005707970820367336
Loss at iteration 1530 : 0.006396573968231678
Loss at iteration 1540 : 0.007752588484436274
Loss at iteration 1550 : 0.008244583383202553
Loss at iteration 1560 : 0.013155106455087662
Loss at iteration 1570 : 0.00958441011607647
Loss at iteration 1580 : 0.006829974241554737
Loss at iteration 1590 : 0.011495502665638924
Loss at iteration 1600 : 0.009624323807656765
Loss at iteration 1610 : 0.021868525072932243
Loss at iteration 1620 : 0.012657145038247108
Loss at iteration 1630 : 0.00851313304156065
Loss at iteration 1640 : 0.004762659780681133
Loss at iteration 1650 : 0.013245333917438984
Loss at iteration 1660 : 0.012274632230401039
Loss at iteration 1670 : 0.012078892439603806
Loss at iteration 1680 : 0.020182881504297256
Loss at iteration 1690 : 0.0076218233443796635
Loss at iteration 1700 : 0.00483624916523695
Loss at iteration 1710 : 0.009160744957625866
Loss at iteration 1720 : 0.01972484588623047
Loss at iteration 1730 : 0.014596620574593544
Loss at iteration 1740 : 0.002514120191335678
Loss at iteration 1750 : 0.010428810492157936
Loss at iteration 1760 : 0.004925783723592758
Loss at iteration 1770 : 0.008133107796311378
Loss at iteration 1780 : 0.017000185325741768
Loss at iteration 1790 : 0.00718064047396183
Loss at iteration 1800 : 0.011806661263108253
Loss at iteration 1810 : 0.006560948211699724
Loss at iteration 1820 : 0.004703283775597811
Loss at iteration 1830 : 0.010262787342071533
Loss at iteration 1840 : 0.005723537877202034
Loss at iteration 1850 : 0.00817751046270132
Loss at iteration 1860 : 0.007403338793665171
Loss at iteration 1870 : 0.005166993476450443
Loss at iteration 1880 : 0.013196577318012714
Loss at iteration 1890 : 0.013459786772727966
Loss at iteration 1900 : 0.012257224880158901
Loss at iteration 1910 : 0.0029734966810792685
Loss at iteration 1920 : 0.023717191070318222
Loss at iteration 1930 : 0.018509048968553543
Loss at iteration 1940 : 0.004824425093829632
Loss at iteration 1950 : 0.012212018482387066
Loss at iteration 1960 : 0.003538269316777587
Loss at iteration 1970 : 0.013194167986512184
Loss at iteration 1980 : 0.008825301192700863
Loss at iteration 1990 : 0.016901895403862
Loss at iteration 2000 : 0.00743458978831768
Loss at iteration 2010 : 0.010050100274384022
Loss at iteration 2020 : 0.008752656169235706
Loss at iteration 2030 : 0.011519281193614006
Loss at iteration 2040 : 0.0029994677752256393
Loss at iteration 2050 : 0.00960893277078867
Loss at iteration 2060 : 0.006627374328672886
Loss at iteration 2070 : 0.012409950606524944
Loss at iteration 2080 : 0.007314383052289486
Loss at iteration 2090 : 0.01141856424510479
Loss at iteration 2100 : 0.006697073113173246
Loss at iteration 2110 : 0.01421887893229723
Loss at iteration 2120 : 0.01626576855778694
Loss at iteration 2130 : 0.014065273106098175
Loss at iteration 2140 : 0.013813892379403114
Loss at iteration 2150 : 0.016637032851576805
Loss at iteration 2160 : 0.009646761231124401
Loss at iteration 2170 : 0.00905360747128725
Loss at iteration 2180 : 0.006342336535453796
Loss at iteration 2190 : 0.007132633589208126
Loss at iteration 2200 : 0.008143942803144455
Loss at iteration 2210 : 0.01447635143995285
Loss at iteration 2220 : 0.009647300466895103
Loss at iteration 2230 : 0.009698630310595036
Loss at iteration 2240 : 0.005034372676163912
Loss at iteration 2250 : 0.00905595812946558
Loss at iteration 2260 : 0.007076115347445011
Loss at iteration 2270 : 0.015976887196302414
Loss at iteration 2280 : 0.013596474193036556
Loss at iteration 2290 : 0.00794367678463459
Loss at iteration 2300 : 0.003114753868430853
Loss at iteration 2310 : 0.013589628040790558
Loss at iteration 2320 : 0.0062834834679961205
Loss at iteration 2330 : 0.007919124327600002
Loss at iteration 2340 : 0.016504967585206032
Loss at iteration 2350 : 0.004564859438687563
Loss at iteration 2360 : 0.012588929384946823
Loss at iteration 2370 : 0.009618028998374939
Loss at iteration 2380 : 0.0076875933445990086
Loss at iteration 2390 : 0.01164793036878109
Loss at iteration 2400 : 0.010211596265435219
Loss at iteration 2410 : 0.009517543949186802
Loss at iteration 2420 : 0.006380136124789715
The SSIM Value is: 0.8445023735364278
The PSNR Value is: 22.03052520751953
the epoch is: 62
Loss at iteration 10 : 0.013335993513464928
Loss at iteration 20 : 0.01574769988656044
Loss at iteration 30 : 0.008786622434854507
Loss at iteration 40 : 0.006954483687877655
Loss at iteration 50 : 0.00817019771784544
Loss at iteration 60 : 0.0037978130858391523
Loss at iteration 70 : 0.012888405472040176
Loss at iteration 80 : 0.004421279300004244
Loss at iteration 90 : 0.013580692932009697
Loss at iteration 100 : 0.019045382738113403
Loss at iteration 110 : 0.014108046889305115
Loss at iteration 120 : 0.011417285539209843
Loss at iteration 130 : 0.011779957450926304
Loss at iteration 140 : 0.0015034886309877038
Loss at iteration 150 : 0.004100427031517029
Loss at iteration 160 : 0.011571209877729416
Loss at iteration 170 : 0.006926318630576134
Loss at iteration 180 : 0.013681845739483833
Loss at iteration 190 : 0.010817773640155792
Loss at iteration 200 : 0.009142329916357994
Loss at iteration 210 : 0.010106920264661312
Loss at iteration 220 : 0.007028344087302685
Loss at iteration 230 : 0.011912347748875618
Loss at iteration 240 : 0.005669384263455868
Loss at iteration 250 : 0.019297026097774506
Loss at iteration 260 : 0.005596974864602089
Loss at iteration 270 : 0.009501739405095577
Loss at iteration 280 : 0.003848753636702895
Loss at iteration 290 : 0.007967599667608738
Loss at iteration 300 : 0.01073438674211502
Loss at iteration 310 : 0.010045558214187622
Loss at iteration 320 : 0.016661640256643295
Loss at iteration 330 : 0.010665085166692734
Loss at iteration 340 : 0.011892151087522507
Loss at iteration 350 : 0.007214343175292015
Loss at iteration 360 : 0.010005336254835129
Loss at iteration 370 : 0.00854548066854477
Loss at iteration 380 : 0.007397667039185762
Loss at iteration 390 : 0.008547250181436539
Loss at iteration 400 : 0.020610066130757332
Loss at iteration 410 : 0.012613032013177872
Loss at iteration 420 : 0.02101336419582367
Loss at iteration 430 : 0.0077333771623671055
Loss at iteration 440 : 0.0038285800255835056
Loss at iteration 450 : 0.009680990129709244
Loss at iteration 460 : 0.012952517718076706
Loss at iteration 470 : 0.010690507479012012
Loss at iteration 480 : 0.007968614809215069
Loss at iteration 490 : 0.009316137991845608
Loss at iteration 500 : 0.009265596978366375
Loss at iteration 510 : 0.00804281048476696
Loss at iteration 520 : 0.006632757373154163
Loss at iteration 530 : 0.016942158341407776
Loss at iteration 540 : 0.011092370375990868
Loss at iteration 550 : 0.0335577130317688
Loss at iteration 560 : 0.00751879345625639
Loss at iteration 570 : 0.014025256969034672
Loss at iteration 580 : 0.003599487943574786
Loss at iteration 590 : 0.005326664075255394
Loss at iteration 600 : 0.008108287118375301
Loss at iteration 610 : 0.0042725736275315285
Loss at iteration 620 : 0.007508201990276575
Loss at iteration 630 : 0.009756747633218765
Loss at iteration 640 : 0.019211439415812492
Loss at iteration 650 : 0.013981455005705357
Loss at iteration 660 : 0.01023254357278347
Loss at iteration 670 : 0.009839072823524475
Loss at iteration 680 : 0.015833426266908646
Loss at iteration 690 : 0.004931329283863306
Loss at iteration 700 : 0.007888800464570522
Loss at iteration 710 : 0.006844605319201946
Loss at iteration 720 : 0.006888070143759251
Loss at iteration 730 : 0.011708315461874008
Loss at iteration 740 : 0.007557782810181379
Loss at iteration 750 : 0.006912727374583483
Loss at iteration 760 : 0.008793765679001808
Loss at iteration 770 : 0.009858432225883007
Loss at iteration 780 : 0.0192961897701025
Loss at iteration 790 : 0.01798475719988346
Loss at iteration 800 : 0.028560642153024673
Loss at iteration 810 : 0.005918994080275297
Loss at iteration 820 : 0.009922115132212639
Loss at iteration 830 : 0.0027849460020661354
Loss at iteration 840 : 0.019149575382471085
Loss at iteration 850 : 0.011440216563642025
Loss at iteration 860 : 0.009466271847486496
Loss at iteration 870 : 0.012870976701378822
Loss at iteration 880 : 0.004968756344169378
Loss at iteration 890 : 0.01628737337887287
Loss at iteration 900 : 0.006431804038584232
Loss at iteration 910 : 0.012462484650313854
Loss at iteration 920 : 0.005566174164414406
Loss at iteration 930 : 0.011274534277617931
Loss at iteration 940 : 0.00865260697901249
Loss at iteration 950 : 0.008197838440537453
Loss at iteration 960 : 0.005419532768428326
Loss at iteration 970 : 0.011320967227220535
Loss at iteration 980 : 0.006341711152344942
Loss at iteration 990 : 0.007702804170548916
Loss at iteration 1000 : 0.013099649921059608
Loss at iteration 1010 : 0.015036324970424175
Loss at iteration 1020 : 0.009688740596175194
Loss at iteration 1030 : 0.008297370746731758
Loss at iteration 1040 : 0.005124052986502647
Loss at iteration 1050 : 0.009678920730948448
Loss at iteration 1060 : 0.006166508421301842
Loss at iteration 1070 : 0.013086093589663506
Loss at iteration 1080 : 0.009163632057607174
Loss at iteration 1090 : 0.022403310984373093
Loss at iteration 1100 : 0.02182970754802227
Loss at iteration 1110 : 0.011808536946773529
Loss at iteration 1120 : 0.006786373443901539
Loss at iteration 1130 : 0.012159799225628376
Loss at iteration 1140 : 0.017388030886650085
Loss at iteration 1150 : 0.008335372433066368
Loss at iteration 1160 : 0.010056043043732643
Loss at iteration 1170 : 0.009585980325937271
Loss at iteration 1180 : 0.007142991758882999
Loss at iteration 1190 : 0.009852491319179535
Loss at iteration 1200 : 0.00672520836815238
Loss at iteration 1210 : 0.007572529371827841
Loss at iteration 1220 : 0.005911294370889664
Loss at iteration 1230 : 0.0061004748567938805
Loss at iteration 1240 : 0.007939686067402363
Loss at iteration 1250 : 0.016234997659921646
Loss at iteration 1260 : 0.010134542360901833
Loss at iteration 1270 : 0.018976477906107903
Loss at iteration 1280 : 0.006863446440547705
Loss at iteration 1290 : 0.020642831921577454
Loss at iteration 1300 : 0.019226383417844772
Loss at iteration 1310 : 0.008283870294690132
Loss at iteration 1320 : 0.004086503759026527
Loss at iteration 1330 : 0.0071639250963926315
Loss at iteration 1340 : 0.01232030801475048
Loss at iteration 1350 : 0.012268013320863247
Loss at iteration 1360 : 0.0050203618593513966
Loss at iteration 1370 : 0.020756803452968597
Loss at iteration 1380 : 0.006186472252011299
Loss at iteration 1390 : 0.015337814576923847
Loss at iteration 1400 : 0.01617833599448204
Loss at iteration 1410 : 0.004593354649841785
Loss at iteration 1420 : 0.01082270871847868
Loss at iteration 1430 : 0.007655646651983261
Loss at iteration 1440 : 0.004372803028672934
Loss at iteration 1450 : 0.005925481207668781
Loss at iteration 1460 : 0.009693268686532974
Loss at iteration 1470 : 0.014201793819665909
Loss at iteration 1480 : 0.00961831770837307
Loss at iteration 1490 : 0.009955005720257759
Loss at iteration 1500 : 0.020788539201021194
Loss at iteration 1510 : 0.011919545009732246
Loss at iteration 1520 : 0.012485930696129799
Loss at iteration 1530 : 0.008469006046652794
Loss at iteration 1540 : 0.014448648318648338
Loss at iteration 1550 : 0.009467481635510921
Loss at iteration 1560 : 0.007249439135193825
Loss at iteration 1570 : 0.015253473073244095
Loss at iteration 1580 : 0.005650814156979322
Loss at iteration 1590 : 0.007952102459967136
Loss at iteration 1600 : 0.004066755063831806
Loss at iteration 1610 : 0.006914806552231312
Loss at iteration 1620 : 0.005819272715598345
Loss at iteration 1630 : 0.012497452087700367
Loss at iteration 1640 : 0.009728136472404003
Loss at iteration 1650 : 0.013764486648142338
Loss at iteration 1660 : 0.0027718376368284225
Loss at iteration 1670 : 0.00517571996897459
Loss at iteration 1680 : 0.011254332028329372
Loss at iteration 1690 : 0.018773922696709633
Loss at iteration 1700 : 0.006043368950486183
Loss at iteration 1710 : 0.007623921148478985
Loss at iteration 1720 : 0.0063835326582193375
Loss at iteration 1730 : 0.015077939257025719
Loss at iteration 1740 : 0.01078040525317192
Loss at iteration 1750 : 0.00418257899582386
Loss at iteration 1760 : 0.006991800386458635
Loss at iteration 1770 : 0.0072655756957829
Loss at iteration 1780 : 0.00635795621201396
Loss at iteration 1790 : 0.010329878889024258
Loss at iteration 1800 : 0.009354566223919392
Loss at iteration 1810 : 0.006688730791211128
Loss at iteration 1820 : 0.009210922755300999
Loss at iteration 1830 : 0.004440790973603725
Loss at iteration 1840 : 0.008426518179476261
Loss at iteration 1850 : 0.011177392676472664
Loss at iteration 1860 : 0.005032761953771114
Loss at iteration 1870 : 0.008174911141395569
Loss at iteration 1880 : 0.015530893579125404
Loss at iteration 1890 : 0.019055090844631195
Loss at iteration 1900 : 0.004856611602008343
Loss at iteration 1910 : 0.013163022696971893
Loss at iteration 1920 : 0.003357337787747383
Loss at iteration 1930 : 0.007237913552671671
Loss at iteration 1940 : 0.011488525196909904
Loss at iteration 1950 : 0.020481765270233154
Loss at iteration 1960 : 0.014996571466326714
Loss at iteration 1970 : 0.008621851913630962
Loss at iteration 1980 : 0.006405223160982132
Loss at iteration 1990 : 0.00824208464473486
Loss at iteration 2000 : 0.00579772237688303
Loss at iteration 2010 : 0.01146713551133871
Loss at iteration 2020 : 0.022515857592225075
Loss at iteration 2030 : 0.01222829520702362
Loss at iteration 2040 : 0.006624712608754635
Loss at iteration 2050 : 0.007976915687322617
Loss at iteration 2060 : 0.007123809307813644
Loss at iteration 2070 : 0.00822197925299406
Loss at iteration 2080 : 0.019021710380911827
Loss at iteration 2090 : 0.011971529573202133
Loss at iteration 2100 : 0.009012612514197826
Loss at iteration 2110 : 0.006304213311523199
Loss at iteration 2120 : 0.013778578490018845
Loss at iteration 2130 : 0.016855746507644653
Loss at iteration 2140 : 0.004678369499742985
Loss at iteration 2150 : 0.008216209709644318
Loss at iteration 2160 : 0.00830485112965107
Loss at iteration 2170 : 0.006297049578279257
Loss at iteration 2180 : 0.01441003568470478
Loss at iteration 2190 : 0.007957727648317814
Loss at iteration 2200 : 0.013907217420637608
Loss at iteration 2210 : 0.012595809996128082
Loss at iteration 2220 : 0.009271168150007725
Loss at iteration 2230 : 0.013803527690470219
Loss at iteration 2240 : 0.007868930697441101
Loss at iteration 2250 : 0.013869727030396461
Loss at iteration 2260 : 0.005494116805493832
Loss at iteration 2270 : 0.014470750465989113
Loss at iteration 2280 : 0.004783804062753916
Loss at iteration 2290 : 0.009112557396292686
Loss at iteration 2300 : 0.008225216530263424
Loss at iteration 2310 : 0.007039394695311785
Loss at iteration 2320 : 0.006975027732551098
Loss at iteration 2330 : 0.010203670710325241
Loss at iteration 2340 : 0.005829740781337023
Loss at iteration 2350 : 0.009451441466808319
Loss at iteration 2360 : 0.00886053778231144
Loss at iteration 2370 : 0.006897429935634136
Loss at iteration 2380 : 0.0042999861761927605
Loss at iteration 2390 : 0.007681132759898901
Loss at iteration 2400 : 0.010463741607964039
Loss at iteration 2410 : 0.0057621849700808525
Loss at iteration 2420 : 0.010367263108491898
The SSIM Value is: 0.8344009558359782
The PSNR Value is: 20.80238742828369
the epoch is: 63
Loss at iteration 10 : 0.00875519122928381
Loss at iteration 20 : 0.017919763922691345
Loss at iteration 30 : 0.015243995934724808
Loss at iteration 40 : 0.005132826045155525
Loss at iteration 50 : 0.016988687217235565
Loss at iteration 60 : 0.019383903592824936
Loss at iteration 70 : 0.015077091753482819
Loss at iteration 80 : 0.00929712038487196
Loss at iteration 90 : 0.005256238393485546
Loss at iteration 100 : 0.01779802143573761
Loss at iteration 110 : 0.008818108588457108
Loss at iteration 120 : 0.014990687370300293
Loss at iteration 130 : 0.010679317638278008
Loss at iteration 140 : 0.009241144172847271
Loss at iteration 150 : 0.0035206470638513565
Loss at iteration 160 : 0.020487939938902855
Loss at iteration 170 : 0.025061575695872307
Loss at iteration 180 : 0.013902667909860611
Loss at iteration 190 : 0.006869526579976082
Loss at iteration 200 : 0.00464782677590847
Loss at iteration 210 : 0.009987558238208294
Loss at iteration 220 : 0.007522640749812126
Loss at iteration 230 : 0.008106645196676254
Loss at iteration 240 : 0.009284854866564274
Loss at iteration 250 : 0.007505180314183235
Loss at iteration 260 : 0.008611897006630898
Loss at iteration 270 : 0.016615470871329308
Loss at iteration 280 : 0.00842068251222372
Loss at iteration 290 : 0.00948265753686428
Loss at iteration 300 : 0.013957477174699306
Loss at iteration 310 : 0.009196325205266476
Loss at iteration 320 : 0.009313719347119331
Loss at iteration 330 : 0.005299142561852932
Loss at iteration 340 : 0.00988788716495037
Loss at iteration 350 : 0.007871383801102638
Loss at iteration 360 : 0.011965908110141754
Loss at iteration 370 : 0.0032042476814240217
Loss at iteration 380 : 0.008364405483007431
Loss at iteration 390 : 0.008370043709874153
Loss at iteration 400 : 0.00795248057693243
Loss at iteration 410 : 0.00280582532286644
Loss at iteration 420 : 0.010352637618780136
Loss at iteration 430 : 0.00577545166015625
Loss at iteration 440 : 0.011182643473148346
Loss at iteration 450 : 0.013715822249650955
Loss at iteration 460 : 0.019903514534235
Loss at iteration 470 : 0.015571597032248974
Loss at iteration 480 : 0.008896558545529842
Loss at iteration 490 : 0.006556357257068157
Loss at iteration 500 : 0.013346616178750992
Loss at iteration 510 : 0.008965156972408295
Loss at iteration 520 : 0.00821103248745203
Loss at iteration 530 : 0.009578265249729156
Loss at iteration 540 : 0.006238087546080351
Loss at iteration 550 : 0.004715597257018089
Loss at iteration 560 : 0.011108933947980404
Loss at iteration 570 : 0.009402906522154808
Loss at iteration 580 : 0.01765303872525692
Loss at iteration 590 : 0.008493815548717976
Loss at iteration 600 : 0.012202580459415913
Loss at iteration 610 : 0.008836846798658371
Loss at iteration 620 : 0.015976345166563988
Loss at iteration 630 : 0.00984338577836752
Loss at iteration 640 : 0.009562471881508827
Loss at iteration 650 : 0.007361259777098894
Loss at iteration 660 : 0.009022376500070095
Loss at iteration 670 : 0.017213081941008568
Loss at iteration 680 : 0.0061550503596663475
Loss at iteration 690 : 0.01572803594172001
Loss at iteration 700 : 0.013312313705682755
Loss at iteration 710 : 0.007407912518829107
Loss at iteration 720 : 0.008738826029002666
Loss at iteration 730 : 0.026860414072871208
Loss at iteration 740 : 0.032721832394599915
Loss at iteration 750 : 0.006714320741593838
Loss at iteration 760 : 0.0028169783763587475
Loss at iteration 770 : 0.009477556683123112
Loss at iteration 780 : 0.005531712900847197
Loss at iteration 790 : 0.0081817377358675
Loss at iteration 800 : 0.015312238596379757
Loss at iteration 810 : 0.010890653356909752
Loss at iteration 820 : 0.0044709197245538235
Loss at iteration 830 : 0.013471629470586777
Loss at iteration 840 : 0.003422191832214594
Loss at iteration 850 : 0.003448660485446453
Loss at iteration 860 : 0.012299859896302223
Loss at iteration 870 : 0.005724526010453701
Loss at iteration 880 : 0.005710784811526537
Loss at iteration 890 : 0.009046121500432491
Loss at iteration 900 : 0.005559353157877922
Loss at iteration 910 : 0.01261228509247303
Loss at iteration 920 : 0.011019431985914707
Loss at iteration 930 : 0.006200646981596947
Loss at iteration 940 : 0.004776796791702509
Loss at iteration 950 : 0.004112245514988899
Loss at iteration 960 : 0.008369840681552887
Loss at iteration 970 : 0.011589954607188702
Loss at iteration 980 : 0.006050536409020424
Loss at iteration 990 : 0.008779109455645084
Loss at iteration 1000 : 0.009700166992843151
Loss at iteration 1010 : 0.00999853853136301
Loss at iteration 1020 : 0.010137338191270828
Loss at iteration 1030 : 0.006220773793756962
Loss at iteration 1040 : 0.011708369478583336
Loss at iteration 1050 : 0.009982652962207794
Loss at iteration 1060 : 0.012056824751198292
Loss at iteration 1070 : 0.011926593258976936
Loss at iteration 1080 : 0.0025792154483497143
Loss at iteration 1090 : 0.012784354388713837
Loss at iteration 1100 : 0.007278704084455967
Loss at iteration 1110 : 0.005916697438806295
Loss at iteration 1120 : 0.015241838060319424
Loss at iteration 1130 : 0.007570242043584585
Loss at iteration 1140 : 0.015671810135245323
Loss at iteration 1150 : 0.004823967348784208
Loss at iteration 1160 : 0.011447782628238201
Loss at iteration 1170 : 0.011773173697292805
Loss at iteration 1180 : 0.011342823505401611
Loss at iteration 1190 : 0.011607898399233818
Loss at iteration 1200 : 0.00782726425677538
Loss at iteration 1210 : 0.013152934610843658
Loss at iteration 1220 : 0.01346664410084486
Loss at iteration 1230 : 0.0038044732064008713
Loss at iteration 1240 : 0.009427329525351524
Loss at iteration 1250 : 0.021978266537189484
Loss at iteration 1260 : 0.0046922811307013035
Loss at iteration 1270 : 0.008502855896949768
Loss at iteration 1280 : 0.019992277026176453
Loss at iteration 1290 : 0.011313830502331257
Loss at iteration 1300 : 0.007859094999730587
Loss at iteration 1310 : 0.006720154546201229
Loss at iteration 1320 : 0.007296460680663586
Loss at iteration 1330 : 0.009246080182492733
Loss at iteration 1340 : 0.0030993998516350985
Loss at iteration 1350 : 0.008291646838188171
Loss at iteration 1360 : 0.013468313962221146
Loss at iteration 1370 : 0.0055708689615130424
Loss at iteration 1380 : 0.003966204822063446
Loss at iteration 1390 : 0.007814647629857063
Loss at iteration 1400 : 0.008934956975281239
Loss at iteration 1410 : 0.02183796837925911
Loss at iteration 1420 : 0.00781499408185482
Loss at iteration 1430 : 0.009494854137301445
Loss at iteration 1440 : 0.017057985067367554
Loss at iteration 1450 : 0.008063625544309616
Loss at iteration 1460 : 0.008142192848026752
Loss at iteration 1470 : 0.008065512403845787
Loss at iteration 1480 : 0.011102992109954357
Loss at iteration 1490 : 0.00750585924834013
Loss at iteration 1500 : 0.004977712873369455
Loss at iteration 1510 : 0.009299793280661106
Loss at iteration 1520 : 0.0021435280796140432
Loss at iteration 1530 : 0.005128846038132906
Loss at iteration 1540 : 0.0051679592579603195
Loss at iteration 1550 : 0.009697305038571358
Loss at iteration 1560 : 0.015202470123767853
Loss at iteration 1570 : 0.011732605285942554
Loss at iteration 1580 : 0.006550639867782593
Loss at iteration 1590 : 0.01625949889421463
Loss at iteration 1600 : 0.02318682335317135
Loss at iteration 1610 : 0.017095815390348434
Loss at iteration 1620 : 0.005321181379258633
Loss at iteration 1630 : 0.011825913563370705
Loss at iteration 1640 : 0.0046077026054263115
Loss at iteration 1650 : 0.010562574490904808
Loss at iteration 1660 : 0.0069785285741090775
Loss at iteration 1670 : 0.012295333668589592
Loss at iteration 1680 : 0.016839999705553055
Loss at iteration 1690 : 0.010794319212436676
Loss at iteration 1700 : 0.016415251418948174
Loss at iteration 1710 : 0.01831388659775257
Loss at iteration 1720 : 0.007809920702129602
Loss at iteration 1730 : 0.005349069368094206
Loss at iteration 1740 : 0.011677340604364872
Loss at iteration 1750 : 0.008949953131377697
Loss at iteration 1760 : 0.005259952042251825
Loss at iteration 1770 : 0.01742989383637905
Loss at iteration 1780 : 0.017867589369416237
Loss at iteration 1790 : 0.010264853946864605
Loss at iteration 1800 : 0.0069433278404176235
Loss at iteration 1810 : 0.005213687662035227
Loss at iteration 1820 : 0.002686253283172846
Loss at iteration 1830 : 0.0027273499872535467
Loss at iteration 1840 : 0.007369291502982378
Loss at iteration 1850 : 0.011565372347831726
Loss at iteration 1860 : 0.009726854972541332
Loss at iteration 1870 : 0.006854257546365261
Loss at iteration 1880 : 0.01271332148462534
Loss at iteration 1890 : 0.006710779387503862
Loss at iteration 1900 : 0.009576213546097279
Loss at iteration 1910 : 0.006021239794790745
Loss at iteration 1920 : 0.007304011844098568
Loss at iteration 1930 : 0.004037254955619574
Loss at iteration 1940 : 0.007552206050604582
Loss at iteration 1950 : 0.007205852307379246
Loss at iteration 1960 : 0.010862898081541061
Loss at iteration 1970 : 0.005686088930815458
Loss at iteration 1980 : 0.008085470646619797
Loss at iteration 1990 : 0.005269826389849186
Loss at iteration 2000 : 0.005002662539482117
Loss at iteration 2010 : 0.005336996167898178
Loss at iteration 2020 : 0.007986152544617653
Loss at iteration 2030 : 0.0038117149379104376
Loss at iteration 2040 : 0.004651718307286501
Loss at iteration 2050 : 0.009908937849104404
Loss at iteration 2060 : 0.007475912105292082
Loss at iteration 2070 : 0.025652654469013214
Loss at iteration 2080 : 0.011506166309118271
Loss at iteration 2090 : 0.00830799899995327
Loss at iteration 2100 : 0.009005934000015259
Loss at iteration 2110 : 0.003931007813662291
Loss at iteration 2120 : 0.006707459222525358
Loss at iteration 2130 : 0.01648099534213543
Loss at iteration 2140 : 0.006187506020069122
Loss at iteration 2150 : 0.014755602926015854
Loss at iteration 2160 : 0.030038565397262573
Loss at iteration 2170 : 0.004061114974319935
Loss at iteration 2180 : 0.015011264942586422
Loss at iteration 2190 : 0.014681346714496613
Loss at iteration 2200 : 0.008015907369554043
Loss at iteration 2210 : 0.01927684247493744
Loss at iteration 2220 : 0.011426691897213459
Loss at iteration 2230 : 0.011339297518134117
Loss at iteration 2240 : 0.0065909698605537415
Loss at iteration 2250 : 0.0050856322050094604
Loss at iteration 2260 : 0.011582552455365658
Loss at iteration 2270 : 0.012316164560616016
Loss at iteration 2280 : 0.011032669804990292
Loss at iteration 2290 : 0.005258700344711542
Loss at iteration 2300 : 0.013012964278459549
Loss at iteration 2310 : 0.00712675740942359
Loss at iteration 2320 : 0.003837482538074255
Loss at iteration 2330 : 0.009214237332344055
Loss at iteration 2340 : 0.010080929845571518
Loss at iteration 2350 : 0.013363886624574661
Loss at iteration 2360 : 0.009087921120226383
Loss at iteration 2370 : 0.005634888540953398
Loss at iteration 2380 : 0.011521806940436363
Loss at iteration 2390 : 0.007753685582429171
Loss at iteration 2400 : 0.0071134972386062145
Loss at iteration 2410 : 0.0028179390355944633
Loss at iteration 2420 : 0.0025367513298988342
The SSIM Value is: 0.8414221803347269
The PSNR Value is: 22.16077626546224
the epoch is: 64
Loss at iteration 10 : 0.00977922324091196
Loss at iteration 20 : 0.008019441738724709
Loss at iteration 30 : 0.008788155391812325
Loss at iteration 40 : 0.00566554581746459
Loss at iteration 50 : 0.011905357241630554
Loss at iteration 60 : 0.010319695807993412
Loss at iteration 70 : 0.00868106260895729
Loss at iteration 80 : 0.004816749133169651
Loss at iteration 90 : 0.008540394715964794
Loss at iteration 100 : 0.017519664019346237
Loss at iteration 110 : 0.007890613749623299
Loss at iteration 120 : 0.02557297982275486
Loss at iteration 130 : 0.00678151473402977
Loss at iteration 140 : 0.007051381282508373
Loss at iteration 150 : 0.012074003927409649
Loss at iteration 160 : 0.010289966128766537
Loss at iteration 170 : 0.0030272952280938625
Loss at iteration 180 : 0.008354408666491508
Loss at iteration 190 : 0.008315648883581161
Loss at iteration 200 : 0.00877730268985033
Loss at iteration 210 : 0.009341923519968987
Loss at iteration 220 : 0.009713079780340195
Loss at iteration 230 : 0.011525103822350502
Loss at iteration 240 : 0.01743525266647339
Loss at iteration 250 : 0.0068251327611505985
Loss at iteration 260 : 0.009440204128623009
Loss at iteration 270 : 0.008121741004288197
Loss at iteration 280 : 0.00999915599822998
Loss at iteration 290 : 0.0058199153281748295
Loss at iteration 300 : 0.009284388273954391
Loss at iteration 310 : 0.011714320629835129
Loss at iteration 320 : 0.006211001425981522
Loss at iteration 330 : 0.016439760103821754
Loss at iteration 340 : 0.005825767759233713
Loss at iteration 350 : 0.008662393316626549
Loss at iteration 360 : 0.020926356315612793
Loss at iteration 370 : 0.0042721182107925415
Loss at iteration 380 : 0.00847453624010086
Loss at iteration 390 : 0.004194926470518112
Loss at iteration 400 : 0.007302404846996069
Loss at iteration 410 : 0.011460580863058567
Loss at iteration 420 : 0.006170786917209625
Loss at iteration 430 : 0.0227064099162817
Loss at iteration 440 : 0.008970584720373154
Loss at iteration 450 : 0.009572976268827915
Loss at iteration 460 : 0.024897586554288864
Loss at iteration 470 : 0.009829644113779068
Loss at iteration 480 : 0.012666916474699974
Loss at iteration 490 : 0.0046922569163143635
Loss at iteration 500 : 0.012369811534881592
Loss at iteration 510 : 0.012855837121605873
Loss at iteration 520 : 0.015675269067287445
Loss at iteration 530 : 0.012741023674607277
Loss at iteration 540 : 0.011257444508373737
Loss at iteration 550 : 0.007611480541527271
Loss at iteration 560 : 0.008814048022031784
Loss at iteration 570 : 0.010418111458420753
Loss at iteration 580 : 0.004238614812493324
Loss at iteration 590 : 0.008395212702453136
Loss at iteration 600 : 0.012806912884116173
Loss at iteration 610 : 0.009666218422353268
Loss at iteration 620 : 0.012310704216361046
Loss at iteration 630 : 0.007954591885209084
Loss at iteration 640 : 0.005120555870234966
Loss at iteration 650 : 0.0029571657069027424
Loss at iteration 660 : 0.005108525976538658
Loss at iteration 670 : 0.005624451674520969
Loss at iteration 680 : 0.013815894722938538
Loss at iteration 690 : 0.00742388004437089
Loss at iteration 700 : 0.0067877816036343575
Loss at iteration 710 : 0.009633706882596016
Loss at iteration 720 : 0.013502826914191246
Loss at iteration 730 : 0.009276507422327995
Loss at iteration 740 : 0.005843655671924353
Loss at iteration 750 : 0.008056558668613434
Loss at iteration 760 : 0.012409631162881851
Loss at iteration 770 : 0.008968176320195198
Loss at iteration 780 : 0.013013532385230064
Loss at iteration 790 : 0.004059935919940472
Loss at iteration 800 : 0.00580700533464551
Loss at iteration 810 : 0.004901429638266563
Loss at iteration 820 : 0.015169177204370499
Loss at iteration 830 : 0.005822078324854374
Loss at iteration 840 : 0.010495014488697052
Loss at iteration 850 : 0.02476680278778076
Loss at iteration 860 : 0.009565107524394989
Loss at iteration 870 : 0.006273587234318256
Loss at iteration 880 : 0.011887878179550171
Loss at iteration 890 : 0.00797201506793499
Loss at iteration 900 : 0.0090450718998909
Loss at iteration 910 : 0.010793148539960384
Loss at iteration 920 : 0.003441516775637865
Loss at iteration 930 : 0.012241099029779434
Loss at iteration 940 : 0.01194674614816904
Loss at iteration 950 : 0.010422768071293831
Loss at iteration 960 : 0.007998551242053509
Loss at iteration 970 : 0.009234225377440453
Loss at iteration 980 : 0.006361560896039009
Loss at iteration 990 : 0.013281252235174179
Loss at iteration 1000 : 0.0060739414766430855
Loss at iteration 1010 : 0.009085336700081825
Loss at iteration 1020 : 0.011475843377411366
Loss at iteration 1030 : 0.005580805707722902
Loss at iteration 1040 : 0.010602203197777271
Loss at iteration 1050 : 0.010852118022739887
Loss at iteration 1060 : 0.00601613475009799
Loss at iteration 1070 : 0.003060653107240796
Loss at iteration 1080 : 0.0027787107974290848
Loss at iteration 1090 : 0.008168525993824005
Loss at iteration 1100 : 0.010502357967197895
Loss at iteration 1110 : 0.014359873719513416
Loss at iteration 1120 : 0.010604949668049812
Loss at iteration 1130 : 0.006542372517287731
Loss at iteration 1140 : 0.03592236340045929
Loss at iteration 1150 : 0.007813249714672565
Loss at iteration 1160 : 0.01225142739713192
Loss at iteration 1170 : 0.009794973768293858
Loss at iteration 1180 : 0.007208279334008694
Loss at iteration 1190 : 0.006235158070921898
Loss at iteration 1200 : 0.013143686577677727
Loss at iteration 1210 : 0.008173534646630287
Loss at iteration 1220 : 0.009559723548591137
Loss at iteration 1230 : 0.0062927124090492725
Loss at iteration 1240 : 0.013151824474334717
Loss at iteration 1250 : 0.012154468335211277
Loss at iteration 1260 : 0.008773069828748703
Loss at iteration 1270 : 0.010357278399169445
Loss at iteration 1280 : 0.008176863193511963
Loss at iteration 1290 : 0.007607483770698309
Loss at iteration 1300 : 0.007216957863420248
Loss at iteration 1310 : 0.007820183411240578
Loss at iteration 1320 : 0.01644151099026203
Loss at iteration 1330 : 0.008820800110697746
Loss at iteration 1340 : 0.011711189523339272
Loss at iteration 1350 : 0.005286362022161484
Loss at iteration 1360 : 0.003928598947823048
Loss at iteration 1370 : 0.007754080928862095
Loss at iteration 1380 : 0.008475638926029205
Loss at iteration 1390 : 0.005822689272463322
Loss at iteration 1400 : 0.010823613032698631
Loss at iteration 1410 : 0.013847438618540764
Loss at iteration 1420 : 0.00853156391531229
Loss at iteration 1430 : 0.0046137310564517975
Loss at iteration 1440 : 0.009771372191607952
Loss at iteration 1450 : 0.007382906973361969
Loss at iteration 1460 : 0.009959189221262932
Loss at iteration 1470 : 0.006250045262277126
Loss at iteration 1480 : 0.0034246176946908236
Loss at iteration 1490 : 0.011302567087113857
Loss at iteration 1500 : 0.004812178201973438
Loss at iteration 1510 : 0.006662381812930107
Loss at iteration 1520 : 0.01889830082654953
Loss at iteration 1530 : 0.0038511769380420446
Loss at iteration 1540 : 0.011924291029572487
Loss at iteration 1550 : 0.022162752225995064
Loss at iteration 1560 : 0.012212030589580536
Loss at iteration 1570 : 0.003866644110530615
Loss at iteration 1580 : 0.009604508988559246
Loss at iteration 1590 : 0.0036907317116856575
Loss at iteration 1600 : 0.006654441822320223
Loss at iteration 1610 : 0.008266668766736984
Loss at iteration 1620 : 0.00691022165119648
Loss at iteration 1630 : 0.0056932782754302025
Loss at iteration 1640 : 0.01092394720762968
Loss at iteration 1650 : 0.011741358786821365
Loss at iteration 1660 : 0.011595223098993301
Loss at iteration 1670 : 0.014435572549700737
Loss at iteration 1680 : 0.006110118702054024
Loss at iteration 1690 : 0.009185070171952248
Loss at iteration 1700 : 0.01135233324021101
Loss at iteration 1710 : 0.005928521975874901
Loss at iteration 1720 : 0.01020928006619215
Loss at iteration 1730 : 0.007576604373753071
Loss at iteration 1740 : 0.014435973018407822
Loss at iteration 1750 : 0.0037314060609787703
Loss at iteration 1760 : 0.0057831620797514915
Loss at iteration 1770 : 0.007725008763372898
Loss at iteration 1780 : 0.0067644864320755005
Loss at iteration 1790 : 0.017193417996168137
Loss at iteration 1800 : 0.008084326982498169
Loss at iteration 1810 : 0.0056978571228682995
Loss at iteration 1820 : 0.006534084677696228
Loss at iteration 1830 : 0.006508519407361746
Loss at iteration 1840 : 0.009122097864747047
Loss at iteration 1850 : 0.008568297140300274
Loss at iteration 1860 : 0.0072851707227528095
Loss at iteration 1870 : 0.008671867661178112
Loss at iteration 1880 : 0.012436635792255402
Loss at iteration 1890 : 0.007835827767848969
Loss at iteration 1900 : 0.00836517196148634
Loss at iteration 1910 : 0.003523619845509529
Loss at iteration 1920 : 0.0062476652674376965
Loss at iteration 1930 : 0.010253907181322575
Loss at iteration 1940 : 0.009946259669959545
Loss at iteration 1950 : 0.007654304150491953
Loss at iteration 1960 : 0.01787746325135231
Loss at iteration 1970 : 0.010562325827777386
Loss at iteration 1980 : 0.013364851474761963
Loss at iteration 1990 : 0.012463820166885853
Loss at iteration 2000 : 0.012117250822484493
Loss at iteration 2010 : 0.009116509929299355
Loss at iteration 2020 : 0.005204100161790848
Loss at iteration 2030 : 0.010428162291646004
Loss at iteration 2040 : 0.015411014668643475
Loss at iteration 2050 : 0.01065968256443739
Loss at iteration 2060 : 0.016148453578352928
Loss at iteration 2070 : 0.00398617796599865
Loss at iteration 2080 : 0.017230626195669174
Loss at iteration 2090 : 0.009141633287072182
Loss at iteration 2100 : 0.0075253392569720745
Loss at iteration 2110 : 0.00472765089944005
Loss at iteration 2120 : 0.016077468171715736
Loss at iteration 2130 : 0.01114850863814354
Loss at iteration 2140 : 0.013241078704595566
Loss at iteration 2150 : 0.009090288542211056
Loss at iteration 2160 : 0.011666413396596909
Loss at iteration 2170 : 0.0023354708682745695
Loss at iteration 2180 : 0.014434845186769962
Loss at iteration 2190 : 0.005959304515272379
Loss at iteration 2200 : 0.012956652790307999
Loss at iteration 2210 : 0.007086209021508694
Loss at iteration 2220 : 0.005542912520468235
Loss at iteration 2230 : 0.007536300458014011
Loss at iteration 2240 : 0.01813463680446148
Loss at iteration 2250 : 0.009309370070695877
Loss at iteration 2260 : 0.008177259936928749
Loss at iteration 2270 : 0.014492961578071117
Loss at iteration 2280 : 0.012386816553771496
Loss at iteration 2290 : 0.004435827024281025
Loss at iteration 2300 : 0.005554476752877235
Loss at iteration 2310 : 0.010857096873223782
Loss at iteration 2320 : 0.009404894895851612
Loss at iteration 2330 : 0.009689094498753548
Loss at iteration 2340 : 0.00644498597830534
Loss at iteration 2350 : 0.0068187592551112175
Loss at iteration 2360 : 0.011173298582434654
Loss at iteration 2370 : 0.010476703755557537
Loss at iteration 2380 : 0.006173650734126568
Loss at iteration 2390 : 0.010457731783390045
Loss at iteration 2400 : 0.005688742734491825
Loss at iteration 2410 : 0.018265023827552795
Loss at iteration 2420 : 0.012822858989238739
The SSIM Value is: 0.8321376283963521
The PSNR Value is: 21.25311896006266
the epoch is: 65
Loss at iteration 10 : 0.009372531436383724
Loss at iteration 20 : 0.008703488856554031
Loss at iteration 30 : 0.009965133853256702
Loss at iteration 40 : 0.015654398128390312
Loss at iteration 50 : 0.014841509982943535
Loss at iteration 60 : 0.007475229911506176
Loss at iteration 70 : 0.004959822632372379
Loss at iteration 80 : 0.008582270704209805
Loss at iteration 90 : 0.010477516800165176
Loss at iteration 100 : 0.008556472137570381
Loss at iteration 110 : 0.004494781605899334
Loss at iteration 120 : 0.008798688650131226
Loss at iteration 130 : 0.014643117785453796
Loss at iteration 140 : 0.006775325164198875
Loss at iteration 150 : 0.010663677006959915
Loss at iteration 160 : 0.009072867222130299
Loss at iteration 170 : 0.01007873099297285
Loss at iteration 180 : 0.012850220315158367
Loss at iteration 190 : 0.007074798922985792
Loss at iteration 200 : 0.006522918585687876
Loss at iteration 210 : 0.017407581210136414
Loss at iteration 220 : 0.011782130226492882
Loss at iteration 230 : 0.010075289756059647
Loss at iteration 240 : 0.014664721675217152
Loss at iteration 250 : 0.00534012820571661
Loss at iteration 260 : 0.006883387453854084
Loss at iteration 270 : 0.0041509633883833885
Loss at iteration 280 : 0.009136280044913292
Loss at iteration 290 : 0.004643396008759737
Loss at iteration 300 : 0.009599102661013603
Loss at iteration 310 : 0.008652865886688232
Loss at iteration 320 : 0.006788869854062796
Loss at iteration 330 : 0.007878360338509083
Loss at iteration 340 : 0.007394756190478802
Loss at iteration 350 : 0.012266362085938454
Loss at iteration 360 : 0.021112339571118355
Loss at iteration 370 : 0.006979237776249647
Loss at iteration 380 : 0.009273085743188858
Loss at iteration 390 : 0.026467852294445038
Loss at iteration 400 : 0.01763995923101902
Loss at iteration 410 : 0.013545969501137733
Loss at iteration 420 : 0.005170284304767847
Loss at iteration 430 : 0.007695595733821392
Loss at iteration 440 : 0.005573561415076256
Loss at iteration 450 : 0.00986369140446186
Loss at iteration 460 : 0.008966739289462566
Loss at iteration 470 : 0.007642941549420357
Loss at iteration 480 : 0.011143474839627743
Loss at iteration 490 : 0.006500712130218744
Loss at iteration 500 : 0.005095283500850201
Loss at iteration 510 : 0.017157023772597313
Loss at iteration 520 : 0.011737024411559105
Loss at iteration 530 : 0.007873696275055408
Loss at iteration 540 : 0.00751168467104435
Loss at iteration 550 : 0.006452406756579876
Loss at iteration 560 : 0.008575895801186562
Loss at iteration 570 : 0.009724363684654236
Loss at iteration 580 : 0.003404081566259265
Loss at iteration 590 : 0.012273685075342655
Loss at iteration 600 : 0.011237715370953083
Loss at iteration 610 : 0.00615701312199235
Loss at iteration 620 : 0.007154291495680809
Loss at iteration 630 : 0.014724237844347954
Loss at iteration 640 : 0.009351802058517933
Loss at iteration 650 : 0.009333514608442783
Loss at iteration 660 : 0.003077347297221422
Loss at iteration 670 : 0.009100311435759068
Loss at iteration 680 : 0.002721146447584033
Loss at iteration 690 : 0.005337218753993511
Loss at iteration 700 : 0.005950647406280041
Loss at iteration 710 : 0.005645131226629019
Loss at iteration 720 : 0.0054268743842840195
Loss at iteration 730 : 0.01053452119231224
Loss at iteration 740 : 0.009626892395317554
Loss at iteration 750 : 0.016933782026171684
Loss at iteration 760 : 0.01836986094713211
Loss at iteration 770 : 0.004658116959035397
Loss at iteration 780 : 0.011257325299084187
Loss at iteration 790 : 0.008784187026321888
Loss at iteration 800 : 0.005698614753782749
Loss at iteration 810 : 0.021484823897480965
Loss at iteration 820 : 0.020739424973726273
Loss at iteration 830 : 0.017945826053619385
Loss at iteration 840 : 0.008121226914227009
Loss at iteration 850 : 0.0075837718322873116
Loss at iteration 860 : 0.006989983841776848
Loss at iteration 870 : 0.008476673625409603
Loss at iteration 880 : 0.004120432771742344
Loss at iteration 890 : 0.018354106694459915
Loss at iteration 900 : 0.014016552828252316
Loss at iteration 910 : 0.019285954535007477
Loss at iteration 920 : 0.015964075922966003
Loss at iteration 930 : 0.012703537940979004
Loss at iteration 940 : 0.007090867031365633
Loss at iteration 950 : 0.0063484786078333855
Loss at iteration 960 : 0.00951709970831871
Loss at iteration 970 : 0.009704000316560268
Loss at iteration 980 : 0.007188510149717331
Loss at iteration 990 : 0.0090150386095047
Loss at iteration 1000 : 0.011016560718417168
Loss at iteration 1010 : 0.0073975687846541405
Loss at iteration 1020 : 0.007407316472381353
Loss at iteration 1030 : 0.007124339230358601
Loss at iteration 1040 : 0.008739477023482323
Loss at iteration 1050 : 0.008023818954825401
Loss at iteration 1060 : 0.021004248410463333
Loss at iteration 1070 : 0.027279812842607498
Loss at iteration 1080 : 0.0068703750148415565
Loss at iteration 1090 : 0.0038787475787103176
Loss at iteration 1100 : 0.013355127535760403
Loss at iteration 1110 : 0.009099760092794895
Loss at iteration 1120 : 0.011505501344799995
Loss at iteration 1130 : 0.013262448832392693
Loss at iteration 1140 : 0.009089366532862186
Loss at iteration 1150 : 0.003636562265455723
Loss at iteration 1160 : 0.01168317161500454
Loss at iteration 1170 : 0.010406415909528732
Loss at iteration 1180 : 0.009817387908697128
Loss at iteration 1190 : 0.015674088150262833
Loss at iteration 1200 : 0.0042063514702022076
Loss at iteration 1210 : 0.009114616550505161
Loss at iteration 1220 : 0.00878270622342825
Loss at iteration 1230 : 0.00947193056344986
Loss at iteration 1240 : 0.011123537085950375
Loss at iteration 1250 : 0.015452930703759193
Loss at iteration 1260 : 0.010418222285807133
Loss at iteration 1270 : 0.015921922400593758
Loss at iteration 1280 : 0.009491881355643272
Loss at iteration 1290 : 0.01266518235206604
Loss at iteration 1300 : 0.005676725413650274
Loss at iteration 1310 : 0.009817519225180149
Loss at iteration 1320 : 0.0036415874492377043
Loss at iteration 1330 : 0.005387602839618921
Loss at iteration 1340 : 0.007863687351346016
Loss at iteration 1350 : 0.0068124402314424515
Loss at iteration 1360 : 0.012728223577141762
Loss at iteration 1370 : 0.005622561555355787
Loss at iteration 1380 : 0.004911682568490505
Loss at iteration 1390 : 0.004803437739610672
Loss at iteration 1400 : 0.006740668322890997
Loss at iteration 1410 : 0.010933653451502323
Loss at iteration 1420 : 0.010925387032330036
Loss at iteration 1430 : 0.005168294068425894
Loss at iteration 1440 : 0.017945479601621628
Loss at iteration 1450 : 0.006492864340543747
Loss at iteration 1460 : 0.015926102176308632
Loss at iteration 1470 : 0.005093073938041925
Loss at iteration 1480 : 0.006933451630175114
Loss at iteration 1490 : 0.008265960030257702
Loss at iteration 1500 : 0.007888206280767918
Loss at iteration 1510 : 0.006014628801494837
Loss at iteration 1520 : 0.0055103604681789875
Loss at iteration 1530 : 0.024298327043652534
Loss at iteration 1540 : 0.011684119701385498
Loss at iteration 1550 : 0.011523074470460415
Loss at iteration 1560 : 0.006188311148434877
Loss at iteration 1570 : 0.00865166261792183
Loss at iteration 1580 : 0.014567619189620018
Loss at iteration 1590 : 0.009515423327684402
Loss at iteration 1600 : 0.008312515914440155
Loss at iteration 1610 : 0.010111378505825996
Loss at iteration 1620 : 0.014713933691382408
Loss at iteration 1630 : 0.015045281499624252
Loss at iteration 1640 : 0.013598729856312275
Loss at iteration 1650 : 0.02072400599718094
Loss at iteration 1660 : 0.008750244043767452
Loss at iteration 1670 : 0.01563592255115509
Loss at iteration 1680 : 0.007275458425283432
Loss at iteration 1690 : 0.013531779870390892
Loss at iteration 1700 : 0.019737470895051956
Loss at iteration 1710 : 0.00847027637064457
Loss at iteration 1720 : 0.01718965172767639
Loss at iteration 1730 : 0.033084750175476074
Loss at iteration 1740 : 0.003482293803244829
Loss at iteration 1750 : 0.022527631372213364
Loss at iteration 1760 : 0.01304619386792183
Loss at iteration 1770 : 0.012285923585295677
Loss at iteration 1780 : 0.008056415244936943
Loss at iteration 1790 : 0.011738752014935017
Loss at iteration 1800 : 0.008016129024326801
Loss at iteration 1810 : 0.009284823201596737
Loss at iteration 1820 : 0.02209450490772724
Loss at iteration 1830 : 0.005478446837514639
Loss at iteration 1840 : 0.005153080448508263
Loss at iteration 1850 : 0.00877334550023079
Loss at iteration 1860 : 0.01485105324536562
Loss at iteration 1870 : 0.016693567857146263
Loss at iteration 1880 : 0.004817331675440073
Loss at iteration 1890 : 0.009573360905051231
Loss at iteration 1900 : 0.017315596342086792
Loss at iteration 1910 : 0.005963762290775776
Loss at iteration 1920 : 0.005206267349421978
Loss at iteration 1930 : 0.005580252036452293
Loss at iteration 1940 : 0.006655010394752026
Loss at iteration 1950 : 0.012231755070388317
Loss at iteration 1960 : 0.0068438188172876835
Loss at iteration 1970 : 0.003940480761229992
Loss at iteration 1980 : 0.03799952566623688
Loss at iteration 1990 : 0.008705329149961472
Loss at iteration 2000 : 0.014508391730487347
Loss at iteration 2010 : 0.010660821571946144
Loss at iteration 2020 : 0.013080301694571972
Loss at iteration 2030 : 0.008488168008625507
Loss at iteration 2040 : 0.020001903176307678
Loss at iteration 2050 : 0.004061924293637276
Loss at iteration 2060 : 0.013290165923535824
Loss at iteration 2070 : 0.013404615223407745
Loss at iteration 2080 : 0.008688170462846756
Loss at iteration 2090 : 0.007625604048371315
Loss at iteration 2100 : 0.009557436220347881
Loss at iteration 2110 : 0.01568981632590294
Loss at iteration 2120 : 0.011351746506989002
Loss at iteration 2130 : 0.007111009210348129
Loss at iteration 2140 : 0.004091386683285236
Loss at iteration 2150 : 0.007937250658869743
Loss at iteration 2160 : 0.003611240303143859
Loss at iteration 2170 : 0.008219163864850998
Loss at iteration 2180 : 0.01052822731435299
Loss at iteration 2190 : 0.00625214446336031
Loss at iteration 2200 : 0.016314920037984848
Loss at iteration 2210 : 0.022508744150400162
Loss at iteration 2220 : 0.013007037341594696
Loss at iteration 2230 : 0.0065687973983585835
Loss at iteration 2240 : 0.011674569919705391
Loss at iteration 2250 : 0.008135153912007809
Loss at iteration 2260 : 0.007971644401550293
Loss at iteration 2270 : 0.012378811836242676
Loss at iteration 2280 : 0.006250147707760334
Loss at iteration 2290 : 0.004598565399646759
Loss at iteration 2300 : 0.005295013543218374
Loss at iteration 2310 : 0.00296906940639019
Loss at iteration 2320 : 0.005541781894862652
Loss at iteration 2330 : 0.005244100000709295
Loss at iteration 2340 : 0.007699791807681322
Loss at iteration 2350 : 0.014307476580142975
Loss at iteration 2360 : 0.0053528305143117905
Loss at iteration 2370 : 0.009108887985348701
Loss at iteration 2380 : 0.015005303546786308
Loss at iteration 2390 : 0.01922348327934742
Loss at iteration 2400 : 0.010492020286619663
Loss at iteration 2410 : 0.009684868156909943
Loss at iteration 2420 : 0.007022609934210777
The SSIM Value is: 0.8334074179331462
The PSNR Value is: 21.213911628723146
the epoch is: 66
Loss at iteration 10 : 0.013374089263379574
Loss at iteration 20 : 0.010703349485993385
Loss at iteration 30 : 0.010430153459310532
Loss at iteration 40 : 0.009902287274599075
Loss at iteration 50 : 0.007202645298093557
Loss at iteration 60 : 0.004497419111430645
Loss at iteration 70 : 0.007324035279452801
Loss at iteration 80 : 0.009370487183332443
Loss at iteration 90 : 0.0031113126315176487
Loss at iteration 100 : 0.009322809986770153
Loss at iteration 110 : 0.011808520182967186
Loss at iteration 120 : 0.010569492354989052
Loss at iteration 130 : 0.0054040453396737576
Loss at iteration 140 : 0.0027093212120234966
Loss at iteration 150 : 0.008695174939930439
Loss at iteration 160 : 0.0064387512393295765
Loss at iteration 170 : 0.008367235772311687
Loss at iteration 180 : 0.010557776317000389
Loss at iteration 190 : 0.006602275650948286
Loss at iteration 200 : 0.005607431288808584
Loss at iteration 210 : 0.014737284742295742
Loss at iteration 220 : 0.006479472853243351
Loss at iteration 230 : 0.005506571847945452
Loss at iteration 240 : 0.007921426557004452
Loss at iteration 250 : 0.0050378344021737576
Loss at iteration 260 : 0.013507938012480736
Loss at iteration 270 : 0.005918461363762617
Loss at iteration 280 : 0.004755166359245777
Loss at iteration 290 : 0.01138355303555727
Loss at iteration 300 : 0.005503063090145588
Loss at iteration 310 : 0.013345860876142979
Loss at iteration 320 : 0.00614415155723691
Loss at iteration 330 : 0.018949637189507484
Loss at iteration 340 : 0.00978061556816101
Loss at iteration 350 : 0.009789291769266129
Loss at iteration 360 : 0.013152548111975193
Loss at iteration 370 : 0.010881009511649609
Loss at iteration 380 : 0.019665712490677834
Loss at iteration 390 : 0.01194924395531416
Loss at iteration 400 : 0.0106841791421175
Loss at iteration 410 : 0.0045903827995061874
Loss at iteration 420 : 0.013507012277841568
Loss at iteration 430 : 0.004430845379829407
Loss at iteration 440 : 0.007468202151358128
Loss at iteration 450 : 0.005113692954182625
Loss at iteration 460 : 0.005050708539783955
Loss at iteration 470 : 0.016724389046430588
Loss at iteration 480 : 0.004574146121740341
Loss at iteration 490 : 0.01070105005055666
Loss at iteration 500 : 0.003656442044302821
Loss at iteration 510 : 0.010623177513480186
Loss at iteration 520 : 0.010288938879966736
Loss at iteration 530 : 0.011423998512327671
Loss at iteration 540 : 0.005924656055867672
Loss at iteration 550 : 0.002595009747892618
Loss at iteration 560 : 0.010730931535363197
Loss at iteration 570 : 0.008776922710239887
Loss at iteration 580 : 0.00914460513740778
Loss at iteration 590 : 0.007728303782641888
Loss at iteration 600 : 0.009639579802751541
Loss at iteration 610 : 0.0061942581087350845
Loss at iteration 620 : 0.01377804297953844
Loss at iteration 630 : 0.009322764351963997
Loss at iteration 640 : 0.0046287039294838905
Loss at iteration 650 : 0.008651940152049065
Loss at iteration 660 : 0.004072368610650301
Loss at iteration 670 : 0.004164263606071472
Loss at iteration 680 : 0.0055135637521743774
Loss at iteration 690 : 0.006691376678645611
Loss at iteration 700 : 0.007587798405438662
Loss at iteration 710 : 0.00714883953332901
Loss at iteration 720 : 0.0027908245101571083
Loss at iteration 730 : 0.01034698449075222
Loss at iteration 740 : 0.011041101068258286
Loss at iteration 750 : 0.0058441925793886185
Loss at iteration 760 : 0.01573294587433338
Loss at iteration 770 : 0.008154697716236115
Loss at iteration 780 : 0.010970201343297958
Loss at iteration 790 : 0.009814238175749779
Loss at iteration 800 : 0.010893629863858223
Loss at iteration 810 : 0.012017615139484406
Loss at iteration 820 : 0.006191484164446592
Loss at iteration 830 : 0.009544333443045616
Loss at iteration 840 : 0.011769561097025871
Loss at iteration 850 : 0.00608764449134469
Loss at iteration 860 : 0.00554698659107089
Loss at iteration 870 : 0.004809900186955929
Loss at iteration 880 : 0.004835623316466808
Loss at iteration 890 : 0.014392112381756306
Loss at iteration 900 : 0.006035105790942907
Loss at iteration 910 : 0.0036518906708806753
Loss at iteration 920 : 0.01512492448091507
Loss at iteration 930 : 0.006706454791128635
Loss at iteration 940 : 0.0023678834550082684
Loss at iteration 950 : 0.00702855596318841
Loss at iteration 960 : 0.010528931394219398
Loss at iteration 970 : 0.012096128426492214
Loss at iteration 980 : 0.0075049856677651405
Loss at iteration 990 : 0.019894467666745186
Loss at iteration 1000 : 0.008975195698440075
Loss at iteration 1010 : 0.006643357686698437
Loss at iteration 1020 : 0.010903307236731052
Loss at iteration 1030 : 0.006941702216863632
Loss at iteration 1040 : 0.010222158394753933
Loss at iteration 1050 : 0.007263256702572107
Loss at iteration 1060 : 0.007358185015618801
Loss at iteration 1070 : 0.01093192771077156
Loss at iteration 1080 : 0.008019075728952885
Loss at iteration 1090 : 0.010549001395702362
Loss at iteration 1100 : 0.0030213799327611923
Loss at iteration 1110 : 0.01658918708562851
Loss at iteration 1120 : 0.013532006181776524
Loss at iteration 1130 : 0.01943022757768631
Loss at iteration 1140 : 0.009544067084789276
Loss at iteration 1150 : 0.018242329359054565
Loss at iteration 1160 : 0.018955105915665627
Loss at iteration 1170 : 0.015480110421776772
Loss at iteration 1180 : 0.008246326819062233
Loss at iteration 1190 : 0.015170572325587273
Loss at iteration 1200 : 0.008680583909153938
Loss at iteration 1210 : 0.011674321256577969
Loss at iteration 1220 : 0.009129063226282597
Loss at iteration 1230 : 0.010540042072534561
Loss at iteration 1240 : 0.007934875786304474
Loss at iteration 1250 : 0.010943371802568436
Loss at iteration 1260 : 0.016514841467142105
Loss at iteration 1270 : 0.0073792822659015656
Loss at iteration 1280 : 0.012141134589910507
Loss at iteration 1290 : 0.005481867119669914
Loss at iteration 1300 : 0.007132737897336483
Loss at iteration 1310 : 0.022574476897716522
Loss at iteration 1320 : 0.007747598923742771
Loss at iteration 1330 : 0.004996686242520809
Loss at iteration 1340 : 0.02075323835015297
Loss at iteration 1350 : 0.00952718686312437
Loss at iteration 1360 : 0.009048789739608765
Loss at iteration 1370 : 0.018285496160387993
Loss at iteration 1380 : 0.0040297601372003555
Loss at iteration 1390 : 0.0291934572160244
Loss at iteration 1400 : 0.006384817883372307
Loss at iteration 1410 : 0.013122021220624447
Loss at iteration 1420 : 0.005782892927527428
Loss at iteration 1430 : 0.003966150339692831
Loss at iteration 1440 : 0.011286620050668716
Loss at iteration 1450 : 0.00857493281364441
Loss at iteration 1460 : 0.010440915822982788
Loss at iteration 1470 : 0.013049937784671783
Loss at iteration 1480 : 0.0071311332285404205
Loss at iteration 1490 : 0.00385663122870028
Loss at iteration 1500 : 0.01937728002667427
Loss at iteration 1510 : 0.009278727695345879
Loss at iteration 1520 : 0.012379906140267849
Loss at iteration 1530 : 0.003808355890214443
Loss at iteration 1540 : 0.0048174867406487465
Loss at iteration 1550 : 0.012287634424865246
Loss at iteration 1560 : 0.013011358678340912
Loss at iteration 1570 : 0.007450825069099665
Loss at iteration 1580 : 0.0075360448099672794
Loss at iteration 1590 : 0.012440843507647514
Loss at iteration 1600 : 0.011936808004975319
Loss at iteration 1610 : 0.004190805368125439
Loss at iteration 1620 : 0.011324924416840076
Loss at iteration 1630 : 0.0068476093001663685
Loss at iteration 1640 : 0.0052582756616175175
Loss at iteration 1650 : 0.010599236935377121
Loss at iteration 1660 : 0.014529045671224594
Loss at iteration 1670 : 0.005697237327694893
Loss at iteration 1680 : 0.007498936727643013
Loss at iteration 1690 : 0.005735764745622873
Loss at iteration 1700 : 0.010005264542996883
Loss at iteration 1710 : 0.008930496871471405
Loss at iteration 1720 : 0.01293161790817976
Loss at iteration 1730 : 0.007060487288981676
Loss at iteration 1740 : 0.005343661643564701
Loss at iteration 1750 : 0.010186372324824333
Loss at iteration 1760 : 0.009426260367035866
Loss at iteration 1770 : 0.0041861459612846375
Loss at iteration 1780 : 0.005593066569417715
Loss at iteration 1790 : 0.009752895683050156
Loss at iteration 1800 : 0.007647165097296238
Loss at iteration 1810 : 0.007783151231706142
Loss at iteration 1820 : 0.009867813438177109
Loss at iteration 1830 : 0.0062863766215741634
Loss at iteration 1840 : 0.00427671754732728
Loss at iteration 1850 : 0.009024934843182564
Loss at iteration 1860 : 0.009783868677914143
Loss at iteration 1870 : 0.009134352207183838
Loss at iteration 1880 : 0.005912032909691334
Loss at iteration 1890 : 0.014070302248001099
Loss at iteration 1900 : 0.01104404591023922
Loss at iteration 1910 : 0.013145891949534416
Loss at iteration 1920 : 0.006798791233450174
Loss at iteration 1930 : 0.011361283250153065
Loss at iteration 1940 : 0.005823581479489803
Loss at iteration 1950 : 0.01458422839641571
Loss at iteration 1960 : 0.011197289451956749
Loss at iteration 1970 : 0.007176682353019714
Loss at iteration 1980 : 0.022166911512613297
Loss at iteration 1990 : 0.009598692879080772
Loss at iteration 2000 : 0.013368278741836548
Loss at iteration 2010 : 0.010082647204399109
Loss at iteration 2020 : 0.012283126823604107
Loss at iteration 2030 : 0.011192219331860542
Loss at iteration 2040 : 0.014317081309854984
Loss at iteration 2050 : 0.009417783468961716
Loss at iteration 2060 : 0.012406950816512108
Loss at iteration 2070 : 0.012045844458043575
Loss at iteration 2080 : 0.012143632397055626
Loss at iteration 2090 : 0.019564034417271614
Loss at iteration 2100 : 0.015703614801168442
Loss at iteration 2110 : 0.013353842310607433
Loss at iteration 2120 : 0.011568831279873848
Loss at iteration 2130 : 0.008390270173549652
Loss at iteration 2140 : 0.007592241279780865
Loss at iteration 2150 : 0.004981439560651779
Loss at iteration 2160 : 0.015574829652905464
Loss at iteration 2170 : 0.006702701561152935
Loss at iteration 2180 : 0.008408837951719761
Loss at iteration 2190 : 0.007724447175860405
Loss at iteration 2200 : 0.014760193414986134
Loss at iteration 2210 : 0.006372561678290367
Loss at iteration 2220 : 0.00553492084145546
Loss at iteration 2230 : 0.005900674033910036
Loss at iteration 2240 : 0.004784385208040476
Loss at iteration 2250 : 0.020627817139029503
Loss at iteration 2260 : 0.016112180426716805
Loss at iteration 2270 : 0.007158702239394188
Loss at iteration 2280 : 0.0049659451469779015
Loss at iteration 2290 : 0.004029877949506044
Loss at iteration 2300 : 0.008930695243179798
Loss at iteration 2310 : 0.009189675562083721
Loss at iteration 2320 : 0.0040523395873606205
Loss at iteration 2330 : 0.008302522823214531
Loss at iteration 2340 : 0.009464792907238007
Loss at iteration 2350 : 0.01360310148447752
Loss at iteration 2360 : 0.0066244108602404594
Loss at iteration 2370 : 0.012666624039411545
Loss at iteration 2380 : 0.008218174800276756
Loss at iteration 2390 : 0.01361224427819252
Loss at iteration 2400 : 0.004942776169627905
Loss at iteration 2410 : 0.01444949023425579
Loss at iteration 2420 : 0.008894890546798706
The SSIM Value is: 0.8434548020362854
The PSNR Value is: 21.575918006896973
the epoch is: 67
Loss at iteration 10 : 0.013781968504190445
Loss at iteration 20 : 0.006539602298289537
Loss at iteration 30 : 0.009140534326434135
Loss at iteration 40 : 0.015454770065844059
Loss at iteration 50 : 0.005808400455862284
Loss at iteration 60 : 0.011911542154848576
Loss at iteration 70 : 0.010539786890149117
Loss at iteration 80 : 0.008006083779036999
Loss at iteration 90 : 0.010185431689023972
Loss at iteration 100 : 0.00597468251362443
Loss at iteration 110 : 0.014130568131804466
Loss at iteration 120 : 0.0026936389040201902
Loss at iteration 130 : 0.011496521532535553
Loss at iteration 140 : 0.013661098666489124
Loss at iteration 150 : 0.01705281250178814
Loss at iteration 160 : 0.00670438539236784
Loss at iteration 170 : 0.004962854087352753
Loss at iteration 180 : 0.010488159954547882
Loss at iteration 190 : 0.014053236693143845
Loss at iteration 200 : 0.009496853686869144
Loss at iteration 210 : 0.010746951214969158
Loss at iteration 220 : 0.009846641682088375
Loss at iteration 230 : 0.01424503792077303
Loss at iteration 240 : 0.013940735720098019
Loss at iteration 250 : 0.009771469980478287
Loss at iteration 260 : 0.008166905492544174
Loss at iteration 270 : 0.014348982833325863
Loss at iteration 280 : 0.016489308327436447
Loss at iteration 290 : 0.008186348713934422
Loss at iteration 300 : 0.007376500405371189
Loss at iteration 310 : 0.0046534426510334015
Loss at iteration 320 : 0.00932270847260952
Loss at iteration 330 : 0.00552264042198658
Loss at iteration 340 : 0.010582711547613144
Loss at iteration 350 : 0.0021688397973775864
Loss at iteration 360 : 0.013011434115469456
Loss at iteration 370 : 0.01051761768758297
Loss at iteration 380 : 0.008525047451257706
Loss at iteration 390 : 0.009163282811641693
Loss at iteration 400 : 0.014055158011615276
Loss at iteration 410 : 0.01041664369404316
Loss at iteration 420 : 0.003035372355952859
Loss at iteration 430 : 0.017336413264274597
Loss at iteration 440 : 0.010472298599779606
Loss at iteration 450 : 0.002487847115844488
Loss at iteration 460 : 0.009634355083107948
Loss at iteration 470 : 0.016117310151457787
Loss at iteration 480 : 0.005564069841057062
Loss at iteration 490 : 0.010543384589254856
Loss at iteration 500 : 0.011923318728804588
Loss at iteration 510 : 0.008827410638332367
Loss at iteration 520 : 0.015430379658937454
Loss at iteration 530 : 0.012351877987384796
Loss at iteration 540 : 0.013729875907301903
Loss at iteration 550 : 0.004166256170719862
Loss at iteration 560 : 0.017796341329813004
Loss at iteration 570 : 0.010469126515090466
Loss at iteration 580 : 0.012034749612212181
Loss at iteration 590 : 0.007513744756579399
Loss at iteration 600 : 0.004015258513391018
Loss at iteration 610 : 0.005329743959009647
Loss at iteration 620 : 0.006176495924592018
Loss at iteration 630 : 0.002777046523988247
Loss at iteration 640 : 0.008022787049412727
Loss at iteration 650 : 0.0075969514437019825
Loss at iteration 660 : 0.009476554580032825
Loss at iteration 670 : 0.010534901171922684
Loss at iteration 680 : 0.011478493921458721
Loss at iteration 690 : 0.018283182755112648
Loss at iteration 700 : 0.01136755384504795
Loss at iteration 710 : 0.009947780519723892
Loss at iteration 720 : 0.008205976337194443
Loss at iteration 730 : 0.0034673020709306
Loss at iteration 740 : 0.007758584339171648
Loss at iteration 750 : 0.00978845078498125
Loss at iteration 760 : 0.014475664123892784
Loss at iteration 770 : 0.009605392813682556
Loss at iteration 780 : 0.010842950083315372
Loss at iteration 790 : 0.009316426701843739
Loss at iteration 800 : 0.0069478703662753105
Loss at iteration 810 : 0.009947570972144604
Loss at iteration 820 : 0.00907936692237854
Loss at iteration 830 : 0.007381831295788288
Loss at iteration 840 : 0.011624529957771301
Loss at iteration 850 : 0.0024075715336948633
Loss at iteration 860 : 0.00253691291436553
Loss at iteration 870 : 0.007431740872561932
Loss at iteration 880 : 0.005585785955190659
Loss at iteration 890 : 0.006739052012562752
Loss at iteration 900 : 0.0111704021692276
Loss at iteration 910 : 0.004903857596218586
Loss at iteration 920 : 0.0039003221318125725
Loss at iteration 930 : 0.00951643381267786
Loss at iteration 940 : 0.033930517733097076
Loss at iteration 950 : 0.032433442771434784
Loss at iteration 960 : 0.012789576314389706
Loss at iteration 970 : 0.004157105460762978
Loss at iteration 980 : 0.011497275903820992
Loss at iteration 990 : 0.010161413811147213
Loss at iteration 1000 : 0.012086580507457256
Loss at iteration 1010 : 0.004890762735158205
Loss at iteration 1020 : 0.007071357686072588
Loss at iteration 1030 : 0.012494849041104317
Loss at iteration 1040 : 0.004676304291933775
Loss at iteration 1050 : 0.009557219222187996
Loss at iteration 1060 : 0.009688379243016243
Loss at iteration 1070 : 0.019543100148439407
Loss at iteration 1080 : 0.007975328713655472
Loss at iteration 1090 : 0.009346472099423409
Loss at iteration 1100 : 0.008670475333929062
Loss at iteration 1110 : 0.005640415009111166
Loss at iteration 1120 : 0.012343786656856537
Loss at iteration 1130 : 0.010690009221434593
Loss at iteration 1140 : 0.004547548480331898
Loss at iteration 1150 : 0.011484299786388874
Loss at iteration 1160 : 0.010347818955779076
Loss at iteration 1170 : 0.010951468721032143
Loss at iteration 1180 : 0.015377161093056202
Loss at iteration 1190 : 0.006910613738000393
Loss at iteration 1200 : 0.012414845637977123
Loss at iteration 1210 : 0.01001592818647623
Loss at iteration 1220 : 0.009242231026291847
Loss at iteration 1230 : 0.004839061759412289
Loss at iteration 1240 : 0.013630206696689129
Loss at iteration 1250 : 0.01642584055662155
Loss at iteration 1260 : 0.011911524459719658
Loss at iteration 1270 : 0.009725838899612427
Loss at iteration 1280 : 0.024664750322699547
Loss at iteration 1290 : 0.011586722917854786
Loss at iteration 1300 : 0.020086299628019333
Loss at iteration 1310 : 0.00940922275185585
Loss at iteration 1320 : 0.00391800282523036
Loss at iteration 1330 : 0.012874399311840534
Loss at iteration 1340 : 0.011916549876332283
Loss at iteration 1350 : 0.013295679353177547
Loss at iteration 1360 : 0.0019982210360467434
Loss at iteration 1370 : 0.004131324589252472
Loss at iteration 1380 : 0.011775247752666473
Loss at iteration 1390 : 0.011810263618826866
Loss at iteration 1400 : 0.007041172124445438
Loss at iteration 1410 : 0.007971111685037613
Loss at iteration 1420 : 0.0037943432107567787
Loss at iteration 1430 : 0.024082563817501068
Loss at iteration 1440 : 0.011639386415481567
Loss at iteration 1450 : 0.011220433749258518
Loss at iteration 1460 : 0.004596904385834932
Loss at iteration 1470 : 0.01306397095322609
Loss at iteration 1480 : 0.012420580722391605
Loss at iteration 1490 : 0.007427415810525417
Loss at iteration 1500 : 0.021620795130729675
Loss at iteration 1510 : 0.0018630143022164702
Loss at iteration 1520 : 0.028943654149770737
Loss at iteration 1530 : 0.012919636443257332
Loss at iteration 1540 : 0.006211074069142342
Loss at iteration 1550 : 0.012806767597794533
Loss at iteration 1560 : 0.0025280150584876537
Loss at iteration 1570 : 0.015209127217531204
Loss at iteration 1580 : 0.007442386355251074
Loss at iteration 1590 : 0.008587853983044624
Loss at iteration 1600 : 0.006591039709746838
Loss at iteration 1610 : 0.005548721179366112
Loss at iteration 1620 : 0.006237892899662256
Loss at iteration 1630 : 0.030711006373167038
Loss at iteration 1640 : 0.008047855459153652
Loss at iteration 1650 : 0.008745667524635792
Loss at iteration 1660 : 0.005689156241714954
Loss at iteration 1670 : 0.017588339745998383
Loss at iteration 1680 : 0.0061894492246210575
Loss at iteration 1690 : 0.009440712630748749
Loss at iteration 1700 : 0.010387822985649109
Loss at iteration 1710 : 0.007266689091920853
Loss at iteration 1720 : 0.014708838425576687
Loss at iteration 1730 : 0.0037056480068713427
Loss at iteration 1740 : 0.0060619390569627285
Loss at iteration 1750 : 0.00817100889980793
Loss at iteration 1760 : 0.009327009320259094
Loss at iteration 1770 : 0.021573062986135483
Loss at iteration 1780 : 0.01385083980858326
Loss at iteration 1790 : 0.010135585442185402
Loss at iteration 1800 : 0.013961573131382465
Loss at iteration 1810 : 0.006536280270665884
Loss at iteration 1820 : 0.00699477456510067
Loss at iteration 1830 : 0.015211599878966808
Loss at iteration 1840 : 0.00505222100764513
Loss at iteration 1850 : 0.00715621467679739
Loss at iteration 1860 : 0.018758483231067657
Loss at iteration 1870 : 0.01945083774626255
Loss at iteration 1880 : 0.0027182770427316427
Loss at iteration 1890 : 0.008945785462856293
Loss at iteration 1900 : 0.009981203824281693
Loss at iteration 1910 : 0.035189174115657806
Loss at iteration 1920 : 0.009420787915587425
Loss at iteration 1930 : 0.005569789092987776
Loss at iteration 1940 : 0.005274883005768061
Loss at iteration 1950 : 0.016091659665107727
Loss at iteration 1960 : 0.018507864326238632
Loss at iteration 1970 : 0.011417312547564507
Loss at iteration 1980 : 0.010800124146044254
Loss at iteration 1990 : 0.011610062792897224
Loss at iteration 2000 : 0.009699283167719841
Loss at iteration 2010 : 0.022711453959345818
Loss at iteration 2020 : 0.019526220858097076
Loss at iteration 2030 : 0.003937046509236097
Loss at iteration 2040 : 0.012165325693786144
Loss at iteration 2050 : 0.0056819673627614975
Loss at iteration 2060 : 0.011198563501238823
Loss at iteration 2070 : 0.006462708115577698
Loss at iteration 2080 : 0.011047348380088806
Loss at iteration 2090 : 0.01574082486331463
Loss at iteration 2100 : 0.0075231934897601604
Loss at iteration 2110 : 0.0097667146474123
Loss at iteration 2120 : 0.013932719826698303
Loss at iteration 2130 : 0.019846579059958458
Loss at iteration 2140 : 0.006939487066119909
Loss at iteration 2150 : 0.006610865704715252
Loss at iteration 2160 : 0.007588583510369062
Loss at iteration 2170 : 0.00641782209277153
Loss at iteration 2180 : 0.006791105959564447
Loss at iteration 2190 : 0.007501915097236633
Loss at iteration 2200 : 0.009236644953489304
Loss at iteration 2210 : 0.014906148426234722
Loss at iteration 2220 : 0.012814130634069443
Loss at iteration 2230 : 0.009064012207090855
Loss at iteration 2240 : 0.007319638505578041
Loss at iteration 2250 : 0.006035023834556341
Loss at iteration 2260 : 0.008986381813883781
Loss at iteration 2270 : 0.011361353099346161
Loss at iteration 2280 : 0.006954840384423733
Loss at iteration 2290 : 0.008810085244476795
Loss at iteration 2300 : 0.00773683562874794
Loss at iteration 2310 : 0.011403670534491539
Loss at iteration 2320 : 0.008620587177574635
Loss at iteration 2330 : 0.006290976889431477
Loss at iteration 2340 : 0.0059866635128855705
Loss at iteration 2350 : 0.015746109187602997
Loss at iteration 2360 : 0.005986575968563557
Loss at iteration 2370 : 0.010920485481619835
Loss at iteration 2380 : 0.008416468277573586
Loss at iteration 2390 : 0.018379423767328262
Loss at iteration 2400 : 0.012251079082489014
Loss at iteration 2410 : 0.005429733544588089
Loss at iteration 2420 : 0.010248270817101002
The SSIM Value is: 0.8425299564997355
The PSNR Value is: 21.946654510498046
the epoch is: 68
Loss at iteration 10 : 0.015227152034640312
Loss at iteration 20 : 0.011000452563166618
Loss at iteration 30 : 0.007819798775017262
Loss at iteration 40 : 0.010871738195419312
Loss at iteration 50 : 0.01044558733701706
Loss at iteration 60 : 0.010853069834411144
Loss at iteration 70 : 0.010095955803990364
Loss at iteration 80 : 0.005550737492740154
Loss at iteration 90 : 0.012173996306955814
Loss at iteration 100 : 0.007847769185900688
Loss at iteration 110 : 0.005927895661443472
Loss at iteration 120 : 0.020455341786146164
Loss at iteration 130 : 0.006197085604071617
Loss at iteration 140 : 0.011228082701563835
Loss at iteration 150 : 0.006696789059787989
Loss at iteration 160 : 0.011695501394569874
Loss at iteration 170 : 0.00925317034125328
Loss at iteration 180 : 0.009371067397296429
Loss at iteration 190 : 0.010191233828663826
Loss at iteration 200 : 0.006877278443425894
Loss at iteration 210 : 0.007484667003154755
Loss at iteration 220 : 0.0061013903468847275
Loss at iteration 230 : 0.010587620548903942
Loss at iteration 240 : 0.009840019978582859
Loss at iteration 250 : 0.010454054921865463
Loss at iteration 260 : 0.0075025735422968864
Loss at iteration 270 : 0.01130380854010582
Loss at iteration 280 : 0.012643814086914062
Loss at iteration 290 : 0.006228229030966759
Loss at iteration 300 : 0.003773554228246212
Loss at iteration 310 : 0.010034136474132538
Loss at iteration 320 : 0.011275991797447205
Loss at iteration 330 : 0.007969092577695847
Loss at iteration 340 : 0.00694282166659832
Loss at iteration 350 : 0.01039198786020279
Loss at iteration 360 : 0.006017263047397137
Loss at iteration 370 : 0.011976756155490875
Loss at iteration 380 : 0.015630656853318214
Loss at iteration 390 : 0.006376475095748901
Loss at iteration 400 : 0.009291155263781548
Loss at iteration 410 : 0.012066209688782692
Loss at iteration 420 : 0.009698888286948204
Loss at iteration 430 : 0.00833800621330738
Loss at iteration 440 : 0.0049750711768865585
Loss at iteration 450 : 0.008660941384732723
Loss at iteration 460 : 0.008804470300674438
Loss at iteration 470 : 0.014362264424562454
Loss at iteration 480 : 0.01330745592713356
Loss at iteration 490 : 0.026757461950182915
Loss at iteration 500 : 0.010452844202518463
Loss at iteration 510 : 0.003950065467506647
Loss at iteration 520 : 0.008366139605641365
Loss at iteration 530 : 0.014248301275074482
Loss at iteration 540 : 0.011457440443336964
Loss at iteration 550 : 0.01002470776438713
Loss at iteration 560 : 0.028823748230934143
Loss at iteration 570 : 0.015776310116052628
Loss at iteration 580 : 0.014756808057427406
Loss at iteration 590 : 0.009568349458277225
Loss at iteration 600 : 0.0026887929998338223
Loss at iteration 610 : 0.016594473272562027
Loss at iteration 620 : 0.009827126748859882
Loss at iteration 630 : 0.008843021467328072
Loss at iteration 640 : 0.007211717776954174
Loss at iteration 650 : 0.014758256264030933
Loss at iteration 660 : 0.01104854978621006
Loss at iteration 670 : 0.005036676302552223
Loss at iteration 680 : 0.02107725292444229
Loss at iteration 690 : 0.012220307253301144
Loss at iteration 700 : 0.01015695184469223
Loss at iteration 710 : 0.015509137883782387
Loss at iteration 720 : 0.009424474090337753
Loss at iteration 730 : 0.011447771452367306
Loss at iteration 740 : 0.011744335293769836
Loss at iteration 750 : 0.00820227526128292
Loss at iteration 760 : 0.007098682224750519
Loss at iteration 770 : 0.013010933995246887
Loss at iteration 780 : 0.011232022196054459
Loss at iteration 790 : 0.007600746117532253
Loss at iteration 800 : 0.007700774818658829
Loss at iteration 810 : 0.005958412773907185
Loss at iteration 820 : 0.008697658777236938
Loss at iteration 830 : 0.008665954694151878
Loss at iteration 840 : 0.004636633209884167
Loss at iteration 850 : 0.008846059441566467
Loss at iteration 860 : 0.014866325072944164
Loss at iteration 870 : 0.008947852067649364
Loss at iteration 880 : 0.006452166475355625
Loss at iteration 890 : 0.007177574094384909
Loss at iteration 900 : 0.014296283014118671
Loss at iteration 910 : 0.007873865775763988
Loss at iteration 920 : 0.011062110774219036
Loss at iteration 930 : 0.0017181448638439178
Loss at iteration 940 : 0.0032338793389499187
Loss at iteration 950 : 0.01402223389595747
Loss at iteration 960 : 0.005914341192692518
Loss at iteration 970 : 0.00839149672538042
Loss at iteration 980 : 0.009394178166985512
Loss at iteration 990 : 0.008577902801334858
Loss at iteration 1000 : 0.0035945801064372063
Loss at iteration 1010 : 0.018933085724711418
Loss at iteration 1020 : 0.008112570270895958
Loss at iteration 1030 : 0.01020841859281063
Loss at iteration 1040 : 0.009565891698002815
Loss at iteration 1050 : 0.00532242376357317
Loss at iteration 1060 : 0.00757221132516861
Loss at iteration 1070 : 0.007551006507128477
Loss at iteration 1080 : 0.007169925607740879
Loss at iteration 1090 : 0.008022147230803967
Loss at iteration 1100 : 0.008232306689023972
Loss at iteration 1110 : 0.006668270565569401
Loss at iteration 1120 : 0.012776022776961327
Loss at iteration 1130 : 0.012382155284285545
Loss at iteration 1140 : 0.013324156403541565
Loss at iteration 1150 : 0.0062604742124676704
Loss at iteration 1160 : 0.015859324485063553
Loss at iteration 1170 : 0.008024759590625763
Loss at iteration 1180 : 0.015458835288882256
Loss at iteration 1190 : 0.0019119910430163145
Loss at iteration 1200 : 0.009544366970658302
Loss at iteration 1210 : 0.015833815559744835
Loss at iteration 1220 : 0.012030023150146008
Loss at iteration 1230 : 0.007337481249123812
Loss at iteration 1240 : 0.01512385718524456
Loss at iteration 1250 : 0.005544333718717098
Loss at iteration 1260 : 0.011257261037826538
Loss at iteration 1270 : 0.007172573357820511
Loss at iteration 1280 : 0.018383920192718506
Loss at iteration 1290 : 0.00865416694432497
Loss at iteration 1300 : 0.005617249291390181
Loss at iteration 1310 : 0.00832764245569706
Loss at iteration 1320 : 0.008014364168047905
Loss at iteration 1330 : 0.01923382095992565
Loss at iteration 1340 : 0.011496935039758682
Loss at iteration 1350 : 0.013088680803775787
Loss at iteration 1360 : 0.011222217231988907
Loss at iteration 1370 : 0.013015315867960453
Loss at iteration 1380 : 0.011567903682589531
Loss at iteration 1390 : 0.010928826406598091
Loss at iteration 1400 : 0.006761993747204542
Loss at iteration 1410 : 0.010747568681836128
Loss at iteration 1420 : 0.00917774997651577
Loss at iteration 1430 : 0.009781882166862488
Loss at iteration 1440 : 0.015515776351094246
Loss at iteration 1450 : 0.008351029828190804
Loss at iteration 1460 : 0.019255438819527626
Loss at iteration 1470 : 0.014751988463103771
Loss at iteration 1480 : 0.01380850002169609
Loss at iteration 1490 : 0.027754202485084534
Loss at iteration 1500 : 0.011962013319134712
Loss at iteration 1510 : 0.012181172147393227
Loss at iteration 1520 : 0.008787683211266994
Loss at iteration 1530 : 0.013376157730817795
Loss at iteration 1540 : 0.029307281598448753
Loss at iteration 1550 : 0.00961089227348566
Loss at iteration 1560 : 0.009065859019756317
Loss at iteration 1570 : 0.009062344208359718
Loss at iteration 1580 : 0.007937365211546421
Loss at iteration 1590 : 0.014048629440367222
Loss at iteration 1600 : 0.011061569675803185
Loss at iteration 1610 : 0.003184238448739052
Loss at iteration 1620 : 0.016020383685827255
Loss at iteration 1630 : 0.0058207157999277115
Loss at iteration 1640 : 0.005919465329498053
Loss at iteration 1650 : 0.003398245433345437
Loss at iteration 1660 : 0.02078954502940178
Loss at iteration 1670 : 0.004322770982980728
Loss at iteration 1680 : 0.004457528702914715
Loss at iteration 1690 : 0.010849989950656891
Loss at iteration 1700 : 0.010227972641587257
Loss at iteration 1710 : 0.014608982019126415
Loss at iteration 1720 : 0.015044266358017921
Loss at iteration 1730 : 0.0062311626970767975
Loss at iteration 1740 : 0.016090605407953262
Loss at iteration 1750 : 0.009165970608592033
Loss at iteration 1760 : 0.007743002846837044
Loss at iteration 1770 : 0.011452676728367805
Loss at iteration 1780 : 0.00871116854250431
Loss at iteration 1790 : 0.008692769333720207
Loss at iteration 1800 : 0.004289431497454643
Loss at iteration 1810 : 0.013576002791523933
Loss at iteration 1820 : 0.004360440652817488
Loss at iteration 1830 : 0.006541280075907707
Loss at iteration 1840 : 0.008282635360956192
Loss at iteration 1850 : 0.008571936748921871
Loss at iteration 1860 : 0.006108123809099197
Loss at iteration 1870 : 0.004689548164606094
Loss at iteration 1880 : 0.01863214001059532
Loss at iteration 1890 : 0.013606537133455276
Loss at iteration 1900 : 0.008668649941682816
Loss at iteration 1910 : 0.016686825081706047
Loss at iteration 1920 : 0.016780788078904152
Loss at iteration 1930 : 0.001919892500154674
Loss at iteration 1940 : 0.012216225266456604
Loss at iteration 1950 : 0.019752955064177513
Loss at iteration 1960 : 0.019590221345424652
Loss at iteration 1970 : 0.009642835706472397
Loss at iteration 1980 : 0.027151837944984436
Loss at iteration 1990 : 0.008416268974542618
Loss at iteration 2000 : 0.006069106049835682
Loss at iteration 2010 : 0.015716705471277237
Loss at iteration 2020 : 0.007871709764003754
Loss at iteration 2030 : 0.004497929941862822
Loss at iteration 2040 : 0.005648762919008732
Loss at iteration 2050 : 0.010423955507576466
Loss at iteration 2060 : 0.008364930748939514
Loss at iteration 2070 : 0.0077315629459917545
Loss at iteration 2080 : 0.02063821814954281
Loss at iteration 2090 : 0.010608518496155739
Loss at iteration 2100 : 0.0066385031677782536
Loss at iteration 2110 : 0.014579540118575096
Loss at iteration 2120 : 0.006455337628722191
Loss at iteration 2130 : 0.007347904611378908
Loss at iteration 2140 : 0.007912099361419678
Loss at iteration 2150 : 0.012969257310032845
Loss at iteration 2160 : 0.009090450592339039
Loss at iteration 2170 : 0.007156070787459612
Loss at iteration 2180 : 0.006856916006654501
Loss at iteration 2190 : 0.00987007562071085
Loss at iteration 2200 : 0.00718019949272275
Loss at iteration 2210 : 0.008509691804647446
Loss at iteration 2220 : 0.00759423291310668
Loss at iteration 2230 : 0.00819181278347969
Loss at iteration 2240 : 0.01853441819548607
Loss at iteration 2250 : 0.00569910230115056
Loss at iteration 2260 : 0.00826573371887207
Loss at iteration 2270 : 0.008118006400763988
Loss at iteration 2280 : 0.012639026157557964
Loss at iteration 2290 : 0.009390133433043957
Loss at iteration 2300 : 0.014002574607729912
Loss at iteration 2310 : 0.0067562018521130085
Loss at iteration 2320 : 0.005805014632642269
Loss at iteration 2330 : 0.0052106184884905815
Loss at iteration 2340 : 0.009799951687455177
Loss at iteration 2350 : 0.005971146747469902
Loss at iteration 2360 : 0.009237449616193771
Loss at iteration 2370 : 0.010694729164242744
Loss at iteration 2380 : 0.014306997880339622
Loss at iteration 2390 : 0.006620023399591446
Loss at iteration 2400 : 0.009405294433236122
Loss at iteration 2410 : 0.005455112084746361
Loss at iteration 2420 : 0.008430670015513897
The SSIM Value is: 0.8376626928647359
The PSNR Value is: 21.597186024983724
the epoch is: 69
Loss at iteration 10 : 0.009671777486801147
Loss at iteration 20 : 0.011792228557169437
Loss at iteration 30 : 0.019824054092168808
Loss at iteration 40 : 0.008956491947174072
Loss at iteration 50 : 0.02093956619501114
Loss at iteration 60 : 0.012406464666128159
Loss at iteration 70 : 0.00804912205785513
Loss at iteration 80 : 0.006286664865911007
Loss at iteration 90 : 0.012847713194787502
Loss at iteration 100 : 0.01516326330602169
Loss at iteration 110 : 0.0044443802908062935
Loss at iteration 120 : 0.008810747414827347
Loss at iteration 130 : 0.010384096764028072
Loss at iteration 140 : 0.012203985825181007
Loss at iteration 150 : 0.023215293884277344
Loss at iteration 160 : 0.03325660899281502
Loss at iteration 170 : 0.009133713319897652
Loss at iteration 180 : 0.0034466362558305264
Loss at iteration 190 : 0.00735106598585844
Loss at iteration 200 : 0.01792488433420658
Loss at iteration 210 : 0.009875433519482613
Loss at iteration 220 : 0.009862770326435566
Loss at iteration 230 : 0.0100721325725317
Loss at iteration 240 : 0.004183863289654255
Loss at iteration 250 : 0.011093927547335625
Loss at iteration 260 : 0.003998791798949242
Loss at iteration 270 : 0.0036056952085345984
Loss at iteration 280 : 0.006466125603765249
Loss at iteration 290 : 0.0071213808842003345
Loss at iteration 300 : 0.012490971945226192
Loss at iteration 310 : 0.002210973994806409
Loss at iteration 320 : 0.005330084823071957
Loss at iteration 330 : 0.011832018382847309
Loss at iteration 340 : 0.0039025461301207542
Loss at iteration 350 : 0.006290226709097624
Loss at iteration 360 : 0.010899091139435768
Loss at iteration 370 : 0.012742696329951286
Loss at iteration 380 : 0.014109205454587936
Loss at iteration 390 : 0.008775787428021431
Loss at iteration 400 : 0.005622544791549444
Loss at iteration 410 : 0.008841566741466522
Loss at iteration 420 : 0.017155785113573074
Loss at iteration 430 : 0.014670146629214287
Loss at iteration 440 : 0.01086144708096981
Loss at iteration 450 : 0.008372288197278976
Loss at iteration 460 : 0.008199268952012062
Loss at iteration 470 : 0.010945426300168037
Loss at iteration 480 : 0.004488606471568346
Loss at iteration 490 : 0.007858716882765293
Loss at iteration 500 : 0.006816783919930458
Loss at iteration 510 : 0.009653344750404358
Loss at iteration 520 : 0.005098589230328798
Loss at iteration 530 : 0.011284466832876205
Loss at iteration 540 : 0.011338441632688046
Loss at iteration 550 : 0.013471708633005619
Loss at iteration 560 : 0.00675018597394228
Loss at iteration 570 : 0.009928049519658089
Loss at iteration 580 : 0.002651042537763715
Loss at iteration 590 : 0.009197224862873554
Loss at iteration 600 : 0.007130998186767101
Loss at iteration 610 : 0.00444298330694437
Loss at iteration 620 : 0.013534688390791416
Loss at iteration 630 : 0.008802782744169235
Loss at iteration 640 : 0.01191210001707077
Loss at iteration 650 : 0.006809096783399582
Loss at iteration 660 : 0.006462967023253441
Loss at iteration 670 : 0.005995363928377628
Loss at iteration 680 : 0.009544220753014088
Loss at iteration 690 : 0.015627916902303696
Loss at iteration 700 : 0.006381206214427948
Loss at iteration 710 : 0.009203881956636906
Loss at iteration 720 : 0.0026623918674886227
Loss at iteration 730 : 0.013347138650715351
Loss at iteration 740 : 0.00632645096629858
Loss at iteration 750 : 0.01396207045763731
Loss at iteration 760 : 0.016601666808128357
Loss at iteration 770 : 0.005662259645760059
Loss at iteration 780 : 0.010874221101403236
Loss at iteration 790 : 0.010888203978538513
Loss at iteration 800 : 0.013684016652405262
Loss at iteration 810 : 0.012745736166834831
Loss at iteration 820 : 0.008054515346884727
Loss at iteration 830 : 0.013904967345297337
Loss at iteration 840 : 0.010746173560619354
Loss at iteration 850 : 0.013692134991288185
Loss at iteration 860 : 0.013412237167358398
Loss at iteration 870 : 0.009968667291104794
Loss at iteration 880 : 0.0038433533627539873
Loss at iteration 890 : 0.005374057684093714
Loss at iteration 900 : 0.004688482265919447
Loss at iteration 910 : 0.00405337568372488
Loss at iteration 920 : 0.009720716625452042
Loss at iteration 930 : 0.010798798874020576
Loss at iteration 940 : 0.008135076612234116
Loss at iteration 950 : 0.033409394323825836
Loss at iteration 960 : 0.005708095617592335
Loss at iteration 970 : 0.007125589065253735
Loss at iteration 980 : 0.004188357852399349
Loss at iteration 990 : 0.01186141837388277
Loss at iteration 1000 : 0.009304391220211983
Loss at iteration 1010 : 0.018257787451148033
Loss at iteration 1020 : 0.010266105644404888
Loss at iteration 1030 : 0.016163602471351624
Loss at iteration 1040 : 0.008316563442349434
Loss at iteration 1050 : 0.007399889640510082
Loss at iteration 1060 : 0.012063588947057724
Loss at iteration 1070 : 0.017067695036530495
Loss at iteration 1080 : 0.004909053444862366
Loss at iteration 1090 : 0.012049980461597443
Loss at iteration 1100 : 0.014656446874141693
Loss at iteration 1110 : 0.007427792530506849
Loss at iteration 1120 : 0.011049800552427769
Loss at iteration 1130 : 0.0169060081243515
Loss at iteration 1140 : 0.013060900382697582
Loss at iteration 1150 : 0.0038886284455657005
Loss at iteration 1160 : 0.009053799323737621
Loss at iteration 1170 : 0.009491661563515663
Loss at iteration 1180 : 0.004514167085289955
Loss at iteration 1190 : 0.003393657738342881
Loss at iteration 1200 : 0.01016008760780096
Loss at iteration 1210 : 0.0031763757579028606
Loss at iteration 1220 : 0.01252952590584755
Loss at iteration 1230 : 0.01000616978853941
Loss at iteration 1240 : 0.005175831262022257
Loss at iteration 1250 : 0.012843094766139984
Loss at iteration 1260 : 0.00665668398141861
Loss at iteration 1270 : 0.006777897011488676
Loss at iteration 1280 : 0.004047751892358065
Loss at iteration 1290 : 0.009912984445691109
Loss at iteration 1300 : 0.008148696273565292
Loss at iteration 1310 : 0.014530085027217865
Loss at iteration 1320 : 0.009820164181292057
Loss at iteration 1330 : 0.009888088330626488
Loss at iteration 1340 : 0.011424603872001171
Loss at iteration 1350 : 0.00799188856035471
Loss at iteration 1360 : 0.006553557701408863
Loss at iteration 1370 : 0.012176988646388054
Loss at iteration 1380 : 0.006165299564599991
Loss at iteration 1390 : 0.004244950599968433
Loss at iteration 1400 : 0.015174366533756256
Loss at iteration 1410 : 0.005322086159139872
Loss at iteration 1420 : 0.011323208920657635
Loss at iteration 1430 : 0.008851956576108932
Loss at iteration 1440 : 0.014988206326961517
Loss at iteration 1450 : 0.006885102950036526
Loss at iteration 1460 : 0.00955921970307827
Loss at iteration 1470 : 0.014119848608970642
Loss at iteration 1480 : 0.008823802694678307
Loss at iteration 1490 : 0.015327470377087593
Loss at iteration 1500 : 0.00910227745771408
Loss at iteration 1510 : 0.006157903000712395
Loss at iteration 1520 : 0.017958737909793854
Loss at iteration 1530 : 0.00936154555529356
Loss at iteration 1540 : 0.01604262739419937
Loss at iteration 1550 : 0.007867340929806232
Loss at iteration 1560 : 0.00951511412858963
Loss at iteration 1570 : 0.016145426779985428
Loss at iteration 1580 : 0.00483280885964632
Loss at iteration 1590 : 0.007807824295014143
Loss at iteration 1600 : 0.014950104057788849
Loss at iteration 1610 : 0.012423321604728699
Loss at iteration 1620 : 0.006580587942153215
Loss at iteration 1630 : 0.013338042423129082
Loss at iteration 1640 : 0.007472495082765818
Loss at iteration 1650 : 0.009129183366894722
Loss at iteration 1660 : 0.008604857139289379
Loss at iteration 1670 : 0.01073212269693613
Loss at iteration 1680 : 0.009739245288074017
Loss at iteration 1690 : 0.007004811428487301
Loss at iteration 1700 : 0.016466768458485603
Loss at iteration 1710 : 0.009877479635179043
Loss at iteration 1720 : 0.007160449866205454
Loss at iteration 1730 : 0.007610690779983997
Loss at iteration 1740 : 0.008470906876027584
Loss at iteration 1750 : 0.010506910271942616
Loss at iteration 1760 : 0.007479903753846884
Loss at iteration 1770 : 0.009260788559913635
Loss at iteration 1780 : 0.006305121351033449
Loss at iteration 1790 : 0.0037376107648015022
Loss at iteration 1800 : 0.013184824958443642
Loss at iteration 1810 : 0.0031561297364532948
Loss at iteration 1820 : 0.009942892007529736
Loss at iteration 1830 : 0.01672932878136635
Loss at iteration 1840 : 0.007500574924051762
Loss at iteration 1850 : 0.007447418756783009
Loss at iteration 1860 : 0.01803918369114399
Loss at iteration 1870 : 0.006061124615371227
Loss at iteration 1880 : 0.01707124337553978
Loss at iteration 1890 : 0.009611271321773529
Loss at iteration 1900 : 0.012306828051805496
Loss at iteration 1910 : 0.013119043782353401
Loss at iteration 1920 : 0.01106300950050354
Loss at iteration 1930 : 0.009854920208454132
Loss at iteration 1940 : 0.014715097844600677
Loss at iteration 1950 : 0.007994139567017555
Loss at iteration 1960 : 0.015982504934072495
Loss at iteration 1970 : 0.003862647572532296
Loss at iteration 1980 : 0.030440447852015495
Loss at iteration 1990 : 0.00645630294457078
Loss at iteration 2000 : 0.004514153115451336
Loss at iteration 2010 : 0.006022755987942219
Loss at iteration 2020 : 0.00545808020979166
Loss at iteration 2030 : 0.011565707623958588
Loss at iteration 2040 : 0.007509805727750063
Loss at iteration 2050 : 0.003081406932324171
Loss at iteration 2060 : 0.0038240221329033375
Loss at iteration 2070 : 0.01055833138525486
Loss at iteration 2080 : 0.0031090700067579746
Loss at iteration 2090 : 0.014016715809702873
Loss at iteration 2100 : 0.00938989594578743
Loss at iteration 2110 : 0.006901225075125694
Loss at iteration 2120 : 0.0038136858493089676
Loss at iteration 2130 : 0.00889284536242485
Loss at iteration 2140 : 0.008860043250024319
Loss at iteration 2150 : 0.002615218749269843
Loss at iteration 2160 : 0.004363843239843845
Loss at iteration 2170 : 0.00900633167475462
Loss at iteration 2180 : 0.007044479716569185
Loss at iteration 2190 : 0.00789882056415081
Loss at iteration 2200 : 0.011864494532346725
Loss at iteration 2210 : 0.006550509948283434
Loss at iteration 2220 : 0.010217083618044853
Loss at iteration 2230 : 0.0029012917075306177
Loss at iteration 2240 : 0.005292594898492098
Loss at iteration 2250 : 0.006920388899743557
Loss at iteration 2260 : 0.006775585934519768
Loss at iteration 2270 : 0.00896449014544487
Loss at iteration 2280 : 0.010895710438489914
Loss at iteration 2290 : 0.008072863332927227
Loss at iteration 2300 : 0.017539342865347862
Loss at iteration 2310 : 0.007619935553520918
Loss at iteration 2320 : 0.005163807421922684
Loss at iteration 2330 : 0.018400194123387337
Loss at iteration 2340 : 0.008415044285356998
Loss at iteration 2350 : 0.00488104484975338
Loss at iteration 2360 : 0.007402063347399235
Loss at iteration 2370 : 0.018447695299983025
Loss at iteration 2380 : 0.007126525044441223
Loss at iteration 2390 : 0.01470106840133667
Loss at iteration 2400 : 0.006601766217499971
Loss at iteration 2410 : 0.003140755696222186
Loss at iteration 2420 : 0.007139137480407953
The SSIM Value is: 0.8457626581192017
The PSNR Value is: 22.22986386617025
the epoch is: 70
Loss at iteration 10 : 0.005908368155360222
Loss at iteration 20 : 0.008722667582333088
Loss at iteration 30 : 0.006450994871556759
Loss at iteration 40 : 0.006743667181581259
Loss at iteration 50 : 0.0046676043421030045
Loss at iteration 60 : 0.00646951561793685
Loss at iteration 70 : 0.020484663546085358
Loss at iteration 80 : 0.010625738650560379
Loss at iteration 90 : 0.012690484523773193
Loss at iteration 100 : 0.011763245798647404
Loss at iteration 110 : 0.005383947864174843
Loss at iteration 120 : 0.008187906816601753
Loss at iteration 130 : 0.009553066454827785
Loss at iteration 140 : 0.005321990232914686
Loss at iteration 150 : 0.010313296690583229
Loss at iteration 160 : 0.021617349237203598
Loss at iteration 170 : 0.009411505423486233
Loss at iteration 180 : 0.0030806732829660177
Loss at iteration 190 : 0.005602293182164431
Loss at iteration 200 : 0.009618493728339672
Loss at iteration 210 : 0.018440410494804382
Loss at iteration 220 : 0.011342432349920273
Loss at iteration 230 : 0.016185302287340164
Loss at iteration 240 : 0.006208094768226147
Loss at iteration 250 : 0.007132912985980511
Loss at iteration 260 : 0.013566738925874233
Loss at iteration 270 : 0.01900290697813034
Loss at iteration 280 : 0.007404005154967308
Loss at iteration 290 : 0.011597966775298119
Loss at iteration 300 : 0.01238978374749422
Loss at iteration 310 : 0.00802561454474926
Loss at iteration 320 : 0.006748638581484556
Loss at iteration 330 : 0.004158555530011654
Loss at iteration 340 : 0.009487600065767765
Loss at iteration 350 : 0.01011497713625431
Loss at iteration 360 : 0.0032597477547824383
Loss at iteration 370 : 0.008895107544958591
Loss at iteration 380 : 0.006811263971030712
Loss at iteration 390 : 0.006339295767247677
Loss at iteration 400 : 0.009211117401719093
Loss at iteration 410 : 0.015962470322847366
Loss at iteration 420 : 0.011285468935966492
Loss at iteration 430 : 0.005889264866709709
Loss at iteration 440 : 0.009106873534619808
Loss at iteration 450 : 0.007709241472184658
Loss at iteration 460 : 0.014056779444217682
Loss at iteration 470 : 0.005819077603518963
Loss at iteration 480 : 0.00863740500062704
Loss at iteration 490 : 0.004291421268135309
Loss at iteration 500 : 0.012942665256559849
Loss at iteration 510 : 0.011987428180873394
Loss at iteration 520 : 0.014925096184015274
Loss at iteration 530 : 0.006113977171480656
Loss at iteration 540 : 0.007590439636260271
Loss at iteration 550 : 0.006885886657983065
Loss at iteration 560 : 0.008221528492867947
Loss at iteration 570 : 0.011015253141522408
Loss at iteration 580 : 0.011976130306720734
Loss at iteration 590 : 0.0037596533074975014
Loss at iteration 600 : 0.01334909163415432
Loss at iteration 610 : 0.005211810581386089
Loss at iteration 620 : 0.010810866951942444
Loss at iteration 630 : 0.006766394712030888
Loss at iteration 640 : 0.007583719212561846
Loss at iteration 650 : 0.012724282220005989
Loss at iteration 660 : 0.010488657280802727
Loss at iteration 670 : 0.017659440636634827
Loss at iteration 680 : 0.005174357444047928
Loss at iteration 690 : 0.011653165332973003
Loss at iteration 700 : 0.00931627582758665
Loss at iteration 710 : 0.017994754016399384
Loss at iteration 720 : 0.014285152778029442
Loss at iteration 730 : 0.008921797387301922
Loss at iteration 740 : 0.011303447186946869
Loss at iteration 750 : 0.02452712692320347
Loss at iteration 760 : 0.005904393270611763
Loss at iteration 770 : 0.00781291164457798
Loss at iteration 780 : 0.007676547393202782
Loss at iteration 790 : 0.007191803772002459
Loss at iteration 800 : 0.007681156508624554
Loss at iteration 810 : 0.02178933098912239
Loss at iteration 820 : 0.00980387069284916
Loss at iteration 830 : 0.010581009089946747
Loss at iteration 840 : 0.01346970908343792
Loss at iteration 850 : 0.008572997525334358
Loss at iteration 860 : 0.011916463263332844
Loss at iteration 870 : 0.00441389624029398
Loss at iteration 880 : 0.011418580077588558
Loss at iteration 890 : 0.014841709285974503
Loss at iteration 900 : 0.0056955087929964066
Loss at iteration 910 : 0.0021515204571187496
Loss at iteration 920 : 0.004548652563244104
Loss at iteration 930 : 0.0072433194145560265
Loss at iteration 940 : 0.010080406442284584
Loss at iteration 950 : 0.005956793203949928
Loss at iteration 960 : 0.020537113770842552
Loss at iteration 970 : 0.01676299422979355
Loss at iteration 980 : 0.0052825105376541615
Loss at iteration 990 : 0.004488861188292503
Loss at iteration 1000 : 0.013820795342326164
Loss at iteration 1010 : 0.0068112812004983425
Loss at iteration 1020 : 0.004364055581390858
Loss at iteration 1030 : 0.012088313698768616
Loss at iteration 1040 : 0.013929452747106552
Loss at iteration 1050 : 0.0034044033382087946
Loss at iteration 1060 : 0.008363748900592327
Loss at iteration 1070 : 0.004413614980876446
Loss at iteration 1080 : 0.008633648045361042
Loss at iteration 1090 : 0.012177428230643272
Loss at iteration 1100 : 0.006514102686196566
Loss at iteration 1110 : 0.0070192813873291016
Loss at iteration 1120 : 0.009208261966705322
Loss at iteration 1130 : 0.008550598286092281
Loss at iteration 1140 : 0.003975928295403719
Loss at iteration 1150 : 0.017931897193193436
Loss at iteration 1160 : 0.006593509577214718
Loss at iteration 1170 : 0.009181037545204163
Loss at iteration 1180 : 0.014734459109604359
Loss at iteration 1190 : 0.011840027756989002
Loss at iteration 1200 : 0.006759366951882839
Loss at iteration 1210 : 0.011845364235341549
Loss at iteration 1220 : 0.00444242637604475
Loss at iteration 1230 : 0.009356770664453506
Loss at iteration 1240 : 0.006186462007462978
Loss at iteration 1250 : 0.0038519699592143297
Loss at iteration 1260 : 0.008674442768096924
Loss at iteration 1270 : 0.008262714371085167
Loss at iteration 1280 : 0.008126351982355118
Loss at iteration 1290 : 0.005722745321691036
Loss at iteration 1300 : 0.010586261749267578
Loss at iteration 1310 : 0.0076607936061918736
Loss at iteration 1320 : 0.006882025860249996
Loss at iteration 1330 : 0.004587729461491108
Loss at iteration 1340 : 0.008048434741795063
Loss at iteration 1350 : 0.010741177946329117
Loss at iteration 1360 : 0.006819368340075016
Loss at iteration 1370 : 0.011212500743567944
Loss at iteration 1380 : 0.023659024387598038
Loss at iteration 1390 : 0.009894207119941711
Loss at iteration 1400 : 0.006055851466953754
Loss at iteration 1410 : 0.005112276412546635
Loss at iteration 1420 : 0.003620704635977745
Loss at iteration 1430 : 0.0020998683758080006
Loss at iteration 1440 : 0.00481311185285449
Loss at iteration 1450 : 0.00973460078239441
Loss at iteration 1460 : 0.010540446266531944
Loss at iteration 1470 : 0.01017917599529028
Loss at iteration 1480 : 0.008729307912290096
Loss at iteration 1490 : 0.011245368979871273
Loss at iteration 1500 : 0.013913515023887157
Loss at iteration 1510 : 0.016245462000370026
Loss at iteration 1520 : 0.012311991304159164
Loss at iteration 1530 : 0.00984039343893528
Loss at iteration 1540 : 0.012222342193126678
Loss at iteration 1550 : 0.007465776056051254
Loss at iteration 1560 : 0.016895655542612076
Loss at iteration 1570 : 0.024756668135523796
Loss at iteration 1580 : 0.00411164341494441
Loss at iteration 1590 : 0.005309277679771185
Loss at iteration 1600 : 0.012922384776175022
Loss at iteration 1610 : 0.011542444117367268
Loss at iteration 1620 : 0.015040780417621136
Loss at iteration 1630 : 0.009396410547196865
Loss at iteration 1640 : 0.01083814911544323
Loss at iteration 1650 : 0.008284833282232285
Loss at iteration 1660 : 0.007360817398875952
Loss at iteration 1670 : 0.005612217355519533
Loss at iteration 1680 : 0.010672896169126034
Loss at iteration 1690 : 0.01236027479171753
Loss at iteration 1700 : 0.009796015918254852
Loss at iteration 1710 : 0.00899717677384615
Loss at iteration 1720 : 0.0095225740224123
Loss at iteration 1730 : 0.01577836647629738
Loss at iteration 1740 : 0.014913724735379219
Loss at iteration 1750 : 0.007075360976159573
Loss at iteration 1760 : 0.0056474097073078156
Loss at iteration 1770 : 0.011418145149946213
Loss at iteration 1780 : 0.005788416601717472
Loss at iteration 1790 : 0.005782834719866514
Loss at iteration 1800 : 0.008176787756383419
Loss at iteration 1810 : 0.0064233713783323765
Loss at iteration 1820 : 0.032332561910152435
Loss at iteration 1830 : 0.01021215133368969
Loss at iteration 1840 : 0.006753400433808565
Loss at iteration 1850 : 0.008288039825856686
Loss at iteration 1860 : 0.011234533041715622
Loss at iteration 1870 : 0.005553979426622391
Loss at iteration 1880 : 0.021542442962527275
Loss at iteration 1890 : 0.006391040049493313
Loss at iteration 1900 : 0.007555041462182999
Loss at iteration 1910 : 0.012161368504166603
Loss at iteration 1920 : 0.0026267478242516518
Loss at iteration 1930 : 0.010739224031567574
Loss at iteration 1940 : 0.01363097969442606
Loss at iteration 1950 : 0.0072598811239004135
Loss at iteration 1960 : 0.01853206939995289
Loss at iteration 1970 : 0.010544441640377045
Loss at iteration 1980 : 0.009713281877338886
Loss at iteration 1990 : 0.005177993793040514
Loss at iteration 2000 : 0.008059248328208923
Loss at iteration 2010 : 0.007743847090750933
Loss at iteration 2020 : 0.007651262916624546
Loss at iteration 2030 : 0.008993878960609436
Loss at iteration 2040 : 0.010480360127985477
Loss at iteration 2050 : 0.011414877139031887
Loss at iteration 2060 : 0.007346584461629391
Loss at iteration 2070 : 0.0038400308694690466
Loss at iteration 2080 : 0.0068189287558197975
Loss at iteration 2090 : 0.010779039934277534
Loss at iteration 2100 : 0.007418463006615639
Loss at iteration 2110 : 0.010821802541613579
Loss at iteration 2120 : 0.005561689380556345
Loss at iteration 2130 : 0.00960440281778574
Loss at iteration 2140 : 0.006893918849527836
Loss at iteration 2150 : 0.008376394398510456
Loss at iteration 2160 : 0.0078097498044371605
Loss at iteration 2170 : 0.01428462564945221
Loss at iteration 2180 : 0.003064674325287342
Loss at iteration 2190 : 0.0056441351771354675
Loss at iteration 2200 : 0.005184691399335861
Loss at iteration 2210 : 0.012145550921559334
Loss at iteration 2220 : 0.010477012023329735
Loss at iteration 2230 : 0.0074890246614813805
Loss at iteration 2240 : 0.011423299089074135
Loss at iteration 2250 : 0.0086912140250206
Loss at iteration 2260 : 0.02359708771109581
Loss at iteration 2270 : 0.015058262273669243
Loss at iteration 2280 : 0.008024876937270164
Loss at iteration 2290 : 0.013481959700584412
Loss at iteration 2300 : 0.00613801646977663
Loss at iteration 2310 : 0.007822471670806408
Loss at iteration 2320 : 0.005586086772382259
Loss at iteration 2330 : 0.010281525552272797
Loss at iteration 2340 : 0.00959197897464037
Loss at iteration 2350 : 0.007217623759061098
Loss at iteration 2360 : 0.007635956164449453
Loss at iteration 2370 : 0.005710172932595015
Loss at iteration 2380 : 0.006561078131198883
Loss at iteration 2390 : 0.0024207686074078083
Loss at iteration 2400 : 0.015533177182078362
Loss at iteration 2410 : 0.011356204748153687
Loss at iteration 2420 : 0.008870701305568218
The SSIM Value is: 0.8473048130671184
The PSNR Value is: 22.346334139506023
the epoch is: 71
Loss at iteration 10 : 0.003637728514149785
Loss at iteration 20 : 0.004550525452941656
Loss at iteration 30 : 0.006769116036593914
Loss at iteration 40 : 0.004436873830854893
Loss at iteration 50 : 0.007892138324677944
Loss at iteration 60 : 0.00680947070941329
Loss at iteration 70 : 0.011086799204349518
Loss at iteration 80 : 0.018279127776622772
Loss at iteration 90 : 0.011032688431441784
Loss at iteration 100 : 0.010448314249515533
Loss at iteration 110 : 0.007051684428006411
Loss at iteration 120 : 0.013948455452919006
Loss at iteration 130 : 0.009444404393434525
Loss at iteration 140 : 0.002359401900321245
Loss at iteration 150 : 0.014384881593286991
Loss at iteration 160 : 0.007527075707912445
Loss at iteration 170 : 0.008554366417229176
Loss at iteration 180 : 0.0037508681416511536
Loss at iteration 190 : 0.008420653641223907
Loss at iteration 200 : 0.005201306659728289
Loss at iteration 210 : 0.005147508345544338
Loss at iteration 220 : 0.018586182966828346
Loss at iteration 230 : 0.006844916846603155
Loss at iteration 240 : 0.011407582089304924
Loss at iteration 250 : 0.009170448407530785
Loss at iteration 260 : 0.01665840484201908
Loss at iteration 270 : 0.01266654022037983
Loss at iteration 280 : 0.008964192122220993
Loss at iteration 290 : 0.005779043305665255
Loss at iteration 300 : 0.004120109602808952
Loss at iteration 310 : 0.005623355507850647
Loss at iteration 320 : 0.011482390575110912
Loss at iteration 330 : 0.01742563024163246
Loss at iteration 340 : 0.010814324021339417
Loss at iteration 350 : 0.006308202166110277
Loss at iteration 360 : 0.011480763554573059
Loss at iteration 370 : 0.014879947528243065
Loss at iteration 380 : 0.0069685871712863445
Loss at iteration 390 : 0.013038980774581432
Loss at iteration 400 : 0.014757311902940273
Loss at iteration 410 : 0.012699789367616177
Loss at iteration 420 : 0.005842344835400581
Loss at iteration 430 : 0.005483152810484171
Loss at iteration 440 : 0.005380392074584961
Loss at iteration 450 : 0.0035264398902654648
Loss at iteration 460 : 0.007280302699655294
Loss at iteration 470 : 0.00693366676568985
Loss at iteration 480 : 0.00462545920163393
Loss at iteration 490 : 0.008106549270451069
Loss at iteration 500 : 0.003415429499000311
Loss at iteration 510 : 0.01095626875758171
Loss at iteration 520 : 0.008288254961371422
Loss at iteration 530 : 0.009804838337004185
Loss at iteration 540 : 0.00744582898914814
Loss at iteration 550 : 0.009338612668216228
Loss at iteration 560 : 0.013369875960052013
Loss at iteration 570 : 0.004605145193636417
Loss at iteration 580 : 0.006535043474286795
Loss at iteration 590 : 0.015124506317079067
Loss at iteration 600 : 0.014631967060267925
Loss at iteration 610 : 0.010896904394030571
Loss at iteration 620 : 0.006896916311234236
Loss at iteration 630 : 0.0019999495707452297
Loss at iteration 640 : 0.008400896564126015
Loss at iteration 650 : 0.014045629650354385
Loss at iteration 660 : 0.015792736783623695
Loss at iteration 670 : 0.0029616057872772217
Loss at iteration 680 : 0.007148304954171181
Loss at iteration 690 : 0.009418177418410778
Loss at iteration 700 : 0.01550575066357851
Loss at iteration 710 : 0.014323142357170582
Loss at iteration 720 : 0.027305565774440765
Loss at iteration 730 : 0.016849756240844727
Loss at iteration 740 : 0.00964322779327631
Loss at iteration 750 : 0.007995149120688438
Loss at iteration 760 : 0.0036153511609882116
Loss at iteration 770 : 0.00862689409404993
Loss at iteration 780 : 0.003609247738495469
Loss at iteration 790 : 0.010928798466920853
Loss at iteration 800 : 0.006922625005245209
Loss at iteration 810 : 0.0034496586304157972
Loss at iteration 820 : 0.004063651897013187
Loss at iteration 830 : 0.011211621575057507
Loss at iteration 840 : 0.012243344448506832
Loss at iteration 850 : 0.017127111554145813
Loss at iteration 860 : 0.010256106965243816
Loss at iteration 870 : 0.011322217993438244
Loss at iteration 880 : 0.008236383087933064
Loss at iteration 890 : 0.006624820176512003
Loss at iteration 900 : 0.010648112744092941
Loss at iteration 910 : 0.003927028737962246
Loss at iteration 920 : 0.016928017139434814
Loss at iteration 930 : 0.0074507626704871655
Loss at iteration 940 : 0.013014941476285458
Loss at iteration 950 : 0.013057590462267399
Loss at iteration 960 : 0.006239819806069136
Loss at iteration 970 : 0.008104076609015465
Loss at iteration 980 : 0.006244382355362177
Loss at iteration 990 : 0.01608506590127945
Loss at iteration 1000 : 0.004713897127658129
Loss at iteration 1010 : 0.013926060870289803
Loss at iteration 1020 : 0.0048945071175694466
Loss at iteration 1030 : 0.008588233962655067
Loss at iteration 1040 : 0.003497995436191559
Loss at iteration 1050 : 0.011986082419753075
Loss at iteration 1060 : 0.013013290241360664
Loss at iteration 1070 : 0.0054199425503611565
Loss at iteration 1080 : 0.005006501451134682
Loss at iteration 1090 : 0.009889713488519192
Loss at iteration 1100 : 0.011084175668656826
Loss at iteration 1110 : 0.018937112763524055
Loss at iteration 1120 : 0.012978521175682545
Loss at iteration 1130 : 0.006858868058770895
Loss at iteration 1140 : 0.024260608479380608
Loss at iteration 1150 : 0.006254986859858036
Loss at iteration 1160 : 0.009427208453416824
Loss at iteration 1170 : 0.006175808608531952
Loss at iteration 1180 : 0.004782767966389656
Loss at iteration 1190 : 0.010156569071114063
Loss at iteration 1200 : 0.004570178687572479
Loss at iteration 1210 : 0.006719524506479502
Loss at iteration 1220 : 0.009510191157460213
Loss at iteration 1230 : 0.009745125658810139
Loss at iteration 1240 : 0.008509170264005661
Loss at iteration 1250 : 0.0064347973093390465
Loss at iteration 1260 : 0.020123014226555824
Loss at iteration 1270 : 0.009853792376816273
Loss at iteration 1280 : 0.007183154113590717
Loss at iteration 1290 : 0.008870594203472137
Loss at iteration 1300 : 0.01893368549644947
Loss at iteration 1310 : 0.004392804577946663
Loss at iteration 1320 : 0.006226513534784317
Loss at iteration 1330 : 0.010245912708342075
Loss at iteration 1340 : 0.014422726817429066
Loss at iteration 1350 : 0.014495829120278358
Loss at iteration 1360 : 0.010826602578163147
Loss at iteration 1370 : 0.01087949424982071
Loss at iteration 1380 : 0.006829341873526573
Loss at iteration 1390 : 0.007861795835196972
Loss at iteration 1400 : 0.00850084237754345
Loss at iteration 1410 : 0.005676017142832279
Loss at iteration 1420 : 0.00435636006295681
Loss at iteration 1430 : 0.0035684690810739994
Loss at iteration 1440 : 0.006784031167626381
Loss at iteration 1450 : 0.00737994909286499
Loss at iteration 1460 : 0.008006885647773743
Loss at iteration 1470 : 0.013693180866539478
Loss at iteration 1480 : 0.010125279426574707
Loss at iteration 1490 : 0.009975587949156761
Loss at iteration 1500 : 0.0057815127074718475
Loss at iteration 1510 : 0.010805611498653889
Loss at iteration 1520 : 0.011767977848649025
Loss at iteration 1530 : 0.009655719622969627
Loss at iteration 1540 : 0.018423836678266525
Loss at iteration 1550 : 0.007044696249067783
Loss at iteration 1560 : 0.008694150485098362
Loss at iteration 1570 : 0.014003463089466095
Loss at iteration 1580 : 0.0071098641492426395
Loss at iteration 1590 : 0.018066393211483955
Loss at iteration 1600 : 0.007125129457563162
Loss at iteration 1610 : 0.007182527799159288
Loss at iteration 1620 : 0.0031420455779880285
Loss at iteration 1630 : 0.013854097574949265
Loss at iteration 1640 : 0.013563745655119419
Loss at iteration 1650 : 0.013720383867621422
Loss at iteration 1660 : 0.008961765095591545
Loss at iteration 1670 : 0.008516587316989899
Loss at iteration 1680 : 0.007005755789577961
Loss at iteration 1690 : 0.005131821148097515
Loss at iteration 1700 : 0.005956356879323721
Loss at iteration 1710 : 0.003476060926914215
Loss at iteration 1720 : 0.00532565638422966
Loss at iteration 1730 : 0.00483879167586565
Loss at iteration 1740 : 0.007625882513821125
Loss at iteration 1750 : 0.01425494160503149
Loss at iteration 1760 : 0.005665878299623728
Loss at iteration 1770 : 0.008962593041360378
Loss at iteration 1780 : 0.005937950685620308
Loss at iteration 1790 : 0.012933922000229359
Loss at iteration 1800 : 0.02550581283867359
Loss at iteration 1810 : 0.013023720122873783
Loss at iteration 1820 : 0.008158275857567787
Loss at iteration 1830 : 0.014695841819047928
Loss at iteration 1840 : 0.028914060443639755
Loss at iteration 1850 : 0.012759252451360226
Loss at iteration 1860 : 0.0185612253844738
Loss at iteration 1870 : 0.021266750991344452
Loss at iteration 1880 : 0.027040205895900726
Loss at iteration 1890 : 0.015063079074025154
Loss at iteration 1900 : 0.006685907021164894
Loss at iteration 1910 : 0.010130058042705059
Loss at iteration 1920 : 0.009232386946678162
Loss at iteration 1930 : 0.006456923671066761
Loss at iteration 1940 : 0.00840241089463234
Loss at iteration 1950 : 0.0124778738245368
Loss at iteration 1960 : 0.006348378956317902
Loss at iteration 1970 : 0.0036703103687614202
Loss at iteration 1980 : 0.011116228997707367
Loss at iteration 1990 : 0.014216123148798943
Loss at iteration 2000 : 0.013293474912643433
Loss at iteration 2010 : 0.006374500226229429
Loss at iteration 2020 : 0.008588329888880253
Loss at iteration 2030 : 0.006277917418628931
Loss at iteration 2040 : 0.005312603432685137
Loss at iteration 2050 : 0.009064496494829655
Loss at iteration 2060 : 0.010043824091553688
Loss at iteration 2070 : 0.01258151140064001
Loss at iteration 2080 : 0.006873130798339844
Loss at iteration 2090 : 0.00652634771540761
Loss at iteration 2100 : 0.01053953543305397
Loss at iteration 2110 : 0.007819133810698986
Loss at iteration 2120 : 0.006045120302587748
Loss at iteration 2130 : 0.010717355646193027
Loss at iteration 2140 : 0.009752144105732441
Loss at iteration 2150 : 0.003690000157803297
Loss at iteration 2160 : 0.007210700772702694
Loss at iteration 2170 : 0.01310921274125576
Loss at iteration 2180 : 0.004852261859923601
Loss at iteration 2190 : 0.005174126010388136
Loss at iteration 2200 : 0.009169588796794415
Loss at iteration 2210 : 0.009596777148544788
Loss at iteration 2220 : 0.015561962500214577
Loss at iteration 2230 : 0.010225318372249603
Loss at iteration 2240 : 0.0379507914185524
Loss at iteration 2250 : 0.007875140756368637
Loss at iteration 2260 : 0.006434882991015911
Loss at iteration 2270 : 0.00702707190066576
Loss at iteration 2280 : 0.01033792458474636
Loss at iteration 2290 : 0.00918161403387785
Loss at iteration 2300 : 0.005367262288928032
Loss at iteration 2310 : 0.009304861538112164
Loss at iteration 2320 : 0.011684847995638847
Loss at iteration 2330 : 0.014805415645241737
Loss at iteration 2340 : 0.013215052895247936
Loss at iteration 2350 : 0.008839709684252739
Loss at iteration 2360 : 0.010081520304083824
Loss at iteration 2370 : 0.017422324046492577
Loss at iteration 2380 : 0.014809945598244667
Loss at iteration 2390 : 0.004905124194920063
Loss at iteration 2400 : 0.007141461130231619
Loss at iteration 2410 : 0.005005075596272945
Loss at iteration 2420 : 0.013472987338900566
The SSIM Value is: 0.8461621840794881
The PSNR Value is: 22.07124423980713
the epoch is: 72
Loss at iteration 10 : 0.005542375613003969
Loss at iteration 20 : 0.011628893204033375
Loss at iteration 30 : 0.005508813541382551
Loss at iteration 40 : 0.010653749108314514
Loss at iteration 50 : 0.01564069092273712
Loss at iteration 60 : 0.006953330710530281
Loss at iteration 70 : 0.004736708477139473
Loss at iteration 80 : 0.009911351837217808
Loss at iteration 90 : 0.007163798902183771
Loss at iteration 100 : 0.007188251242041588
Loss at iteration 110 : 0.012749255634844303
Loss at iteration 120 : 0.004808439407497644
Loss at iteration 130 : 0.011103923432528973
Loss at iteration 140 : 0.005505494773387909
Loss at iteration 150 : 0.014356300234794617
Loss at iteration 160 : 0.008209118619561195
Loss at iteration 170 : 0.00715221744030714
Loss at iteration 180 : 0.010956880636513233
Loss at iteration 190 : 0.008208254352211952
Loss at iteration 200 : 0.006324018817394972
Loss at iteration 210 : 0.004805820994079113
Loss at iteration 220 : 0.010684354230761528
Loss at iteration 230 : 0.009404733777046204
Loss at iteration 240 : 0.011553863063454628
Loss at iteration 250 : 0.008056222461163998
Loss at iteration 260 : 0.01100852806121111
Loss at iteration 270 : 0.010155853815376759
Loss at iteration 280 : 0.010184409096837044
Loss at iteration 290 : 0.015752065926790237
Loss at iteration 300 : 0.003989009186625481
Loss at iteration 310 : 0.0069289375096559525
Loss at iteration 320 : 0.014804912731051445
Loss at iteration 330 : 0.010756614618003368
Loss at iteration 340 : 0.007860495708882809
Loss at iteration 350 : 0.014216679148375988
Loss at iteration 360 : 0.0065810056403279305
Loss at iteration 370 : 0.004777025431394577
Loss at iteration 380 : 0.01014687865972519
Loss at iteration 390 : 0.003340465947985649
Loss at iteration 400 : 0.0041237156838178635
Loss at iteration 410 : 0.016225818544626236
Loss at iteration 420 : 0.008067772723734379
Loss at iteration 430 : 0.01041690818965435
Loss at iteration 440 : 0.005033833906054497
Loss at iteration 450 : 0.004951063077896833
Loss at iteration 460 : 0.005243304185569286
Loss at iteration 470 : 0.016440242528915405
Loss at iteration 480 : 0.008160068653523922
Loss at iteration 490 : 0.008758402429521084
Loss at iteration 500 : 0.0035340224858373404
Loss at iteration 510 : 0.01222409401088953
Loss at iteration 520 : 0.009731469675898552
Loss at iteration 530 : 0.01098378375172615
Loss at iteration 540 : 0.007182986941188574
Loss at iteration 550 : 0.005111979320645332
Loss at iteration 560 : 0.0031211888417601585
Loss at iteration 570 : 0.007601909805089235
Loss at iteration 580 : 0.008385798893868923
Loss at iteration 590 : 0.010611416772007942
Loss at iteration 600 : 0.005393446423113346
Loss at iteration 610 : 0.015230415388941765
Loss at iteration 620 : 0.029722750186920166
Loss at iteration 630 : 0.008613293059170246
Loss at iteration 640 : 0.010551068000495434
Loss at iteration 650 : 0.01616167277097702
Loss at iteration 660 : 0.010133136063814163
Loss at iteration 670 : 0.010850085876882076
Loss at iteration 680 : 0.0073191458359360695
Loss at iteration 690 : 0.005152630154043436
Loss at iteration 700 : 0.009439853951334953
Loss at iteration 710 : 0.011615222319960594
Loss at iteration 720 : 0.010545806027948856
Loss at iteration 730 : 0.005406493786722422
Loss at iteration 740 : 0.00574896577745676
Loss at iteration 750 : 0.013777936808764935
Loss at iteration 760 : 0.009704452008008957
Loss at iteration 770 : 0.009671302512288094
Loss at iteration 780 : 0.004636990372091532
Loss at iteration 790 : 0.023898227140307426
Loss at iteration 800 : 0.00494302436709404
Loss at iteration 810 : 0.007461782079190016
Loss at iteration 820 : 0.006933967117220163
Loss at iteration 830 : 0.01182111632078886
Loss at iteration 840 : 0.002684979233890772
Loss at iteration 850 : 0.005910965614020824
Loss at iteration 860 : 0.008709757588803768
Loss at iteration 870 : 0.008160291239619255
Loss at iteration 880 : 0.043486226350069046
Loss at iteration 890 : 0.008901470340788364
Loss at iteration 900 : 0.01821303181350231
Loss at iteration 910 : 0.003498123027384281
Loss at iteration 920 : 0.005931425839662552
Loss at iteration 930 : 0.0031590242870151997
Loss at iteration 940 : 0.007355038542300463
Loss at iteration 950 : 0.00859779678285122
Loss at iteration 960 : 0.0050009144470095634
Loss at iteration 970 : 0.013592150993645191
Loss at iteration 980 : 0.016314158216118813
Loss at iteration 990 : 0.014515318907797337
Loss at iteration 1000 : 0.015011833980679512
Loss at iteration 1010 : 0.014794258400797844
Loss at iteration 1020 : 0.009014955721795559
Loss at iteration 1030 : 0.013621056452393532
Loss at iteration 1040 : 0.010726343840360641
Loss at iteration 1050 : 0.005295820068567991
Loss at iteration 1060 : 0.010063373483717442
Loss at iteration 1070 : 0.005731445737183094
Loss at iteration 1080 : 0.008939478546380997
Loss at iteration 1090 : 0.008197212591767311
Loss at iteration 1100 : 0.010617302730679512
Loss at iteration 1110 : 0.00682917982339859
Loss at iteration 1120 : 0.012440180405974388
Loss at iteration 1130 : 0.007487209513783455
Loss at iteration 1140 : 0.011762086302042007
Loss at iteration 1150 : 0.010448604822158813
Loss at iteration 1160 : 0.006721863988786936
Loss at iteration 1170 : 0.012250459752976894
Loss at iteration 1180 : 0.006946003530174494
Loss at iteration 1190 : 0.01050036121159792
Loss at iteration 1200 : 0.009410145692527294
Loss at iteration 1210 : 0.02368178777396679
Loss at iteration 1220 : 0.012095065787434578
Loss at iteration 1230 : 0.00918535515666008
Loss at iteration 1240 : 0.005340317729860544
Loss at iteration 1250 : 0.005181119777262211
Loss at iteration 1260 : 0.005016425624489784
Loss at iteration 1270 : 0.011078954674303532
Loss at iteration 1280 : 0.004514325875788927
Loss at iteration 1290 : 0.010579965077340603
Loss at iteration 1300 : 0.00798749178647995
Loss at iteration 1310 : 0.020248759537935257
Loss at iteration 1320 : 0.013894177973270416
Loss at iteration 1330 : 0.009208515286445618
Loss at iteration 1340 : 0.014761947095394135
Loss at iteration 1350 : 0.004332975950092077
Loss at iteration 1360 : 0.006182780954986811
Loss at iteration 1370 : 0.009956888854503632
Loss at iteration 1380 : 0.010346024297177792
Loss at iteration 1390 : 0.020859381183981895
Loss at iteration 1400 : 0.009218763560056686
Loss at iteration 1410 : 0.00841881986707449
Loss at iteration 1420 : 0.018476741388440132
Loss at iteration 1430 : 0.007080655544996262
Loss at iteration 1440 : 0.009609200060367584
Loss at iteration 1450 : 0.015044741332530975
Loss at iteration 1460 : 0.02901720069348812
Loss at iteration 1470 : 0.01711522415280342
Loss at iteration 1480 : 0.01019238494336605
Loss at iteration 1490 : 0.014805778861045837
Loss at iteration 1500 : 0.006824548356235027
Loss at iteration 1510 : 0.007820455357432365
Loss at iteration 1520 : 0.005742095876485109
Loss at iteration 1530 : 0.004447634331882
Loss at iteration 1540 : 0.010534808970987797
Loss at iteration 1550 : 0.004086294211447239
Loss at iteration 1560 : 0.008635704405605793
Loss at iteration 1570 : 0.011664845049381256
Loss at iteration 1580 : 0.017357807606458664
Loss at iteration 1590 : 0.007218814920634031
Loss at iteration 1600 : 0.009213539771735668
Loss at iteration 1610 : 0.012949978932738304
Loss at iteration 1620 : 0.004338013473898172
Loss at iteration 1630 : 0.007582521997392178
Loss at iteration 1640 : 0.008281374350190163
Loss at iteration 1650 : 0.006872010882943869
Loss at iteration 1660 : 0.007852324284613132
Loss at iteration 1670 : 0.0046537453308701515
Loss at iteration 1680 : 0.007917992770671844
Loss at iteration 1690 : 0.006019321270287037
Loss at iteration 1700 : 0.01296792458742857
Loss at iteration 1710 : 0.012141192331910133
Loss at iteration 1720 : 0.009700238704681396
Loss at iteration 1730 : 0.005306629464030266
Loss at iteration 1740 : 0.0064028529450297356
Loss at iteration 1750 : 0.009334288537502289
Loss at iteration 1760 : 0.005956662353128195
Loss at iteration 1770 : 0.011164475232362747
Loss at iteration 1780 : 0.006611104588955641
Loss at iteration 1790 : 0.014427246525883675
Loss at iteration 1800 : 0.005951049737632275
Loss at iteration 1810 : 0.0073987701907753944
Loss at iteration 1820 : 0.00538276880979538
Loss at iteration 1830 : 0.009000503458082676
Loss at iteration 1840 : 0.009963953867554665
Loss at iteration 1850 : 0.006709805224090815
Loss at iteration 1860 : 0.008341523818671703
Loss at iteration 1870 : 0.006379926577210426
Loss at iteration 1880 : 0.01898910105228424
Loss at iteration 1890 : 0.01128267403692007
Loss at iteration 1900 : 0.018607279285788536
Loss at iteration 1910 : 0.0036330735310912132
Loss at iteration 1920 : 0.0033485903404653072
Loss at iteration 1930 : 0.01105111837387085
Loss at iteration 1940 : 0.00826174020767212
Loss at iteration 1950 : 0.009469402022659779
Loss at iteration 1960 : 0.005114614497870207
Loss at iteration 1970 : 0.005107743199914694
Loss at iteration 1980 : 0.007943148724734783
Loss at iteration 1990 : 0.01813119277358055
Loss at iteration 2000 : 0.00699402391910553
Loss at iteration 2010 : 0.011969150975346565
Loss at iteration 2020 : 0.009810343384742737
Loss at iteration 2030 : 0.004702456295490265
Loss at iteration 2040 : 0.010913166217505932
Loss at iteration 2050 : 0.006370976101607084
Loss at iteration 2060 : 0.007125944830477238
Loss at iteration 2070 : 0.009034901857376099
Loss at iteration 2080 : 0.006679645739495754
Loss at iteration 2090 : 0.0036904895678162575
Loss at iteration 2100 : 0.015341270714998245
Loss at iteration 2110 : 0.013737942092120647
Loss at iteration 2120 : 0.0054991282522678375
Loss at iteration 2130 : 0.011945203877985477
Loss at iteration 2140 : 0.012344099581241608
Loss at iteration 2150 : 0.009250904433429241
Loss at iteration 2160 : 0.006395228207111359
Loss at iteration 2170 : 0.011674612760543823
Loss at iteration 2180 : 0.015105733647942543
Loss at iteration 2190 : 0.0056449430994689465
Loss at iteration 2200 : 0.01690666750073433
Loss at iteration 2210 : 0.020590204745531082
Loss at iteration 2220 : 0.010592242702841759
Loss at iteration 2230 : 0.020410802215337753
Loss at iteration 2240 : 0.01759982854127884
Loss at iteration 2250 : 0.015800567343831062
Loss at iteration 2260 : 0.017964128404855728
Loss at iteration 2270 : 0.039294980466365814
Loss at iteration 2280 : 0.025308959186077118
Loss at iteration 2290 : 0.019319385290145874
Loss at iteration 2300 : 0.019166849553585052
Loss at iteration 2310 : 0.009697373025119305
Loss at iteration 2320 : 0.014059515669941902
Loss at iteration 2330 : 0.007273651659488678
Loss at iteration 2340 : 0.016301222145557404
Loss at iteration 2350 : 0.00993320345878601
Loss at iteration 2360 : 0.010944867506623268
Loss at iteration 2370 : 0.013353073969483376
Loss at iteration 2380 : 0.009559568017721176
Loss at iteration 2390 : 0.014911968261003494
Loss at iteration 2400 : 0.01028166338801384
Loss at iteration 2410 : 0.006566180381923914
Loss at iteration 2420 : 0.0039360737428069115
The SSIM Value is: 0.836413832505544
The PSNR Value is: 22.616349856058758
the epoch is: 73
Loss at iteration 10 : 0.009501118212938309
Loss at iteration 20 : 0.01148927304893732
Loss at iteration 30 : 0.016668550670146942
Loss at iteration 40 : 0.014916926622390747
Loss at iteration 50 : 0.00493059866130352
Loss at iteration 60 : 0.0034860665909945965
Loss at iteration 70 : 0.022429145872592926
Loss at iteration 80 : 0.01917276158928871
Loss at iteration 90 : 0.009155239909887314
Loss at iteration 100 : 0.017996223643422127
Loss at iteration 110 : 0.007871263660490513
Loss at iteration 120 : 0.015000289306044579
Loss at iteration 130 : 0.014776399359107018
Loss at iteration 140 : 0.006972047500312328
Loss at iteration 150 : 0.013044318184256554
Loss at iteration 160 : 0.011115847155451775
Loss at iteration 170 : 0.005846730433404446
Loss at iteration 180 : 0.003940907772630453
Loss at iteration 190 : 0.013637332245707512
Loss at iteration 200 : 0.00798619445413351
Loss at iteration 210 : 0.01862938702106476
Loss at iteration 220 : 0.016734469681978226
Loss at iteration 230 : 0.010295062325894833
Loss at iteration 240 : 0.013958578929305077
Loss at iteration 250 : 0.013431055471301079
Loss at iteration 260 : 0.00527642946690321
Loss at iteration 270 : 0.005532677751034498
Loss at iteration 280 : 0.019603155553340912
Loss at iteration 290 : 0.010706317611038685
Loss at iteration 300 : 0.01749153807759285
Loss at iteration 310 : 0.012583143077790737
Loss at iteration 320 : 0.018115082755684853
Loss at iteration 330 : 0.011942237615585327
Loss at iteration 340 : 0.018991591408848763
Loss at iteration 350 : 0.009095093235373497
Loss at iteration 360 : 0.01552435290068388
Loss at iteration 370 : 0.0029044875409454107
Loss at iteration 380 : 0.003992591984570026
Loss at iteration 390 : 0.00895971804857254
Loss at iteration 400 : 0.02441883645951748
Loss at iteration 410 : 0.0064838966354727745
Loss at iteration 420 : 0.0072591109201312065
Loss at iteration 430 : 0.007920964621007442
Loss at iteration 440 : 0.009106027893722057
Loss at iteration 450 : 0.011516879312694073
Loss at iteration 460 : 0.006565913092344999
Loss at iteration 470 : 0.0074570681899785995
Loss at iteration 480 : 0.002301581436768174
Loss at iteration 490 : 0.00888868048787117
Loss at iteration 500 : 0.00923140812665224
Loss at iteration 510 : 0.011265468783676624
Loss at iteration 520 : 0.010480426251888275
Loss at iteration 530 : 0.007071223109960556
Loss at iteration 540 : 0.019298292696475983
Loss at iteration 550 : 0.005039689596742392
Loss at iteration 560 : 0.009525613859295845
Loss at iteration 570 : 0.0033645222429186106
Loss at iteration 580 : 0.007631905376911163
Loss at iteration 590 : 0.0074112000875175
Loss at iteration 600 : 0.008062189444899559
Loss at iteration 610 : 0.008749045431613922
Loss at iteration 620 : 0.01841522753238678
Loss at iteration 630 : 0.004016908351331949
Loss at iteration 640 : 0.007356385700404644
Loss at iteration 650 : 0.007932334206998348
Loss at iteration 660 : 0.0076096076518297195
Loss at iteration 670 : 0.008582760579884052
Loss at iteration 680 : 0.008310622535645962
Loss at iteration 690 : 0.005438258871436119
Loss at iteration 700 : 0.012560160830616951
Loss at iteration 710 : 0.012838488444685936
Loss at iteration 720 : 0.005976857151836157
Loss at iteration 730 : 0.0067202141508460045
Loss at iteration 740 : 0.004591371864080429
Loss at iteration 750 : 0.003849050495773554
Loss at iteration 760 : 0.004805849865078926
Loss at iteration 770 : 0.009826990775763988
Loss at iteration 780 : 0.006230941973626614
Loss at iteration 790 : 0.014611737802624702
Loss at iteration 800 : 0.008825882337987423
Loss at iteration 810 : 0.008839146234095097
Loss at iteration 820 : 0.006826299708336592
Loss at iteration 830 : 0.0065794289112091064
Loss at iteration 840 : 0.0048791514709591866
Loss at iteration 850 : 0.007594859227538109
Loss at iteration 860 : 0.01173160970211029
Loss at iteration 870 : 0.0113865677267313
Loss at iteration 880 : 0.005160259082913399
Loss at iteration 890 : 0.009220640175044537
Loss at iteration 900 : 0.014451049268245697
Loss at iteration 910 : 0.013709913939237595
Loss at iteration 920 : 0.014692017808556557
Loss at iteration 930 : 0.008536403998732567
Loss at iteration 940 : 0.004824676550924778
Loss at iteration 950 : 0.008514275774359703
Loss at iteration 960 : 0.01288409624248743
Loss at iteration 970 : 0.010684918612241745
Loss at iteration 980 : 0.006894429214298725
Loss at iteration 990 : 0.02373313531279564
Loss at iteration 1000 : 0.00987018458545208
Loss at iteration 1010 : 0.004195207264274359
Loss at iteration 1020 : 0.011865726672112942
Loss at iteration 1030 : 0.008900698274374008
Loss at iteration 1040 : 0.009016326628625393
Loss at iteration 1050 : 0.009742354042828083
Loss at iteration 1060 : 0.004409534856677055
Loss at iteration 1070 : 0.005782102234661579
Loss at iteration 1080 : 0.021011900156736374
Loss at iteration 1090 : 0.009100371040403843
Loss at iteration 1100 : 0.006911145988851786
Loss at iteration 1110 : 0.012589258141815662
Loss at iteration 1120 : 0.009907255880534649
Loss at iteration 1130 : 0.012058151885867119
Loss at iteration 1140 : 0.007686902303248644
Loss at iteration 1150 : 0.013085626997053623
Loss at iteration 1160 : 0.008502669632434845
Loss at iteration 1170 : 0.004477027803659439
Loss at iteration 1180 : 0.00573598500341177
Loss at iteration 1190 : 0.009624168276786804
Loss at iteration 1200 : 0.006157143972814083
Loss at iteration 1210 : 0.007061019539833069
Loss at iteration 1220 : 0.014010467566549778
Loss at iteration 1230 : 0.035883281379938126
Loss at iteration 1240 : 0.008416575379669666
Loss at iteration 1250 : 0.014217540621757507
Loss at iteration 1260 : 0.006373564712703228
Loss at iteration 1270 : 0.011093161068856716
Loss at iteration 1280 : 0.015594607219099998
Loss at iteration 1290 : 0.032820772379636765
Loss at iteration 1300 : 0.006831909529864788
Loss at iteration 1310 : 0.014101561158895493
Loss at iteration 1320 : 0.008512750267982483
Loss at iteration 1330 : 0.009889697656035423
Loss at iteration 1340 : 0.0070127882063388824
Loss at iteration 1350 : 0.0072641996666789055
Loss at iteration 1360 : 0.00418124720454216
Loss at iteration 1370 : 0.008926233276724815
Loss at iteration 1380 : 0.022214410826563835
Loss at iteration 1390 : 0.009328878484666348
Loss at iteration 1400 : 0.009569942019879818
Loss at iteration 1410 : 0.009285135194659233
Loss at iteration 1420 : 0.005087367724627256
Loss at iteration 1430 : 0.018119046464562416
Loss at iteration 1440 : 0.011105041019618511
Loss at iteration 1450 : 0.011136235669255257
Loss at iteration 1460 : 0.008360149338841438
Loss at iteration 1470 : 0.003943542018532753
Loss at iteration 1480 : 0.005354331806302071
Loss at iteration 1490 : 0.01364651508629322
Loss at iteration 1500 : 0.004559346474707127
Loss at iteration 1510 : 0.006856369785964489
Loss at iteration 1520 : 0.007387182675302029
Loss at iteration 1530 : 0.01201608031988144
Loss at iteration 1540 : 0.0037578486371785402
Loss at iteration 1550 : 0.010262500494718552
Loss at iteration 1560 : 0.006393045652657747
Loss at iteration 1570 : 0.008061991073191166
Loss at iteration 1580 : 0.007921470329165459
Loss at iteration 1590 : 0.006073044613003731
Loss at iteration 1600 : 0.012744623236358166
Loss at iteration 1610 : 0.005892151966691017
Loss at iteration 1620 : 0.010648141615092754
Loss at iteration 1630 : 0.008350580930709839
Loss at iteration 1640 : 0.007612902671098709
Loss at iteration 1650 : 0.007618430536240339
Loss at iteration 1660 : 0.003896495094522834
Loss at iteration 1670 : 0.01128643099218607
Loss at iteration 1680 : 0.007052930071949959
Loss at iteration 1690 : 0.010450002737343311
Loss at iteration 1700 : 0.005993722006678581
Loss at iteration 1710 : 0.0060487897135317326
Loss at iteration 1720 : 0.009327206760644913
Loss at iteration 1730 : 0.02044820971786976
Loss at iteration 1740 : 0.006412474904209375
Loss at iteration 1750 : 0.008106451481580734
Loss at iteration 1760 : 0.00839524157345295
Loss at iteration 1770 : 0.014288458041846752
Loss at iteration 1780 : 0.006756943184882402
Loss at iteration 1790 : 0.007176660466939211
Loss at iteration 1800 : 0.008121354505419731
Loss at iteration 1810 : 0.0065007577650249004
Loss at iteration 1820 : 0.011207829229533672
Loss at iteration 1830 : 0.013086878694593906
Loss at iteration 1840 : 0.01288115419447422
Loss at iteration 1850 : 0.011088641360402107
Loss at iteration 1860 : 0.010458136908710003
Loss at iteration 1870 : 0.012960691004991531
Loss at iteration 1880 : 0.00367013830691576
Loss at iteration 1890 : 0.004543721210211515
Loss at iteration 1900 : 0.015486851334571838
Loss at iteration 1910 : 0.0067344484850764275
Loss at iteration 1920 : 0.011312724091112614
Loss at iteration 1930 : 0.01292773149907589
Loss at iteration 1940 : 0.008751023560762405
Loss at iteration 1950 : 0.004549207165837288
Loss at iteration 1960 : 0.0057393996976315975
Loss at iteration 1970 : 0.012745022773742676
Loss at iteration 1980 : 0.009527073241770267
Loss at iteration 1990 : 0.008475746028125286
Loss at iteration 2000 : 0.009579511359333992
Loss at iteration 2010 : 0.009279978461563587
Loss at iteration 2020 : 0.007154164835810661
Loss at iteration 2030 : 0.008024686016142368
Loss at iteration 2040 : 0.020212974399328232
Loss at iteration 2050 : 0.007890881970524788
Loss at iteration 2060 : 0.010426306165754795
Loss at iteration 2070 : 0.0118767861276865
Loss at iteration 2080 : 0.00910949520766735
Loss at iteration 2090 : 0.00601440854370594
Loss at iteration 2100 : 0.00600024126470089
Loss at iteration 2110 : 0.008855851367115974
Loss at iteration 2120 : 0.015408026054501534
Loss at iteration 2130 : 0.014217441901564598
Loss at iteration 2140 : 0.01271536760032177
Loss at iteration 2150 : 0.01373605988919735
Loss at iteration 2160 : 0.007906177081167698
Loss at iteration 2170 : 0.009334726259112358
Loss at iteration 2180 : 0.015405314043164253
Loss at iteration 2190 : 0.008010393008589745
Loss at iteration 2200 : 0.016592813655734062
Loss at iteration 2210 : 0.008988031186163425
Loss at iteration 2220 : 0.0073450650088489056
Loss at iteration 2230 : 0.003893513698130846
Loss at iteration 2240 : 0.01728871650993824
Loss at iteration 2250 : 0.0074279699474573135
Loss at iteration 2260 : 0.0061647845432162285
Loss at iteration 2270 : 0.007940222509205341
Loss at iteration 2280 : 0.004256516229361296
Loss at iteration 2290 : 0.009612652473151684
Loss at iteration 2300 : 0.004049454350024462
Loss at iteration 2310 : 0.007590910419821739
Loss at iteration 2320 : 0.00701097771525383
Loss at iteration 2330 : 0.009254270233213902
Loss at iteration 2340 : 0.009177643805742264
Loss at iteration 2350 : 0.006415525916963816
Loss at iteration 2360 : 0.010377117432653904
Loss at iteration 2370 : 0.003822780679911375
Loss at iteration 2380 : 0.004658917896449566
Loss at iteration 2390 : 0.015011227689683437
Loss at iteration 2400 : 0.015308422967791557
Loss at iteration 2410 : 0.007707156240940094
Loss at iteration 2420 : 0.00704659428447485
The SSIM Value is: 0.8487245400746664
The PSNR Value is: 22.614334869384766
the epoch is: 74
Loss at iteration 10 : 0.006302919704467058
Loss at iteration 20 : 0.0033551359083503485
Loss at iteration 30 : 0.0037675658240914345
Loss at iteration 40 : 0.0045403968542814255
Loss at iteration 50 : 0.010174356400966644
Loss at iteration 60 : 0.007656557951122522
Loss at iteration 70 : 0.006051519885659218
Loss at iteration 80 : 0.004386488348245621
Loss at iteration 90 : 0.011851766146719456
Loss at iteration 100 : 0.010441179387271404
Loss at iteration 110 : 0.014381635934114456
Loss at iteration 120 : 0.00966823473572731
Loss at iteration 130 : 0.006537000648677349
Loss at iteration 140 : 0.006137781776487827
Loss at iteration 150 : 0.0110367676243186
Loss at iteration 160 : 0.006122078746557236
Loss at iteration 170 : 0.01088296715170145
Loss at iteration 180 : 0.008157477714121342
Loss at iteration 190 : 0.012389710173010826
Loss at iteration 200 : 0.020330173894762993
Loss at iteration 210 : 0.005150193814188242
Loss at iteration 220 : 0.004563646856695414
Loss at iteration 230 : 0.007807986810803413
Loss at iteration 240 : 0.008695995435118675
Loss at iteration 250 : 0.01062793843448162
Loss at iteration 260 : 0.008626392111182213
Loss at iteration 270 : 0.024191103875637054
Loss at iteration 280 : 0.008020533248782158
Loss at iteration 290 : 0.014599790796637535
Loss at iteration 300 : 0.005617278628051281
Loss at iteration 310 : 0.015613794326782227
Loss at iteration 320 : 0.00976693257689476
Loss at iteration 330 : 0.004839648026973009
Loss at iteration 340 : 0.014430850744247437
Loss at iteration 350 : 0.008311612531542778
Loss at iteration 360 : 0.0037610866129398346
Loss at iteration 370 : 0.007840965874493122
Loss at iteration 380 : 0.013466157019138336
Loss at iteration 390 : 0.006881886161863804
Loss at iteration 400 : 0.0065344637259840965
Loss at iteration 410 : 0.03350159525871277
Loss at iteration 420 : 0.012645859271287918
Loss at iteration 430 : 0.009180991910398006
Loss at iteration 440 : 0.0052360547706484795
Loss at iteration 450 : 0.004516406450420618
Loss at iteration 460 : 0.006980291102081537
Loss at iteration 470 : 0.01044558733701706
Loss at iteration 480 : 0.012661842629313469
Loss at iteration 490 : 0.006817188113927841
Loss at iteration 500 : 0.012110935524106026
Loss at iteration 510 : 0.00347300642170012
Loss at iteration 520 : 0.014298769645392895
Loss at iteration 530 : 0.01976151578128338
Loss at iteration 540 : 0.008622270077466965
Loss at iteration 550 : 0.01038677990436554
Loss at iteration 560 : 0.006253806408494711
Loss at iteration 570 : 0.006061679217964411
Loss at iteration 580 : 0.005455391481518745
Loss at iteration 590 : 0.015137860551476479
Loss at iteration 600 : 0.01125045120716095
Loss at iteration 610 : 0.007684569805860519
Loss at iteration 620 : 0.011770302429795265
Loss at iteration 630 : 0.016418104991316795
Loss at iteration 640 : 0.0064506251364946365
Loss at iteration 650 : 0.01066778413951397
Loss at iteration 660 : 0.003395914565771818
Loss at iteration 670 : 0.008669713512063026
Loss at iteration 680 : 0.009550889953970909
Loss at iteration 690 : 0.016324367374181747
Loss at iteration 700 : 0.002456319984048605
Loss at iteration 710 : 0.01171085238456726
Loss at iteration 720 : 0.005688810255378485
Loss at iteration 730 : 0.005437411367893219
Loss at iteration 740 : 0.007416890002787113
Loss at iteration 750 : 0.015409640967845917
Loss at iteration 760 : 0.006601178087294102
Loss at iteration 770 : 0.004239541478455067
Loss at iteration 780 : 0.014764860272407532
Loss at iteration 790 : 0.007935133762657642
Loss at iteration 800 : 0.013066773302853107
Loss at iteration 810 : 0.007410742808133364
Loss at iteration 820 : 0.006221657153218985
Loss at iteration 830 : 0.011080106720328331
Loss at iteration 840 : 0.014458347111940384
Loss at iteration 850 : 0.006018682848662138
Loss at iteration 860 : 0.007977615110576153
Loss at iteration 870 : 0.012835996225476265
Loss at iteration 880 : 0.010723652318120003
Loss at iteration 890 : 0.006772951688617468
Loss at iteration 900 : 0.004972237162292004
Loss at iteration 910 : 0.00597399054095149
Loss at iteration 920 : 0.008957864716649055
Loss at iteration 930 : 0.011047270148992538
Loss at iteration 940 : 0.012406452558934689
Loss at iteration 950 : 0.012698058970272541
Loss at iteration 960 : 0.006997535936534405
Loss at iteration 970 : 0.007051040418446064
Loss at iteration 980 : 0.00772114610299468
Loss at iteration 990 : 0.0069844480603933334
Loss at iteration 1000 : 0.022265858948230743
Loss at iteration 1010 : 0.010442239232361317
Loss at iteration 1020 : 0.00917652528733015
Loss at iteration 1030 : 0.0395427867770195
Loss at iteration 1040 : 0.007257482502609491
Loss at iteration 1050 : 0.007518390193581581
Loss at iteration 1060 : 0.008472058922052383
Loss at iteration 1070 : 0.007947866804897785
Loss at iteration 1080 : 0.010615133680403233
Loss at iteration 1090 : 0.011515732854604721
Loss at iteration 1100 : 0.009983575902879238
Loss at iteration 1110 : 0.006953272968530655
Loss at iteration 1120 : 0.008615498431026936
Loss at iteration 1130 : 0.0066017284989356995
Loss at iteration 1140 : 0.015156704932451248
Loss at iteration 1150 : 0.01251283846795559
Loss at iteration 1160 : 0.013827521353960037
Loss at iteration 1170 : 0.003753236262127757
Loss at iteration 1180 : 0.0027918654959648848
Loss at iteration 1190 : 0.013155564665794373
Loss at iteration 1200 : 0.010426206514239311
Loss at iteration 1210 : 0.010239897295832634
Loss at iteration 1220 : 0.008542968891561031
Loss at iteration 1230 : 0.0076700784265995026
Loss at iteration 1240 : 0.019467120990157127
Loss at iteration 1250 : 0.00780353182926774
Loss at iteration 1260 : 0.008786985650658607
Loss at iteration 1270 : 0.012097947299480438
Loss at iteration 1280 : 0.00841488130390644
Loss at iteration 1290 : 0.0050568426959216595
Loss at iteration 1300 : 0.012114415876567364
Loss at iteration 1310 : 0.0035672367084771395
Loss at iteration 1320 : 0.004989887587726116
Loss at iteration 1330 : 0.01837792806327343
Loss at iteration 1340 : 0.016049126163125038
Loss at iteration 1350 : 0.004489784128963947
Loss at iteration 1360 : 0.019316570833325386
Loss at iteration 1370 : 0.006038092076778412
Loss at iteration 1380 : 0.0067572034895420074
Loss at iteration 1390 : 0.0036680824123322964
Loss at iteration 1400 : 0.012885566800832748
Loss at iteration 1410 : 0.021428193897008896
Loss at iteration 1420 : 0.0173337459564209
Loss at iteration 1430 : 0.0051256888546049595
Loss at iteration 1440 : 0.01002604141831398
Loss at iteration 1450 : 0.00804830901324749
Loss at iteration 1460 : 0.007702917791903019
Loss at iteration 1470 : 0.0024423152208328247
Loss at iteration 1480 : 0.006535189691931009
Loss at iteration 1490 : 0.0036427865270525217
Loss at iteration 1500 : 0.015271496027708054
Loss at iteration 1510 : 0.00582426181063056
Loss at iteration 1520 : 0.015945257619023323
Loss at iteration 1530 : 0.012838209047913551
Loss at iteration 1540 : 0.01096465066075325
Loss at iteration 1550 : 0.009840242564678192
Loss at iteration 1560 : 0.00867479108273983
Loss at iteration 1570 : 0.004765823017805815
Loss at iteration 1580 : 0.014232172630727291
Loss at iteration 1590 : 0.0049057211726903915
Loss at iteration 1600 : 0.005855166353285313
Loss at iteration 1610 : 0.007708565331995487
Loss at iteration 1620 : 0.006120697595179081
Loss at iteration 1630 : 0.007961315102875233
Loss at iteration 1640 : 0.012459024786949158
Loss at iteration 1650 : 0.011556418612599373
Loss at iteration 1660 : 0.011667650192975998
Loss at iteration 1670 : 0.008821018040180206
Loss at iteration 1680 : 0.010108518414199352
Loss at iteration 1690 : 0.010052627883851528
Loss at iteration 1700 : 0.011281292885541916
Loss at iteration 1710 : 0.017236817628145218
Loss at iteration 1720 : 0.013094920665025711
Loss at iteration 1730 : 0.010077456012368202
Loss at iteration 1740 : 0.010874628089368343
Loss at iteration 1750 : 0.015651412308216095
Loss at iteration 1760 : 0.008393565192818642
Loss at iteration 1770 : 0.024789275601506233
Loss at iteration 1780 : 0.009505599737167358
Loss at iteration 1790 : 0.01672874204814434
Loss at iteration 1800 : 0.012385987676680088
Loss at iteration 1810 : 0.012150072492659092
Loss at iteration 1820 : 0.008371657691895962
Loss at iteration 1830 : 0.007513832300901413
Loss at iteration 1840 : 0.009932175278663635
Loss at iteration 1850 : 0.010656612925231457
Loss at iteration 1860 : 0.009447756223380566
Loss at iteration 1870 : 0.009147907607257366
Loss at iteration 1880 : 0.008571396581828594
Loss at iteration 1890 : 0.006834971718490124
Loss at iteration 1900 : 0.01164601743221283
Loss at iteration 1910 : 0.010359864681959152
Loss at iteration 1920 : 0.019904645159840584
Loss at iteration 1930 : 0.007146920543164015
Loss at iteration 1940 : 0.006420365534722805
Loss at iteration 1950 : 0.007044732104986906
Loss at iteration 1960 : 0.005270286463201046
Loss at iteration 1970 : 0.017337942495942116
Loss at iteration 1980 : 0.009728370234370232
Loss at iteration 1990 : 0.005036623682826757
Loss at iteration 2000 : 0.007064206060022116
Loss at iteration 2010 : 0.024682151153683662
Loss at iteration 2020 : 0.011063222773373127
Loss at iteration 2030 : 0.017068685963749886
Loss at iteration 2040 : 0.005618551280349493
Loss at iteration 2050 : 0.0038958715740591288
Loss at iteration 2060 : 0.007963825948536396
Loss at iteration 2070 : 0.006752173416316509
Loss at iteration 2080 : 0.014623686671257019
Loss at iteration 2090 : 0.013158675283193588
Loss at iteration 2100 : 0.021908599883317947
Loss at iteration 2110 : 0.010510135442018509
Loss at iteration 2120 : 0.00862122979015112
Loss at iteration 2130 : 0.007369812577962875
Loss at iteration 2140 : 0.006049249786883593
Loss at iteration 2150 : 0.013399798423051834
Loss at iteration 2160 : 0.009509772062301636
Loss at iteration 2170 : 0.03144892677664757
Loss at iteration 2180 : 0.008752438239753246
Loss at iteration 2190 : 0.009197065606713295
Loss at iteration 2200 : 0.007948711514472961
Loss at iteration 2210 : 0.005173009354621172
Loss at iteration 2220 : 0.009488184005022049
Loss at iteration 2230 : 0.02194892056286335
Loss at iteration 2240 : 0.007928328588604927
Loss at iteration 2250 : 0.011415674351155758
Loss at iteration 2260 : 0.007215104065835476
Loss at iteration 2270 : 0.00549073051661253
Loss at iteration 2280 : 0.009184534661471844
Loss at iteration 2290 : 0.008612360805273056
Loss at iteration 2300 : 0.006383822299540043
Loss at iteration 2310 : 0.01279644574970007
Loss at iteration 2320 : 0.010565905831754208
Loss at iteration 2330 : 0.011306384578347206
Loss at iteration 2340 : 0.005383687559515238
Loss at iteration 2350 : 0.010538743808865547
Loss at iteration 2360 : 0.010976478457450867
Loss at iteration 2370 : 0.013283489271998405
Loss at iteration 2380 : 0.006337692029774189
Loss at iteration 2390 : 0.005810776259750128
Loss at iteration 2400 : 0.01889922097325325
Loss at iteration 2410 : 0.0034206353593617678
Loss at iteration 2420 : 0.009821157902479172
The SSIM Value is: 0.8459340850512187
The PSNR Value is: 22.33820037841797
the epoch is: 75
Loss at iteration 10 : 0.006699091754853725
Loss at iteration 20 : 0.008898692205548286
Loss at iteration 30 : 0.007722430396825075
Loss at iteration 40 : 0.012336757965385914
Loss at iteration 50 : 0.011759420856833458
Loss at iteration 60 : 0.008048147894442081
Loss at iteration 70 : 0.009230729192495346
Loss at iteration 80 : 0.01642889529466629
Loss at iteration 90 : 0.003635663539171219
Loss at iteration 100 : 0.007060445379465818
Loss at iteration 110 : 0.022635173052549362
Loss at iteration 120 : 0.008717532269656658
Loss at iteration 130 : 0.007542780134826899
Loss at iteration 140 : 0.014794248156249523
Loss at iteration 150 : 0.01302347518503666
Loss at iteration 160 : 0.009125033393502235
Loss at iteration 170 : 0.007213424891233444
Loss at iteration 180 : 0.005802089814096689
Loss at iteration 190 : 0.007439387030899525
Loss at iteration 200 : 0.01038037147372961
Loss at iteration 210 : 0.006949901580810547
Loss at iteration 220 : 0.006886822171509266
Loss at iteration 230 : 0.00623609684407711
Loss at iteration 240 : 0.008039037697017193
Loss at iteration 250 : 0.008112872950732708
Loss at iteration 260 : 0.013194159604609013
Loss at iteration 270 : 0.0026884684339165688
Loss at iteration 280 : 0.00428770249709487
Loss at iteration 290 : 0.010381004773080349
Loss at iteration 300 : 0.004370677284896374
Loss at iteration 310 : 0.008587460964918137
Loss at iteration 320 : 0.007691026199609041
Loss at iteration 330 : 0.012497416697442532
Loss at iteration 340 : 0.010511966422200203
Loss at iteration 350 : 0.00244605029001832
Loss at iteration 360 : 0.005199761129915714
Loss at iteration 370 : 0.009577397257089615
Loss at iteration 380 : 0.011781522072851658
Loss at iteration 390 : 0.0036756223998963833
Loss at iteration 400 : 0.0075960345566272736
Loss at iteration 410 : 0.015437598340213299
Loss at iteration 420 : 0.016030030325055122
Loss at iteration 430 : 0.009408676996827126
Loss at iteration 440 : 0.005232808645814657
Loss at iteration 450 : 0.009635647758841515
Loss at iteration 460 : 0.010199013166129589
Loss at iteration 470 : 0.013020187616348267
Loss at iteration 480 : 0.010905470699071884
Loss at iteration 490 : 0.004667737055569887
Loss at iteration 500 : 0.007293787319213152
Loss at iteration 510 : 0.016042612493038177
Loss at iteration 520 : 0.010611020028591156
Loss at iteration 530 : 0.012528405524790287
Loss at iteration 540 : 0.015859169885516167
Loss at iteration 550 : 0.012554961256682873
Loss at iteration 560 : 0.025261498987674713
Loss at iteration 570 : 0.006649213843047619
Loss at iteration 580 : 0.012719349935650826
Loss at iteration 590 : 0.01727481000125408
Loss at iteration 600 : 0.003501242259517312
Loss at iteration 610 : 0.006501941010355949
Loss at iteration 620 : 0.014408706687390804
Loss at iteration 630 : 0.009609324857592583
Loss at iteration 640 : 0.013971186242997646
Loss at iteration 650 : 0.006528171245008707
Loss at iteration 660 : 0.008131030015647411
Loss at iteration 670 : 0.008795743808150291
Loss at iteration 680 : 0.00609253067523241
Loss at iteration 690 : 0.008592034690082073
Loss at iteration 700 : 0.007607177831232548
Loss at iteration 710 : 0.012083535082638264
Loss at iteration 720 : 0.009848185814917088
Loss at iteration 730 : 0.007268741726875305
Loss at iteration 740 : 0.009675164707005024
Loss at iteration 750 : 0.0024564180057495832
Loss at iteration 760 : 0.004580284468829632
Loss at iteration 770 : 0.007736932951956987
Loss at iteration 780 : 0.005519998725503683
Loss at iteration 790 : 0.0060056657530367374
Loss at iteration 800 : 0.007325985003262758
Loss at iteration 810 : 0.012032469734549522
Loss at iteration 820 : 0.008947459980845451
Loss at iteration 830 : 0.004755549598485231
Loss at iteration 840 : 0.0068855294957757
Loss at iteration 850 : 0.002084419596940279
Loss at iteration 860 : 0.009899502620100975
Loss at iteration 870 : 0.005864960607141256
Loss at iteration 880 : 0.005036960355937481
Loss at iteration 890 : 0.008250938728451729
Loss at iteration 900 : 0.007227174937725067
Loss at iteration 910 : 0.016621150076389313
Loss at iteration 920 : 0.016444971784949303
Loss at iteration 930 : 0.007963987998664379
Loss at iteration 940 : 0.013091831468045712
Loss at iteration 950 : 0.004265123046934605
Loss at iteration 960 : 0.018200956284999847
Loss at iteration 970 : 0.01315439771860838
Loss at iteration 980 : 0.013035756535828114
Loss at iteration 990 : 0.00857869815081358
Loss at iteration 1000 : 0.004934658762067556
Loss at iteration 1010 : 0.019295314326882362
Loss at iteration 1020 : 0.007218813057988882
Loss at iteration 1030 : 0.010365193709731102
Loss at iteration 1040 : 0.009469551034271717
Loss at iteration 1050 : 0.004560314118862152
Loss at iteration 1060 : 0.013807142153382301
Loss at iteration 1070 : 0.009012173861265182
Loss at iteration 1080 : 0.011569883674383163
Loss at iteration 1090 : 0.010203484445810318
Loss at iteration 1100 : 0.007800355087965727
Loss at iteration 1110 : 0.012178141623735428
Loss at iteration 1120 : 0.007778430823236704
Loss at iteration 1130 : 0.0034006477799266577
Loss at iteration 1140 : 0.03352624922990799
Loss at iteration 1150 : 0.00617778766900301
Loss at iteration 1160 : 0.010135372169315815
Loss at iteration 1170 : 0.00794108584523201
Loss at iteration 1180 : 0.010379713028669357
Loss at iteration 1190 : 0.0074249496683478355
Loss at iteration 1200 : 0.0041588712483644485
Loss at iteration 1210 : 0.00804462656378746
Loss at iteration 1220 : 0.0067235492169857025
Loss at iteration 1230 : 0.005685913376510143
Loss at iteration 1240 : 0.01086229644715786
Loss at iteration 1250 : 0.00876187440007925
Loss at iteration 1260 : 0.007919151335954666
Loss at iteration 1270 : 0.022401105612516403
Loss at iteration 1280 : 0.005163577850908041
Loss at iteration 1290 : 0.008576842024922371
Loss at iteration 1300 : 0.004545304924249649
Loss at iteration 1310 : 0.017593277618288994
Loss at iteration 1320 : 0.011062481440603733
Loss at iteration 1330 : 0.007413300219923258
Loss at iteration 1340 : 0.008050024509429932
Loss at iteration 1350 : 0.01436422485858202
Loss at iteration 1360 : 0.00778704509139061
Loss at iteration 1370 : 0.007391263730823994
Loss at iteration 1380 : 0.007350356318056583
Loss at iteration 1390 : 0.012231539934873581
Loss at iteration 1400 : 0.014135434292256832
Loss at iteration 1410 : 0.010136752389371395
Loss at iteration 1420 : 0.007929559797048569
Loss at iteration 1430 : 0.020009513944387436
Loss at iteration 1440 : 0.027826925739645958
Loss at iteration 1450 : 0.015084688551723957
Loss at iteration 1460 : 0.004949760157614946
Loss at iteration 1470 : 0.0055635841563344
Loss at iteration 1480 : 0.004050233867019415
Loss at iteration 1490 : 0.005655843298882246
Loss at iteration 1500 : 0.010798759758472443
Loss at iteration 1510 : 0.007754459977149963
Loss at iteration 1520 : 0.007157047279179096
Loss at iteration 1530 : 0.006922051310539246
Loss at iteration 1540 : 0.012316713109612465
Loss at iteration 1550 : 0.011834576725959778
Loss at iteration 1560 : 0.012323467992246151
Loss at iteration 1570 : 0.004801181145012379
Loss at iteration 1580 : 0.006958425976336002
Loss at iteration 1590 : 0.0074173640459775925
Loss at iteration 1600 : 0.010763773694634438
Loss at iteration 1610 : 0.006918531842529774
Loss at iteration 1620 : 0.004633196629583836
Loss at iteration 1630 : 0.003941324073821306
Loss at iteration 1640 : 0.010494844987988472
Loss at iteration 1650 : 0.007434525992721319
Loss at iteration 1660 : 0.01091751828789711
Loss at iteration 1670 : 0.008297105319797993
Loss at iteration 1680 : 0.00685362471267581
Loss at iteration 1690 : 0.009267919696867466
Loss at iteration 1700 : 0.00482466584071517
Loss at iteration 1710 : 0.009327641688287258
Loss at iteration 1720 : 0.009885670617222786
Loss at iteration 1730 : 0.010061884298920631
Loss at iteration 1740 : 0.011633331887423992
Loss at iteration 1750 : 0.007341321557760239
Loss at iteration 1760 : 0.008939946070313454
Loss at iteration 1770 : 0.01225276105105877
Loss at iteration 1780 : 0.014084551483392715
Loss at iteration 1790 : 0.014406105503439903
Loss at iteration 1800 : 0.0041516004130244255
Loss at iteration 1810 : 0.007353443652391434
Loss at iteration 1820 : 0.0059943306259810925
Loss at iteration 1830 : 0.011337763629853725
Loss at iteration 1840 : 0.0035010592546314
Loss at iteration 1850 : 0.014781547710299492
Loss at iteration 1860 : 0.0035406097304075956
Loss at iteration 1870 : 0.009292321279644966
Loss at iteration 1880 : 0.0104755237698555
Loss at iteration 1890 : 0.007541137747466564
Loss at iteration 1900 : 0.007692538667470217
Loss at iteration 1910 : 0.008961224928498268
Loss at iteration 1920 : 0.021920815110206604
Loss at iteration 1930 : 0.009627864696085453
Loss at iteration 1940 : 0.022323068231344223
Loss at iteration 1950 : 0.007077885325998068
Loss at iteration 1960 : 0.007838673889636993
Loss at iteration 1970 : 0.002383438404649496
Loss at iteration 1980 : 0.004997534211724997
Loss at iteration 1990 : 0.006544779986143112
Loss at iteration 2000 : 0.009855886921286583
Loss at iteration 2010 : 0.016635214909911156
Loss at iteration 2020 : 0.008160293102264404
Loss at iteration 2030 : 0.013784006237983704
Loss at iteration 2040 : 0.006516330875456333
Loss at iteration 2050 : 0.00883195735514164
Loss at iteration 2060 : 0.00447183009237051
Loss at iteration 2070 : 0.01791946403682232
Loss at iteration 2080 : 0.014260109513998032
Loss at iteration 2090 : 0.008719811215996742
Loss at iteration 2100 : 0.006402804981917143
Loss at iteration 2110 : 0.008420111611485481
Loss at iteration 2120 : 0.012492261826992035
Loss at iteration 2130 : 0.010366423055529594
Loss at iteration 2140 : 0.012835324741899967
Loss at iteration 2150 : 0.025390302762389183
Loss at iteration 2160 : 0.007017651107162237
Loss at iteration 2170 : 0.011906127445399761
Loss at iteration 2180 : 0.011178498156368732
Loss at iteration 2190 : 0.005712789949029684
Loss at iteration 2200 : 0.005999696906656027
Loss at iteration 2210 : 0.011239059269428253
Loss at iteration 2220 : 0.01994297280907631
Loss at iteration 2230 : 0.0103022875264287
Loss at iteration 2240 : 0.00672259833663702
Loss at iteration 2250 : 0.01165531761944294
Loss at iteration 2260 : 0.007642725948244333
Loss at iteration 2270 : 0.018664343282580376
Loss at iteration 2280 : 0.01652822457253933
Loss at iteration 2290 : 0.007448933552950621
Loss at iteration 2300 : 0.008726334199309349
Loss at iteration 2310 : 0.007228252477943897
Loss at iteration 2320 : 0.004713167902082205
Loss at iteration 2330 : 0.00814262218773365
Loss at iteration 2340 : 0.020341146737337112
Loss at iteration 2350 : 0.012853847816586494
Loss at iteration 2360 : 0.009472012519836426
Loss at iteration 2370 : 0.008352781645953655
Loss at iteration 2380 : 0.003814354306086898
Loss at iteration 2390 : 0.008492938242852688
Loss at iteration 2400 : 0.0034704646095633507
Loss at iteration 2410 : 0.004335894715040922
Loss at iteration 2420 : 0.014458540827035904
The SSIM Value is: 0.842231277624766
The PSNR Value is: 22.007020696004233
the epoch is: 76
Loss at iteration 10 : 0.00724374782294035
Loss at iteration 20 : 0.004993345122784376
Loss at iteration 30 : 0.0023210346698760986
Loss at iteration 40 : 0.013352541252970695
Loss at iteration 50 : 0.007537434343248606
Loss at iteration 60 : 0.00892429705709219
Loss at iteration 70 : 0.00926070474088192
Loss at iteration 80 : 0.015412947162985802
Loss at iteration 90 : 0.019859332591295242
Loss at iteration 100 : 0.010453513823449612
Loss at iteration 110 : 0.0038079689256846905
Loss at iteration 120 : 0.009524669498205185
Loss at iteration 130 : 0.006131116300821304
Loss at iteration 140 : 0.022248975932598114
Loss at iteration 150 : 0.009478101506829262
Loss at iteration 160 : 0.006868349388241768
Loss at iteration 170 : 0.012557679787278175
Loss at iteration 180 : 0.01359450351446867
Loss at iteration 190 : 0.01218474842607975
Loss at iteration 200 : 0.01551758125424385
Loss at iteration 210 : 0.010756364092230797
Loss at iteration 220 : 0.00642823614180088
Loss at iteration 230 : 0.016890211030840874
Loss at iteration 240 : 0.009656607173383236
Loss at iteration 250 : 0.01441316120326519
Loss at iteration 260 : 0.008733648806810379
Loss at iteration 270 : 0.010963231325149536
Loss at iteration 280 : 0.008279076777398586
Loss at iteration 290 : 0.011708216741681099
Loss at iteration 300 : 0.01182339247316122
Loss at iteration 310 : 0.003646263387054205
Loss at iteration 320 : 0.006232119631022215
Loss at iteration 330 : 0.0069793700240552425
Loss at iteration 340 : 0.004723337013274431
Loss at iteration 350 : 0.0050791604444384575
Loss at iteration 360 : 0.003617351409047842
Loss at iteration 370 : 0.007265996187925339
Loss at iteration 380 : 0.00937739759683609
Loss at iteration 390 : 0.008646923117339611
Loss at iteration 400 : 0.0069573139771819115
Loss at iteration 410 : 0.008001905865967274
Loss at iteration 420 : 0.009495885111391544
Loss at iteration 430 : 0.010497377254068851
Loss at iteration 440 : 0.01574958674609661
Loss at iteration 450 : 0.009886961430311203
Loss at iteration 460 : 0.007585751358419657
Loss at iteration 470 : 0.007853595539927483
Loss at iteration 480 : 0.014935791492462158
Loss at iteration 490 : 0.013251255266368389
Loss at iteration 500 : 0.0068231928162276745
Loss at iteration 510 : 0.013269097544252872
Loss at iteration 520 : 0.012358038686215878
Loss at iteration 530 : 0.009854299016296864
Loss at iteration 540 : 0.009863315150141716
Loss at iteration 550 : 0.004750619642436504
Loss at iteration 560 : 0.006452246103435755
Loss at iteration 570 : 0.008464395068585873
Loss at iteration 580 : 0.007148244418203831
Loss at iteration 590 : 0.006888025440275669
Loss at iteration 600 : 0.010809672065079212
Loss at iteration 610 : 0.0038229236379265785
Loss at iteration 620 : 0.009324702434241772
Loss at iteration 630 : 0.0040260618552565575
Loss at iteration 640 : 0.004646562971174717
Loss at iteration 650 : 0.011762595735490322
Loss at iteration 660 : 0.004767939448356628
Loss at iteration 670 : 0.010733449831604958
Loss at iteration 680 : 0.014371081255376339
Loss at iteration 690 : 0.013116245158016682
Loss at iteration 700 : 0.0056119924411177635
Loss at iteration 710 : 0.007042070850729942
Loss at iteration 720 : 0.013059710152447224
Loss at iteration 730 : 0.005074152257293463
Loss at iteration 740 : 0.015913644805550575
Loss at iteration 750 : 0.015181383118033409
Loss at iteration 760 : 0.013117008842527866
Loss at iteration 770 : 0.015533223748207092
Loss at iteration 780 : 0.00935611966997385
Loss at iteration 790 : 0.01582868956029415
Loss at iteration 800 : 0.006608662661164999
Loss at iteration 810 : 0.008756138384342194
Loss at iteration 820 : 0.013430911116302013
Loss at iteration 830 : 0.010991248302161694
Loss at iteration 840 : 0.0080663887783885
Loss at iteration 850 : 0.0048042903654277325
Loss at iteration 860 : 0.00510788569226861
Loss at iteration 870 : 0.00972338393330574
Loss at iteration 880 : 0.005679766181856394
Loss at iteration 890 : 0.009276263415813446
Loss at iteration 900 : 0.01120862178504467
Loss at iteration 910 : 0.011772646568715572
Loss at iteration 920 : 0.008744443766772747
Loss at iteration 930 : 0.007450528908520937
Loss at iteration 940 : 0.013475594110786915
Loss at iteration 950 : 0.043484508991241455
Loss at iteration 960 : 0.010332675650715828
Loss at iteration 970 : 0.012567064724862576
Loss at iteration 980 : 0.0050170691683888435
Loss at iteration 990 : 0.01429594773799181
Loss at iteration 1000 : 0.00669638579711318
Loss at iteration 1010 : 0.008815472945570946
Loss at iteration 1020 : 0.021003108471632004
Loss at iteration 1030 : 0.00685812858864665
Loss at iteration 1040 : 0.012405507266521454
Loss at iteration 1050 : 0.008592532947659492
Loss at iteration 1060 : 0.012572664767503738
Loss at iteration 1070 : 0.009661206044256687
Loss at iteration 1080 : 0.006221151910722256
Loss at iteration 1090 : 0.013048231601715088
Loss at iteration 1100 : 0.007802062667906284
Loss at iteration 1110 : 0.009281990118324757
Loss at iteration 1120 : 0.005392294842749834
Loss at iteration 1130 : 0.021381769329309464
Loss at iteration 1140 : 0.009872529655694962
Loss at iteration 1150 : 0.009607287123799324
Loss at iteration 1160 : 0.007428861688822508
Loss at iteration 1170 : 0.005003097001463175
Loss at iteration 1180 : 0.014309493824839592
Loss at iteration 1190 : 0.00787996407598257
Loss at iteration 1200 : 0.006061231251806021
Loss at iteration 1210 : 0.009744355455040932
Loss at iteration 1220 : 0.011393828317523003
Loss at iteration 1230 : 0.007607811130583286
Loss at iteration 1240 : 0.006300616078078747
Loss at iteration 1250 : 0.0038319858722388744
Loss at iteration 1260 : 0.005545299034565687
Loss at iteration 1270 : 0.009287279099225998
Loss at iteration 1280 : 0.0069656698033213615
Loss at iteration 1290 : 0.007514025550335646
Loss at iteration 1300 : 0.013734877109527588
Loss at iteration 1310 : 0.010109043680131435
Loss at iteration 1320 : 0.0059811207465827465
Loss at iteration 1330 : 0.018035952001810074
Loss at iteration 1340 : 0.010841228067874908
Loss at iteration 1350 : 0.009625725448131561
Loss at iteration 1360 : 0.007181944325566292
Loss at iteration 1370 : 0.007853617891669273
Loss at iteration 1380 : 0.013048039749264717
Loss at iteration 1390 : 0.012963008135557175
Loss at iteration 1400 : 0.00877083744853735
Loss at iteration 1410 : 0.0064886994659900665
Loss at iteration 1420 : 0.009088108316063881
Loss at iteration 1430 : 0.012006059288978577
Loss at iteration 1440 : 0.012492485344409943
Loss at iteration 1450 : 0.007730488665401936
Loss at iteration 1460 : 0.008949777111411095
Loss at iteration 1470 : 0.008731965906918049
Loss at iteration 1480 : 0.008095022290945053
Loss at iteration 1490 : 0.004034345969557762
Loss at iteration 1500 : 0.009818527847528458
Loss at iteration 1510 : 0.005136233754456043
Loss at iteration 1520 : 0.009284544736146927
Loss at iteration 1530 : 0.003539229277521372
Loss at iteration 1540 : 0.008320452645421028
Loss at iteration 1550 : 0.0054165334440767765
Loss at iteration 1560 : 0.004136186093091965
Loss at iteration 1570 : 0.008543875068426132
Loss at iteration 1580 : 0.007914524525403976
Loss at iteration 1590 : 0.004067426547408104
Loss at iteration 1600 : 0.007064967416226864
Loss at iteration 1610 : 0.009335462935268879
Loss at iteration 1620 : 0.009823170490562916
Loss at iteration 1630 : 0.004088163375854492
Loss at iteration 1640 : 0.011891058646142483
Loss at iteration 1650 : 0.014438697136938572
Loss at iteration 1660 : 0.01511501707136631
Loss at iteration 1670 : 0.011279717087745667
Loss at iteration 1680 : 0.008615726605057716
Loss at iteration 1690 : 0.006809095852077007
Loss at iteration 1700 : 0.010925239883363247
Loss at iteration 1710 : 0.007167906500399113
Loss at iteration 1720 : 0.013330243527889252
Loss at iteration 1730 : 0.006525082513689995
Loss at iteration 1740 : 0.010937176644802094
Loss at iteration 1750 : 0.009916730225086212
Loss at iteration 1760 : 0.013070760294795036
Loss at iteration 1770 : 0.014982499182224274
Loss at iteration 1780 : 0.011694580316543579
Loss at iteration 1790 : 0.014967858791351318
Loss at iteration 1800 : 0.008646351285278797
Loss at iteration 1810 : 0.011030282825231552
Loss at iteration 1820 : 0.0090881222859025
Loss at iteration 1830 : 0.024366959929466248
Loss at iteration 1840 : 0.013151861727237701
Loss at iteration 1850 : 0.014938895590603352
Loss at iteration 1860 : 0.009576909244060516
Loss at iteration 1870 : 0.007155274040997028
Loss at iteration 1880 : 0.011636827141046524
Loss at iteration 1890 : 0.004800805822014809
Loss at iteration 1900 : 0.009706763550639153
Loss at iteration 1910 : 0.015341076999902725
Loss at iteration 1920 : 0.00622373353689909
Loss at iteration 1930 : 0.023943625390529633
Loss at iteration 1940 : 0.005389093421399593
Loss at iteration 1950 : 0.012802367098629475
Loss at iteration 1960 : 0.005471105687320232
Loss at iteration 1970 : 0.008433383889496326
Loss at iteration 1980 : 0.003956043627113104
Loss at iteration 1990 : 0.016745124012231827
Loss at iteration 2000 : 0.007313068024814129
Loss at iteration 2010 : 0.01229138858616352
Loss at iteration 2020 : 0.00757339783012867
Loss at iteration 2030 : 0.011157150380313396
Loss at iteration 2040 : 0.009544073604047298
Loss at iteration 2050 : 0.020131777971982956
Loss at iteration 2060 : 0.007973043248057365
Loss at iteration 2070 : 0.004747043363749981
Loss at iteration 2080 : 0.004146869760006666
Loss at iteration 2090 : 0.011637585237622261
Loss at iteration 2100 : 0.011478256434202194
Loss at iteration 2110 : 0.010610039345920086
Loss at iteration 2120 : 0.008017264306545258
Loss at iteration 2130 : 0.028014175593852997
Loss at iteration 2140 : 0.011715956963598728
Loss at iteration 2150 : 0.015786277130246162
Loss at iteration 2160 : 0.01005549542605877
Loss at iteration 2170 : 0.003939429298043251
Loss at iteration 2180 : 0.019130321219563484
Loss at iteration 2190 : 0.010907558724284172
Loss at iteration 2200 : 0.006690002977848053
Loss at iteration 2210 : 0.004523861687630415
Loss at iteration 2220 : 0.006453788373619318
Loss at iteration 2230 : 0.011271227151155472
Loss at iteration 2240 : 0.007970636710524559
Loss at iteration 2250 : 0.011517362669110298
Loss at iteration 2260 : 0.011811376549303532
Loss at iteration 2270 : 0.009769785217940807
Loss at iteration 2280 : 0.006364783272147179
Loss at iteration 2290 : 0.007124396972358227
Loss at iteration 2300 : 0.008385471999645233
Loss at iteration 2310 : 0.013201450929045677
Loss at iteration 2320 : 0.015074668452143669
Loss at iteration 2330 : 0.0035341563634574413
Loss at iteration 2340 : 0.00546250119805336
Loss at iteration 2350 : 0.008924616500735283
Loss at iteration 2360 : 0.003358871676027775
Loss at iteration 2370 : 0.0061719538643956184
Loss at iteration 2380 : 0.012557941488921642
Loss at iteration 2390 : 0.014581353403627872
Loss at iteration 2400 : 0.01293644867837429
Loss at iteration 2410 : 0.004915967117995024
Loss at iteration 2420 : 0.008468572981655598
The SSIM Value is: 0.8485332091649374
The PSNR Value is: 22.116867701212566
the epoch is: 77
Loss at iteration 10 : 0.011111661791801453
Loss at iteration 20 : 0.018545404076576233
Loss at iteration 30 : 0.012442171573638916
Loss at iteration 40 : 0.00954347476363182
Loss at iteration 50 : 0.007925726473331451
Loss at iteration 60 : 0.008800236508250237
Loss at iteration 70 : 0.007133145350962877
Loss at iteration 80 : 0.012844697572290897
Loss at iteration 90 : 0.013309231027960777
Loss at iteration 100 : 0.00820502731949091
Loss at iteration 110 : 0.01603291928768158
Loss at iteration 120 : 0.0077081299386918545
Loss at iteration 130 : 0.016122382134199142
Loss at iteration 140 : 0.008410953916609287
Loss at iteration 150 : 0.01330101303756237
Loss at iteration 160 : 0.008529217913746834
Loss at iteration 170 : 0.009197614155709743
Loss at iteration 180 : 0.006980446632951498
Loss at iteration 190 : 0.00446749571710825
Loss at iteration 200 : 0.016892116516828537
Loss at iteration 210 : 0.004635876044631004
Loss at iteration 220 : 0.007523818872869015
Loss at iteration 230 : 0.008925297297537327
Loss at iteration 240 : 0.008053427562117577
Loss at iteration 250 : 0.010987784713506699
Loss at iteration 260 : 0.00850051362067461
Loss at iteration 270 : 0.013937316834926605
Loss at iteration 280 : 0.008159976452589035
Loss at iteration 290 : 0.0053763012401759624
Loss at iteration 300 : 0.006726151332259178
Loss at iteration 310 : 0.0034179622307419777
Loss at iteration 320 : 0.009332705289125443
Loss at iteration 330 : 0.00694894976913929
Loss at iteration 340 : 0.005646375473588705
Loss at iteration 350 : 0.002693593269214034
Loss at iteration 360 : 0.0050011854618787766
Loss at iteration 370 : 0.01077499333769083
Loss at iteration 380 : 0.006308284588158131
Loss at iteration 390 : 0.0024873274378478527
Loss at iteration 400 : 0.012916235253214836
Loss at iteration 410 : 0.015994340181350708
Loss at iteration 420 : 0.010167345404624939
Loss at iteration 430 : 0.01610303297638893
Loss at iteration 440 : 0.004029264207929373
Loss at iteration 450 : 0.0146230049431324
Loss at iteration 460 : 0.006990522146224976
Loss at iteration 470 : 0.0043274639174342155
Loss at iteration 480 : 0.00975821539759636
Loss at iteration 490 : 0.008431518450379372
Loss at iteration 500 : 0.009526824578642845
Loss at iteration 510 : 0.005069327540695667
Loss at iteration 520 : 0.01277467142790556
Loss at iteration 530 : 0.005861357785761356
Loss at iteration 540 : 0.008819444105029106
Loss at iteration 550 : 0.005435388535261154
Loss at iteration 560 : 0.012206004932522774
Loss at iteration 570 : 0.008859097957611084
Loss at iteration 580 : 0.010368036106228828
Loss at iteration 590 : 0.01118758600205183
Loss at iteration 600 : 0.004411063157021999
Loss at iteration 610 : 0.0063089607283473015
Loss at iteration 620 : 0.008050231263041496
Loss at iteration 630 : 0.007945997640490532
Loss at iteration 640 : 0.005798786878585815
Loss at iteration 650 : 0.006302857771515846
Loss at iteration 660 : 0.008709396235644817
Loss at iteration 670 : 0.0037121702916920185
Loss at iteration 680 : 0.013475432991981506
Loss at iteration 690 : 0.009714173153042793
Loss at iteration 700 : 0.008103501982986927
Loss at iteration 710 : 0.002891247160732746
Loss at iteration 720 : 0.010125872679054737
Loss at iteration 730 : 0.011039608158171177
Loss at iteration 740 : 0.01443223562091589
Loss at iteration 750 : 0.018792517483234406
Loss at iteration 760 : 0.004267792217433453
Loss at iteration 770 : 0.003993236925452948
Loss at iteration 780 : 0.004748516250401735
Loss at iteration 790 : 0.009254674427211285
Loss at iteration 800 : 0.0066356114111840725
Loss at iteration 810 : 0.011230090633034706
Loss at iteration 820 : 0.013584604486823082
Loss at iteration 830 : 0.011962649412453175
Loss at iteration 840 : 0.01161524374037981
Loss at iteration 850 : 0.004677127115428448
Loss at iteration 860 : 0.005468147806823254
Loss at iteration 870 : 0.012452839873731136
Loss at iteration 880 : 0.005733039230108261
Loss at iteration 890 : 0.008665431290864944
Loss at iteration 900 : 0.0068544442765414715
Loss at iteration 910 : 0.010733816772699356
Loss at iteration 920 : 0.01803508587181568
Loss at iteration 930 : 0.01010747067630291
Loss at iteration 940 : 0.01828175224363804
Loss at iteration 950 : 0.004328934475779533
Loss at iteration 960 : 0.0077275666408240795
Loss at iteration 970 : 0.0052110846154391766
Loss at iteration 980 : 0.009503424167633057
Loss at iteration 990 : 0.013355729170143604
Loss at iteration 1000 : 0.003415364772081375
Loss at iteration 1010 : 0.009936776012182236
Loss at iteration 1020 : 0.016603723168373108
Loss at iteration 1030 : 0.005423250142484903
Loss at iteration 1040 : 0.007899254560470581
Loss at iteration 1050 : 0.010938634164631367
Loss at iteration 1060 : 0.003221525577828288
Loss at iteration 1070 : 0.008585739880800247
Loss at iteration 1080 : 0.01295577734708786
Loss at iteration 1090 : 0.015388842672109604
Loss at iteration 1100 : 0.010309700854122639
Loss at iteration 1110 : 0.009490731172263622
Loss at iteration 1120 : 0.006377512589097023
Loss at iteration 1130 : 0.011275336146354675
Loss at iteration 1140 : 0.007731326390057802
Loss at iteration 1150 : 0.013625133782625198
Loss at iteration 1160 : 0.0040502650663256645
Loss at iteration 1170 : 0.011289450339972973
Loss at iteration 1180 : 0.006535666063427925
Loss at iteration 1190 : 0.005410041194409132
Loss at iteration 1200 : 0.011131291277706623
Loss at iteration 1210 : 0.011126041412353516
Loss at iteration 1220 : 0.006439938209950924
Loss at iteration 1230 : 0.011651515029370785
Loss at iteration 1240 : 0.011386950500309467
Loss at iteration 1250 : 0.00421417411416769
Loss at iteration 1260 : 0.012046556919813156
Loss at iteration 1270 : 0.02702372893691063
Loss at iteration 1280 : 0.004162467084825039
Loss at iteration 1290 : 0.016360029578208923
Loss at iteration 1300 : 0.005931598600000143
Loss at iteration 1310 : 0.009167857468128204
Loss at iteration 1320 : 0.024096129462122917
Loss at iteration 1330 : 0.007516506128013134
Loss at iteration 1340 : 0.008192203007638454
Loss at iteration 1350 : 0.007625054568052292
Loss at iteration 1360 : 0.006871852558106184
Loss at iteration 1370 : 0.011518076062202454
Loss at iteration 1380 : 0.0035507555585354567
Loss at iteration 1390 : 0.012139293365180492
Loss at iteration 1400 : 0.01567552238702774
Loss at iteration 1410 : 0.008372362703084946
Loss at iteration 1420 : 0.01225760206580162
Loss at iteration 1430 : 0.005277564283460379
Loss at iteration 1440 : 0.006546477787196636
Loss at iteration 1450 : 0.007927069440484047
Loss at iteration 1460 : 0.008216757327318192
Loss at iteration 1470 : 0.009237421676516533
Loss at iteration 1480 : 0.008636095561087132
Loss at iteration 1490 : 0.006114952266216278
Loss at iteration 1500 : 0.01161118783056736
Loss at iteration 1510 : 0.0058842608705163
Loss at iteration 1520 : 0.010694164782762527
Loss at iteration 1530 : 0.00203436310403049
Loss at iteration 1540 : 0.008475777693092823
Loss at iteration 1550 : 0.010910292156040668
Loss at iteration 1560 : 0.007303604856133461
Loss at iteration 1570 : 0.004891449119895697
Loss at iteration 1580 : 0.01781936176121235
Loss at iteration 1590 : 0.014977888204157352
Loss at iteration 1600 : 0.006346362177282572
Loss at iteration 1610 : 0.005784826353192329
Loss at iteration 1620 : 0.011186279356479645
Loss at iteration 1630 : 0.007157270796597004
Loss at iteration 1640 : 0.014642765745520592
Loss at iteration 1650 : 0.008388262242078781
Loss at iteration 1660 : 0.006248705089092255
Loss at iteration 1670 : 0.0068672457709908485
Loss at iteration 1680 : 0.013967243954539299
Loss at iteration 1690 : 0.011292656883597374
Loss at iteration 1700 : 0.027974611148238182
Loss at iteration 1710 : 0.015919849276542664
Loss at iteration 1720 : 0.023962100967764854
Loss at iteration 1730 : 0.014173615723848343
Loss at iteration 1740 : 0.006307446863502264
Loss at iteration 1750 : 0.01468566246330738
Loss at iteration 1760 : 0.006074362900108099
Loss at iteration 1770 : 0.004719529766589403
Loss at iteration 1780 : 0.004837429616600275
Loss at iteration 1790 : 0.006635740865021944
Loss at iteration 1800 : 0.009166069328784943
Loss at iteration 1810 : 0.007865453138947487
Loss at iteration 1820 : 0.005229758098721504
Loss at iteration 1830 : 0.006239786744117737
Loss at iteration 1840 : 0.0055556753650307655
Loss at iteration 1850 : 0.01133174542337656
Loss at iteration 1860 : 0.004273673519492149
Loss at iteration 1870 : 0.006042024120688438
Loss at iteration 1880 : 0.007434007711708546
Loss at iteration 1890 : 0.006567119620740414
Loss at iteration 1900 : 0.01231988612562418
Loss at iteration 1910 : 0.013699818402528763
Loss at iteration 1920 : 0.009967685677111149
Loss at iteration 1930 : 0.011192990466952324
Loss at iteration 1940 : 0.005926703102886677
Loss at iteration 1950 : 0.01520842220634222
Loss at iteration 1960 : 0.006989830639213324
Loss at iteration 1970 : 0.009625489823520184
Loss at iteration 1980 : 0.01585492491722107
Loss at iteration 1990 : 0.012055210769176483
Loss at iteration 2000 : 0.010941443964838982
Loss at iteration 2010 : 0.004769397899508476
Loss at iteration 2020 : 0.01042863354086876
Loss at iteration 2030 : 0.01144360564649105
Loss at iteration 2040 : 0.002598782069981098
Loss at iteration 2050 : 0.010285220108926296
Loss at iteration 2060 : 0.00439228443428874
Loss at iteration 2070 : 0.022769439965486526
Loss at iteration 2080 : 0.009701760485768318
Loss at iteration 2090 : 0.010491360910236835
Loss at iteration 2100 : 0.01182534173130989
Loss at iteration 2110 : 0.003906858153641224
Loss at iteration 2120 : 0.013649370521306992
Loss at iteration 2130 : 0.007840362377464771
Loss at iteration 2140 : 0.014121678657829762
Loss at iteration 2150 : 0.021040543913841248
Loss at iteration 2160 : 0.007375136949121952
Loss at iteration 2170 : 0.016209600493311882
Loss at iteration 2180 : 0.005648987367749214
Loss at iteration 2190 : 0.024939045310020447
Loss at iteration 2200 : 0.0069971755146980286
Loss at iteration 2210 : 0.009660552255809307
Loss at iteration 2220 : 0.015140118077397346
Loss at iteration 2230 : 0.005472736898809671
Loss at iteration 2240 : 0.012136293575167656
Loss at iteration 2250 : 0.00542158167809248
Loss at iteration 2260 : 0.01737966574728489
Loss at iteration 2270 : 0.015842841938138008
Loss at iteration 2280 : 0.00758872926235199
Loss at iteration 2290 : 0.0066385576501488686
Loss at iteration 2300 : 0.006422913633286953
Loss at iteration 2310 : 0.009356841444969177
Loss at iteration 2320 : 0.003131976816803217
Loss at iteration 2330 : 0.006065944209694862
Loss at iteration 2340 : 0.009075664915144444
Loss at iteration 2350 : 0.007494802586734295
Loss at iteration 2360 : 0.00749982800334692
Loss at iteration 2370 : 0.008457801304757595
Loss at iteration 2380 : 0.005727706477046013
Loss at iteration 2390 : 0.007805728819221258
Loss at iteration 2400 : 0.007237663492560387
Loss at iteration 2410 : 0.006200823467224836
Loss at iteration 2420 : 0.005105466581881046
The SSIM Value is: 0.844625727335612
The PSNR Value is: 21.803672091166177
the epoch is: 78
Loss at iteration 10 : 0.0052240826189517975
Loss at iteration 20 : 0.005951059050858021
Loss at iteration 30 : 0.015086055733263493
Loss at iteration 40 : 0.013472383841872215
Loss at iteration 50 : 0.01580619253218174
Loss at iteration 60 : 0.017053117975592613
Loss at iteration 70 : 0.008016307838261127
Loss at iteration 80 : 0.013314242474734783
Loss at iteration 90 : 0.014379605650901794
Loss at iteration 100 : 0.013847368769347668
Loss at iteration 110 : 0.010570071637630463
Loss at iteration 120 : 0.011633563786745071
Loss at iteration 130 : 0.0081885801628232
Loss at iteration 140 : 0.007818272337317467
Loss at iteration 150 : 0.010794021189212799
Loss at iteration 160 : 0.006312231067568064
Loss at iteration 170 : 0.007141249254345894
Loss at iteration 180 : 0.005649595987051725
Loss at iteration 190 : 0.005912673193961382
Loss at iteration 200 : 0.008631879463791847
Loss at iteration 210 : 0.006498024798929691
Loss at iteration 220 : 0.004666475113481283
Loss at iteration 230 : 0.01160707138478756
Loss at iteration 240 : 0.004616443067789078
Loss at iteration 250 : 0.011630132794380188
Loss at iteration 260 : 0.022477325052022934
Loss at iteration 270 : 0.01210076455026865
Loss at iteration 280 : 0.019860608503222466
Loss at iteration 290 : 0.006078882142901421
Loss at iteration 300 : 0.014663571491837502
Loss at iteration 310 : 0.007978669367730618
Loss at iteration 320 : 0.003382529830560088
Loss at iteration 330 : 0.012249035760760307
Loss at iteration 340 : 0.004700765013694763
Loss at iteration 350 : 0.02076532132923603
Loss at iteration 360 : 0.008429777808487415
Loss at iteration 370 : 0.012284313328564167
Loss at iteration 380 : 0.008336961269378662
Loss at iteration 390 : 0.01914137788116932
Loss at iteration 400 : 0.019086895510554314
Loss at iteration 410 : 0.003499658079817891
Loss at iteration 420 : 0.01084660179913044
Loss at iteration 430 : 0.013811160810291767
Loss at iteration 440 : 0.003308862214908004
Loss at iteration 450 : 0.013340570032596588
Loss at iteration 460 : 0.012867767363786697
Loss at iteration 470 : 0.006522647105157375
Loss at iteration 480 : 0.016950145363807678
Loss at iteration 490 : 0.02206552028656006
Loss at iteration 500 : 0.008130461908876896
Loss at iteration 510 : 0.013120260089635849
Loss at iteration 520 : 0.017141006886959076
Loss at iteration 530 : 0.010853314772248268
Loss at iteration 540 : 0.024222400039434433
Loss at iteration 550 : 0.014437125995755196
Loss at iteration 560 : 0.011431707069277763
Loss at iteration 570 : 0.010118568316102028
Loss at iteration 580 : 0.004887360613793135
Loss at iteration 590 : 0.006991216912865639
Loss at iteration 600 : 0.007694055791944265
Loss at iteration 610 : 0.009054279886186123
Loss at iteration 620 : 0.008199114352464676
Loss at iteration 630 : 0.005424897652119398
Loss at iteration 640 : 0.008162721060216427
Loss at iteration 650 : 0.010477389208972454
Loss at iteration 660 : 0.005359979812055826
Loss at iteration 670 : 0.009748328477144241
Loss at iteration 680 : 0.005019947420805693
Loss at iteration 690 : 0.00989910215139389
Loss at iteration 700 : 0.014465847983956337
Loss at iteration 710 : 0.012141427956521511
Loss at iteration 720 : 0.017588667571544647
Loss at iteration 730 : 0.01065463200211525
Loss at iteration 740 : 0.009358723647892475
Loss at iteration 750 : 0.005846652202308178
Loss at iteration 760 : 0.006904615089297295
Loss at iteration 770 : 0.01655774563550949
Loss at iteration 780 : 0.006055899430066347
Loss at iteration 790 : 0.009729653596878052
Loss at iteration 800 : 0.014776944182813168
Loss at iteration 810 : 0.003491116687655449
Loss at iteration 820 : 0.01114486064761877
Loss at iteration 830 : 0.010577591136097908
Loss at iteration 840 : 0.003095603082329035
Loss at iteration 850 : 0.007966564036905766
Loss at iteration 860 : 0.011494097299873829
Loss at iteration 870 : 0.004733093548566103
Loss at iteration 880 : 0.005488715134561062
Loss at iteration 890 : 0.009586650878190994
Loss at iteration 900 : 0.006695175543427467
Loss at iteration 910 : 0.023542972281575203
Loss at iteration 920 : 0.010873019695281982
Loss at iteration 930 : 0.003914922010153532
Loss at iteration 940 : 0.01005093939602375
Loss at iteration 950 : 0.0075227259658277035
Loss at iteration 960 : 0.015298396348953247
Loss at iteration 970 : 0.02126566506922245
Loss at iteration 980 : 0.0051531135104596615
Loss at iteration 990 : 0.01972408965229988
Loss at iteration 1000 : 0.006672295741736889
Loss at iteration 1010 : 0.008055485785007477
Loss at iteration 1020 : 0.011223647743463516
Loss at iteration 1030 : 0.004844370763748884
Loss at iteration 1040 : 0.010179479606449604
Loss at iteration 1050 : 0.006344766356050968
Loss at iteration 1060 : 0.009221932850778103
Loss at iteration 1070 : 0.00861392728984356
Loss at iteration 1080 : 0.008679287508130074
Loss at iteration 1090 : 0.005832944996654987
Loss at iteration 1100 : 0.0074419681914150715
Loss at iteration 1110 : 0.009456613101065159
Loss at iteration 1120 : 0.008653277531266212
Loss at iteration 1130 : 0.01184849627315998
Loss at iteration 1140 : 0.005901772528886795
Loss at iteration 1150 : 0.006304299924522638
Loss at iteration 1160 : 0.010115187615156174
Loss at iteration 1170 : 0.004962867125868797
Loss at iteration 1180 : 0.015025143511593342
Loss at iteration 1190 : 0.007206169422715902
Loss at iteration 1200 : 0.010014371946454048
Loss at iteration 1210 : 0.00713943550363183
Loss at iteration 1220 : 0.01877313107252121
Loss at iteration 1230 : 0.008934461511671543
Loss at iteration 1240 : 0.013473989441990852
Loss at iteration 1250 : 0.002628654008731246
Loss at iteration 1260 : 0.0036030057817697525
Loss at iteration 1270 : 0.018793508410453796
Loss at iteration 1280 : 0.01653612218797207
Loss at iteration 1290 : 0.004785266704857349
Loss at iteration 1300 : 0.004204896744340658
Loss at iteration 1310 : 0.00444782292470336
Loss at iteration 1320 : 0.007258826866745949
Loss at iteration 1330 : 0.009606106206774712
Loss at iteration 1340 : 0.007278485223650932
Loss at iteration 1350 : 0.004887912422418594
Loss at iteration 1360 : 0.007699477020651102
Loss at iteration 1370 : 0.008382147178053856
Loss at iteration 1380 : 0.003957466688007116
Loss at iteration 1390 : 0.008650039322674274
Loss at iteration 1400 : 0.0052451808005571365
Loss at iteration 1410 : 0.01739327237010002
Loss at iteration 1420 : 0.00410714466124773
Loss at iteration 1430 : 0.008770698681473732
Loss at iteration 1440 : 0.004336040932685137
Loss at iteration 1450 : 0.010260840877890587
Loss at iteration 1460 : 0.007039912045001984
Loss at iteration 1470 : 0.009067892096936703
Loss at iteration 1480 : 0.009561638347804546
Loss at iteration 1490 : 0.026695240288972855
Loss at iteration 1500 : 0.007194369565695524
Loss at iteration 1510 : 0.004490284714847803
Loss at iteration 1520 : 0.008463244885206223
Loss at iteration 1530 : 0.004226944409310818
Loss at iteration 1540 : 0.008701179176568985
Loss at iteration 1550 : 0.009902426041662693
Loss at iteration 1560 : 0.010803543031215668
Loss at iteration 1570 : 0.011065633036196232
Loss at iteration 1580 : 0.005397087894380093
Loss at iteration 1590 : 0.00946970283985138
Loss at iteration 1600 : 0.009009983390569687
Loss at iteration 1610 : 0.010165495797991753
Loss at iteration 1620 : 0.004758692812174559
Loss at iteration 1630 : 0.005375340580940247
Loss at iteration 1640 : 0.015496274456381798
Loss at iteration 1650 : 0.005794679746031761
Loss at iteration 1660 : 0.01607261225581169
Loss at iteration 1670 : 0.009686059318482876
Loss at iteration 1680 : 0.01506764255464077
Loss at iteration 1690 : 0.013735968619585037
Loss at iteration 1700 : 0.007240442559123039
Loss at iteration 1710 : 0.004534028470516205
Loss at iteration 1720 : 0.012518197298049927
Loss at iteration 1730 : 0.003626648336648941
Loss at iteration 1740 : 0.009781145490705967
Loss at iteration 1750 : 0.009555996395647526
Loss at iteration 1760 : 0.02082536369562149
Loss at iteration 1770 : 0.01623883843421936
Loss at iteration 1780 : 0.024994665756821632
Loss at iteration 1790 : 0.0056791407987475395
Loss at iteration 1800 : 0.013573741540312767
Loss at iteration 1810 : 0.00952452328056097
Loss at iteration 1820 : 0.011870153248310089
Loss at iteration 1830 : 0.010607462376356125
Loss at iteration 1840 : 0.014551297761499882
Loss at iteration 1850 : 0.010925092734396458
Loss at iteration 1860 : 0.004839175846427679
Loss at iteration 1870 : 0.008496833965182304
Loss at iteration 1880 : 0.010509468615055084
Loss at iteration 1890 : 0.010373109951615334
Loss at iteration 1900 : 0.011520521715283394
Loss at iteration 1910 : 0.019684940576553345
Loss at iteration 1920 : 0.011255184188485146
Loss at iteration 1930 : 0.00712673319503665
Loss at iteration 1940 : 0.003636517096310854
Loss at iteration 1950 : 0.004969282075762749
Loss at iteration 1960 : 0.009153176099061966
Loss at iteration 1970 : 0.008215954527258873
Loss at iteration 1980 : 0.0039733294397592545
Loss at iteration 1990 : 0.013399142771959305
Loss at iteration 2000 : 0.006297220475971699
Loss at iteration 2010 : 0.016288498416543007
Loss at iteration 2020 : 0.008174922317266464
Loss at iteration 2030 : 0.004887777380645275
Loss at iteration 2040 : 0.007870898582041264
Loss at iteration 2050 : 0.009281469509005547
Loss at iteration 2060 : 0.007571715861558914
Loss at iteration 2070 : 0.014763915911316872
Loss at iteration 2080 : 0.013706071302294731
Loss at iteration 2090 : 0.0027801000978797674
Loss at iteration 2100 : 0.010847067460417747
Loss at iteration 2110 : 0.012582523748278618
Loss at iteration 2120 : 0.008452272973954678
Loss at iteration 2130 : 0.008171070367097855
Loss at iteration 2140 : 0.016301780939102173
Loss at iteration 2150 : 0.010143176652491093
Loss at iteration 2160 : 0.009304300881922245
Loss at iteration 2170 : 0.010311027988791466
Loss at iteration 2180 : 0.008605683222413063
Loss at iteration 2190 : 0.005125851836055517
Loss at iteration 2200 : 0.017450133338570595
Loss at iteration 2210 : 0.015169438906013966
Loss at iteration 2220 : 0.0044363681226968765
Loss at iteration 2230 : 0.012008457444608212
Loss at iteration 2240 : 0.008038843050599098
Loss at iteration 2250 : 0.011712554842233658
Loss at iteration 2260 : 0.011708268895745277
Loss at iteration 2270 : 0.014053668826818466
Loss at iteration 2280 : 0.005214891862124205
Loss at iteration 2290 : 0.005240517668426037
Loss at iteration 2300 : 0.008030163124203682
Loss at iteration 2310 : 0.007759318687021732
Loss at iteration 2320 : 0.012981371022760868
Loss at iteration 2330 : 0.008264253847301006
Loss at iteration 2340 : 0.012332207523286343
Loss at iteration 2350 : 0.013671472668647766
Loss at iteration 2360 : 0.009234104305505753
Loss at iteration 2370 : 0.008575962856411934
Loss at iteration 2380 : 0.010592152364552021
Loss at iteration 2390 : 0.00446012057363987
Loss at iteration 2400 : 0.0050396122969686985
Loss at iteration 2410 : 0.01385403424501419
Loss at iteration 2420 : 0.014448827132582664
The SSIM Value is: 0.8452284773190816
The PSNR Value is: 22.554846382141115
the epoch is: 79
Loss at iteration 10 : 0.006577363703399897
Loss at iteration 20 : 0.008743194863200188
Loss at iteration 30 : 0.017380373552441597
Loss at iteration 40 : 0.00446429755538702
Loss at iteration 50 : 0.010450114496052265
Loss at iteration 60 : 0.010100951418280602
Loss at iteration 70 : 0.015242526307702065
Loss at iteration 80 : 0.018965527415275574
Loss at iteration 90 : 0.030297281220555305
Loss at iteration 100 : 0.012633385136723518
Loss at iteration 110 : 0.01209068764001131
Loss at iteration 120 : 0.01045636273920536
Loss at iteration 130 : 0.009802494198083878
Loss at iteration 140 : 0.009021153673529625
Loss at iteration 150 : 0.012096849270164967
Loss at iteration 160 : 0.004956216551363468
Loss at iteration 170 : 0.007533823139965534
Loss at iteration 180 : 0.011356423608958721
Loss at iteration 190 : 0.012401480227708817
Loss at iteration 200 : 0.00908934697508812
Loss at iteration 210 : 0.015242831781506538
Loss at iteration 220 : 0.007171359844505787
Loss at iteration 230 : 0.005865315906703472
Loss at iteration 240 : 0.005781055428087711
Loss at iteration 250 : 0.007142074406147003
Loss at iteration 260 : 0.009579470381140709
Loss at iteration 270 : 0.00811830349266529
Loss at iteration 280 : 0.005286882631480694
Loss at iteration 290 : 0.011969311162829399
Loss at iteration 300 : 0.009022179991006851
Loss at iteration 310 : 0.007906176149845123
Loss at iteration 320 : 0.012445556931197643
Loss at iteration 330 : 0.00699276477098465
Loss at iteration 340 : 0.011001895181834698
Loss at iteration 350 : 0.004783344455063343
Loss at iteration 360 : 0.004136822186410427
Loss at iteration 370 : 0.006445684935897589
Loss at iteration 380 : 0.01375151053071022
Loss at iteration 390 : 0.017770718783140182
Loss at iteration 400 : 0.00562297971919179
Loss at iteration 410 : 0.004190066829323769
Loss at iteration 420 : 0.0072798822075128555
Loss at iteration 430 : 0.007990007288753986
Loss at iteration 440 : 0.013930992223322392
Loss at iteration 450 : 0.014167116954922676
Loss at iteration 460 : 0.004809429403394461
Loss at iteration 470 : 0.008899682201445103
Loss at iteration 480 : 0.005860916338860989
Loss at iteration 490 : 0.006769839208573103
Loss at iteration 500 : 0.008004837669432163
Loss at iteration 510 : 0.005494050681591034
Loss at iteration 520 : 0.009176209568977356
Loss at iteration 530 : 0.009839007630944252
Loss at iteration 540 : 0.00979688297957182
Loss at iteration 550 : 0.011331171728670597
Loss at iteration 560 : 0.006700099911540747
Loss at iteration 570 : 0.016037873923778534
Loss at iteration 580 : 0.005168952979147434
Loss at iteration 590 : 0.00623969454318285
Loss at iteration 600 : 0.0034685053396970034
Loss at iteration 610 : 0.004232550971210003
Loss at iteration 620 : 0.006146276369690895
Loss at iteration 630 : 0.00743823079392314
Loss at iteration 640 : 0.011414873413741589
Loss at iteration 650 : 0.007415488362312317
Loss at iteration 660 : 0.01188279315829277
Loss at iteration 670 : 0.006209269631654024
Loss at iteration 680 : 0.016042692586779594
Loss at iteration 690 : 0.00818220991641283
Loss at iteration 700 : 0.019758082926273346
Loss at iteration 710 : 0.007159276865422726
Loss at iteration 720 : 0.007331633009016514
Loss at iteration 730 : 0.008991203270852566
Loss at iteration 740 : 0.008428018540143967
Loss at iteration 750 : 0.00963861308991909
Loss at iteration 760 : 0.007096277084201574
Loss at iteration 770 : 0.00855786632746458
Loss at iteration 780 : 0.0070791528560221195
Loss at iteration 790 : 0.009929963387548923
Loss at iteration 800 : 0.023463275283575058
Loss at iteration 810 : 0.01036965474486351
Loss at iteration 820 : 0.008734550327062607
Loss at iteration 830 : 0.008052607998251915
Loss at iteration 840 : 0.005787370260804892
Loss at iteration 850 : 0.0064437370747327805
Loss at iteration 860 : 0.01171180885285139
Loss at iteration 870 : 0.005783279426395893
Loss at iteration 880 : 0.014889834448695183
Loss at iteration 890 : 0.008709430694580078
Loss at iteration 900 : 0.016206752508878708
Loss at iteration 910 : 0.019598934799432755
Loss at iteration 920 : 0.011397064663469791
Loss at iteration 930 : 0.009903804399073124
Loss at iteration 940 : 0.011372924782335758
Loss at iteration 950 : 0.015366842970252037
Loss at iteration 960 : 0.00932088028639555
Loss at iteration 970 : 0.010867467150092125
Loss at iteration 980 : 0.005688759498298168
Loss at iteration 990 : 0.013644068501889706
Loss at iteration 1000 : 0.008766835555434227
Loss at iteration 1010 : 0.012203661724925041
Loss at iteration 1020 : 0.008370621129870415
Loss at iteration 1030 : 0.007341351360082626
Loss at iteration 1040 : 0.015100756660103798
Loss at iteration 1050 : 0.01332872174680233
Loss at iteration 1060 : 0.00477855047211051
Loss at iteration 1070 : 0.00826089084148407
Loss at iteration 1080 : 0.015268899500370026
Loss at iteration 1090 : 0.010237426497042179
Loss at iteration 1100 : 0.006258198991417885
Loss at iteration 1110 : 0.007308262400329113
Loss at iteration 1120 : 0.011223919689655304
Loss at iteration 1130 : 0.006501906551420689
Loss at iteration 1140 : 0.007372536230832338
Loss at iteration 1150 : 0.0061110625974833965
Loss at iteration 1160 : 0.0064226724207401276
Loss at iteration 1170 : 0.007575628347694874
Loss at iteration 1180 : 0.006869637407362461
Loss at iteration 1190 : 0.02218674309551716
Loss at iteration 1200 : 0.013581806793808937
Loss at iteration 1210 : 0.009189581498503685
Loss at iteration 1220 : 0.007052678614854813
Loss at iteration 1230 : 0.0093320831656456
Loss at iteration 1240 : 0.0072976453229784966
Loss at iteration 1250 : 0.006733886431902647
Loss at iteration 1260 : 0.008655151352286339
Loss at iteration 1270 : 0.01666977070271969
Loss at iteration 1280 : 0.015491518191993237
Loss at iteration 1290 : 0.00823560543358326
Loss at iteration 1300 : 0.009712831117212772
Loss at iteration 1310 : 0.010745424777269363
Loss at iteration 1320 : 0.007614574395120144
Loss at iteration 1330 : 0.013386379927396774
Loss at iteration 1340 : 0.016992367804050446
Loss at iteration 1350 : 0.005008486565202475
Loss at iteration 1360 : 0.010111041367053986
Loss at iteration 1370 : 0.009255558252334595
Loss at iteration 1380 : 0.006167903542518616
Loss at iteration 1390 : 0.010516283102333546
Loss at iteration 1400 : 0.0042026774026453495
Loss at iteration 1410 : 0.008013512939214706
Loss at iteration 1420 : 0.0035964197013527155
Loss at iteration 1430 : 0.008120608516037464
Loss at iteration 1440 : 0.010255523957312107
Loss at iteration 1450 : 0.010026590898633003
Loss at iteration 1460 : 0.0038789098616689444
Loss at iteration 1470 : 0.016797251999378204
Loss at iteration 1480 : 0.0053806607611477375
Loss at iteration 1490 : 0.010471497662365437
Loss at iteration 1500 : 0.007871737703680992
Loss at iteration 1510 : 0.005620875395834446
Loss at iteration 1520 : 0.00833730399608612
Loss at iteration 1530 : 0.004683634731918573
Loss at iteration 1540 : 0.007106540724635124
Loss at iteration 1550 : 0.01414310559630394
Loss at iteration 1560 : 0.004346366506069899
Loss at iteration 1570 : 0.0072840675711631775
Loss at iteration 1580 : 0.009067252278327942
Loss at iteration 1590 : 0.019950227811932564
Loss at iteration 1600 : 0.004751091357320547
Loss at iteration 1610 : 0.006384940817952156
Loss at iteration 1620 : 0.010584220290184021
Loss at iteration 1630 : 0.014340274035930634
Loss at iteration 1640 : 0.00793173536658287
Loss at iteration 1650 : 0.010853882879018784
Loss at iteration 1660 : 0.007826598361134529
Loss at iteration 1670 : 0.008144453167915344
Loss at iteration 1680 : 0.005438219755887985
Loss at iteration 1690 : 0.011561586521565914
Loss at iteration 1700 : 0.009611401706933975
Loss at iteration 1710 : 0.00912498403340578
Loss at iteration 1720 : 0.010082637891173363
Loss at iteration 1730 : 0.009576933458447456
Loss at iteration 1740 : 0.014380678534507751
Loss at iteration 1750 : 0.006495627574622631
Loss at iteration 1760 : 0.00866822712123394
Loss at iteration 1770 : 0.005645382683724165
Loss at iteration 1780 : 0.009366361424326897
Loss at iteration 1790 : 0.005555560812354088
Loss at iteration 1800 : 0.004081602208316326
Loss at iteration 1810 : 0.005541339050978422
Loss at iteration 1820 : 0.021089091897010803
Loss at iteration 1830 : 0.005521375685930252
Loss at iteration 1840 : 0.007398937828838825
Loss at iteration 1850 : 0.03940814733505249
Loss at iteration 1860 : 0.009459740482270718
Loss at iteration 1870 : 0.008943953551352024
Loss at iteration 1880 : 0.0033490490168333054
Loss at iteration 1890 : 0.022722123190760612
Loss at iteration 1900 : 0.002364205662161112
Loss at iteration 1910 : 0.016508877277374268
Loss at iteration 1920 : 0.00933847390115261
Loss at iteration 1930 : 0.006657415069639683
Loss at iteration 1940 : 0.01086726225912571
Loss at iteration 1950 : 0.01060051191598177
Loss at iteration 1960 : 0.009827210567891598
Loss at iteration 1970 : 0.01266659889370203
Loss at iteration 1980 : 0.005824248772114515
Loss at iteration 1990 : 0.013896683230996132
Loss at iteration 2000 : 0.006729677319526672
Loss at iteration 2010 : 0.03860307112336159
Loss at iteration 2020 : 0.006733791437000036
Loss at iteration 2030 : 0.006985215470194817
Loss at iteration 2040 : 0.0022600481752306223
Loss at iteration 2050 : 0.012400762178003788
Loss at iteration 2060 : 0.019314978271722794
Loss at iteration 2070 : 0.012371412478387356
Loss at iteration 2080 : 0.00679518049582839
Loss at iteration 2090 : 0.015026269480586052
Loss at iteration 2100 : 0.011982257477939129
Loss at iteration 2110 : 0.010932767763733864
Loss at iteration 2120 : 0.009948397986590862
Loss at iteration 2130 : 0.00806688517332077
Loss at iteration 2140 : 0.02300957962870598
Loss at iteration 2150 : 0.018261874094605446
Loss at iteration 2160 : 0.008640739135444164
Loss at iteration 2170 : 0.022420501336455345
Loss at iteration 2180 : 0.005070444196462631
Loss at iteration 2190 : 0.004058066289871931
Loss at iteration 2200 : 0.007900101132690907
Loss at iteration 2210 : 0.00784529559314251
Loss at iteration 2220 : 0.006367040798068047
Loss at iteration 2230 : 0.012407486326992512
Loss at iteration 2240 : 0.009528974071145058
Loss at iteration 2250 : 0.012804783880710602
Loss at iteration 2260 : 0.006584072019904852
Loss at iteration 2270 : 0.022948209196329117
Loss at iteration 2280 : 0.005020586308091879
Loss at iteration 2290 : 0.00621354253962636
Loss at iteration 2300 : 0.013971267268061638
Loss at iteration 2310 : 0.005815480370074511
Loss at iteration 2320 : 0.01056724414229393
Loss at iteration 2330 : 0.006115753203630447
Loss at iteration 2340 : 0.012028018943965435
Loss at iteration 2350 : 0.02183782495558262
Loss at iteration 2360 : 0.0123904999345541
Loss at iteration 2370 : 0.012044002301990986
Loss at iteration 2380 : 0.004268506541848183
Loss at iteration 2390 : 0.008014868944883347
Loss at iteration 2400 : 0.016054049134254456
Loss at iteration 2410 : 0.0068542929366230965
Loss at iteration 2420 : 0.01973878964781761
The SSIM Value is: 0.8422419269879658
The PSNR Value is: 22.25432408650716
the epoch is: 80
Loss at iteration 10 : 0.006879440508782864
Loss at iteration 20 : 0.012715410441160202
Loss at iteration 30 : 0.008939909748733044
Loss at iteration 40 : 0.0076779271475970745
Loss at iteration 50 : 0.014849837869405746
Loss at iteration 60 : 0.015039156191051006
Loss at iteration 70 : 0.00937754288315773
Loss at iteration 80 : 0.006681067869067192
Loss at iteration 90 : 0.003715891856700182
Loss at iteration 100 : 0.009829332120716572
Loss at iteration 110 : 0.0078054205514490604
Loss at iteration 120 : 0.009284798055887222
Loss at iteration 130 : 0.005068003199994564
Loss at iteration 140 : 0.0033978763967752457
Loss at iteration 150 : 0.010774806141853333
Loss at iteration 160 : 0.008043752983212471
Loss at iteration 170 : 0.008127013221383095
Loss at iteration 180 : 0.01384455244988203
Loss at iteration 190 : 0.0076467604376375675
Loss at iteration 200 : 0.004917356185615063
Loss at iteration 210 : 0.0029029948636889458
Loss at iteration 220 : 0.007827089168131351
Loss at iteration 230 : 0.01268763467669487
Loss at iteration 240 : 0.009350365027785301
Loss at iteration 250 : 0.014321042224764824
Loss at iteration 260 : 0.009160809218883514
Loss at iteration 270 : 0.01215280219912529
Loss at iteration 280 : 0.010997967794537544
Loss at iteration 290 : 0.013473003171384335
Loss at iteration 300 : 0.009137607179582119
Loss at iteration 310 : 0.014833609573543072
Loss at iteration 320 : 0.012490786612033844
Loss at iteration 330 : 0.007351450622081757
Loss at iteration 340 : 0.0029268749058246613
Loss at iteration 350 : 0.0065521541982889175
Loss at iteration 360 : 0.006566542200744152
Loss at iteration 370 : 0.013399582356214523
Loss at iteration 380 : 0.010902740992605686
Loss at iteration 390 : 0.010540160350501537
Loss at iteration 400 : 0.011766689829528332
Loss at iteration 410 : 0.008811360225081444
Loss at iteration 420 : 0.014944560825824738
Loss at iteration 430 : 0.007551234215497971
Loss at iteration 440 : 0.006688979454338551
Loss at iteration 450 : 0.014546952210366726
Loss at iteration 460 : 0.011298883706331253
Loss at iteration 470 : 0.00793928187340498
Loss at iteration 480 : 0.010458474978804588
Loss at iteration 490 : 0.013254116289317608
Loss at iteration 500 : 0.0069500296376645565
Loss at iteration 510 : 0.014169617556035519
Loss at iteration 520 : 0.013107807375490665
Loss at iteration 530 : 0.005107301287353039
Loss at iteration 540 : 0.013797436840832233
Loss at iteration 550 : 0.019345756620168686
Loss at iteration 560 : 0.005766644142568111
Loss at iteration 570 : 0.005410525947809219
Loss at iteration 580 : 0.012293040752410889
Loss at iteration 590 : 0.017024965956807137
Loss at iteration 600 : 0.010231995955109596
Loss at iteration 610 : 0.00865249428898096
Loss at iteration 620 : 0.004375013522803783
Loss at iteration 630 : 0.011327620595693588
Loss at iteration 640 : 0.003020872361958027
Loss at iteration 650 : 0.013387676328420639
Loss at iteration 660 : 0.008163430728018284
Loss at iteration 670 : 0.004907496273517609
Loss at iteration 680 : 0.011524292640388012
Loss at iteration 690 : 0.0030383572448045015
Loss at iteration 700 : 0.013671258464455605
Loss at iteration 710 : 0.0070948791690170765
Loss at iteration 720 : 0.00992509350180626
Loss at iteration 730 : 0.009980868548154831
Loss at iteration 740 : 0.005981056019663811
Loss at iteration 750 : 0.017672156915068626
Loss at iteration 760 : 0.0021508284844458103
Loss at iteration 770 : 0.013959522359073162
Loss at iteration 780 : 0.007208600640296936
Loss at iteration 790 : 0.013622067868709564
Loss at iteration 800 : 0.011880580335855484
Loss at iteration 810 : 0.009939453564584255
Loss at iteration 820 : 0.015465090051293373
Loss at iteration 830 : 0.0075558084063231945
Loss at iteration 840 : 0.006629315670579672
Loss at iteration 850 : 0.004795934073626995
Loss at iteration 860 : 0.00637481827288866
Loss at iteration 870 : 0.01485320832580328
Loss at iteration 880 : 0.014979153871536255
Loss at iteration 890 : 0.014767464250326157
Loss at iteration 900 : 0.005751688499003649
Loss at iteration 910 : 0.015881706029176712
Loss at iteration 920 : 0.014376324601471424
Loss at iteration 930 : 0.012524849735200405
Loss at iteration 940 : 0.004834387451410294
Loss at iteration 950 : 0.013065974228084087
Loss at iteration 960 : 0.010140451602637768
Loss at iteration 970 : 0.005633745342493057
Loss at iteration 980 : 0.01169659849256277
Loss at iteration 990 : 0.006721516139805317
Loss at iteration 1000 : 0.012402555905282497
Loss at iteration 1010 : 0.007068254519253969
Loss at iteration 1020 : 0.008993715979158878
Loss at iteration 1030 : 0.0058766016736626625
Loss at iteration 1040 : 0.009264972060918808
Loss at iteration 1050 : 0.009194417856633663
Loss at iteration 1060 : 0.005309787578880787
Loss at iteration 1070 : 0.00838755164295435
Loss at iteration 1080 : 0.01174203958362341
Loss at iteration 1090 : 0.008671652525663376
Loss at iteration 1100 : 0.009710133075714111
Loss at iteration 1110 : 0.00741778826341033
Loss at iteration 1120 : 0.01680626906454563
Loss at iteration 1130 : 0.005105277523398399
Loss at iteration 1140 : 0.007163267582654953
Loss at iteration 1150 : 0.005682154092937708
Loss at iteration 1160 : 0.007400083355605602
Loss at iteration 1170 : 0.014277081936597824
Loss at iteration 1180 : 0.009552732110023499
Loss at iteration 1190 : 0.014572972431778908
Loss at iteration 1200 : 0.017250454053282738
Loss at iteration 1210 : 0.008733419701457024
Loss at iteration 1220 : 0.005494508892297745
Loss at iteration 1230 : 0.00847778283059597
Loss at iteration 1240 : 0.00688683707267046
Loss at iteration 1250 : 0.006677012890577316
Loss at iteration 1260 : 0.008182168938219547
Loss at iteration 1270 : 0.012613062746822834
Loss at iteration 1280 : 0.008742885664105415
Loss at iteration 1290 : 0.004923016764223576
Loss at iteration 1300 : 0.011740010231733322
Loss at iteration 1310 : 0.013523516245186329
Loss at iteration 1320 : 0.013902798295021057
Loss at iteration 1330 : 0.004903945606201887
Loss at iteration 1340 : 0.00573904300108552
Loss at iteration 1350 : 0.013651788234710693
Loss at iteration 1360 : 0.008285364136099815
Loss at iteration 1370 : 0.006111937575042248
Loss at iteration 1380 : 0.00617917999625206
Loss at iteration 1390 : 0.007881416007876396
Loss at iteration 1400 : 0.006286046002060175
Loss at iteration 1410 : 0.004583397414535284
Loss at iteration 1420 : 0.002760057570412755
Loss at iteration 1430 : 0.011247562244534492
Loss at iteration 1440 : 0.007805831730365753
Loss at iteration 1450 : 0.004528464749455452
Loss at iteration 1460 : 0.011387553066015244
Loss at iteration 1470 : 0.012192608788609505
Loss at iteration 1480 : 0.008405033499002457
Loss at iteration 1490 : 0.0038859746418893337
Loss at iteration 1500 : 0.011950138956308365
Loss at iteration 1510 : 0.009393660351634026
Loss at iteration 1520 : 0.003093248698860407
Loss at iteration 1530 : 0.01618979498744011
Loss at iteration 1540 : 0.017688237130641937
Loss at iteration 1550 : 0.009016543626785278
Loss at iteration 1560 : 0.00851583294570446
Loss at iteration 1570 : 0.005967684090137482
Loss at iteration 1580 : 0.0039056986570358276
Loss at iteration 1590 : 0.005325073841959238
Loss at iteration 1600 : 0.006688928231596947
Loss at iteration 1610 : 0.019172629341483116
Loss at iteration 1620 : 0.01251827459782362
Loss at iteration 1630 : 0.016784323379397392
Loss at iteration 1640 : 0.011203616857528687
Loss at iteration 1650 : 0.01223007496446371
Loss at iteration 1660 : 0.010075780563056469
Loss at iteration 1670 : 0.005297922994941473
Loss at iteration 1680 : 0.008750755339860916
Loss at iteration 1690 : 0.012127017602324486
Loss at iteration 1700 : 0.00818964745849371
Loss at iteration 1710 : 0.0054456801153719425
Loss at iteration 1720 : 0.009907751344144344
Loss at iteration 1730 : 0.012085448950529099
Loss at iteration 1740 : 0.02007751539349556
Loss at iteration 1750 : 0.007470382377505302
Loss at iteration 1760 : 0.0034932605922222137
Loss at iteration 1770 : 0.010091898962855339
Loss at iteration 1780 : 0.008002053014934063
Loss at iteration 1790 : 0.004053633660078049
Loss at iteration 1800 : 0.005253604147583246
Loss at iteration 1810 : 0.005050995387136936
Loss at iteration 1820 : 0.005635477602481842
Loss at iteration 1830 : 0.00667533976957202
Loss at iteration 1840 : 0.005833070259541273
Loss at iteration 1850 : 0.009149260818958282
Loss at iteration 1860 : 0.004573758691549301
Loss at iteration 1870 : 0.004795806482434273
Loss at iteration 1880 : 0.014053277671337128
Loss at iteration 1890 : 0.011953011155128479
Loss at iteration 1900 : 0.00838611088693142
Loss at iteration 1910 : 0.0058281272649765015
Loss at iteration 1920 : 0.0047353412955999374
Loss at iteration 1930 : 0.007761873304843903
Loss at iteration 1940 : 0.013650819659233093
Loss at iteration 1950 : 0.004142587538808584
Loss at iteration 1960 : 0.01685904711484909
Loss at iteration 1970 : 0.013954424299299717
Loss at iteration 1980 : 0.009862054139375687
Loss at iteration 1990 : 0.007566051557660103
Loss at iteration 2000 : 0.005201818887144327
Loss at iteration 2010 : 0.006687305402010679
Loss at iteration 2020 : 0.008755852468311787
Loss at iteration 2030 : 0.00933525525033474
Loss at iteration 2040 : 0.008962268009781837
Loss at iteration 2050 : 0.01609940081834793
Loss at iteration 2060 : 0.01152007281780243
Loss at iteration 2070 : 0.007176874205470085
Loss at iteration 2080 : 0.008267139084637165
Loss at iteration 2090 : 0.01038086973130703
Loss at iteration 2100 : 0.005656752735376358
Loss at iteration 2110 : 0.0073090908117592335
Loss at iteration 2120 : 0.008030503056943417
Loss at iteration 2130 : 0.0071183559484779835
Loss at iteration 2140 : 0.007076235953718424
Loss at iteration 2150 : 0.009163090959191322
Loss at iteration 2160 : 0.013296067714691162
Loss at iteration 2170 : 0.006771643180400133
Loss at iteration 2180 : 0.006785050965845585
Loss at iteration 2190 : 0.010034790262579918
Loss at iteration 2200 : 0.005191729869693518
Loss at iteration 2210 : 0.0029876423068344593
Loss at iteration 2220 : 0.013361549004912376
Loss at iteration 2230 : 0.012323543429374695
Loss at iteration 2240 : 0.010063092224299908
Loss at iteration 2250 : 0.008399680256843567
Loss at iteration 2260 : 0.009205156937241554
Loss at iteration 2270 : 0.007951346226036549
Loss at iteration 2280 : 0.01307064387947321
Loss at iteration 2290 : 0.015371425077319145
Loss at iteration 2300 : 0.006484099198132753
Loss at iteration 2310 : 0.006892145145684481
Loss at iteration 2320 : 0.004076280165463686
Loss at iteration 2330 : 0.007836329750716686
Loss at iteration 2340 : 0.003533199429512024
Loss at iteration 2350 : 0.005854254122823477
Loss at iteration 2360 : 0.00836185459047556
Loss at iteration 2370 : 0.008792264387011528
Loss at iteration 2380 : 0.018073420971632004
Loss at iteration 2390 : 0.027427976951003075
Loss at iteration 2400 : 0.0174412839114666
Loss at iteration 2410 : 0.009514152072370052
Loss at iteration 2420 : 0.01416034996509552
The SSIM Value is: 0.8476487358411153
The PSNR Value is: 22.92371374766032
the highest SSIM value is: 22.92371374766032
the epoch is: 81
Loss at iteration 10 : 0.006436323747038841
Loss at iteration 20 : 0.014967644587159157
Loss at iteration 30 : 0.010512088425457478
Loss at iteration 40 : 0.005087458994239569
Loss at iteration 50 : 0.0036323941312730312
Loss at iteration 60 : 0.010819271206855774
Loss at iteration 70 : 0.004287685267627239
Loss at iteration 80 : 0.013189033605158329
Loss at iteration 90 : 0.01850043423473835
Loss at iteration 100 : 0.008896352723240852
Loss at iteration 110 : 0.009319519624114037
Loss at iteration 120 : 0.01806899718940258
Loss at iteration 130 : 0.005498120561242104
Loss at iteration 140 : 0.003822700586169958
Loss at iteration 150 : 0.009028585627675056
Loss at iteration 160 : 0.008603540249168873
Loss at iteration 170 : 0.008294844068586826
Loss at iteration 180 : 0.010985439643263817
Loss at iteration 190 : 0.017140062525868416
Loss at iteration 200 : 0.013060270808637142
Loss at iteration 210 : 0.007293553091585636
Loss at iteration 220 : 0.010611883364617825
Loss at iteration 230 : 0.01345639768987894
Loss at iteration 240 : 0.0083055030554533
Loss at iteration 250 : 0.003766394918784499
Loss at iteration 260 : 0.0043984814547002316
Loss at iteration 270 : 0.009970870800316334
Loss at iteration 280 : 0.007843504659831524
Loss at iteration 290 : 0.01134840864688158
Loss at iteration 300 : 0.008811949752271175
Loss at iteration 310 : 0.015646519139409065
Loss at iteration 320 : 0.01497799251228571
Loss at iteration 330 : 0.00971240270882845
Loss at iteration 340 : 0.011319317854940891
Loss at iteration 350 : 0.006560291163623333
Loss at iteration 360 : 0.012956729158759117
Loss at iteration 370 : 0.012278438545763493
Loss at iteration 380 : 0.0037489840760827065
Loss at iteration 390 : 0.01768469251692295
Loss at iteration 400 : 0.012836307287216187
Loss at iteration 410 : 0.007197282277047634
Loss at iteration 420 : 0.012429643422365189
Loss at iteration 430 : 0.008867252618074417
Loss at iteration 440 : 0.01871528849005699
Loss at iteration 450 : 0.010500244796276093
Loss at iteration 460 : 0.006157652474939823
Loss at iteration 470 : 0.006248621270060539
Loss at iteration 480 : 0.0024059622082859278
Loss at iteration 490 : 0.012564102187752724
Loss at iteration 500 : 0.00834164023399353
Loss at iteration 510 : 0.008918479084968567
Loss at iteration 520 : 0.017975587397813797
Loss at iteration 530 : 0.008753707632422447
Loss at iteration 540 : 0.012967128306627274
Loss at iteration 550 : 0.008072545751929283
Loss at iteration 560 : 0.008370175957679749
Loss at iteration 570 : 0.005849836394190788
Loss at iteration 580 : 0.008487802930176258
Loss at iteration 590 : 0.003940335474908352
Loss at iteration 600 : 0.011412778869271278
Loss at iteration 610 : 0.007707750890403986
Loss at iteration 620 : 0.011404003947973251
Loss at iteration 630 : 0.009438595734536648
Loss at iteration 640 : 0.01385767012834549
Loss at iteration 650 : 0.017331361770629883
Loss at iteration 660 : 0.00866627786308527
Loss at iteration 670 : 0.015032770112156868
Loss at iteration 680 : 0.006611693650484085
Loss at iteration 690 : 0.007879513315856457
Loss at iteration 700 : 0.012866047210991383
Loss at iteration 710 : 0.0045354897156357765
Loss at iteration 720 : 0.013052461668848991
Loss at iteration 730 : 0.014900763519108295
Loss at iteration 740 : 0.012600498273968697
Loss at iteration 750 : 0.020882844924926758
Loss at iteration 760 : 0.006128983572125435
Loss at iteration 770 : 0.009437907487154007
Loss at iteration 780 : 0.009236961603164673
Loss at iteration 790 : 0.01060773991048336
Loss at iteration 800 : 0.007913518697023392
Loss at iteration 810 : 0.0026430462021380663
Loss at iteration 820 : 0.013873172923922539
Loss at iteration 830 : 0.00531761534512043
Loss at iteration 840 : 0.005780709907412529
Loss at iteration 850 : 0.011111896485090256
Loss at iteration 860 : 0.008049610070884228
Loss at iteration 870 : 0.018357349559664726
Loss at iteration 880 : 0.008091200143098831
Loss at iteration 890 : 0.01886126771569252
Loss at iteration 900 : 0.008184700272977352
Loss at iteration 910 : 0.0077886683866381645
Loss at iteration 920 : 0.009856468997895718
Loss at iteration 930 : 0.013398613780736923
Loss at iteration 940 : 0.008739332668483257
Loss at iteration 950 : 0.012855117209255695
Loss at iteration 960 : 0.00849104579538107
Loss at iteration 970 : 0.014656930230557919
Loss at iteration 980 : 0.007899507880210876
Loss at iteration 990 : 0.007287484593689442
Loss at iteration 1000 : 0.019121583551168442
Loss at iteration 1010 : 0.008658748120069504
Loss at iteration 1020 : 0.0034918314777314663
Loss at iteration 1030 : 0.012046150863170624
Loss at iteration 1040 : 0.006978047080338001
Loss at iteration 1050 : 0.0066542597487568855
Loss at iteration 1060 : 0.006190713495016098
Loss at iteration 1070 : 0.0021505418699234724
Loss at iteration 1080 : 0.0063372510485351086
Loss at iteration 1090 : 0.007113164756447077
Loss at iteration 1100 : 0.00798287894576788
Loss at iteration 1110 : 0.011673100292682648
Loss at iteration 1120 : 0.010988237336277962
Loss at iteration 1130 : 0.011637209914624691
Loss at iteration 1140 : 0.014511472545564175
Loss at iteration 1150 : 0.004580799490213394
Loss at iteration 1160 : 0.010155860334634781
Loss at iteration 1170 : 0.011968061327934265
Loss at iteration 1180 : 0.006968979723751545
Loss at iteration 1190 : 0.01122209895402193
Loss at iteration 1200 : 0.013558341190218925
Loss at iteration 1210 : 0.01397014781832695
Loss at iteration 1220 : 0.004335327073931694
Loss at iteration 1230 : 0.016359034925699234
Loss at iteration 1240 : 0.006555469240993261
Loss at iteration 1250 : 0.008140897378325462
Loss at iteration 1260 : 0.004838245455175638
Loss at iteration 1270 : 0.004096441436558962
Loss at iteration 1280 : 0.011506379581987858
Loss at iteration 1290 : 0.0035702872555702925
Loss at iteration 1300 : 0.014860017225146294
Loss at iteration 1310 : 0.012503945268690586
Loss at iteration 1320 : 0.005225681234151125
Loss at iteration 1330 : 0.010400835424661636
Loss at iteration 1340 : 0.007829606533050537
Loss at iteration 1350 : 0.005972302518785
Loss at iteration 1360 : 0.00918775238096714
Loss at iteration 1370 : 0.008326709270477295
Loss at iteration 1380 : 0.00708925724029541
Loss at iteration 1390 : 0.012445441447198391
Loss at iteration 1400 : 0.008034983649849892
Loss at iteration 1410 : 0.012781870551407337
Loss at iteration 1420 : 0.009962232783436775
Loss at iteration 1430 : 0.007377529516816139
Loss at iteration 1440 : 0.00543390866369009
Loss at iteration 1450 : 0.0037544502411037683
Loss at iteration 1460 : 0.009605275467038155
Loss at iteration 1470 : 0.021375762298703194
Loss at iteration 1480 : 0.011131410486996174
Loss at iteration 1490 : 0.01093185506761074
Loss at iteration 1500 : 0.011730749160051346
Loss at iteration 1510 : 0.006302909925580025
Loss at iteration 1520 : 0.016716713085770607
Loss at iteration 1530 : 0.005128276534378529
Loss at iteration 1540 : 0.00934032816439867
Loss at iteration 1550 : 0.006047732196748257
Loss at iteration 1560 : 0.00299824308604002
Loss at iteration 1570 : 0.012124608270823956
Loss at iteration 1580 : 0.016565881669521332
Loss at iteration 1590 : 0.0167315024882555
Loss at iteration 1600 : 0.004419431090354919
Loss at iteration 1610 : 0.016363725066184998
Loss at iteration 1620 : 0.018189391121268272
Loss at iteration 1630 : 0.015919357538223267
Loss at iteration 1640 : 0.006169280037283897
Loss at iteration 1650 : 0.013464690186083317
Loss at iteration 1660 : 0.011103300377726555
Loss at iteration 1670 : 0.011449160985648632
Loss at iteration 1680 : 0.006504088640213013
Loss at iteration 1690 : 0.008272228762507439
Loss at iteration 1700 : 0.0029019934590905905
Loss at iteration 1710 : 0.010515322908759117
Loss at iteration 1720 : 0.01209432352334261
Loss at iteration 1730 : 0.005598218180239201
Loss at iteration 1740 : 0.010232971981167793
Loss at iteration 1750 : 0.012211926281452179
Loss at iteration 1760 : 0.008269069716334343
Loss at iteration 1770 : 0.00635087164118886
Loss at iteration 1780 : 0.005855613388121128
Loss at iteration 1790 : 0.0074233803898096085
Loss at iteration 1800 : 0.00821613147854805
Loss at iteration 1810 : 0.006427142769098282
Loss at iteration 1820 : 0.004284119699150324
Loss at iteration 1830 : 0.011408891528844833
Loss at iteration 1840 : 0.013038227334618568
Loss at iteration 1850 : 0.007835723459720612
Loss at iteration 1860 : 0.003989524208009243
Loss at iteration 1870 : 0.015481911599636078
Loss at iteration 1880 : 0.00617200555279851
Loss at iteration 1890 : 0.010167885571718216
Loss at iteration 1900 : 0.009979043155908585
Loss at iteration 1910 : 0.004891623742878437
Loss at iteration 1920 : 0.010427512228488922
Loss at iteration 1930 : 0.011490163393318653
Loss at iteration 1940 : 0.016669658944010735
Loss at iteration 1950 : 0.006298803258687258
Loss at iteration 1960 : 0.017763230949640274
Loss at iteration 1970 : 0.014752369374036789
Loss at iteration 1980 : 0.005419689696282148
Loss at iteration 1990 : 0.0074894302524626255
Loss at iteration 2000 : 0.00519805820658803
Loss at iteration 2010 : 0.0076710837893188
Loss at iteration 2020 : 0.0036934895906597376
Loss at iteration 2030 : 0.011314570903778076
Loss at iteration 2040 : 0.014948567375540733
Loss at iteration 2050 : 0.010990225709974766
Loss at iteration 2060 : 0.006424370221793652
Loss at iteration 2070 : 0.007831458002328873
Loss at iteration 2080 : 0.008703397586941719
Loss at iteration 2090 : 0.006594948936253786
Loss at iteration 2100 : 0.005810303147882223
Loss at iteration 2110 : 0.014381304383277893
Loss at iteration 2120 : 0.007777440827339888
Loss at iteration 2130 : 0.009478126652538776
Loss at iteration 2140 : 0.005477354861795902
Loss at iteration 2150 : 0.010295230895280838
Loss at iteration 2160 : 0.009593458846211433
Loss at iteration 2170 : 0.004545111674815416
Loss at iteration 2180 : 0.01270287111401558
Loss at iteration 2190 : 0.005060894414782524
Loss at iteration 2200 : 0.01070051733404398
Loss at iteration 2210 : 0.004519603215157986
Loss at iteration 2220 : 0.005583837628364563
Loss at iteration 2230 : 0.007597482297569513
Loss at iteration 2240 : 0.010353736579418182
Loss at iteration 2250 : 0.004868559073656797
Loss at iteration 2260 : 0.0023289741948246956
Loss at iteration 2270 : 0.007046147715300322
Loss at iteration 2280 : 0.009875726886093616
Loss at iteration 2290 : 0.01056094840168953
Loss at iteration 2300 : 0.005984703078866005
Loss at iteration 2310 : 0.007987037301063538
Loss at iteration 2320 : 0.007294574286788702
Loss at iteration 2330 : 0.010700253769755363
Loss at iteration 2340 : 0.014973454177379608
Loss at iteration 2350 : 0.014791124500334263
Loss at iteration 2360 : 0.008282260037958622
Loss at iteration 2370 : 0.007518438622355461
Loss at iteration 2380 : 0.005374603904783726
Loss at iteration 2390 : 0.015718810260295868
Loss at iteration 2400 : 0.0072910236194729805
Loss at iteration 2410 : 0.009256103076040745
Loss at iteration 2420 : 0.0074008433148264885
The SSIM Value is: 0.8476671576499939
The PSNR Value is: 22.74951057434082
the epoch is: 82
Loss at iteration 10 : 0.005056727211922407
Loss at iteration 20 : 0.009709469974040985
Loss at iteration 30 : 0.034681349992752075
Loss at iteration 40 : 0.007547101937234402
Loss at iteration 50 : 0.005567190237343311
Loss at iteration 60 : 0.03523235768079758
Loss at iteration 70 : 0.007058288436383009
Loss at iteration 80 : 0.00876675546169281
Loss at iteration 90 : 0.006507146172225475
Loss at iteration 100 : 0.0034094350412487984
Loss at iteration 110 : 0.0038125517312437296
Loss at iteration 120 : 0.004410712979733944
Loss at iteration 130 : 0.0065351747907698154
Loss at iteration 140 : 0.010679406113922596
Loss at iteration 150 : 0.0071175540797412395
Loss at iteration 160 : 0.010055527091026306
Loss at iteration 170 : 0.019199419766664505
Loss at iteration 180 : 0.008895584382116795
Loss at iteration 190 : 0.006135105155408382
Loss at iteration 200 : 0.006385703571140766
Loss at iteration 210 : 0.010534978471696377
Loss at iteration 220 : 0.005467503797262907
Loss at iteration 230 : 0.005750331096351147
Loss at iteration 240 : 0.006163957994431257
Loss at iteration 250 : 0.007987065240740776
Loss at iteration 260 : 0.0043083312921226025
Loss at iteration 270 : 0.009842371568083763
Loss at iteration 280 : 0.007477583363652229
Loss at iteration 290 : 0.006298476830124855
Loss at iteration 300 : 0.006425864063203335
Loss at iteration 310 : 0.0032957380171865225
Loss at iteration 320 : 0.009320901706814766
Loss at iteration 330 : 0.005083062686026096
Loss at iteration 340 : 0.006115639582276344
Loss at iteration 350 : 0.011366280727088451
Loss at iteration 360 : 0.005952674429863691
Loss at iteration 370 : 0.016857191920280457
Loss at iteration 380 : 0.011417119763791561
Loss at iteration 390 : 0.03944020718336105
Loss at iteration 400 : 0.00665284926071763
Loss at iteration 410 : 0.012170745059847832
Loss at iteration 420 : 0.0065710656344890594
Loss at iteration 430 : 0.006650393363088369
Loss at iteration 440 : 0.007357507944107056
Loss at iteration 450 : 0.007323905825614929
Loss at iteration 460 : 0.015028432011604309
Loss at iteration 470 : 0.0056859832257032394
Loss at iteration 480 : 0.011516704224050045
Loss at iteration 490 : 0.0028007435612380505
Loss at iteration 500 : 0.005996201187372208
Loss at iteration 510 : 0.009882760234177113
Loss at iteration 520 : 0.019354259595274925
Loss at iteration 530 : 0.011113201268017292
Loss at iteration 540 : 0.0062591200694441795
Loss at iteration 550 : 0.006553427781909704
Loss at iteration 560 : 0.01647002249956131
Loss at iteration 570 : 0.010354642756283283
Loss at iteration 580 : 0.009480495937168598
Loss at iteration 590 : 0.00731464009732008
Loss at iteration 600 : 0.012999730184674263
Loss at iteration 610 : 0.007278664968907833
Loss at iteration 620 : 0.007891876623034477
Loss at iteration 630 : 0.0024071410298347473
Loss at iteration 640 : 0.002734755165874958
Loss at iteration 650 : 0.01019690465182066
Loss at iteration 660 : 0.006456563249230385
Loss at iteration 670 : 0.013108069077134132
Loss at iteration 680 : 0.013172915205359459
Loss at iteration 690 : 0.01310975942760706
Loss at iteration 700 : 0.01199338585138321
Loss at iteration 710 : 0.01738991215825081
Loss at iteration 720 : 0.007384555414319038
Loss at iteration 730 : 0.011779285036027431
Loss at iteration 740 : 0.01352236233651638
Loss at iteration 750 : 0.0206308513879776
Loss at iteration 760 : 0.007680132053792477
Loss at iteration 770 : 0.006408470682799816
Loss at iteration 780 : 0.003890151856467128
Loss at iteration 790 : 0.01476452685892582
Loss at iteration 800 : 0.014481664635241032
Loss at iteration 810 : 0.0194607712328434
Loss at iteration 820 : 0.008896339684724808
Loss at iteration 830 : 0.0076622674241662025
Loss at iteration 840 : 0.009231418371200562
Loss at iteration 850 : 0.004053035750985146
Loss at iteration 860 : 0.009888377040624619
Loss at iteration 870 : 0.016490669921040535
Loss at iteration 880 : 0.0060423375107347965
Loss at iteration 890 : 0.0030510136857628822
Loss at iteration 900 : 0.011401192285120487
Loss at iteration 910 : 0.009511744603514671
Loss at iteration 920 : 0.005788059905171394
Loss at iteration 930 : 0.010936209000647068
Loss at iteration 940 : 0.003480687504634261
Loss at iteration 950 : 0.011776953935623169
Loss at iteration 960 : 0.007952743209898472
Loss at iteration 970 : 0.0124514140188694
Loss at iteration 980 : 0.011456974782049656
Loss at iteration 990 : 0.006319242529571056
Loss at iteration 1000 : 0.009685169905424118
Loss at iteration 1010 : 0.010432148352265358
Loss at iteration 1020 : 0.00396843021735549
Loss at iteration 1030 : 0.009029009379446507
Loss at iteration 1040 : 0.008256776258349419
Loss at iteration 1050 : 0.009404833428561687
Loss at iteration 1060 : 0.012528504244983196
Loss at iteration 1070 : 0.01091097667813301
Loss at iteration 1080 : 0.0034235490020364523
Loss at iteration 1090 : 0.005894657224416733
Loss at iteration 1100 : 0.011823146604001522
Loss at iteration 1110 : 0.009699171409010887
Loss at iteration 1120 : 0.0028171876911073923
Loss at iteration 1130 : 0.022999238222837448
Loss at iteration 1140 : 0.007766137830913067
Loss at iteration 1150 : 0.0072765350341796875
Loss at iteration 1160 : 0.012732399627566338
Loss at iteration 1170 : 0.013491679914295673
Loss at iteration 1180 : 0.007740896660834551
Loss at iteration 1190 : 0.00566341495141387
Loss at iteration 1200 : 0.01809585653245449
Loss at iteration 1210 : 0.008329610340297222
Loss at iteration 1220 : 0.011497779749333858
Loss at iteration 1230 : 0.011569403111934662
Loss at iteration 1240 : 0.006912419106811285
Loss at iteration 1250 : 0.009715355932712555
Loss at iteration 1260 : 0.012286987155675888
Loss at iteration 1270 : 0.007385186851024628
Loss at iteration 1280 : 0.006437024101614952
Loss at iteration 1290 : 0.012078329920768738
Loss at iteration 1300 : 0.005864317528903484
Loss at iteration 1310 : 0.007342084310948849
Loss at iteration 1320 : 0.012867499142885208
Loss at iteration 1330 : 0.007692997343838215
Loss at iteration 1340 : 0.0042150202207267284
Loss at iteration 1350 : 0.009183591231703758
Loss at iteration 1360 : 0.009418229572474957
Loss at iteration 1370 : 0.009055504575371742
Loss at iteration 1380 : 0.006979508325457573
Loss at iteration 1390 : 0.006075857672840357
Loss at iteration 1400 : 0.0028536515310406685
Loss at iteration 1410 : 0.006298837251961231
Loss at iteration 1420 : 0.010537080466747284
Loss at iteration 1430 : 0.0039262897334992886
Loss at iteration 1440 : 0.006591000594198704
Loss at iteration 1450 : 0.010594647377729416
Loss at iteration 1460 : 0.014923972077667713
Loss at iteration 1470 : 0.023711614310741425
Loss at iteration 1480 : 0.008006359450519085
Loss at iteration 1490 : 0.008537263609468937
Loss at iteration 1500 : 0.009940395131707191
Loss at iteration 1510 : 0.011776772327721119
Loss at iteration 1520 : 0.004266471602022648
Loss at iteration 1530 : 0.006579037755727768
Loss at iteration 1540 : 0.006221580319106579
Loss at iteration 1550 : 0.011716863140463829
Loss at iteration 1560 : 0.007962401024997234
Loss at iteration 1570 : 0.008470408618450165
Loss at iteration 1580 : 0.018910778686404228
Loss at iteration 1590 : 0.006004209630191326
Loss at iteration 1600 : 0.013177696615457535
Loss at iteration 1610 : 0.010632816702127457
Loss at iteration 1620 : 0.014143196865916252
Loss at iteration 1630 : 0.004879946820437908
Loss at iteration 1640 : 0.005240349564701319
Loss at iteration 1650 : 0.008042940869927406
Loss at iteration 1660 : 0.005155504681169987
Loss at iteration 1670 : 0.006099673453718424
Loss at iteration 1680 : 0.004751207306981087
Loss at iteration 1690 : 0.013298636302351952
Loss at iteration 1700 : 0.004655403550714254
Loss at iteration 1710 : 0.011313611641526222
Loss at iteration 1720 : 0.01232802402228117
Loss at iteration 1730 : 0.01407727412879467
Loss at iteration 1740 : 0.015263817273080349
Loss at iteration 1750 : 0.014662185683846474
Loss at iteration 1760 : 0.013324882835149765
Loss at iteration 1770 : 0.0075751193799078465
Loss at iteration 1780 : 0.009808000177145004
Loss at iteration 1790 : 0.0065215760841965675
Loss at iteration 1800 : 0.007529927883297205
Loss at iteration 1810 : 0.007775056175887585
Loss at iteration 1820 : 0.0206937063485384
Loss at iteration 1830 : 0.0036240897607058287
Loss at iteration 1840 : 0.0037550386041402817
Loss at iteration 1850 : 0.01865921914577484
Loss at iteration 1860 : 0.007732790894806385
Loss at iteration 1870 : 0.008669295348227024
Loss at iteration 1880 : 0.009167705662548542
Loss at iteration 1890 : 0.004621167667210102
Loss at iteration 1900 : 0.0161978080868721
Loss at iteration 1910 : 0.0028494081925600767
Loss at iteration 1920 : 0.010729366913437843
Loss at iteration 1930 : 0.006527298130095005
Loss at iteration 1940 : 0.009272778406739235
Loss at iteration 1950 : 0.00739952502772212
Loss at iteration 1960 : 0.007452263496816158
Loss at iteration 1970 : 0.0031120635103434324
Loss at iteration 1980 : 0.011537179350852966
Loss at iteration 1990 : 0.009350109845399857
Loss at iteration 2000 : 0.012176780961453915
Loss at iteration 2010 : 0.006886508781462908
Loss at iteration 2020 : 0.012272258289158344
Loss at iteration 2030 : 0.01012180745601654
Loss at iteration 2040 : 0.0061687203124165535
Loss at iteration 2050 : 0.031348101794719696
Loss at iteration 2060 : 0.006823115516453981
Loss at iteration 2070 : 0.010934943333268166
Loss at iteration 2080 : 0.01701485551893711
Loss at iteration 2090 : 0.005246253684163094
Loss at iteration 2100 : 0.005261334590613842
Loss at iteration 2110 : 0.008478783071041107
Loss at iteration 2120 : 0.013805503025650978
Loss at iteration 2130 : 0.011241067200899124
Loss at iteration 2140 : 0.03806417062878609
Loss at iteration 2150 : 0.008965933695435524
Loss at iteration 2160 : 0.0032440496142953634
Loss at iteration 2170 : 0.008942294865846634
Loss at iteration 2180 : 0.00632411427795887
Loss at iteration 2190 : 0.006794230546802282
Loss at iteration 2200 : 0.007365639787167311
Loss at iteration 2210 : 0.006145879160612822
Loss at iteration 2220 : 0.0047115180641412735
Loss at iteration 2230 : 0.0019353856332600117
Loss at iteration 2240 : 0.008577650412917137
Loss at iteration 2250 : 0.01206898968666792
Loss at iteration 2260 : 0.0038420716300606728
Loss at iteration 2270 : 0.010575768537819386
Loss at iteration 2280 : 0.00417799549177289
Loss at iteration 2290 : 0.007286855485290289
Loss at iteration 2300 : 0.007453984580934048
Loss at iteration 2310 : 0.0042665498331189156
Loss at iteration 2320 : 0.00598716177046299
Loss at iteration 2330 : 0.008731999434530735
Loss at iteration 2340 : 0.006112817209213972
Loss at iteration 2350 : 0.007725668139755726
Loss at iteration 2360 : 0.007765777409076691
Loss at iteration 2370 : 0.005442884285002947
Loss at iteration 2380 : 0.017817450687289238
Loss at iteration 2390 : 0.0052317483350634575
Loss at iteration 2400 : 0.009487218223512173
Loss at iteration 2410 : 0.019288666546344757
Loss at iteration 2420 : 0.009201237931847572
The SSIM Value is: 0.8424656669298808
The PSNR Value is: 22.088495445251464
the epoch is: 83
Loss at iteration 10 : 0.011086425743997097
Loss at iteration 20 : 0.0067508406937122345
Loss at iteration 30 : 0.007847742177546024
Loss at iteration 40 : 0.011748646385967731
Loss at iteration 50 : 0.010624369606375694
Loss at iteration 60 : 0.00520881824195385
Loss at iteration 70 : 0.011700831353664398
Loss at iteration 80 : 0.011102478951215744
Loss at iteration 90 : 0.008703496307134628
Loss at iteration 100 : 0.03453107923269272
Loss at iteration 110 : 0.009559723548591137
Loss at iteration 120 : 0.01293223723769188
Loss at iteration 130 : 0.010028105229139328
Loss at iteration 140 : 0.008765571750700474
Loss at iteration 150 : 0.007472687866538763
Loss at iteration 160 : 0.002044526394456625
Loss at iteration 170 : 0.004624240566045046
Loss at iteration 180 : 0.018455930054187775
Loss at iteration 190 : 0.01239072997123003
Loss at iteration 200 : 0.016705457121133804
Loss at iteration 210 : 0.005864324048161507
Loss at iteration 220 : 0.004890214651823044
Loss at iteration 230 : 0.016898589208722115
Loss at iteration 240 : 0.0033071241341531277
Loss at iteration 250 : 0.02007252350449562
Loss at iteration 260 : 0.011707019992172718
Loss at iteration 270 : 0.011489523574709892
Loss at iteration 280 : 0.011468554846942425
Loss at iteration 290 : 0.009562449529767036
Loss at iteration 300 : 0.005049934610724449
Loss at iteration 310 : 0.006833639927208424
Loss at iteration 320 : 0.008573286235332489
Loss at iteration 330 : 0.011638162657618523
Loss at iteration 340 : 0.015437189489603043
Loss at iteration 350 : 0.012389975599944592
Loss at iteration 360 : 0.010685919784009457
Loss at iteration 370 : 0.007728693541139364
Loss at iteration 380 : 0.01065697893500328
Loss at iteration 390 : 0.008742243982851505
Loss at iteration 400 : 0.007341506890952587
Loss at iteration 410 : 0.012102306820452213
Loss at iteration 420 : 0.012802070006728172
Loss at iteration 430 : 0.014325577765703201
Loss at iteration 440 : 0.006957398261874914
Loss at iteration 450 : 0.008325099013745785
Loss at iteration 460 : 0.018241846933960915
Loss at iteration 470 : 0.007548762485384941
Loss at iteration 480 : 0.010545054450631142
Loss at iteration 490 : 0.007233483716845512
Loss at iteration 500 : 0.010651777498424053
Loss at iteration 510 : 0.01030314713716507
Loss at iteration 520 : 0.010326161049306393
Loss at iteration 530 : 0.010714864358305931
Loss at iteration 540 : 0.008265464566648006
Loss at iteration 550 : 0.011667362414300442
Loss at iteration 560 : 0.006867381278425455
Loss at iteration 570 : 0.006390098948031664
Loss at iteration 580 : 0.006544226780533791
Loss at iteration 590 : 0.012191344052553177
Loss at iteration 600 : 0.007216965779662132
Loss at iteration 610 : 0.009720511734485626
Loss at iteration 620 : 0.007863624952733517
Loss at iteration 630 : 0.013674351386725903
Loss at iteration 640 : 0.0027413249481469393
Loss at iteration 650 : 0.010807572863996029
Loss at iteration 660 : 0.007053164299577475
Loss at iteration 670 : 0.009424409829080105
Loss at iteration 680 : 0.005913741886615753
Loss at iteration 690 : 0.01192840002477169
Loss at iteration 700 : 0.012660006061196327
Loss at iteration 710 : 0.004649374634027481
Loss at iteration 720 : 0.00865141674876213
Loss at iteration 730 : 0.00772250397130847
Loss at iteration 740 : 0.006163221783936024
Loss at iteration 750 : 0.006580899003893137
Loss at iteration 760 : 0.011373203247785568
Loss at iteration 770 : 0.006088266149163246
Loss at iteration 780 : 0.011675022542476654
Loss at iteration 790 : 0.01258872076869011
Loss at iteration 800 : 0.00798332691192627
Loss at iteration 810 : 0.0064736949279904366
Loss at iteration 820 : 0.004530236124992371
Loss at iteration 830 : 0.007910004816949368
Loss at iteration 840 : 0.011599206365644932
Loss at iteration 850 : 0.010393552482128143
Loss at iteration 860 : 0.004303161520510912
Loss at iteration 870 : 0.008601396344602108
Loss at iteration 880 : 0.005674957763403654
Loss at iteration 890 : 0.005727093666791916
Loss at iteration 900 : 0.008272891864180565
Loss at iteration 910 : 0.007752817124128342
Loss at iteration 920 : 0.00508134113624692
Loss at iteration 930 : 0.007028833031654358
Loss at iteration 940 : 0.009672945365309715
Loss at iteration 950 : 0.008292129263281822
Loss at iteration 960 : 0.004177804104983807
Loss at iteration 970 : 0.006035293452441692
Loss at iteration 980 : 0.008342492394149303
Loss at iteration 990 : 0.013283980078995228
Loss at iteration 1000 : 0.0110850278288126
Loss at iteration 1010 : 0.02187650464475155
Loss at iteration 1020 : 0.013670452870428562
Loss at iteration 1030 : 0.0092457951977849
Loss at iteration 1040 : 0.005262183956801891
Loss at iteration 1050 : 0.010718599893152714
Loss at iteration 1060 : 0.00834635365754366
Loss at iteration 1070 : 0.008004551753401756
Loss at iteration 1080 : 0.015105842612683773
Loss at iteration 1090 : 0.003969860263168812
Loss at iteration 1100 : 0.006287408992648125
Loss at iteration 1110 : 0.008138444274663925
Loss at iteration 1120 : 0.00887221097946167
Loss at iteration 1130 : 0.003100148867815733
Loss at iteration 1140 : 0.009896550327539444
Loss at iteration 1150 : 0.015664594247937202
Loss at iteration 1160 : 0.013750046491622925
Loss at iteration 1170 : 0.005656093824654818
Loss at iteration 1180 : 0.0050827800296247005
Loss at iteration 1190 : 0.010157031938433647
Loss at iteration 1200 : 0.01017854642122984
Loss at iteration 1210 : 0.006786122918128967
Loss at iteration 1220 : 0.010789492167532444
Loss at iteration 1230 : 0.004151429049670696
Loss at iteration 1240 : 0.009416242130100727
Loss at iteration 1250 : 0.007550808135420084
Loss at iteration 1260 : 0.006387809757143259
Loss at iteration 1270 : 0.007687962613999844
Loss at iteration 1280 : 0.010903111658990383
Loss at iteration 1290 : 0.01848664879798889
Loss at iteration 1300 : 0.006950249895453453
Loss at iteration 1310 : 0.008584685623645782
Loss at iteration 1320 : 0.005405937787145376
Loss at iteration 1330 : 0.009640206582844257
Loss at iteration 1340 : 0.01141783595085144
Loss at iteration 1350 : 0.003995069302618504
Loss at iteration 1360 : 0.005949575453996658
Loss at iteration 1370 : 0.007700545713305473
Loss at iteration 1380 : 0.007478805724531412
Loss at iteration 1390 : 0.004693077877163887
Loss at iteration 1400 : 0.013669551350176334
Loss at iteration 1410 : 0.008742107078433037
Loss at iteration 1420 : 0.007672830484807491
Loss at iteration 1430 : 0.008359105326235294
Loss at iteration 1440 : 0.0069979894906282425
Loss at iteration 1450 : 0.008705583401024342
Loss at iteration 1460 : 0.00809413380920887
Loss at iteration 1470 : 0.0059754615649580956
Loss at iteration 1480 : 0.017341502010822296
Loss at iteration 1490 : 0.005174084100872278
Loss at iteration 1500 : 0.006421252153813839
Loss at iteration 1510 : 0.01075692567974329
Loss at iteration 1520 : 0.010287144221365452
Loss at iteration 1530 : 0.006679483689367771
Loss at iteration 1540 : 0.009442703798413277
Loss at iteration 1550 : 0.01340903528034687
Loss at iteration 1560 : 0.013269885443150997
Loss at iteration 1570 : 0.0212501659989357
Loss at iteration 1580 : 0.0186835415661335
Loss at iteration 1590 : 0.00634557381272316
Loss at iteration 1600 : 0.01630144752562046
Loss at iteration 1610 : 0.007651050109416246
Loss at iteration 1620 : 0.020764479413628578
Loss at iteration 1630 : 0.012679863721132278
Loss at iteration 1640 : 0.007979352958500385
Loss at iteration 1650 : 0.006612574681639671
Loss at iteration 1660 : 0.012670557014644146
Loss at iteration 1670 : 0.007139749359339476
Loss at iteration 1680 : 0.008430578745901585
Loss at iteration 1690 : 0.00689250323921442
Loss at iteration 1700 : 0.010591845028102398
Loss at iteration 1710 : 0.007139296270906925
Loss at iteration 1720 : 0.006886056624352932
Loss at iteration 1730 : 0.010594934225082397
Loss at iteration 1740 : 0.007791915908455849
Loss at iteration 1750 : 0.005835660267621279
Loss at iteration 1760 : 0.008888520300388336
Loss at iteration 1770 : 0.007111347280442715
Loss at iteration 1780 : 0.005529714748263359
Loss at iteration 1790 : 0.005625152960419655
Loss at iteration 1800 : 0.009477304294705391
Loss at iteration 1810 : 0.008418243378400803
Loss at iteration 1820 : 0.00880136713385582
Loss at iteration 1830 : 0.006795016583055258
Loss at iteration 1840 : 0.008250469341874123
Loss at iteration 1850 : 0.013930052518844604
Loss at iteration 1860 : 0.007174050435423851
Loss at iteration 1870 : 0.004287904128432274
Loss at iteration 1880 : 0.011303533799946308
Loss at iteration 1890 : 0.014654180034995079
Loss at iteration 1900 : 0.004923250526189804
Loss at iteration 1910 : 0.012131355702877045
Loss at iteration 1920 : 0.008737408556044102
Loss at iteration 1930 : 0.01667519472539425
Loss at iteration 1940 : 0.005809108726680279
Loss at iteration 1950 : 0.010665936395525932
Loss at iteration 1960 : 0.013716882094740868
Loss at iteration 1970 : 0.011955587193369865
Loss at iteration 1980 : 0.005967189557850361
Loss at iteration 1990 : 0.007885200902819633
Loss at iteration 2000 : 0.009573463350534439
Loss at iteration 2010 : 0.013007836416363716
Loss at iteration 2020 : 0.014490587636828423
Loss at iteration 2030 : 0.011050578206777573
Loss at iteration 2040 : 0.004815674852579832
Loss at iteration 2050 : 0.011264936998486519
Loss at iteration 2060 : 0.010511357337236404
Loss at iteration 2070 : 0.005145766772329807
Loss at iteration 2080 : 0.011473194696009159
Loss at iteration 2090 : 0.014763690531253815
Loss at iteration 2100 : 0.01025619637221098
Loss at iteration 2110 : 0.006180185358971357
Loss at iteration 2120 : 0.009632277302443981
Loss at iteration 2130 : 0.011261280626058578
Loss at iteration 2140 : 0.008816294372081757
Loss at iteration 2150 : 0.015897713601589203
Loss at iteration 2160 : 0.005265761166810989
Loss at iteration 2170 : 0.014604213647544384
Loss at iteration 2180 : 0.004639878869056702
Loss at iteration 2190 : 0.0065888697281479836
Loss at iteration 2200 : 0.010702040046453476
Loss at iteration 2210 : 0.008997218683362007
Loss at iteration 2220 : 0.007043357007205486
Loss at iteration 2230 : 0.006539271213114262
Loss at iteration 2240 : 0.014509150758385658
Loss at iteration 2250 : 0.009557566605508327
Loss at iteration 2260 : 0.011212422512471676
Loss at iteration 2270 : 0.009438863955438137
Loss at iteration 2280 : 0.006387867033481598
Loss at iteration 2290 : 0.013543498702347279
Loss at iteration 2300 : 0.019932478666305542
Loss at iteration 2310 : 0.008650945499539375
Loss at iteration 2320 : 0.007592186331748962
Loss at iteration 2330 : 0.010365239344537258
Loss at iteration 2340 : 0.006357961799949408
Loss at iteration 2350 : 0.004487180151045322
Loss at iteration 2360 : 0.011942029930651188
Loss at iteration 2370 : 0.007040497846901417
Loss at iteration 2380 : 0.009105434641242027
Loss at iteration 2390 : 0.011349113658070564
Loss at iteration 2400 : 0.005887332372367382
Loss at iteration 2410 : 0.004110489506274462
Loss at iteration 2420 : 0.005234093405306339
The SSIM Value is: 0.8483229557673136
The PSNR Value is: 22.742647234598795
the epoch is: 84
Loss at iteration 10 : 0.009203081950545311
Loss at iteration 20 : 0.009914819151163101
Loss at iteration 30 : 0.010678212158381939
Loss at iteration 40 : 0.005297395400702953
Loss at iteration 50 : 0.00836760550737381
Loss at iteration 60 : 0.005490798968821764
Loss at iteration 70 : 0.015553872101008892
Loss at iteration 80 : 0.008330016396939754
Loss at iteration 90 : 0.010719948448240757
Loss at iteration 100 : 0.019344234839081764
Loss at iteration 110 : 0.014785697683691978
Loss at iteration 120 : 0.006521868519484997
Loss at iteration 130 : 0.011043166741728783
Loss at iteration 140 : 0.005117954220622778
Loss at iteration 150 : 0.019420552998781204
Loss at iteration 160 : 0.0071853818371891975
Loss at iteration 170 : 0.0025734910741448402
Loss at iteration 180 : 0.004742449149489403
Loss at iteration 190 : 0.012663575820624828
Loss at iteration 200 : 0.006799523718655109
Loss at iteration 210 : 0.01890118047595024
Loss at iteration 220 : 0.013504118658602238
Loss at iteration 230 : 0.01781172677874565
Loss at iteration 240 : 0.014680086635053158
Loss at iteration 250 : 0.0026902880053967237
Loss at iteration 260 : 0.014369916170835495
Loss at iteration 270 : 0.008216645568609238
Loss at iteration 280 : 0.011215387843549252
Loss at iteration 290 : 0.009400003589689732
Loss at iteration 300 : 0.009093273431062698
Loss at iteration 310 : 0.005186239257454872
Loss at iteration 320 : 0.008714450523257256
Loss at iteration 330 : 0.006109840236604214
Loss at iteration 340 : 0.012527030892670155
Loss at iteration 350 : 0.008087613619863987
Loss at iteration 360 : 0.012534873560070992
Loss at iteration 370 : 0.012209106236696243
Loss at iteration 380 : 0.03820154443383217
Loss at iteration 390 : 0.014410294592380524
Loss at iteration 400 : 0.012127559632062912
Loss at iteration 410 : 0.01293642446398735
Loss at iteration 420 : 0.034534208476543427
Loss at iteration 430 : 0.023822739720344543
Loss at iteration 440 : 0.0038507310673594475
Loss at iteration 450 : 0.01305923517793417
Loss at iteration 460 : 0.008504736237227917
Loss at iteration 470 : 0.005071713589131832
Loss at iteration 480 : 0.01062105130404234
Loss at iteration 490 : 0.004643074236810207
Loss at iteration 500 : 0.006308294832706451
Loss at iteration 510 : 0.006098384037613869
Loss at iteration 520 : 0.012887890450656414
Loss at iteration 530 : 0.007904654368758202
Loss at iteration 540 : 0.006256872322410345
Loss at iteration 550 : 0.005147126503288746
Loss at iteration 560 : 0.007521385792642832
Loss at iteration 570 : 0.0064333416521549225
Loss at iteration 580 : 0.01072198711335659
Loss at iteration 590 : 0.004566812422126532
Loss at iteration 600 : 0.00461102370172739
Loss at iteration 610 : 0.006883964873850346
Loss at iteration 620 : 0.009878351353108883
Loss at iteration 630 : 0.00783192366361618
Loss at iteration 640 : 0.018044488504529
Loss at iteration 650 : 0.007945704273879528
Loss at iteration 660 : 0.008983321487903595
Loss at iteration 670 : 0.018208011984825134
Loss at iteration 680 : 0.008687639608979225
Loss at iteration 690 : 0.004191872663795948
Loss at iteration 700 : 0.008771036751568317
Loss at iteration 710 : 0.007076638750731945
Loss at iteration 720 : 0.013382358476519585
Loss at iteration 730 : 0.01038213912397623
Loss at iteration 740 : 0.007032976485788822
Loss at iteration 750 : 0.017711590975522995
Loss at iteration 760 : 0.009111635386943817
Loss at iteration 770 : 0.0065160226076841354
Loss at iteration 780 : 0.009008307009935379
Loss at iteration 790 : 0.010069504380226135
Loss at iteration 800 : 0.00988884549587965
Loss at iteration 810 : 0.009017055854201317
Loss at iteration 820 : 0.015303421765565872
Loss at iteration 830 : 0.008532408624887466
Loss at iteration 840 : 0.013659743592143059
Loss at iteration 850 : 0.013167236000299454
Loss at iteration 860 : 0.006385935936123133
Loss at iteration 870 : 0.007353140041232109
Loss at iteration 880 : 0.005039370618760586
Loss at iteration 890 : 0.007039692718535662
Loss at iteration 900 : 0.0035555637441575527
Loss at iteration 910 : 0.009683312848210335
Loss at iteration 920 : 0.003915463574230671
Loss at iteration 930 : 0.0019318775739520788
Loss at iteration 940 : 0.012295777909457684
Loss at iteration 950 : 0.007120741065591574
Loss at iteration 960 : 0.012674304656684399
Loss at iteration 970 : 0.011874059215188026
Loss at iteration 980 : 0.014782220125198364
Loss at iteration 990 : 0.009507530368864536
Loss at iteration 1000 : 0.01156753022223711
Loss at iteration 1010 : 0.008706704713404179
Loss at iteration 1020 : 0.0034726050216704607
Loss at iteration 1030 : 0.01329064927995205
Loss at iteration 1040 : 0.014831991866230965
Loss at iteration 1050 : 0.015811072662472725
Loss at iteration 1060 : 0.008150584995746613
Loss at iteration 1070 : 0.0043459925800561905
Loss at iteration 1080 : 0.008002863265573978
Loss at iteration 1090 : 0.011402060277760029
Loss at iteration 1100 : 0.007596142590045929
Loss at iteration 1110 : 0.008471912704408169
Loss at iteration 1120 : 0.014674374833703041
Loss at iteration 1130 : 0.01153415348380804
Loss at iteration 1140 : 0.005969792138785124
Loss at iteration 1150 : 0.009470206685364246
Loss at iteration 1160 : 0.010468034073710442
Loss at iteration 1170 : 0.01089734211564064
Loss at iteration 1180 : 0.007735554128885269
Loss at iteration 1190 : 0.007270875386893749
Loss at iteration 1200 : 0.015058541670441628
Loss at iteration 1210 : 0.005170020274817944
Loss at iteration 1220 : 0.012543991208076477
Loss at iteration 1230 : 0.011631254106760025
Loss at iteration 1240 : 0.009870207868516445
Loss at iteration 1250 : 0.0042043933644890785
Loss at iteration 1260 : 0.019429050385951996
Loss at iteration 1270 : 0.0062635368667542934
Loss at iteration 1280 : 0.006951901130378246
Loss at iteration 1290 : 0.01579134352505207
Loss at iteration 1300 : 0.0033480210695415735
Loss at iteration 1310 : 0.01766670122742653
Loss at iteration 1320 : 0.014279264025390148
Loss at iteration 1330 : 0.013498036190867424
Loss at iteration 1340 : 0.003795142052695155
Loss at iteration 1350 : 0.008770965039730072
Loss at iteration 1360 : 0.0042852978222072124
Loss at iteration 1370 : 0.015071061439812183
Loss at iteration 1380 : 0.012997368350625038
Loss at iteration 1390 : 0.016293415799736977
Loss at iteration 1400 : 0.01960388757288456
Loss at iteration 1410 : 0.0086531862616539
Loss at iteration 1420 : 0.009925967082381248
Loss at iteration 1430 : 0.007168576121330261
Loss at iteration 1440 : 0.0037277790252119303
Loss at iteration 1450 : 0.00936845876276493
Loss at iteration 1460 : 0.008018841966986656
Loss at iteration 1470 : 0.004997250624001026
Loss at iteration 1480 : 0.009201433509588242
Loss at iteration 1490 : 0.0029637289699167013
Loss at iteration 1500 : 0.010660093277692795
Loss at iteration 1510 : 0.0033602267503738403
Loss at iteration 1520 : 0.008468590676784515
Loss at iteration 1530 : 0.022113926708698273
Loss at iteration 1540 : 0.006922904402017593
Loss at iteration 1550 : 0.014486968517303467
Loss at iteration 1560 : 0.0030085351318120956
Loss at iteration 1570 : 0.00984637625515461
Loss at iteration 1580 : 0.002212169114500284
Loss at iteration 1590 : 0.004413430113345385
Loss at iteration 1600 : 0.006972660776227713
Loss at iteration 1610 : 0.016566652804613113
Loss at iteration 1620 : 0.015196427702903748
Loss at iteration 1630 : 0.0039966958574950695
Loss at iteration 1640 : 0.008719606325030327
Loss at iteration 1650 : 0.005202361382544041
Loss at iteration 1660 : 0.015031922608613968
Loss at iteration 1670 : 0.005665245465934277
Loss at iteration 1680 : 0.005634658969938755
Loss at iteration 1690 : 0.01629999466240406
Loss at iteration 1700 : 0.006523987278342247
Loss at iteration 1710 : 0.013466522097587585
Loss at iteration 1720 : 0.01013727393001318
Loss at iteration 1730 : 0.006255185231566429
Loss at iteration 1740 : 0.012727007269859314
Loss at iteration 1750 : 0.009550423361361027
Loss at iteration 1760 : 0.00840572640299797
Loss at iteration 1770 : 0.006062147673219442
Loss at iteration 1780 : 0.005950474180281162
Loss at iteration 1790 : 0.006151929497718811
Loss at iteration 1800 : 0.014283711090683937
Loss at iteration 1810 : 0.00715221744030714
Loss at iteration 1820 : 0.007943037897348404
Loss at iteration 1830 : 0.016393255442380905
Loss at iteration 1840 : 0.0073085050098598
Loss at iteration 1850 : 0.006629593670368195
Loss at iteration 1860 : 0.006674257107079029
Loss at iteration 1870 : 0.012471278198063374
Loss at iteration 1880 : 0.018250256776809692
Loss at iteration 1890 : 0.005825630854815245
Loss at iteration 1900 : 0.0079584289342165
Loss at iteration 1910 : 0.006970098242163658
Loss at iteration 1920 : 0.014823492616415024
Loss at iteration 1930 : 0.008948626928031445
Loss at iteration 1940 : 0.006325393915176392
Loss at iteration 1950 : 0.006212497130036354
Loss at iteration 1960 : 0.008467314764857292
Loss at iteration 1970 : 0.0062664831057190895
Loss at iteration 1980 : 0.010343109257519245
Loss at iteration 1990 : 0.0079716257750988
Loss at iteration 2000 : 0.0036711636930704117
Loss at iteration 2010 : 0.019223351031541824
Loss at iteration 2020 : 0.009348888881504536
Loss at iteration 2030 : 0.0066032567992806435
Loss at iteration 2040 : 0.004185146186500788
Loss at iteration 2050 : 0.005525471176952124
Loss at iteration 2060 : 0.015110820531845093
Loss at iteration 2070 : 0.006398594938218594
Loss at iteration 2080 : 0.009513149037957191
Loss at iteration 2090 : 0.011686772108078003
Loss at iteration 2100 : 0.021464280784130096
Loss at iteration 2110 : 0.010150949470698833
Loss at iteration 2120 : 0.006682891398668289
Loss at iteration 2130 : 0.004631532356142998
Loss at iteration 2140 : 0.00801694206893444
Loss at iteration 2150 : 0.0035879637580364943
Loss at iteration 2160 : 0.007480822503566742
Loss at iteration 2170 : 0.012078428640961647
Loss at iteration 2180 : 0.005295592360198498
Loss at iteration 2190 : 0.00810317974537611
Loss at iteration 2200 : 0.007476941682398319
Loss at iteration 2210 : 0.006575366482138634
Loss at iteration 2220 : 0.0026332035195082426
Loss at iteration 2230 : 0.011098242364823818
Loss at iteration 2240 : 0.003788382513448596
Loss at iteration 2250 : 0.0038021851796656847
Loss at iteration 2260 : 0.004176221322268248
Loss at iteration 2270 : 0.007470731623470783
Loss at iteration 2280 : 0.008918014355003834
Loss at iteration 2290 : 0.009964575991034508
Loss at iteration 2300 : 0.012975284829735756
Loss at iteration 2310 : 0.03497271612286568
Loss at iteration 2320 : 0.008356696926057339
Loss at iteration 2330 : 0.007424581330269575
Loss at iteration 2340 : 0.008750271052122116
Loss at iteration 2350 : 0.004288031719624996
Loss at iteration 2360 : 0.005569765344262123
Loss at iteration 2370 : 0.014284951612353325
Loss at iteration 2380 : 0.006584956776350737
Loss at iteration 2390 : 0.008429817855358124
Loss at iteration 2400 : 0.012471340596675873
Loss at iteration 2410 : 0.01900867372751236
Loss at iteration 2420 : 0.010129074566066265
The SSIM Value is: 0.8428374449412028
The PSNR Value is: 21.70871130625407
the epoch is: 85
Loss at iteration 10 : 0.007112526800483465
Loss at iteration 20 : 0.007949507795274258
Loss at iteration 30 : 0.011190937831997871
Loss at iteration 40 : 0.0035577183589339256
Loss at iteration 50 : 0.020947616547346115
Loss at iteration 60 : 0.008652771823108196
Loss at iteration 70 : 0.008740770630538464
Loss at iteration 80 : 0.015257184393703938
Loss at iteration 90 : 0.011621503159403801
Loss at iteration 100 : 0.008196106180548668
Loss at iteration 110 : 0.007573132868856192
Loss at iteration 120 : 0.010090382769703865
Loss at iteration 130 : 0.011161338537931442
Loss at iteration 140 : 0.008106498047709465
Loss at iteration 150 : 0.003399206791073084
Loss at iteration 160 : 0.00205362681299448
Loss at iteration 170 : 0.004303481429815292
Loss at iteration 180 : 0.014849057421088219
Loss at iteration 190 : 0.009962876327335835
Loss at iteration 200 : 0.009127040393650532
Loss at iteration 210 : 0.005633870605379343
Loss at iteration 220 : 0.010124284774065018
Loss at iteration 230 : 0.015422491356730461
Loss at iteration 240 : 0.007491813041269779
Loss at iteration 250 : 0.005822952836751938
Loss at iteration 260 : 0.0053445505909621716
Loss at iteration 270 : 0.008297133259475231
Loss at iteration 280 : 0.013840092346072197
Loss at iteration 290 : 0.009479810483753681
Loss at iteration 300 : 0.004892691969871521
Loss at iteration 310 : 0.007482070010155439
Loss at iteration 320 : 0.017883192747831345
Loss at iteration 330 : 0.009449631907045841
Loss at iteration 340 : 0.007835445925593376
Loss at iteration 350 : 0.009496771730482578
Loss at iteration 360 : 0.008040638640522957
Loss at iteration 370 : 0.011221407912671566
Loss at iteration 380 : 0.01581614278256893
Loss at iteration 390 : 0.006604143418371677
Loss at iteration 400 : 0.017386600375175476
Loss at iteration 410 : 0.007776489481329918
Loss at iteration 420 : 0.005564781371504068
Loss at iteration 430 : 0.014324303716421127
Loss at iteration 440 : 0.006300076376646757
Loss at iteration 450 : 0.01589355617761612
Loss at iteration 460 : 0.006071547977626324
Loss at iteration 470 : 0.017050549387931824
Loss at iteration 480 : 0.0049692559987306595
Loss at iteration 490 : 0.009446614421904087
Loss at iteration 500 : 0.006077831145375967
Loss at iteration 510 : 0.018738826736807823
Loss at iteration 520 : 0.008808494545519352
Loss at iteration 530 : 0.005884612910449505
Loss at iteration 540 : 0.007177462801337242
Loss at iteration 550 : 0.007352580316364765
Loss at iteration 560 : 0.013155077584087849
Loss at iteration 570 : 0.018674807623028755
Loss at iteration 580 : 0.005702136550098658
Loss at iteration 590 : 0.012001457624137402
Loss at iteration 600 : 0.012006253935396671
Loss at iteration 610 : 0.00841442309319973
Loss at iteration 620 : 0.005454749334603548
Loss at iteration 630 : 0.0075724464841187
Loss at iteration 640 : 0.007005022373050451
Loss at iteration 650 : 0.017484381794929504
Loss at iteration 660 : 0.007892485707998276
Loss at iteration 670 : 0.0068710725754499435
Loss at iteration 680 : 0.0049798330292105675
Loss at iteration 690 : 0.005595053546130657
Loss at iteration 700 : 0.015330495312809944
Loss at iteration 710 : 0.003414431121200323
Loss at iteration 720 : 0.007871557027101517
Loss at iteration 730 : 0.011615277267992496
Loss at iteration 740 : 0.0043654367327690125
Loss at iteration 750 : 0.018642358481884003
Loss at iteration 760 : 0.007761185988783836
Loss at iteration 770 : 0.009556414559483528
Loss at iteration 780 : 0.0055883717723190784
Loss at iteration 790 : 0.008374517783522606
Loss at iteration 800 : 0.008197835646569729
Loss at iteration 810 : 0.006590954028069973
Loss at iteration 820 : 0.006913036108016968
Loss at iteration 830 : 0.0032258278224617243
Loss at iteration 840 : 0.0049601225182414055
Loss at iteration 850 : 0.006088487338274717
Loss at iteration 860 : 0.005560724064707756
Loss at iteration 870 : 0.0041120355017483234
Loss at iteration 880 : 0.005648934282362461
Loss at iteration 890 : 0.0066382428631186485
Loss at iteration 900 : 0.009198999963700771
Loss at iteration 910 : 0.0065821693278849125
Loss at iteration 920 : 0.008869858458638191
Loss at iteration 930 : 0.01614554598927498
Loss at iteration 940 : 0.0026819577906280756
Loss at iteration 950 : 0.011070538312196732
Loss at iteration 960 : 0.015539162792265415
Loss at iteration 970 : 0.006663027219474316
Loss at iteration 980 : 0.012306718155741692
Loss at iteration 990 : 0.008369449526071548
Loss at iteration 1000 : 0.007945320568978786
Loss at iteration 1010 : 0.012622667476534843
Loss at iteration 1020 : 0.011857903562486172
Loss at iteration 1030 : 0.003918978851288557
Loss at iteration 1040 : 0.01595192775130272
Loss at iteration 1050 : 0.0038089402951300144
Loss at iteration 1060 : 0.014173449948430061
Loss at iteration 1070 : 0.011308247223496437
Loss at iteration 1080 : 0.008625490590929985
Loss at iteration 1090 : 0.006497375667095184
Loss at iteration 1100 : 0.012101301923394203
Loss at iteration 1110 : 0.020899783819913864
Loss at iteration 1120 : 0.0051502566784620285
Loss at iteration 1130 : 0.0030599196907132864
Loss at iteration 1140 : 0.004555904306471348
Loss at iteration 1150 : 0.006470114458352327
Loss at iteration 1160 : 0.00761981587857008
Loss at iteration 1170 : 0.007466601207852364
Loss at iteration 1180 : 0.003494232427328825
Loss at iteration 1190 : 0.011005757376551628
Loss at iteration 1200 : 0.003111312398687005
Loss at iteration 1210 : 0.00727889034897089
Loss at iteration 1220 : 0.008489138446748257
Loss at iteration 1230 : 0.00641020480543375
Loss at iteration 1240 : 0.0038901318330317736
Loss at iteration 1250 : 0.021689612418413162
Loss at iteration 1260 : 0.010243864730000496
Loss at iteration 1270 : 0.009011389687657356
Loss at iteration 1280 : 0.007538983598351479
Loss at iteration 1290 : 0.009935877285897732
Loss at iteration 1300 : 0.006055166013538837
Loss at iteration 1310 : 0.007281511090695858
Loss at iteration 1320 : 0.03375693038105965
Loss at iteration 1330 : 0.016466576606035233
Loss at iteration 1340 : 0.007532679475843906
Loss at iteration 1350 : 0.006228139158338308
Loss at iteration 1360 : 0.006630859803408384
Loss at iteration 1370 : 0.0061175646260380745
Loss at iteration 1380 : 0.010877406224608421
Loss at iteration 1390 : 0.005412260536104441
Loss at iteration 1400 : 0.010315090417861938
Loss at iteration 1410 : 0.005329086445271969
Loss at iteration 1420 : 0.010945385321974754
Loss at iteration 1430 : 0.0058982884511351585
Loss at iteration 1440 : 0.005173106677830219
Loss at iteration 1450 : 0.009386368095874786
Loss at iteration 1460 : 0.006840733345597982
Loss at iteration 1470 : 0.0019981644582003355
Loss at iteration 1480 : 0.003522985614836216
Loss at iteration 1490 : 0.008406173437833786
Loss at iteration 1500 : 0.010397587902843952
Loss at iteration 1510 : 0.010729722678661346
Loss at iteration 1520 : 0.00439003249630332
Loss at iteration 1530 : 0.004001769237220287
Loss at iteration 1540 : 0.0070137451402843
Loss at iteration 1550 : 0.0080190971493721
Loss at iteration 1560 : 0.014742746949195862
Loss at iteration 1570 : 0.007080589886754751
Loss at iteration 1580 : 0.010987761430442333
Loss at iteration 1590 : 0.008087433874607086
Loss at iteration 1600 : 0.009121917188167572
Loss at iteration 1610 : 0.011550839990377426
Loss at iteration 1620 : 0.004298162646591663
Loss at iteration 1630 : 0.006975442636758089
Loss at iteration 1640 : 0.007315322756767273
Loss at iteration 1650 : 0.015111776068806648
Loss at iteration 1660 : 0.009169934317469597
Loss at iteration 1670 : 0.013703879900276661
Loss at iteration 1680 : 0.0031815925613045692
Loss at iteration 1690 : 0.010567774996161461
Loss at iteration 1700 : 0.011933130212128162
Loss at iteration 1710 : 0.002930044662207365
Loss at iteration 1720 : 0.028323695063591003
Loss at iteration 1730 : 0.013393210247159004
Loss at iteration 1740 : 0.016613991931080818
Loss at iteration 1750 : 0.006466721184551716
Loss at iteration 1760 : 0.013291136361658573
Loss at iteration 1770 : 0.005467582494020462
Loss at iteration 1780 : 0.006381888873875141
Loss at iteration 1790 : 0.010776695795357227
Loss at iteration 1800 : 0.010087110102176666
Loss at iteration 1810 : 0.01168489083647728
Loss at iteration 1820 : 0.012061946094036102
Loss at iteration 1830 : 0.007143951952457428
Loss at iteration 1840 : 0.004444415681064129
Loss at iteration 1850 : 0.009376166388392448
Loss at iteration 1860 : 0.005095308180898428
Loss at iteration 1870 : 0.01801004633307457
Loss at iteration 1880 : 0.006876608356833458
Loss at iteration 1890 : 0.002680104225873947
Loss at iteration 1900 : 0.010101906955242157
Loss at iteration 1910 : 0.015077179297804832
Loss at iteration 1920 : 0.006304738577455282
Loss at iteration 1930 : 0.005336330737918615
Loss at iteration 1940 : 0.00819400791078806
Loss at iteration 1950 : 0.005660258233547211
Loss at iteration 1960 : 0.017334874719381332
Loss at iteration 1970 : 0.0030577071011066437
Loss at iteration 1980 : 0.008299492299556732
Loss at iteration 1990 : 0.010899736545979977
Loss at iteration 2000 : 0.008368737995624542
Loss at iteration 2010 : 0.0076178861781954765
Loss at iteration 2020 : 0.01081401202827692
Loss at iteration 2030 : 0.010070200078189373
Loss at iteration 2040 : 0.01051592268049717
Loss at iteration 2050 : 0.007866253145039082
Loss at iteration 2060 : 0.008816525340080261
Loss at iteration 2070 : 0.005744118243455887
Loss at iteration 2080 : 0.005903269164264202
Loss at iteration 2090 : 0.02193724550306797
Loss at iteration 2100 : 0.009632025845348835
Loss at iteration 2110 : 0.010268551297485828
Loss at iteration 2120 : 0.015774214640259743
Loss at iteration 2130 : 0.014206061139702797
Loss at iteration 2140 : 0.007693770807236433
Loss at iteration 2150 : 0.006071074865758419
Loss at iteration 2160 : 0.01718241162598133
Loss at iteration 2170 : 0.014901760965585709
Loss at iteration 2180 : 0.014354921877384186
Loss at iteration 2190 : 0.015726858749985695
Loss at iteration 2200 : 0.015855176374316216
Loss at iteration 2210 : 0.00868903286755085
Loss at iteration 2220 : 0.002701391698792577
Loss at iteration 2230 : 0.007413952611386776
Loss at iteration 2240 : 0.009520379826426506
Loss at iteration 2250 : 0.0053895520977675915
Loss at iteration 2260 : 0.004934336524456739
Loss at iteration 2270 : 0.012666313908994198
Loss at iteration 2280 : 0.01531000342220068
Loss at iteration 2290 : 0.013590266928076744
Loss at iteration 2300 : 0.006795661523938179
Loss at iteration 2310 : 0.00868205539882183
Loss at iteration 2320 : 0.017088264226913452
Loss at iteration 2330 : 0.006951645016670227
Loss at iteration 2340 : 0.015010636299848557
Loss at iteration 2350 : 0.006084618158638477
Loss at iteration 2360 : 0.022677114233374596
Loss at iteration 2370 : 0.006493670400232077
Loss at iteration 2380 : 0.005597454495728016
Loss at iteration 2390 : 0.010349569842219353
Loss at iteration 2400 : 0.012396572157740593
Loss at iteration 2410 : 0.01665402576327324
Loss at iteration 2420 : 0.005595033522695303
The SSIM Value is: 0.8511314908663432
The PSNR Value is: 23.12414417266846
the highest SSIM value is: 23.12414417266846
the epoch is: 86
Loss at iteration 10 : 0.02197251468896866
Loss at iteration 20 : 0.010908044874668121
Loss at iteration 30 : 0.010147765278816223
Loss at iteration 40 : 0.00476323626935482
Loss at iteration 50 : 0.010019805282354355
Loss at iteration 60 : 0.011684931814670563
Loss at iteration 70 : 0.0053336587734520435
Loss at iteration 80 : 0.014687850140035152
Loss at iteration 90 : 0.007911363616585732
Loss at iteration 100 : 0.004886475391685963
Loss at iteration 110 : 0.017587173730134964
Loss at iteration 120 : 0.0036158624570816755
Loss at iteration 130 : 0.006904540583491325
Loss at iteration 140 : 0.0056230672635138035
Loss at iteration 150 : 0.00689686369150877
Loss at iteration 160 : 0.006782772950828075
Loss at iteration 170 : 0.015534543432295322
Loss at iteration 180 : 0.020539049059152603
Loss at iteration 190 : 0.00620801979675889
Loss at iteration 200 : 0.0085354745388031
Loss at iteration 210 : 0.00899563916027546
Loss at iteration 220 : 0.008089380338788033
Loss at iteration 230 : 0.005217275582253933
Loss at iteration 240 : 0.0040372032672166824
Loss at iteration 250 : 0.009234491735696793
Loss at iteration 260 : 0.013971870765089989
Loss at iteration 270 : 0.01039905659854412
Loss at iteration 280 : 0.009116721339523792
Loss at iteration 290 : 0.004701108671724796
Loss at iteration 300 : 0.00814555399119854
Loss at iteration 310 : 0.007051926571875811
Loss at iteration 320 : 0.005223526619374752
Loss at iteration 330 : 0.011967997997999191
Loss at iteration 340 : 0.013152539730072021
Loss at iteration 350 : 0.013383913785219193
Loss at iteration 360 : 0.010719685815274715
Loss at iteration 370 : 0.0045552304945886135
Loss at iteration 380 : 0.007722385227680206
Loss at iteration 390 : 0.005009830929338932
Loss at iteration 400 : 0.005864717997610569
Loss at iteration 410 : 0.011212272569537163
Loss at iteration 420 : 0.006428648717701435
Loss at iteration 430 : 0.008121635764837265
Loss at iteration 440 : 0.009157388471066952
Loss at iteration 450 : 0.0068471780978143215
Loss at iteration 460 : 0.009037836454808712
Loss at iteration 470 : 0.005974461790174246
Loss at iteration 480 : 0.005986933130770922
Loss at iteration 490 : 0.008408724330365658
Loss at iteration 500 : 0.009294174611568451
Loss at iteration 510 : 0.003807231318205595
Loss at iteration 520 : 0.014107638038694859
Loss at iteration 530 : 0.007998215034604073
Loss at iteration 540 : 0.006211346480995417
Loss at iteration 550 : 0.00589686119928956
Loss at iteration 560 : 0.01490926556289196
Loss at iteration 570 : 0.013175388798117638
Loss at iteration 580 : 0.011299928650259972
Loss at iteration 590 : 0.008298808708786964
Loss at iteration 600 : 0.003644185373559594
Loss at iteration 610 : 0.007709339261054993
Loss at iteration 620 : 0.006972251459956169
Loss at iteration 630 : 0.008679753169417381
Loss at iteration 640 : 0.007900134660303593
Loss at iteration 650 : 0.008403079584240913
Loss at iteration 660 : 0.016656043007969856
Loss at iteration 670 : 0.009851966984570026
Loss at iteration 680 : 0.008057322353124619
Loss at iteration 690 : 0.005807450972497463
Loss at iteration 700 : 0.014690766111016273
Loss at iteration 710 : 0.003979934379458427
Loss at iteration 720 : 0.0046683745458722115
Loss at iteration 730 : 0.012118076905608177
Loss at iteration 740 : 0.012652384117245674
Loss at iteration 750 : 0.006761833559721708
Loss at iteration 760 : 0.009355878457427025
Loss at iteration 770 : 0.012507481500506401
Loss at iteration 780 : 0.008691190741956234
Loss at iteration 790 : 0.0019564381800591946
Loss at iteration 800 : 0.01872285269200802
Loss at iteration 810 : 0.008971743285655975
Loss at iteration 820 : 0.00794895552098751
Loss at iteration 830 : 0.010554300621151924
Loss at iteration 840 : 0.010595105588436127
Loss at iteration 850 : 0.010795888490974903
Loss at iteration 860 : 0.0063949632458388805
Loss at iteration 870 : 0.010621693916618824
Loss at iteration 880 : 0.01554698683321476
Loss at iteration 890 : 0.022501446306705475
Loss at iteration 900 : 0.007620296906679869
Loss at iteration 910 : 0.00695160124450922
Loss at iteration 920 : 0.01141086034476757
Loss at iteration 930 : 0.007875863462686539
Loss at iteration 940 : 0.005185783375054598
Loss at iteration 950 : 0.014289083890616894
Loss at iteration 960 : 0.007789914496243
Loss at iteration 970 : 0.005693013314157724
Loss at iteration 980 : 0.011957298964262009
Loss at iteration 990 : 0.011841299012303352
Loss at iteration 1000 : 0.008427642285823822
Loss at iteration 1010 : 0.004210032057017088
Loss at iteration 1020 : 0.009101740084588528
Loss at iteration 1030 : 0.004107552580535412
Loss at iteration 1040 : 0.01287228986620903
Loss at iteration 1050 : 0.014782669954001904
Loss at iteration 1060 : 0.009029673412442207
Loss at iteration 1070 : 0.008226319216191769
Loss at iteration 1080 : 0.005718155298382044
Loss at iteration 1090 : 0.011114252731204033
Loss at iteration 1100 : 0.0062135993503034115
Loss at iteration 1110 : 0.013123699463903904
Loss at iteration 1120 : 0.00935925543308258
Loss at iteration 1130 : 0.012756065465509892
Loss at iteration 1140 : 0.008207414299249649
Loss at iteration 1150 : 0.005533948540687561
Loss at iteration 1160 : 0.008891705423593521
Loss at iteration 1170 : 0.027930349111557007
Loss at iteration 1180 : 0.00727383978664875
Loss at iteration 1190 : 0.005768034607172012
Loss at iteration 1200 : 0.009322806261479855
Loss at iteration 1210 : 0.007458288222551346
Loss at iteration 1220 : 0.005414752289652824
Loss at iteration 1230 : 0.011252602562308311
Loss at iteration 1240 : 0.02218618243932724
Loss at iteration 1250 : 0.009697151370346546
Loss at iteration 1260 : 0.019524432718753815
Loss at iteration 1270 : 0.01115158386528492
Loss at iteration 1280 : 0.010297205299139023
Loss at iteration 1290 : 0.0075234780088067055
Loss at iteration 1300 : 0.002382880076766014
Loss at iteration 1310 : 0.0064567681401968
Loss at iteration 1320 : 0.007924827747046947
Loss at iteration 1330 : 0.0033539696596562862
Loss at iteration 1340 : 0.00832341331988573
Loss at iteration 1350 : 0.012183928862214088
Loss at iteration 1360 : 0.014467165805399418
Loss at iteration 1370 : 0.011909600347280502
Loss at iteration 1380 : 0.004336679819971323
Loss at iteration 1390 : 0.005915152840316296
Loss at iteration 1400 : 0.0017232144018635154
Loss at iteration 1410 : 0.008454492315649986
Loss at iteration 1420 : 0.007812148425728083
Loss at iteration 1430 : 0.007471620570868254
Loss at iteration 1440 : 0.007660708390176296
Loss at iteration 1450 : 0.007128262426704168
Loss at iteration 1460 : 0.009256531484425068
Loss at iteration 1470 : 0.016245262697339058
Loss at iteration 1480 : 0.007835695520043373
Loss at iteration 1490 : 0.008559120818972588
Loss at iteration 1500 : 0.005453080870211124
Loss at iteration 1510 : 0.005601896904408932
Loss at iteration 1520 : 0.008092612028121948
Loss at iteration 1530 : 0.007020445540547371
Loss at iteration 1540 : 0.013718659058213234
Loss at iteration 1550 : 0.010817831382155418
Loss at iteration 1560 : 0.007793292868882418
Loss at iteration 1570 : 0.004611491691321135
Loss at iteration 1580 : 0.006050145719200373
Loss at iteration 1590 : 0.014041377231478691
Loss at iteration 1600 : 0.015429302118718624
Loss at iteration 1610 : 0.013195267878472805
Loss at iteration 1620 : 0.01599707640707493
Loss at iteration 1630 : 0.00850358884781599
Loss at iteration 1640 : 0.011320388875901699
Loss at iteration 1650 : 0.009833995252847672
Loss at iteration 1660 : 0.011735104024410248
Loss at iteration 1670 : 0.003090384416282177
Loss at iteration 1680 : 0.006884247530251741
Loss at iteration 1690 : 0.005047434009611607
Loss at iteration 1700 : 0.005688173230737448
Loss at iteration 1710 : 0.006493095774203539
Loss at iteration 1720 : 0.007427297066897154
Loss at iteration 1730 : 0.008791015483438969
Loss at iteration 1740 : 0.014207781292498112
Loss at iteration 1750 : 0.013742746785283089
Loss at iteration 1760 : 0.0062821172177791595
Loss at iteration 1770 : 0.005367991514503956
Loss at iteration 1780 : 0.0048012761399149895
Loss at iteration 1790 : 0.01176134217530489
Loss at iteration 1800 : 0.009018894284963608
Loss at iteration 1810 : 0.0026714601553976536
Loss at iteration 1820 : 0.01239306852221489
Loss at iteration 1830 : 0.004454121459275484
Loss at iteration 1840 : 0.01848028600215912
Loss at iteration 1850 : 0.006307586096227169
Loss at iteration 1860 : 0.006606583017855883
Loss at iteration 1870 : 0.008469703607261181
Loss at iteration 1880 : 0.016310717910528183
Loss at iteration 1890 : 0.008012158796191216
Loss at iteration 1900 : 0.007604769431054592
Loss at iteration 1910 : 0.010258302092552185
Loss at iteration 1920 : 0.00439844885841012
Loss at iteration 1930 : 0.011052543297410011
Loss at iteration 1940 : 0.023625079542398453
Loss at iteration 1950 : 0.01024036854505539
Loss at iteration 1960 : 0.008259913884103298
Loss at iteration 1970 : 0.01443128939718008
Loss at iteration 1980 : 0.0061957817524671555
Loss at iteration 1990 : 0.0074814241379499435
Loss at iteration 2000 : 0.008591745048761368
Loss at iteration 2010 : 0.0036288006231188774
Loss at iteration 2020 : 0.009130069054663181
Loss at iteration 2030 : 0.007227414753288031
Loss at iteration 2040 : 0.009482831694185734
Loss at iteration 2050 : 0.006645317655056715
Loss at iteration 2060 : 0.006666562519967556
Loss at iteration 2070 : 0.009162521921098232
Loss at iteration 2080 : 0.010044209659099579
Loss at iteration 2090 : 0.006452268920838833
Loss at iteration 2100 : 0.009563589468598366
Loss at iteration 2110 : 0.013294534757733345
Loss at iteration 2120 : 0.01189940795302391
Loss at iteration 2130 : 0.012900197878479958
Loss at iteration 2140 : 0.013015137985348701
Loss at iteration 2150 : 0.006815496366471052
Loss at iteration 2160 : 0.00694871274754405
Loss at iteration 2170 : 0.006754681468009949
Loss at iteration 2180 : 0.009018166922032833
Loss at iteration 2190 : 0.004497298505157232
Loss at iteration 2200 : 0.008025498129427433
Loss at iteration 2210 : 0.006304010283201933
Loss at iteration 2220 : 0.012413685210049152
Loss at iteration 2230 : 0.009225679561495781
Loss at iteration 2240 : 0.008664725348353386
Loss at iteration 2250 : 0.00588814914226532
Loss at iteration 2260 : 0.019786659628152847
Loss at iteration 2270 : 0.013181588612496853
Loss at iteration 2280 : 0.005753015633672476
Loss at iteration 2290 : 0.008047746494412422
Loss at iteration 2300 : 0.008392667397856712
Loss at iteration 2310 : 0.007661956362426281
Loss at iteration 2320 : 0.010990962386131287
Loss at iteration 2330 : 0.00851182360202074
Loss at iteration 2340 : 0.013609779067337513
Loss at iteration 2350 : 0.03615135699510574
Loss at iteration 2360 : 0.011496242135763168
Loss at iteration 2370 : 0.01843520812690258
Loss at iteration 2380 : 0.016223374754190445
Loss at iteration 2390 : 0.005300859920680523
Loss at iteration 2400 : 0.012380866333842278
Loss at iteration 2410 : 0.007994544692337513
Loss at iteration 2420 : 0.010672414675354958
The SSIM Value is: 0.8383455912272135
The PSNR Value is: 21.49108206431071
the epoch is: 87
Loss at iteration 10 : 0.00811171904206276
Loss at iteration 20 : 0.005459003150463104
Loss at iteration 30 : 0.007845479995012283
Loss at iteration 40 : 0.007788824383169413
Loss at iteration 50 : 0.010695390403270721
Loss at iteration 60 : 0.010039148852229118
Loss at iteration 70 : 0.012321456335484982
Loss at iteration 80 : 0.011515546590089798
Loss at iteration 90 : 0.008626455441117287
Loss at iteration 100 : 0.00913294404745102
Loss at iteration 110 : 0.006673178635537624
Loss at iteration 120 : 0.014970443211495876
Loss at iteration 130 : 0.007829682901501656
Loss at iteration 140 : 0.008627359755337238
Loss at iteration 150 : 0.010737498290836811
Loss at iteration 160 : 0.01282883808016777
Loss at iteration 170 : 0.008889608085155487
Loss at iteration 180 : 0.005913744680583477
Loss at iteration 190 : 0.008619165979325771
Loss at iteration 200 : 0.008485994301736355
Loss at iteration 210 : 0.01811062917113304
Loss at iteration 220 : 0.009357714094221592
Loss at iteration 230 : 0.014249445870518684
Loss at iteration 240 : 0.014272529631853104
Loss at iteration 250 : 0.016818206757307053
Loss at iteration 260 : 0.02826015092432499
Loss at iteration 270 : 0.009551556780934334
Loss at iteration 280 : 0.009951435960829258
Loss at iteration 290 : 0.013153663836419582
Loss at iteration 300 : 0.02276952564716339
Loss at iteration 310 : 0.012824075296521187
Loss at iteration 320 : 0.0065015098080039024
Loss at iteration 330 : 0.00911051407456398
Loss at iteration 340 : 0.00975580234080553
Loss at iteration 350 : 0.0038284058682620525
Loss at iteration 360 : 0.011337625794112682
Loss at iteration 370 : 0.011640092357993126
Loss at iteration 380 : 0.012846000492572784
Loss at iteration 390 : 0.014994055032730103
Loss at iteration 400 : 0.005122210830450058
Loss at iteration 410 : 0.004622808191925287
Loss at iteration 420 : 0.0112967099994421
Loss at iteration 430 : 0.011258727870881557
Loss at iteration 440 : 0.005715223960578442
Loss at iteration 450 : 0.0030576782301068306
Loss at iteration 460 : 0.003167038783431053
Loss at iteration 470 : 0.011773670092225075
Loss at iteration 480 : 0.010210547596216202
Loss at iteration 490 : 0.008000382222235203
Loss at iteration 500 : 0.00454529095441103
Loss at iteration 510 : 0.008635210804641247
Loss at iteration 520 : 0.008850255981087685
Loss at iteration 530 : 0.006543283816426992
Loss at iteration 540 : 0.008274686522781849
Loss at iteration 550 : 0.005758210085332394
Loss at iteration 560 : 0.003222919534891844
Loss at iteration 570 : 0.00917016714811325
Loss at iteration 580 : 0.0060589369386434555
Loss at iteration 590 : 0.01218587439507246
Loss at iteration 600 : 0.003923673648387194
Loss at iteration 610 : 0.010797028429806232
Loss at iteration 620 : 0.004026105161756277
Loss at iteration 630 : 0.003683404065668583
Loss at iteration 640 : 0.012687206268310547
Loss at iteration 650 : 0.008986295200884342
Loss at iteration 660 : 0.016329003497958183
Loss at iteration 670 : 0.012786995619535446
Loss at iteration 680 : 0.0016066569369286299
Loss at iteration 690 : 0.003028909210115671
Loss at iteration 700 : 0.006170433014631271
Loss at iteration 710 : 0.007349926047027111
Loss at iteration 720 : 0.004287050571292639
Loss at iteration 730 : 0.00976803433150053
Loss at iteration 740 : 0.01203866209834814
Loss at iteration 750 : 0.006121434736996889
Loss at iteration 760 : 0.004473832435905933
Loss at iteration 770 : 0.011854148469865322
Loss at iteration 780 : 0.011132469400763512
Loss at iteration 790 : 0.010548807680606842
Loss at iteration 800 : 0.015090434812009335
Loss at iteration 810 : 0.005052302032709122
Loss at iteration 820 : 0.007840415462851524
Loss at iteration 830 : 0.010940873995423317
Loss at iteration 840 : 0.005691268015652895
Loss at iteration 850 : 0.008212918415665627
Loss at iteration 860 : 0.01688029244542122
Loss at iteration 870 : 0.007919092662632465
Loss at iteration 880 : 0.004011399112641811
Loss at iteration 890 : 0.013206662610173225
Loss at iteration 900 : 0.007665074430406094
Loss at iteration 910 : 0.00899579655379057
Loss at iteration 920 : 0.01475158054381609
Loss at iteration 930 : 0.005351989064365625
Loss at iteration 940 : 0.006415908224880695
Loss at iteration 950 : 0.023760948330163956
Loss at iteration 960 : 0.00892721489071846
Loss at iteration 970 : 0.006697961129248142
Loss at iteration 980 : 0.0031178612262010574
Loss at iteration 990 : 0.008615577593445778
Loss at iteration 1000 : 0.004258078057318926
Loss at iteration 1010 : 0.008908792398869991
Loss at iteration 1020 : 0.012210615910589695
Loss at iteration 1030 : 0.007910340093076229
Loss at iteration 1040 : 0.005251810885965824
Loss at iteration 1050 : 0.004562098998576403
Loss at iteration 1060 : 0.00931906420737505
Loss at iteration 1070 : 0.013058368116617203
Loss at iteration 1080 : 0.01955467276275158
Loss at iteration 1090 : 0.007314866408705711
Loss at iteration 1100 : 0.014169512316584587
Loss at iteration 1110 : 0.006696540862321854
Loss at iteration 1120 : 0.013442002236843109
Loss at iteration 1130 : 0.010922255925834179
Loss at iteration 1140 : 0.005290524568408728
Loss at iteration 1150 : 0.007368383929133415
Loss at iteration 1160 : 0.005025974474847317
Loss at iteration 1170 : 0.011949130333960056
Loss at iteration 1180 : 0.008048107847571373
Loss at iteration 1190 : 0.0056686075404286385
Loss at iteration 1200 : 0.026384463533759117
Loss at iteration 1210 : 0.004667468834668398
Loss at iteration 1220 : 0.004149595275521278
Loss at iteration 1230 : 0.00880899652838707
Loss at iteration 1240 : 0.002994426293298602
Loss at iteration 1250 : 0.012968989089131355
Loss at iteration 1260 : 0.006009007804095745
Loss at iteration 1270 : 0.010095851495862007
Loss at iteration 1280 : 0.01232399046421051
Loss at iteration 1290 : 0.01156618446111679
Loss at iteration 1300 : 0.005156295374035835
Loss at iteration 1310 : 0.014536704868078232
Loss at iteration 1320 : 0.009572731330990791
Loss at iteration 1330 : 0.015313902869820595
Loss at iteration 1340 : 0.013630522415041924
Loss at iteration 1350 : 0.005636292975395918
Loss at iteration 1360 : 0.01087278500199318
Loss at iteration 1370 : 0.0028431888204067945
Loss at iteration 1380 : 0.005743394140154123
Loss at iteration 1390 : 0.016037888824939728
Loss at iteration 1400 : 0.0056953891180455685
Loss at iteration 1410 : 0.008881714195013046
Loss at iteration 1420 : 0.00982321985065937
Loss at iteration 1430 : 0.006323148030787706
Loss at iteration 1440 : 0.007265164516866207
Loss at iteration 1450 : 0.010752581059932709
Loss at iteration 1460 : 0.011953332461416721
Loss at iteration 1470 : 0.01247368659824133
Loss at iteration 1480 : 0.010122264735400677
Loss at iteration 1490 : 0.009056856855750084
Loss at iteration 1500 : 0.01768786646425724
Loss at iteration 1510 : 0.02342582494020462
Loss at iteration 1520 : 0.013149760663509369
Loss at iteration 1530 : 0.005289037711918354
Loss at iteration 1540 : 0.0065398141741752625
Loss at iteration 1550 : 0.00805102288722992
Loss at iteration 1560 : 0.004922921769320965
Loss at iteration 1570 : 0.005182282533496618
Loss at iteration 1580 : 0.011011054739356041
Loss at iteration 1590 : 0.005251587834209204
Loss at iteration 1600 : 0.0091202761977911
Loss at iteration 1610 : 0.004775546491146088
Loss at iteration 1620 : 0.00963161326944828
Loss at iteration 1630 : 0.006205047480762005
Loss at iteration 1640 : 0.0062345354817807674
Loss at iteration 1650 : 0.003764266613870859
Loss at iteration 1660 : 0.009505289606750011
Loss at iteration 1670 : 0.00750680360943079
Loss at iteration 1680 : 0.014801017940044403
Loss at iteration 1690 : 0.008190975524485111
Loss at iteration 1700 : 0.011004824191331863
Loss at iteration 1710 : 0.01159969624131918
Loss at iteration 1720 : 0.01608400233089924
Loss at iteration 1730 : 0.01217885036021471
Loss at iteration 1740 : 0.005534895695745945
Loss at iteration 1750 : 0.0048780315555632114
Loss at iteration 1760 : 0.01695300079882145
Loss at iteration 1770 : 0.014490624889731407
Loss at iteration 1780 : 0.021910540759563446
Loss at iteration 1790 : 0.01152135245501995
Loss at iteration 1800 : 0.006574406288564205
Loss at iteration 1810 : 0.012407895177602768
Loss at iteration 1820 : 0.004531410057097673
Loss at iteration 1830 : 0.0027756544295698404
Loss at iteration 1840 : 0.006327593699097633
Loss at iteration 1850 : 0.025803694501519203
Loss at iteration 1860 : 0.012733357958495617
Loss at iteration 1870 : 0.008661339059472084
Loss at iteration 1880 : 0.011773903854191303
Loss at iteration 1890 : 0.006931213662028313
Loss at iteration 1900 : 0.009264710359275341
Loss at iteration 1910 : 0.00546769006177783
Loss at iteration 1920 : 0.014051257632672787
Loss at iteration 1930 : 0.015641625970602036
Loss at iteration 1940 : 0.004627959802746773
Loss at iteration 1950 : 0.0066337198950350285
Loss at iteration 1960 : 0.00878391694277525
Loss at iteration 1970 : 0.012338546104729176
Loss at iteration 1980 : 0.004577334970235825
Loss at iteration 1990 : 0.022591639310121536
Loss at iteration 2000 : 0.010194873437285423
Loss at iteration 2010 : 0.013616747222840786
Loss at iteration 2020 : 0.006609240546822548
Loss at iteration 2030 : 0.012601752765476704
Loss at iteration 2040 : 0.004927823320031166
Loss at iteration 2050 : 0.009878728538751602
Loss at iteration 2060 : 0.0054071503691375256
Loss at iteration 2070 : 0.0036490224301815033
Loss at iteration 2080 : 0.0029711928218603134
Loss at iteration 2090 : 0.011184209026396275
Loss at iteration 2100 : 0.018718000501394272
Loss at iteration 2110 : 0.007259001024067402
Loss at iteration 2120 : 0.0057045468129217625
Loss at iteration 2130 : 0.008995135314762592
Loss at iteration 2140 : 0.015377745032310486
Loss at iteration 2150 : 0.006352235563099384
Loss at iteration 2160 : 0.0029380263295024633
Loss at iteration 2170 : 0.007891491055488586
Loss at iteration 2180 : 0.018480392172932625
Loss at iteration 2190 : 0.014347366988658905
Loss at iteration 2200 : 0.011784026399254799
Loss at iteration 2210 : 0.006500082090497017
Loss at iteration 2220 : 0.006667574867606163
Loss at iteration 2230 : 0.021349137648940086
Loss at iteration 2240 : 0.003983364440500736
Loss at iteration 2250 : 0.009236594662070274
Loss at iteration 2260 : 0.010415266267955303
Loss at iteration 2270 : 0.007366560865193605
Loss at iteration 2280 : 0.008332301862537861
Loss at iteration 2290 : 0.007290678098797798
Loss at iteration 2300 : 0.003805924439802766
Loss at iteration 2310 : 0.005985813681036234
Loss at iteration 2320 : 0.011139106005430222
Loss at iteration 2330 : 0.01232148241251707
Loss at iteration 2340 : 0.005969081539660692
Loss at iteration 2350 : 0.015299303457140923
Loss at iteration 2360 : 0.009442804381251335
Loss at iteration 2370 : 0.010244852863252163
Loss at iteration 2380 : 0.011632243171334267
Loss at iteration 2390 : 0.0032979552634060383
Loss at iteration 2400 : 0.01111296471208334
Loss at iteration 2410 : 0.0239473357796669
Loss at iteration 2420 : 0.01082080602645874
The SSIM Value is: 0.8435021281242371
The PSNR Value is: 22.060635121663413
the epoch is: 88
Loss at iteration 10 : 0.006569089833647013
Loss at iteration 20 : 0.006362980231642723
Loss at iteration 30 : 0.01309880055487156
Loss at iteration 40 : 0.009322124533355236
Loss at iteration 50 : 0.003817636054009199
Loss at iteration 60 : 0.00556490384042263
Loss at iteration 70 : 0.014161702245473862
Loss at iteration 80 : 0.01899224892258644
Loss at iteration 90 : 0.0061347829177975655
Loss at iteration 100 : 0.01060298178344965
Loss at iteration 110 : 0.01354166865348816
Loss at iteration 120 : 0.004300569649785757
Loss at iteration 130 : 0.020656166598200798
Loss at iteration 140 : 0.005505352281033993
Loss at iteration 150 : 0.009255241602659225
Loss at iteration 160 : 0.0077827088534832
Loss at iteration 170 : 0.008075700141489506
Loss at iteration 180 : 0.011272932402789593
Loss at iteration 190 : 0.008911151438951492
Loss at iteration 200 : 0.017171751707792282
Loss at iteration 210 : 0.021440928801894188
Loss at iteration 220 : 0.007154136896133423
Loss at iteration 230 : 0.011598484590649605
Loss at iteration 240 : 0.001823747530579567
Loss at iteration 250 : 0.00784420408308506
Loss at iteration 260 : 0.012881838716566563
Loss at iteration 270 : 0.005069064907729626
Loss at iteration 280 : 0.011151173152029514
Loss at iteration 290 : 0.010283011011779308
Loss at iteration 300 : 0.008451453410089016
Loss at iteration 310 : 0.005894767586141825
Loss at iteration 320 : 0.005971907638013363
Loss at iteration 330 : 0.009173411875963211
Loss at iteration 340 : 0.006529751233756542
Loss at iteration 350 : 0.020732412114739418
Loss at iteration 360 : 0.004144773352891207
Loss at iteration 370 : 0.008693545125424862
Loss at iteration 380 : 0.00894214492291212
Loss at iteration 390 : 0.008255903609097004
Loss at iteration 400 : 0.007187680806964636
Loss at iteration 410 : 0.010609474033117294
Loss at iteration 420 : 0.018266327679157257
Loss at iteration 430 : 0.0035537290386855602
Loss at iteration 440 : 0.00761793926358223
Loss at iteration 450 : 0.005345561075955629
Loss at iteration 460 : 0.0074569834396243095
Loss at iteration 470 : 0.007819889113307
Loss at iteration 480 : 0.00676510576158762
Loss at iteration 490 : 0.007643420249223709
Loss at iteration 500 : 0.006699488032609224
Loss at iteration 510 : 0.01179486233741045
Loss at iteration 520 : 0.005923795513808727
Loss at iteration 530 : 0.004389903973788023
Loss at iteration 540 : 0.010409950278699398
Loss at iteration 550 : 0.00529977073892951
Loss at iteration 560 : 0.007819974794983864
Loss at iteration 570 : 0.005359006114304066
Loss at iteration 580 : 0.005797639489173889
Loss at iteration 590 : 0.018207425251603127
Loss at iteration 600 : 0.009663593024015427
Loss at iteration 610 : 0.014005198143422604
Loss at iteration 620 : 0.009412167593836784
Loss at iteration 630 : 0.011507142335176468
Loss at iteration 640 : 0.0033491477370262146
Loss at iteration 650 : 0.008653173223137856
Loss at iteration 660 : 0.0052066524513065815
Loss at iteration 670 : 0.007233405951410532
Loss at iteration 680 : 0.008145119063556194
Loss at iteration 690 : 0.009360410273075104
Loss at iteration 700 : 0.010885825380682945
Loss at iteration 710 : 0.004054537974298
Loss at iteration 720 : 0.012755084782838821
Loss at iteration 730 : 0.010771892964839935
Loss at iteration 740 : 0.016388867050409317
Loss at iteration 750 : 0.008589223958551884
Loss at iteration 760 : 0.015479162335395813
Loss at iteration 770 : 0.026370275765657425
Loss at iteration 780 : 0.013011908158659935
Loss at iteration 790 : 0.002431682776659727
Loss at iteration 800 : 0.01660543493926525
Loss at iteration 810 : 0.008115136995911598
Loss at iteration 820 : 0.009953156113624573
Loss at iteration 830 : 0.0034739116672426462
Loss at iteration 840 : 0.011131811887025833
Loss at iteration 850 : 0.010837705805897713
Loss at iteration 860 : 0.00747889606282115
Loss at iteration 870 : 0.010462645441293716
Loss at iteration 880 : 0.005893743596971035
Loss at iteration 890 : 0.009346164762973785
Loss at iteration 900 : 0.002857566811144352
Loss at iteration 910 : 0.006431053392589092
Loss at iteration 920 : 0.009047476574778557
Loss at iteration 930 : 0.006520354188978672
Loss at iteration 940 : 0.008089128881692886
Loss at iteration 950 : 0.005974444095045328
Loss at iteration 960 : 0.010156181640923023
Loss at iteration 970 : 0.01109853945672512
Loss at iteration 980 : 0.01151398103684187
Loss at iteration 990 : 0.0029567554593086243
Loss at iteration 1000 : 0.008993402123451233
Loss at iteration 1010 : 0.01290149800479412
Loss at iteration 1020 : 0.006427829619497061
Loss at iteration 1030 : 0.007053909357637167
Loss at iteration 1040 : 0.007863825187087059
Loss at iteration 1050 : 0.01080064196139574
Loss at iteration 1060 : 0.00582507811486721
Loss at iteration 1070 : 0.012650178745388985
Loss at iteration 1080 : 0.01083344779908657
Loss at iteration 1090 : 0.007893918082118034
Loss at iteration 1100 : 0.010870862752199173
Loss at iteration 1110 : 0.007593739312142134
Loss at iteration 1120 : 0.0059304265305399895
Loss at iteration 1130 : 0.015316379256546497
Loss at iteration 1140 : 0.0052717081271111965
Loss at iteration 1150 : 0.0027588680386543274
Loss at iteration 1160 : 0.005943682044744492
Loss at iteration 1170 : 0.009084089659154415
Loss at iteration 1180 : 0.0055465386249125
Loss at iteration 1190 : 0.012062499299645424
Loss at iteration 1200 : 0.006691671907901764
Loss at iteration 1210 : 0.00854388065636158
Loss at iteration 1220 : 0.006682234816253185
Loss at iteration 1230 : 0.008654197677969933
Loss at iteration 1240 : 0.015056004747748375
Loss at iteration 1250 : 0.015035854652523994
Loss at iteration 1260 : 0.0025535242166370153
Loss at iteration 1270 : 0.011047271080315113
Loss at iteration 1280 : 0.007219066843390465
Loss at iteration 1290 : 0.00929463841021061
Loss at iteration 1300 : 0.014772854745388031
Loss at iteration 1310 : 0.0029351855628192425
Loss at iteration 1320 : 0.005540015641599894
Loss at iteration 1330 : 0.009289246052503586
Loss at iteration 1340 : 0.004735215101391077
Loss at iteration 1350 : 0.007143981754779816
Loss at iteration 1360 : 0.009162360802292824
Loss at iteration 1370 : 0.009614231064915657
Loss at iteration 1380 : 0.007931064814329147
Loss at iteration 1390 : 0.006300289649516344
Loss at iteration 1400 : 0.008145916275680065
Loss at iteration 1410 : 0.007594267372041941
Loss at iteration 1420 : 0.009064573794603348
Loss at iteration 1430 : 0.007571005262434483
Loss at iteration 1440 : 0.013579653576016426
Loss at iteration 1450 : 0.002711720997467637
Loss at iteration 1460 : 0.0072044567205011845
Loss at iteration 1470 : 0.00935595016926527
Loss at iteration 1480 : 0.007395679131150246
Loss at iteration 1490 : 0.012672258540987968
Loss at iteration 1500 : 0.014210611581802368
Loss at iteration 1510 : 0.009922017343342304
Loss at iteration 1520 : 0.008139698766171932
Loss at iteration 1530 : 0.010671352967619896
Loss at iteration 1540 : 0.005792604759335518
Loss at iteration 1550 : 0.01167516503483057
Loss at iteration 1560 : 0.0062449537217617035
Loss at iteration 1570 : 0.005747566930949688
Loss at iteration 1580 : 0.00766102597117424
Loss at iteration 1590 : 0.003665659110993147
Loss at iteration 1600 : 0.004932225216180086
Loss at iteration 1610 : 0.003259582445025444
Loss at iteration 1620 : 0.005493236239999533
Loss at iteration 1630 : 0.0089986901730299
Loss at iteration 1640 : 0.007682576309889555
Loss at iteration 1650 : 0.003435630351305008
Loss at iteration 1660 : 0.0031746160238981247
Loss at iteration 1670 : 0.006422827485948801
Loss at iteration 1680 : 0.010339172556996346
Loss at iteration 1690 : 0.00857274979352951
Loss at iteration 1700 : 0.007236236706376076
Loss at iteration 1710 : 0.005827626213431358
Loss at iteration 1720 : 0.011028783395886421
Loss at iteration 1730 : 0.004891463089734316
Loss at iteration 1740 : 0.004142304882407188
Loss at iteration 1750 : 0.002673882292583585
Loss at iteration 1760 : 0.019130436703562737
Loss at iteration 1770 : 0.00975961983203888
Loss at iteration 1780 : 0.011508714407682419
Loss at iteration 1790 : 0.009612799622118473
Loss at iteration 1800 : 0.007838907651603222
Loss at iteration 1810 : 0.006042066961526871
Loss at iteration 1820 : 0.029557406902313232
Loss at iteration 1830 : 0.0072594936937093735
Loss at iteration 1840 : 0.005868622101843357
Loss at iteration 1850 : 0.018808741122484207
Loss at iteration 1860 : 0.00935367587953806
Loss at iteration 1870 : 0.010279422625899315
Loss at iteration 1880 : 0.005633368622511625
Loss at iteration 1890 : 0.007337729446589947
Loss at iteration 1900 : 0.005284295417368412
Loss at iteration 1910 : 0.008877863176167011
Loss at iteration 1920 : 0.005090237129479647
Loss at iteration 1930 : 0.00845435168594122
Loss at iteration 1940 : 0.02151748351752758
Loss at iteration 1950 : 0.0065659028477966785
Loss at iteration 1960 : 0.01404534000903368
Loss at iteration 1970 : 0.005146385170519352
Loss at iteration 1980 : 0.011014016345143318
Loss at iteration 1990 : 0.0042372955940663815
Loss at iteration 2000 : 0.005755548365414143
Loss at iteration 2010 : 0.0023588957265019417
Loss at iteration 2020 : 0.005829296540468931
Loss at iteration 2030 : 0.00480908527970314
Loss at iteration 2040 : 0.018047897145152092
Loss at iteration 2050 : 0.00967628788203001
Loss at iteration 2060 : 0.01960914395749569
Loss at iteration 2070 : 0.021477119997143745
Loss at iteration 2080 : 0.005183222703635693
Loss at iteration 2090 : 0.008257280103862286
Loss at iteration 2100 : 0.007060997653752565
Loss at iteration 2110 : 0.009227418340742588
Loss at iteration 2120 : 0.018496572971343994
Loss at iteration 2130 : 0.007515068165957928
Loss at iteration 2140 : 0.0135301873087883
Loss at iteration 2150 : 0.009075522422790527
Loss at iteration 2160 : 0.0076807779259979725
Loss at iteration 2170 : 0.01050732284784317
Loss at iteration 2180 : 0.01189190149307251
Loss at iteration 2190 : 0.0177453700453043
Loss at iteration 2200 : 0.006301007699221373
Loss at iteration 2210 : 0.009043514728546143
Loss at iteration 2220 : 0.009839285165071487
Loss at iteration 2230 : 0.010930015705525875
Loss at iteration 2240 : 0.008470190688967705
Loss at iteration 2250 : 0.023237669840455055
Loss at iteration 2260 : 0.01149788498878479
Loss at iteration 2270 : 0.007759098894894123
Loss at iteration 2280 : 0.00572788342833519
Loss at iteration 2290 : 0.01020017359405756
Loss at iteration 2300 : 0.00803657528012991
Loss at iteration 2310 : 0.010611820966005325
Loss at iteration 2320 : 0.011485316790640354
Loss at iteration 2330 : 0.010881267488002777
Loss at iteration 2340 : 0.00774794165045023
Loss at iteration 2350 : 0.007699555717408657
Loss at iteration 2360 : 0.011710255406796932
Loss at iteration 2370 : 0.011472155340015888
Loss at iteration 2380 : 0.009276751428842545
Loss at iteration 2390 : 0.004367813002318144
Loss at iteration 2400 : 0.005374570842832327
Loss at iteration 2410 : 0.006174277514219284
Loss at iteration 2420 : 0.004798941779881716
The SSIM Value is: 0.8490868409474691
The PSNR Value is: 22.48501828511556
the epoch is: 89
Loss at iteration 10 : 0.006087070796638727
Loss at iteration 20 : 0.0071966093964874744
Loss at iteration 30 : 0.013386932201683521
Loss at iteration 40 : 0.009811787866055965
Loss at iteration 50 : 0.016338607296347618
Loss at iteration 60 : 0.007369108498096466
Loss at iteration 70 : 0.007343042176216841
Loss at iteration 80 : 0.01247622724622488
Loss at iteration 90 : 0.005895689595490694
Loss at iteration 100 : 0.01833612658083439
Loss at iteration 110 : 0.0056809065863490105
Loss at iteration 120 : 0.009998934343457222
Loss at iteration 130 : 0.008747939020395279
Loss at iteration 140 : 0.006185052916407585
Loss at iteration 150 : 0.01212590467184782
Loss at iteration 160 : 0.009506059810519218
Loss at iteration 170 : 0.006626399699598551
Loss at iteration 180 : 0.009862885810434818
Loss at iteration 190 : 0.00674236286431551
Loss at iteration 200 : 0.0063835810869932175
Loss at iteration 210 : 0.006651849485933781
Loss at iteration 220 : 0.010750336572527885
Loss at iteration 230 : 0.007616793736815453
Loss at iteration 240 : 0.01007725391536951
Loss at iteration 250 : 0.006899813190102577
Loss at iteration 260 : 0.015175720676779747
Loss at iteration 270 : 0.01132036093622446
Loss at iteration 280 : 0.007743271067738533
Loss at iteration 290 : 0.01006375066936016
Loss at iteration 300 : 0.009793666191399097
Loss at iteration 310 : 0.0069707720540463924
Loss at iteration 320 : 0.006804553791880608
Loss at iteration 330 : 0.007151137106120586
Loss at iteration 340 : 0.005005411803722382
Loss at iteration 350 : 0.00836862064898014
Loss at iteration 360 : 0.009011615067720413
Loss at iteration 370 : 0.014968937262892723
Loss at iteration 380 : 0.0106044365093112
Loss at iteration 390 : 0.005727809388190508
Loss at iteration 400 : 0.0044654845260083675
Loss at iteration 410 : 0.0044482131488621235
Loss at iteration 420 : 0.0057168928906321526
Loss at iteration 430 : 0.01635286584496498
Loss at iteration 440 : 0.007971118204295635
Loss at iteration 450 : 0.007156373467296362
Loss at iteration 460 : 0.008119514212012291
Loss at iteration 470 : 0.013467622920870781
Loss at iteration 480 : 0.007334365509450436
Loss at iteration 490 : 0.010223657824099064
Loss at iteration 500 : 0.008792639710009098
Loss at iteration 510 : 0.00909892562776804
Loss at iteration 520 : 0.005538884084671736
Loss at iteration 530 : 0.010966910049319267
Loss at iteration 540 : 0.01578182354569435
Loss at iteration 550 : 0.009881566278636456
Loss at iteration 560 : 0.005507254973053932
Loss at iteration 570 : 0.01689116284251213
Loss at iteration 580 : 0.006597084924578667
Loss at iteration 590 : 0.0057045044377446175
Loss at iteration 600 : 0.024589311331510544
Loss at iteration 610 : 0.004953731782734394
Loss at iteration 620 : 0.010365999303758144
Loss at iteration 630 : 0.009458106011152267
Loss at iteration 640 : 0.009788382798433304
Loss at iteration 650 : 0.010674597695469856
Loss at iteration 660 : 0.009695839136838913
Loss at iteration 670 : 0.01410597562789917
Loss at iteration 680 : 0.014641575515270233
Loss at iteration 690 : 0.0180349163711071
Loss at iteration 700 : 0.007771541364490986
Loss at iteration 710 : 0.008395439013838768
Loss at iteration 720 : 0.01221458613872528
Loss at iteration 730 : 0.0051461257971823215
Loss at iteration 740 : 0.007185354828834534
Loss at iteration 750 : 0.0130713926628232
Loss at iteration 760 : 0.008975053206086159
Loss at iteration 770 : 0.006985938176512718
Loss at iteration 780 : 0.008533273823559284
Loss at iteration 790 : 0.009347707033157349
Loss at iteration 800 : 0.012495267204940319
Loss at iteration 810 : 0.007313375361263752
Loss at iteration 820 : 0.03330925852060318
Loss at iteration 830 : 0.021432379260659218
Loss at iteration 840 : 0.004540143068879843
Loss at iteration 850 : 0.0067376745864748955
Loss at iteration 860 : 0.004488753154873848
Loss at iteration 870 : 0.006606030277907848
Loss at iteration 880 : 0.0022814925760030746
Loss at iteration 890 : 0.0038994126953184605
Loss at iteration 900 : 0.002756810747087002
Loss at iteration 910 : 0.005002831108868122
Loss at iteration 920 : 0.014992458745837212
Loss at iteration 930 : 0.020050689578056335
Loss at iteration 940 : 0.007204003632068634
Loss at iteration 950 : 0.010452153161168098
Loss at iteration 960 : 0.009038821794092655
Loss at iteration 970 : 0.0032387308310717344
Loss at iteration 980 : 0.02195565588772297
Loss at iteration 990 : 0.0062362514436244965
Loss at iteration 1000 : 0.011855654418468475
Loss at iteration 1010 : 0.011800587177276611
Loss at iteration 1020 : 0.007057091221213341
Loss at iteration 1030 : 0.003961686976253986
Loss at iteration 1040 : 0.006222694180905819
Loss at iteration 1050 : 0.01015220396220684
Loss at iteration 1060 : 0.0025717688258737326
Loss at iteration 1070 : 0.016419626772403717
Loss at iteration 1080 : 0.013770264573395252
Loss at iteration 1090 : 0.006118824705481529
Loss at iteration 1100 : 0.011541238985955715
Loss at iteration 1110 : 0.008088162168860435
Loss at iteration 1120 : 0.008889466524124146
Loss at iteration 1130 : 0.01101867575198412
Loss at iteration 1140 : 0.0027108865324407816
Loss at iteration 1150 : 0.011960706673562527
Loss at iteration 1160 : 0.011211564764380455
Loss at iteration 1170 : 0.009832685813307762
Loss at iteration 1180 : 0.008638247847557068
Loss at iteration 1190 : 0.015147209167480469
Loss at iteration 1200 : 0.010483737103641033
Loss at iteration 1210 : 0.007351478096097708
Loss at iteration 1220 : 0.0036222455091774464
Loss at iteration 1230 : 0.010102979838848114
Loss at iteration 1240 : 0.011122111231088638
Loss at iteration 1250 : 0.006076894700527191
Loss at iteration 1260 : 0.00747606111690402
Loss at iteration 1270 : 0.015993863344192505
Loss at iteration 1280 : 0.002839609980583191
Loss at iteration 1290 : 0.009159866720438004
Loss at iteration 1300 : 0.005819470621645451
Loss at iteration 1310 : 0.012071814388036728
Loss at iteration 1320 : 0.004111574497073889
Loss at iteration 1330 : 0.004418366122990847
Loss at iteration 1340 : 0.00778519781306386
Loss at iteration 1350 : 0.013175275176763535
Loss at iteration 1360 : 0.006117693614214659
Loss at iteration 1370 : 0.012065024115145206
Loss at iteration 1380 : 0.004060233477503061
Loss at iteration 1390 : 0.006673312745988369
Loss at iteration 1400 : 0.024983296170830727
Loss at iteration 1410 : 0.013609947636723518
Loss at iteration 1420 : 0.015297996811568737
Loss at iteration 1430 : 0.01685020513832569
Loss at iteration 1440 : 0.01953897252678871
Loss at iteration 1450 : 0.008742340840399265
Loss at iteration 1460 : 0.010219535790383816
Loss at iteration 1470 : 0.008097555488348007
Loss at iteration 1480 : 0.00996662862598896
Loss at iteration 1490 : 0.008091761730611324
Loss at iteration 1500 : 0.011017528362572193
Loss at iteration 1510 : 0.009515790268778801
Loss at iteration 1520 : 0.006110166199505329
Loss at iteration 1530 : 0.010800554417073727
Loss at iteration 1540 : 0.006921588443219662
Loss at iteration 1550 : 0.0068774111568927765
Loss at iteration 1560 : 0.005459519103169441
Loss at iteration 1570 : 0.01247299276292324
Loss at iteration 1580 : 0.016773615032434464
Loss at iteration 1590 : 0.004822894930839539
Loss at iteration 1600 : 0.005598667077720165
Loss at iteration 1610 : 0.004798447247594595
Loss at iteration 1620 : 0.009708501398563385
Loss at iteration 1630 : 0.00902131199836731
Loss at iteration 1640 : 0.0048234788700938225
Loss at iteration 1650 : 0.018619297072291374
Loss at iteration 1660 : 0.007902746088802814
Loss at iteration 1670 : 0.0053428239189088345
Loss at iteration 1680 : 0.003750026226043701
Loss at iteration 1690 : 0.011801081709563732
Loss at iteration 1700 : 0.011375166475772858
Loss at iteration 1710 : 0.005803073290735483
Loss at iteration 1720 : 0.009058711118996143
Loss at iteration 1730 : 0.0068213073536753654
Loss at iteration 1740 : 0.007140841335058212
Loss at iteration 1750 : 0.008048396557569504
Loss at iteration 1760 : 0.014387661591172218
Loss at iteration 1770 : 0.015238219872117043
Loss at iteration 1780 : 0.0049317521043121815
Loss at iteration 1790 : 0.012995841912925243
Loss at iteration 1800 : 0.004745704587548971
Loss at iteration 1810 : 0.007887747138738632
Loss at iteration 1820 : 0.03704218566417694
Loss at iteration 1830 : 0.008098507300019264
Loss at iteration 1840 : 0.011594478040933609
Loss at iteration 1850 : 0.008784249424934387
Loss at iteration 1860 : 0.007073699496686459
Loss at iteration 1870 : 0.005445400718599558
Loss at iteration 1880 : 0.006033123470842838
Loss at iteration 1890 : 0.00564810773357749
Loss at iteration 1900 : 0.01650596410036087
Loss at iteration 1910 : 0.011705868877470493
Loss at iteration 1920 : 0.015532413497567177
Loss at iteration 1930 : 0.024586714804172516
Loss at iteration 1940 : 0.005286233499646187
Loss at iteration 1950 : 0.007838371209800243
Loss at iteration 1960 : 0.009092634543776512
Loss at iteration 1970 : 0.010569483041763306
Loss at iteration 1980 : 0.004756908863782883
Loss at iteration 1990 : 0.006418478675186634
Loss at iteration 2000 : 0.007874172180891037
Loss at iteration 2010 : 0.008169872686266899
Loss at iteration 2020 : 0.010691105388104916
Loss at iteration 2030 : 0.019116243347525597
Loss at iteration 2040 : 0.005912481807172298
Loss at iteration 2050 : 0.009023502469062805
Loss at iteration 2060 : 0.011429114267230034
Loss at iteration 2070 : 0.005688894540071487
Loss at iteration 2080 : 0.009383046999573708
Loss at iteration 2090 : 0.005566172301769257
Loss at iteration 2100 : 0.008768364787101746
Loss at iteration 2110 : 0.00561174564063549
Loss at iteration 2120 : 0.010977480560541153
Loss at iteration 2130 : 0.008200001902878284
Loss at iteration 2140 : 0.008744045160710812
Loss at iteration 2150 : 0.0076714069582521915
Loss at iteration 2160 : 0.007869502529501915
Loss at iteration 2170 : 0.008238164708018303
Loss at iteration 2180 : 0.01054693665355444
Loss at iteration 2190 : 0.005744590424001217
Loss at iteration 2200 : 0.009607451036572456
Loss at iteration 2210 : 0.00879217591136694
Loss at iteration 2220 : 0.006341911852359772
Loss at iteration 2230 : 0.010318090207874775
Loss at iteration 2240 : 0.013092870824038982
Loss at iteration 2250 : 0.007457375060766935
Loss at iteration 2260 : 0.01084967516362667
Loss at iteration 2270 : 0.020417891442775726
Loss at iteration 2280 : 0.009744536131620407
Loss at iteration 2290 : 0.00969812273979187
Loss at iteration 2300 : 0.017398782074451447
Loss at iteration 2310 : 0.009689763188362122
Loss at iteration 2320 : 0.006620213855057955
Loss at iteration 2330 : 0.008463812060654163
Loss at iteration 2340 : 0.006591578014194965
Loss at iteration 2350 : 0.01056762970983982
Loss at iteration 2360 : 0.012418399564921856
Loss at iteration 2370 : 0.011176632717251778
Loss at iteration 2380 : 0.012197047472000122
Loss at iteration 2390 : 0.006372657138854265
Loss at iteration 2400 : 0.011348294094204903
Loss at iteration 2410 : 0.013791404664516449
Loss at iteration 2420 : 0.0032502636313438416
The SSIM Value is: 0.8455143253008525
The PSNR Value is: 22.26442705790202
the epoch is: 90
Loss at iteration 10 : 0.008686377666890621
Loss at iteration 20 : 0.00697565171867609
Loss at iteration 30 : 0.008994855917990208
Loss at iteration 40 : 0.008686683140695095
Loss at iteration 50 : 0.014537760056555271
Loss at iteration 60 : 0.004956502001732588
Loss at iteration 70 : 0.004831769037991762
Loss at iteration 80 : 0.004130965564399958
Loss at iteration 90 : 0.007381727918982506
Loss at iteration 100 : 0.01456099096685648
Loss at iteration 110 : 0.014957251027226448
Loss at iteration 120 : 0.006884780712425709
Loss at iteration 130 : 0.00812481064349413
Loss at iteration 140 : 0.005959587171673775
Loss at iteration 150 : 0.008795440196990967
Loss at iteration 160 : 0.007145577110350132
Loss at iteration 170 : 0.025209344923496246
Loss at iteration 180 : 0.009747077710926533
Loss at iteration 190 : 0.009407244622707367
Loss at iteration 200 : 0.005332788918167353
Loss at iteration 210 : 0.008728856220841408
Loss at iteration 220 : 0.007868759334087372
Loss at iteration 230 : 0.008339595049619675
Loss at iteration 240 : 0.01848311722278595
Loss at iteration 250 : 0.013865528628230095
Loss at iteration 260 : 0.009756491519510746
Loss at iteration 270 : 0.01104314811527729
Loss at iteration 280 : 0.006385137792676687
Loss at iteration 290 : 0.006121644750237465
Loss at iteration 300 : 0.0088993851095438
Loss at iteration 310 : 0.009851612150669098
Loss at iteration 320 : 0.009869197383522987
Loss at iteration 330 : 0.009034556336700916
Loss at iteration 340 : 0.008126141503453255
Loss at iteration 350 : 0.004698846954852343
Loss at iteration 360 : 0.006833883002400398
Loss at iteration 370 : 0.008145065978169441
Loss at iteration 380 : 0.004444860387593508
Loss at iteration 390 : 0.011456318199634552
Loss at iteration 400 : 0.008307582698762417
Loss at iteration 410 : 0.013166402466595173
Loss at iteration 420 : 0.004788300953805447
Loss at iteration 430 : 0.0032426437828689814
Loss at iteration 440 : 0.007109348196536303
Loss at iteration 450 : 0.005657424218952656
Loss at iteration 460 : 0.009641542099416256
Loss at iteration 470 : 0.009778328239917755
Loss at iteration 480 : 0.011677744798362255
Loss at iteration 490 : 0.014530310407280922
Loss at iteration 500 : 0.006825048942118883
Loss at iteration 510 : 0.006717592477798462
Loss at iteration 520 : 0.016717037186026573
Loss at iteration 530 : 0.007916659116744995
Loss at iteration 540 : 0.006266025826334953
Loss at iteration 550 : 0.004196460358798504
Loss at iteration 560 : 0.012663494795560837
Loss at iteration 570 : 0.013039707206189632
Loss at iteration 580 : 0.012312035076320171
Loss at iteration 590 : 0.003657455323264003
Loss at iteration 600 : 0.00693264277651906
Loss at iteration 610 : 0.009768497198820114
Loss at iteration 620 : 0.012349475175142288
Loss at iteration 630 : 0.009301295503973961
Loss at iteration 640 : 0.005786573514342308
Loss at iteration 650 : 0.006850261706858873
Loss at iteration 660 : 0.003619976108893752
Loss at iteration 670 : 0.0070619345642626286
Loss at iteration 680 : 0.004530636593699455
Loss at iteration 690 : 0.0046867248602211475
Loss at iteration 700 : 0.01135572511702776
Loss at iteration 710 : 0.008318359963595867
Loss at iteration 720 : 0.017106996849179268
Loss at iteration 730 : 0.01071845181286335
Loss at iteration 740 : 0.011346330866217613
Loss at iteration 750 : 0.015307405963540077
Loss at iteration 760 : 0.009110587649047375
Loss at iteration 770 : 0.009968998841941357
Loss at iteration 780 : 0.003646805416792631
Loss at iteration 790 : 0.014780985191464424
Loss at iteration 800 : 0.008844615891575813
Loss at iteration 810 : 0.003547108732163906
Loss at iteration 820 : 0.008926528505980968
Loss at iteration 830 : 0.01018726546317339
Loss at iteration 840 : 0.014540142379701138
Loss at iteration 850 : 0.006212467327713966
Loss at iteration 860 : 0.009830940514802933
Loss at iteration 870 : 0.006220285315066576
Loss at iteration 880 : 0.009475205093622208
Loss at iteration 890 : 0.007022772915661335
Loss at iteration 900 : 0.009271694347262383
Loss at iteration 910 : 0.008346110582351685
Loss at iteration 920 : 0.009982641786336899
Loss at iteration 930 : 0.015221023932099342
Loss at iteration 940 : 0.017374571412801743
Loss at iteration 950 : 0.007979389280080795
Loss at iteration 960 : 0.003962314687669277
Loss at iteration 970 : 0.005705562420189381
Loss at iteration 980 : 0.009556518867611885
Loss at iteration 990 : 0.00554483849555254
Loss at iteration 1000 : 0.005375174339860678
Loss at iteration 1010 : 0.011801917105913162
Loss at iteration 1020 : 0.024972965940833092
Loss at iteration 1030 : 0.01795342192053795
Loss at iteration 1040 : 0.004547834396362305
Loss at iteration 1050 : 0.015048159286379814
Loss at iteration 1060 : 0.009168104268610477
Loss at iteration 1070 : 0.005112688522785902
Loss at iteration 1080 : 0.005895683541893959
Loss at iteration 1090 : 0.01804262399673462
Loss at iteration 1100 : 0.006974942982196808
Loss at iteration 1110 : 0.006847300101071596
Loss at iteration 1120 : 0.007603224832564592
Loss at iteration 1130 : 0.005474423058331013
Loss at iteration 1140 : 0.007583855651319027
Loss at iteration 1150 : 0.014912277460098267
Loss at iteration 1160 : 0.011561404913663864
Loss at iteration 1170 : 0.006721515208482742
Loss at iteration 1180 : 0.005745932459831238
Loss at iteration 1190 : 0.005599667318165302
Loss at iteration 1200 : 0.013286426663398743
Loss at iteration 1210 : 0.006616849452257156
Loss at iteration 1220 : 0.0029378749895840883
Loss at iteration 1230 : 0.007753395475447178
Loss at iteration 1240 : 0.00789769645780325
Loss at iteration 1250 : 0.0118483891710639
Loss at iteration 1260 : 0.007371115032583475
Loss at iteration 1270 : 0.01001355703920126
Loss at iteration 1280 : 0.006888770963996649
Loss at iteration 1290 : 0.009712202474474907
Loss at iteration 1300 : 0.007221415638923645
Loss at iteration 1310 : 0.018016880378127098
Loss at iteration 1320 : 0.009060000069439411
Loss at iteration 1330 : 0.010138630867004395
Loss at iteration 1340 : 0.008097405545413494
Loss at iteration 1350 : 0.003130430355668068
Loss at iteration 1360 : 0.011776803992688656
Loss at iteration 1370 : 0.006179195828735828
Loss at iteration 1380 : 0.0040886919014155865
Loss at iteration 1390 : 0.021991560235619545
Loss at iteration 1400 : 0.015013270080089569
Loss at iteration 1410 : 0.008557184599339962
Loss at iteration 1420 : 0.012923801317811012
Loss at iteration 1430 : 0.008424024097621441
Loss at iteration 1440 : 0.0057454234920442104
Loss at iteration 1450 : 0.014303697273135185
Loss at iteration 1460 : 0.006363668013364077
Loss at iteration 1470 : 0.006768716499209404
Loss at iteration 1480 : 0.00829235278069973
Loss at iteration 1490 : 0.00976699497550726
Loss at iteration 1500 : 0.005878825671970844
Loss at iteration 1510 : 0.0227444376796484
Loss at iteration 1520 : 0.008738946169614792
Loss at iteration 1530 : 0.013102026656270027
Loss at iteration 1540 : 0.0068481131456792355
Loss at iteration 1550 : 0.015313073992729187
Loss at iteration 1560 : 0.0065991878509521484
Loss at iteration 1570 : 0.011614092625677586
Loss at iteration 1580 : 0.00930043961852789
Loss at iteration 1590 : 0.0068152002058923244
Loss at iteration 1600 : 0.005469861906021833
Loss at iteration 1610 : 0.006589725147932768
Loss at iteration 1620 : 0.011594308540225029
Loss at iteration 1630 : 0.00547432154417038
Loss at iteration 1640 : 0.011440708301961422
Loss at iteration 1650 : 0.007154842372983694
Loss at iteration 1660 : 0.009138677269220352
Loss at iteration 1670 : 0.004864584654569626
Loss at iteration 1680 : 0.008012876845896244
Loss at iteration 1690 : 0.006771043408662081
Loss at iteration 1700 : 0.0113800885155797
Loss at iteration 1710 : 0.0047454144805669785
Loss at iteration 1720 : 0.005085751414299011
Loss at iteration 1730 : 0.011056693270802498
Loss at iteration 1740 : 0.00755591643974185
Loss at iteration 1750 : 0.005805551074445248
Loss at iteration 1760 : 0.011125807650387287
Loss at iteration 1770 : 0.01030544750392437
Loss at iteration 1780 : 0.008218835107982159
Loss at iteration 1790 : 0.012060079723596573
Loss at iteration 1800 : 0.016028309240937233
Loss at iteration 1810 : 0.011264825239777565
Loss at iteration 1820 : 0.004595205653458834
Loss at iteration 1830 : 0.014850967563688755
Loss at iteration 1840 : 0.010386901907622814
Loss at iteration 1850 : 0.02735901065170765
Loss at iteration 1860 : 0.01497322041541338
Loss at iteration 1870 : 0.01101464033126831
Loss at iteration 1880 : 0.015465517528355122
Loss at iteration 1890 : 0.005277979653328657
Loss at iteration 1900 : 0.004654931370168924
Loss at iteration 1910 : 0.02038046345114708
Loss at iteration 1920 : 0.006525867618620396
Loss at iteration 1930 : 0.007023688405752182
Loss at iteration 1940 : 0.014458717778325081
Loss at iteration 1950 : 0.01322898454964161
Loss at iteration 1960 : 0.00391741655766964
Loss at iteration 1970 : 0.012439883314073086
Loss at iteration 1980 : 0.007935442961752415
Loss at iteration 1990 : 0.008731286972761154
Loss at iteration 2000 : 0.008738614618778229
Loss at iteration 2010 : 0.008795702829957008
Loss at iteration 2020 : 0.00645825220271945
Loss at iteration 2030 : 0.00909804180264473
Loss at iteration 2040 : 0.0065751452930271626
Loss at iteration 2050 : 0.010323035530745983
Loss at iteration 2060 : 0.011767799034714699
Loss at iteration 2070 : 0.009917670860886574
Loss at iteration 2080 : 0.013289804570376873
Loss at iteration 2090 : 0.013648662716150284
Loss at iteration 2100 : 0.006464334204792976
Loss at iteration 2110 : 0.009988872334361076
Loss at iteration 2120 : 0.005239550024271011
Loss at iteration 2130 : 0.0077587151899933815
Loss at iteration 2140 : 0.009881033562123775
Loss at iteration 2150 : 0.004921650979667902
Loss at iteration 2160 : 0.006721506826579571
Loss at iteration 2170 : 0.009006217122077942
Loss at iteration 2180 : 0.00609519612044096
Loss at iteration 2190 : 0.008483954705297947
Loss at iteration 2200 : 0.007624994032084942
Loss at iteration 2210 : 0.00400120671838522
Loss at iteration 2220 : 0.011308838613331318
Loss at iteration 2230 : 0.009044036269187927
Loss at iteration 2240 : 0.006150785367935896
Loss at iteration 2250 : 0.005744406953454018
Loss at iteration 2260 : 0.007835883647203445
Loss at iteration 2270 : 0.006785894278436899
Loss at iteration 2280 : 0.007098685950040817
Loss at iteration 2290 : 0.004606756381690502
Loss at iteration 2300 : 0.007449425756931305
Loss at iteration 2310 : 0.013503164052963257
Loss at iteration 2320 : 0.0044793980196118355
Loss at iteration 2330 : 0.0070124659687280655
Loss at iteration 2340 : 0.008566419593989849
Loss at iteration 2350 : 0.007477363105863333
Loss at iteration 2360 : 0.010964483954012394
Loss at iteration 2370 : 0.011730057187378407
Loss at iteration 2380 : 0.0028363263700157404
Loss at iteration 2390 : 0.00842855591326952
Loss at iteration 2400 : 0.005885849241167307
Loss at iteration 2410 : 0.009657969698309898
Loss at iteration 2420 : 0.005303054116666317
The SSIM Value is: 0.8465517520904541
The PSNR Value is: 22.316014607747395
the epoch is: 91
Loss at iteration 10 : 0.002988397143781185
Loss at iteration 20 : 0.0038456381298601627
Loss at iteration 30 : 0.009599762037396431
Loss at iteration 40 : 0.014974097721278667
Loss at iteration 50 : 0.011279210448265076
Loss at iteration 60 : 0.011203188449144363
Loss at iteration 70 : 0.005415910854935646
Loss at iteration 80 : 0.00625747861340642
Loss at iteration 90 : 0.008847114630043507
Loss at iteration 100 : 0.00848066620528698
Loss at iteration 110 : 0.010103663429617882
Loss at iteration 120 : 0.011932745575904846
Loss at iteration 130 : 0.008630701340734959
Loss at iteration 140 : 0.011032437905669212
Loss at iteration 150 : 0.00797684583812952
Loss at iteration 160 : 0.006289387121796608
Loss at iteration 170 : 0.005016219802200794
Loss at iteration 180 : 0.006031320430338383
Loss at iteration 190 : 0.008100935257971287
Loss at iteration 200 : 0.020638104528188705
Loss at iteration 210 : 0.009524048306047916
Loss at iteration 220 : 0.009122508578002453
Loss at iteration 230 : 0.008106010034680367
Loss at iteration 240 : 0.005858835764229298
Loss at iteration 250 : 0.020732982084155083
Loss at iteration 260 : 0.004805995151400566
Loss at iteration 270 : 0.007538896985352039
Loss at iteration 280 : 0.007174093276262283
Loss at iteration 290 : 0.010032003745436668
Loss at iteration 300 : 0.008130826987326145
Loss at iteration 310 : 0.008800579234957695
Loss at iteration 320 : 0.010501151904463768
Loss at iteration 330 : 0.01202003937214613
Loss at iteration 340 : 0.00758149242028594
Loss at iteration 350 : 0.00673752510920167
Loss at iteration 360 : 0.013610133901238441
Loss at iteration 370 : 0.010572942905128002
Loss at iteration 380 : 0.005162001587450504
Loss at iteration 390 : 0.005679579451680183
Loss at iteration 400 : 0.0068290564231574535
Loss at iteration 410 : 0.013279815204441547
Loss at iteration 420 : 0.006498668342828751
Loss at iteration 430 : 0.013544144108891487
Loss at iteration 440 : 0.0038155303336679935
Loss at iteration 450 : 0.011532213538885117
Loss at iteration 460 : 0.008280710317194462
Loss at iteration 470 : 0.002944988664239645
Loss at iteration 480 : 0.009102975018322468
Loss at iteration 490 : 0.008398331701755524
Loss at iteration 500 : 0.010903325863182545
Loss at iteration 510 : 0.0034138800110667944
Loss at iteration 520 : 0.009365011937916279
Loss at iteration 530 : 0.008476760238409042
Loss at iteration 540 : 0.0048585874028503895
Loss at iteration 550 : 0.012424500659108162
Loss at iteration 560 : 0.011395872570574284
Loss at iteration 570 : 0.006353173870593309
Loss at iteration 580 : 0.01689240336418152
Loss at iteration 590 : 0.015906713902950287
Loss at iteration 600 : 0.024004116654396057
Loss at iteration 610 : 0.010867568664252758
Loss at iteration 620 : 0.00235998397693038
Loss at iteration 630 : 0.006103494204580784
Loss at iteration 640 : 0.013149969279766083
Loss at iteration 650 : 0.004084639251232147
Loss at iteration 660 : 0.003390040947124362
Loss at iteration 670 : 0.005203802138566971
Loss at iteration 680 : 0.011573788709938526
Loss at iteration 690 : 0.007596238050609827
Loss at iteration 700 : 0.010786467231810093
Loss at iteration 710 : 0.006453515961766243
Loss at iteration 720 : 0.009146451950073242
Loss at iteration 730 : 0.010538937523961067
Loss at iteration 740 : 0.009785346686840057
Loss at iteration 750 : 0.006069590337574482
Loss at iteration 760 : 0.016275569796562195
Loss at iteration 770 : 0.004721815697848797
Loss at iteration 780 : 0.007567380089312792
Loss at iteration 790 : 0.012201482430100441
Loss at iteration 800 : 0.0055844904854893684
Loss at iteration 810 : 0.008625974878668785
Loss at iteration 820 : 0.004828170873224735
Loss at iteration 830 : 0.010017736814916134
Loss at iteration 840 : 0.00947863981127739
Loss at iteration 850 : 0.0028165134135633707
Loss at iteration 860 : 0.0020503606647253036
Loss at iteration 870 : 0.00962867308408022
Loss at iteration 880 : 0.010515883564949036
Loss at iteration 890 : 0.0053612245246768
Loss at iteration 900 : 0.0054416051134467125
Loss at iteration 910 : 0.008285433985292912
Loss at iteration 920 : 0.009266786277294159
Loss at iteration 930 : 0.010463781654834747
Loss at iteration 940 : 0.012665674090385437
Loss at iteration 950 : 0.005137581378221512
Loss at iteration 960 : 0.003727298229932785
Loss at iteration 970 : 0.008486654609441757
Loss at iteration 980 : 0.015140419825911522
Loss at iteration 990 : 0.005685374140739441
Loss at iteration 1000 : 0.010371308773756027
Loss at iteration 1010 : 0.010282914154231548
Loss at iteration 1020 : 0.015538590028882027
Loss at iteration 1030 : 0.011518626473844051
Loss at iteration 1040 : 0.008645087480545044
Loss at iteration 1050 : 0.004438718780875206
Loss at iteration 1060 : 0.010632299818098545
Loss at iteration 1070 : 0.006793171167373657
Loss at iteration 1080 : 0.0038410909473896027
Loss at iteration 1090 : 0.007141360081732273
Loss at iteration 1100 : 0.011003808118402958
Loss at iteration 1110 : 0.025372181087732315
Loss at iteration 1120 : 0.006228451617062092
Loss at iteration 1130 : 0.006864779628813267
Loss at iteration 1140 : 0.004638779908418655
Loss at iteration 1150 : 0.009936521761119366
Loss at iteration 1160 : 0.0065466491505503654
Loss at iteration 1170 : 0.010212295688688755
Loss at iteration 1180 : 0.006638954859226942
Loss at iteration 1190 : 0.00561519805341959
Loss at iteration 1200 : 0.01644144020974636
Loss at iteration 1210 : 0.01406458206474781
Loss at iteration 1220 : 0.020134521648287773
Loss at iteration 1230 : 0.005667134653776884
Loss at iteration 1240 : 0.0034604165703058243
Loss at iteration 1250 : 0.008327401243150234
Loss at iteration 1260 : 0.011614439077675343
Loss at iteration 1270 : 0.0028385238256305456
Loss at iteration 1280 : 0.0037636798806488514
Loss at iteration 1290 : 0.008134707808494568
Loss at iteration 1300 : 0.011307841166853905
Loss at iteration 1310 : 0.025643227621912956
Loss at iteration 1320 : 0.01309319119900465
Loss at iteration 1330 : 0.007753184996545315
Loss at iteration 1340 : 0.007750379387289286
Loss at iteration 1350 : 0.00973491556942463
Loss at iteration 1360 : 0.008480962365865707
Loss at iteration 1370 : 0.014745360240340233
Loss at iteration 1380 : 0.00910868402570486
Loss at iteration 1390 : 0.009224762208759785
Loss at iteration 1400 : 0.009858354926109314
Loss at iteration 1410 : 0.014721374027431011
Loss at iteration 1420 : 0.007717811036854982
Loss at iteration 1430 : 0.009138721041381359
Loss at iteration 1440 : 0.010984499007463455
Loss at iteration 1450 : 0.013309577479958534
Loss at iteration 1460 : 0.005094273015856743
Loss at iteration 1470 : 0.0042798747308552265
Loss at iteration 1480 : 0.0206371508538723
Loss at iteration 1490 : 0.003950517158955336
Loss at iteration 1500 : 0.007922932505607605
Loss at iteration 1510 : 0.010175235569477081
Loss at iteration 1520 : 0.007070189341902733
Loss at iteration 1530 : 0.004927204456180334
Loss at iteration 1540 : 0.011771007440984249
Loss at iteration 1550 : 0.005946469958871603
Loss at iteration 1560 : 0.015072347596287727
Loss at iteration 1570 : 0.009033340029418468
Loss at iteration 1580 : 0.017651306465268135
Loss at iteration 1590 : 0.00592493312433362
Loss at iteration 1600 : 0.007088550832122564
Loss at iteration 1610 : 0.005982385948300362
Loss at iteration 1620 : 0.0159516092389822
Loss at iteration 1630 : 0.008510051295161247
Loss at iteration 1640 : 0.009946209378540516
Loss at iteration 1650 : 0.009460050612688065
Loss at iteration 1660 : 0.008962893858551979
Loss at iteration 1670 : 0.007363748736679554
Loss at iteration 1680 : 0.007750974036753178
Loss at iteration 1690 : 0.00786779448390007
Loss at iteration 1700 : 0.009213168174028397
Loss at iteration 1710 : 0.010091114789247513
Loss at iteration 1720 : 0.007977515459060669
Loss at iteration 1730 : 0.004773427732288837
Loss at iteration 1740 : 0.008405927568674088
Loss at iteration 1750 : 0.004396676551550627
Loss at iteration 1760 : 0.004150183871388435
Loss at iteration 1770 : 0.007528781425207853
Loss at iteration 1780 : 0.007799524813890457
Loss at iteration 1790 : 0.011116507463157177
Loss at iteration 1800 : 0.010772455483675003
Loss at iteration 1810 : 0.011152025312185287
Loss at iteration 1820 : 0.008670367300510406
Loss at iteration 1830 : 0.007979195564985275
Loss at iteration 1840 : 0.007749645970761776
Loss at iteration 1850 : 0.010856343433260918
Loss at iteration 1860 : 0.004330058116465807
Loss at iteration 1870 : 0.016918029636144638
Loss at iteration 1880 : 0.010190892964601517
Loss at iteration 1890 : 0.002603746484965086
Loss at iteration 1900 : 0.01112948078662157
Loss at iteration 1910 : 0.005565976724028587
Loss at iteration 1920 : 0.009399637579917908
Loss at iteration 1930 : 0.007535190787166357
Loss at iteration 1940 : 0.009223964996635914
Loss at iteration 1950 : 0.01738857291638851
Loss at iteration 1960 : 0.011502076871693134
Loss at iteration 1970 : 0.011985392309725285
Loss at iteration 1980 : 0.005654408596456051
Loss at iteration 1990 : 0.010033650323748589
Loss at iteration 2000 : 0.014448290690779686
Loss at iteration 2010 : 0.0028365841135382652
Loss at iteration 2020 : 0.01111491397023201
Loss at iteration 2030 : 0.008204947225749493
Loss at iteration 2040 : 0.007599284872412682
Loss at iteration 2050 : 0.0043736607767641544
Loss at iteration 2060 : 0.005864208564162254
Loss at iteration 2070 : 0.011904197745025158
Loss at iteration 2080 : 0.005363141186535358
Loss at iteration 2090 : 0.00885053537786007
Loss at iteration 2100 : 0.005910618230700493
Loss at iteration 2110 : 0.005793819669634104
Loss at iteration 2120 : 0.007839861325919628
Loss at iteration 2130 : 0.010467593558132648
Loss at iteration 2140 : 0.007263009902089834
Loss at iteration 2150 : 0.010702352970838547
Loss at iteration 2160 : 0.008285978808999062
Loss at iteration 2170 : 0.013676258735358715
Loss at iteration 2180 : 0.00745320413261652
Loss at iteration 2190 : 0.009245085529983044
Loss at iteration 2200 : 0.011478717438876629
Loss at iteration 2210 : 0.005939380265772343
Loss at iteration 2220 : 0.008412939496338367
Loss at iteration 2230 : 0.007084902375936508
Loss at iteration 2240 : 0.021142592653632164
Loss at iteration 2250 : 0.00844491645693779
Loss at iteration 2260 : 0.008986626751720905
Loss at iteration 2270 : 0.010687565430998802
Loss at iteration 2280 : 0.014480053447186947
Loss at iteration 2290 : 0.012061899527907372
Loss at iteration 2300 : 0.00829637423157692
Loss at iteration 2310 : 0.005102100782096386
Loss at iteration 2320 : 0.0064821019768714905
Loss at iteration 2330 : 0.0058493949472904205
Loss at iteration 2340 : 0.007693182677030563
Loss at iteration 2350 : 0.005361560732126236
Loss at iteration 2360 : 0.003673400031402707
Loss at iteration 2370 : 0.0057012224569916725
Loss at iteration 2380 : 0.007100301329046488
Loss at iteration 2390 : 0.011677875183522701
Loss at iteration 2400 : 0.011416105553507805
Loss at iteration 2410 : 0.00705281738191843
Loss at iteration 2420 : 0.007279395125806332
The SSIM Value is: 0.8429432471593221
The PSNR Value is: 21.696265347798665
the epoch is: 92
Loss at iteration 10 : 0.007273018825799227
Loss at iteration 20 : 0.01541273295879364
Loss at iteration 30 : 0.014683456160128117
Loss at iteration 40 : 0.013137249276041985
Loss at iteration 50 : 0.016676653176546097
Loss at iteration 60 : 0.016201511025428772
Loss at iteration 70 : 0.009301462210714817
Loss at iteration 80 : 0.008166572079062462
Loss at iteration 90 : 0.008469294756650925
Loss at iteration 100 : 0.013342653401196003
Loss at iteration 110 : 0.016557956114411354
Loss at iteration 120 : 0.012520144693553448
Loss at iteration 130 : 0.013638190925121307
Loss at iteration 140 : 0.007677746936678886
Loss at iteration 150 : 0.007113567553460598
Loss at iteration 160 : 0.008882200345396996
Loss at iteration 170 : 0.005495975725352764
Loss at iteration 180 : 0.007651261519640684
Loss at iteration 190 : 0.007821382023394108
Loss at iteration 200 : 0.012920470908284187
Loss at iteration 210 : 0.009960449300706387
Loss at iteration 220 : 0.010838592424988747
Loss at iteration 230 : 0.010137420147657394
Loss at iteration 240 : 0.003299462143331766
Loss at iteration 250 : 0.003857129020616412
Loss at iteration 260 : 0.010689777322113514
Loss at iteration 270 : 0.010807588696479797
Loss at iteration 280 : 0.015750085934996605
Loss at iteration 290 : 0.007257112301886082
Loss at iteration 300 : 0.009273326955735683
Loss at iteration 310 : 0.01241461094468832
Loss at iteration 320 : 0.006778504233807325
Loss at iteration 330 : 0.005419512744992971
Loss at iteration 340 : 0.011194659397006035
Loss at iteration 350 : 0.0103460643440485
Loss at iteration 360 : 0.009416405111551285
Loss at iteration 370 : 0.010056628845632076
Loss at iteration 380 : 0.004078410565853119
Loss at iteration 390 : 0.004471912514418364
Loss at iteration 400 : 0.004017339088022709
Loss at iteration 410 : 0.012530322186648846
Loss at iteration 420 : 0.005316221155226231
Loss at iteration 430 : 0.008950225077569485
Loss at iteration 440 : 0.009741062298417091
Loss at iteration 450 : 0.013735784217715263
Loss at iteration 460 : 0.008185764774680138
Loss at iteration 470 : 0.008270824328064919
Loss at iteration 480 : 0.00910213589668274
Loss at iteration 490 : 0.005761538166552782
Loss at iteration 500 : 0.0043803369626402855
Loss at iteration 510 : 0.004682272206991911
Loss at iteration 520 : 0.010285204276442528
Loss at iteration 530 : 0.004176082089543343
Loss at iteration 540 : 0.003565403865650296
Loss at iteration 550 : 0.004793641623109579
Loss at iteration 560 : 0.008680494502186775
Loss at iteration 570 : 0.0053203231655061245
Loss at iteration 580 : 0.014459215104579926
Loss at iteration 590 : 0.002865827176719904
Loss at iteration 600 : 0.0038836244493722916
Loss at iteration 610 : 0.016092056408524513
Loss at iteration 620 : 0.010364738292992115
Loss at iteration 630 : 0.009038115851581097
Loss at iteration 640 : 0.005493694916367531
Loss at iteration 650 : 0.0077154007740318775
Loss at iteration 660 : 0.007256154902279377
Loss at iteration 670 : 0.011664042249321938
Loss at iteration 680 : 0.015172788873314857
Loss at iteration 690 : 0.008961435407400131
Loss at iteration 700 : 0.008081890642642975
Loss at iteration 710 : 0.008786879479885101
Loss at iteration 720 : 0.004430213011801243
Loss at iteration 730 : 0.010407219640910625
Loss at iteration 740 : 0.006052862387150526
Loss at iteration 750 : 0.003343273652717471
Loss at iteration 760 : 0.004494730848819017
Loss at iteration 770 : 0.011645834892988205
Loss at iteration 780 : 0.016383254900574684
Loss at iteration 790 : 0.007752720732241869
Loss at iteration 800 : 0.005796336568892002
Loss at iteration 810 : 0.008771110326051712
Loss at iteration 820 : 0.007602344732731581
Loss at iteration 830 : 0.006865855306386948
Loss at iteration 840 : 0.01802258938550949
Loss at iteration 850 : 0.007291954942047596
Loss at iteration 860 : 0.004783880431205034
Loss at iteration 870 : 0.006934811361134052
Loss at iteration 880 : 0.011865785345435143
Loss at iteration 890 : 0.0043854257091879845
Loss at iteration 900 : 0.012378516606986523
Loss at iteration 910 : 0.005720720626413822
Loss at iteration 920 : 0.01877938024699688
Loss at iteration 930 : 0.009472737088799477
Loss at iteration 940 : 0.010794480331242085
Loss at iteration 950 : 0.009188777767121792
Loss at iteration 960 : 0.011620230972766876
Loss at iteration 970 : 0.0021480589639395475
Loss at iteration 980 : 0.005185285117477179
Loss at iteration 990 : 0.019670899957418442
Loss at iteration 1000 : 0.009113674983382225
Loss at iteration 1010 : 0.018584419041872025
Loss at iteration 1020 : 0.007566448301076889
Loss at iteration 1030 : 0.0025124275125563145
Loss at iteration 1040 : 0.009744917042553425
Loss at iteration 1050 : 0.0042466046288609505
Loss at iteration 1060 : 0.009461689740419388
Loss at iteration 1070 : 0.004607471637427807
Loss at iteration 1080 : 0.00776648661121726
Loss at iteration 1090 : 0.008084465749561787
Loss at iteration 1100 : 0.009270167909562588
Loss at iteration 1110 : 0.014852665364742279
Loss at iteration 1120 : 0.010762780904769897
Loss at iteration 1130 : 0.007179825101047754
Loss at iteration 1140 : 0.007497522048652172
Loss at iteration 1150 : 0.004301277454942465
Loss at iteration 1160 : 0.006973159033805132
Loss at iteration 1170 : 0.0097846994176507
Loss at iteration 1180 : 0.010609139688313007
Loss at iteration 1190 : 0.006639427971094847
Loss at iteration 1200 : 0.00811921525746584
Loss at iteration 1210 : 0.006080204620957375
Loss at iteration 1220 : 0.01351509615778923
Loss at iteration 1230 : 0.00888774823397398
Loss at iteration 1240 : 0.005129937082529068
Loss at iteration 1250 : 0.005349383223801851
Loss at iteration 1260 : 0.005618852097541094
Loss at iteration 1270 : 0.017384106293320656
Loss at iteration 1280 : 0.004839184228330851
Loss at iteration 1290 : 0.00875892210751772
Loss at iteration 1300 : 0.00789082981646061
Loss at iteration 1310 : 0.007384598255157471
Loss at iteration 1320 : 0.010893791913986206
Loss at iteration 1330 : 0.013390526175498962
Loss at iteration 1340 : 0.0038808826357126236
Loss at iteration 1350 : 0.01273956149816513
Loss at iteration 1360 : 0.012105592526495457
Loss at iteration 1370 : 0.010112150572240353
Loss at iteration 1380 : 0.009381519630551338
Loss at iteration 1390 : 0.010895539075136185
Loss at iteration 1400 : 0.003523743711411953
Loss at iteration 1410 : 0.015305401757359505
Loss at iteration 1420 : 0.008681803941726685
Loss at iteration 1430 : 0.013441606424748898
Loss at iteration 1440 : 0.010340549051761627
Loss at iteration 1450 : 0.01612735539674759
Loss at iteration 1460 : 0.008666952140629292
Loss at iteration 1470 : 0.010566690005362034
Loss at iteration 1480 : 0.016260342672467232
Loss at iteration 1490 : 0.006638464983552694
Loss at iteration 1500 : 0.010313848033547401
Loss at iteration 1510 : 0.022766966372728348
Loss at iteration 1520 : 0.0036836648359894753
Loss at iteration 1530 : 0.00828481838107109
Loss at iteration 1540 : 0.006265024188905954
Loss at iteration 1550 : 0.011212083511054516
Loss at iteration 1560 : 0.004321204498410225
Loss at iteration 1570 : 0.0033863692078739405
Loss at iteration 1580 : 0.01164846122264862
Loss at iteration 1590 : 0.006882554851472378
Loss at iteration 1600 : 0.007837519980967045
Loss at iteration 1610 : 0.0068015712313354015
Loss at iteration 1620 : 0.005042980890721083
Loss at iteration 1630 : 0.008994334377348423
Loss at iteration 1640 : 0.013301457278430462
Loss at iteration 1650 : 0.011030943132936954
Loss at iteration 1660 : 0.014608649536967278
Loss at iteration 1670 : 0.003821486607193947
Loss at iteration 1680 : 0.011711245402693748
Loss at iteration 1690 : 0.009009295143187046
Loss at iteration 1700 : 0.012203802354633808
Loss at iteration 1710 : 0.014789743348956108
Loss at iteration 1720 : 0.011422323063015938
Loss at iteration 1730 : 0.0051065185107290745
Loss at iteration 1740 : 0.011905131861567497
Loss at iteration 1750 : 0.008090793155133724
Loss at iteration 1760 : 0.00435911538079381
Loss at iteration 1770 : 0.00901635829359293
Loss at iteration 1780 : 0.005881075281649828
Loss at iteration 1790 : 0.004560752771794796
Loss at iteration 1800 : 0.005698633845895529
Loss at iteration 1810 : 0.008509508334100246
Loss at iteration 1820 : 0.0045788465067744255
Loss at iteration 1830 : 0.010581782087683678
Loss at iteration 1840 : 0.00915730744600296
Loss at iteration 1850 : 0.008924110792577267
Loss at iteration 1860 : 0.006638922728598118
Loss at iteration 1870 : 0.010453170165419579
Loss at iteration 1880 : 0.01377431396394968
Loss at iteration 1890 : 0.007424960844218731
Loss at iteration 1900 : 0.006333290599286556
Loss at iteration 1910 : 0.012264118529856205
Loss at iteration 1920 : 0.004585284274071455
Loss at iteration 1930 : 0.007626106962561607
Loss at iteration 1940 : 0.007061128504574299
Loss at iteration 1950 : 0.009381122887134552
Loss at iteration 1960 : 0.007474277168512344
Loss at iteration 1970 : 0.006848160643130541
Loss at iteration 1980 : 0.010438662022352219
Loss at iteration 1990 : 0.004539187997579575
Loss at iteration 2000 : 0.010168073698878288
Loss at iteration 2010 : 0.006142935715615749
Loss at iteration 2020 : 0.008369914256036282
Loss at iteration 2030 : 0.009392348118126392
Loss at iteration 2040 : 0.009122716262936592
Loss at iteration 2050 : 0.012159731239080429
Loss at iteration 2060 : 0.004863501060754061
Loss at iteration 2070 : 0.009874213486909866
Loss at iteration 2080 : 0.005586518440395594
Loss at iteration 2090 : 0.005064796656370163
Loss at iteration 2100 : 0.005027391482144594
Loss at iteration 2110 : 0.016441795974969864
Loss at iteration 2120 : 0.005720896180719137
Loss at iteration 2130 : 0.02294188365340233
Loss at iteration 2140 : 0.009720503352582455
Loss at iteration 2150 : 0.006499452982097864
Loss at iteration 2160 : 0.009314793162047863
Loss at iteration 2170 : 0.011428476311266422
Loss at iteration 2180 : 0.005965786054730415
Loss at iteration 2190 : 0.01209481991827488
Loss at iteration 2200 : 0.009207496419548988
Loss at iteration 2210 : 0.00895859394222498
Loss at iteration 2220 : 0.01555562298744917
Loss at iteration 2230 : 0.015431081876158714
Loss at iteration 2240 : 0.010286843404173851
Loss at iteration 2250 : 0.012092424556612968
Loss at iteration 2260 : 0.01198774203658104
Loss at iteration 2270 : 0.01136690378189087
Loss at iteration 2280 : 0.003891649190336466
Loss at iteration 2290 : 0.004348664544522762
Loss at iteration 2300 : 0.00404603686183691
Loss at iteration 2310 : 0.003776140511035919
Loss at iteration 2320 : 0.0029738000594079494
Loss at iteration 2330 : 0.005478524137288332
Loss at iteration 2340 : 0.007210447918623686
Loss at iteration 2350 : 0.004535226617008448
Loss at iteration 2360 : 0.003550951601937413
Loss at iteration 2370 : 0.006474276073276997
Loss at iteration 2380 : 0.0051139164716005325
Loss at iteration 2390 : 0.007315824273973703
Loss at iteration 2400 : 0.009026299230754375
Loss at iteration 2410 : 0.01100511010736227
Loss at iteration 2420 : 0.008433775044977665
The SSIM Value is: 0.8459484418233235
The PSNR Value is: 21.839699935913085
the epoch is: 93
Loss at iteration 10 : 0.010314136743545532
Loss at iteration 20 : 0.006093410775065422
Loss at iteration 30 : 0.00805447343736887
Loss at iteration 40 : 0.009457501582801342
Loss at iteration 50 : 0.008548305369913578
Loss at iteration 60 : 0.006427688058465719
Loss at iteration 70 : 0.009502631612122059
Loss at iteration 80 : 0.0053038024343550205
Loss at iteration 90 : 0.009825007058680058
Loss at iteration 100 : 0.016715168952941895
Loss at iteration 110 : 0.011806954629719257
Loss at iteration 120 : 0.005688325501978397
Loss at iteration 130 : 0.01061241701245308
Loss at iteration 140 : 0.0047031971625983715
Loss at iteration 150 : 0.006264117546379566
Loss at iteration 160 : 0.014541075564920902
Loss at iteration 170 : 0.01350143738090992
Loss at iteration 180 : 0.017621498554944992
Loss at iteration 190 : 0.0094541534781456
Loss at iteration 200 : 0.004215055610984564
Loss at iteration 210 : 0.011180114932358265
Loss at iteration 220 : 0.0023818586487323046
Loss at iteration 230 : 0.006639758124947548
Loss at iteration 240 : 0.013200764544308186
Loss at iteration 250 : 0.004308757837861776
Loss at iteration 260 : 0.002873610472306609
Loss at iteration 270 : 0.012600729241967201
Loss at iteration 280 : 0.013739947229623795
Loss at iteration 290 : 0.0027280296199023724
Loss at iteration 300 : 0.010300409980118275
Loss at iteration 310 : 0.009852846153080463
Loss at iteration 320 : 0.032609693706035614
Loss at iteration 330 : 0.011041918769478798
Loss at iteration 340 : 0.004223913885653019
Loss at iteration 350 : 0.008698808960616589
Loss at iteration 360 : 0.008152727968990803
Loss at iteration 370 : 0.0047228955663740635
Loss at iteration 380 : 0.005876461043953896
Loss at iteration 390 : 0.004172465298324823
Loss at iteration 400 : 0.007149211131036282
Loss at iteration 410 : 0.012664582580327988
Loss at iteration 420 : 0.007227592170238495
Loss at iteration 430 : 0.007280592806637287
Loss at iteration 440 : 0.007497461047023535
Loss at iteration 450 : 0.009932901710271835
Loss at iteration 460 : 0.018532700836658478
Loss at iteration 470 : 0.004383191466331482
Loss at iteration 480 : 0.005475242622196674
Loss at iteration 490 : 0.015484610572457314
Loss at iteration 500 : 0.005367450416088104
Loss at iteration 510 : 0.008753541857004166
Loss at iteration 520 : 0.007438586093485355
Loss at iteration 530 : 0.015489906072616577
Loss at iteration 540 : 0.006560085341334343
Loss at iteration 550 : 0.005476850084960461
Loss at iteration 560 : 0.01261411514133215
Loss at iteration 570 : 0.009109576232731342
Loss at iteration 580 : 0.012794618494808674
Loss at iteration 590 : 0.015787893906235695
Loss at iteration 600 : 0.011676289141178131
Loss at iteration 610 : 0.007537589408457279
Loss at iteration 620 : 0.015226708725094795
Loss at iteration 630 : 0.031515154987573624
Loss at iteration 640 : 0.0048032524064183235
Loss at iteration 650 : 0.03182176128029823
Loss at iteration 660 : 0.003071174491196871
Loss at iteration 670 : 0.01077978778630495
Loss at iteration 680 : 0.008590906858444214
Loss at iteration 690 : 0.012650296092033386
Loss at iteration 700 : 0.010005082935094833
Loss at iteration 710 : 0.009615963324904442
Loss at iteration 720 : 0.0052416459657251835
Loss at iteration 730 : 0.007496786769479513
Loss at iteration 740 : 0.015226936899125576
Loss at iteration 750 : 0.007574004121124744
Loss at iteration 760 : 0.004926104564219713
Loss at iteration 770 : 0.004263290669769049
Loss at iteration 780 : 0.006201642099767923
Loss at iteration 790 : 0.0033955834805965424
Loss at iteration 800 : 0.01907791942358017
Loss at iteration 810 : 0.006976976990699768
Loss at iteration 820 : 0.007593326736241579
Loss at iteration 830 : 0.006893833167850971
Loss at iteration 840 : 0.011356894858181477
Loss at iteration 850 : 0.006132706068456173
Loss at iteration 860 : 0.003332330146804452
Loss at iteration 870 : 0.004593071062117815
Loss at iteration 880 : 0.004126249812543392
Loss at iteration 890 : 0.005010099615901709
Loss at iteration 900 : 0.00889230240136385
Loss at iteration 910 : 0.01580657996237278
Loss at iteration 920 : 0.012431127019226551
Loss at iteration 930 : 0.014644899405539036
Loss at iteration 940 : 0.013630828820168972
Loss at iteration 950 : 0.0032269801013171673
Loss at iteration 960 : 0.004965177737176418
Loss at iteration 970 : 0.005926559213548899
Loss at iteration 980 : 0.005671273916959763
Loss at iteration 990 : 0.006314911879599094
Loss at iteration 1000 : 0.007080797106027603
Loss at iteration 1010 : 0.005477750673890114
Loss at iteration 1020 : 0.010771708562970161
Loss at iteration 1030 : 0.006610056385397911
Loss at iteration 1040 : 0.00851679127663374
Loss at iteration 1050 : 0.005704555194824934
Loss at iteration 1060 : 0.006316604558378458
Loss at iteration 1070 : 0.0067254952155053616
Loss at iteration 1080 : 0.010165848769247532
Loss at iteration 1090 : 0.010820180177688599
Loss at iteration 1100 : 0.01018662191927433
Loss at iteration 1110 : 0.022252380847930908
Loss at iteration 1120 : 0.008556089363992214
Loss at iteration 1130 : 0.005023600999265909
Loss at iteration 1140 : 0.008423283696174622
Loss at iteration 1150 : 0.008913811296224594
Loss at iteration 1160 : 0.011479300446808338
Loss at iteration 1170 : 0.005697320681065321
Loss at iteration 1180 : 0.007106485776603222
Loss at iteration 1190 : 0.00776671152561903
Loss at iteration 1200 : 0.006684189196676016
Loss at iteration 1210 : 0.006951829884201288
Loss at iteration 1220 : 0.0110589899122715
Loss at iteration 1230 : 0.003578835166990757
Loss at iteration 1240 : 0.010417207144200802
Loss at iteration 1250 : 0.012855740264058113
Loss at iteration 1260 : 0.011790442280471325
Loss at iteration 1270 : 0.004087140783667564
Loss at iteration 1280 : 0.00885937549173832
Loss at iteration 1290 : 0.006664597429335117
Loss at iteration 1300 : 0.018351376056671143
Loss at iteration 1310 : 0.015561913140118122
Loss at iteration 1320 : 0.010485202074050903
Loss at iteration 1330 : 0.01097495574504137
Loss at iteration 1340 : 0.006777117028832436
Loss at iteration 1350 : 0.0040273708291351795
Loss at iteration 1360 : 0.004600018262863159
Loss at iteration 1370 : 0.005090365651994944
Loss at iteration 1380 : 0.006101181730628014
Loss at iteration 1390 : 0.011323971673846245
Loss at iteration 1400 : 0.0075348131358623505
Loss at iteration 1410 : 0.017146270722150803
Loss at iteration 1420 : 0.014290759339928627
Loss at iteration 1430 : 0.0060928016901016235
Loss at iteration 1440 : 0.010144931264221668
Loss at iteration 1450 : 0.008472371846437454
Loss at iteration 1460 : 0.00464339554309845
Loss at iteration 1470 : 0.0068876128643751144
Loss at iteration 1480 : 0.006632319651544094
Loss at iteration 1490 : 0.00973236933350563
Loss at iteration 1500 : 0.005699568428099155
Loss at iteration 1510 : 0.018065715208649635
Loss at iteration 1520 : 0.006513201165944338
Loss at iteration 1530 : 0.00679769366979599
Loss at iteration 1540 : 0.006277022417634726
Loss at iteration 1550 : 0.008052474819123745
Loss at iteration 1560 : 0.010707253590226173
Loss at iteration 1570 : 0.007781785912811756
Loss at iteration 1580 : 0.007807649672031403
Loss at iteration 1590 : 0.00965341180562973
Loss at iteration 1600 : 0.005930288694798946
Loss at iteration 1610 : 0.014184986241161823
Loss at iteration 1620 : 0.008252352476119995
Loss at iteration 1630 : 0.007555785588920116
Loss at iteration 1640 : 0.006431511603295803
Loss at iteration 1650 : 0.013579754158854485
Loss at iteration 1660 : 0.010609802789986134
Loss at iteration 1670 : 0.011431227438151836
Loss at iteration 1680 : 0.00840771198272705
Loss at iteration 1690 : 0.016857856884598732
Loss at iteration 1700 : 0.010871633887290955
Loss at iteration 1710 : 0.007243374362587929
Loss at iteration 1720 : 0.010613439604640007
Loss at iteration 1730 : 0.00663044024258852
Loss at iteration 1740 : 0.005894290748983622
Loss at iteration 1750 : 0.008639607578516006
Loss at iteration 1760 : 0.007267879322171211
Loss at iteration 1770 : 0.004349777474999428
Loss at iteration 1780 : 0.016829174011945724
Loss at iteration 1790 : 0.009334069676697254
Loss at iteration 1800 : 0.009800422005355358
Loss at iteration 1810 : 0.02256002463400364
Loss at iteration 1820 : 0.010042800568044186
Loss at iteration 1830 : 0.010567545890808105
Loss at iteration 1840 : 0.016786139458417892
Loss at iteration 1850 : 0.0037536141462624073
Loss at iteration 1860 : 0.0054301917552948
Loss at iteration 1870 : 0.006201423704624176
Loss at iteration 1880 : 0.01188930869102478
Loss at iteration 1890 : 0.008280394598841667
Loss at iteration 1900 : 0.009226769208908081
Loss at iteration 1910 : 0.015337078832089901
Loss at iteration 1920 : 0.022229919210076332
Loss at iteration 1930 : 0.0028890755493193865
Loss at iteration 1940 : 0.00830891914665699
Loss at iteration 1950 : 0.007128084544092417
Loss at iteration 1960 : 0.0072174095548689365
Loss at iteration 1970 : 0.006217631045728922
Loss at iteration 1980 : 0.004843850154429674
Loss at iteration 1990 : 0.007182498462498188
Loss at iteration 2000 : 0.008964480832219124
Loss at iteration 2010 : 0.007269580848515034
Loss at iteration 2020 : 0.00679474463686347
Loss at iteration 2030 : 0.01059234794229269
Loss at iteration 2040 : 0.0168866328895092
Loss at iteration 2050 : 0.00868694856762886
Loss at iteration 2060 : 0.02488718554377556
Loss at iteration 2070 : 0.011897770687937737
Loss at iteration 2080 : 0.0284059327095747
Loss at iteration 2090 : 0.011483770795166492
Loss at iteration 2100 : 0.0072827767580747604
Loss at iteration 2110 : 0.01691879704594612
Loss at iteration 2120 : 0.00808513443917036
Loss at iteration 2130 : 0.004839656874537468
Loss at iteration 2140 : 0.008171111345291138
Loss at iteration 2150 : 0.01039327122271061
Loss at iteration 2160 : 0.005253067705780268
Loss at iteration 2170 : 0.012647437863051891
Loss at iteration 2180 : 0.004045749083161354
Loss at iteration 2190 : 0.0181450042873621
Loss at iteration 2200 : 0.0091933598741889
Loss at iteration 2210 : 0.012860707938671112
Loss at iteration 2220 : 0.015836264938116074
Loss at iteration 2230 : 0.009325933642685413
Loss at iteration 2240 : 0.019470544531941414
Loss at iteration 2250 : 0.009409062564373016
Loss at iteration 2260 : 0.010986579582095146
Loss at iteration 2270 : 0.010882347822189331
Loss at iteration 2280 : 0.009111575782299042
Loss at iteration 2290 : 0.010991008020937443
Loss at iteration 2300 : 0.00859793834388256
Loss at iteration 2310 : 0.006960752885788679
Loss at iteration 2320 : 0.00805956032127142
Loss at iteration 2330 : 0.006283189170062542
Loss at iteration 2340 : 0.009671307168900967
Loss at iteration 2350 : 0.005891784094274044
Loss at iteration 2360 : 0.006132116541266441
Loss at iteration 2370 : 0.004672045819461346
Loss at iteration 2380 : 0.004183011129498482
Loss at iteration 2390 : 0.009389398619532585
Loss at iteration 2400 : 0.01537394244223833
Loss at iteration 2410 : 0.009054714813828468
Loss at iteration 2420 : 0.016547560691833496
The SSIM Value is: 0.8422030369440715
The PSNR Value is: 21.962114334106445
the epoch is: 94
Loss at iteration 10 : 0.013221632689237595
Loss at iteration 20 : 0.009091024287045002
Loss at iteration 30 : 0.006583952344954014
Loss at iteration 40 : 0.009192289784550667
Loss at iteration 50 : 0.008918894454836845
Loss at iteration 60 : 0.004833349026739597
Loss at iteration 70 : 0.012488041073083878
Loss at iteration 80 : 0.008338424377143383
Loss at iteration 90 : 0.006519399117678404
Loss at iteration 100 : 0.007146233227103949
Loss at iteration 110 : 0.002715983195230365
Loss at iteration 120 : 0.011256019584834576
Loss at iteration 130 : 0.0022989397402852774
Loss at iteration 140 : 0.016176344826817513
Loss at iteration 150 : 0.006737957708537579
Loss at iteration 160 : 0.008147269487380981
Loss at iteration 170 : 0.01408288162201643
Loss at iteration 180 : 0.011556440964341164
Loss at iteration 190 : 0.009622214362025261
Loss at iteration 200 : 0.007218100130558014
Loss at iteration 210 : 0.007381661795079708
Loss at iteration 220 : 0.002739794785156846
Loss at iteration 230 : 0.006170950829982758
Loss at iteration 240 : 0.01141098327934742
Loss at iteration 250 : 0.0038678657729178667
Loss at iteration 260 : 0.005038152448832989
Loss at iteration 270 : 0.009602753445506096
Loss at iteration 280 : 0.010613075457513332
Loss at iteration 290 : 0.008956135250627995
Loss at iteration 300 : 0.008307992480695248
Loss at iteration 310 : 0.0033787451684474945
Loss at iteration 320 : 0.02084929123520851
Loss at iteration 330 : 0.006222127005457878
Loss at iteration 340 : 0.004433325491845608
Loss at iteration 350 : 0.007430706638842821
Loss at iteration 360 : 0.007099447771906853
Loss at iteration 370 : 0.005607155151665211
Loss at iteration 380 : 0.008272240869700909
Loss at iteration 390 : 0.008691927418112755
Loss at iteration 400 : 0.008493891917169094
Loss at iteration 410 : 0.00558940414339304
Loss at iteration 420 : 0.0106188440695405
Loss at iteration 430 : 0.009849239140748978
Loss at iteration 440 : 0.021920785307884216
Loss at iteration 450 : 0.009800169616937637
Loss at iteration 460 : 0.006426427513360977
Loss at iteration 470 : 0.0033522904850542545
Loss at iteration 480 : 0.01370405312627554
Loss at iteration 490 : 0.006095940712839365
Loss at iteration 500 : 0.011288979090750217
Loss at iteration 510 : 0.002901666332036257
Loss at iteration 520 : 0.005905797239392996
Loss at iteration 530 : 0.005503029562532902
Loss at iteration 540 : 0.014131452888250351
Loss at iteration 550 : 0.007585548330098391
Loss at iteration 560 : 0.007802644744515419
Loss at iteration 570 : 0.0076824272982776165
Loss at iteration 580 : 0.01145926583558321
Loss at iteration 590 : 0.009460886009037495
Loss at iteration 600 : 0.005872718058526516
Loss at iteration 610 : 0.002866278402507305
Loss at iteration 620 : 0.008147229440510273
Loss at iteration 630 : 0.01371046993881464
Loss at iteration 640 : 0.005771760828793049
Loss at iteration 650 : 0.005792166106402874
Loss at iteration 660 : 0.012449011206626892
Loss at iteration 670 : 0.006979838944971561
Loss at iteration 680 : 0.00360270868986845
Loss at iteration 690 : 0.00665291678160429
Loss at iteration 700 : 0.008906777948141098
Loss at iteration 710 : 0.009741113521158695
Loss at iteration 720 : 0.0061320289969444275
Loss at iteration 730 : 0.007888451218605042
Loss at iteration 740 : 0.00704613234847784
Loss at iteration 750 : 0.003743202658370137
Loss at iteration 760 : 0.005428562872111797
Loss at iteration 770 : 0.0068025435321033
Loss at iteration 780 : 0.0065855165012180805
Loss at iteration 790 : 0.012529367581009865
Loss at iteration 800 : 0.005305323749780655
Loss at iteration 810 : 0.007842385210096836
Loss at iteration 820 : 0.010365013964474201
Loss at iteration 830 : 0.0055143265053629875
Loss at iteration 840 : 0.00864005833864212
Loss at iteration 850 : 0.016558345407247543
Loss at iteration 860 : 0.007165035232901573
Loss at iteration 870 : 0.010128233581781387
Loss at iteration 880 : 0.0033418056555092335
Loss at iteration 890 : 0.011571299284696579
Loss at iteration 900 : 0.004884406924247742
Loss at iteration 910 : 0.010349282063543797
Loss at iteration 920 : 0.007350012194365263
Loss at iteration 930 : 0.013474752195179462
Loss at iteration 940 : 0.009949072264134884
Loss at iteration 950 : 0.00912921130657196
Loss at iteration 960 : 0.002600795589387417
Loss at iteration 970 : 0.010190515778958797
Loss at iteration 980 : 0.006061471067368984
Loss at iteration 990 : 0.0044720470905303955
Loss at iteration 1000 : 0.0094230268150568
Loss at iteration 1010 : 0.006556681357324123
Loss at iteration 1020 : 0.007288707885891199
Loss at iteration 1030 : 0.004202932585030794
Loss at iteration 1040 : 0.005926582496613264
Loss at iteration 1050 : 0.006740377750247717
Loss at iteration 1060 : 0.007042706944048405
Loss at iteration 1070 : 0.006788522936403751
Loss at iteration 1080 : 0.005410401616245508
Loss at iteration 1090 : 0.005041639320552349
Loss at iteration 1100 : 0.004103492945432663
Loss at iteration 1110 : 0.017262108623981476
Loss at iteration 1120 : 0.0054084742441773415
Loss at iteration 1130 : 0.005495849531143904
Loss at iteration 1140 : 0.004745728801935911
Loss at iteration 1150 : 0.010084789246320724
Loss at iteration 1160 : 0.011430852115154266
Loss at iteration 1170 : 0.006414275616407394
Loss at iteration 1180 : 0.006125312298536301
Loss at iteration 1190 : 0.004927929490804672
Loss at iteration 1200 : 0.0054483069106936455
Loss at iteration 1210 : 0.005325758829712868
Loss at iteration 1220 : 0.012219585478305817
Loss at iteration 1230 : 0.008589575067162514
Loss at iteration 1240 : 0.008264884352684021
Loss at iteration 1250 : 0.00839219894260168
Loss at iteration 1260 : 0.004979776218533516
Loss at iteration 1270 : 0.006329108960926533
Loss at iteration 1280 : 0.008858703076839447
Loss at iteration 1290 : 0.017009716480970383
Loss at iteration 1300 : 0.014270860701799393
Loss at iteration 1310 : 0.0047111110761761665
Loss at iteration 1320 : 0.01636573299765587
Loss at iteration 1330 : 0.005960834678262472
Loss at iteration 1340 : 0.006880845408886671
Loss at iteration 1350 : 0.0067173633724451065
Loss at iteration 1360 : 0.0065507288090884686
Loss at iteration 1370 : 0.010365007445216179
Loss at iteration 1380 : 0.015148984268307686
Loss at iteration 1390 : 0.0022449553944170475
Loss at iteration 1400 : 0.00860175397247076
Loss at iteration 1410 : 0.007858086377382278
Loss at iteration 1420 : 0.009887756779789925
Loss at iteration 1430 : 0.009564216248691082
Loss at iteration 1440 : 0.01630503311753273
Loss at iteration 1450 : 0.010693145915865898
Loss at iteration 1460 : 0.009661760181188583
Loss at iteration 1470 : 0.01429375447332859
Loss at iteration 1480 : 0.01008268166333437
Loss at iteration 1490 : 0.007186908274888992
Loss at iteration 1500 : 0.005724740214645863
Loss at iteration 1510 : 0.006900294683873653
Loss at iteration 1520 : 0.011630971916019917
Loss at iteration 1530 : 0.006659455131739378
Loss at iteration 1540 : 0.00815882720053196
Loss at iteration 1550 : 0.006513873115181923
Loss at iteration 1560 : 0.01207959745079279
Loss at iteration 1570 : 0.006264501251280308
Loss at iteration 1580 : 0.0025770235806703568
Loss at iteration 1590 : 0.006007773336023092
Loss at iteration 1600 : 0.010050621815025806
Loss at iteration 1610 : 0.0030256561003625393
Loss at iteration 1620 : 0.011445993557572365
Loss at iteration 1630 : 0.007063308265060186
Loss at iteration 1640 : 0.0164056234061718
Loss at iteration 1650 : 0.006706688087433577
Loss at iteration 1660 : 0.006035144440829754
Loss at iteration 1670 : 0.008790121413767338
Loss at iteration 1680 : 0.007476371247321367
Loss at iteration 1690 : 0.019531991332769394
Loss at iteration 1700 : 0.009321175515651703
Loss at iteration 1710 : 0.004430278204381466
Loss at iteration 1720 : 0.007999014109373093
Loss at iteration 1730 : 0.006093291100114584
Loss at iteration 1740 : 0.008216315880417824
Loss at iteration 1750 : 0.010543796233832836
Loss at iteration 1760 : 0.0171493086963892
Loss at iteration 1770 : 0.009437951259315014
Loss at iteration 1780 : 0.0058121271431446075
Loss at iteration 1790 : 0.006487876642495394
Loss at iteration 1800 : 0.0070544518530368805
Loss at iteration 1810 : 0.005735526792705059
Loss at iteration 1820 : 0.009695257060229778
Loss at iteration 1830 : 0.008275003172457218
Loss at iteration 1840 : 0.012928059324622154
Loss at iteration 1850 : 0.00622984953224659
Loss at iteration 1860 : 0.02005484327673912
Loss at iteration 1870 : 0.004959414713084698
Loss at iteration 1880 : 0.007457960397005081
Loss at iteration 1890 : 0.005428739357739687
Loss at iteration 1900 : 0.011377960443496704
Loss at iteration 1910 : 0.015641700476408005
Loss at iteration 1920 : 0.01022680290043354
Loss at iteration 1930 : 0.0064733074977993965
Loss at iteration 1940 : 0.007651391439139843
Loss at iteration 1950 : 0.01507764495909214
Loss at iteration 1960 : 0.008144024759531021
Loss at iteration 1970 : 0.011280659586191177
Loss at iteration 1980 : 0.0068946401588618755
Loss at iteration 1990 : 0.005772875156253576
Loss at iteration 2000 : 0.00422324426472187
Loss at iteration 2010 : 0.016924742609262466
Loss at iteration 2020 : 0.006499367766082287
Loss at iteration 2030 : 0.009838606230914593
Loss at iteration 2040 : 0.020781002938747406
Loss at iteration 2050 : 0.009625704027712345
Loss at iteration 2060 : 0.019206635653972626
Loss at iteration 2070 : 0.021935084834694862
Loss at iteration 2080 : 0.01273820735514164
Loss at iteration 2090 : 0.008594349026679993
Loss at iteration 2100 : 0.008535390719771385
Loss at iteration 2110 : 0.006901515647768974
Loss at iteration 2120 : 0.004670834634453058
Loss at iteration 2130 : 0.008529288694262505
Loss at iteration 2140 : 0.00875790324062109
Loss at iteration 2150 : 0.012090750969946384
Loss at iteration 2160 : 0.018388861790299416
Loss at iteration 2170 : 0.011001260951161385
Loss at iteration 2180 : 0.007044018246233463
Loss at iteration 2190 : 0.009840341284871101
Loss at iteration 2200 : 0.006027067080140114
Loss at iteration 2210 : 0.005580240860581398
Loss at iteration 2220 : 0.009042041376233101
Loss at iteration 2230 : 0.015868667513132095
Loss at iteration 2240 : 0.006512321066111326
Loss at iteration 2250 : 0.0035344399511814117
Loss at iteration 2260 : 0.01374115888029337
Loss at iteration 2270 : 0.004392501898109913
Loss at iteration 2280 : 0.014378639869391918
Loss at iteration 2290 : 0.005901527591049671
Loss at iteration 2300 : 0.009556871838867664
Loss at iteration 2310 : 0.003650563070550561
Loss at iteration 2320 : 0.006570546422153711
Loss at iteration 2330 : 0.002272510202601552
Loss at iteration 2340 : 0.015204054303467274
Loss at iteration 2350 : 0.00750925624743104
Loss at iteration 2360 : 0.0047987075522542
Loss at iteration 2370 : 0.004633510485291481
Loss at iteration 2380 : 0.012058340944349766
Loss at iteration 2390 : 0.009002052247524261
Loss at iteration 2400 : 0.013780955225229263
Loss at iteration 2410 : 0.008877112530171871
Loss at iteration 2420 : 0.00742713175714016
The SSIM Value is: 0.8518173416455587
The PSNR Value is: 22.546988677978515
the epoch is: 95
Loss at iteration 10 : 0.00955553725361824
Loss at iteration 20 : 0.005611160304397345
Loss at iteration 30 : 0.010029885917901993
Loss at iteration 40 : 0.024509534239768982
Loss at iteration 50 : 0.005254578776657581
Loss at iteration 60 : 0.010182795114815235
Loss at iteration 70 : 0.010846302844583988
Loss at iteration 80 : 0.0070707229897379875
Loss at iteration 90 : 0.007899469695985317
Loss at iteration 100 : 0.006121480371803045
Loss at iteration 110 : 0.007777299731969833
Loss at iteration 120 : 0.00907834805548191
Loss at iteration 130 : 0.010729076340794563
Loss at iteration 140 : 0.010433374904096127
Loss at iteration 150 : 0.007904326543211937
Loss at iteration 160 : 0.010875372216105461
Loss at iteration 170 : 0.016968591138720512
Loss at iteration 180 : 0.003313665511086583
Loss at iteration 190 : 0.009107677266001701
Loss at iteration 200 : 0.009900414384901524
Loss at iteration 210 : 0.005187876522541046
Loss at iteration 220 : 0.006879313848912716
Loss at iteration 230 : 0.003311396576464176
Loss at iteration 240 : 0.018138397485017776
Loss at iteration 250 : 0.006482093129307032
Loss at iteration 260 : 0.009342959150671959
Loss at iteration 270 : 0.005471128039062023
Loss at iteration 280 : 0.015973102301359177
Loss at iteration 290 : 0.0038529355078935623
Loss at iteration 300 : 0.006070176605135202
Loss at iteration 310 : 0.011276924051344395
Loss at iteration 320 : 0.004402562510222197
Loss at iteration 330 : 0.009461489506065845
Loss at iteration 340 : 0.010639849118888378
Loss at iteration 350 : 0.005722853355109692
Loss at iteration 360 : 0.006034102290868759
Loss at iteration 370 : 0.012219266965985298
Loss at iteration 380 : 0.008057942613959312
Loss at iteration 390 : 0.008603017777204514
Loss at iteration 400 : 0.003708865726366639
Loss at iteration 410 : 0.01553822960704565
Loss at iteration 420 : 0.01079152524471283
Loss at iteration 430 : 0.007223197259008884
Loss at iteration 440 : 0.00613622460514307
Loss at iteration 450 : 0.01608872041106224
Loss at iteration 460 : 0.01354490127414465
Loss at iteration 470 : 0.009670604020357132
Loss at iteration 480 : 0.003778213867917657
Loss at iteration 490 : 0.007147233001887798
Loss at iteration 500 : 0.002720469143241644
Loss at iteration 510 : 0.013400454074144363
Loss at iteration 520 : 0.01136519480496645
Loss at iteration 530 : 0.011025510728359222
Loss at iteration 540 : 0.0069986367598176
Loss at iteration 550 : 0.007452396210283041
Loss at iteration 560 : 0.005461278837174177
Loss at iteration 570 : 0.006955208722501993
Loss at iteration 580 : 0.010023955255746841
Loss at iteration 590 : 0.004041798412799835
Loss at iteration 600 : 0.009518643841147423
Loss at iteration 610 : 0.008373811841011047
Loss at iteration 620 : 0.007516802288591862
Loss at iteration 630 : 0.008449933491647243
Loss at iteration 640 : 0.009698230773210526
Loss at iteration 650 : 0.005087716039270163
Loss at iteration 660 : 0.004676115233451128
Loss at iteration 670 : 0.011053278110921383
Loss at iteration 680 : 0.011626987718045712
Loss at iteration 690 : 0.006450760643929243
Loss at iteration 700 : 0.004364805296063423
Loss at iteration 710 : 0.008274673484265804
Loss at iteration 720 : 0.002156993607059121
Loss at iteration 730 : 0.017438560724258423
Loss at iteration 740 : 0.010044518858194351
Loss at iteration 750 : 0.009481710381805897
Loss at iteration 760 : 0.007138024549931288
Loss at iteration 770 : 0.007185101974755526
Loss at iteration 780 : 0.005518288351595402
Loss at iteration 790 : 0.010643983259797096
Loss at iteration 800 : 0.004543688148260117
Loss at iteration 810 : 0.01131853461265564
Loss at iteration 820 : 0.018286757171154022
Loss at iteration 830 : 0.003940887283533812
Loss at iteration 840 : 0.01375757995992899
Loss at iteration 850 : 0.008267471566796303
Loss at iteration 860 : 0.008652761578559875
Loss at iteration 870 : 0.00583628099411726
Loss at iteration 880 : 0.007818003185093403
Loss at iteration 890 : 0.006546167656779289
Loss at iteration 900 : 0.007263187784701586
Loss at iteration 910 : 0.011379541829228401
Loss at iteration 920 : 0.01580318808555603
Loss at iteration 930 : 0.008845388889312744
Loss at iteration 940 : 0.006754499860107899
Loss at iteration 950 : 0.018291974440217018
Loss at iteration 960 : 0.008793366141617298
Loss at iteration 970 : 0.0131545290350914
Loss at iteration 980 : 0.010591628961265087
Loss at iteration 990 : 0.009679991751909256
Loss at iteration 1000 : 0.010529683902859688
Loss at iteration 1010 : 0.0036598551087081432
Loss at iteration 1020 : 0.007841215468943119
Loss at iteration 1030 : 0.013686390593647957
Loss at iteration 1040 : 0.008763575926423073
Loss at iteration 1050 : 0.0034602254163473845
Loss at iteration 1060 : 0.005056200549006462
Loss at iteration 1070 : 0.007280905265361071
Loss at iteration 1080 : 0.013094739988446236
Loss at iteration 1090 : 0.004628930240869522
Loss at iteration 1100 : 0.018681460991501808
Loss at iteration 1110 : 0.01865329034626484
Loss at iteration 1120 : 0.004622535314410925
Loss at iteration 1130 : 0.008283857256174088
Loss at iteration 1140 : 0.005235257558524609
Loss at iteration 1150 : 0.01330616045743227
Loss at iteration 1160 : 0.006128039211034775
Loss at iteration 1170 : 0.007636167109012604
Loss at iteration 1180 : 0.007740399334579706
Loss at iteration 1190 : 0.013750619255006313
Loss at iteration 1200 : 0.013913847506046295
Loss at iteration 1210 : 0.007347242906689644
Loss at iteration 1220 : 0.012583203613758087
Loss at iteration 1230 : 0.012950430624186993
Loss at iteration 1240 : 0.0057922061532735825
Loss at iteration 1250 : 0.00901157408952713
Loss at iteration 1260 : 0.021519577130675316
Loss at iteration 1270 : 0.016173768788576126
Loss at iteration 1280 : 0.0339793860912323
Loss at iteration 1290 : 0.011536883190274239
Loss at iteration 1300 : 0.01181081309914589
Loss at iteration 1310 : 0.007845887914299965
Loss at iteration 1320 : 0.00392756424844265
Loss at iteration 1330 : 0.011050445027649403
Loss at iteration 1340 : 0.02118806354701519
Loss at iteration 1350 : 0.006106615532189608
Loss at iteration 1360 : 0.006413780618458986
Loss at iteration 1370 : 0.013257162645459175
Loss at iteration 1380 : 0.015911825001239777
Loss at iteration 1390 : 0.009234382770955563
Loss at iteration 1400 : 0.00819043256342411
Loss at iteration 1410 : 0.0070134494453668594
Loss at iteration 1420 : 0.007005653344094753
Loss at iteration 1430 : 0.007085811346769333
Loss at iteration 1440 : 0.005868217907845974
Loss at iteration 1450 : 0.00406951829791069
Loss at iteration 1460 : 0.015185292810201645
Loss at iteration 1470 : 0.014548138715326786
Loss at iteration 1480 : 0.011630984954535961
Loss at iteration 1490 : 0.005958897061645985
Loss at iteration 1500 : 0.0029782901983708143
Loss at iteration 1510 : 0.016237609088420868
Loss at iteration 1520 : 0.007322654128074646
Loss at iteration 1530 : 0.006446750368922949
Loss at iteration 1540 : 0.01117430254817009
Loss at iteration 1550 : 0.004705156199634075
Loss at iteration 1560 : 0.006784249097108841
Loss at iteration 1570 : 0.012231238186359406
Loss at iteration 1580 : 0.03755899518728256
Loss at iteration 1590 : 0.005337746813893318
Loss at iteration 1600 : 0.008635718375444412
Loss at iteration 1610 : 0.009272093884646893
Loss at iteration 1620 : 0.006999710574746132
Loss at iteration 1630 : 0.007580705918371677
Loss at iteration 1640 : 0.00721112173050642
Loss at iteration 1650 : 0.013860036619007587
Loss at iteration 1660 : 0.00810087937861681
Loss at iteration 1670 : 0.0076722316443920135
Loss at iteration 1680 : 0.005747505929321051
Loss at iteration 1690 : 0.0113594438880682
Loss at iteration 1700 : 0.011447680182754993
Loss at iteration 1710 : 0.007095664739608765
Loss at iteration 1720 : 0.00439724326133728
Loss at iteration 1730 : 0.008800335228443146
Loss at iteration 1740 : 0.006500329822301865
Loss at iteration 1750 : 0.018310721963644028
Loss at iteration 1760 : 0.017830077558755875
Loss at iteration 1770 : 0.005359220318496227
Loss at iteration 1780 : 0.009568354114890099
Loss at iteration 1790 : 0.007048403844237328
Loss at iteration 1800 : 0.008266777731478214
Loss at iteration 1810 : 0.01016190554946661
Loss at iteration 1820 : 0.012329737655818462
Loss at iteration 1830 : 0.004037393257021904
Loss at iteration 1840 : 0.006921517662703991
Loss at iteration 1850 : 0.008270977064967155
Loss at iteration 1860 : 0.01336041372269392
Loss at iteration 1870 : 0.003161650151014328
Loss at iteration 1880 : 0.00965791568160057
Loss at iteration 1890 : 0.008166170679032803
Loss at iteration 1900 : 0.015516144223511219
Loss at iteration 1910 : 0.011356430128216743
Loss at iteration 1920 : 0.00951194204390049
Loss at iteration 1930 : 0.010099975392222404
Loss at iteration 1940 : 0.012174488976597786
Loss at iteration 1950 : 0.0046217674389481544
Loss at iteration 1960 : 0.010250801220536232
Loss at iteration 1970 : 0.008588336408138275
Loss at iteration 1980 : 0.005247290711849928
Loss at iteration 1990 : 0.007086338475346565
Loss at iteration 2000 : 0.006034302990883589
Loss at iteration 2010 : 0.009891063906252384
Loss at iteration 2020 : 0.014136934652924538
Loss at iteration 2030 : 0.006986783817410469
Loss at iteration 2040 : 0.02388853393495083
Loss at iteration 2050 : 0.014606412500143051
Loss at iteration 2060 : 0.004731787834316492
Loss at iteration 2070 : 0.0066021522507071495
Loss at iteration 2080 : 0.009387168101966381
Loss at iteration 2090 : 0.008655374869704247
Loss at iteration 2100 : 0.006215247325599194
Loss at iteration 2110 : 0.013589325360953808
Loss at iteration 2120 : 0.00524577870965004
Loss at iteration 2130 : 0.00479124765843153
Loss at iteration 2140 : 0.012845856137573719
Loss at iteration 2150 : 0.004683380015194416
Loss at iteration 2160 : 0.010028774850070477
Loss at iteration 2170 : 0.008149818517267704
Loss at iteration 2180 : 0.006456247065216303
Loss at iteration 2190 : 0.007937334477901459
Loss at iteration 2200 : 0.006444796919822693
Loss at iteration 2210 : 0.010620178654789925
Loss at iteration 2220 : 0.012409579940140247
Loss at iteration 2230 : 0.007327829487621784
Loss at iteration 2240 : 0.009250778704881668
Loss at iteration 2250 : 0.006755885202437639
Loss at iteration 2260 : 0.01211167499423027
Loss at iteration 2270 : 0.013436621055006981
Loss at iteration 2280 : 0.003838267643004656
Loss at iteration 2290 : 0.00750991515815258
Loss at iteration 2300 : 0.021067075431346893
Loss at iteration 2310 : 0.0035677102860063314
Loss at iteration 2320 : 0.0058691659942269325
Loss at iteration 2330 : 0.010354605503380299
Loss at iteration 2340 : 0.0061264908872544765
Loss at iteration 2350 : 0.010099126026034355
Loss at iteration 2360 : 0.008748888038098812
Loss at iteration 2370 : 0.012451205402612686
Loss at iteration 2380 : 0.016261007636785507
Loss at iteration 2390 : 0.011577331461012363
Loss at iteration 2400 : 0.0038674348033964634
Loss at iteration 2410 : 0.006799908354878426
Loss at iteration 2420 : 0.011961500160396099
The SSIM Value is: 0.8390411694844564
The PSNR Value is: 22.390869649251304
the epoch is: 96
Loss at iteration 10 : 0.014199182391166687
Loss at iteration 20 : 0.006321133114397526
Loss at iteration 30 : 0.009995484724640846
Loss at iteration 40 : 0.01821126975119114
Loss at iteration 50 : 0.009187491610646248
Loss at iteration 60 : 0.014873543754220009
Loss at iteration 70 : 0.02076803147792816
Loss at iteration 80 : 0.01713138073682785
Loss at iteration 90 : 0.015356659889221191
Loss at iteration 100 : 0.02276040054857731
Loss at iteration 110 : 0.012891637161374092
Loss at iteration 120 : 0.003691533114761114
Loss at iteration 130 : 0.007884891703724861
Loss at iteration 140 : 0.006763393059372902
Loss at iteration 150 : 0.00629003532230854
Loss at iteration 160 : 0.0057478658854961395
Loss at iteration 170 : 0.014863036572933197
Loss at iteration 180 : 0.011745537631213665
Loss at iteration 190 : 0.013242780230939388
Loss at iteration 200 : 0.018115021288394928
Loss at iteration 210 : 0.0068148537538945675
Loss at iteration 220 : 0.012055895291268826
Loss at iteration 230 : 0.006717705633491278
Loss at iteration 240 : 0.009149103425443172
Loss at iteration 250 : 0.006227609235793352
Loss at iteration 260 : 0.007829327136278152
Loss at iteration 270 : 0.003198947524651885
Loss at iteration 280 : 0.002552282065153122
Loss at iteration 290 : 0.008902164176106453
Loss at iteration 300 : 0.006998363882303238
Loss at iteration 310 : 0.005932524334639311
Loss at iteration 320 : 0.0063738408498466015
Loss at iteration 330 : 0.004601703025400639
Loss at iteration 340 : 0.003855532966554165
Loss at iteration 350 : 0.009467496536672115
Loss at iteration 360 : 0.00784141942858696
Loss at iteration 370 : 0.011682420037686825
Loss at iteration 380 : 0.010861356742680073
Loss at iteration 390 : 0.011895504780113697
Loss at iteration 400 : 0.005740520544350147
Loss at iteration 410 : 0.005130840465426445
Loss at iteration 420 : 0.005202921107411385
Loss at iteration 430 : 0.0028622942045331
Loss at iteration 440 : 0.011292966082692146
Loss at iteration 450 : 0.003081702860072255
Loss at iteration 460 : 0.012762423604726791
Loss at iteration 470 : 0.017134997993707657
Loss at iteration 480 : 0.011037740856409073
Loss at iteration 490 : 0.011435757391154766
Loss at iteration 500 : 0.01108807697892189
Loss at iteration 510 : 0.01707138679921627
Loss at iteration 520 : 0.008848677389323711
Loss at iteration 530 : 0.00841592252254486
Loss at iteration 540 : 0.01032696757465601
Loss at iteration 550 : 0.004583465866744518
Loss at iteration 560 : 0.0111025869846344
Loss at iteration 570 : 0.006110940128564835
Loss at iteration 580 : 0.006060456857085228
Loss at iteration 590 : 0.009789734147489071
Loss at iteration 600 : 0.009744089096784592
Loss at iteration 610 : 0.008038491010665894
Loss at iteration 620 : 0.00968978926539421
Loss at iteration 630 : 0.007780183106660843
Loss at iteration 640 : 0.0035594103392213583
Loss at iteration 650 : 0.010426074266433716
Loss at iteration 660 : 0.0024003651924431324
Loss at iteration 670 : 0.007945591583848
Loss at iteration 680 : 0.01350174006074667
Loss at iteration 690 : 0.0029259314760565758
Loss at iteration 700 : 0.003731049597263336
Loss at iteration 710 : 0.014317657798528671
Loss at iteration 720 : 0.0035032092127949
Loss at iteration 730 : 0.003464343026280403
Loss at iteration 740 : 0.006794560234993696
Loss at iteration 750 : 0.007880030199885368
Loss at iteration 760 : 0.0023580293636769056
Loss at iteration 770 : 0.010491440072655678
Loss at iteration 780 : 0.009314711205661297
Loss at iteration 790 : 0.007626318372786045
Loss at iteration 800 : 0.003000183729454875
Loss at iteration 810 : 0.011734338477253914
Loss at iteration 820 : 0.006070801056921482
Loss at iteration 830 : 0.012196408584713936
Loss at iteration 840 : 0.006286689545959234
Loss at iteration 850 : 0.007722762413322926
Loss at iteration 860 : 0.017099110409617424
Loss at iteration 870 : 0.013831663876771927
Loss at iteration 880 : 0.01721281185746193
Loss at iteration 890 : 0.004927413538098335
Loss at iteration 900 : 0.020989662036299706
Loss at iteration 910 : 0.009747561067342758
Loss at iteration 920 : 0.009038960561156273
Loss at iteration 930 : 0.007446713279932737
Loss at iteration 940 : 0.013996482826769352
Loss at iteration 950 : 0.005526605062186718
Loss at iteration 960 : 0.005622255615890026
Loss at iteration 970 : 0.006987538654357195
Loss at iteration 980 : 0.006028450094163418
Loss at iteration 990 : 0.008983485400676727
Loss at iteration 1000 : 0.01993974670767784
Loss at iteration 1010 : 0.00543156499043107
Loss at iteration 1020 : 0.0038550905883312225
Loss at iteration 1030 : 0.01723085530102253
Loss at iteration 1040 : 0.011189677752554417
Loss at iteration 1050 : 0.015561256557703018
Loss at iteration 1060 : 0.004444628022611141
Loss at iteration 1070 : 0.00408496567979455
Loss at iteration 1080 : 0.006779830902814865
Loss at iteration 1090 : 0.013786865398287773
Loss at iteration 1100 : 0.004181534983217716
Loss at iteration 1110 : 0.005383669398725033
Loss at iteration 1120 : 0.004247309640049934
Loss at iteration 1130 : 0.013093579560518265
Loss at iteration 1140 : 0.007248592562973499
Loss at iteration 1150 : 0.007919863797724247
Loss at iteration 1160 : 0.005979970563203096
Loss at iteration 1170 : 0.008563579991459846
Loss at iteration 1180 : 0.008387656882405281
Loss at iteration 1190 : 0.015816766768693924
Loss at iteration 1200 : 0.010348891839385033
Loss at iteration 1210 : 0.014952881261706352
Loss at iteration 1220 : 0.015272112563252449
Loss at iteration 1230 : 0.005967751611024141
Loss at iteration 1240 : 0.017728090286254883
Loss at iteration 1250 : 0.010049981065094471
Loss at iteration 1260 : 0.004011365119367838
Loss at iteration 1270 : 0.010439872741699219
Loss at iteration 1280 : 0.00600187573581934
Loss at iteration 1290 : 0.006484033074229956
Loss at iteration 1300 : 0.009275670163333416
Loss at iteration 1310 : 0.006197775714099407
Loss at iteration 1320 : 0.01103997603058815
Loss at iteration 1330 : 0.0021371077746152878
Loss at iteration 1340 : 0.006846719421446323
Loss at iteration 1350 : 0.0039863670244812965
Loss at iteration 1360 : 0.009939412586390972
Loss at iteration 1370 : 0.009656190872192383
Loss at iteration 1380 : 0.015141132287681103
Loss at iteration 1390 : 0.005827673710882664
Loss at iteration 1400 : 0.00699873361736536
Loss at iteration 1410 : 0.0033491342328488827
Loss at iteration 1420 : 0.005415334366261959
Loss at iteration 1430 : 0.009765497408807278
Loss at iteration 1440 : 0.007387430407106876
Loss at iteration 1450 : 0.014471393078565598
Loss at iteration 1460 : 0.005497363395988941
Loss at iteration 1470 : 0.014556742273271084
Loss at iteration 1480 : 0.00483322748914361
Loss at iteration 1490 : 0.03122837468981743
Loss at iteration 1500 : 0.009975801222026348
Loss at iteration 1510 : 0.008538398891687393
Loss at iteration 1520 : 0.0070454636588692665
Loss at iteration 1530 : 0.004624916240572929
Loss at iteration 1540 : 0.010402004234492779
Loss at iteration 1550 : 0.010381550528109074
Loss at iteration 1560 : 0.006168072577565908
Loss at iteration 1570 : 0.013251939788460732
Loss at iteration 1580 : 0.012761052697896957
Loss at iteration 1590 : 0.008251347579061985
Loss at iteration 1600 : 0.006467642728239298
Loss at iteration 1610 : 0.01243911124765873
Loss at iteration 1620 : 0.004618438892066479
Loss at iteration 1630 : 0.00858707632869482
Loss at iteration 1640 : 0.009342480450868607
Loss at iteration 1650 : 0.007827038876712322
Loss at iteration 1660 : 0.007773727178573608
Loss at iteration 1670 : 0.006280248053371906
Loss at iteration 1680 : 0.012846139259636402
Loss at iteration 1690 : 0.00789653044193983
Loss at iteration 1700 : 0.00898507609963417
Loss at iteration 1710 : 0.01297701708972454
Loss at iteration 1720 : 0.018869012594223022
Loss at iteration 1730 : 0.006306931376457214
Loss at iteration 1740 : 0.004452497698366642
Loss at iteration 1750 : 0.0057335300371050835
Loss at iteration 1760 : 0.010822531767189503
Loss at iteration 1770 : 0.004750277381390333
Loss at iteration 1780 : 0.003988736774772406
Loss at iteration 1790 : 0.005629697348922491
Loss at iteration 1800 : 0.012632550671696663
Loss at iteration 1810 : 0.00859016738831997
Loss at iteration 1820 : 0.016627972945570946
Loss at iteration 1830 : 0.011437073349952698
Loss at iteration 1840 : 0.016879908740520477
Loss at iteration 1850 : 0.008304683491587639
Loss at iteration 1860 : 0.008141951635479927
Loss at iteration 1870 : 0.005936195142567158
Loss at iteration 1880 : 0.008099054917693138
Loss at iteration 1890 : 0.0027237029280513525
Loss at iteration 1900 : 0.007875002920627594
Loss at iteration 1910 : 0.011654331348836422
Loss at iteration 1920 : 0.0055079227313399315
Loss at iteration 1930 : 0.012147024273872375
Loss at iteration 1940 : 0.0064866626635193825
Loss at iteration 1950 : 0.0029559244867414236
Loss at iteration 1960 : 0.006531926803290844
Loss at iteration 1970 : 0.005546957720071077
Loss at iteration 1980 : 0.005653327330946922
Loss at iteration 1990 : 0.011048698797821999
Loss at iteration 2000 : 0.003977833315730095
Loss at iteration 2010 : 0.004463026765733957
Loss at iteration 2020 : 0.01330186054110527
Loss at iteration 2030 : 0.011900955811142921
Loss at iteration 2040 : 0.01036167424172163
Loss at iteration 2050 : 0.00851055420935154
Loss at iteration 2060 : 0.005181128159165382
Loss at iteration 2070 : 0.007531699724495411
Loss at iteration 2080 : 0.02592175267636776
Loss at iteration 2090 : 0.008238403126597404
Loss at iteration 2100 : 0.00854398962110281
Loss at iteration 2110 : 0.004750688560307026
Loss at iteration 2120 : 0.001530672307126224
Loss at iteration 2130 : 0.015200856141746044
Loss at iteration 2140 : 0.00699341855943203
Loss at iteration 2150 : 0.013407876715064049
Loss at iteration 2160 : 0.005097593646496534
Loss at iteration 2170 : 0.007428377866744995
Loss at iteration 2180 : 0.018577806651592255
Loss at iteration 2190 : 0.011734012514352798
Loss at iteration 2200 : 0.0048827831633389
Loss at iteration 2210 : 0.012095828540623188
Loss at iteration 2220 : 0.009146785363554955
Loss at iteration 2230 : 0.006394854746758938
Loss at iteration 2240 : 0.011808626353740692
Loss at iteration 2250 : 0.006399259902536869
Loss at iteration 2260 : 0.00819557998329401
Loss at iteration 2270 : 0.006933866534382105
Loss at iteration 2280 : 0.007233718875795603
Loss at iteration 2290 : 0.007092694751918316
Loss at iteration 2300 : 0.006160759832710028
Loss at iteration 2310 : 0.009068076498806477
Loss at iteration 2320 : 0.005507376976311207
Loss at iteration 2330 : 0.010504530742764473
Loss at iteration 2340 : 0.001735445111989975
Loss at iteration 2350 : 0.006170423701405525
Loss at iteration 2360 : 0.016158899292349815
Loss at iteration 2370 : 0.0036660870537161827
Loss at iteration 2380 : 0.011346500366926193
Loss at iteration 2390 : 0.00931501667946577
Loss at iteration 2400 : 0.007534781936556101
Loss at iteration 2410 : 0.008805528283119202
Loss at iteration 2420 : 0.007999435998499393
The SSIM Value is: 0.8437339623769124
The PSNR Value is: 22.018769454956054
the epoch is: 97
Loss at iteration 10 : 0.007066858466714621
Loss at iteration 20 : 0.006615782156586647
Loss at iteration 30 : 0.01633305847644806
Loss at iteration 40 : 0.007425553631037474
Loss at iteration 50 : 0.007237989921122789
Loss at iteration 60 : 0.005408505443483591
Loss at iteration 70 : 0.008475948125123978
Loss at iteration 80 : 0.006264601368457079
Loss at iteration 90 : 0.005790654569864273
Loss at iteration 100 : 0.005151701625436544
Loss at iteration 110 : 0.007432653568685055
Loss at iteration 120 : 0.01308530569076538
Loss at iteration 130 : 0.025696346536278725
Loss at iteration 140 : 0.017629671841859818
Loss at iteration 150 : 0.0056376270949840546
Loss at iteration 160 : 0.010229984298348427
Loss at iteration 170 : 0.005377345718443394
Loss at iteration 180 : 0.008958647958934307
Loss at iteration 190 : 0.0020820866338908672
Loss at iteration 200 : 0.007062061689794064
Loss at iteration 210 : 0.003465444315224886
Loss at iteration 220 : 0.006460749544203281
Loss at iteration 230 : 0.007126450538635254
Loss at iteration 240 : 0.005631400737911463
Loss at iteration 250 : 0.003625499317422509
Loss at iteration 260 : 0.012420468963682652
Loss at iteration 270 : 0.007509968243539333
Loss at iteration 280 : 0.006928206887096167
Loss at iteration 290 : 0.007496675476431847
Loss at iteration 300 : 0.006587332114577293
Loss at iteration 310 : 0.006918972823768854
Loss at iteration 320 : 0.016906609758734703
Loss at iteration 330 : 0.006527860648930073
Loss at iteration 340 : 0.008783577010035515
Loss at iteration 350 : 0.0031253090128302574
Loss at iteration 360 : 0.007439983077347279
Loss at iteration 370 : 0.029926680028438568
Loss at iteration 380 : 0.013601599261164665
Loss at iteration 390 : 0.010143836960196495
Loss at iteration 400 : 0.010073746554553509
Loss at iteration 410 : 0.0022929420229047537
Loss at iteration 420 : 0.021052002906799316
Loss at iteration 430 : 0.011349706910550594
Loss at iteration 440 : 0.008083444088697433
Loss at iteration 450 : 0.007854008115828037
Loss at iteration 460 : 0.012878380715847015
Loss at iteration 470 : 0.017691919580101967
Loss at iteration 480 : 0.0064989542588591576
Loss at iteration 490 : 0.003072352148592472
Loss at iteration 500 : 0.009937635622918606
Loss at iteration 510 : 0.00689489021897316
Loss at iteration 520 : 0.007282590493559837
Loss at iteration 530 : 0.009580180048942566
Loss at iteration 540 : 0.0037975204177200794
Loss at iteration 550 : 0.007828179746866226
Loss at iteration 560 : 0.002780780429020524
Loss at iteration 570 : 0.00500428956001997
Loss at iteration 580 : 0.008603235706686974
Loss at iteration 590 : 0.006532801780849695
Loss at iteration 600 : 0.003681774716824293
Loss at iteration 610 : 0.005159411113709211
Loss at iteration 620 : 0.007012232672423124
Loss at iteration 630 : 0.010099008679389954
Loss at iteration 640 : 0.005548080895096064
Loss at iteration 650 : 0.016159402206540108
Loss at iteration 660 : 0.004207168705761433
Loss at iteration 670 : 0.004704885184764862
Loss at iteration 680 : 0.007493133656680584
Loss at iteration 690 : 0.006750974338501692
Loss at iteration 700 : 0.013463703915476799
Loss at iteration 710 : 0.0016256747767329216
Loss at iteration 720 : 0.0134580722078681
Loss at iteration 730 : 0.01160597987473011
Loss at iteration 740 : 0.005085259675979614
Loss at iteration 750 : 0.006958354264497757
Loss at iteration 760 : 0.006450635381042957
Loss at iteration 770 : 0.009009297005832195
Loss at iteration 780 : 0.014770377427339554
Loss at iteration 790 : 0.008724430575966835
Loss at iteration 800 : 0.02192307449877262
Loss at iteration 810 : 0.01325259730219841
Loss at iteration 820 : 0.010006467811763287
Loss at iteration 830 : 0.006268746219575405
Loss at iteration 840 : 0.01327600423246622
Loss at iteration 850 : 0.00915277749300003
Loss at iteration 860 : 0.012920777313411236
Loss at iteration 870 : 0.0039032823406159878
Loss at iteration 880 : 0.0155496159568429
Loss at iteration 890 : 0.0080281225964427
Loss at iteration 900 : 0.01840292103588581
Loss at iteration 910 : 0.004150193650275469
Loss at iteration 920 : 0.01043308712542057
Loss at iteration 930 : 0.011063830927014351
Loss at iteration 940 : 0.008607637137174606
Loss at iteration 950 : 0.024432798847556114
Loss at iteration 960 : 0.006593283265829086
Loss at iteration 970 : 0.006689579226076603
Loss at iteration 980 : 0.0031659065280109644
Loss at iteration 990 : 0.006149438209831715
Loss at iteration 1000 : 0.007719601970165968
Loss at iteration 1010 : 0.007995658554136753
Loss at iteration 1020 : 0.011041817255318165
Loss at iteration 1030 : 0.005267464555799961
Loss at iteration 1040 : 0.009496674872934818
Loss at iteration 1050 : 0.011457049287855625
Loss at iteration 1060 : 0.009729982353746891
Loss at iteration 1070 : 0.020229892805218697
Loss at iteration 1080 : 0.007837587967514992
Loss at iteration 1090 : 0.02318309061229229
Loss at iteration 1100 : 0.008311118930578232
Loss at iteration 1110 : 0.01029742881655693
Loss at iteration 1120 : 0.0073977187275886536
Loss at iteration 1130 : 0.008138942532241344
Loss at iteration 1140 : 0.015595201402902603
Loss at iteration 1150 : 0.011695771478116512
Loss at iteration 1160 : 0.013676147907972336
Loss at iteration 1170 : 0.004559410735964775
Loss at iteration 1180 : 0.004163374658674002
Loss at iteration 1190 : 0.01628711074590683
Loss at iteration 1200 : 0.009314768016338348
Loss at iteration 1210 : 0.0069814929738640785
Loss at iteration 1220 : 0.003583394456654787
Loss at iteration 1230 : 0.010072289034724236
Loss at iteration 1240 : 0.009007690474390984
Loss at iteration 1250 : 0.00716700404882431
Loss at iteration 1260 : 0.010527844540774822
Loss at iteration 1270 : 0.012639551423490047
Loss at iteration 1280 : 0.004457791335880756
Loss at iteration 1290 : 0.004718503449112177
Loss at iteration 1300 : 0.004627760034054518
Loss at iteration 1310 : 0.009368869476020336
Loss at iteration 1320 : 0.004289939999580383
Loss at iteration 1330 : 0.010509044863283634
Loss at iteration 1340 : 0.015706835314631462
Loss at iteration 1350 : 0.017365584149956703
Loss at iteration 1360 : 0.013492001220583916
Loss at iteration 1370 : 0.00969159509986639
Loss at iteration 1380 : 0.012704948894679546
Loss at iteration 1390 : 0.005006232298910618
Loss at iteration 1400 : 0.013103337027132511
Loss at iteration 1410 : 0.00667764013633132
Loss at iteration 1420 : 0.004152208101004362
Loss at iteration 1430 : 0.005271303467452526
Loss at iteration 1440 : 0.009645538404583931
Loss at iteration 1450 : 0.009766635484993458
Loss at iteration 1460 : 0.020309045910835266
Loss at iteration 1470 : 0.011532237753272057
Loss at iteration 1480 : 0.00363028421998024
Loss at iteration 1490 : 0.006062856875360012
Loss at iteration 1500 : 0.008936521597206593
Loss at iteration 1510 : 0.010253868997097015
Loss at iteration 1520 : 0.005977156572043896
Loss at iteration 1530 : 0.007910389453172684
Loss at iteration 1540 : 0.012121540494263172
Loss at iteration 1550 : 0.012293653562664986
Loss at iteration 1560 : 0.0070766727440059185
Loss at iteration 1570 : 0.010984156280755997
Loss at iteration 1580 : 0.006683598272502422
Loss at iteration 1590 : 0.011442415416240692
Loss at iteration 1600 : 0.018253888934850693
Loss at iteration 1610 : 0.010192902758717537
Loss at iteration 1620 : 0.019276786595582962
Loss at iteration 1630 : 0.011199945583939552
Loss at iteration 1640 : 0.01612231694161892
Loss at iteration 1650 : 0.004420621320605278
Loss at iteration 1660 : 0.005264440551400185
Loss at iteration 1670 : 0.012643746100366116
Loss at iteration 1680 : 0.00917986873537302
Loss at iteration 1690 : 0.016575321555137634
Loss at iteration 1700 : 0.008982229046523571
Loss at iteration 1710 : 0.005599397234618664
Loss at iteration 1720 : 0.016672849655151367
Loss at iteration 1730 : 0.011982602998614311
Loss at iteration 1740 : 0.0064740595407783985
Loss at iteration 1750 : 0.0055031985975801945
Loss at iteration 1760 : 0.008903339505195618
Loss at iteration 1770 : 0.010360293090343475
Loss at iteration 1780 : 0.012422727420926094
Loss at iteration 1790 : 0.004186284728348255
Loss at iteration 1800 : 0.010807105340063572
Loss at iteration 1810 : 0.005074171349406242
Loss at iteration 1820 : 0.010909577831625938
Loss at iteration 1830 : 0.004908011294901371
Loss at iteration 1840 : 0.010694924741983414
Loss at iteration 1850 : 0.010500452481210232
Loss at iteration 1860 : 0.009882568381726742
Loss at iteration 1870 : 0.007755231112241745
Loss at iteration 1880 : 0.006071038544178009
Loss at iteration 1890 : 0.008639432489871979
Loss at iteration 1900 : 0.02308117412030697
Loss at iteration 1910 : 0.013830826617777348
Loss at iteration 1920 : 0.00938576739281416
Loss at iteration 1930 : 0.0075343018397688866
Loss at iteration 1940 : 0.006411164999008179
Loss at iteration 1950 : 0.010166486725211143
Loss at iteration 1960 : 0.004734436050057411
Loss at iteration 1970 : 0.006845880765467882
Loss at iteration 1980 : 0.009745268151164055
Loss at iteration 1990 : 0.01108454167842865
Loss at iteration 2000 : 0.007881546393036842
Loss at iteration 2010 : 0.007506350986659527
Loss at iteration 2020 : 0.007837280631065369
Loss at iteration 2030 : 0.01147996075451374
Loss at iteration 2040 : 0.009989692829549313
Loss at iteration 2050 : 0.007805154658854008
Loss at iteration 2060 : 0.007152261212468147
Loss at iteration 2070 : 0.010767869651317596
Loss at iteration 2080 : 0.005129260942339897
Loss at iteration 2090 : 0.009872086346149445
Loss at iteration 2100 : 0.010775069706141949
Loss at iteration 2110 : 0.00526094064116478
Loss at iteration 2120 : 0.0062334006652235985
Loss at iteration 2130 : 0.0052803438156843185
Loss at iteration 2140 : 0.005330185405910015
Loss at iteration 2150 : 0.0057161543518304825
Loss at iteration 2160 : 0.004682606086134911
Loss at iteration 2170 : 0.002492717234417796
Loss at iteration 2180 : 0.009051741100847721
Loss at iteration 2190 : 0.006759524345397949
Loss at iteration 2200 : 0.010161664336919785
Loss at iteration 2210 : 0.0065049538388848305
Loss at iteration 2220 : 0.004713069647550583
Loss at iteration 2230 : 0.0027548985090106726
Loss at iteration 2240 : 0.004191003739833832
Loss at iteration 2250 : 0.005531220696866512
Loss at iteration 2260 : 0.010116210207343102
Loss at iteration 2270 : 0.0017460688250139356
Loss at iteration 2280 : 0.007681500166654587
Loss at iteration 2290 : 0.012597520835697651
Loss at iteration 2300 : 0.006103423424065113
Loss at iteration 2310 : 0.005582652520388365
Loss at iteration 2320 : 0.009033521637320518
Loss at iteration 2330 : 0.005516895093023777
Loss at iteration 2340 : 0.011794233694672585
Loss at iteration 2350 : 0.015006222762167454
Loss at iteration 2360 : 0.008082021027803421
Loss at iteration 2370 : 0.01004843134433031
Loss at iteration 2380 : 0.0074079763144254684
Loss at iteration 2390 : 0.007817070931196213
Loss at iteration 2400 : 0.006505969911813736
Loss at iteration 2410 : 0.011182477697730064
Loss at iteration 2420 : 0.0128598902374506
The SSIM Value is: 0.8359623233477275
The PSNR Value is: 21.099708302815756
the epoch is: 98
Loss at iteration 10 : 0.005498676095157862
Loss at iteration 20 : 0.007768785580992699
Loss at iteration 30 : 0.01166905090212822
Loss at iteration 40 : 0.011083897203207016
Loss at iteration 50 : 0.009089026600122452
Loss at iteration 60 : 0.0039429268799722195
Loss at iteration 70 : 0.005834175273776054
Loss at iteration 80 : 0.013153882697224617
Loss at iteration 90 : 0.010024305433034897
Loss at iteration 100 : 0.009921498596668243
Loss at iteration 110 : 0.011430265381932259
Loss at iteration 120 : 0.005362803116440773
Loss at iteration 130 : 0.007457184139639139
Loss at iteration 140 : 0.007394140586256981
Loss at iteration 150 : 0.01612001657485962
Loss at iteration 160 : 0.007519273553043604
Loss at iteration 170 : 0.024577999487519264
Loss at iteration 180 : 0.004237142391502857
Loss at iteration 190 : 0.006739073898643255
Loss at iteration 200 : 0.008360886946320534
Loss at iteration 210 : 0.005459873005747795
Loss at iteration 220 : 0.004354282282292843
Loss at iteration 230 : 0.004493378102779388
Loss at iteration 240 : 0.008510587736964226
Loss at iteration 250 : 0.01291690208017826
Loss at iteration 260 : 0.003454474499449134
Loss at iteration 270 : 0.005306227132678032
Loss at iteration 280 : 0.008130618371069431
Loss at iteration 290 : 0.006364435888826847
Loss at iteration 300 : 0.006259124726057053
Loss at iteration 310 : 0.011537848971784115
Loss at iteration 320 : 0.01110228430479765
Loss at iteration 330 : 0.010752868838608265
Loss at iteration 340 : 0.006961112841963768
Loss at iteration 350 : 0.010246223770081997
Loss at iteration 360 : 0.004180181305855513
Loss at iteration 370 : 0.00598526606336236
Loss at iteration 380 : 0.004583163186907768
Loss at iteration 390 : 0.004885654430836439
Loss at iteration 400 : 0.01151118241250515
Loss at iteration 410 : 0.00831823330372572
Loss at iteration 420 : 0.006120257545262575
Loss at iteration 430 : 0.010233001783490181
Loss at iteration 440 : 0.01331445761024952
Loss at iteration 450 : 0.005912069696933031
Loss at iteration 460 : 0.0057710036635398865
Loss at iteration 470 : 0.0047921487130224705
Loss at iteration 480 : 0.007709571160376072
Loss at iteration 490 : 0.004888470750302076
Loss at iteration 500 : 0.0035045964177697897
Loss at iteration 510 : 0.006474286783486605
Loss at iteration 520 : 0.009391720406711102
Loss at iteration 530 : 0.012500742450356483
Loss at iteration 540 : 0.009593975730240345
Loss at iteration 550 : 0.007248342037200928
Loss at iteration 560 : 0.007701674941927195
Loss at iteration 570 : 0.006044493988156319
Loss at iteration 580 : 0.016120269894599915
Loss at iteration 590 : 0.01160538848489523
Loss at iteration 600 : 0.009158683009445667
Loss at iteration 610 : 0.0030003495048731565
Loss at iteration 620 : 0.005356200970709324
Loss at iteration 630 : 0.013971141539514065
Loss at iteration 640 : 0.007543246261775494
Loss at iteration 650 : 0.009389564394950867
Loss at iteration 660 : 0.003851037472486496
Loss at iteration 670 : 0.007091267500072718
Loss at iteration 680 : 0.008035248145461082
Loss at iteration 690 : 0.015486338175833225
Loss at iteration 700 : 0.005343324970453978
Loss at iteration 710 : 0.007864655926823616
Loss at iteration 720 : 0.011076166294515133
Loss at iteration 730 : 0.00861299317330122
Loss at iteration 740 : 0.014112770557403564
Loss at iteration 750 : 0.009300099685788155
Loss at iteration 760 : 0.009118257090449333
Loss at iteration 770 : 0.005387068726122379
Loss at iteration 780 : 0.00351138599216938
Loss at iteration 790 : 0.012315030209720135
Loss at iteration 800 : 0.008462146855890751
Loss at iteration 810 : 0.016225891187787056
Loss at iteration 820 : 0.004634954035282135
Loss at iteration 830 : 0.02100970409810543
Loss at iteration 840 : 0.006684084888547659
Loss at iteration 850 : 0.008327679708600044
Loss at iteration 860 : 0.010676558129489422
Loss at iteration 870 : 0.009714826010167599
Loss at iteration 880 : 0.010191688314080238
Loss at iteration 890 : 0.006334803532809019
Loss at iteration 900 : 0.011201784014701843
Loss at iteration 910 : 0.014176392927765846
Loss at iteration 920 : 0.0026516809593886137
Loss at iteration 930 : 0.01297706738114357
Loss at iteration 940 : 0.006494271568953991
Loss at iteration 950 : 0.01128469780087471
Loss at iteration 960 : 0.008444909937679768
Loss at iteration 970 : 0.008140180259943008
Loss at iteration 980 : 0.009765286929905415
Loss at iteration 990 : 0.0028240764513611794
Loss at iteration 1000 : 0.010334476828575134
Loss at iteration 1010 : 0.009740050882101059
Loss at iteration 1020 : 0.00854344479739666
Loss at iteration 1030 : 0.008610422722995281
Loss at iteration 1040 : 0.009619942866265774
Loss at iteration 1050 : 0.009841382503509521
Loss at iteration 1060 : 0.0028671089094132185
Loss at iteration 1070 : 0.0069765374064445496
Loss at iteration 1080 : 0.007049522828310728
Loss at iteration 1090 : 0.016268528997898102
Loss at iteration 1100 : 0.004684999119490385
Loss at iteration 1110 : 0.005893123336136341
Loss at iteration 1120 : 0.0033635739237070084
Loss at iteration 1130 : 0.009112738072872162
Loss at iteration 1140 : 0.007248567417263985
Loss at iteration 1150 : 0.012500092387199402
Loss at iteration 1160 : 0.004987806547433138
Loss at iteration 1170 : 0.01046384871006012
Loss at iteration 1180 : 0.013002569787204266
Loss at iteration 1190 : 0.0071763233281672
Loss at iteration 1200 : 0.004465142730623484
Loss at iteration 1210 : 0.012074761092662811
Loss at iteration 1220 : 0.0154561223462224
Loss at iteration 1230 : 0.00965945702046156
Loss at iteration 1240 : 0.007897036150097847
Loss at iteration 1250 : 0.012430629692971706
Loss at iteration 1260 : 0.008973195217549801
Loss at iteration 1270 : 0.0060634128749370575
Loss at iteration 1280 : 0.009190761484205723
Loss at iteration 1290 : 0.0030977732967585325
Loss at iteration 1300 : 0.004437353927642107
Loss at iteration 1310 : 0.02177029848098755
Loss at iteration 1320 : 0.009897833690047264
Loss at iteration 1330 : 0.006151611916720867
Loss at iteration 1340 : 0.010805139318108559
Loss at iteration 1350 : 0.006598437204957008
Loss at iteration 1360 : 0.006050500087440014
Loss at iteration 1370 : 0.015881599858403206
Loss at iteration 1380 : 0.014255080372095108
Loss at iteration 1390 : 0.00769861601293087
Loss at iteration 1400 : 0.010141607373952866
Loss at iteration 1410 : 0.0030101067386567593
Loss at iteration 1420 : 0.003954483196139336
Loss at iteration 1430 : 0.012764612212777138
Loss at iteration 1440 : 0.007281565573066473
Loss at iteration 1450 : 0.009363663382828236
Loss at iteration 1460 : 0.00739190774038434
Loss at iteration 1470 : 0.010224000550806522
Loss at iteration 1480 : 0.015454054810106754
Loss at iteration 1490 : 0.009648798033595085
Loss at iteration 1500 : 0.005336686037480831
Loss at iteration 1510 : 0.0046624974347651005
Loss at iteration 1520 : 0.008644264191389084
Loss at iteration 1530 : 0.0036323918029665947
Loss at iteration 1540 : 0.008414970710873604
Loss at iteration 1550 : 0.010354013182222843
Loss at iteration 1560 : 0.009119168855249882
Loss at iteration 1570 : 0.009272218681871891
Loss at iteration 1580 : 0.027368707582354546
Loss at iteration 1590 : 0.004942004103213549
Loss at iteration 1600 : 0.011327211745083332
Loss at iteration 1610 : 0.007233935408294201
Loss at iteration 1620 : 0.008144480176270008
Loss at iteration 1630 : 0.007886908948421478
Loss at iteration 1640 : 0.004797304980456829
Loss at iteration 1650 : 0.007844212464988232
Loss at iteration 1660 : 0.006599295884370804
Loss at iteration 1670 : 0.005401965696364641
Loss at iteration 1680 : 0.006291394121944904
Loss at iteration 1690 : 0.008869017474353313
Loss at iteration 1700 : 0.011733129620552063
Loss at iteration 1710 : 0.00699786888435483
Loss at iteration 1720 : 0.011828480288386345
Loss at iteration 1730 : 0.004395004361867905
Loss at iteration 1740 : 0.007148910313844681
Loss at iteration 1750 : 0.008019858971238136
Loss at iteration 1760 : 0.0052950093522667885
Loss at iteration 1770 : 0.004371670074760914
Loss at iteration 1780 : 0.00697071198374033
Loss at iteration 1790 : 0.0027763070538640022
Loss at iteration 1800 : 0.014685413800179958
Loss at iteration 1810 : 0.0074161989614367485
Loss at iteration 1820 : 0.007439887151122093
Loss at iteration 1830 : 0.011509931646287441
Loss at iteration 1840 : 0.012195631861686707
Loss at iteration 1850 : 0.010550107806921005
Loss at iteration 1860 : 0.00302712875418365
Loss at iteration 1870 : 0.01728040538728237
Loss at iteration 1880 : 0.002199374372139573
Loss at iteration 1890 : 0.00808096956461668
Loss at iteration 1900 : 0.0058194780722260475
Loss at iteration 1910 : 0.010379775427281857
Loss at iteration 1920 : 0.004514267668128014
Loss at iteration 1930 : 0.0180966854095459
Loss at iteration 1940 : 0.011198954656720161
Loss at iteration 1950 : 0.006519385613501072
Loss at iteration 1960 : 0.013427751138806343
Loss at iteration 1970 : 0.006967526860535145
Loss at iteration 1980 : 0.008230871520936489
Loss at iteration 1990 : 0.00862342119216919
Loss at iteration 2000 : 0.01945742405951023
Loss at iteration 2010 : 0.011375249363481998
Loss at iteration 2020 : 0.01117714773863554
Loss at iteration 2030 : 0.008996795862913132
Loss at iteration 2040 : 0.009412373416125774
Loss at iteration 2050 : 0.0157733466476202
Loss at iteration 2060 : 0.010019253939390182
Loss at iteration 2070 : 0.022242456674575806
Loss at iteration 2080 : 0.004461606498807669
Loss at iteration 2090 : 0.0101547259837389
Loss at iteration 2100 : 0.005707019008696079
Loss at iteration 2110 : 0.0065475390292704105
Loss at iteration 2120 : 0.027104292064905167
Loss at iteration 2130 : 0.014008007943630219
Loss at iteration 2140 : 0.016413088887929916
Loss at iteration 2150 : 0.0070211817510426044
Loss at iteration 2160 : 0.0058797081001102924
Loss at iteration 2170 : 0.008956369943916798
Loss at iteration 2180 : 0.016896821558475494
Loss at iteration 2190 : 0.012718490324914455
Loss at iteration 2200 : 0.006663109641522169
Loss at iteration 2210 : 0.0074137672781944275
Loss at iteration 2220 : 0.004399159923195839
Loss at iteration 2230 : 0.009238154627382755
Loss at iteration 2240 : 0.008841391652822495
Loss at iteration 2250 : 0.008967163972556591
Loss at iteration 2260 : 0.006173756439238787
Loss at iteration 2270 : 0.013067067600786686
Loss at iteration 2280 : 0.01348656602203846
Loss at iteration 2290 : 0.015948783606290817
Loss at iteration 2300 : 0.007986596785485744
Loss at iteration 2310 : 0.007575966417789459
Loss at iteration 2320 : 0.015522459521889687
Loss at iteration 2330 : 0.016091544181108475
Loss at iteration 2340 : 0.005180391948670149
Loss at iteration 2350 : 0.013303242623806
Loss at iteration 2360 : 0.008462985046207905
Loss at iteration 2370 : 0.005288134794682264
Loss at iteration 2380 : 0.004826766904443502
Loss at iteration 2390 : 0.009104866534471512
Loss at iteration 2400 : 0.01440716814249754
Loss at iteration 2410 : 0.018122242763638496
Loss at iteration 2420 : 0.01058401819318533
The SSIM Value is: 0.8431054751078287
The PSNR Value is: 21.692989921569826
the epoch is: 99
Loss at iteration 10 : 0.01588263362646103
Loss at iteration 20 : 0.01295612845569849
Loss at iteration 30 : 0.002640285063534975
Loss at iteration 40 : 0.010707197710871696
Loss at iteration 50 : 0.003932899795472622
Loss at iteration 60 : 0.010271443985402584
Loss at iteration 70 : 0.010650700889527798
Loss at iteration 80 : 0.0057921214029192924
Loss at iteration 90 : 0.007085979450494051
Loss at iteration 100 : 0.009844151325523853
Loss at iteration 110 : 0.00837101973593235
Loss at iteration 120 : 0.005709371995180845
Loss at iteration 130 : 0.018697464838624
Loss at iteration 140 : 0.010660488158464432
Loss at iteration 150 : 0.008815810084342957
Loss at iteration 160 : 0.009579046629369259
Loss at iteration 170 : 0.013957024551928043
Loss at iteration 180 : 0.008852679282426834
Loss at iteration 190 : 0.010461832396686077
Loss at iteration 200 : 0.011181765235960484
Loss at iteration 210 : 0.009323219768702984
Loss at iteration 220 : 0.013083476573228836
Loss at iteration 230 : 0.01018109917640686
Loss at iteration 240 : 0.00557179469615221
Loss at iteration 250 : 0.008003264665603638
Loss at iteration 260 : 0.012447770684957504
Loss at iteration 270 : 0.009222122840583324
Loss at iteration 280 : 0.006307981908321381
Loss at iteration 290 : 0.005322824232280254
Loss at iteration 300 : 0.010657981969416142
Loss at iteration 310 : 0.007850408554077148
Loss at iteration 320 : 0.005990905221551657
Loss at iteration 330 : 0.012000005692243576
Loss at iteration 340 : 0.008652478456497192
Loss at iteration 350 : 0.00817053858190775
Loss at iteration 360 : 0.010574698448181152
Loss at iteration 370 : 0.007163329981267452
Loss at iteration 380 : 0.003455657046288252
Loss at iteration 390 : 0.016621911898255348
Loss at iteration 400 : 0.005946877878159285
Loss at iteration 410 : 0.010658479295670986
Loss at iteration 420 : 0.006704786792397499
Loss at iteration 430 : 0.01718839257955551
Loss at iteration 440 : 0.022588759660720825
Loss at iteration 450 : 0.011114126071333885
Loss at iteration 460 : 0.007704084739089012
Loss at iteration 470 : 0.0039640069007873535
Loss at iteration 480 : 0.008340210653841496
Loss at iteration 490 : 0.009317731484770775
Loss at iteration 500 : 0.003789398819208145
Loss at iteration 510 : 0.004468759521842003
Loss at iteration 520 : 0.011619007214903831
Loss at iteration 530 : 0.005813029129058123
Loss at iteration 540 : 0.023660708218812943
Loss at iteration 550 : 0.00943022407591343
Loss at iteration 560 : 0.005730286240577698
Loss at iteration 570 : 0.007800030056387186
Loss at iteration 580 : 0.03799714893102646
Loss at iteration 590 : 0.011642392724752426
Loss at iteration 600 : 0.0086032310500741
Loss at iteration 610 : 0.004438645206391811
Loss at iteration 620 : 0.012221246026456356
Loss at iteration 630 : 0.0034556412138044834
Loss at iteration 640 : 0.009541310369968414
Loss at iteration 650 : 0.0048017483204603195
Loss at iteration 660 : 0.0076222606003284454
Loss at iteration 670 : 0.007824103347957134
Loss at iteration 680 : 0.008093731477856636
Loss at iteration 690 : 0.00686596380546689
Loss at iteration 700 : 0.007365693803876638
Loss at iteration 710 : 0.005205168388783932
Loss at iteration 720 : 0.005610827822238207
Loss at iteration 730 : 0.00709442887455225
Loss at iteration 740 : 0.012617439031600952
Loss at iteration 750 : 0.007420032750815153
Loss at iteration 760 : 0.0076410965994000435
Loss at iteration 770 : 0.011664438992738724
Loss at iteration 780 : 0.011619909666478634
Loss at iteration 790 : 0.01832527108490467
Loss at iteration 800 : 0.007817326113581657
Loss at iteration 810 : 0.012928411364555359
Loss at iteration 820 : 0.006448127329349518
Loss at iteration 830 : 0.007811332121491432
Loss at iteration 840 : 0.005374743137508631
Loss at iteration 850 : 0.011657443828880787
Loss at iteration 860 : 0.00787873100489378
Loss at iteration 870 : 0.008145419880747795
Loss at iteration 880 : 0.012462804093956947
Loss at iteration 890 : 0.013922978192567825
Loss at iteration 900 : 0.007916102185845375
Loss at iteration 910 : 0.01126340962946415
Loss at iteration 920 : 0.005566248204559088
Loss at iteration 930 : 0.01054245326668024
Loss at iteration 940 : 0.011481539346277714
Loss at iteration 950 : 0.007959321141242981
Loss at iteration 960 : 0.007744959555566311
Loss at iteration 970 : 0.003297364106401801
Loss at iteration 980 : 0.008152971044182777
Loss at iteration 990 : 0.013808374293148518
Loss at iteration 1000 : 0.01319222990423441
Loss at iteration 1010 : 0.007374877575784922
Loss at iteration 1020 : 0.004193832166492939
Loss at iteration 1030 : 0.006781720090657473
Loss at iteration 1040 : 0.004824008792638779
Loss at iteration 1050 : 0.009426819160580635
Loss at iteration 1060 : 0.010987362824380398
Loss at iteration 1070 : 0.010897497646510601
Loss at iteration 1080 : 0.005744623020291328
Loss at iteration 1090 : 0.006517748348414898
Loss at iteration 1100 : 0.010556858964264393
Loss at iteration 1110 : 0.012270359322428703
Loss at iteration 1120 : 0.02023526281118393
Loss at iteration 1130 : 0.008909123949706554
Loss at iteration 1140 : 0.019802920520305634
Loss at iteration 1150 : 0.003338197013363242
Loss at iteration 1160 : 0.010770226828753948
Loss at iteration 1170 : 0.006493309047073126
Loss at iteration 1180 : 0.008388594724237919
Loss at iteration 1190 : 0.010091273114085197
Loss at iteration 1200 : 0.015324785374104977
Loss at iteration 1210 : 0.004982306621968746
Loss at iteration 1220 : 0.00475362129509449
Loss at iteration 1230 : 0.01586771570146084
Loss at iteration 1240 : 0.01534823514521122
Loss at iteration 1250 : 0.00930408388376236
Loss at iteration 1260 : 0.00717422878369689
Loss at iteration 1270 : 0.008748630061745644
Loss at iteration 1280 : 0.0058455574326217175
Loss at iteration 1290 : 0.006147553212940693
Loss at iteration 1300 : 0.006750599015504122
Loss at iteration 1310 : 0.019033916294574738
Loss at iteration 1320 : 0.008841827511787415
Loss at iteration 1330 : 0.006043445784598589
Loss at iteration 1340 : 0.008556737564504147
Loss at iteration 1350 : 0.008957535028457642
Loss at iteration 1360 : 0.0168759748339653
Loss at iteration 1370 : 0.0042209201492369175
Loss at iteration 1380 : 0.005196783691644669
Loss at iteration 1390 : 0.008938058279454708
Loss at iteration 1400 : 0.010712708346545696
Loss at iteration 1410 : 0.007608848623931408
Loss at iteration 1420 : 0.009548225440084934
Loss at iteration 1430 : 0.018802056089043617
Loss at iteration 1440 : 0.009432322345674038
Loss at iteration 1450 : 0.01011979766190052
Loss at iteration 1460 : 0.008401881903409958
Loss at iteration 1470 : 0.010651049204170704
Loss at iteration 1480 : 0.013205435127019882
Loss at iteration 1490 : 0.017612678930163383
Loss at iteration 1500 : 0.017376305535435677
Loss at iteration 1510 : 0.008297438733279705
Loss at iteration 1520 : 0.015859264880418777
Loss at iteration 1530 : 0.007982282899320126
Loss at iteration 1540 : 0.012497550807893276
Loss at iteration 1550 : 0.012573981657624245
Loss at iteration 1560 : 0.013899093493819237
Loss at iteration 1570 : 0.005186283029615879
Loss at iteration 1580 : 0.009597284719347954
Loss at iteration 1590 : 0.014823604375123978
Loss at iteration 1600 : 0.012145603075623512
Loss at iteration 1610 : 0.015559242106974125
Loss at iteration 1620 : 0.006325939204543829
Loss at iteration 1630 : 0.005739410407841206
Loss at iteration 1640 : 0.010660694912075996
Loss at iteration 1650 : 0.01115498412400484
Loss at iteration 1660 : 0.006486866157501936
Loss at iteration 1670 : 0.007394822780042887
Loss at iteration 1680 : 0.00566089665517211
Loss at iteration 1690 : 0.004750795196741819
Loss at iteration 1700 : 0.009597275406122208
Loss at iteration 1710 : 0.006302511319518089
Loss at iteration 1720 : 0.012957105413079262
Loss at iteration 1730 : 0.0036338972859084606
Loss at iteration 1740 : 0.004110012203454971
Loss at iteration 1750 : 0.014607995748519897
Loss at iteration 1760 : 0.009895575232803822
Loss at iteration 1770 : 0.010768545791506767
Loss at iteration 1780 : 0.009010935202240944
Loss at iteration 1790 : 0.008390463888645172
Loss at iteration 1800 : 0.010414637625217438
Loss at iteration 1810 : 0.002590607386082411
Loss at iteration 1820 : 0.01136104017496109
Loss at iteration 1830 : 0.0124889574944973
Loss at iteration 1840 : 0.009972323663532734
Loss at iteration 1850 : 0.00614025816321373
Loss at iteration 1860 : 0.007299485150724649
Loss at iteration 1870 : 0.013866581954061985
Loss at iteration 1880 : 0.023998428136110306
Loss at iteration 1890 : 0.007640970405191183
Loss at iteration 1900 : 0.008461114019155502
Loss at iteration 1910 : 0.0074263946153223515
Loss at iteration 1920 : 0.004620174877345562
Loss at iteration 1930 : 0.011784507893025875
Loss at iteration 1940 : 0.01279862504452467
Loss at iteration 1950 : 0.01054205559194088
Loss at iteration 1960 : 0.010621558874845505
Loss at iteration 1970 : 0.009844240732491016
Loss at iteration 1980 : 0.004382715094834566
Loss at iteration 1990 : 0.005573316477239132
Loss at iteration 2000 : 0.007656794041395187
Loss at iteration 2010 : 0.009699374437332153
Loss at iteration 2020 : 0.01730121299624443
Loss at iteration 2030 : 0.0063619655556976795
Loss at iteration 2040 : 0.006656754296272993
Loss at iteration 2050 : 0.011525966227054596
Loss at iteration 2060 : 0.004840490873903036
Loss at iteration 2070 : 0.008438726887106895
Loss at iteration 2080 : 0.00482210423797369
Loss at iteration 2090 : 0.008153872564435005
Loss at iteration 2100 : 0.004518310539424419
Loss at iteration 2110 : 0.012349065393209457
Loss at iteration 2120 : 0.010990116745233536
Loss at iteration 2130 : 0.004571171477437019
Loss at iteration 2140 : 0.007613694295287132
Loss at iteration 2150 : 0.008767932653427124
Loss at iteration 2160 : 0.0030373285990208387
Loss at iteration 2170 : 0.006348390132188797
Loss at iteration 2180 : 0.004243948962539434
Loss at iteration 2190 : 0.007916638627648354
Loss at iteration 2200 : 0.0016350257210433483
Loss at iteration 2210 : 0.023357044905424118
Loss at iteration 2220 : 0.005284240003675222
Loss at iteration 2230 : 0.004468502476811409
Loss at iteration 2240 : 0.0052986107766628265
Loss at iteration 2250 : 0.01665005460381508
Loss at iteration 2260 : 0.011487050913274288
Loss at iteration 2270 : 0.004027570132166147
Loss at iteration 2280 : 0.009685052558779716
Loss at iteration 2290 : 0.010341867804527283
Loss at iteration 2300 : 0.002385559258982539
Loss at iteration 2310 : 0.009898989461362362
Loss at iteration 2320 : 0.0031630389858037233
Loss at iteration 2330 : 0.013330433517694473
Loss at iteration 2340 : 0.006965130567550659
Loss at iteration 2350 : 0.00768297677859664
Loss at iteration 2360 : 0.009739230386912823
Loss at iteration 2370 : 0.005982541013509035
Loss at iteration 2380 : 0.0038302652537822723
Loss at iteration 2390 : 0.014483170583844185
Loss at iteration 2400 : 0.003936396446079016
Loss at iteration 2410 : 0.006144121754914522
Loss at iteration 2420 : 0.009956363588571548
The SSIM Value is: 0.8350569407145182
The PSNR Value is: 20.76362158457438
the epoch is: 100
Loss at iteration 10 : 0.006412387825548649
Loss at iteration 20 : 0.008448553271591663
Loss at iteration 30 : 0.007060355972498655
Loss at iteration 40 : 0.008199883624911308
Loss at iteration 50 : 0.013661269098520279
Loss at iteration 60 : 0.008658677339553833
Loss at iteration 70 : 0.008851118385791779
Loss at iteration 80 : 0.010563939809799194
Loss at iteration 90 : 0.016703728586435318
Loss at iteration 100 : 0.00494376989081502
Loss at iteration 110 : 0.005816203076392412
Loss at iteration 120 : 0.009436298161745071
Loss at iteration 130 : 0.010140031576156616
Loss at iteration 140 : 0.011054281145334244
Loss at iteration 150 : 0.009609351865947247
Loss at iteration 160 : 0.008578965440392494
Loss at iteration 170 : 0.009844115935266018
Loss at iteration 180 : 0.00489469151943922
Loss at iteration 190 : 0.015112636610865593
Loss at iteration 200 : 0.017101891338825226
Loss at iteration 210 : 0.020467624068260193
Loss at iteration 220 : 0.012096320278942585
Loss at iteration 230 : 0.008662139065563679
Loss at iteration 240 : 0.010785188525915146
Loss at iteration 250 : 0.007604092825204134
Loss at iteration 260 : 0.013525278307497501
Loss at iteration 270 : 0.010907378979027271
Loss at iteration 280 : 0.01682053506374359
Loss at iteration 290 : 0.011808261275291443
Loss at iteration 300 : 0.005906940437853336
Loss at iteration 310 : 0.0253773033618927
Loss at iteration 320 : 0.01695897802710533
Loss at iteration 330 : 0.0199102982878685
Loss at iteration 340 : 0.010823970660567284
Loss at iteration 350 : 0.0064362213015556335
Loss at iteration 360 : 0.0053332773968577385
Loss at iteration 370 : 0.003869237145408988
Loss at iteration 380 : 0.014581277035176754
Loss at iteration 390 : 0.007069344166666269
Loss at iteration 400 : 0.008425559848546982
Loss at iteration 410 : 0.009699963964521885
Loss at iteration 420 : 0.007767251692712307
Loss at iteration 430 : 0.006835250649601221
Loss at iteration 440 : 0.0043793171644210815
Loss at iteration 450 : 0.00297688040882349
Loss at iteration 460 : 0.007519586011767387
Loss at iteration 470 : 0.0046267276629805565
Loss at iteration 480 : 0.009597846306860447
Loss at iteration 490 : 0.005030971020460129
Loss at iteration 500 : 0.005534598603844643
Loss at iteration 510 : 0.008066571317613125
Loss at iteration 520 : 0.008825763128697872
Loss at iteration 530 : 0.01159595511853695
Loss at iteration 540 : 0.0289668720215559
Loss at iteration 550 : 0.01709618791937828
Loss at iteration 560 : 0.00931932870298624
Loss at iteration 570 : 0.007750028744339943
Loss at iteration 580 : 0.009668814949691296
Loss at iteration 590 : 0.004622553009539843
Loss at iteration 600 : 0.007895363494753838
Loss at iteration 610 : 0.010727513581514359
Loss at iteration 620 : 0.0071245464496314526
Loss at iteration 630 : 0.008717673830688
Loss at iteration 640 : 0.008978057652711868
Loss at iteration 650 : 0.0130320955067873
Loss at iteration 660 : 0.011566868051886559
Loss at iteration 670 : 0.011006586253643036
Loss at iteration 680 : 0.007571537047624588
Loss at iteration 690 : 0.0042731426656246185
Loss at iteration 700 : 0.006266971584409475
Loss at iteration 710 : 0.020917804911732674
Loss at iteration 720 : 0.008974632248282433
Loss at iteration 730 : 0.010939579457044601
Loss at iteration 740 : 0.01534176990389824
Loss at iteration 750 : 0.0057847388088703156
Loss at iteration 760 : 0.009574461728334427
Loss at iteration 770 : 0.005340815521776676
Loss at iteration 780 : 0.0062385378405451775
Loss at iteration 790 : 0.002781403949484229
Loss at iteration 800 : 0.009151116944849491
Loss at iteration 810 : 0.015347190201282501
Loss at iteration 820 : 0.0035372371785342693
Loss at iteration 830 : 0.006781711243093014
Loss at iteration 840 : 0.00986032746732235
Loss at iteration 850 : 0.008336624130606651
Loss at iteration 860 : 0.004857549909502268
Loss at iteration 870 : 0.014620172791182995
Loss at iteration 880 : 0.011248967610299587
Loss at iteration 890 : 0.011594605632126331
Loss at iteration 900 : 0.010981096886098385
Loss at iteration 910 : 0.009509455412626266
Loss at iteration 920 : 0.010488071478903294
Loss at iteration 930 : 0.006752585060894489
Loss at iteration 940 : 0.010664965026080608
Loss at iteration 950 : 0.005457285325974226
Loss at iteration 960 : 0.012556089088320732
Loss at iteration 970 : 0.007409749086946249
Loss at iteration 980 : 0.012197853066027164
Loss at iteration 990 : 0.005235880613327026
Loss at iteration 1000 : 0.012625842355191708
Loss at iteration 1010 : 0.004010542295873165
Loss at iteration 1020 : 0.004230001475661993
Loss at iteration 1030 : 0.005512072239071131
Loss at iteration 1040 : 0.0032117858063429594
Loss at iteration 1050 : 0.00841597467660904
Loss at iteration 1060 : 0.006039957981556654
Loss at iteration 1070 : 0.005565970204770565
Loss at iteration 1080 : 0.006795178633183241
Loss at iteration 1090 : 0.01056068018078804
Loss at iteration 1100 : 0.009097347036004066
Loss at iteration 1110 : 0.006836207117885351
Loss at iteration 1120 : 0.010385876521468163
Loss at iteration 1130 : 0.012759452685713768
Loss at iteration 1140 : 0.023828577250242233
Loss at iteration 1150 : 0.025091996416449547
Loss at iteration 1160 : 0.011607359163463116
Loss at iteration 1170 : 0.007261953316628933
Loss at iteration 1180 : 0.016120653599500656
Loss at iteration 1190 : 0.014031855389475822
Loss at iteration 1200 : 0.015789711847901344
Loss at iteration 1210 : 0.013222752138972282
Loss at iteration 1220 : 0.008173243142664433
Loss at iteration 1230 : 0.012036707252264023
Loss at iteration 1240 : 0.005974924191832542
Loss at iteration 1250 : 0.014935694634914398
Loss at iteration 1260 : 0.014541739597916603
Loss at iteration 1270 : 0.008217529393732548
Loss at iteration 1280 : 0.003418681677430868
Loss at iteration 1290 : 0.010630470700562
Loss at iteration 1300 : 0.007224945817142725
Loss at iteration 1310 : 0.013457338325679302
Loss at iteration 1320 : 0.0024033840745687485
Loss at iteration 1330 : 0.006907481234520674
Loss at iteration 1340 : 0.004110497888177633
Loss at iteration 1350 : 0.007264301180839539
Loss at iteration 1360 : 0.010155871510505676
Loss at iteration 1370 : 0.006340424530208111
Loss at iteration 1380 : 0.006594134494662285
Loss at iteration 1390 : 0.0064170784316957
Loss at iteration 1400 : 0.007401110604405403
Loss at iteration 1410 : 0.006816580425947905
Loss at iteration 1420 : 0.008719924837350845
Loss at iteration 1430 : 0.005782222840934992
Loss at iteration 1440 : 0.01653202436864376
Loss at iteration 1450 : 0.006037029903382063
Loss at iteration 1460 : 0.005695442669093609
Loss at iteration 1470 : 0.006504397839307785
Loss at iteration 1480 : 0.010528098791837692
Loss at iteration 1490 : 0.004233939573168755
Loss at iteration 1500 : 0.010102902539074421
Loss at iteration 1510 : 0.004108784254640341
Loss at iteration 1520 : 0.013931043446063995
Loss at iteration 1530 : 0.008537009358406067
Loss at iteration 1540 : 0.006829011254012585
Loss at iteration 1550 : 0.0033702547661960125
Loss at iteration 1560 : 0.009826621040701866
Loss at iteration 1570 : 0.007775281555950642
Loss at iteration 1580 : 0.009554222226142883
Loss at iteration 1590 : 0.012560036964714527
Loss at iteration 1600 : 0.004410349298268557
Loss at iteration 1610 : 0.005723044741898775
Loss at iteration 1620 : 0.00866057351231575
Loss at iteration 1630 : 0.005278462544083595
Loss at iteration 1640 : 0.01279200054705143
Loss at iteration 1650 : 0.004698298405855894
Loss at iteration 1660 : 0.013537918217480183
Loss at iteration 1670 : 0.011426271870732307
Loss at iteration 1680 : 0.00917708221822977
Loss at iteration 1690 : 0.006506121251732111
Loss at iteration 1700 : 0.008367725647985935
Loss at iteration 1710 : 0.008755422197282314
Loss at iteration 1720 : 0.006077904719859362
Loss at iteration 1730 : 0.004551957361400127
Loss at iteration 1740 : 0.009730574674904346
Loss at iteration 1750 : 0.015144426375627518
Loss at iteration 1760 : 0.007228733506053686
Loss at iteration 1770 : 0.009769790805876255
Loss at iteration 1780 : 0.005093382205814123
Loss at iteration 1790 : 0.012166017666459084
Loss at iteration 1800 : 0.008633877150714397
Loss at iteration 1810 : 0.006001512054353952
Loss at iteration 1820 : 0.009617876261472702
Loss at iteration 1830 : 0.005155145190656185
Loss at iteration 1840 : 0.004891416523605585
Loss at iteration 1850 : 0.005814790725708008
Loss at iteration 1860 : 0.011931682005524635
Loss at iteration 1870 : 0.007850214838981628
Loss at iteration 1880 : 0.00900859385728836
Loss at iteration 1890 : 0.009666528552770615
Loss at iteration 1900 : 0.01591777428984642
Loss at iteration 1910 : 0.01303971465677023
Loss at iteration 1920 : 0.013201085850596428
Loss at iteration 1930 : 0.007097521331161261
Loss at iteration 1940 : 0.008351926691830158
Loss at iteration 1950 : 0.005407609045505524
Loss at iteration 1960 : 0.004118736833333969
Loss at iteration 1970 : 0.010918313637375832
Loss at iteration 1980 : 0.010838767513632774
Loss at iteration 1990 : 0.024528205394744873
Loss at iteration 2000 : 0.01378499623388052
Loss at iteration 2010 : 0.00799047201871872
Loss at iteration 2020 : 0.004678813740611076
Loss at iteration 2030 : 0.004638051148504019
Loss at iteration 2040 : 0.00848587229847908
Loss at iteration 2050 : 0.006865041330456734
Loss at iteration 2060 : 0.011821376159787178
Loss at iteration 2070 : 0.008291849866509438
Loss at iteration 2080 : 0.004452618770301342
Loss at iteration 2090 : 0.011703272350132465
Loss at iteration 2100 : 0.005772709380835295
Loss at iteration 2110 : 0.006556473672389984
Loss at iteration 2120 : 0.004848076030611992
Loss at iteration 2130 : 0.008605245500802994
Loss at iteration 2140 : 0.008123266510665417
Loss at iteration 2150 : 0.00802033394575119
Loss at iteration 2160 : 0.027673901990056038
Loss at iteration 2170 : 0.007027808111160994
Loss at iteration 2180 : 0.013384699821472168
Loss at iteration 2190 : 0.004805147182196379
Loss at iteration 2200 : 0.0073566315695643425
Loss at iteration 2210 : 0.014701665379106998
Loss at iteration 2220 : 0.011892720125615597
Loss at iteration 2230 : 0.008683502674102783
Loss at iteration 2240 : 0.004868372343480587
Loss at iteration 2250 : 0.01129989419132471
Loss at iteration 2260 : 0.01211351528763771
Loss at iteration 2270 : 0.005698997061699629
Loss at iteration 2280 : 0.010106834582984447
Loss at iteration 2290 : 0.007231684401631355
Loss at iteration 2300 : 0.006915338337421417
Loss at iteration 2310 : 0.003956273198127747
Loss at iteration 2320 : 0.007724075112491846
Loss at iteration 2330 : 0.007624650374054909
Loss at iteration 2340 : 0.012642462737858295
Loss at iteration 2350 : 0.012916983105242252
Loss at iteration 2360 : 0.008812743239104748
Loss at iteration 2370 : 0.011446699500083923
Loss at iteration 2380 : 0.01904032565653324
Loss at iteration 2390 : 0.02282755821943283
Loss at iteration 2400 : 0.004890832118690014
Loss at iteration 2410 : 0.015613194555044174
Loss at iteration 2420 : 0.005685325246304274
The SSIM Value is: 0.8396332263946533
The PSNR Value is: 22.064995702107748
the epoch is: 101
Loss at iteration 10 : 0.016801010817289352
Loss at iteration 20 : 0.010374193079769611
Loss at iteration 30 : 0.00819389708340168
Loss at iteration 40 : 0.009247132577002048
Loss at iteration 50 : 0.006265922449529171
Loss at iteration 60 : 0.010217013768851757
Loss at iteration 70 : 0.003605410922318697
Loss at iteration 80 : 0.0023612426593899727
Loss at iteration 90 : 0.013171296566724777
Loss at iteration 100 : 0.014101497828960419
Loss at iteration 110 : 0.013787399977445602
Loss at iteration 120 : 0.008341574110090733
Loss at iteration 130 : 0.005388118792325258
Loss at iteration 140 : 0.007424067705869675
Loss at iteration 150 : 0.010960040614008904
Loss at iteration 160 : 0.008024659007787704
Loss at iteration 170 : 0.007382269948720932
Loss at iteration 180 : 0.006503855809569359
Loss at iteration 190 : 0.0070019131526350975
Loss at iteration 200 : 0.007452935446053743
Loss at iteration 210 : 0.012114645913243294
Loss at iteration 220 : 0.008683004416525364
Loss at iteration 230 : 0.01352906133979559
Loss at iteration 240 : 0.011020423844456673
Loss at iteration 250 : 0.004523506388068199
Loss at iteration 260 : 0.012005358003079891
Loss at iteration 270 : 0.005245814565569162
Loss at iteration 280 : 0.008495613932609558
Loss at iteration 290 : 0.008722450584173203
Loss at iteration 300 : 0.018242692574858665
Loss at iteration 310 : 0.00603132788091898
Loss at iteration 320 : 0.006863312795758247
Loss at iteration 330 : 0.01139624509960413
Loss at iteration 340 : 0.00606381194666028
Loss at iteration 350 : 0.008733135648071766
Loss at iteration 360 : 0.014338752254843712
Loss at iteration 370 : 0.012564745731651783
Loss at iteration 380 : 0.013355804607272148
Loss at iteration 390 : 0.007248871959745884
Loss at iteration 400 : 0.004063084721565247
Loss at iteration 410 : 0.011296949349343777
Loss at iteration 420 : 0.017923330888152122
Loss at iteration 430 : 0.005714450962841511
Loss at iteration 440 : 0.012525530532002449
Loss at iteration 450 : 0.036877721548080444
Loss at iteration 460 : 0.013678550720214844
Loss at iteration 470 : 0.011813901364803314
Loss at iteration 480 : 0.005445828661322594
Loss at iteration 490 : 0.004331799224019051
Loss at iteration 500 : 0.010968887247145176
Loss at iteration 510 : 0.008662904612720013
Loss at iteration 520 : 0.009138003922998905
Loss at iteration 530 : 0.018415125086903572
Loss at iteration 540 : 0.017789574339985847
Loss at iteration 550 : 0.005449647083878517
Loss at iteration 560 : 0.007138109765946865
Loss at iteration 570 : 0.005466328002512455
Loss at iteration 580 : 0.007822311483323574
Loss at iteration 590 : 0.00589022459462285
Loss at iteration 600 : 0.005045711062848568
Loss at iteration 610 : 0.007199907209724188
Loss at iteration 620 : 0.008747636340558529
Loss at iteration 630 : 0.010367113165557384
Loss at iteration 640 : 0.007056615315377712
Loss at iteration 650 : 0.016206949949264526
Loss at iteration 660 : 0.002622151980176568
Loss at iteration 670 : 0.01893763616681099
Loss at iteration 680 : 0.006190894637256861
Loss at iteration 690 : 0.0036857514642179012
Loss at iteration 700 : 0.0043563530780375
Loss at iteration 710 : 0.005957420915365219
Loss at iteration 720 : 0.00920463353395462
Loss at iteration 730 : 0.012821738608181477
Loss at iteration 740 : 0.002476078923791647
Loss at iteration 750 : 0.008750749751925468
Loss at iteration 760 : 0.00606331555172801
Loss at iteration 770 : 0.01025855727493763
Loss at iteration 780 : 0.01155106257647276
Loss at iteration 790 : 0.006792333908379078
Loss at iteration 800 : 0.006894872523844242
Loss at iteration 810 : 0.011235338635742664
Loss at iteration 820 : 0.006802467629313469
Loss at iteration 830 : 0.003634127788245678
Loss at iteration 840 : 0.012714470736682415
Loss at iteration 850 : 0.005720426328480244
Loss at iteration 860 : 0.008568893186748028
Loss at iteration 870 : 0.008617093786597252
Loss at iteration 880 : 0.009209747426211834
Loss at iteration 890 : 0.006926536560058594
Loss at iteration 900 : 0.006191094871610403
Loss at iteration 910 : 0.005039088893681765
Loss at iteration 920 : 0.00829867459833622
Loss at iteration 930 : 0.013176767155528069
Loss at iteration 940 : 0.004394609946757555
Loss at iteration 950 : 0.008246471174061298
Loss at iteration 960 : 0.011174489744007587
Loss at iteration 970 : 0.004464169964194298
Loss at iteration 980 : 0.010150756686925888
Loss at iteration 990 : 0.005351549480110407
Loss at iteration 1000 : 0.003497285069897771
Loss at iteration 1010 : 0.007745211943984032
Loss at iteration 1020 : 0.010022224858403206
Loss at iteration 1030 : 0.004190482199192047
Loss at iteration 1040 : 0.0031942371279001236
Loss at iteration 1050 : 0.005898164119571447
Loss at iteration 1060 : 0.01590600237250328
Loss at iteration 1070 : 0.006755569949746132
Loss at iteration 1080 : 0.013824679888784885
Loss at iteration 1090 : 0.006388272624462843
Loss at iteration 1100 : 0.010163872502744198
Loss at iteration 1110 : 0.007774753496050835
Loss at iteration 1120 : 0.011635508388280869
Loss at iteration 1130 : 0.0044762203469872475
Loss at iteration 1140 : 0.009880080819129944
Loss at iteration 1150 : 0.012479616329073906
Loss at iteration 1160 : 0.01592189073562622
Loss at iteration 1170 : 0.009329566732048988
Loss at iteration 1180 : 0.006197787821292877
Loss at iteration 1190 : 0.014674734324216843
Loss at iteration 1200 : 0.013236967846751213
Loss at iteration 1210 : 0.005494436249136925
Loss at iteration 1220 : 0.008748460561037064
Loss at iteration 1230 : 0.003029194660484791
Loss at iteration 1240 : 0.011469800025224686
Loss at iteration 1250 : 0.004665447864681482
Loss at iteration 1260 : 0.004759333096444607
Loss at iteration 1270 : 0.017422856763005257
Loss at iteration 1280 : 0.009828580543398857
Loss at iteration 1290 : 0.0026034268084913492
Loss at iteration 1300 : 0.00574022950604558
Loss at iteration 1310 : 0.00837541464716196
Loss at iteration 1320 : 0.013130863197147846
Loss at iteration 1330 : 0.02217879891395569
Loss at iteration 1340 : 0.017002694308757782
Loss at iteration 1350 : 0.007504496723413467
Loss at iteration 1360 : 0.00633798073977232
Loss at iteration 1370 : 0.009618033654987812
Loss at iteration 1380 : 0.004864441696554422
Loss at iteration 1390 : 0.002671389142051339
Loss at iteration 1400 : 0.004716084338724613
Loss at iteration 1410 : 0.013999857939779758
Loss at iteration 1420 : 0.00404190830886364
Loss at iteration 1430 : 0.009340967983007431
Loss at iteration 1440 : 0.007302663289010525
Loss at iteration 1450 : 0.00999084860086441
Loss at iteration 1460 : 0.007064024452120066
Loss at iteration 1470 : 0.0037730911280959845
Loss at iteration 1480 : 0.009468893520534039
Loss at iteration 1490 : 0.01110515184700489
Loss at iteration 1500 : 0.006112448405474424
Loss at iteration 1510 : 0.011499658226966858
Loss at iteration 1520 : 0.010011046193540096
Loss at iteration 1530 : 0.01422249898314476
Loss at iteration 1540 : 0.013844446279108524
Loss at iteration 1550 : 0.006104086060076952
Loss at iteration 1560 : 0.0036793334875255823
Loss at iteration 1570 : 0.007137980777770281
Loss at iteration 1580 : 0.010152981616556644
Loss at iteration 1590 : 0.020615478977560997
Loss at iteration 1600 : 0.011705741286277771
Loss at iteration 1610 : 0.006443141959607601
Loss at iteration 1620 : 0.00795263797044754
Loss at iteration 1630 : 0.006430456880480051
Loss at iteration 1640 : 0.006586180999875069
Loss at iteration 1650 : 0.006887469440698624
Loss at iteration 1660 : 0.004827681928873062
Loss at iteration 1670 : 0.007512234151363373
Loss at iteration 1680 : 0.008555484935641289
Loss at iteration 1690 : 0.009684494696557522
Loss at iteration 1700 : 0.013176188804209232
Loss at iteration 1710 : 0.008975895121693611
Loss at iteration 1720 : 0.0039808256551623344
Loss at iteration 1730 : 0.008751888759434223
Loss at iteration 1740 : 0.00805397517979145
Loss at iteration 1750 : 0.0053210267797112465
Loss at iteration 1760 : 0.0074812499806284904
Loss at iteration 1770 : 0.009647868573665619
Loss at iteration 1780 : 0.0069810692220926285
Loss at iteration 1790 : 0.015712210908532143
Loss at iteration 1800 : 0.01029336079955101
Loss at iteration 1810 : 0.004165458492934704
Loss at iteration 1820 : 0.008782424964010715
Loss at iteration 1830 : 0.006580017972737551
Loss at iteration 1840 : 0.014582324773073196
Loss at iteration 1850 : 0.010888350196182728
Loss at iteration 1860 : 0.006119089666754007
Loss at iteration 1870 : 0.013374467380344868
Loss at iteration 1880 : 0.01370135135948658
Loss at iteration 1890 : 0.008146796375513077
Loss at iteration 1900 : 0.012549290433526039
Loss at iteration 1910 : 0.01665320061147213
Loss at iteration 1920 : 0.006446888670325279
Loss at iteration 1930 : 0.011404578574001789
Loss at iteration 1940 : 0.0058907330967485905
Loss at iteration 1950 : 0.009289482608437538
Loss at iteration 1960 : 0.006502667907625437
Loss at iteration 1970 : 0.004446888342499733
Loss at iteration 1980 : 0.01101024728268385
Loss at iteration 1990 : 0.007470867596566677
Loss at iteration 2000 : 0.014239227399230003
Loss at iteration 2010 : 0.016120420768857002
Loss at iteration 2020 : 0.008320567198097706
Loss at iteration 2030 : 0.006023879162967205
Loss at iteration 2040 : 0.004747106693685055
Loss at iteration 2050 : 0.010940173640847206
Loss at iteration 2060 : 0.008950206451117992
Loss at iteration 2070 : 0.0034968522377312183
Loss at iteration 2080 : 0.008062024600803852
Loss at iteration 2090 : 0.01956060342490673
Loss at iteration 2100 : 0.006250309757888317
Loss at iteration 2110 : 0.007104718126356602
Loss at iteration 2120 : 0.009954817593097687
Loss at iteration 2130 : 0.007915875874459743
Loss at iteration 2140 : 0.015940707176923752
Loss at iteration 2150 : 0.012684234417974949
Loss at iteration 2160 : 0.010252549313008785
Loss at iteration 2170 : 0.008038950152695179
Loss at iteration 2180 : 0.013203803449869156
Loss at iteration 2190 : 0.014958778396248817
Loss at iteration 2200 : 0.00797850452363491
Loss at iteration 2210 : 0.008179099299013615
Loss at iteration 2220 : 0.007911323569715023
Loss at iteration 2230 : 0.005394018720835447
Loss at iteration 2240 : 0.011947649531066418
Loss at iteration 2250 : 0.010038841515779495
Loss at iteration 2260 : 0.00739654153585434
Loss at iteration 2270 : 0.008927250280976295
Loss at iteration 2280 : 0.008781852200627327
Loss at iteration 2290 : 0.0027539606671780348
Loss at iteration 2300 : 0.010514668188989162
Loss at iteration 2310 : 0.014391003176569939
Loss at iteration 2320 : 0.007127760443836451
Loss at iteration 2330 : 0.01000226754695177
Loss at iteration 2340 : 0.018294015899300575
Loss at iteration 2350 : 0.009314458817243576
Loss at iteration 2360 : 0.010182926431298256
Loss at iteration 2370 : 0.006646891590207815
Loss at iteration 2380 : 0.007817142643034458
Loss at iteration 2390 : 0.002579372376203537
Loss at iteration 2400 : 0.007026246283203363
Loss at iteration 2410 : 0.005918086040765047
Loss at iteration 2420 : 0.009483182802796364
The SSIM Value is: 0.8445416649182638
The PSNR Value is: 22.04497661590576
the epoch is: 102
Loss at iteration 10 : 0.007696854416280985
Loss at iteration 20 : 0.00779888778924942
Loss at iteration 30 : 0.010788197629153728
Loss at iteration 40 : 0.008043880574405193
Loss at iteration 50 : 0.009763496927917004
Loss at iteration 60 : 0.0040368628688156605
Loss at iteration 70 : 0.011857302859425545
Loss at iteration 80 : 0.005442934576421976
Loss at iteration 90 : 0.006050335709005594
Loss at iteration 100 : 0.005672974977642298
Loss at iteration 110 : 0.015156515873968601
Loss at iteration 120 : 0.0031013500411063433
Loss at iteration 130 : 0.0054556806571781635
Loss at iteration 140 : 0.007405002601444721
Loss at iteration 150 : 0.005198203027248383
Loss at iteration 160 : 0.03168768435716629
Loss at iteration 170 : 0.004620460793375969
Loss at iteration 180 : 0.007628289051353931
Loss at iteration 190 : 0.004888652358204126
Loss at iteration 200 : 0.013004367239773273
Loss at iteration 210 : 0.010811004787683487
Loss at iteration 220 : 0.0035718970466405153
Loss at iteration 230 : 0.01788536086678505
Loss at iteration 240 : 0.009985078126192093
Loss at iteration 250 : 0.008260861039161682
Loss at iteration 260 : 0.004683151841163635
Loss at iteration 270 : 0.012149118818342686
Loss at iteration 280 : 0.00950279738754034
Loss at iteration 290 : 0.0034890349488705397
Loss at iteration 300 : 0.009622112847864628
Loss at iteration 310 : 0.005781480111181736
Loss at iteration 320 : 0.005731484387069941
Loss at iteration 330 : 0.005845846142619848
Loss at iteration 340 : 0.00806740578263998
Loss at iteration 350 : 0.002961191348731518
Loss at iteration 360 : 0.009547199122607708
Loss at iteration 370 : 0.011985484510660172
Loss at iteration 380 : 0.007960339076817036
Loss at iteration 390 : 0.010860929265618324
Loss at iteration 400 : 0.008996863849461079
Loss at iteration 410 : 0.006528402678668499
Loss at iteration 420 : 0.0033443523570895195
Loss at iteration 430 : 0.010521536692976952
Loss at iteration 440 : 0.007907766848802567
Loss at iteration 450 : 0.003801489481702447
Loss at iteration 460 : 0.004129413980990648
Loss at iteration 470 : 0.008093097247183323
Loss at iteration 480 : 0.010559214279055595
Loss at iteration 490 : 0.004256444051861763
Loss at iteration 500 : 0.006040535867214203
Loss at iteration 510 : 0.014093741774559021
Loss at iteration 520 : 0.003957469016313553
Loss at iteration 530 : 0.004459492862224579
Loss at iteration 540 : 0.012184079736471176
Loss at iteration 550 : 0.008379276841878891
Loss at iteration 560 : 0.009898914024233818
Loss at iteration 570 : 0.006875435821712017
Loss at iteration 580 : 0.007397086825221777
Loss at iteration 590 : 0.007193451747298241
Loss at iteration 600 : 0.011418601498007774
Loss at iteration 610 : 0.0063399747014045715
Loss at iteration 620 : 0.0067823054268956184
Loss at iteration 630 : 0.020277902483940125
Loss at iteration 640 : 0.0023253662511706352
Loss at iteration 650 : 0.017245568335056305
Loss at iteration 660 : 0.004046876914799213
Loss at iteration 670 : 0.0084219453856349
Loss at iteration 680 : 0.0087673868983984
Loss at iteration 690 : 0.007544046267867088
Loss at iteration 700 : 0.005214546341449022
Loss at iteration 710 : 0.007945947349071503
Loss at iteration 720 : 0.009912483394145966
Loss at iteration 730 : 0.0032006902620196342
Loss at iteration 740 : 0.005337266251444817
Loss at iteration 750 : 0.009483572095632553
Loss at iteration 760 : 0.01087282132357359
Loss at iteration 770 : 0.007395274005830288
Loss at iteration 780 : 0.01780865527689457
Loss at iteration 790 : 0.007583689875900745
Loss at iteration 800 : 0.004228158388286829
Loss at iteration 810 : 0.01631157286465168
Loss at iteration 820 : 0.010215469636023045
Loss at iteration 830 : 0.01031589601188898
Loss at iteration 840 : 0.008495107293128967
Loss at iteration 850 : 0.008832788094878197
Loss at iteration 860 : 0.004423810169100761
Loss at iteration 870 : 0.003495886456221342
Loss at iteration 880 : 0.016063176095485687
Loss at iteration 890 : 0.004727665334939957
Loss at iteration 900 : 0.006643963046371937
Loss at iteration 910 : 0.004964159801602364
Loss at iteration 920 : 0.006966039072722197
Loss at iteration 930 : 0.005571738351136446
Loss at iteration 940 : 0.007483139634132385
Loss at iteration 950 : 0.010539229959249496
Loss at iteration 960 : 0.02157648839056492
Loss at iteration 970 : 0.010127075016498566
Loss at iteration 980 : 0.015524993650615215
Loss at iteration 990 : 0.02256348356604576
Loss at iteration 1000 : 0.0041063870303332806
Loss at iteration 1010 : 0.002131305867806077
Loss at iteration 1020 : 0.009047188796103
Loss at iteration 1030 : 0.014810824766755104
Loss at iteration 1040 : 0.00718300137668848
Loss at iteration 1050 : 0.004421842750161886
Loss at iteration 1060 : 0.006734735798090696
Loss at iteration 1070 : 0.009402601979672909
Loss at iteration 1080 : 0.013510724529623985
Loss at iteration 1090 : 0.008860384114086628
Loss at iteration 1100 : 0.012861557304859161
Loss at iteration 1110 : 0.006390818860381842
Loss at iteration 1120 : 0.01029154285788536
Loss at iteration 1130 : 0.009779371321201324
Loss at iteration 1140 : 0.009415704756975174
Loss at iteration 1150 : 0.007572535891085863
Loss at iteration 1160 : 0.013296500779688358
Loss at iteration 1170 : 0.005082431249320507
Loss at iteration 1180 : 0.017648598179221153
Loss at iteration 1190 : 0.008109686896204948
Loss at iteration 1200 : 0.018219642341136932
Loss at iteration 1210 : 0.026755433529615402
Loss at iteration 1220 : 0.009007412940263748
Loss at iteration 1230 : 0.008137292228639126
Loss at iteration 1240 : 0.00564593868330121
Loss at iteration 1250 : 0.004050014540553093
Loss at iteration 1260 : 0.00700471643358469
Loss at iteration 1270 : 0.010610125958919525
Loss at iteration 1280 : 0.022268962115049362
Loss at iteration 1290 : 0.013730638660490513
Loss at iteration 1300 : 0.011991070583462715
Loss at iteration 1310 : 0.0059498632326722145
Loss at iteration 1320 : 0.010058216750621796
Loss at iteration 1330 : 0.008069979026913643
Loss at iteration 1340 : 0.006317994091659784
Loss at iteration 1350 : 0.010529257357120514
Loss at iteration 1360 : 0.018345322459936142
Loss at iteration 1370 : 0.011460861191153526
Loss at iteration 1380 : 0.007055134512484074
Loss at iteration 1390 : 0.006943452171981335
Loss at iteration 1400 : 0.0170903317630291
Loss at iteration 1410 : 0.007258890196681023
Loss at iteration 1420 : 0.019472340121865273
Loss at iteration 1430 : 0.025454973801970482
Loss at iteration 1440 : 0.007728868164122105
Loss at iteration 1450 : 0.017608949914574623
Loss at iteration 1460 : 0.00892561487853527
Loss at iteration 1470 : 0.013127028942108154
Loss at iteration 1480 : 0.012558713555335999
Loss at iteration 1490 : 0.010658083483576775
Loss at iteration 1500 : 0.01267590094357729
Loss at iteration 1510 : 0.008226422592997551
Loss at iteration 1520 : 0.013754298910498619
Loss at iteration 1530 : 0.007756252307444811
Loss at iteration 1540 : 0.008733861148357391
Loss at iteration 1550 : 0.015322072431445122
Loss at iteration 1560 : 0.006613209843635559
Loss at iteration 1570 : 0.01710844598710537
Loss at iteration 1580 : 0.007192940451204777
Loss at iteration 1590 : 0.011809413321316242
Loss at iteration 1600 : 0.01318163238465786
Loss at iteration 1610 : 0.004686726722866297
Loss at iteration 1620 : 0.005550037138164043
Loss at iteration 1630 : 0.005449805408716202
Loss at iteration 1640 : 0.005716973450034857
Loss at iteration 1650 : 0.008090618066489697
Loss at iteration 1660 : 0.006544402334839106
Loss at iteration 1670 : 0.01891046017408371
Loss at iteration 1680 : 0.010423731058835983
Loss at iteration 1690 : 0.010093934834003448
Loss at iteration 1700 : 0.011155448853969574
Loss at iteration 1710 : 0.014980560168623924
Loss at iteration 1720 : 0.008726753294467926
Loss at iteration 1730 : 0.006306534167379141
Loss at iteration 1740 : 0.009716236032545567
Loss at iteration 1750 : 0.007624289486557245
Loss at iteration 1760 : 0.005955249071121216
Loss at iteration 1770 : 0.010860809125006199
Loss at iteration 1780 : 0.008082326501607895
Loss at iteration 1790 : 0.015509282238781452
Loss at iteration 1800 : 0.012277965433895588
Loss at iteration 1810 : 0.005378196015954018
Loss at iteration 1820 : 0.01236257515847683
Loss at iteration 1830 : 0.010617047548294067
Loss at iteration 1840 : 0.010913914069533348
Loss at iteration 1850 : 0.002649226225912571
Loss at iteration 1860 : 0.014713801443576813
Loss at iteration 1870 : 0.010224818252027035
Loss at iteration 1880 : 0.010493346489965916
Loss at iteration 1890 : 0.007412619888782501
Loss at iteration 1900 : 0.005201580468565226
Loss at iteration 1910 : 0.009334307163953781
Loss at iteration 1920 : 0.002061081351712346
Loss at iteration 1930 : 0.0062087601982057095
Loss at iteration 1940 : 0.006601427216082811
Loss at iteration 1950 : 0.007910159416496754
Loss at iteration 1960 : 0.013444223441183567
Loss at iteration 1970 : 0.008045578375458717
Loss at iteration 1980 : 0.008156104013323784
Loss at iteration 1990 : 0.01896025612950325
Loss at iteration 2000 : 0.00899545568972826
Loss at iteration 2010 : 0.009127615951001644
Loss at iteration 2020 : 0.004984960425645113
Loss at iteration 2030 : 0.00951824989169836
Loss at iteration 2040 : 0.01260694395750761
Loss at iteration 2050 : 0.00832211785018444
Loss at iteration 2060 : 0.00395138980820775
Loss at iteration 2070 : 0.010402745567262173
Loss at iteration 2080 : 0.007447578012943268
Loss at iteration 2090 : 0.003427860327064991
Loss at iteration 2100 : 0.02203446254134178
Loss at iteration 2110 : 0.010294357314705849
Loss at iteration 2120 : 0.00824920553714037
Loss at iteration 2130 : 0.013608762994408607
Loss at iteration 2140 : 0.018518563359975815
Loss at iteration 2150 : 0.007777741178870201
Loss at iteration 2160 : 0.004610397852957249
Loss at iteration 2170 : 0.003244137391448021
Loss at iteration 2180 : 0.007329211570322514
Loss at iteration 2190 : 0.0058995382860302925
Loss at iteration 2200 : 0.00517561100423336
Loss at iteration 2210 : 0.007062579970806837
Loss at iteration 2220 : 0.01955617219209671
Loss at iteration 2230 : 0.016139984130859375
Loss at iteration 2240 : 0.006251581013202667
Loss at iteration 2250 : 0.006202196702361107
Loss at iteration 2260 : 0.009433886036276817
Loss at iteration 2270 : 0.006241154856979847
Loss at iteration 2280 : 0.011582101695239544
Loss at iteration 2290 : 0.005831796210259199
Loss at iteration 2300 : 0.026952218264341354
Loss at iteration 2310 : 0.008240421302616596
Loss at iteration 2320 : 0.013101683929562569
Loss at iteration 2330 : 0.010430693626403809
Loss at iteration 2340 : 0.013437634333968163
Loss at iteration 2350 : 0.01876155473291874
Loss at iteration 2360 : 0.007794403005391359
Loss at iteration 2370 : 0.011255301535129547
Loss at iteration 2380 : 0.009748351760208607
Loss at iteration 2390 : 0.006074718665331602
Loss at iteration 2400 : 0.0070816390216350555
Loss at iteration 2410 : 0.005746223032474518
Loss at iteration 2420 : 0.007846744731068611
The SSIM Value is: 0.8505952000617981
The PSNR Value is: 22.637739817301433
the epoch is: 103
Loss at iteration 10 : 0.006335406564176083
Loss at iteration 20 : 0.00527208112180233
Loss at iteration 30 : 0.0073245009407401085
Loss at iteration 40 : 0.007342480588704348
Loss at iteration 50 : 0.0044477637857198715
Loss at iteration 60 : 0.0038321225438266993
Loss at iteration 70 : 0.015657376497983932
Loss at iteration 80 : 0.00543997623026371
Loss at iteration 90 : 0.005329502280801535
Loss at iteration 100 : 0.011154954321682453
Loss at iteration 110 : 0.008200624026358128
Loss at iteration 120 : 0.010343095287680626
Loss at iteration 130 : 0.0071228789165616035
Loss at iteration 140 : 0.00968988984823227
Loss at iteration 150 : 0.006503489799797535
Loss at iteration 160 : 0.012415251694619656
Loss at iteration 170 : 0.010121124796569347
Loss at iteration 180 : 0.006486669182777405
Loss at iteration 190 : 0.010199885815382004
Loss at iteration 200 : 0.017823662608861923
Loss at iteration 210 : 0.011372683569788933
Loss at iteration 220 : 0.011937393806874752
Loss at iteration 230 : 0.03397957608103752
Loss at iteration 240 : 0.01036260649561882
Loss at iteration 250 : 0.012789677828550339
Loss at iteration 260 : 0.005585048347711563
Loss at iteration 270 : 0.004963838495314121
Loss at iteration 280 : 0.0052271150052547455
Loss at iteration 290 : 0.0020637442357838154
Loss at iteration 300 : 0.010796379297971725
Loss at iteration 310 : 0.011793544515967369
Loss at iteration 320 : 0.004866793751716614
Loss at iteration 330 : 0.006229938007891178
Loss at iteration 340 : 0.006690771318972111
Loss at iteration 350 : 0.010190177708864212
Loss at iteration 360 : 0.013827169314026833
Loss at iteration 370 : 0.008180509321391582
Loss at iteration 380 : 0.00923074223101139
Loss at iteration 390 : 0.010090917348861694
Loss at iteration 400 : 0.02059834636747837
Loss at iteration 410 : 0.00430021807551384
Loss at iteration 420 : 0.004010011442005634
Loss at iteration 430 : 0.007967839948832989
Loss at iteration 440 : 0.003140599001199007
Loss at iteration 450 : 0.010375050827860832
Loss at iteration 460 : 0.008573179133236408
Loss at iteration 470 : 0.008133383467793465
Loss at iteration 480 : 0.012867600657045841
Loss at iteration 490 : 0.007253749296069145
Loss at iteration 500 : 0.01366589404642582
Loss at iteration 510 : 0.006249298807233572
Loss at iteration 520 : 0.00687649380415678
Loss at iteration 530 : 0.004925191402435303
Loss at iteration 540 : 0.004692538641393185
Loss at iteration 550 : 0.010392744094133377
Loss at iteration 560 : 0.011971646919846535
Loss at iteration 570 : 0.009306143969297409
Loss at iteration 580 : 0.00588664785027504
Loss at iteration 590 : 0.006532813422381878
Loss at iteration 600 : 0.0052381884306669235
Loss at iteration 610 : 0.004485849756747484
Loss at iteration 620 : 0.0178974736481905
Loss at iteration 630 : 0.015087340027093887
Loss at iteration 640 : 0.010990984737873077
Loss at iteration 650 : 0.004630872048437595
Loss at iteration 660 : 0.025851164013147354
Loss at iteration 670 : 0.006928006187081337
Loss at iteration 680 : 0.011128301732242107
Loss at iteration 690 : 0.010736209340393543
Loss at iteration 700 : 0.006260749883949757
Loss at iteration 710 : 0.009446152485907078
Loss at iteration 720 : 0.012054241262376308
Loss at iteration 730 : 0.01244857907295227
Loss at iteration 740 : 0.011147793382406235
Loss at iteration 750 : 0.008891013450920582
Loss at iteration 760 : 0.01340146828442812
Loss at iteration 770 : 0.007109170779585838
Loss at iteration 780 : 0.0045577227137982845
Loss at iteration 790 : 0.005934048444032669
Loss at iteration 800 : 0.011114094406366348
Loss at iteration 810 : 0.014489661902189255
Loss at iteration 820 : 0.007508725393563509
Loss at iteration 830 : 0.016888033598661423
Loss at iteration 840 : 0.007389470003545284
Loss at iteration 850 : 0.008056777529418468
Loss at iteration 860 : 0.006078592035919428
Loss at iteration 870 : 0.006251827348023653
Loss at iteration 880 : 0.01478501409292221
Loss at iteration 890 : 0.0034086392261087894
Loss at iteration 900 : 0.017347747460007668
Loss at iteration 910 : 0.007944532670080662
Loss at iteration 920 : 0.004567187745124102
Loss at iteration 930 : 0.012469171546399593
Loss at iteration 940 : 0.0075203366577625275
Loss at iteration 950 : 0.014867846854031086
Loss at iteration 960 : 0.01163306925445795
Loss at iteration 970 : 0.016575921326875687
Loss at iteration 980 : 0.0034790888894349337
Loss at iteration 990 : 0.004047790076583624
Loss at iteration 1000 : 0.007485098205506802
Loss at iteration 1010 : 0.008323590271174908
Loss at iteration 1020 : 0.007958883419632912
Loss at iteration 1030 : 0.011062679812312126
Loss at iteration 1040 : 0.01295170746743679
Loss at iteration 1050 : 0.009705901145935059
Loss at iteration 1060 : 0.007383435964584351
Loss at iteration 1070 : 0.008435172960162163
Loss at iteration 1080 : 0.0059257810935378075
Loss at iteration 1090 : 0.010386970825493336
Loss at iteration 1100 : 0.01323897484689951
Loss at iteration 1110 : 0.004109920933842659
Loss at iteration 1120 : 0.004528827499598265
Loss at iteration 1130 : 0.019594013690948486
Loss at iteration 1140 : 0.009307383559644222
Loss at iteration 1150 : 0.006517302710562944
Loss at iteration 1160 : 0.007224819622933865
Loss at iteration 1170 : 0.0020529478788375854
Loss at iteration 1180 : 0.0037027010694146156
Loss at iteration 1190 : 0.004540849477052689
Loss at iteration 1200 : 0.009794837795197964
Loss at iteration 1210 : 0.013270236551761627
Loss at iteration 1220 : 0.0072333067655563354
Loss at iteration 1230 : 0.00792447105050087
Loss at iteration 1240 : 0.006603441201150417
Loss at iteration 1250 : 0.006649911869317293
Loss at iteration 1260 : 0.003355776658281684
Loss at iteration 1270 : 0.009307418949902058
Loss at iteration 1280 : 0.00411220034584403
Loss at iteration 1290 : 0.0023669200018048286
Loss at iteration 1300 : 0.012225935235619545
Loss at iteration 1310 : 0.015845393761992455
Loss at iteration 1320 : 0.023260651156306267
Loss at iteration 1330 : 0.007107412442564964
Loss at iteration 1340 : 0.009408296085894108
Loss at iteration 1350 : 0.006756320595741272
Loss at iteration 1360 : 0.00846097245812416
Loss at iteration 1370 : 0.007504674606025219
Loss at iteration 1380 : 0.014251433312892914
Loss at iteration 1390 : 0.007772823795676231
Loss at iteration 1400 : 0.010734234005212784
Loss at iteration 1410 : 0.004735264461487532
Loss at iteration 1420 : 0.008097217418253422
Loss at iteration 1430 : 0.007838854566216469
Loss at iteration 1440 : 0.0058776200748980045
Loss at iteration 1450 : 0.009976115077733994
Loss at iteration 1460 : 0.01394620444625616
Loss at iteration 1470 : 0.0065207574516534805
Loss at iteration 1480 : 0.006426345091313124
Loss at iteration 1490 : 0.015105485916137695
Loss at iteration 1500 : 0.003577072639018297
Loss at iteration 1510 : 0.006132010370492935
Loss at iteration 1520 : 0.012350929901003838
Loss at iteration 1530 : 0.006690252106636763
Loss at iteration 1540 : 0.009128119796514511
Loss at iteration 1550 : 0.006250306498259306
Loss at iteration 1560 : 0.015215951949357986
Loss at iteration 1570 : 0.009271739982068539
Loss at iteration 1580 : 0.007109538652002811
Loss at iteration 1590 : 0.006668854504823685
Loss at iteration 1600 : 0.004669703543186188
Loss at iteration 1610 : 0.006185317412018776
Loss at iteration 1620 : 0.012590411119163036
Loss at iteration 1630 : 0.0063704028725624084
Loss at iteration 1640 : 0.004399007651954889
Loss at iteration 1650 : 0.009217102080583572
Loss at iteration 1660 : 0.010011234320700169
Loss at iteration 1670 : 0.010983619838953018
Loss at iteration 1680 : 0.007165251765400171
Loss at iteration 1690 : 0.003924955613911152
Loss at iteration 1700 : 0.007612660527229309
Loss at iteration 1710 : 0.006096139550209045
Loss at iteration 1720 : 0.021549033001065254
Loss at iteration 1730 : 0.011160130612552166
Loss at iteration 1740 : 0.011098443530499935
Loss at iteration 1750 : 0.014411602169275284
Loss at iteration 1760 : 0.0061342353001236916
Loss at iteration 1770 : 0.003605196252465248
Loss at iteration 1780 : 0.00876664649695158
Loss at iteration 1790 : 0.00681501068174839
Loss at iteration 1800 : 0.021331682801246643
Loss at iteration 1810 : 0.008060133084654808
Loss at iteration 1820 : 0.008753970265388489
Loss at iteration 1830 : 0.009148498065769672
Loss at iteration 1840 : 0.006574368104338646
Loss at iteration 1850 : 0.005488282535225153
Loss at iteration 1860 : 0.007928408682346344
Loss at iteration 1870 : 0.00875612162053585
Loss at iteration 1880 : 0.009016651660203934
Loss at iteration 1890 : 0.007247176021337509
Loss at iteration 1900 : 0.006709669716656208
Loss at iteration 1910 : 0.012049679644405842
Loss at iteration 1920 : 0.006916314363479614
Loss at iteration 1930 : 0.0160202793776989
Loss at iteration 1940 : 0.00867447629570961
Loss at iteration 1950 : 0.012243418022990227
Loss at iteration 1960 : 0.00847652554512024
Loss at iteration 1970 : 0.007973846048116684
Loss at iteration 1980 : 0.008748732507228851
Loss at iteration 1990 : 0.006752302870154381
Loss at iteration 2000 : 0.016977187246084213
Loss at iteration 2010 : 0.0035567900631576777
Loss at iteration 2020 : 0.003368526231497526
Loss at iteration 2030 : 0.013891995884478092
Loss at iteration 2040 : 0.010830004699528217
Loss at iteration 2050 : 0.013634605333209038
Loss at iteration 2060 : 0.0054263826459646225
Loss at iteration 2070 : 0.014780966565012932
Loss at iteration 2080 : 0.009505963884294033
Loss at iteration 2090 : 0.006792216561734676
Loss at iteration 2100 : 0.010372736491262913
Loss at iteration 2110 : 0.0097653241828084
Loss at iteration 2120 : 0.007267956621944904
Loss at iteration 2130 : 0.010530173778533936
Loss at iteration 2140 : 0.004870440345257521
Loss at iteration 2150 : 0.007386213168501854
Loss at iteration 2160 : 0.007848821580410004
Loss at iteration 2170 : 0.007574115879833698
Loss at iteration 2180 : 0.01136072352528572
Loss at iteration 2190 : 0.010897092521190643
Loss at iteration 2200 : 0.004630670882761478
Loss at iteration 2210 : 0.015914691612124443
Loss at iteration 2220 : 0.003394431434571743
Loss at iteration 2230 : 0.0069667017087340355
Loss at iteration 2240 : 0.007221836596727371
Loss at iteration 2250 : 0.017121877521276474
Loss at iteration 2260 : 0.007703371345996857
Loss at iteration 2270 : 0.00820291880518198
Loss at iteration 2280 : 0.01614382676780224
Loss at iteration 2290 : 0.02102016657590866
Loss at iteration 2300 : 0.011827762238681316
Loss at iteration 2310 : 0.010453972965478897
Loss at iteration 2320 : 0.011570721864700317
Loss at iteration 2330 : 0.006097647827118635
Loss at iteration 2340 : 0.006279647815972567
Loss at iteration 2350 : 0.019536565989255905
Loss at iteration 2360 : 0.010568792000412941
Loss at iteration 2370 : 0.00636235810816288
Loss at iteration 2380 : 0.015131186693906784
Loss at iteration 2390 : 0.012379992753267288
Loss at iteration 2400 : 0.01315727736800909
Loss at iteration 2410 : 0.00424785865470767
Loss at iteration 2420 : 0.0077015189453959465
The SSIM Value is: 0.8465252081553142
The PSNR Value is: 22.4966734568278
the epoch is: 104
Loss at iteration 10 : 0.007709089200943708
Loss at iteration 20 : 0.009786969050765038
Loss at iteration 30 : 0.019836843013763428
Loss at iteration 40 : 0.012852986343204975
Loss at iteration 50 : 0.004393775947391987
Loss at iteration 60 : 0.008680615574121475
Loss at iteration 70 : 0.007259008474647999
Loss at iteration 80 : 0.008801407180726528
Loss at iteration 90 : 0.004692750982940197
Loss at iteration 100 : 0.012892123311758041
Loss at iteration 110 : 0.008056201972067356
Loss at iteration 120 : 0.00637236051261425
Loss at iteration 130 : 0.003859682707116008
Loss at iteration 140 : 0.013251794502139091
Loss at iteration 150 : 0.01411252748221159
Loss at iteration 160 : 0.011423103511333466
Loss at iteration 170 : 0.0085607273504138
Loss at iteration 180 : 0.0029114324133843184
Loss at iteration 190 : 0.011735925450921059
Loss at iteration 200 : 0.00392534676939249
Loss at iteration 210 : 0.01379229687154293
Loss at iteration 220 : 0.0049910591915249825
Loss at iteration 230 : 0.005112117156386375
Loss at iteration 240 : 0.003926550038158894
Loss at iteration 250 : 0.011554955504834652
Loss at iteration 260 : 0.005892935208976269
Loss at iteration 270 : 0.0037540884222835302
Loss at iteration 280 : 0.010744207538664341
Loss at iteration 290 : 0.002776675159111619
Loss at iteration 300 : 0.020120058208703995
Loss at iteration 310 : 0.013637288473546505
Loss at iteration 320 : 0.005744777154177427
Loss at iteration 330 : 0.008733117021620274
Loss at iteration 340 : 0.014003148302435875
Loss at iteration 350 : 0.0038187531754374504
Loss at iteration 360 : 0.011557661928236485
Loss at iteration 370 : 0.00890164915472269
Loss at iteration 380 : 0.006309138610959053
Loss at iteration 390 : 0.009376883506774902
Loss at iteration 400 : 0.008342549204826355
Loss at iteration 410 : 0.004236286040395498
Loss at iteration 420 : 0.012561497278511524
Loss at iteration 430 : 0.0076166498474776745
Loss at iteration 440 : 0.009427710436284542
Loss at iteration 450 : 0.0027933891396969557
Loss at iteration 460 : 0.007505957968533039
Loss at iteration 470 : 0.005395031999796629
Loss at iteration 480 : 0.012128246948122978
Loss at iteration 490 : 0.004625500645488501
Loss at iteration 500 : 0.013845228590071201
Loss at iteration 510 : 0.0072533381171524525
Loss at iteration 520 : 0.0030214227735996246
Loss at iteration 530 : 0.0036721769720315933
Loss at iteration 540 : 0.00933144986629486
Loss at iteration 550 : 0.00988056417554617
Loss at iteration 560 : 0.005055717192590237
Loss at iteration 570 : 0.012753956019878387
Loss at iteration 580 : 0.01153593510389328
Loss at iteration 590 : 0.012548478320240974
Loss at iteration 600 : 0.004490486811846495
Loss at iteration 610 : 0.011962038464844227
Loss at iteration 620 : 0.007420952897518873
Loss at iteration 630 : 0.030560806393623352
Loss at iteration 640 : 0.010113941505551338
Loss at iteration 650 : 0.003547065891325474
Loss at iteration 660 : 0.00768289202824235
Loss at iteration 670 : 0.014606223441660404
Loss at iteration 680 : 0.0060308873653411865
Loss at iteration 690 : 0.009265357628464699
Loss at iteration 700 : 0.013507152907550335
Loss at iteration 710 : 0.007655214052647352
Loss at iteration 720 : 0.007892554625868797
Loss at iteration 730 : 0.006222940981388092
Loss at iteration 740 : 0.011612805537879467
Loss at iteration 750 : 0.006306319963186979
Loss at iteration 760 : 0.00871780700981617
Loss at iteration 770 : 0.01004074327647686
Loss at iteration 780 : 0.006088618654757738
Loss at iteration 790 : 0.0023977821692824364
Loss at iteration 800 : 0.015324613079428673
Loss at iteration 810 : 0.009790584444999695
Loss at iteration 820 : 0.009128300473093987
Loss at iteration 830 : 0.008762598037719727
Loss at iteration 840 : 0.011648443527519703
Loss at iteration 850 : 0.0065112244337797165
Loss at iteration 860 : 0.011754073202610016
Loss at iteration 870 : 0.004366974346339703
Loss at iteration 880 : 0.00331106036901474
Loss at iteration 890 : 0.0038882375229150057
Loss at iteration 900 : 0.01024080440402031
Loss at iteration 910 : 0.013559190556406975
Loss at iteration 920 : 0.006367159076035023
Loss at iteration 930 : 0.014413608238101006
Loss at iteration 940 : 0.0070649986155331135
Loss at iteration 950 : 0.008252963423728943
Loss at iteration 960 : 0.024947751313447952
Loss at iteration 970 : 0.004021119326353073
Loss at iteration 980 : 0.007663230411708355
Loss at iteration 990 : 0.003889134619385004
Loss at iteration 1000 : 0.008299024775624275
Loss at iteration 1010 : 0.010014745406806469
Loss at iteration 1020 : 0.016075313091278076
Loss at iteration 1030 : 0.007470998913049698
Loss at iteration 1040 : 0.0088456179946661
Loss at iteration 1050 : 0.007008733227849007
Loss at iteration 1060 : 0.011135646142065525
Loss at iteration 1070 : 0.005143593996763229
Loss at iteration 1080 : 0.013327520340681076
Loss at iteration 1090 : 0.006313402205705643
Loss at iteration 1100 : 0.01491083949804306
Loss at iteration 1110 : 0.006301634944975376
Loss at iteration 1120 : 0.010094331577420235
Loss at iteration 1130 : 0.00768797192722559
Loss at iteration 1140 : 0.004322075750678778
Loss at iteration 1150 : 0.005937942303717136
Loss at iteration 1160 : 0.00764492666348815
Loss at iteration 1170 : 0.005646322388201952
Loss at iteration 1180 : 0.004287663847208023
Loss at iteration 1190 : 0.008633008226752281
Loss at iteration 1200 : 0.0027828312013298273
Loss at iteration 1210 : 0.007747978903353214
Loss at iteration 1220 : 0.007438811007887125
Loss at iteration 1230 : 0.0033529908396303654
Loss at iteration 1240 : 0.009223023429512978
Loss at iteration 1250 : 0.005055039189755917
Loss at iteration 1260 : 0.006236960180103779
Loss at iteration 1270 : 0.015370005741715431
Loss at iteration 1280 : 0.024549640715122223
Loss at iteration 1290 : 0.007810588926076889
Loss at iteration 1300 : 0.0053673009388148785
Loss at iteration 1310 : 0.009107104502618313
Loss at iteration 1320 : 0.004601757507771254
Loss at iteration 1330 : 0.012026557698845863
Loss at iteration 1340 : 0.008472653105854988
Loss at iteration 1350 : 0.005820779129862785
Loss at iteration 1360 : 0.01953916624188423
Loss at iteration 1370 : 0.011815998703241348
Loss at iteration 1380 : 0.008337796665728092
Loss at iteration 1390 : 0.014351218938827515
Loss at iteration 1400 : 0.008231469430029392
Loss at iteration 1410 : 0.006417726632207632
Loss at iteration 1420 : 0.006597448140382767
Loss at iteration 1430 : 0.01788005791604519
Loss at iteration 1440 : 0.007542148698121309
Loss at iteration 1450 : 0.0044165002182126045
Loss at iteration 1460 : 0.004552117083221674
Loss at iteration 1470 : 0.00464745843783021
Loss at iteration 1480 : 0.012085523456335068
Loss at iteration 1490 : 0.005268049892038107
Loss at iteration 1500 : 0.014290080405771732
Loss at iteration 1510 : 0.0020131408236920834
Loss at iteration 1520 : 0.036558203399181366
Loss at iteration 1530 : 0.0047688535414636135
Loss at iteration 1540 : 0.011849519796669483
Loss at iteration 1550 : 0.004192446358501911
Loss at iteration 1560 : 0.010380822233855724
Loss at iteration 1570 : 0.006061067339032888
Loss at iteration 1580 : 0.008628366515040398
Loss at iteration 1590 : 0.0037746448069810867
Loss at iteration 1600 : 0.009842561557888985
Loss at iteration 1610 : 0.005725272931158543
Loss at iteration 1620 : 0.011925453320145607
Loss at iteration 1630 : 0.006537470035254955
Loss at iteration 1640 : 0.011902564205229282
Loss at iteration 1650 : 0.012120567262172699
Loss at iteration 1660 : 0.006972770672291517
Loss at iteration 1670 : 0.006049709394574165
Loss at iteration 1680 : 0.010416043922305107
Loss at iteration 1690 : 0.008081315085291862
Loss at iteration 1700 : 0.011104651726782322
Loss at iteration 1710 : 0.013012402690947056
Loss at iteration 1720 : 0.015824707224965096
Loss at iteration 1730 : 0.00911503005772829
Loss at iteration 1740 : 0.010353204794228077
Loss at iteration 1750 : 0.006401550956070423
Loss at iteration 1760 : 0.00917100626975298
Loss at iteration 1770 : 0.013281101360917091
Loss at iteration 1780 : 0.006586337462067604
Loss at iteration 1790 : 0.008638493716716766
Loss at iteration 1800 : 0.014624452218413353
Loss at iteration 1810 : 0.010071183554828167
Loss at iteration 1820 : 0.009031979367136955
Loss at iteration 1830 : 0.008019398897886276
Loss at iteration 1840 : 0.005633631255477667
Loss at iteration 1850 : 0.015027975663542747
Loss at iteration 1860 : 0.010908128693699837
Loss at iteration 1870 : 0.0059447744861245155
Loss at iteration 1880 : 0.011198719963431358
Loss at iteration 1890 : 0.007063291035592556
Loss at iteration 1900 : 0.004553437232971191
Loss at iteration 1910 : 0.0037951990962028503
Loss at iteration 1920 : 0.0061539821326732635
Loss at iteration 1930 : 0.012240004725754261
Loss at iteration 1940 : 0.0059631457552313805
Loss at iteration 1950 : 0.00787787139415741
Loss at iteration 1960 : 0.005465952213853598
Loss at iteration 1970 : 0.01120902132242918
Loss at iteration 1980 : 0.009636277332901955
Loss at iteration 1990 : 0.00790401641279459
Loss at iteration 2000 : 0.0054449583403766155
Loss at iteration 2010 : 0.018896138295531273
Loss at iteration 2020 : 0.02127402275800705
Loss at iteration 2030 : 0.007119959685951471
Loss at iteration 2040 : 0.004601768683642149
Loss at iteration 2050 : 0.009183520451188087
Loss at iteration 2060 : 0.0034257564693689346
Loss at iteration 2070 : 0.003715869039297104
Loss at iteration 2080 : 0.0036692738067358732
Loss at iteration 2090 : 0.008178009651601315
Loss at iteration 2100 : 0.007995450869202614
Loss at iteration 2110 : 0.005178871098905802
Loss at iteration 2120 : 0.016088934615254402
Loss at iteration 2130 : 0.007768047042191029
Loss at iteration 2140 : 0.0051506138406693935
Loss at iteration 2150 : 0.01227728370577097
Loss at iteration 2160 : 0.005555415991693735
Loss at iteration 2170 : 0.005461225751787424
Loss at iteration 2180 : 0.0077219270169734955
Loss at iteration 2190 : 0.01709861122071743
Loss at iteration 2200 : 0.005271114408969879
Loss at iteration 2210 : 0.012603206560015678
Loss at iteration 2220 : 0.0065075065940618515
Loss at iteration 2230 : 0.019302839413285255
Loss at iteration 2240 : 0.033335454761981964
Loss at iteration 2250 : 0.009337574243545532
Loss at iteration 2260 : 0.009145871736109257
Loss at iteration 2270 : 0.01944786310195923
Loss at iteration 2280 : 0.005213486030697823
Loss at iteration 2290 : 0.0058364360593259335
Loss at iteration 2300 : 0.00723864883184433
Loss at iteration 2310 : 0.007953505963087082
Loss at iteration 2320 : 0.01079699769616127
Loss at iteration 2330 : 0.01775209978222847
Loss at iteration 2340 : 0.007584733888506889
Loss at iteration 2350 : 0.01291850209236145
Loss at iteration 2360 : 0.0063661509193480015
Loss at iteration 2370 : 0.012940260581672192
Loss at iteration 2380 : 0.00859252829104662
Loss at iteration 2390 : 0.008211989887058735
Loss at iteration 2400 : 0.00878445990383625
Loss at iteration 2410 : 0.007207015994936228
Loss at iteration 2420 : 0.01443859189748764
The SSIM Value is: 0.8449875553448994
The PSNR Value is: 22.41147060394287
the epoch is: 105
Loss at iteration 10 : 0.009073109365999699
Loss at iteration 20 : 0.022871633991599083
Loss at iteration 30 : 0.004481760784983635
Loss at iteration 40 : 0.0069140223786234856
Loss at iteration 50 : 0.005807316862046719
Loss at iteration 60 : 0.010381481610238552
Loss at iteration 70 : 0.010681383311748505
Loss at iteration 80 : 0.014426156878471375
Loss at iteration 90 : 0.009227569214999676
Loss at iteration 100 : 0.00902550294995308
Loss at iteration 110 : 0.006814478896558285
Loss at iteration 120 : 0.008559945039451122
Loss at iteration 130 : 0.012822972610592842
Loss at iteration 140 : 0.001823536353185773
Loss at iteration 150 : 0.005592995323240757
Loss at iteration 160 : 0.004531458020210266
Loss at iteration 170 : 0.017018379643559456
Loss at iteration 180 : 0.00861357431858778
Loss at iteration 190 : 0.01452476717531681
Loss at iteration 200 : 0.008072279393672943
Loss at iteration 210 : 0.011045152321457863
Loss at iteration 220 : 0.006068508140742779
Loss at iteration 230 : 0.010467933490872383
Loss at iteration 240 : 0.008205017074942589
Loss at iteration 250 : 0.008694332093000412
Loss at iteration 260 : 0.013395130634307861
Loss at iteration 270 : 0.007735467050224543
Loss at iteration 280 : 0.004804485477507114
Loss at iteration 290 : 0.010457166470587254
Loss at iteration 300 : 0.013865116983652115
Loss at iteration 310 : 0.01343045849353075
Loss at iteration 320 : 0.006925354246050119
Loss at iteration 330 : 0.011153778992593288
Loss at iteration 340 : 0.01010114885866642
Loss at iteration 350 : 0.005826233420521021
Loss at iteration 360 : 0.00969416368752718
Loss at iteration 370 : 0.01935858279466629
Loss at iteration 380 : 0.0034189349971711636
Loss at iteration 390 : 0.005863905884325504
Loss at iteration 400 : 0.007317307870835066
Loss at iteration 410 : 0.008635909296572208
Loss at iteration 420 : 0.004165057558566332
Loss at iteration 430 : 0.011527104303240776
Loss at iteration 440 : 0.007778211496770382
Loss at iteration 450 : 0.0031875630374997854
Loss at iteration 460 : 0.018578168004751205
Loss at iteration 470 : 0.006116004660725594
Loss at iteration 480 : 0.016291605308651924
Loss at iteration 490 : 0.010735109448432922
Loss at iteration 500 : 0.005969703663140535
Loss at iteration 510 : 0.02323358692228794
Loss at iteration 520 : 0.004981575533747673
Loss at iteration 530 : 0.00696724746376276
Loss at iteration 540 : 0.0021769257728010416
Loss at iteration 550 : 0.020443454384803772
Loss at iteration 560 : 0.013293417170643806
Loss at iteration 570 : 0.012551546096801758
Loss at iteration 580 : 0.005669447593390942
Loss at iteration 590 : 0.007439299486577511
Loss at iteration 600 : 0.006280004978179932
Loss at iteration 610 : 0.014880959875881672
Loss at iteration 620 : 0.006066286936402321
Loss at iteration 630 : 0.007767518050968647
Loss at iteration 640 : 0.013148875907063484
Loss at iteration 650 : 0.012338036671280861
Loss at iteration 660 : 0.009674363769590855
Loss at iteration 670 : 0.005522682797163725
Loss at iteration 680 : 0.008373543620109558
Loss at iteration 690 : 0.005706002004444599
Loss at iteration 700 : 0.007944811135530472
Loss at iteration 710 : 0.00956269446760416
Loss at iteration 720 : 0.0069852182641625404
Loss at iteration 730 : 0.011274084448814392
Loss at iteration 740 : 0.007657153531908989
Loss at iteration 750 : 0.0065848310478031635
Loss at iteration 760 : 0.0063201370649039745
Loss at iteration 770 : 0.0040329378098249435
Loss at iteration 780 : 0.0047170426696538925
Loss at iteration 790 : 0.009236887097358704
Loss at iteration 800 : 0.008625157177448273
Loss at iteration 810 : 0.007609423249959946
Loss at iteration 820 : 0.0030313124880194664
Loss at iteration 830 : 0.008162623271346092
Loss at iteration 840 : 0.013822946697473526
Loss at iteration 850 : 0.01105363480746746
Loss at iteration 860 : 0.007362055592238903
Loss at iteration 870 : 0.006154233124107122
Loss at iteration 880 : 0.010217002592980862
Loss at iteration 890 : 0.006145751569420099
Loss at iteration 900 : 0.008078189566731453
Loss at iteration 910 : 0.011115056462585926
Loss at iteration 920 : 0.0042661214247345924
Loss at iteration 930 : 0.02472038008272648
Loss at iteration 940 : 0.008206143043935299
Loss at iteration 950 : 0.005424147471785545
Loss at iteration 960 : 0.01148020476102829
Loss at iteration 970 : 0.011301827616989613
Loss at iteration 980 : 0.017515581101179123
Loss at iteration 990 : 0.00876230001449585
Loss at iteration 1000 : 0.012514062225818634
Loss at iteration 1010 : 0.00917847454547882
Loss at iteration 1020 : 0.005743971560150385
Loss at iteration 1030 : 0.015158789232373238
Loss at iteration 1040 : 0.009635421447455883
Loss at iteration 1050 : 0.014736293815076351
Loss at iteration 1060 : 0.012896787375211716
Loss at iteration 1070 : 0.009225043468177319
Loss at iteration 1080 : 0.025135556235909462
Loss at iteration 1090 : 0.005554437171667814
Loss at iteration 1100 : 0.010045184753835201
Loss at iteration 1110 : 0.005384137388318777
Loss at iteration 1120 : 0.012830184772610664
Loss at iteration 1130 : 0.018915055319666862
Loss at iteration 1140 : 0.005628904327750206
Loss at iteration 1150 : 0.005626961123198271
Loss at iteration 1160 : 0.016869526356458664
Loss at iteration 1170 : 0.006055310368537903
Loss at iteration 1180 : 0.007930501364171505
Loss at iteration 1190 : 0.007197496015578508
Loss at iteration 1200 : 0.011141832917928696
Loss at iteration 1210 : 0.0053209722973406315
Loss at iteration 1220 : 0.010516316629946232
Loss at iteration 1230 : 0.005790879484266043
Loss at iteration 1240 : 0.008240900933742523
Loss at iteration 1250 : 0.012728875502943993
Loss at iteration 1260 : 0.00971534475684166
Loss at iteration 1270 : 0.010267308913171291
Loss at iteration 1280 : 0.007064055651426315
Loss at iteration 1290 : 0.003813808783888817
Loss at iteration 1300 : 0.004333592019975185
Loss at iteration 1310 : 0.016472090035676956
Loss at iteration 1320 : 0.008953671902418137
Loss at iteration 1330 : 0.006099813152104616
Loss at iteration 1340 : 0.004695120267570019
Loss at iteration 1350 : 0.007160613778978586
Loss at iteration 1360 : 0.008163531310856342
Loss at iteration 1370 : 0.013016868382692337
Loss at iteration 1380 : 0.009115148335695267
Loss at iteration 1390 : 0.010659269988536835
Loss at iteration 1400 : 0.006963291205465794
Loss at iteration 1410 : 0.008104538545012474
Loss at iteration 1420 : 0.011932449415326118
Loss at iteration 1430 : 0.007543056737631559
Loss at iteration 1440 : 0.012942087836563587
Loss at iteration 1450 : 0.008314486593008041
Loss at iteration 1460 : 0.010433916002511978
Loss at iteration 1470 : 0.008208246901631355
Loss at iteration 1480 : 0.0052918968722224236
Loss at iteration 1490 : 0.011882958933711052
Loss at iteration 1500 : 0.005996891297399998
Loss at iteration 1510 : 0.01058840099722147
Loss at iteration 1520 : 0.0038514104671776295
Loss at iteration 1530 : 0.0052703674882650375
Loss at iteration 1540 : 0.006325798574835062
Loss at iteration 1550 : 0.020367328077554703
Loss at iteration 1560 : 0.0033582572359591722
Loss at iteration 1570 : 0.0036897852551192045
Loss at iteration 1580 : 0.008958776481449604
Loss at iteration 1590 : 0.006970156449824572
Loss at iteration 1600 : 0.008173278532922268
Loss at iteration 1610 : 0.005589903332293034
Loss at iteration 1620 : 0.0038323032204061747
Loss at iteration 1630 : 0.005287822801619768
Loss at iteration 1640 : 0.013337630778551102
Loss at iteration 1650 : 0.014536486007273197
Loss at iteration 1660 : 0.010271168313920498
Loss at iteration 1670 : 0.009319213218986988
Loss at iteration 1680 : 0.0032220608554780483
Loss at iteration 1690 : 0.004678216762840748
Loss at iteration 1700 : 0.009486725553870201
Loss at iteration 1710 : 0.009774944745004177
Loss at iteration 1720 : 0.0034935362637043
Loss at iteration 1730 : 0.008170702494680882
Loss at iteration 1740 : 0.0039016955997794867
Loss at iteration 1750 : 0.01832241378724575
Loss at iteration 1760 : 0.006475951988250017
Loss at iteration 1770 : 0.00638676667585969
Loss at iteration 1780 : 0.010396995581686497
Loss at iteration 1790 : 0.009205412119626999
Loss at iteration 1800 : 0.0048403493128716946
Loss at iteration 1810 : 0.012887181714177132
Loss at iteration 1820 : 0.012549749575555325
Loss at iteration 1830 : 0.008837965317070484
Loss at iteration 1840 : 0.015573335811495781
Loss at iteration 1850 : 0.009466917254030704
Loss at iteration 1860 : 0.008414430543780327
Loss at iteration 1870 : 0.004472360480576754
Loss at iteration 1880 : 0.008730735629796982
Loss at iteration 1890 : 0.006707141641527414
Loss at iteration 1900 : 0.012331701815128326
Loss at iteration 1910 : 0.015283741988241673
Loss at iteration 1920 : 0.003929200582206249
Loss at iteration 1930 : 0.01626039855182171
Loss at iteration 1940 : 0.0030239648185670376
Loss at iteration 1950 : 0.016145730391144753
Loss at iteration 1960 : 0.012480766512453556
Loss at iteration 1970 : 0.012212889268994331
Loss at iteration 1980 : 0.01625867560505867
Loss at iteration 1990 : 0.007050343323498964
Loss at iteration 2000 : 0.008220319636166096
Loss at iteration 2010 : 0.011669160798192024
Loss at iteration 2020 : 0.004478096030652523
Loss at iteration 2030 : 0.0033855431247502565
Loss at iteration 2040 : 0.004448046907782555
Loss at iteration 2050 : 0.004393672104924917
Loss at iteration 2060 : 0.007927486672997475
Loss at iteration 2070 : 0.0020604063756763935
Loss at iteration 2080 : 0.0055466522462666035
Loss at iteration 2090 : 0.010563814081251621
Loss at iteration 2100 : 0.013798817992210388
Loss at iteration 2110 : 0.005828662775456905
Loss at iteration 2120 : 0.0033372915349900723
Loss at iteration 2130 : 0.02738390862941742
Loss at iteration 2140 : 0.012442653067409992
Loss at iteration 2150 : 0.004350192379206419
Loss at iteration 2160 : 0.011966289952397346
Loss at iteration 2170 : 0.015119566582143307
Loss at iteration 2180 : 0.0063229030929505825
Loss at iteration 2190 : 0.006694029550999403
Loss at iteration 2200 : 0.013849564827978611
Loss at iteration 2210 : 0.011555405333638191
Loss at iteration 2220 : 0.005934535525739193
Loss at iteration 2230 : 0.015663476660847664
Loss at iteration 2240 : 0.012014207430183887
Loss at iteration 2250 : 0.0023336848244071007
Loss at iteration 2260 : 0.006710035260766745
Loss at iteration 2270 : 0.006538180634379387
Loss at iteration 2280 : 0.004501288756728172
Loss at iteration 2290 : 0.01304370816797018
Loss at iteration 2300 : 0.0030181780457496643
Loss at iteration 2310 : 0.008315803483128548
Loss at iteration 2320 : 0.004285265691578388
Loss at iteration 2330 : 0.007768580690026283
Loss at iteration 2340 : 0.0037911818362772465
Loss at iteration 2350 : 0.009066885337233543
Loss at iteration 2360 : 0.0066172340884804726
Loss at iteration 2370 : 0.008793584071099758
Loss at iteration 2380 : 0.004532367456704378
Loss at iteration 2390 : 0.005260508973151445
Loss at iteration 2400 : 0.007984887808561325
Loss at iteration 2410 : 0.006658382713794708
Loss at iteration 2420 : 0.0075345225632190704
The SSIM Value is: 0.8518654465675354
The PSNR Value is: 22.544782892862955
the epoch is: 106
Loss at iteration 10 : 0.009535137563943863
Loss at iteration 20 : 0.015110512264072895
Loss at iteration 30 : 0.010820982977747917
Loss at iteration 40 : 0.007865787483751774
Loss at iteration 50 : 0.013187479227781296
Loss at iteration 60 : 0.004146034829318523
Loss at iteration 70 : 0.008211763575673103
Loss at iteration 80 : 0.010972164571285248
Loss at iteration 90 : 0.00802243035286665
Loss at iteration 100 : 0.007696575950831175
Loss at iteration 110 : 0.004850917961448431
Loss at iteration 120 : 0.011307241395115852
Loss at iteration 130 : 0.012186439707875252
Loss at iteration 140 : 0.012184824794530869
Loss at iteration 150 : 0.010882968083024025
Loss at iteration 160 : 0.005133494269102812
Loss at iteration 170 : 0.006153420079499483
Loss at iteration 180 : 0.002868320792913437
Loss at iteration 190 : 0.008502867072820663
Loss at iteration 200 : 0.010893695056438446
Loss at iteration 210 : 0.013422608375549316
Loss at iteration 220 : 0.009006021544337273
Loss at iteration 230 : 0.004569028504192829
Loss at iteration 240 : 0.008388468995690346
Loss at iteration 250 : 0.0030846726149320602
Loss at iteration 260 : 0.007121989969164133
Loss at iteration 270 : 0.0072242445312440395
Loss at iteration 280 : 0.006192144472151995
Loss at iteration 290 : 0.009084435179829597
Loss at iteration 300 : 0.0062512969598174095
Loss at iteration 310 : 0.0051215654239058495
Loss at iteration 320 : 0.0063373553566634655
Loss at iteration 330 : 0.007299847900867462
Loss at iteration 340 : 0.007834034040570259
Loss at iteration 350 : 0.01573329046368599
Loss at iteration 360 : 0.010780615732073784
Loss at iteration 370 : 0.013242915272712708
Loss at iteration 380 : 0.013104453682899475
Loss at iteration 390 : 0.0067166234366595745
Loss at iteration 400 : 0.014009824022650719
Loss at iteration 410 : 0.0032054209150373936
Loss at iteration 420 : 0.0031708606984466314
Loss at iteration 430 : 0.010060520842671394
Loss at iteration 440 : 0.0039258552715182304
Loss at iteration 450 : 0.0019351481460034847
Loss at iteration 460 : 0.005528845824301243
Loss at iteration 470 : 0.011064974591135979
Loss at iteration 480 : 0.007795410230755806
Loss at iteration 490 : 0.002680043922737241
Loss at iteration 500 : 0.011978600174188614
Loss at iteration 510 : 0.0041625178419053555
Loss at iteration 520 : 0.010724874213337898
Loss at iteration 530 : 0.008175527676939964
Loss at iteration 540 : 0.013515154831111431
Loss at iteration 550 : 0.006105309817939997
Loss at iteration 560 : 0.012985682114958763
Loss at iteration 570 : 0.007492654025554657
Loss at iteration 580 : 0.01007944904267788
Loss at iteration 590 : 0.016882041469216347
Loss at iteration 600 : 0.007591132540255785
Loss at iteration 610 : 0.013439690694212914
Loss at iteration 620 : 0.016088789328932762
Loss at iteration 630 : 0.009101329371333122
Loss at iteration 640 : 0.006863897200673819
Loss at iteration 650 : 0.004506295546889305
Loss at iteration 660 : 0.006961129605770111
Loss at iteration 670 : 0.008965701796114445
Loss at iteration 680 : 0.005963921081274748
Loss at iteration 690 : 0.014785354025661945
Loss at iteration 700 : 0.025942819193005562
Loss at iteration 710 : 0.015797985717654228
Loss at iteration 720 : 0.016164900735020638
Loss at iteration 730 : 0.0049479068256914616
Loss at iteration 740 : 0.013750316575169563
Loss at iteration 750 : 0.0063337404280900955
Loss at iteration 760 : 0.007352757267653942
Loss at iteration 770 : 0.011107262223958969
Loss at iteration 780 : 0.006664476357400417
Loss at iteration 790 : 0.00875550415366888
Loss at iteration 800 : 0.007350106257945299
Loss at iteration 810 : 0.006357737351208925
Loss at iteration 820 : 0.006549616809934378
Loss at iteration 830 : 0.014213177375495434
Loss at iteration 840 : 0.0059274714440107346
Loss at iteration 850 : 0.009001507423818111
Loss at iteration 860 : 0.0046759434044361115
Loss at iteration 870 : 0.006578315980732441
Loss at iteration 880 : 0.014594944193959236
Loss at iteration 890 : 0.008735650219023228
Loss at iteration 900 : 0.005729416850954294
Loss at iteration 910 : 0.006501481402665377
Loss at iteration 920 : 0.00419731205329299
Loss at iteration 930 : 0.005874768365174532
Loss at iteration 940 : 0.003773851552978158
Loss at iteration 950 : 0.01061251387000084
Loss at iteration 960 : 0.0175724346190691
Loss at iteration 970 : 0.010631229728460312
Loss at iteration 980 : 0.007454900071024895
Loss at iteration 990 : 0.008490348234772682
Loss at iteration 1000 : 0.011730995960533619
Loss at iteration 1010 : 0.008611563593149185
Loss at iteration 1020 : 0.00868894811719656
Loss at iteration 1030 : 0.019452251493930817
Loss at iteration 1040 : 0.005056786350905895
Loss at iteration 1050 : 0.014534459449350834
Loss at iteration 1060 : 0.005263038910925388
Loss at iteration 1070 : 0.01747608184814453
Loss at iteration 1080 : 0.004918589256703854
Loss at iteration 1090 : 0.004772838670760393
Loss at iteration 1100 : 0.012202662415802479
Loss at iteration 1110 : 0.008970105089247227
Loss at iteration 1120 : 0.011103574186563492
Loss at iteration 1130 : 0.0046488698571920395
Loss at iteration 1140 : 0.010558071546256542
Loss at iteration 1150 : 0.007004036568105221
Loss at iteration 1160 : 0.004927953239530325
Loss at iteration 1170 : 0.01590028963983059
Loss at iteration 1180 : 0.005814702715724707
Loss at iteration 1190 : 0.01261832658201456
Loss at iteration 1200 : 0.022020263597369194
Loss at iteration 1210 : 0.005469298921525478
Loss at iteration 1220 : 0.01131594367325306
Loss at iteration 1230 : 0.00528746796771884
Loss at iteration 1240 : 0.011821596883237362
Loss at iteration 1250 : 0.008048462681472301
Loss at iteration 1260 : 0.009093261323869228
Loss at iteration 1270 : 0.012068144045770168
Loss at iteration 1280 : 0.005739941727370024
Loss at iteration 1290 : 0.01429623644798994
Loss at iteration 1300 : 0.008926227688789368
Loss at iteration 1310 : 0.0038385039661079645
Loss at iteration 1320 : 0.0085349315777421
Loss at iteration 1330 : 0.004002508241683245
Loss at iteration 1340 : 0.013411568477749825
Loss at iteration 1350 : 0.005287963896989822
Loss at iteration 1360 : 0.006496901158243418
Loss at iteration 1370 : 0.01036747545003891
Loss at iteration 1380 : 0.0091286925598979
Loss at iteration 1390 : 0.007319853641092777
Loss at iteration 1400 : 0.0071023921482264996
Loss at iteration 1410 : 0.003982541151344776
Loss at iteration 1420 : 0.012651946395635605
Loss at iteration 1430 : 0.040440842509269714
Loss at iteration 1440 : 0.013731622137129307
Loss at iteration 1450 : 0.004530471283942461
Loss at iteration 1460 : 0.013414369896054268
Loss at iteration 1470 : 0.004999603144824505
Loss at iteration 1480 : 0.010472327470779419
Loss at iteration 1490 : 0.0034024128690361977
Loss at iteration 1500 : 0.010298732668161392
Loss at iteration 1510 : 0.010043256916105747
Loss at iteration 1520 : 0.02384285442531109
Loss at iteration 1530 : 0.006219746079295874
Loss at iteration 1540 : 0.01554586086422205
Loss at iteration 1550 : 0.010997474193572998
Loss at iteration 1560 : 0.003018166171386838
Loss at iteration 1570 : 0.011977460235357285
Loss at iteration 1580 : 0.006494850851595402
Loss at iteration 1590 : 0.010334406048059464
Loss at iteration 1600 : 0.00655350461602211
Loss at iteration 1610 : 0.007289565168321133
Loss at iteration 1620 : 0.006165388505905867
Loss at iteration 1630 : 0.007414679974317551
Loss at iteration 1640 : 0.006437290459871292
Loss at iteration 1650 : 0.011260105296969414
Loss at iteration 1660 : 0.00845546554774046
Loss at iteration 1670 : 0.005103457719087601
Loss at iteration 1680 : 0.01232478953897953
Loss at iteration 1690 : 0.009392784908413887
Loss at iteration 1700 : 0.0028778333216905594
Loss at iteration 1710 : 0.010099709033966064
Loss at iteration 1720 : 0.005167630035430193
Loss at iteration 1730 : 0.010879617184400558
Loss at iteration 1740 : 0.0062625352293252945
Loss at iteration 1750 : 0.01293838582932949
Loss at iteration 1760 : 0.005812580697238445
Loss at iteration 1770 : 0.008134810253977776
Loss at iteration 1780 : 0.004642814863473177
Loss at iteration 1790 : 0.008396392688155174
Loss at iteration 1800 : 0.013238303363323212
Loss at iteration 1810 : 0.011412359774112701
Loss at iteration 1820 : 0.010105627588927746
Loss at iteration 1830 : 0.004451597575098276
Loss at iteration 1840 : 0.010542857460677624
Loss at iteration 1850 : 0.008826720528304577
Loss at iteration 1860 : 0.010169404558837414
Loss at iteration 1870 : 0.012923568487167358
Loss at iteration 1880 : 0.0053875502198934555
Loss at iteration 1890 : 0.0049333879724144936
Loss at iteration 1900 : 0.013522496446967125
Loss at iteration 1910 : 0.017585091292858124
Loss at iteration 1920 : 0.012692555785179138
Loss at iteration 1930 : 0.011103636585175991
Loss at iteration 1940 : 0.006060747429728508
Loss at iteration 1950 : 0.005046860780566931
Loss at iteration 1960 : 0.0044777169823646545
Loss at iteration 1970 : 0.009996036998927593
Loss at iteration 1980 : 0.012484260834753513
Loss at iteration 1990 : 0.006021692883223295
Loss at iteration 2000 : 0.0045435503125190735
Loss at iteration 2010 : 0.012852955609560013
Loss at iteration 2020 : 0.0070648486725986
Loss at iteration 2030 : 0.003924448508769274
Loss at iteration 2040 : 0.010872773826122284
Loss at iteration 2050 : 0.005426380783319473
Loss at iteration 2060 : 0.0027748020365834236
Loss at iteration 2070 : 0.004758733324706554
Loss at iteration 2080 : 0.0026530628092586994
Loss at iteration 2090 : 0.0034989025443792343
Loss at iteration 2100 : 0.007434246130287647
Loss at iteration 2110 : 0.005848935805261135
Loss at iteration 2120 : 0.011372330598533154
Loss at iteration 2130 : 0.013825729489326477
Loss at iteration 2140 : 0.008957767859101295
Loss at iteration 2150 : 0.009695050306618214
Loss at iteration 2160 : 0.007492244243621826
Loss at iteration 2170 : 0.014299900270998478
Loss at iteration 2180 : 0.003936218097805977
Loss at iteration 2190 : 0.009431695565581322
Loss at iteration 2200 : 0.004029175732284784
Loss at iteration 2210 : 0.009959086775779724
Loss at iteration 2220 : 0.009141911752521992
Loss at iteration 2230 : 0.007310056127607822
Loss at iteration 2240 : 0.0027217513415962458
Loss at iteration 2250 : 0.004819951485842466
Loss at iteration 2260 : 0.005585619248449802
Loss at iteration 2270 : 0.005246098153293133
Loss at iteration 2280 : 0.01000531017780304
Loss at iteration 2290 : 0.007564234081655741
Loss at iteration 2300 : 0.009886413812637329
Loss at iteration 2310 : 0.004662467632442713
Loss at iteration 2320 : 0.005183628760278225
Loss at iteration 2330 : 0.008034981787204742
Loss at iteration 2340 : 0.011605393141508102
Loss at iteration 2350 : 0.01234745979309082
Loss at iteration 2360 : 0.004551220219582319
Loss at iteration 2370 : 0.01216053031384945
Loss at iteration 2380 : 0.002870733616873622
Loss at iteration 2390 : 0.005805624648928642
Loss at iteration 2400 : 0.007490713614970446
Loss at iteration 2410 : 0.009277435019612312
Loss at iteration 2420 : 0.011221551336348057
The SSIM Value is: 0.8485778292020162
The PSNR Value is: 22.597694206237794
the epoch is: 107
Loss at iteration 10 : 0.005129276774823666
Loss at iteration 20 : 0.00988016463816166
Loss at iteration 30 : 0.0028578825294971466
Loss at iteration 40 : 0.003970036283135414
Loss at iteration 50 : 0.003922285512089729
Loss at iteration 60 : 0.007703636772930622
Loss at iteration 70 : 0.008236663416028023
Loss at iteration 80 : 0.004997117444872856
Loss at iteration 90 : 0.010140115395188332
Loss at iteration 100 : 0.011987672187387943
Loss at iteration 110 : 0.020736418664455414
Loss at iteration 120 : 0.011277086101472378
Loss at iteration 130 : 0.008816651999950409
Loss at iteration 140 : 0.006297336891293526
Loss at iteration 150 : 0.010166337713599205
Loss at iteration 160 : 0.011068560183048248
Loss at iteration 170 : 0.010892265476286411
Loss at iteration 180 : 0.010199472308158875
Loss at iteration 190 : 0.005041440017521381
Loss at iteration 200 : 0.009977168403565884
Loss at iteration 210 : 0.008044399321079254
Loss at iteration 220 : 0.009510581381618977
Loss at iteration 230 : 0.006355498917400837
Loss at iteration 240 : 0.017915379256010056
Loss at iteration 250 : 0.006558201741427183
Loss at iteration 260 : 0.003693812293931842
Loss at iteration 270 : 0.005973596591502428
Loss at iteration 280 : 0.005195559002459049
Loss at iteration 290 : 0.003944157622754574
Loss at iteration 300 : 0.008352866396307945
Loss at iteration 310 : 0.010029797442257404
Loss at iteration 320 : 0.01130712777376175
Loss at iteration 330 : 0.011075143702328205
Loss at iteration 340 : 0.006133010145276785
Loss at iteration 350 : 0.007961029186844826
Loss at iteration 360 : 0.00424880301579833
Loss at iteration 370 : 0.0036944029852747917
Loss at iteration 380 : 0.008987207897007465
Loss at iteration 390 : 0.010514667257666588
Loss at iteration 400 : 0.00544129079207778
Loss at iteration 410 : 0.00622640922665596
Loss at iteration 420 : 0.008943811990320683
Loss at iteration 430 : 0.010155459865927696
Loss at iteration 440 : 0.0061512114480137825
Loss at iteration 450 : 0.007361664902418852
Loss at iteration 460 : 0.01869310438632965
Loss at iteration 470 : 0.009976151399314404
Loss at iteration 480 : 0.003606574609875679
Loss at iteration 490 : 0.016837870702147484
Loss at iteration 500 : 0.00916496105492115
Loss at iteration 510 : 0.011264115571975708
Loss at iteration 520 : 0.009600568562746048
Loss at iteration 530 : 0.014695990830659866
Loss at iteration 540 : 0.00925446581095457
Loss at iteration 550 : 0.014670834876596928
Loss at iteration 560 : 0.005254101939499378
Loss at iteration 570 : 0.029503803700208664
Loss at iteration 580 : 0.009418966248631477
Loss at iteration 590 : 0.0165417417883873
Loss at iteration 600 : 0.008008291944861412
Loss at iteration 610 : 0.0076242247596383095
Loss at iteration 620 : 0.018183445557951927
Loss at iteration 630 : 0.011463863775134087
Loss at iteration 640 : 0.007344692945480347
Loss at iteration 650 : 0.004865260794758797
Loss at iteration 660 : 0.01033379789441824
Loss at iteration 670 : 0.010594935156404972
Loss at iteration 680 : 0.004481056705117226
Loss at iteration 690 : 0.015548535622656345
Loss at iteration 700 : 0.012332741171121597
Loss at iteration 710 : 0.003820983227342367
Loss at iteration 720 : 0.00843636505305767
Loss at iteration 730 : 0.006397613324224949
Loss at iteration 740 : 0.01136910729110241
Loss at iteration 750 : 0.016585569828748703
Loss at iteration 760 : 0.008696384727954865
Loss at iteration 770 : 0.0018548303050920367
Loss at iteration 780 : 0.017085710540413857
Loss at iteration 790 : 0.011472197249531746
Loss at iteration 800 : 0.013315082527697086
Loss at iteration 810 : 0.012576493434607983
Loss at iteration 820 : 0.008242052048444748
Loss at iteration 830 : 0.012173941358923912
Loss at iteration 840 : 0.006891721859574318
Loss at iteration 850 : 0.014981822110712528
Loss at iteration 860 : 0.008111278526484966
Loss at iteration 870 : 0.0024592699483036995
Loss at iteration 880 : 0.004776662681251764
Loss at iteration 890 : 0.004262601025402546
Loss at iteration 900 : 0.006343956105411053
Loss at iteration 910 : 0.010311637073755264
Loss at iteration 920 : 0.010678203776478767
Loss at iteration 930 : 0.004131056368350983
Loss at iteration 940 : 0.004211311228573322
Loss at iteration 950 : 0.004148320760577917
Loss at iteration 960 : 0.01099108625203371
Loss at iteration 970 : 0.009827399626374245
Loss at iteration 980 : 0.006412230432033539
Loss at iteration 990 : 0.00845949724316597
Loss at iteration 1000 : 0.01708257384598255
Loss at iteration 1010 : 0.004593563266098499
Loss at iteration 1020 : 0.007726950570940971
Loss at iteration 1030 : 0.00444968743249774
Loss at iteration 1040 : 0.008548155426979065
Loss at iteration 1050 : 0.007129639387130737
Loss at iteration 1060 : 0.02860763482749462
Loss at iteration 1070 : 0.0032917482312768698
Loss at iteration 1080 : 0.012225789949297905
Loss at iteration 1090 : 0.014799108728766441
Loss at iteration 1100 : 0.004607326351106167
Loss at iteration 1110 : 0.004940859507769346
Loss at iteration 1120 : 0.00881163403391838
Loss at iteration 1130 : 0.005013323854655027
Loss at iteration 1140 : 0.003926351200789213
Loss at iteration 1150 : 0.008635111153125763
Loss at iteration 1160 : 0.004521326161921024
Loss at iteration 1170 : 0.008834214881062508
Loss at iteration 1180 : 0.005554398521780968
Loss at iteration 1190 : 0.011535831727087498
Loss at iteration 1200 : 0.006171721965074539
Loss at iteration 1210 : 0.006781451404094696
Loss at iteration 1220 : 0.007047760300338268
Loss at iteration 1230 : 0.005816576071083546
Loss at iteration 1240 : 0.006514932028949261
Loss at iteration 1250 : 0.006215477362275124
Loss at iteration 1260 : 0.004843295086175203
Loss at iteration 1270 : 0.010210352949798107
Loss at iteration 1280 : 0.0249127596616745
Loss at iteration 1290 : 0.013467575423419476
Loss at iteration 1300 : 0.007044957485049963
Loss at iteration 1310 : 0.006801818031817675
Loss at iteration 1320 : 0.010336237959563732
Loss at iteration 1330 : 0.02347552962601185
Loss at iteration 1340 : 0.010453404858708382
Loss at iteration 1350 : 0.007787033449858427
Loss at iteration 1360 : 0.014078989624977112
Loss at iteration 1370 : 0.0049158441834151745
Loss at iteration 1380 : 0.008172279223799706
Loss at iteration 1390 : 0.011463969014585018
Loss at iteration 1400 : 0.014948705211281776
Loss at iteration 1410 : 0.0060773566365242004
Loss at iteration 1420 : 0.0034637851640582085
Loss at iteration 1430 : 0.008312014862895012
Loss at iteration 1440 : 0.009215322323143482
Loss at iteration 1450 : 0.0016822422621771693
Loss at iteration 1460 : 0.011106513440608978
Loss at iteration 1470 : 0.0029579130932688713
Loss at iteration 1480 : 0.0094924196600914
Loss at iteration 1490 : 0.008761467412114143
Loss at iteration 1500 : 0.013581524603068829
Loss at iteration 1510 : 0.008486537262797356
Loss at iteration 1520 : 0.00400290172547102
Loss at iteration 1530 : 0.00946788303554058
Loss at iteration 1540 : 0.003789481706917286
Loss at iteration 1550 : 0.01318326685577631
Loss at iteration 1560 : 0.008318772539496422
Loss at iteration 1570 : 0.007203743793070316
Loss at iteration 1580 : 0.007124557625502348
Loss at iteration 1590 : 0.011134968139231205
Loss at iteration 1600 : 0.010232791304588318
Loss at iteration 1610 : 0.013084707781672478
Loss at iteration 1620 : 0.004313175566494465
Loss at iteration 1630 : 0.010757531970739365
Loss at iteration 1640 : 0.007518564350903034
Loss at iteration 1650 : 0.005748070310801268
Loss at iteration 1660 : 0.00996427796781063
Loss at iteration 1670 : 0.005162342451512814
Loss at iteration 1680 : 0.008333735167980194
Loss at iteration 1690 : 0.011446883901953697
Loss at iteration 1700 : 0.011287371627986431
Loss at iteration 1710 : 0.0030938333366066217
Loss at iteration 1720 : 0.020592231303453445
Loss at iteration 1730 : 0.0035827718675136566
Loss at iteration 1740 : 0.005585602950304747
Loss at iteration 1750 : 0.004858753643929958
Loss at iteration 1760 : 0.017500314861536026
Loss at iteration 1770 : 0.005044098477810621
Loss at iteration 1780 : 0.013620859012007713
Loss at iteration 1790 : 0.00580420158803463
Loss at iteration 1800 : 0.006678393576294184
Loss at iteration 1810 : 0.007211856544017792
Loss at iteration 1820 : 0.010507467202842236
Loss at iteration 1830 : 0.004570652265101671
Loss at iteration 1840 : 0.004662943072617054
Loss at iteration 1850 : 0.009991216473281384
Loss at iteration 1860 : 0.013648848049342632
Loss at iteration 1870 : 0.011641483753919601
Loss at iteration 1880 : 0.0072156768292188644
Loss at iteration 1890 : 0.021636199206113815
Loss at iteration 1900 : 0.010440977290272713
Loss at iteration 1910 : 0.004538359120488167
Loss at iteration 1920 : 0.010387339629232883
Loss at iteration 1930 : 0.006286007352173328
Loss at iteration 1940 : 0.01584116369485855
Loss at iteration 1950 : 0.007509367540478706
Loss at iteration 1960 : 0.005231568589806557
Loss at iteration 1970 : 0.008633339777588844
Loss at iteration 1980 : 0.007109393831342459
Loss at iteration 1990 : 0.011646999046206474
Loss at iteration 2000 : 0.011766145005822182
Loss at iteration 2010 : 0.005935850087553263
Loss at iteration 2020 : 0.015370579436421394
Loss at iteration 2030 : 0.004621222615242004
Loss at iteration 2040 : 0.009138970635831356
Loss at iteration 2050 : 0.004852405283600092
Loss at iteration 2060 : 0.008707931265234947
Loss at iteration 2070 : 0.007343033794313669
Loss at iteration 2080 : 0.0060799927450716496
Loss at iteration 2090 : 0.009927812963724136
Loss at iteration 2100 : 0.007990626618266106
Loss at iteration 2110 : 0.007053902838379145
Loss at iteration 2120 : 0.011842082254588604
Loss at iteration 2130 : 0.0069852955639362335
Loss at iteration 2140 : 0.016451213508844376
Loss at iteration 2150 : 0.010336760431528091
Loss at iteration 2160 : 0.007178209722042084
Loss at iteration 2170 : 0.004855146631598473
Loss at iteration 2180 : 0.00927259773015976
Loss at iteration 2190 : 0.0087626613676548
Loss at iteration 2200 : 0.014550803229212761
Loss at iteration 2210 : 0.008416739292442799
Loss at iteration 2220 : 0.010687636211514473
Loss at iteration 2230 : 0.004912152886390686
Loss at iteration 2240 : 0.005998301785439253
Loss at iteration 2250 : 0.00445171445608139
Loss at iteration 2260 : 0.01677756756544113
Loss at iteration 2270 : 0.008570762351155281
Loss at iteration 2280 : 0.007932716980576515
Loss at iteration 2290 : 0.0024052183143794537
Loss at iteration 2300 : 0.010202172212302685
Loss at iteration 2310 : 0.005237572826445103
Loss at iteration 2320 : 0.0059264665469527245
Loss at iteration 2330 : 0.014092644676566124
Loss at iteration 2340 : 0.00857679545879364
Loss at iteration 2350 : 0.02225515991449356
Loss at iteration 2360 : 0.004849523771554232
Loss at iteration 2370 : 0.0051918611861765385
Loss at iteration 2380 : 0.011863397434353828
Loss at iteration 2390 : 0.015203854069113731
Loss at iteration 2400 : 0.007044918369501829
Loss at iteration 2410 : 0.006150614935904741
Loss at iteration 2420 : 0.006354855373501778
The SSIM Value is: 0.8433761596679688
The PSNR Value is: 21.651321919759116
the epoch is: 108
Loss at iteration 10 : 0.01627497933804989
Loss at iteration 20 : 0.0068108015693724155
Loss at iteration 30 : 0.004431214649230242
Loss at iteration 40 : 0.006150429602712393
Loss at iteration 50 : 0.008621405810117722
Loss at iteration 60 : 0.010091720148921013
Loss at iteration 70 : 0.00821884348988533
Loss at iteration 80 : 0.009536407887935638
Loss at iteration 90 : 0.0052427370101213455
Loss at iteration 100 : 0.012624264694750309
Loss at iteration 110 : 0.014664760790765285
Loss at iteration 120 : 0.00953758880496025
Loss at iteration 130 : 0.007796864490956068
Loss at iteration 140 : 0.01375122182071209
Loss at iteration 150 : 0.00916956178843975
Loss at iteration 160 : 0.015321440994739532
Loss at iteration 170 : 0.008173592388629913
Loss at iteration 180 : 0.012729266658425331
Loss at iteration 190 : 0.008182710036635399
Loss at iteration 200 : 0.007800648454576731
Loss at iteration 210 : 0.00962231494486332
Loss at iteration 220 : 0.00547702657058835
Loss at iteration 230 : 0.007475588005036116
Loss at iteration 240 : 0.006102903746068478
Loss at iteration 250 : 0.015106281265616417
Loss at iteration 260 : 0.010735107585787773
Loss at iteration 270 : 0.00920432060956955
Loss at iteration 280 : 0.009123900905251503
Loss at iteration 290 : 0.005733768921345472
Loss at iteration 300 : 0.006406222935765982
Loss at iteration 310 : 0.00889596063643694
Loss at iteration 320 : 0.004738530144095421
Loss at iteration 330 : 0.007736970204859972
Loss at iteration 340 : 0.012943685054779053
Loss at iteration 350 : 0.014482703991234303
Loss at iteration 360 : 0.011663002893328667
Loss at iteration 370 : 0.010470776818692684
Loss at iteration 380 : 0.007081117946654558
Loss at iteration 390 : 0.007240063976496458
Loss at iteration 400 : 0.003288249485194683
Loss at iteration 410 : 0.005438700318336487
Loss at iteration 420 : 0.012805522419512272
Loss at iteration 430 : 0.005607119761407375
Loss at iteration 440 : 0.009480539709329605
Loss at iteration 450 : 0.005835945252329111
Loss at iteration 460 : 0.008442511782050133
Loss at iteration 470 : 0.007335756439715624
Loss at iteration 480 : 0.01234421506524086
Loss at iteration 490 : 0.006588672287762165
Loss at iteration 500 : 0.005213376600295305
Loss at iteration 510 : 0.0058649806305766106
Loss at iteration 520 : 0.008221713826060295
Loss at iteration 530 : 0.007019620388746262
Loss at iteration 540 : 0.007637089118361473
Loss at iteration 550 : 0.0077355545945465565
Loss at iteration 560 : 0.014069144614040852
Loss at iteration 570 : 0.009455908089876175
Loss at iteration 580 : 0.004997485317289829
Loss at iteration 590 : 0.00522340415045619
Loss at iteration 600 : 0.005501902662217617
Loss at iteration 610 : 0.0050119319930672646
Loss at iteration 620 : 0.007567410822957754
Loss at iteration 630 : 0.00960546638816595
Loss at iteration 640 : 0.006318187341094017
Loss at iteration 650 : 0.017827032133936882
Loss at iteration 660 : 0.007380051072686911
Loss at iteration 670 : 0.014398995786905289
Loss at iteration 680 : 0.005785890389233828
Loss at iteration 690 : 0.006561286747455597
Loss at iteration 700 : 0.026558447629213333
Loss at iteration 710 : 0.0066917589865624905
Loss at iteration 720 : 0.010531935840845108
Loss at iteration 730 : 0.011931559070944786
Loss at iteration 740 : 0.009849822148680687
Loss at iteration 750 : 0.014320632442831993
Loss at iteration 760 : 0.004520281217992306
Loss at iteration 770 : 0.007909261621534824
Loss at iteration 780 : 0.006184656172990799
Loss at iteration 790 : 0.00415736623108387
Loss at iteration 800 : 0.009530778042972088
Loss at iteration 810 : 0.010260619223117828
Loss at iteration 820 : 0.003967723809182644
Loss at iteration 830 : 0.003487589070573449
Loss at iteration 840 : 0.007069780956953764
Loss at iteration 850 : 0.006261423230171204
Loss at iteration 860 : 0.0015579266473650932
Loss at iteration 870 : 0.012641292065382004
Loss at iteration 880 : 0.004056654870510101
Loss at iteration 890 : 0.007129466161131859
Loss at iteration 900 : 0.019317379221320152
Loss at iteration 910 : 0.012991615571081638
Loss at iteration 920 : 0.011463645845651627
Loss at iteration 930 : 0.0028202123939990997
Loss at iteration 940 : 0.007516848389059305
Loss at iteration 950 : 0.005421092733740807
Loss at iteration 960 : 0.0076621416956186295
Loss at iteration 970 : 0.004809291567653418
Loss at iteration 980 : 0.012292029336094856
Loss at iteration 990 : 0.01062095444649458
Loss at iteration 1000 : 0.008190769702196121
Loss at iteration 1010 : 0.013920980505645275
Loss at iteration 1020 : 0.010581831447780132
Loss at iteration 1030 : 0.006970571354031563
Loss at iteration 1040 : 0.010057065635919571
Loss at iteration 1050 : 0.010400724597275257
Loss at iteration 1060 : 0.009564634412527084
Loss at iteration 1070 : 0.012185090221464634
Loss at iteration 1080 : 0.008774950169026852
Loss at iteration 1090 : 0.007697518914937973
Loss at iteration 1100 : 0.014681989327073097
Loss at iteration 1110 : 0.004801001399755478
Loss at iteration 1120 : 0.007693864405155182
Loss at iteration 1130 : 0.010027012787759304
Loss at iteration 1140 : 0.008678081445395947
Loss at iteration 1150 : 0.010479258373379707
Loss at iteration 1160 : 0.005598917603492737
Loss at iteration 1170 : 0.009628869593143463
Loss at iteration 1180 : 0.0019820118322968483
Loss at iteration 1190 : 0.004697974771261215
Loss at iteration 1200 : 0.006553804501891136
Loss at iteration 1210 : 0.0067681302316486835
Loss at iteration 1220 : 0.006458069197833538
Loss at iteration 1230 : 0.011189404875040054
Loss at iteration 1240 : 0.012347993440926075
Loss at iteration 1250 : 0.010000352747738361
Loss at iteration 1260 : 0.011627363972365856
Loss at iteration 1270 : 0.019370079040527344
Loss at iteration 1280 : 0.01071842946112156
Loss at iteration 1290 : 0.013761171139776707
Loss at iteration 1300 : 0.0054671308025717735
Loss at iteration 1310 : 0.00997011736035347
Loss at iteration 1320 : 0.010202181525528431
Loss at iteration 1330 : 0.008541066199541092
Loss at iteration 1340 : 0.011819127947092056
Loss at iteration 1350 : 0.0230275709182024
Loss at iteration 1360 : 0.014293152838945389
Loss at iteration 1370 : 0.003305137623101473
Loss at iteration 1380 : 0.014100825414061546
Loss at iteration 1390 : 0.003960535861551762
Loss at iteration 1400 : 0.008591245859861374
Loss at iteration 1410 : 0.012067609466612339
Loss at iteration 1420 : 0.007948201149702072
Loss at iteration 1430 : 0.011002265848219395
Loss at iteration 1440 : 0.0074554006569087505
Loss at iteration 1450 : 0.007830251008272171
Loss at iteration 1460 : 0.006155730225145817
Loss at iteration 1470 : 0.006966269109398127
Loss at iteration 1480 : 0.005124775227159262
Loss at iteration 1490 : 0.008398426696658134
Loss at iteration 1500 : 0.012767910026013851
Loss at iteration 1510 : 0.004305325914174318
Loss at iteration 1520 : 0.005784088745713234
Loss at iteration 1530 : 0.00897008366882801
Loss at iteration 1540 : 0.011967398226261139
Loss at iteration 1550 : 0.009296867996454239
Loss at iteration 1560 : 0.006667601875960827
Loss at iteration 1570 : 0.0125298872590065
Loss at iteration 1580 : 0.011752979829907417
Loss at iteration 1590 : 0.010388050228357315
Loss at iteration 1600 : 0.008955612778663635
Loss at iteration 1610 : 0.005375628359615803
Loss at iteration 1620 : 0.009665523655712605
Loss at iteration 1630 : 0.005870441906154156
Loss at iteration 1640 : 0.012022210285067558
Loss at iteration 1650 : 0.005983925424516201
Loss at iteration 1660 : 0.005724692717194557
Loss at iteration 1670 : 0.006517835892736912
Loss at iteration 1680 : 0.00944499485194683
Loss at iteration 1690 : 0.01317407563328743
Loss at iteration 1700 : 0.010909873992204666
Loss at iteration 1710 : 0.006595798302441835
Loss at iteration 1720 : 0.007977522909641266
Loss at iteration 1730 : 0.007539203390479088
Loss at iteration 1740 : 0.01171702891588211
Loss at iteration 1750 : 0.005238027777522802
Loss at iteration 1760 : 0.004140870179980993
Loss at iteration 1770 : 0.006939144805073738
Loss at iteration 1780 : 0.008360476233065128
Loss at iteration 1790 : 0.013322742655873299
Loss at iteration 1800 : 0.008895737119019032
Loss at iteration 1810 : 0.003387969918549061
Loss at iteration 1820 : 0.00720876595005393
Loss at iteration 1830 : 0.005171758122742176
Loss at iteration 1840 : 0.007553547620773315
Loss at iteration 1850 : 0.007387885823845863
Loss at iteration 1860 : 0.009883380495011806
Loss at iteration 1870 : 0.006577469874173403
Loss at iteration 1880 : 0.005437963642179966
Loss at iteration 1890 : 0.003711241064593196
Loss at iteration 1900 : 0.01025348249822855
Loss at iteration 1910 : 0.00795124750584364
Loss at iteration 1920 : 0.007829555310308933
Loss at iteration 1930 : 0.005288010463118553
Loss at iteration 1940 : 0.01744004711508751
Loss at iteration 1950 : 0.004689947701990604
Loss at iteration 1960 : 0.007291157729923725
Loss at iteration 1970 : 0.003100795205682516
Loss at iteration 1980 : 0.005883641075342894
Loss at iteration 1990 : 0.0060003893449902534
Loss at iteration 2000 : 0.005243530496954918
Loss at iteration 2010 : 0.0035944287665188313
Loss at iteration 2020 : 0.0026688924990594387
Loss at iteration 2030 : 0.00487115141004324
Loss at iteration 2040 : 0.005374678410589695
Loss at iteration 2050 : 0.00878834631294012
Loss at iteration 2060 : 0.00882425345480442
Loss at iteration 2070 : 0.005375578533858061
Loss at iteration 2080 : 0.02621852420270443
Loss at iteration 2090 : 0.003704376984387636
Loss at iteration 2100 : 0.004513726569712162
Loss at iteration 2110 : 0.004872391931712627
Loss at iteration 2120 : 0.006415015086531639
Loss at iteration 2130 : 0.006602116860449314
Loss at iteration 2140 : 0.006310888100415468
Loss at iteration 2150 : 0.008444996550679207
Loss at iteration 2160 : 0.019211994484066963
Loss at iteration 2170 : 0.01318475790321827
Loss at iteration 2180 : 0.006589872296899557
Loss at iteration 2190 : 0.004607196431607008
Loss at iteration 2200 : 0.009811339899897575
Loss at iteration 2210 : 0.0037827338092029095
Loss at iteration 2220 : 0.006711112335324287
Loss at iteration 2230 : 0.00900757685303688
Loss at iteration 2240 : 0.005078974179923534
Loss at iteration 2250 : 0.009866723790764809
Loss at iteration 2260 : 0.008213323540985584
Loss at iteration 2270 : 0.0056807613000273705
Loss at iteration 2280 : 0.01763826794922352
Loss at iteration 2290 : 0.00927102193236351
Loss at iteration 2300 : 0.008088464848697186
Loss at iteration 2310 : 0.01000660378485918
Loss at iteration 2320 : 0.011700243689119816
Loss at iteration 2330 : 0.008393064141273499
Loss at iteration 2340 : 0.011679207906126976
Loss at iteration 2350 : 0.011224010027945042
Loss at iteration 2360 : 0.013392322696745396
Loss at iteration 2370 : 0.00600980082526803
Loss at iteration 2380 : 0.009039192460477352
Loss at iteration 2390 : 0.008503715507686138
Loss at iteration 2400 : 0.022909723222255707
Loss at iteration 2410 : 0.007022846024483442
Loss at iteration 2420 : 0.006495749577879906
The SSIM Value is: 0.8494592706362406
The PSNR Value is: 22.42768071492513
the epoch is: 109
Loss at iteration 10 : 0.02163507603108883
Loss at iteration 20 : 0.011268094182014465
Loss at iteration 30 : 0.004525334108620882
Loss at iteration 40 : 0.00664297491312027
Loss at iteration 50 : 0.013385002501308918
Loss at iteration 60 : 0.007751009427011013
Loss at iteration 70 : 0.008168910630047321
Loss at iteration 80 : 0.013457387685775757
Loss at iteration 90 : 0.005839887075126171
Loss at iteration 100 : 0.013425336219370365
Loss at iteration 110 : 0.005609816871583462
Loss at iteration 120 : 0.006997999735176563
Loss at iteration 130 : 0.007824794389307499
Loss at iteration 140 : 0.008570127189159393
Loss at iteration 150 : 0.017548350617289543
Loss at iteration 160 : 0.006808823440223932
Loss at iteration 170 : 0.010700633749365807
Loss at iteration 180 : 0.009592046029865742
Loss at iteration 190 : 0.008405115455389023
Loss at iteration 200 : 0.011816333048045635
Loss at iteration 210 : 0.0065478673204779625
Loss at iteration 220 : 0.004517054185271263
Loss at iteration 230 : 0.004188619554042816
Loss at iteration 240 : 0.007426369469612837
Loss at iteration 250 : 0.006922801956534386
Loss at iteration 260 : 0.0062544019892811775
Loss at iteration 270 : 0.008322665467858315
Loss at iteration 280 : 0.0094237569719553
Loss at iteration 290 : 0.005553110968321562
Loss at iteration 300 : 0.008271322585642338
Loss at iteration 310 : 0.008269459009170532
Loss at iteration 320 : 0.007624709978699684
Loss at iteration 330 : 0.009905567392706871
Loss at iteration 340 : 0.005926292855292559
Loss at iteration 350 : 0.009339215233922005
Loss at iteration 360 : 0.012128064408898354
Loss at iteration 370 : 0.006043505854904652
Loss at iteration 380 : 0.009120390750467777
Loss at iteration 390 : 0.013070737011730671
Loss at iteration 400 : 0.010767029598355293
Loss at iteration 410 : 0.002804852556437254
Loss at iteration 420 : 0.008165597915649414
Loss at iteration 430 : 0.006396126467734575
Loss at iteration 440 : 0.010008563287556171
Loss at iteration 450 : 0.008698415011167526
Loss at iteration 460 : 0.011516006663441658
Loss at iteration 470 : 0.012290595099329948
Loss at iteration 480 : 0.012929792515933514
Loss at iteration 490 : 0.0010134030599147081
Loss at iteration 500 : 0.008012699894607067
Loss at iteration 510 : 0.009104989469051361
Loss at iteration 520 : 0.003220971208065748
Loss at iteration 530 : 0.00888836570084095
Loss at iteration 540 : 0.013153793290257454
Loss at iteration 550 : 0.004408913664519787
Loss at iteration 560 : 0.016273193061351776
Loss at iteration 570 : 0.00994502380490303
Loss at iteration 580 : 0.011239778250455856
Loss at iteration 590 : 0.005460623651742935
Loss at iteration 600 : 0.02204900234937668
Loss at iteration 610 : 0.007528200279921293
Loss at iteration 620 : 0.009000023826956749
Loss at iteration 630 : 0.006371743511408567
Loss at iteration 640 : 0.0051364232785999775
Loss at iteration 650 : 0.016853787004947662
Loss at iteration 660 : 0.008150705136358738
Loss at iteration 670 : 0.012404903769493103
Loss at iteration 680 : 0.006742129102349281
Loss at iteration 690 : 0.005906222388148308
Loss at iteration 700 : 0.006236285902559757
Loss at iteration 710 : 0.013478722423315048
Loss at iteration 720 : 0.015607353299856186
Loss at iteration 730 : 0.005880149081349373
Loss at iteration 740 : 0.004277300555258989
Loss at iteration 750 : 0.013174825347959995
Loss at iteration 760 : 0.013851135969161987
Loss at iteration 770 : 0.010988529771566391
Loss at iteration 780 : 0.007846735417842865
Loss at iteration 790 : 0.004009033087641001
Loss at iteration 800 : 0.005017012357711792
Loss at iteration 810 : 0.008934714831411839
Loss at iteration 820 : 0.009643889032304287
Loss at iteration 830 : 0.00909382477402687
Loss at iteration 840 : 0.008174726739525795
Loss at iteration 850 : 0.00710487924516201
Loss at iteration 860 : 0.006707909516990185
Loss at iteration 870 : 0.01380509790033102
Loss at iteration 880 : 0.009629684500396252
Loss at iteration 890 : 0.0163596011698246
Loss at iteration 900 : 0.012805846519768238
Loss at iteration 910 : 0.010341068729758263
Loss at iteration 920 : 0.008662003092467785
Loss at iteration 930 : 0.010476810857653618
Loss at iteration 940 : 0.018063846975564957
Loss at iteration 950 : 0.004417537245899439
Loss at iteration 960 : 0.0059544905088841915
Loss at iteration 970 : 0.010513444431126118
Loss at iteration 980 : 0.005924123339354992
Loss at iteration 990 : 0.006663178093731403
Loss at iteration 1000 : 0.018257595598697662
Loss at iteration 1010 : 0.012004180811345577
Loss at iteration 1020 : 0.004829713609069586
Loss at iteration 1030 : 0.005414190702140331
Loss at iteration 1040 : 0.008282337337732315
Loss at iteration 1050 : 0.010427787899971008
Loss at iteration 1060 : 0.0050469618290662766
Loss at iteration 1070 : 0.013316720724105835
Loss at iteration 1080 : 0.0042931633070111275
Loss at iteration 1090 : 0.019792085513472557
Loss at iteration 1100 : 0.005135373678058386
Loss at iteration 1110 : 0.012746816501021385
Loss at iteration 1120 : 0.014249743893742561
Loss at iteration 1130 : 0.004727671388536692
Loss at iteration 1140 : 0.0040245987474918365
Loss at iteration 1150 : 0.004065023269504309
Loss at iteration 1160 : 0.009194763377308846
Loss at iteration 1170 : 0.012439509853720665
Loss at iteration 1180 : 0.012061631307005882
Loss at iteration 1190 : 0.008874941617250443
Loss at iteration 1200 : 0.016536973416805267
Loss at iteration 1210 : 0.01791052147746086
Loss at iteration 1220 : 0.005311650689691305
Loss at iteration 1230 : 0.011702531948685646
Loss at iteration 1240 : 0.00908648781478405
Loss at iteration 1250 : 0.004873564466834068
Loss at iteration 1260 : 0.0062712025828659534
Loss at iteration 1270 : 0.009104380384087563
Loss at iteration 1280 : 0.0062832036055624485
Loss at iteration 1290 : 0.0074843354523181915
Loss at iteration 1300 : 0.002136816969141364
Loss at iteration 1310 : 0.014516736380755901
Loss at iteration 1320 : 0.005533413961529732
Loss at iteration 1330 : 0.004684962797909975
Loss at iteration 1340 : 0.0046998076140880585
Loss at iteration 1350 : 0.00972356740385294
Loss at iteration 1360 : 0.007597674150019884
Loss at iteration 1370 : 0.011402127332985401
Loss at iteration 1380 : 0.014373459853231907
Loss at iteration 1390 : 0.006183765362948179
Loss at iteration 1400 : 0.00560337956994772
Loss at iteration 1410 : 0.014699002727866173
Loss at iteration 1420 : 0.00930212251842022
Loss at iteration 1430 : 0.007932763546705246
Loss at iteration 1440 : 0.010562186129391193
Loss at iteration 1450 : 0.00575048616155982
Loss at iteration 1460 : 0.012095771729946136
Loss at iteration 1470 : 0.012148372828960419
Loss at iteration 1480 : 0.0038895546458661556
Loss at iteration 1490 : 0.014636368490755558
Loss at iteration 1500 : 0.006589788477867842
Loss at iteration 1510 : 0.01737329177558422
Loss at iteration 1520 : 0.01190915796905756
Loss at iteration 1530 : 0.010945983231067657
Loss at iteration 1540 : 0.011306065134704113
Loss at iteration 1550 : 0.0060240719467401505
Loss at iteration 1560 : 0.00844388548284769
Loss at iteration 1570 : 0.008136152289807796
Loss at iteration 1580 : 0.01277024857699871
Loss at iteration 1590 : 0.0067137316800653934
Loss at iteration 1600 : 0.005780633073300123
Loss at iteration 1610 : 0.00404472416266799
Loss at iteration 1620 : 0.011062297970056534
Loss at iteration 1630 : 0.008393221534788609
Loss at iteration 1640 : 0.012355133891105652
Loss at iteration 1650 : 0.008104276843369007
Loss at iteration 1660 : 0.016902470961213112
Loss at iteration 1670 : 0.012629484757781029
Loss at iteration 1680 : 0.010422994382679462
Loss at iteration 1690 : 0.007724732160568237
Loss at iteration 1700 : 0.011388663202524185
Loss at iteration 1710 : 0.004262072499841452
Loss at iteration 1720 : 0.012186282314360142
Loss at iteration 1730 : 0.008432071655988693
Loss at iteration 1740 : 0.012258026748895645
Loss at iteration 1750 : 0.021431172266602516
Loss at iteration 1760 : 0.011955711990594864
Loss at iteration 1770 : 0.0069259535521268845
Loss at iteration 1780 : 0.0128887128084898
Loss at iteration 1790 : 0.004295899998396635
Loss at iteration 1800 : 0.013356723822653294
Loss at iteration 1810 : 0.014169538393616676
Loss at iteration 1820 : 0.008583102375268936
Loss at iteration 1830 : 0.01354309730231762
Loss at iteration 1840 : 0.012952549383044243
Loss at iteration 1850 : 0.005092840641736984
Loss at iteration 1860 : 0.015684988349676132
Loss at iteration 1870 : 0.011223727837204933
Loss at iteration 1880 : 0.006058600731194019
Loss at iteration 1890 : 0.008080372586846352
Loss at iteration 1900 : 0.001955984625965357
Loss at iteration 1910 : 0.0040053920820355415
Loss at iteration 1920 : 0.008165169507265091
Loss at iteration 1930 : 0.004911221098154783
Loss at iteration 1940 : 0.0096444021910429
Loss at iteration 1950 : 0.012849319726228714
Loss at iteration 1960 : 0.005476911086589098
Loss at iteration 1970 : 0.006482906639575958
Loss at iteration 1980 : 0.010006614029407501
Loss at iteration 1990 : 0.0023698098957538605
Loss at iteration 2000 : 0.008671322837471962
Loss at iteration 2010 : 0.009459097869694233
Loss at iteration 2020 : 0.004136913921684027
Loss at iteration 2030 : 0.010351037606596947
Loss at iteration 2040 : 0.0023866305127739906
Loss at iteration 2050 : 0.01736282929778099
Loss at iteration 2060 : 0.010589106939733028
Loss at iteration 2070 : 0.002885502763092518
Loss at iteration 2080 : 0.0071892221458256245
Loss at iteration 2090 : 0.002498915418982506
Loss at iteration 2100 : 0.005692304112017155
Loss at iteration 2110 : 0.0050880215130746365
Loss at iteration 2120 : 0.00821701716631651
Loss at iteration 2130 : 0.010338421911001205
Loss at iteration 2140 : 0.004030569456517696
Loss at iteration 2150 : 0.006724187172949314
Loss at iteration 2160 : 0.00612451508641243
Loss at iteration 2170 : 0.007449307478964329
Loss at iteration 2180 : 0.0059873913414776325
Loss at iteration 2190 : 0.0033670489210635424
Loss at iteration 2200 : 0.005145208910107613
Loss at iteration 2210 : 0.0069193160161376
Loss at iteration 2220 : 0.006645622663199902
Loss at iteration 2230 : 0.009687680751085281
Loss at iteration 2240 : 0.007182985544204712
Loss at iteration 2250 : 0.008014123886823654
Loss at iteration 2260 : 0.007013850379735231
Loss at iteration 2270 : 0.00420934846624732
Loss at iteration 2280 : 0.009811549447476864
Loss at iteration 2290 : 0.004963632673025131
Loss at iteration 2300 : 0.005423380993306637
Loss at iteration 2310 : 0.006449527572840452
Loss at iteration 2320 : 0.006031418684870005
Loss at iteration 2330 : 0.005371985957026482
Loss at iteration 2340 : 0.005291304085403681
Loss at iteration 2350 : 0.005470299627631903
Loss at iteration 2360 : 0.005906015168875456
Loss at iteration 2370 : 0.003598447423428297
Loss at iteration 2380 : 0.008718479424715042
Loss at iteration 2390 : 0.008344264701008797
Loss at iteration 2400 : 0.004532776307314634
Loss at iteration 2410 : 0.0073166582733392715
Loss at iteration 2420 : 0.00923161767423153
The SSIM Value is: 0.8465344905853271
The PSNR Value is: 22.514375114440917
the epoch is: 110
Loss at iteration 10 : 0.00878226663917303
Loss at iteration 20 : 0.005330560728907585
Loss at iteration 30 : 0.016710493713617325
Loss at iteration 40 : 0.004508323036134243
Loss at iteration 50 : 0.003961104899644852
Loss at iteration 60 : 0.005466040689498186
Loss at iteration 70 : 0.004074550233781338
Loss at iteration 80 : 0.012216883711516857
Loss at iteration 90 : 0.006686467677354813
Loss at iteration 100 : 0.012731506489217281
Loss at iteration 110 : 0.012003028765320778
Loss at iteration 120 : 0.0074743363074958324
Loss at iteration 130 : 0.009182034060359001
Loss at iteration 140 : 0.008756879717111588
Loss at iteration 150 : 0.005888424348086119
Loss at iteration 160 : 0.004773955326527357
Loss at iteration 170 : 0.005523432977497578
Loss at iteration 180 : 0.0054985228925943375
Loss at iteration 190 : 0.009312191046774387
Loss at iteration 200 : 0.004921011161059141
Loss at iteration 210 : 0.012052296660840511
Loss at iteration 220 : 0.010931896045804024
Loss at iteration 230 : 0.005099334288388491
Loss at iteration 240 : 0.0038770721293985844
Loss at iteration 250 : 0.0017631268128752708
Loss at iteration 260 : 0.006317881867289543
Loss at iteration 270 : 0.02626691944897175
Loss at iteration 280 : 0.005389994475990534
Loss at iteration 290 : 0.007097920402884483
Loss at iteration 300 : 0.01423237007111311
Loss at iteration 310 : 0.0050579458475112915
Loss at iteration 320 : 0.01901271939277649
Loss at iteration 330 : 0.013324083760380745
Loss at iteration 340 : 0.009335475042462349
Loss at iteration 350 : 0.007892696186900139
Loss at iteration 360 : 0.010567006655037403
Loss at iteration 370 : 0.009220401756465435
Loss at iteration 380 : 0.00965452753007412
Loss at iteration 390 : 0.0029807158280164003
Loss at iteration 400 : 0.009549672715365887
Loss at iteration 410 : 0.014412869699299335
Loss at iteration 420 : 0.0019010568503290415
Loss at iteration 430 : 0.019954349845647812
Loss at iteration 440 : 0.0068655116483569145
Loss at iteration 450 : 0.02608376368880272
Loss at iteration 460 : 0.004620622843503952
Loss at iteration 470 : 0.009427075274288654
Loss at iteration 480 : 0.010470353998243809
Loss at iteration 490 : 0.006088845431804657
Loss at iteration 500 : 0.00538927735760808
Loss at iteration 510 : 0.0137462904676795
Loss at iteration 520 : 0.00652281753718853
Loss at iteration 530 : 0.005981868132948875
Loss at iteration 540 : 0.008114991709589958
Loss at iteration 550 : 0.011642582714557648
Loss at iteration 560 : 0.003142594126984477
Loss at iteration 570 : 0.011608364060521126
Loss at iteration 580 : 0.006188817322254181
Loss at iteration 590 : 0.008510180748999119
Loss at iteration 600 : 0.007529900874942541
Loss at iteration 610 : 0.01453787088394165
Loss at iteration 620 : 0.010735981166362762
Loss at iteration 630 : 0.014644786715507507
Loss at iteration 640 : 0.007251146715134382
Loss at iteration 650 : 0.012050824239850044
Loss at iteration 660 : 0.009617447853088379
Loss at iteration 670 : 0.004366082139313221
Loss at iteration 680 : 0.009626585058867931
Loss at iteration 690 : 0.00819987989962101
Loss at iteration 700 : 0.003184102475643158
Loss at iteration 710 : 0.01467449776828289
Loss at iteration 720 : 0.002623149659484625
Loss at iteration 730 : 0.010316877625882626
Loss at iteration 740 : 0.004868169780820608
Loss at iteration 750 : 0.005234942305833101
Loss at iteration 760 : 0.008971745148301125
Loss at iteration 770 : 0.006117736455053091
Loss at iteration 780 : 0.006966169457882643
Loss at iteration 790 : 0.003898301161825657
Loss at iteration 800 : 0.009835460223257542
Loss at iteration 810 : 0.01768394559621811
Loss at iteration 820 : 0.014822468161582947
Loss at iteration 830 : 0.006611519493162632
Loss at iteration 840 : 0.003539520315825939
Loss at iteration 850 : 0.010097400285303593
Loss at iteration 860 : 0.0059909820556640625
Loss at iteration 870 : 0.00847279280424118
Loss at iteration 880 : 0.008078143931925297
Loss at iteration 890 : 0.012078720144927502
Loss at iteration 900 : 0.005547146312892437
Loss at iteration 910 : 0.0043529183603823185
Loss at iteration 920 : 0.0051721674390137196
Loss at iteration 930 : 0.009248881600797176
Loss at iteration 940 : 0.010055418126285076
Loss at iteration 950 : 0.005152801983058453
Loss at iteration 960 : 0.009669751860201359
Loss at iteration 970 : 0.00597506295889616
Loss at iteration 980 : 0.01807219348847866
Loss at iteration 990 : 0.02079426683485508
Loss at iteration 1000 : 0.0062062619253993034
Loss at iteration 1010 : 0.009666861034929752
Loss at iteration 1020 : 0.004694126080721617
Loss at iteration 1030 : 0.005091505125164986
Loss at iteration 1040 : 0.0063617597334086895
Loss at iteration 1050 : 0.0044485582038760185
Loss at iteration 1060 : 0.007821334525942802
Loss at iteration 1070 : 0.007198077626526356
Loss at iteration 1080 : 0.01362811028957367
Loss at iteration 1090 : 0.009705915115773678
Loss at iteration 1100 : 0.0068437280133366585
Loss at iteration 1110 : 0.006588232237845659
Loss at iteration 1120 : 0.006583234760910273
Loss at iteration 1130 : 0.010953370481729507
Loss at iteration 1140 : 0.011964278295636177
Loss at iteration 1150 : 0.009137136861681938
Loss at iteration 1160 : 0.012919852510094643
Loss at iteration 1170 : 0.007488367147743702
Loss at iteration 1180 : 0.012499243021011353
Loss at iteration 1190 : 0.010129568167030811
Loss at iteration 1200 : 0.011583658866584301
Loss at iteration 1210 : 0.009148593991994858
Loss at iteration 1220 : 0.01385144516825676
Loss at iteration 1230 : 0.00946139544248581
Loss at iteration 1240 : 0.00756299402564764
Loss at iteration 1250 : 0.012790248729288578
Loss at iteration 1260 : 0.012283599004149437
Loss at iteration 1270 : 0.003986069932579994
Loss at iteration 1280 : 0.007475262042135
Loss at iteration 1290 : 0.015530936419963837
Loss at iteration 1300 : 0.010624570772051811
Loss at iteration 1310 : 0.008028700947761536
Loss at iteration 1320 : 0.008700371719896793
Loss at iteration 1330 : 0.006383179686963558
Loss at iteration 1340 : 0.009000017307698727
Loss at iteration 1350 : 0.01230764389038086
Loss at iteration 1360 : 0.005193565972149372
Loss at iteration 1370 : 0.006400886457413435
Loss at iteration 1380 : 0.005638522561639547
Loss at iteration 1390 : 0.011558904312551022
Loss at iteration 1400 : 0.008714351803064346
Loss at iteration 1410 : 0.014514418318867683
Loss at iteration 1420 : 0.006903522647917271
Loss at iteration 1430 : 0.00827249325811863
Loss at iteration 1440 : 0.006898972205817699
Loss at iteration 1450 : 0.004810683894902468
Loss at iteration 1460 : 0.014251317828893661
Loss at iteration 1470 : 0.01420106366276741
Loss at iteration 1480 : 0.004575145430862904
Loss at iteration 1490 : 0.009124652482569218
Loss at iteration 1500 : 0.0076174670830369
Loss at iteration 1510 : 0.007654298096895218
Loss at iteration 1520 : 0.006314799655228853
Loss at iteration 1530 : 0.006135174073278904
Loss at iteration 1540 : 0.009582635015249252
Loss at iteration 1550 : 0.012486586347222328
Loss at iteration 1560 : 0.010141229256987572
Loss at iteration 1570 : 0.008011695928871632
Loss at iteration 1580 : 0.015040941536426544
Loss at iteration 1590 : 0.006130843888968229
Loss at iteration 1600 : 0.01388036273419857
Loss at iteration 1610 : 0.003287962172180414
Loss at iteration 1620 : 0.011203334666788578
Loss at iteration 1630 : 0.0017927761655300856
Loss at iteration 1640 : 0.014122988097369671
Loss at iteration 1650 : 0.0038947013672441244
Loss at iteration 1660 : 0.0072894636541605
Loss at iteration 1670 : 0.006291951052844524
Loss at iteration 1680 : 0.00542763527482748
Loss at iteration 1690 : 0.008631672710180283
Loss at iteration 1700 : 0.01844991184771061
Loss at iteration 1710 : 0.019083717837929726
Loss at iteration 1720 : 0.0033269054256379604
Loss at iteration 1730 : 0.010722336359322071
Loss at iteration 1740 : 0.004528782330453396
Loss at iteration 1750 : 0.009343063458800316
Loss at iteration 1760 : 0.012809313833713531
Loss at iteration 1770 : 0.013647881336510181
Loss at iteration 1780 : 0.00463412469252944
Loss at iteration 1790 : 0.009512039832770824
Loss at iteration 1800 : 0.009318888187408447
Loss at iteration 1810 : 0.010400176979601383
Loss at iteration 1820 : 0.004852638579905033
Loss at iteration 1830 : 0.00527778547257185
Loss at iteration 1840 : 0.0037817489355802536
Loss at iteration 1850 : 0.007150419522076845
Loss at iteration 1860 : 0.012189588509500027
Loss at iteration 1870 : 0.005417806562036276
Loss at iteration 1880 : 0.006667058914899826
Loss at iteration 1890 : 0.00409796554595232
Loss at iteration 1900 : 0.010292772203683853
Loss at iteration 1910 : 0.0064829313196241856
Loss at iteration 1920 : 0.01280319131910801
Loss at iteration 1930 : 0.004153019282966852
Loss at iteration 1940 : 0.017551591619849205
Loss at iteration 1950 : 0.0036681098863482475
Loss at iteration 1960 : 0.02039237879216671
Loss at iteration 1970 : 0.0022392382379621267
Loss at iteration 1980 : 0.00610730517655611
Loss at iteration 1990 : 0.0089876102283597
Loss at iteration 2000 : 0.010890161618590355
Loss at iteration 2010 : 0.011183639988303185
Loss at iteration 2020 : 0.007508568465709686
Loss at iteration 2030 : 0.0063627660274505615
Loss at iteration 2040 : 0.005034919828176498
Loss at iteration 2050 : 0.011834302917122841
Loss at iteration 2060 : 0.006608603522181511
Loss at iteration 2070 : 0.018654359504580498
Loss at iteration 2080 : 0.0063028656877577305
Loss at iteration 2090 : 0.008807268925011158
Loss at iteration 2100 : 0.008652630262076855
Loss at iteration 2110 : 0.007904525846242905
Loss at iteration 2120 : 0.009577451273798943
Loss at iteration 2130 : 0.006847633980214596
Loss at iteration 2140 : 0.016692033037543297
Loss at iteration 2150 : 0.006592078134417534
Loss at iteration 2160 : 0.008300925604999065
Loss at iteration 2170 : 0.004024151246994734
Loss at iteration 2180 : 0.006362541578710079
Loss at iteration 2190 : 0.008236406370997429
Loss at iteration 2200 : 0.004316488280892372
Loss at iteration 2210 : 0.007925926707684994
Loss at iteration 2220 : 0.00811814796179533
Loss at iteration 2230 : 0.00631155539304018
Loss at iteration 2240 : 0.007768847048282623
Loss at iteration 2250 : 0.013130296021699905
Loss at iteration 2260 : 0.009852924384176731
Loss at iteration 2270 : 0.005821188911795616
Loss at iteration 2280 : 0.00780033553019166
Loss at iteration 2290 : 0.012083897367119789
Loss at iteration 2300 : 0.0046379719860851765
Loss at iteration 2310 : 0.011407679878175259
Loss at iteration 2320 : 0.004899338819086552
Loss at iteration 2330 : 0.0038034291937947273
Loss at iteration 2340 : 0.0057740965858101845
Loss at iteration 2350 : 0.01290349755436182
Loss at iteration 2360 : 0.004127548076212406
Loss at iteration 2370 : 0.005439793691039085
Loss at iteration 2380 : 0.009149951860308647
Loss at iteration 2390 : 0.0037680845707654953
Loss at iteration 2400 : 0.0036406831350177526
Loss at iteration 2410 : 0.003712239908054471
Loss at iteration 2420 : 0.008161278441548347
The SSIM Value is: 0.8457337419191996
The PSNR Value is: 21.695546213785807
the epoch is: 111
Loss at iteration 10 : 0.019806494936347008
Loss at iteration 20 : 0.007600513286888599
Loss at iteration 30 : 0.010589621029794216
Loss at iteration 40 : 0.007867025211453438
Loss at iteration 50 : 0.005112281069159508
Loss at iteration 60 : 0.0064934235997498035
Loss at iteration 70 : 0.008750629611313343
Loss at iteration 80 : 0.003920236602425575
Loss at iteration 90 : 0.019113698974251747
Loss at iteration 100 : 0.005927977617830038
Loss at iteration 110 : 0.01134817861020565
Loss at iteration 120 : 0.013460574671626091
Loss at iteration 130 : 0.015827935189008713
Loss at iteration 140 : 0.0027184374630451202
Loss at iteration 150 : 0.011098184622824192
Loss at iteration 160 : 0.013268368318676949
Loss at iteration 170 : 0.006124642677605152
Loss at iteration 180 : 0.008607398718595505
Loss at iteration 190 : 0.0095795514062047
Loss at iteration 200 : 0.004952778108417988
Loss at iteration 210 : 0.007264001294970512
Loss at iteration 220 : 0.0035434416495263577
Loss at iteration 230 : 0.010041086934506893
Loss at iteration 240 : 0.008708879351615906
Loss at iteration 250 : 0.008065910078585148
Loss at iteration 260 : 0.007152950391173363
Loss at iteration 270 : 0.0051244087517261505
Loss at iteration 280 : 0.006888683885335922
Loss at iteration 290 : 0.008852409198880196
Loss at iteration 300 : 0.009873686358332634
Loss at iteration 310 : 0.01027641911059618
Loss at iteration 320 : 0.007074854336678982
Loss at iteration 330 : 0.011429419741034508
Loss at iteration 340 : 0.008171494118869305
Loss at iteration 350 : 0.006005855277180672
Loss at iteration 360 : 0.00819166749715805
Loss at iteration 370 : 0.006478254217654467
Loss at iteration 380 : 0.010106425732374191
Loss at iteration 390 : 0.008239250630140305
Loss at iteration 400 : 0.005930381827056408
Loss at iteration 410 : 0.022735822945833206
Loss at iteration 420 : 0.008712789975106716
Loss at iteration 430 : 0.010057837702333927
Loss at iteration 440 : 0.019294019788503647
Loss at iteration 450 : 0.008646738715469837
Loss at iteration 460 : 0.019633706659078598
Loss at iteration 470 : 0.009318915195763111
Loss at iteration 480 : 0.01102043129503727
Loss at iteration 490 : 0.0032266085036098957
Loss at iteration 500 : 0.012693172320723534
Loss at iteration 510 : 0.006976629141718149
Loss at iteration 520 : 0.011303872801363468
Loss at iteration 530 : 0.004525882191956043
Loss at iteration 540 : 0.009668397717177868
Loss at iteration 550 : 0.009148365817964077
Loss at iteration 560 : 0.006513352971524
Loss at iteration 570 : 0.012213434092700481
Loss at iteration 580 : 0.00888198520988226
Loss at iteration 590 : 0.00780017813667655
Loss at iteration 600 : 0.008581745438277721
Loss at iteration 610 : 0.007872423157095909
Loss at iteration 620 : 0.012554671615362167
Loss at iteration 630 : 0.006349591538310051
Loss at iteration 640 : 0.00769036216661334
Loss at iteration 650 : 0.012985676527023315
Loss at iteration 660 : 0.005006208550184965
Loss at iteration 670 : 0.007781447842717171
Loss at iteration 680 : 0.012656860053539276
Loss at iteration 690 : 0.002847556257620454
Loss at iteration 700 : 0.00828642025589943
Loss at iteration 710 : 0.00717886071652174
Loss at iteration 720 : 0.008491747081279755
Loss at iteration 730 : 0.004112731199711561
Loss at iteration 740 : 0.011593093164265156
Loss at iteration 750 : 0.009515605866909027
Loss at iteration 760 : 0.019797012209892273
Loss at iteration 770 : 0.011801102198660374
Loss at iteration 780 : 0.00790945440530777
Loss at iteration 790 : 0.008255412802100182
Loss at iteration 800 : 0.0054669687524437904
Loss at iteration 810 : 0.007908793166279793
Loss at iteration 820 : 0.011241484433412552
Loss at iteration 830 : 0.010794769041240215
Loss at iteration 840 : 0.005185398738831282
Loss at iteration 850 : 0.001898312009871006
Loss at iteration 860 : 0.005023765377700329
Loss at iteration 870 : 0.003876263741403818
Loss at iteration 880 : 0.003052332904189825
Loss at iteration 890 : 0.006251892540603876
Loss at iteration 900 : 0.006572255864739418
Loss at iteration 910 : 0.006900342181324959
Loss at iteration 920 : 0.015499849803745747
Loss at iteration 930 : 0.0036136843264102936
Loss at iteration 940 : 0.016065552830696106
Loss at iteration 950 : 0.0058431606739759445
Loss at iteration 960 : 0.005907867103815079
Loss at iteration 970 : 0.01021283958107233
Loss at iteration 980 : 0.006309317424893379
Loss at iteration 990 : 0.009818779304623604
Loss at iteration 1000 : 0.011313146911561489
Loss at iteration 1010 : 0.005955760832875967
Loss at iteration 1020 : 0.01794574037194252
Loss at iteration 1030 : 0.012907257303595543
Loss at iteration 1040 : 0.020919915288686752
Loss at iteration 1050 : 0.009371140971779823
Loss at iteration 1060 : 0.014975777827203274
Loss at iteration 1070 : 0.007020630873739719
Loss at iteration 1080 : 0.004620607476681471
Loss at iteration 1090 : 0.00692380266264081
Loss at iteration 1100 : 0.006481145042926073
Loss at iteration 1110 : 0.006186621263623238
Loss at iteration 1120 : 0.013223562389612198
Loss at iteration 1130 : 0.00815093144774437
Loss at iteration 1140 : 0.010059259831905365
Loss at iteration 1150 : 0.010110361501574516
Loss at iteration 1160 : 0.013398408889770508
Loss at iteration 1170 : 0.006938795559108257
Loss at iteration 1180 : 0.013446127064526081
Loss at iteration 1190 : 0.006038014777004719
Loss at iteration 1200 : 0.009236807003617287
Loss at iteration 1210 : 0.005372518673539162
Loss at iteration 1220 : 0.01429855078458786
Loss at iteration 1230 : 0.00475709605962038
Loss at iteration 1240 : 0.007277677766978741
Loss at iteration 1250 : 0.007072080858051777
Loss at iteration 1260 : 0.014063006266951561
Loss at iteration 1270 : 0.006768310908228159
Loss at iteration 1280 : 0.02000880427658558
Loss at iteration 1290 : 0.009643271565437317
Loss at iteration 1300 : 0.010612010955810547
Loss at iteration 1310 : 0.005020570009946823
Loss at iteration 1320 : 0.004238629713654518
Loss at iteration 1330 : 0.009379041381180286
Loss at iteration 1340 : 0.010823824442923069
Loss at iteration 1350 : 0.0048996019177138805
Loss at iteration 1360 : 0.003833048976957798
Loss at iteration 1370 : 0.006342816166579723
Loss at iteration 1380 : 0.0054417941719293594
Loss at iteration 1390 : 0.007578488439321518
Loss at iteration 1400 : 0.007967546582221985
Loss at iteration 1410 : 0.006858331151306629
Loss at iteration 1420 : 0.005196233280003071
Loss at iteration 1430 : 0.010741133242845535
Loss at iteration 1440 : 0.011656475253403187
Loss at iteration 1450 : 0.009853940457105637
Loss at iteration 1460 : 0.004364740569144487
Loss at iteration 1470 : 0.005243518389761448
Loss at iteration 1480 : 0.014532644301652908
Loss at iteration 1490 : 0.003513325471431017
Loss at iteration 1500 : 0.007375319954007864
Loss at iteration 1510 : 0.008458164520561695
Loss at iteration 1520 : 0.009153150953352451
Loss at iteration 1530 : 0.00785291101783514
Loss at iteration 1540 : 0.005684942938387394
Loss at iteration 1550 : 0.017047006636857986
Loss at iteration 1560 : 0.00972464308142662
Loss at iteration 1570 : 0.008384324610233307
Loss at iteration 1580 : 0.008794053457677364
Loss at iteration 1590 : 0.0026917969807982445
Loss at iteration 1600 : 0.007969421334564686
Loss at iteration 1610 : 0.008451417088508606
Loss at iteration 1620 : 0.015679243952035904
Loss at iteration 1630 : 0.017077550292015076
Loss at iteration 1640 : 0.00774036580696702
Loss at iteration 1650 : 0.003094394225627184
Loss at iteration 1660 : 0.011609856970608234
Loss at iteration 1670 : 0.006409529596567154
Loss at iteration 1680 : 0.001867271144874394
Loss at iteration 1690 : 0.01557433046400547
Loss at iteration 1700 : 0.008038397878408432
Loss at iteration 1710 : 0.015495833940804005
Loss at iteration 1720 : 0.0040583256632089615
Loss at iteration 1730 : 0.00459393672645092
Loss at iteration 1740 : 0.004325896967202425
Loss at iteration 1750 : 0.007624231744557619
Loss at iteration 1760 : 0.011320403777062893
Loss at iteration 1770 : 0.012005731463432312
Loss at iteration 1780 : 0.011823993176221848
Loss at iteration 1790 : 0.007818270474672318
Loss at iteration 1800 : 0.009806999005377293
Loss at iteration 1810 : 0.010131056420505047
Loss at iteration 1820 : 0.008326655253767967
Loss at iteration 1830 : 0.00673088151961565
Loss at iteration 1840 : 0.005950248334556818
Loss at iteration 1850 : 0.007205262780189514
Loss at iteration 1860 : 0.0130302207544446
Loss at iteration 1870 : 0.012991201132535934
Loss at iteration 1880 : 0.008252727799117565
Loss at iteration 1890 : 0.01432793214917183
Loss at iteration 1900 : 0.01942710019648075
Loss at iteration 1910 : 0.0055258204229176044
Loss at iteration 1920 : 0.0031889593228697777
Loss at iteration 1930 : 0.009836237877607346
Loss at iteration 1940 : 0.013241708278656006
Loss at iteration 1950 : 0.010271434672176838
Loss at iteration 1960 : 0.006560389418154955
Loss at iteration 1970 : 0.011256413534283638
Loss at iteration 1980 : 0.00864819623529911
Loss at iteration 1990 : 0.013011765666306019
Loss at iteration 2000 : 0.005130970850586891
Loss at iteration 2010 : 0.007819615304470062
Loss at iteration 2020 : 0.008111139759421349
Loss at iteration 2030 : 0.007368049584329128
Loss at iteration 2040 : 0.0062251221388578415
Loss at iteration 2050 : 0.010939824394881725
Loss at iteration 2060 : 0.010111507028341293
Loss at iteration 2070 : 0.009679358452558517
Loss at iteration 2080 : 0.01978394016623497
Loss at iteration 2090 : 0.015573147684335709
Loss at iteration 2100 : 0.007971161045134068
Loss at iteration 2110 : 0.01570330560207367
Loss at iteration 2120 : 0.013407237827777863
Loss at iteration 2130 : 0.003984745126217604
Loss at iteration 2140 : 0.01234609354287386
Loss at iteration 2150 : 0.00804479792714119
Loss at iteration 2160 : 0.0064974818378686905
Loss at iteration 2170 : 0.011325356550514698
Loss at iteration 2180 : 0.013346617110073566
Loss at iteration 2190 : 0.0034685481805354357
Loss at iteration 2200 : 0.00717171560972929
Loss at iteration 2210 : 0.010944630019366741
Loss at iteration 2220 : 0.008298400789499283
Loss at iteration 2230 : 0.02051827311515808
Loss at iteration 2240 : 0.006909479387104511
Loss at iteration 2250 : 0.01064562238752842
Loss at iteration 2260 : 0.011167830787599087
Loss at iteration 2270 : 0.0044910176657140255
Loss at iteration 2280 : 0.012834273278713226
Loss at iteration 2290 : 0.0060031116008758545
Loss at iteration 2300 : 0.005775363650172949
Loss at iteration 2310 : 0.015382726676762104
Loss at iteration 2320 : 0.005516896024346352
Loss at iteration 2330 : 0.011353219859302044
Loss at iteration 2340 : 0.017489667981863022
Loss at iteration 2350 : 0.0033499058336019516
Loss at iteration 2360 : 0.01213611476123333
Loss at iteration 2370 : 0.009230975061655045
Loss at iteration 2380 : 0.019057897850871086
Loss at iteration 2390 : 0.017685705795884132
Loss at iteration 2400 : 0.00940156914293766
Loss at iteration 2410 : 0.009005754254758358
Loss at iteration 2420 : 0.016945362091064453
The SSIM Value is: 0.8456052621205647
The PSNR Value is: 22.21281731923421
the epoch is: 112
Loss at iteration 10 : 0.020803701132535934
Loss at iteration 20 : 0.007520454004406929
Loss at iteration 30 : 0.005423784255981445
Loss at iteration 40 : 0.008321091532707214
Loss at iteration 50 : 0.004777210298925638
Loss at iteration 60 : 0.01062178798019886
Loss at iteration 70 : 0.004270453937351704
Loss at iteration 80 : 0.010126578621566296
Loss at iteration 90 : 0.0089578777551651
Loss at iteration 100 : 0.004411619622260332
Loss at iteration 110 : 0.009774016216397285
Loss at iteration 120 : 0.00899201538413763
Loss at iteration 130 : 0.007886620238423347
Loss at iteration 140 : 0.010370239615440369
Loss at iteration 150 : 0.0097026526927948
Loss at iteration 160 : 0.008018308319151402
Loss at iteration 170 : 0.0019445932703092694
Loss at iteration 180 : 0.009185262024402618
Loss at iteration 190 : 0.002789477352052927
Loss at iteration 200 : 0.011219460517168045
Loss at iteration 210 : 0.008094089105725288
Loss at iteration 220 : 0.003363278228789568
Loss at iteration 230 : 0.006182648241519928
Loss at iteration 240 : 0.008335689082741737
Loss at iteration 250 : 0.0068756393156945705
Loss at iteration 260 : 0.009681259281933308
Loss at iteration 270 : 0.011223170906305313
Loss at iteration 280 : 0.006403123028576374
Loss at iteration 290 : 0.0054063983261585236
Loss at iteration 300 : 0.007908525876700878
Loss at iteration 310 : 0.010443120263516903
Loss at iteration 320 : 0.011071487329900265
Loss at iteration 330 : 0.0021619205363094807
Loss at iteration 340 : 0.009084210731089115
Loss at iteration 350 : 0.022915050387382507
Loss at iteration 360 : 0.005874007008969784
Loss at iteration 370 : 0.0033710291609168053
Loss at iteration 380 : 0.00733731035143137
Loss at iteration 390 : 0.0140390545129776
Loss at iteration 400 : 0.0066038211807608604
Loss at iteration 410 : 0.01531713642179966
Loss at iteration 420 : 0.010468524880707264
Loss at iteration 430 : 0.008051435463130474
Loss at iteration 440 : 0.01110227219760418
Loss at iteration 450 : 0.010212751105427742
Loss at iteration 460 : 0.0116238659247756
Loss at iteration 470 : 0.003163645975291729
Loss at iteration 480 : 0.008766635321080685
Loss at iteration 490 : 0.004168075043708086
Loss at iteration 500 : 0.010646859183907509
Loss at iteration 510 : 0.007101179100573063
Loss at iteration 520 : 0.008289331570267677
Loss at iteration 530 : 0.0028349137865006924
Loss at iteration 540 : 0.0058633992448449135
Loss at iteration 550 : 0.005779045633971691
Loss at iteration 560 : 0.004808553960174322
Loss at iteration 570 : 0.008016558364033699
Loss at iteration 580 : 0.006015302147716284
Loss at iteration 590 : 0.00597816426306963
Loss at iteration 600 : 0.007566120009869337
Loss at iteration 610 : 0.003114622551947832
Loss at iteration 620 : 0.003985575400292873
Loss at iteration 630 : 0.002863257424905896
Loss at iteration 640 : 0.01149617601186037
Loss at iteration 650 : 0.00784582830965519
Loss at iteration 660 : 0.008899700827896595
Loss at iteration 670 : 0.008828566409647465
Loss at iteration 680 : 0.007645071484148502
Loss at iteration 690 : 0.006461507175117731
Loss at iteration 700 : 0.011795380152761936
Loss at iteration 710 : 0.007240261882543564
Loss at iteration 720 : 0.004629720468074083
Loss at iteration 730 : 0.009830113500356674
Loss at iteration 740 : 0.004773161839693785
Loss at iteration 750 : 0.008975807577371597
Loss at iteration 760 : 0.010954533703625202
Loss at iteration 770 : 0.002944289008155465
Loss at iteration 780 : 0.012592650949954987
Loss at iteration 790 : 0.0066457814536988735
Loss at iteration 800 : 0.0048768422566354275
Loss at iteration 810 : 0.003442230634391308
Loss at iteration 820 : 0.005560785531997681
Loss at iteration 830 : 0.007131020538508892
Loss at iteration 840 : 0.007285617291927338
Loss at iteration 850 : 0.01170908659696579
Loss at iteration 860 : 0.005060461815446615
Loss at iteration 870 : 0.016294078901410103
Loss at iteration 880 : 0.003798134159296751
Loss at iteration 890 : 0.01526012271642685
Loss at iteration 900 : 0.005709619261324406
Loss at iteration 910 : 0.006370857823640108
Loss at iteration 920 : 0.01666365936398506
Loss at iteration 930 : 0.008488559164106846
Loss at iteration 940 : 0.01886380836367607
Loss at iteration 950 : 0.010900380089879036
Loss at iteration 960 : 0.008105240762233734
Loss at iteration 970 : 0.015176068991422653
Loss at iteration 980 : 0.0067338901571929455
Loss at iteration 990 : 0.004170677624642849
Loss at iteration 1000 : 0.013204622082412243
Loss at iteration 1010 : 0.006424380466341972
Loss at iteration 1020 : 0.01166242454200983
Loss at iteration 1030 : 0.003499645506963134
Loss at iteration 1040 : 0.009369809180498123
Loss at iteration 1050 : 0.007134962826967239
Loss at iteration 1060 : 0.010054951533675194
Loss at iteration 1070 : 0.011926786974072456
Loss at iteration 1080 : 0.004364922177046537
Loss at iteration 1090 : 0.006015317514538765
Loss at iteration 1100 : 0.011253542266786098
Loss at iteration 1110 : 0.004190709907561541
Loss at iteration 1120 : 0.00966576300561428
Loss at iteration 1130 : 0.007439001463353634
Loss at iteration 1140 : 0.0035699245054274797
Loss at iteration 1150 : 0.012177885510027409
Loss at iteration 1160 : 0.005228368565440178
Loss at iteration 1170 : 0.00942644290626049
Loss at iteration 1180 : 0.006417303811758757
Loss at iteration 1190 : 0.018407220020890236
Loss at iteration 1200 : 0.006900538224726915
Loss at iteration 1210 : 0.005794024560600519
Loss at iteration 1220 : 0.007568430155515671
Loss at iteration 1230 : 0.009322701953351498
Loss at iteration 1240 : 0.009067166596651077
Loss at iteration 1250 : 0.02021617256104946
Loss at iteration 1260 : 0.00627135718241334
Loss at iteration 1270 : 0.010550512000918388
Loss at iteration 1280 : 0.005657298490405083
Loss at iteration 1290 : 0.008106722496449947
Loss at iteration 1300 : 0.005064886063337326
Loss at iteration 1310 : 0.014342853799462318
Loss at iteration 1320 : 0.010121584869921207
Loss at iteration 1330 : 0.010600058361887932
Loss at iteration 1340 : 0.005024556536227465
Loss at iteration 1350 : 0.009606700390577316
Loss at iteration 1360 : 0.004698231816291809
Loss at iteration 1370 : 0.008022308349609375
Loss at iteration 1380 : 0.005160859785974026
Loss at iteration 1390 : 0.007578616496175528
Loss at iteration 1400 : 0.0034384301397949457
Loss at iteration 1410 : 0.004564020317047834
Loss at iteration 1420 : 0.01266439352184534
Loss at iteration 1430 : 0.007414621766656637
Loss at iteration 1440 : 0.01022210530936718
Loss at iteration 1450 : 0.01661112532019615
Loss at iteration 1460 : 0.003056928515434265
Loss at iteration 1470 : 0.006054317578673363
Loss at iteration 1480 : 0.009028668515384197
Loss at iteration 1490 : 0.008345029316842556
Loss at iteration 1500 : 0.005895722191780806
Loss at iteration 1510 : 0.004516733810305595
Loss at iteration 1520 : 0.012732695788145065
Loss at iteration 1530 : 0.015551142394542694
Loss at iteration 1540 : 0.004940805956721306
Loss at iteration 1550 : 0.013222431764006615
Loss at iteration 1560 : 0.0033806785941123962
Loss at iteration 1570 : 0.009848656132817268
Loss at iteration 1580 : 0.0016485501546412706
Loss at iteration 1590 : 0.010055303573608398
Loss at iteration 1600 : 0.011826146394014359
Loss at iteration 1610 : 0.008903157897293568
Loss at iteration 1620 : 0.01713121123611927
Loss at iteration 1630 : 0.010388980619609356
Loss at iteration 1640 : 0.008833479136228561
Loss at iteration 1650 : 0.005889627616852522
Loss at iteration 1660 : 0.005142947658896446
Loss at iteration 1670 : 0.007170087657868862
Loss at iteration 1680 : 0.009008808992803097
Loss at iteration 1690 : 0.0082788011059165
Loss at iteration 1700 : 0.010187273845076561
Loss at iteration 1710 : 0.002344813197851181
Loss at iteration 1720 : 0.005478131119161844
Loss at iteration 1730 : 0.007899342104792595
Loss at iteration 1740 : 0.004699873272329569
Loss at iteration 1750 : 0.004968039225786924
Loss at iteration 1760 : 0.005262741819024086
Loss at iteration 1770 : 0.0056463200598955154
Loss at iteration 1780 : 0.0026618335396051407
Loss at iteration 1790 : 0.010441160760819912
Loss at iteration 1800 : 0.004103620070964098
Loss at iteration 1810 : 0.0065370830707252026
Loss at iteration 1820 : 0.01027788408100605
Loss at iteration 1830 : 0.008080477826297283
Loss at iteration 1840 : 0.0052408138290047646
Loss at iteration 1850 : 0.008640463463962078
Loss at iteration 1860 : 0.008806983008980751
Loss at iteration 1870 : 0.006230772472918034
Loss at iteration 1880 : 0.0039913044311106205
Loss at iteration 1890 : 0.008113481104373932
Loss at iteration 1900 : 0.009734497405588627
Loss at iteration 1910 : 0.007201852276921272
Loss at iteration 1920 : 0.011572502553462982
Loss at iteration 1930 : 0.012333791702985764
Loss at iteration 1940 : 0.007822811603546143
Loss at iteration 1950 : 0.011987997218966484
Loss at iteration 1960 : 0.012376763857901096
Loss at iteration 1970 : 0.007314257323741913
Loss at iteration 1980 : 0.00966204609721899
Loss at iteration 1990 : 0.005732322111725807
Loss at iteration 2000 : 0.005461958236992359
Loss at iteration 2010 : 0.008406832814216614
Loss at iteration 2020 : 0.004728407599031925
Loss at iteration 2030 : 0.007922856137156487
Loss at iteration 2040 : 0.006706452928483486
Loss at iteration 2050 : 0.014844464138150215
Loss at iteration 2060 : 0.006244406569749117
Loss at iteration 2070 : 0.008419720456004143
Loss at iteration 2080 : 0.008781247772276402
Loss at iteration 2090 : 0.010942085646092892
Loss at iteration 2100 : 0.009234610013663769
Loss at iteration 2110 : 0.007985872216522694
Loss at iteration 2120 : 0.00661246944218874
Loss at iteration 2130 : 0.007804483640938997
Loss at iteration 2140 : 0.005246602464467287
Loss at iteration 2150 : 0.013981189578771591
Loss at iteration 2160 : 0.0077841999009251595
Loss at iteration 2170 : 0.0075898622162640095
Loss at iteration 2180 : 0.010981537401676178
Loss at iteration 2190 : 0.012706934474408627
Loss at iteration 2200 : 0.016025161370635033
Loss at iteration 2210 : 0.006326412316411734
Loss at iteration 2220 : 0.009963770397007465
Loss at iteration 2230 : 0.006260927300900221
Loss at iteration 2240 : 0.010630400851368904
Loss at iteration 2250 : 0.011682514101266861
Loss at iteration 2260 : 0.014341343194246292
Loss at iteration 2270 : 0.005520355422049761
Loss at iteration 2280 : 0.004224844742566347
Loss at iteration 2290 : 0.01574244350194931
Loss at iteration 2300 : 0.011273138225078583
Loss at iteration 2310 : 0.013369604013860226
Loss at iteration 2320 : 0.00475298473611474
Loss at iteration 2330 : 0.003907964564859867
Loss at iteration 2340 : 0.005437410436570644
Loss at iteration 2350 : 0.006467269733548164
Loss at iteration 2360 : 0.0029177567921578884
Loss at iteration 2370 : 0.009883632883429527
Loss at iteration 2380 : 0.007531719282269478
Loss at iteration 2390 : 0.008077479898929596
Loss at iteration 2400 : 0.009198904037475586
Loss at iteration 2410 : 0.004944905173033476
Loss at iteration 2420 : 0.018071254715323448
The SSIM Value is: 0.8287581165631612
The PSNR Value is: 21.015755399068198
the epoch is: 113
Loss at iteration 10 : 0.010303199291229248
Loss at iteration 20 : 0.004609363153576851
Loss at iteration 30 : 0.005748484283685684
Loss at iteration 40 : 0.013787524774670601
Loss at iteration 50 : 0.02258792333304882
Loss at iteration 60 : 0.013407701626420021
Loss at iteration 70 : 0.009134052321314812
Loss at iteration 80 : 0.010217444971203804
Loss at iteration 90 : 0.011565853841602802
Loss at iteration 100 : 0.005931861698627472
Loss at iteration 110 : 0.012174556031823158
Loss at iteration 120 : 0.004691800568252802
Loss at iteration 130 : 0.004764343611896038
Loss at iteration 140 : 0.016490887850522995
Loss at iteration 150 : 0.008616587147116661
Loss at iteration 160 : 0.015883637592196465
Loss at iteration 170 : 0.006135471165180206
Loss at iteration 180 : 0.007716177962720394
Loss at iteration 190 : 0.008506618440151215
Loss at iteration 200 : 0.003049868391826749
Loss at iteration 210 : 0.010080832056701183
Loss at iteration 220 : 0.0048866961151361465
Loss at iteration 230 : 0.005617750342935324
Loss at iteration 240 : 0.006427611690014601
Loss at iteration 250 : 0.0059372312389314175
Loss at iteration 260 : 0.009860433638095856
Loss at iteration 270 : 0.004584010224789381
Loss at iteration 280 : 0.007032038643956184
Loss at iteration 290 : 0.003927674610167742
Loss at iteration 300 : 0.006786923389881849
Loss at iteration 310 : 0.0075464751571416855
Loss at iteration 320 : 0.0036681133788079023
Loss at iteration 330 : 0.011087358929216862
Loss at iteration 340 : 0.008108175359666348
Loss at iteration 350 : 0.014755217358469963
Loss at iteration 360 : 0.007932862266898155
Loss at iteration 370 : 0.007949653081595898
Loss at iteration 380 : 0.01004655659198761
Loss at iteration 390 : 0.005240325350314379
Loss at iteration 400 : 0.011011192575097084
Loss at iteration 410 : 0.017031017690896988
Loss at iteration 420 : 0.007100151386111975
Loss at iteration 430 : 0.0035385936498641968
Loss at iteration 440 : 0.009923772886395454
Loss at iteration 450 : 0.004486405290663242
Loss at iteration 460 : 0.008906815201044083
Loss at iteration 470 : 0.005662454757839441
Loss at iteration 480 : 0.004422301426529884
Loss at iteration 490 : 0.01200420968234539
Loss at iteration 500 : 0.008645356632769108
Loss at iteration 510 : 0.002574077807366848
Loss at iteration 520 : 0.010455486364662647
Loss at iteration 530 : 0.010738462209701538
Loss at iteration 540 : 0.006900596898049116
Loss at iteration 550 : 0.00465577095746994
Loss at iteration 560 : 0.003602443728595972
Loss at iteration 570 : 0.008759532123804092
Loss at iteration 580 : 0.009991006925702095
Loss at iteration 590 : 0.008135860785841942
Loss at iteration 600 : 0.012073952704668045
Loss at iteration 610 : 0.009238135069608688
Loss at iteration 620 : 0.007529225666075945
Loss at iteration 630 : 0.00993965845555067
Loss at iteration 640 : 0.009937752038240433
Loss at iteration 650 : 0.011881114915013313
Loss at iteration 660 : 0.003525492735207081
Loss at iteration 670 : 0.009639451280236244
Loss at iteration 680 : 0.0059280782006680965
Loss at iteration 690 : 0.01628047227859497
Loss at iteration 700 : 0.0048217251896858215
Loss at iteration 710 : 0.004309325944632292
Loss at iteration 720 : 0.007814359851181507
Loss at iteration 730 : 0.013790462166070938
Loss at iteration 740 : 0.007288758642971516
Loss at iteration 750 : 0.003869633888825774
Loss at iteration 760 : 0.008444796316325665
Loss at iteration 770 : 0.006080396473407745
Loss at iteration 780 : 0.005026572849601507
Loss at iteration 790 : 0.0051103997975587845
Loss at iteration 800 : 0.004557271022349596
Loss at iteration 810 : 0.011494483798742294
Loss at iteration 820 : 0.007177282590419054
Loss at iteration 830 : 0.004555387422442436
Loss at iteration 840 : 0.00991416722536087
Loss at iteration 850 : 0.004218739923089743
Loss at iteration 860 : 0.008429219014942646
Loss at iteration 870 : 0.014561318792402744
Loss at iteration 880 : 0.0046599614433944225
Loss at iteration 890 : 0.009159916080534458
Loss at iteration 900 : 0.007610308472067118
Loss at iteration 910 : 0.005456686019897461
Loss at iteration 920 : 0.012940413318574429
Loss at iteration 930 : 0.008109510876238346
Loss at iteration 940 : 0.011363795958459377
Loss at iteration 950 : 0.006901185493916273
Loss at iteration 960 : 0.016149695962667465
Loss at iteration 970 : 0.006460082717239857
Loss at iteration 980 : 0.009314371272921562
Loss at iteration 990 : 0.0053680515848100185
Loss at iteration 1000 : 0.00671528372913599
Loss at iteration 1010 : 0.009628796949982643
Loss at iteration 1020 : 0.005921059288084507
Loss at iteration 1030 : 0.005088686477392912
Loss at iteration 1040 : 0.0075149680487811565
Loss at iteration 1050 : 0.011292688548564911
Loss at iteration 1060 : 0.006503588519990444
Loss at iteration 1070 : 0.008398205041885376
Loss at iteration 1080 : 0.005150793120265007
Loss at iteration 1090 : 0.007254736497998238
Loss at iteration 1100 : 0.01912621222436428
Loss at iteration 1110 : 0.008795973844826221
Loss at iteration 1120 : 0.007389484904706478
Loss at iteration 1130 : 0.007271843496710062
Loss at iteration 1140 : 0.00833924300968647
Loss at iteration 1150 : 0.021460123360157013
Loss at iteration 1160 : 0.009317890740931034
Loss at iteration 1170 : 0.008945480920374393
Loss at iteration 1180 : 0.005420539062470198
Loss at iteration 1190 : 0.0051338826306164265
Loss at iteration 1200 : 0.0059236204251646996
Loss at iteration 1210 : 0.011407850310206413
Loss at iteration 1220 : 0.005364659242331982
Loss at iteration 1230 : 0.004611167125403881
Loss at iteration 1240 : 0.0078043281100690365
Loss at iteration 1250 : 0.0042490572668612
Loss at iteration 1260 : 0.002482784679159522
Loss at iteration 1270 : 0.006548404693603516
Loss at iteration 1280 : 0.007304996717721224
Loss at iteration 1290 : 0.013665682636201382
Loss at iteration 1300 : 0.0053696888498961926
Loss at iteration 1310 : 0.005720137618482113
Loss at iteration 1320 : 0.009365862235426903
Loss at iteration 1330 : 0.0023592826910316944
Loss at iteration 1340 : 0.008889987133443356
Loss at iteration 1350 : 0.004005339927971363
Loss at iteration 1360 : 0.013213420286774635
Loss at iteration 1370 : 0.006316438317298889
Loss at iteration 1380 : 0.007441728375852108
Loss at iteration 1390 : 0.007343776524066925
Loss at iteration 1400 : 0.0063162753358483315
Loss at iteration 1410 : 0.02535848133265972
Loss at iteration 1420 : 0.005729209631681442
Loss at iteration 1430 : 0.0061918762512505054
Loss at iteration 1440 : 0.007176259066909552
Loss at iteration 1450 : 0.013829322531819344
Loss at iteration 1460 : 0.007056687027215958
Loss at iteration 1470 : 0.0036369208246469498
Loss at iteration 1480 : 0.007624045945703983
Loss at iteration 1490 : 0.00524071604013443
Loss at iteration 1500 : 0.014033484272658825
Loss at iteration 1510 : 0.005564714781939983
Loss at iteration 1520 : 0.007121961563825607
Loss at iteration 1530 : 0.018527913838624954
Loss at iteration 1540 : 0.007622251287102699
Loss at iteration 1550 : 0.011581557802855968
Loss at iteration 1560 : 0.006044833920896053
Loss at iteration 1570 : 0.007422291673719883
Loss at iteration 1580 : 0.020527491346001625
Loss at iteration 1590 : 0.01259302906692028
Loss at iteration 1600 : 0.004413648974150419
Loss at iteration 1610 : 0.003936599008738995
Loss at iteration 1620 : 0.0055848159827291965
Loss at iteration 1630 : 0.00803217850625515
Loss at iteration 1640 : 0.011927133426070213
Loss at iteration 1650 : 0.006924344692379236
Loss at iteration 1660 : 0.009715230204164982
Loss at iteration 1670 : 0.02015249989926815
Loss at iteration 1680 : 0.010727595537900925
Loss at iteration 1690 : 0.005645000841468573
Loss at iteration 1700 : 0.013806209899485111
Loss at iteration 1710 : 0.008421534672379494
Loss at iteration 1720 : 0.003867716295644641
Loss at iteration 1730 : 0.004225239623337984
Loss at iteration 1740 : 0.013051949441432953
Loss at iteration 1750 : 0.0024852645583450794
Loss at iteration 1760 : 0.012758085504174232
Loss at iteration 1770 : 0.009130142629146576
Loss at iteration 1780 : 0.015287501737475395
Loss at iteration 1790 : 0.006200381554663181
Loss at iteration 1800 : 0.008867204189300537
Loss at iteration 1810 : 0.008734376169741154
Loss at iteration 1820 : 0.00630840053781867
Loss at iteration 1830 : 0.009980063885450363
Loss at iteration 1840 : 0.009583846665918827
Loss at iteration 1850 : 0.004806003998965025
Loss at iteration 1860 : 0.010490117594599724
Loss at iteration 1870 : 0.008289779536426067
Loss at iteration 1880 : 0.006872962228953838
Loss at iteration 1890 : 0.008621776476502419
Loss at iteration 1900 : 0.01653546281158924
Loss at iteration 1910 : 0.0045511177740991116
Loss at iteration 1920 : 0.008757833391427994
Loss at iteration 1930 : 0.008167802356183529
Loss at iteration 1940 : 0.009606493636965752
Loss at iteration 1950 : 0.012539633549749851
Loss at iteration 1960 : 0.003427353920415044
Loss at iteration 1970 : 0.01240414846688509
Loss at iteration 1980 : 0.01042751595377922
Loss at iteration 1990 : 0.007052951492369175
Loss at iteration 2000 : 0.01886880211532116
Loss at iteration 2010 : 0.00815786886960268
Loss at iteration 2020 : 0.004106942098587751
Loss at iteration 2030 : 0.014634046703577042
Loss at iteration 2040 : 0.015065984800457954
Loss at iteration 2050 : 0.00832018069922924
Loss at iteration 2060 : 0.010879116132855415
Loss at iteration 2070 : 0.007589172106236219
Loss at iteration 2080 : 0.014293797314167023
Loss at iteration 2090 : 0.010379446670413017
Loss at iteration 2100 : 0.003592926077544689
Loss at iteration 2110 : 0.011255886405706406
Loss at iteration 2120 : 0.003032553941011429
Loss at iteration 2130 : 0.004000624641776085
Loss at iteration 2140 : 0.009040339849889278
Loss at iteration 2150 : 0.00949148554354906
Loss at iteration 2160 : 0.008329346776008606
Loss at iteration 2170 : 0.011140253394842148
Loss at iteration 2180 : 0.019204474985599518
Loss at iteration 2190 : 0.005685345269739628
Loss at iteration 2200 : 0.009315692819654942
Loss at iteration 2210 : 0.011512350291013718
Loss at iteration 2220 : 0.02089601941406727
Loss at iteration 2230 : 0.01680929586291313
Loss at iteration 2240 : 0.010562739335000515
Loss at iteration 2250 : 0.006067067850381136
Loss at iteration 2260 : 0.004260873422026634
Loss at iteration 2270 : 0.00824582576751709
Loss at iteration 2280 : 0.005482300650328398
Loss at iteration 2290 : 0.004066417459398508
Loss at iteration 2300 : 0.00939848367124796
Loss at iteration 2310 : 0.008038980886340141
Loss at iteration 2320 : 0.004805722273886204
Loss at iteration 2330 : 0.0020943116396665573
Loss at iteration 2340 : 0.019846362993121147
Loss at iteration 2350 : 0.006613919045776129
Loss at iteration 2360 : 0.00607305159792304
Loss at iteration 2370 : 0.006533774547278881
Loss at iteration 2380 : 0.004164783749729395
Loss at iteration 2390 : 0.002626871457323432
Loss at iteration 2400 : 0.009077377617359161
Loss at iteration 2410 : 0.004758164752274752
Loss at iteration 2420 : 0.008255086839199066
The SSIM Value is: 0.8499690731366475
The PSNR Value is: 21.463979212443032
the epoch is: 114
Loss at iteration 10 : 0.013482208363711834
Loss at iteration 20 : 0.0032898467034101486
Loss at iteration 30 : 0.004841004032641649
Loss at iteration 40 : 0.004876997321844101
Loss at iteration 50 : 0.0029396931640803814
Loss at iteration 60 : 0.008322661742568016
Loss at iteration 70 : 0.0050512985326349735
Loss at iteration 80 : 0.00501605961471796
Loss at iteration 90 : 0.01786416955292225
Loss at iteration 100 : 0.0064789610914886
Loss at iteration 110 : 0.0033086526673287153
Loss at iteration 120 : 0.022990766912698746
Loss at iteration 130 : 0.01416088454425335
Loss at iteration 140 : 0.006283499766141176
Loss at iteration 150 : 0.006610956974327564
Loss at iteration 160 : 0.007704129442572594
Loss at iteration 170 : 0.005336516071110964
Loss at iteration 180 : 0.008243884891271591
Loss at iteration 190 : 0.008206144906580448
Loss at iteration 200 : 0.006174264941364527
Loss at iteration 210 : 0.006121926009654999
Loss at iteration 220 : 0.02046532742679119
Loss at iteration 230 : 0.007086348254233599
Loss at iteration 240 : 0.0038447307888418436
Loss at iteration 250 : 0.006603688467293978
Loss at iteration 260 : 0.014849104918539524
Loss at iteration 270 : 0.006795916706323624
Loss at iteration 280 : 0.005131191108375788
Loss at iteration 290 : 0.013842432759702206
Loss at iteration 300 : 0.007869456894695759
Loss at iteration 310 : 0.009544809348881245
Loss at iteration 320 : 0.005861991550773382
Loss at iteration 330 : 0.010184217244386673
Loss at iteration 340 : 0.005709152668714523
Loss at iteration 350 : 0.010241853073239326
Loss at iteration 360 : 0.006802530959248543
Loss at iteration 370 : 0.005521420389413834
Loss at iteration 380 : 0.007232758216559887
Loss at iteration 390 : 0.01023699901998043
Loss at iteration 400 : 0.004772653803229332
Loss at iteration 410 : 0.009619783610105515
Loss at iteration 420 : 0.01319988165050745
Loss at iteration 430 : 0.011705935001373291
Loss at iteration 440 : 0.006735516712069511
Loss at iteration 450 : 0.005719915498048067
Loss at iteration 460 : 0.013678883202373981
Loss at iteration 470 : 0.008263415656983852
Loss at iteration 480 : 0.003722232999280095
Loss at iteration 490 : 0.005559096112847328
Loss at iteration 500 : 0.008030874654650688
Loss at iteration 510 : 0.010011745616793633
Loss at iteration 520 : 0.013901697471737862
Loss at iteration 530 : 0.010432373732328415
Loss at iteration 540 : 0.007147064432501793
Loss at iteration 550 : 0.005139333661645651
Loss at iteration 560 : 0.006158878561109304
Loss at iteration 570 : 0.008669700473546982
Loss at iteration 580 : 0.005790637340396643
Loss at iteration 590 : 0.017241960391402245
Loss at iteration 600 : 0.003990677185356617
Loss at iteration 610 : 0.009153586812317371
Loss at iteration 620 : 0.005700428504496813
Loss at iteration 630 : 0.006179070565849543
Loss at iteration 640 : 0.0055152010172605515
Loss at iteration 650 : 0.0028352674562484026
Loss at iteration 660 : 0.0055698505602777
Loss at iteration 670 : 0.007965046912431717
Loss at iteration 680 : 0.013162853196263313
Loss at iteration 690 : 0.002389664528891444
Loss at iteration 700 : 0.00613638199865818
Loss at iteration 710 : 0.006473262794315815
Loss at iteration 720 : 0.011072838678956032
Loss at iteration 730 : 0.007811510935425758
Loss at iteration 740 : 0.006650031544268131
Loss at iteration 750 : 0.005342417396605015
Loss at iteration 760 : 0.008389895781874657
Loss at iteration 770 : 0.008055106736719608
Loss at iteration 780 : 0.007249891757965088
Loss at iteration 790 : 0.00504958676174283
Loss at iteration 800 : 0.011836271733045578
Loss at iteration 810 : 0.008111770264804363
Loss at iteration 820 : 0.005877852439880371
Loss at iteration 830 : 0.0049432492814958096
Loss at iteration 840 : 0.016346104443073273
Loss at iteration 850 : 0.010545583441853523
Loss at iteration 860 : 0.015642739832401276
Loss at iteration 870 : 0.00915481150150299
Loss at iteration 880 : 0.004438560456037521
Loss at iteration 890 : 0.015896376222372055
Loss at iteration 900 : 0.005988557823002338
Loss at iteration 910 : 0.01023394800722599
Loss at iteration 920 : 0.0029894292820245028
Loss at iteration 930 : 0.012378251180052757
Loss at iteration 940 : 0.006634980905801058
Loss at iteration 950 : 0.007776303216814995
Loss at iteration 960 : 0.007863994687795639
Loss at iteration 970 : 0.006247413344681263
Loss at iteration 980 : 0.01058986410498619
Loss at iteration 990 : 0.005549282766878605
Loss at iteration 1000 : 0.006248854100704193
Loss at iteration 1010 : 0.007498582359403372
Loss at iteration 1020 : 0.018220169469714165
Loss at iteration 1030 : 0.013266009278595448
Loss at iteration 1040 : 0.007166984491050243
Loss at iteration 1050 : 0.003824732732027769
Loss at iteration 1060 : 0.00471374299377203
Loss at iteration 1070 : 0.0056387316435575485
Loss at iteration 1080 : 0.007781168445944786
Loss at iteration 1090 : 0.01784977689385414
Loss at iteration 1100 : 0.005498157348483801
Loss at iteration 1110 : 0.008232238702476025
Loss at iteration 1120 : 0.011964978650212288
Loss at iteration 1130 : 0.005809464491903782
Loss at iteration 1140 : 0.010470828972756863
Loss at iteration 1150 : 0.00858230795711279
Loss at iteration 1160 : 0.0029940649401396513
Loss at iteration 1170 : 0.004693606868386269
Loss at iteration 1180 : 0.014444738626480103
Loss at iteration 1190 : 0.004571965429931879
Loss at iteration 1200 : 0.011547999456524849
Loss at iteration 1210 : 0.015054598450660706
Loss at iteration 1220 : 0.005540060810744762
Loss at iteration 1230 : 0.007692917715758085
Loss at iteration 1240 : 0.01708041876554489
Loss at iteration 1250 : 0.008110552094876766
Loss at iteration 1260 : 0.008482779376208782
Loss at iteration 1270 : 0.004340495448559523
Loss at iteration 1280 : 0.01027894951403141
Loss at iteration 1290 : 0.006247132085263729
Loss at iteration 1300 : 0.009584259241819382
Loss at iteration 1310 : 0.007078030612319708
Loss at iteration 1320 : 0.010377242229878902
Loss at iteration 1330 : 0.006091753952205181
Loss at iteration 1340 : 0.008061502128839493
Loss at iteration 1350 : 0.008097527548670769
Loss at iteration 1360 : 0.008263548836112022
Loss at iteration 1370 : 0.014473200775682926
Loss at iteration 1380 : 0.009141530841588974
Loss at iteration 1390 : 0.00668939296156168
Loss at iteration 1400 : 0.011791028082370758
Loss at iteration 1410 : 0.014096301980316639
Loss at iteration 1420 : 0.007958958856761456
Loss at iteration 1430 : 0.02061641588807106
Loss at iteration 1440 : 0.005873390939086676
Loss at iteration 1450 : 0.00928060058504343
Loss at iteration 1460 : 0.005137473810464144
Loss at iteration 1470 : 0.010344544425606728
Loss at iteration 1480 : 0.011398358270525932
Loss at iteration 1490 : 0.007886415347456932
Loss at iteration 1500 : 0.01664326712489128
Loss at iteration 1510 : 0.016601430252194405
Loss at iteration 1520 : 0.005806947126984596
Loss at iteration 1530 : 0.009969658218324184
Loss at iteration 1540 : 0.013213610276579857
Loss at iteration 1550 : 0.011380292475223541
Loss at iteration 1560 : 0.012957671657204628
Loss at iteration 1570 : 0.006287636235356331
Loss at iteration 1580 : 0.004549130331724882
Loss at iteration 1590 : 0.012410582974553108
Loss at iteration 1600 : 0.018037520349025726
Loss at iteration 1610 : 0.010329565033316612
Loss at iteration 1620 : 0.015086695551872253
Loss at iteration 1630 : 0.011182675138115883
Loss at iteration 1640 : 0.009781001135706902
Loss at iteration 1650 : 0.008491557091474533
Loss at iteration 1660 : 0.008665543049573898
Loss at iteration 1670 : 0.008524815551936626
Loss at iteration 1680 : 0.0045907399617135525
Loss at iteration 1690 : 0.004053107928484678
Loss at iteration 1700 : 0.004022984299808741
Loss at iteration 1710 : 0.008202281780540943
Loss at iteration 1720 : 0.005278902128338814
Loss at iteration 1730 : 0.0160321444272995
Loss at iteration 1740 : 0.007837467826902866
Loss at iteration 1750 : 0.007087303325533867
Loss at iteration 1760 : 0.009003623388707638
Loss at iteration 1770 : 0.007601847406476736
Loss at iteration 1780 : 0.008881335146725178
Loss at iteration 1790 : 0.006578140426427126
Loss at iteration 1800 : 0.011682534590363503
Loss at iteration 1810 : 0.00903741642832756
Loss at iteration 1820 : 0.010402538813650608
Loss at iteration 1830 : 0.006369784474372864
Loss at iteration 1840 : 0.008067525923252106
Loss at iteration 1850 : 0.007074879948049784
Loss at iteration 1860 : 0.006647573783993721
Loss at iteration 1870 : 0.007355093955993652
Loss at iteration 1880 : 0.006788927596062422
Loss at iteration 1890 : 0.01581430807709694
Loss at iteration 1900 : 0.009876346215605736
Loss at iteration 1910 : 0.00458860769867897
Loss at iteration 1920 : 0.0052751400507986546
Loss at iteration 1930 : 0.0061474391259253025
Loss at iteration 1940 : 0.0037219745572656393
Loss at iteration 1950 : 0.01214323379099369
Loss at iteration 1960 : 0.011162159964442253
Loss at iteration 1970 : 0.009094740264117718
Loss at iteration 1980 : 0.0025525928940624
Loss at iteration 1990 : 0.00857122614979744
Loss at iteration 2000 : 0.008847548626363277
Loss at iteration 2010 : 0.00825142115354538
Loss at iteration 2020 : 0.007717397529631853
Loss at iteration 2030 : 0.008849797770380974
Loss at iteration 2040 : 0.007723617367446423
Loss at iteration 2050 : 0.007619570475071669
Loss at iteration 2060 : 0.007524305954575539
Loss at iteration 2070 : 0.005337466485798359
Loss at iteration 2080 : 0.0062942360527813435
Loss at iteration 2090 : 0.009441554546356201
Loss at iteration 2100 : 0.00836586207151413
Loss at iteration 2110 : 0.0030306093394756317
Loss at iteration 2120 : 0.006863238289952278
Loss at iteration 2130 : 0.007266703061759472
Loss at iteration 2140 : 0.00815678108483553
Loss at iteration 2150 : 0.007030019536614418
Loss at iteration 2160 : 0.013814417645335197
Loss at iteration 2170 : 0.010775224305689335
Loss at iteration 2180 : 0.0102585693821311
Loss at iteration 2190 : 0.004605147987604141
Loss at iteration 2200 : 0.006480038166046143
Loss at iteration 2210 : 0.0037182990927249193
Loss at iteration 2220 : 0.007415647618472576
Loss at iteration 2230 : 0.009726116433739662
Loss at iteration 2240 : 0.008586127310991287
Loss at iteration 2250 : 0.006145989056676626
Loss at iteration 2260 : 0.009039049968123436
Loss at iteration 2270 : 0.004600370768457651
Loss at iteration 2280 : 0.004962971433997154
Loss at iteration 2290 : 0.01046261191368103
Loss at iteration 2300 : 0.008161771111190319
Loss at iteration 2310 : 0.00897905696183443
Loss at iteration 2320 : 0.0016421277541667223
Loss at iteration 2330 : 0.010247806087136269
Loss at iteration 2340 : 0.004872701596468687
Loss at iteration 2350 : 0.011217843741178513
Loss at iteration 2360 : 0.007346099242568016
Loss at iteration 2370 : 0.011084413155913353
Loss at iteration 2380 : 0.0026573161594569683
Loss at iteration 2390 : 0.006170439999550581
Loss at iteration 2400 : 0.0037006642669439316
Loss at iteration 2410 : 0.007630211301147938
Loss at iteration 2420 : 0.007990490645170212
The SSIM Value is: 0.8450820406277975
The PSNR Value is: 22.025743548075358
the epoch is: 115
Loss at iteration 10 : 0.006220536306500435
Loss at iteration 20 : 0.009830635040998459
Loss at iteration 30 : 0.007145534735172987
Loss at iteration 40 : 0.008521918207406998
Loss at iteration 50 : 0.010089597664773464
Loss at iteration 60 : 0.007396576926112175
Loss at iteration 70 : 0.006988338194787502
Loss at iteration 80 : 0.00944712944328785
Loss at iteration 90 : 0.006547672674059868
Loss at iteration 100 : 0.005677270703017712
Loss at iteration 110 : 0.00981917418539524
Loss at iteration 120 : 0.008817176334559917
Loss at iteration 130 : 0.014278543181717396
Loss at iteration 140 : 0.007997645996510983
Loss at iteration 150 : 0.005400161724537611
Loss at iteration 160 : 0.007119855377823114
Loss at iteration 170 : 0.007544552907347679
Loss at iteration 180 : 0.007872864603996277
Loss at iteration 190 : 0.003706300863996148
Loss at iteration 200 : 0.007994714193046093
Loss at iteration 210 : 0.008696884848177433
Loss at iteration 220 : 0.004520857706665993
Loss at iteration 230 : 0.005705071613192558
Loss at iteration 240 : 0.005740228109061718
Loss at iteration 250 : 0.007183554116636515
Loss at iteration 260 : 0.00481491070240736
Loss at iteration 270 : 0.004245634190738201
Loss at iteration 280 : 0.00736713781952858
Loss at iteration 290 : 0.011037943884730339
Loss at iteration 300 : 0.034263383597135544
Loss at iteration 310 : 0.004743258468806744
Loss at iteration 320 : 0.005463839508593082
Loss at iteration 330 : 0.013540193438529968
Loss at iteration 340 : 0.0030377604998648167
Loss at iteration 350 : 0.004238127265125513
Loss at iteration 360 : 0.004111188929527998
Loss at iteration 370 : 0.0025295745581388474
Loss at iteration 380 : 0.00554370554164052
Loss at iteration 390 : 0.0053212083876132965
Loss at iteration 400 : 0.005056598223745823
Loss at iteration 410 : 0.0076886811293661594
Loss at iteration 420 : 0.004953861236572266
Loss at iteration 430 : 0.009795883670449257
Loss at iteration 440 : 0.007326491177082062
Loss at iteration 450 : 0.005444458220154047
Loss at iteration 460 : 0.013814507983624935
Loss at iteration 470 : 0.008087742142379284
Loss at iteration 480 : 0.006680943071842194
Loss at iteration 490 : 0.004741124343127012
Loss at iteration 500 : 0.007008719723671675
Loss at iteration 510 : 0.00863917637616396
Loss at iteration 520 : 0.01899273507297039
Loss at iteration 530 : 0.014411546289920807
Loss at iteration 540 : 0.008463717997074127
Loss at iteration 550 : 0.006070824805647135
Loss at iteration 560 : 0.005370611324906349
Loss at iteration 570 : 0.0038367509841918945
Loss at iteration 580 : 0.0056503876112401485
Loss at iteration 590 : 0.008994538336992264
Loss at iteration 600 : 0.004853137768805027
Loss at iteration 610 : 0.0114505086094141
Loss at iteration 620 : 0.03204325586557388
Loss at iteration 630 : 0.008179567754268646
Loss at iteration 640 : 0.009008887223899364
Loss at iteration 650 : 0.014048630371689796
Loss at iteration 660 : 0.008224905468523502
Loss at iteration 670 : 0.01065780594944954
Loss at iteration 680 : 0.003973389510065317
Loss at iteration 690 : 0.018172042444348335
Loss at iteration 700 : 0.009270183742046356
Loss at iteration 710 : 0.00903196632862091
Loss at iteration 720 : 0.007573044393211603
Loss at iteration 730 : 0.007895898073911667
Loss at iteration 740 : 0.011013912037014961
Loss at iteration 750 : 0.013049046508967876
Loss at iteration 760 : 0.005442894995212555
Loss at iteration 770 : 0.003343777498230338
Loss at iteration 780 : 0.008088994771242142
Loss at iteration 790 : 0.00695760315284133
Loss at iteration 800 : 0.0112899299710989
Loss at iteration 810 : 0.006971961818635464
Loss at iteration 820 : 0.008093167096376419
Loss at iteration 830 : 0.0054597011767327785
Loss at iteration 840 : 0.0016418989980593324
Loss at iteration 850 : 0.004455283749848604
Loss at iteration 860 : 0.014213593676686287
Loss at iteration 870 : 0.007377251982688904
Loss at iteration 880 : 0.0035482451785355806
Loss at iteration 890 : 0.0070988452062010765
Loss at iteration 900 : 0.01599212922155857
Loss at iteration 910 : 0.008084313943982124
Loss at iteration 920 : 0.004382303915917873
Loss at iteration 930 : 0.009154999628663063
Loss at iteration 940 : 0.006534777116030455
Loss at iteration 950 : 0.007481752894818783
Loss at iteration 960 : 0.007568682543933392
Loss at iteration 970 : 0.012216554023325443
Loss at iteration 980 : 0.015690604224801064
Loss at iteration 990 : 0.005949861835688353
Loss at iteration 1000 : 0.008691195398569107
Loss at iteration 1010 : 0.009633118286728859
Loss at iteration 1020 : 0.011662887409329414
Loss at iteration 1030 : 0.014298936352133751
Loss at iteration 1040 : 0.012155544944107533
Loss at iteration 1050 : 0.009269487112760544
Loss at iteration 1060 : 0.008662795647978783
Loss at iteration 1070 : 0.0064928047358989716
Loss at iteration 1080 : 0.003729891497641802
Loss at iteration 1090 : 0.005177865270525217
Loss at iteration 1100 : 0.012533050030469894
Loss at iteration 1110 : 0.01029166392982006
Loss at iteration 1120 : 0.008159799501299858
Loss at iteration 1130 : 0.005911920219659805
Loss at iteration 1140 : 0.008158503100275993
Loss at iteration 1150 : 0.008720191195607185
Loss at iteration 1160 : 0.009181324392557144
Loss at iteration 1170 : 0.022209124639630318
Loss at iteration 1180 : 0.015442783012986183
Loss at iteration 1190 : 0.019190531224012375
Loss at iteration 1200 : 0.011997690424323082
Loss at iteration 1210 : 0.0031743727158755064
Loss at iteration 1220 : 0.010303635150194168
Loss at iteration 1230 : 0.010197729803621769
Loss at iteration 1240 : 0.004736984148621559
Loss at iteration 1250 : 0.0144229456782341
Loss at iteration 1260 : 0.006048072595149279
Loss at iteration 1270 : 0.007147645577788353
Loss at iteration 1280 : 0.006676145829260349
Loss at iteration 1290 : 0.013287559151649475
Loss at iteration 1300 : 0.0034474129788577557
Loss at iteration 1310 : 0.010783894918859005
Loss at iteration 1320 : 0.0035828398540616035
Loss at iteration 1330 : 0.0130523182451725
Loss at iteration 1340 : 0.001484565087594092
Loss at iteration 1350 : 0.011263715103268623
Loss at iteration 1360 : 0.01224089227616787
Loss at iteration 1370 : 0.010678946040570736
Loss at iteration 1380 : 0.007756935898214579
Loss at iteration 1390 : 0.008491615764796734
Loss at iteration 1400 : 0.004980106838047504
Loss at iteration 1410 : 0.009914491325616837
Loss at iteration 1420 : 0.025329548865556717
Loss at iteration 1430 : 0.007418517023324966
Loss at iteration 1440 : 0.013017406687140465
Loss at iteration 1450 : 0.009669462218880653
Loss at iteration 1460 : 0.0051697236485779285
Loss at iteration 1470 : 0.008049658499658108
Loss at iteration 1480 : 0.006124616600573063
Loss at iteration 1490 : 0.011862401850521564
Loss at iteration 1500 : 0.008545128628611565
Loss at iteration 1510 : 0.012969721108675003
Loss at iteration 1520 : 0.005780098028481007
Loss at iteration 1530 : 0.010703101754188538
Loss at iteration 1540 : 0.010683570057153702
Loss at iteration 1550 : 0.008695663884282112
Loss at iteration 1560 : 0.0066285692155361176
Loss at iteration 1570 : 0.011151619255542755
Loss at iteration 1580 : 0.012315153144299984
Loss at iteration 1590 : 0.027858803048729897
Loss at iteration 1600 : 0.012694653123617172
Loss at iteration 1610 : 0.008592143654823303
Loss at iteration 1620 : 0.01925196684896946
Loss at iteration 1630 : 0.02213883213698864
Loss at iteration 1640 : 0.016832465305924416
Loss at iteration 1650 : 0.017669618129730225
Loss at iteration 1660 : 0.00890257302671671
Loss at iteration 1670 : 0.005936717614531517
Loss at iteration 1680 : 0.02241528406739235
Loss at iteration 1690 : 0.007547857239842415
Loss at iteration 1700 : 0.007466351613402367
Loss at iteration 1710 : 0.00989523809403181
Loss at iteration 1720 : 0.020397167652845383
Loss at iteration 1730 : 0.007313494570553303
Loss at iteration 1740 : 0.018206952139735222
Loss at iteration 1750 : 0.007472135126590729
Loss at iteration 1760 : 0.008588193915784359
Loss at iteration 1770 : 0.009734462015330791
Loss at iteration 1780 : 0.007001146674156189
Loss at iteration 1790 : 0.022200502455234528
Loss at iteration 1800 : 0.005437485873699188
Loss at iteration 1810 : 0.006257205735892057
Loss at iteration 1820 : 0.021334150806069374
Loss at iteration 1830 : 0.004832115024328232
Loss at iteration 1840 : 0.0039733778685331345
Loss at iteration 1850 : 0.00726680364459753
Loss at iteration 1860 : 0.01974901370704174
Loss at iteration 1870 : 0.011761832050979137
Loss at iteration 1880 : 0.014206523075699806
Loss at iteration 1890 : 0.010278912261128426
Loss at iteration 1900 : 0.016022078692913055
Loss at iteration 1910 : 0.01621287316083908
Loss at iteration 1920 : 0.007896973751485348
Loss at iteration 1930 : 0.01199842244386673
Loss at iteration 1940 : 0.00955328531563282
Loss at iteration 1950 : 0.01210777647793293
Loss at iteration 1960 : 0.012075870297849178
Loss at iteration 1970 : 0.009992687031626701
Loss at iteration 1980 : 0.012643215246498585
Loss at iteration 1990 : 0.012844696640968323
Loss at iteration 2000 : 0.012665562331676483
Loss at iteration 2010 : 0.011732785031199455
Loss at iteration 2020 : 0.01609877683222294
Loss at iteration 2030 : 0.013604815118014812
Loss at iteration 2040 : 0.008622168563306332
Loss at iteration 2050 : 0.006662668660283089
Loss at iteration 2060 : 0.03354492411017418
Loss at iteration 2070 : 0.0199822299182415
Loss at iteration 2080 : 0.0076836226508021355
Loss at iteration 2090 : 0.011866849847137928
Loss at iteration 2100 : 0.01708538830280304
Loss at iteration 2110 : 0.014003114774823189
Loss at iteration 2120 : 0.025554373860359192
Loss at iteration 2130 : 0.00963984802365303
Loss at iteration 2140 : 0.005290884990245104
Loss at iteration 2150 : 0.014580309391021729
Loss at iteration 2160 : 0.005580628290772438
Loss at iteration 2170 : 0.006447252351790667
Loss at iteration 2180 : 0.008331198245286942
Loss at iteration 2190 : 0.0036343862302601337
Loss at iteration 2200 : 0.004287053365260363
Loss at iteration 2210 : 0.007945582270622253
Loss at iteration 2220 : 0.006550035439431667
Loss at iteration 2230 : 0.005197012331336737
Loss at iteration 2240 : 0.0052776033990085125
Loss at iteration 2250 : 0.009064586833119392
Loss at iteration 2260 : 0.006136755459010601
Loss at iteration 2270 : 0.006779992952942848
Loss at iteration 2280 : 0.00644890358671546
Loss at iteration 2290 : 0.015128538012504578
Loss at iteration 2300 : 0.013496432453393936
Loss at iteration 2310 : 0.005676122382283211
Loss at iteration 2320 : 0.005299302749335766
Loss at iteration 2330 : 0.005361621268093586
Loss at iteration 2340 : 0.007620080839842558
Loss at iteration 2350 : 0.008592061698436737
Loss at iteration 2360 : 0.01596774160861969
Loss at iteration 2370 : 0.01269941870123148
Loss at iteration 2380 : 0.016310349106788635
Loss at iteration 2390 : 0.013932356610894203
Loss at iteration 2400 : 0.011669696308672428
Loss at iteration 2410 : 0.012272492982447147
Loss at iteration 2420 : 0.003760590450838208
The SSIM Value is: 0.846482515335083
The PSNR Value is: 22.528576596577963
the epoch is: 116
Loss at iteration 10 : 0.005485932808369398
Loss at iteration 20 : 0.00538606708869338
Loss at iteration 30 : 0.007292150054126978
Loss at iteration 40 : 0.006614407058805227
Loss at iteration 50 : 0.01052877027541399
Loss at iteration 60 : 0.005063062533736229
Loss at iteration 70 : 0.014356400817632675
Loss at iteration 80 : 0.01389184407889843
Loss at iteration 90 : 0.013620087876915932
Loss at iteration 100 : 0.006420557852834463
Loss at iteration 110 : 0.004642733372747898
Loss at iteration 120 : 0.03181146830320358
Loss at iteration 130 : 0.00539357028901577
Loss at iteration 140 : 0.009692483581602573
Loss at iteration 150 : 0.00996899139136076
Loss at iteration 160 : 0.00579083152115345
Loss at iteration 170 : 0.008182410150766373
Loss at iteration 180 : 0.016099214553833008
Loss at iteration 190 : 0.005122589413076639
Loss at iteration 200 : 0.0025755332317203283
Loss at iteration 210 : 0.006830966100096703
Loss at iteration 220 : 0.015529239550232887
Loss at iteration 230 : 0.011670703999698162
Loss at iteration 240 : 0.005239584483206272
Loss at iteration 250 : 0.002963019534945488
Loss at iteration 260 : 0.0167516078799963
Loss at iteration 270 : 0.010517539456486702
Loss at iteration 280 : 0.007186255417764187
Loss at iteration 290 : 0.004340882878750563
Loss at iteration 300 : 0.005073340144008398
Loss at iteration 310 : 0.011097722686827183
Loss at iteration 320 : 0.007439569570124149
Loss at iteration 330 : 0.007813405245542526
Loss at iteration 340 : 0.005974540952593088
Loss at iteration 350 : 0.006951170042157173
Loss at iteration 360 : 0.004117314703762531
Loss at iteration 370 : 0.008333006873726845
Loss at iteration 380 : 0.011788805015385151
Loss at iteration 390 : 0.005417189560830593
Loss at iteration 400 : 0.014181037433445454
Loss at iteration 410 : 0.006604881025850773
Loss at iteration 420 : 0.0032526555005460978
Loss at iteration 430 : 0.008547003380954266
Loss at iteration 440 : 0.008073421195149422
Loss at iteration 450 : 0.005347513128072023
Loss at iteration 460 : 0.005920645780861378
Loss at iteration 470 : 0.006026699207723141
Loss at iteration 480 : 0.008235109969973564
Loss at iteration 490 : 0.0067431130446493626
Loss at iteration 500 : 0.002130478387698531
Loss at iteration 510 : 0.006571928039193153
Loss at iteration 520 : 0.00890069454908371
Loss at iteration 530 : 0.0038232041988521814
Loss at iteration 540 : 0.011162416078150272
Loss at iteration 550 : 0.0065076276659965515
Loss at iteration 560 : 0.005463363602757454
Loss at iteration 570 : 0.012909628450870514
Loss at iteration 580 : 0.007026434410363436
Loss at iteration 590 : 0.008409971371293068
Loss at iteration 600 : 0.0058121830224990845
Loss at iteration 610 : 0.007899891585111618
Loss at iteration 620 : 0.009208622388541698
Loss at iteration 630 : 0.0068893274292349815
Loss at iteration 640 : 0.00862064678221941
Loss at iteration 650 : 0.01187960710376501
Loss at iteration 660 : 0.008683672174811363
Loss at iteration 670 : 0.011408369988203049
Loss at iteration 680 : 0.009837618097662926
Loss at iteration 690 : 0.0034103109501302242
Loss at iteration 700 : 0.007934261113405228
Loss at iteration 710 : 0.008504858240485191
Loss at iteration 720 : 0.017956310883164406
Loss at iteration 730 : 0.007320858538150787
Loss at iteration 740 : 0.005575214978307486
Loss at iteration 750 : 0.0035836673341691494
Loss at iteration 760 : 0.007875640876591206
Loss at iteration 770 : 0.014487219974398613
Loss at iteration 780 : 0.008859899826347828
Loss at iteration 790 : 0.0024491059593856335
Loss at iteration 800 : 0.007275752257555723
Loss at iteration 810 : 0.013798817992210388
Loss at iteration 820 : 0.006554401479661465
Loss at iteration 830 : 0.0135616110637784
Loss at iteration 840 : 0.014169418253004551
Loss at iteration 850 : 0.0020069770980626345
Loss at iteration 860 : 0.00586620531976223
Loss at iteration 870 : 0.009286027401685715
Loss at iteration 880 : 0.007268039509654045
Loss at iteration 890 : 0.007314359303563833
Loss at iteration 900 : 0.023792335763573647
Loss at iteration 910 : 0.005126099102199078
Loss at iteration 920 : 0.008654003031551838
Loss at iteration 930 : 0.008028203621506691
Loss at iteration 940 : 0.008737673051655293
Loss at iteration 950 : 0.021953700110316277
Loss at iteration 960 : 0.006892407778650522
Loss at iteration 970 : 0.005192004609853029
Loss at iteration 980 : 0.012801729142665863
Loss at iteration 990 : 0.002318374579772353
Loss at iteration 1000 : 0.007503090426325798
Loss at iteration 1010 : 0.005454773083329201
Loss at iteration 1020 : 0.007545643486082554
Loss at iteration 1030 : 0.0049132537096738815
Loss at iteration 1040 : 0.009822518564760685
Loss at iteration 1050 : 0.006242059636861086
Loss at iteration 1060 : 0.008934319019317627
Loss at iteration 1070 : 0.008168931119143963
Loss at iteration 1080 : 0.013363376259803772
Loss at iteration 1090 : 0.004715179093182087
Loss at iteration 1100 : 0.0059882961213588715
Loss at iteration 1110 : 0.0038461314979940653
Loss at iteration 1120 : 0.007900848984718323
Loss at iteration 1130 : 0.015224404633045197
Loss at iteration 1140 : 0.02002560906112194
Loss at iteration 1150 : 0.011129466816782951
Loss at iteration 1160 : 0.006149759981781244
Loss at iteration 1170 : 0.007482285611331463
Loss at iteration 1180 : 0.014286864548921585
Loss at iteration 1190 : 0.008368698880076408
Loss at iteration 1200 : 0.01252057310193777
Loss at iteration 1210 : 0.010820127092301846
Loss at iteration 1220 : 0.009800359606742859
Loss at iteration 1230 : 0.016085609793663025
Loss at iteration 1240 : 0.0126511100679636
Loss at iteration 1250 : 0.011903736740350723
Loss at iteration 1260 : 0.004681522026658058
Loss at iteration 1270 : 0.009185714647173882
Loss at iteration 1280 : 0.008140100166201591
Loss at iteration 1290 : 0.005323026329278946
Loss at iteration 1300 : 0.007516162469983101
Loss at iteration 1310 : 0.008845659904181957
Loss at iteration 1320 : 0.006289207376539707
Loss at iteration 1330 : 0.0062431516125798225
Loss at iteration 1340 : 0.004055249039083719
Loss at iteration 1350 : 0.005970856174826622
Loss at iteration 1360 : 0.016419799998402596
Loss at iteration 1370 : 0.009441310539841652
Loss at iteration 1380 : 0.0179890226572752
Loss at iteration 1390 : 0.007868349552154541
Loss at iteration 1400 : 0.010875433683395386
Loss at iteration 1410 : 0.017204243689775467
Loss at iteration 1420 : 0.004262708127498627
Loss at iteration 1430 : 0.00867206696420908
Loss at iteration 1440 : 0.01296490989625454
Loss at iteration 1450 : 0.009481986984610558
Loss at iteration 1460 : 0.00687056127935648
Loss at iteration 1470 : 0.013684872537851334
Loss at iteration 1480 : 0.010910212062299252
Loss at iteration 1490 : 0.03308607265353203
Loss at iteration 1500 : 0.008280912414193153
Loss at iteration 1510 : 0.005275914911180735
Loss at iteration 1520 : 0.00477842940017581
Loss at iteration 1530 : 0.002728881314396858
Loss at iteration 1540 : 0.011890580877661705
Loss at iteration 1550 : 0.013460292480885983
Loss at iteration 1560 : 0.005125388503074646
Loss at iteration 1570 : 0.0060500469990074635
Loss at iteration 1580 : 0.010946471244096756
Loss at iteration 1590 : 0.011434689164161682
Loss at iteration 1600 : 0.007822349667549133
Loss at iteration 1610 : 0.007607600186020136
Loss at iteration 1620 : 0.0028488277457654476
Loss at iteration 1630 : 0.01206266786903143
Loss at iteration 1640 : 0.018217163160443306
Loss at iteration 1650 : 0.007780872751027346
Loss at iteration 1660 : 0.010196183808147907
Loss at iteration 1670 : 0.007988164201378822
Loss at iteration 1680 : 0.00585638452321291
Loss at iteration 1690 : 0.007549553643912077
Loss at iteration 1700 : 0.012941938824951649
Loss at iteration 1710 : 0.010559502989053726
Loss at iteration 1720 : 0.009629444219172001
Loss at iteration 1730 : 0.0039480640552937984
Loss at iteration 1740 : 0.0076088327914476395
Loss at iteration 1750 : 0.009819195605814457
Loss at iteration 1760 : 0.015255596488714218
Loss at iteration 1770 : 0.012424923479557037
Loss at iteration 1780 : 0.017015937715768814
Loss at iteration 1790 : 0.009632640518248081
Loss at iteration 1800 : 0.010690143331885338
Loss at iteration 1810 : 0.005700265057384968
Loss at iteration 1820 : 0.004797281697392464
Loss at iteration 1830 : 0.004618535749614239
Loss at iteration 1840 : 0.01432211697101593
Loss at iteration 1850 : 0.005760107655078173
Loss at iteration 1860 : 0.004011209588497877
Loss at iteration 1870 : 0.005881702993065119
Loss at iteration 1880 : 0.008782644756138325
Loss at iteration 1890 : 0.007718189619481564
Loss at iteration 1900 : 0.013561571016907692
Loss at iteration 1910 : 0.0026572744827717543
Loss at iteration 1920 : 0.010080775246024132
Loss at iteration 1930 : 0.017504166811704636
Loss at iteration 1940 : 0.012690991163253784
Loss at iteration 1950 : 0.007922505959868431
Loss at iteration 1960 : 0.008848934434354305
Loss at iteration 1970 : 0.023175310343503952
Loss at iteration 1980 : 0.013656402006745338
Loss at iteration 1990 : 0.0050263903103768826
Loss at iteration 2000 : 0.013013112358748913
Loss at iteration 2010 : 0.01935441792011261
Loss at iteration 2020 : 0.00867617316544056
Loss at iteration 2030 : 0.015183163806796074
Loss at iteration 2040 : 0.0039939479902386665
Loss at iteration 2050 : 0.008699038997292519
Loss at iteration 2060 : 0.016855895519256592
Loss at iteration 2070 : 0.013816475868225098
Loss at iteration 2080 : 0.011493176221847534
Loss at iteration 2090 : 0.0075379060581326485
Loss at iteration 2100 : 0.017885180190205574
Loss at iteration 2110 : 0.00506760086864233
Loss at iteration 2120 : 0.008288605138659477
Loss at iteration 2130 : 0.016165923327207565
Loss at iteration 2140 : 0.00874838326126337
Loss at iteration 2150 : 0.011108167469501495
Loss at iteration 2160 : 0.0073024616576731205
Loss at iteration 2170 : 0.0070393565110862255
Loss at iteration 2180 : 0.015035432763397694
Loss at iteration 2190 : 0.013741087168455124
Loss at iteration 2200 : 0.018321456387639046
Loss at iteration 2210 : 0.009814893826842308
Loss at iteration 2220 : 0.010256301611661911
Loss at iteration 2230 : 0.011624149046838284
Loss at iteration 2240 : 0.022993452847003937
Loss at iteration 2250 : 0.007118671201169491
Loss at iteration 2260 : 0.01408668328076601
Loss at iteration 2270 : 0.01125792134553194
Loss at iteration 2280 : 0.011446251533925533
Loss at iteration 2290 : 0.018520060926675797
Loss at iteration 2300 : 0.009854750707745552
Loss at iteration 2310 : 0.005581557285040617
Loss at iteration 2320 : 0.011487185023725033
Loss at iteration 2330 : 0.00934130884706974
Loss at iteration 2340 : 0.00526039581745863
Loss at iteration 2350 : 0.003319880459457636
Loss at iteration 2360 : 0.009236748330295086
Loss at iteration 2370 : 0.00940103642642498
Loss at iteration 2380 : 0.015027487650513649
Loss at iteration 2390 : 0.010981485247612
Loss at iteration 2400 : 0.0025901461485773325
Loss at iteration 2410 : 0.009054703637957573
Loss at iteration 2420 : 0.006901733577251434
The SSIM Value is: 0.8418316046396891
The PSNR Value is: 21.928977330525715
the epoch is: 117
Loss at iteration 10 : 0.012334655970335007
Loss at iteration 20 : 0.0060971928760409355
Loss at iteration 30 : 0.007022084202617407
Loss at iteration 40 : 0.008823965676128864
Loss at iteration 50 : 0.010671829804778099
Loss at iteration 60 : 0.010067121125757694
Loss at iteration 70 : 0.01628255657851696
Loss at iteration 80 : 0.009289887733757496
Loss at iteration 90 : 0.009387909434735775
Loss at iteration 100 : 0.012748914770781994
Loss at iteration 110 : 0.006967131979763508
Loss at iteration 120 : 0.006905101705342531
Loss at iteration 130 : 0.009181085042655468
Loss at iteration 140 : 0.0072141713462769985
Loss at iteration 150 : 0.006057775113731623
Loss at iteration 160 : 0.006153345573693514
Loss at iteration 170 : 0.007933449931442738
Loss at iteration 180 : 0.007133830338716507
Loss at iteration 190 : 0.005162299610674381
Loss at iteration 200 : 0.005070718005299568
Loss at iteration 210 : 0.005780079402029514
Loss at iteration 220 : 0.012391353957355022
Loss at iteration 230 : 0.011616356670856476
Loss at iteration 240 : 0.01846359856426716
Loss at iteration 250 : 0.003717083716765046
Loss at iteration 260 : 0.012312388978898525
Loss at iteration 270 : 0.005401397589594126
Loss at iteration 280 : 0.010497010312974453
Loss at iteration 290 : 0.015005982480943203
Loss at iteration 300 : 0.004132326226681471
Loss at iteration 310 : 0.006571656093001366
Loss at iteration 320 : 0.01135861873626709
Loss at iteration 330 : 0.007959441281855106
Loss at iteration 340 : 0.00582351116463542
Loss at iteration 350 : 0.005436447914689779
Loss at iteration 360 : 0.009838102385401726
Loss at iteration 370 : 0.016619088128209114
Loss at iteration 380 : 0.0078079309314489365
Loss at iteration 390 : 0.0032856601756066084
Loss at iteration 400 : 0.008288312703371048
Loss at iteration 410 : 0.009679651819169521
Loss at iteration 420 : 0.0038010957650840282
Loss at iteration 430 : 0.011797674931585789
Loss at iteration 440 : 0.005281739868223667
Loss at iteration 450 : 0.009441214613616467
Loss at iteration 460 : 0.0021451860666275024
Loss at iteration 470 : 0.01281819213181734
Loss at iteration 480 : 0.006272048689424992
Loss at iteration 490 : 0.008906122297048569
Loss at iteration 500 : 0.004714323207736015
Loss at iteration 510 : 0.008968072012066841
Loss at iteration 520 : 0.007540819235146046
Loss at iteration 530 : 0.011610867455601692
Loss at iteration 540 : 0.01733960583806038
Loss at iteration 550 : 0.009506436996161938
Loss at iteration 560 : 0.008423968218266964
Loss at iteration 570 : 0.016027551144361496
Loss at iteration 580 : 0.008840992115437984
Loss at iteration 590 : 0.008312420919537544
Loss at iteration 600 : 0.0032316199503839016
Loss at iteration 610 : 0.005963165778666735
Loss at iteration 620 : 0.005405910778790712
Loss at iteration 630 : 0.009173611178994179
Loss at iteration 640 : 0.00779791921377182
Loss at iteration 650 : 0.013165101408958435
Loss at iteration 660 : 0.005763705354183912
Loss at iteration 670 : 0.003485920839011669
Loss at iteration 680 : 0.014395828358829021
Loss at iteration 690 : 0.007047620601952076
Loss at iteration 700 : 0.009560711681842804
Loss at iteration 710 : 0.006413237191736698
Loss at iteration 720 : 0.007831897586584091
Loss at iteration 730 : 0.024211280047893524
Loss at iteration 740 : 0.007362589240074158
Loss at iteration 750 : 0.0018471239600330591
Loss at iteration 760 : 0.006559343077242374
Loss at iteration 770 : 0.0037011466920375824
Loss at iteration 780 : 0.011618785560131073
Loss at iteration 790 : 0.007777363993227482
Loss at iteration 800 : 0.010444731451570988
Loss at iteration 810 : 0.01498572900891304
Loss at iteration 820 : 0.00914870947599411
Loss at iteration 830 : 0.0036271996796131134
Loss at iteration 840 : 0.01003977656364441
Loss at iteration 850 : 0.011996759101748466
Loss at iteration 860 : 0.01111510582268238
Loss at iteration 870 : 0.011769386939704418
Loss at iteration 880 : 0.01561293751001358
Loss at iteration 890 : 0.005049245432019234
Loss at iteration 900 : 0.013405850157141685
Loss at iteration 910 : 0.00861056987196207
Loss at iteration 920 : 0.008930404670536518
Loss at iteration 930 : 0.0032741734758019447
Loss at iteration 940 : 0.004759797360748053
Loss at iteration 950 : 0.011549503542482853
Loss at iteration 960 : 0.0062716309912502766
Loss at iteration 970 : 0.009019283577799797
Loss at iteration 980 : 0.006117155309766531
Loss at iteration 990 : 0.008019221015274525
Loss at iteration 1000 : 0.005640027113258839
Loss at iteration 1010 : 0.0060951244086027145
Loss at iteration 1020 : 0.006448229309171438
Loss at iteration 1030 : 0.01156339980661869
Loss at iteration 1040 : 0.003945563919842243
Loss at iteration 1050 : 0.0035425208043307066
Loss at iteration 1060 : 0.006997615564614534
Loss at iteration 1070 : 0.016976743936538696
Loss at iteration 1080 : 0.00922390166670084
Loss at iteration 1090 : 0.008371389470994473
Loss at iteration 1100 : 0.011551160365343094
Loss at iteration 1110 : 0.011401901952922344
Loss at iteration 1120 : 0.010434523224830627
Loss at iteration 1130 : 0.0044030663557350636
Loss at iteration 1140 : 0.008331513032317162
Loss at iteration 1150 : 0.007042340002954006
Loss at iteration 1160 : 0.009672594256699085
Loss at iteration 1170 : 0.004503638483583927
Loss at iteration 1180 : 0.006961747072637081
Loss at iteration 1190 : 0.005028220824897289
Loss at iteration 1200 : 0.008959419094026089
Loss at iteration 1210 : 0.008744495920836926
Loss at iteration 1220 : 0.006396526005119085
Loss at iteration 1230 : 0.01292025949805975
Loss at iteration 1240 : 0.0040008435025811195
Loss at iteration 1250 : 0.011980408802628517
Loss at iteration 1260 : 0.01474417932331562
Loss at iteration 1270 : 0.004034377634525299
Loss at iteration 1280 : 0.010645970702171326
Loss at iteration 1290 : 0.010313162580132484
Loss at iteration 1300 : 0.007169381249696016
Loss at iteration 1310 : 0.004857752937823534
Loss at iteration 1320 : 0.0019451433327049017
Loss at iteration 1330 : 0.004419640637934208
Loss at iteration 1340 : 0.0036663608625531197
Loss at iteration 1350 : 0.005995064973831177
Loss at iteration 1360 : 0.002077727345749736
Loss at iteration 1370 : 0.004693192429840565
Loss at iteration 1380 : 0.004448371008038521
Loss at iteration 1390 : 0.017432801425457
Loss at iteration 1400 : 0.0051781111396849155
Loss at iteration 1410 : 0.005159431137144566
Loss at iteration 1420 : 0.0048837498761713505
Loss at iteration 1430 : 0.008067455142736435
Loss at iteration 1440 : 0.007690938655287027
Loss at iteration 1450 : 0.01185915619134903
Loss at iteration 1460 : 0.011583564803004265
Loss at iteration 1470 : 0.01610655151307583
Loss at iteration 1480 : 0.014733181335031986
Loss at iteration 1490 : 0.004217911511659622
Loss at iteration 1500 : 0.01044502668082714
Loss at iteration 1510 : 0.005036182701587677
Loss at iteration 1520 : 0.009962394833564758
Loss at iteration 1530 : 0.009295736439526081
Loss at iteration 1540 : 0.004047248046845198
Loss at iteration 1550 : 0.007042590528726578
Loss at iteration 1560 : 0.0073117827996611595
Loss at iteration 1570 : 0.0077755264937877655
Loss at iteration 1580 : 0.0323689803481102
Loss at iteration 1590 : 0.0053139119409024715
Loss at iteration 1600 : 0.009475965052843094
Loss at iteration 1610 : 0.0055328840389847755
Loss at iteration 1620 : 0.008359044790267944
Loss at iteration 1630 : 0.010197636671364307
Loss at iteration 1640 : 0.014649800956249237
Loss at iteration 1650 : 0.007506169378757477
Loss at iteration 1660 : 0.006400970742106438
Loss at iteration 1670 : 0.011491804383695126
Loss at iteration 1680 : 0.0023673013783991337
Loss at iteration 1690 : 0.0069749909453094006
Loss at iteration 1700 : 0.015958843752741814
Loss at iteration 1710 : 0.010387002490460873
Loss at iteration 1720 : 0.005308820866048336
Loss at iteration 1730 : 0.021817466244101524
Loss at iteration 1740 : 0.0029161456041038036
Loss at iteration 1750 : 0.014380310662090778
Loss at iteration 1760 : 0.005916465073823929
Loss at iteration 1770 : 0.004869610536843538
Loss at iteration 1780 : 0.008747616782784462
Loss at iteration 1790 : 0.007883749902248383
Loss at iteration 1800 : 0.0021510054357349873
Loss at iteration 1810 : 0.0037806564942002296
Loss at iteration 1820 : 0.003791132476180792
Loss at iteration 1830 : 0.015123074874281883
Loss at iteration 1840 : 0.0038910936564207077
Loss at iteration 1850 : 0.005966691300272942
Loss at iteration 1860 : 0.010425626300275326
Loss at iteration 1870 : 0.005996267311275005
Loss at iteration 1880 : 0.012520182877779007
Loss at iteration 1890 : 0.0028352616354823112
Loss at iteration 1900 : 0.008149608038365841
Loss at iteration 1910 : 0.006054372526705265
Loss at iteration 1920 : 0.004603923298418522
Loss at iteration 1930 : 0.014202512800693512
Loss at iteration 1940 : 0.003049211110919714
Loss at iteration 1950 : 0.016030361875891685
Loss at iteration 1960 : 0.0033738205675035715
Loss at iteration 1970 : 0.006856366526335478
Loss at iteration 1980 : 0.015719855204224586
Loss at iteration 1990 : 0.011165465228259563
Loss at iteration 2000 : 0.006146409548819065
Loss at iteration 2010 : 0.012110245414078236
Loss at iteration 2020 : 0.0033718920312821865
Loss at iteration 2030 : 0.007669994607567787
Loss at iteration 2040 : 0.00524298707023263
Loss at iteration 2050 : 0.012632456608116627
Loss at iteration 2060 : 0.011973104439675808
Loss at iteration 2070 : 0.0073991320095956326
Loss at iteration 2080 : 0.008260629139840603
Loss at iteration 2090 : 0.010622766800224781
Loss at iteration 2100 : 0.003790805349126458
Loss at iteration 2110 : 0.006482748314738274
Loss at iteration 2120 : 0.007243363652378321
Loss at iteration 2130 : 0.00599431898444891
Loss at iteration 2140 : 0.006298246327787638
Loss at iteration 2150 : 0.00940901692956686
Loss at iteration 2160 : 0.0049498253501951694
Loss at iteration 2170 : 0.010435326024889946
Loss at iteration 2180 : 0.0074578444473445415
Loss at iteration 2190 : 0.006404226645827293
Loss at iteration 2200 : 0.01201111450791359
Loss at iteration 2210 : 0.019295766949653625
Loss at iteration 2220 : 0.01625044271349907
Loss at iteration 2230 : 0.00790390558540821
Loss at iteration 2240 : 0.010274195112287998
Loss at iteration 2250 : 0.007568069268018007
Loss at iteration 2260 : 0.011576840654015541
Loss at iteration 2270 : 0.006002575159072876
Loss at iteration 2280 : 0.006596340797841549
Loss at iteration 2290 : 0.004321684129536152
Loss at iteration 2300 : 0.0075426604598760605
Loss at iteration 2310 : 0.014486979693174362
Loss at iteration 2320 : 0.008792095817625523
Loss at iteration 2330 : 0.014607792720198631
Loss at iteration 2340 : 0.012271102517843246
Loss at iteration 2350 : 0.00538814440369606
Loss at iteration 2360 : 0.0122761819511652
Loss at iteration 2370 : 0.004798380192369223
Loss at iteration 2380 : 0.006802746094763279
Loss at iteration 2390 : 0.009336847811937332
Loss at iteration 2400 : 0.02833620458841324
Loss at iteration 2410 : 0.007775356061756611
Loss at iteration 2420 : 0.004566436633467674
The SSIM Value is: 0.8480522274971009
The PSNR Value is: 22.828237024943032
the epoch is: 118
Loss at iteration 10 : 0.00878002680838108
Loss at iteration 20 : 0.009394402615725994
Loss at iteration 30 : 0.0077508543618023396
Loss at iteration 40 : 0.016355380415916443
Loss at iteration 50 : 0.012428753077983856
Loss at iteration 60 : 0.008855605497956276
Loss at iteration 70 : 0.008600885979831219
Loss at iteration 80 : 0.012535843066871166
Loss at iteration 90 : 0.0034884249325841665
Loss at iteration 100 : 0.007693377323448658
Loss at iteration 110 : 0.0036636071745306253
Loss at iteration 120 : 0.006854591891169548
Loss at iteration 130 : 0.007650331594049931
Loss at iteration 140 : 0.0029415020253509283
Loss at iteration 150 : 0.004585367627441883
Loss at iteration 160 : 0.018610555678606033
Loss at iteration 170 : 0.0025190168526023626
Loss at iteration 180 : 0.004371346905827522
Loss at iteration 190 : 0.00715501606464386
Loss at iteration 200 : 0.005000742617994547
Loss at iteration 210 : 0.010415097698569298
Loss at iteration 220 : 0.010764422826468945
Loss at iteration 230 : 0.006670091301202774
Loss at iteration 240 : 0.015223363414406776
Loss at iteration 250 : 0.009506888687610626
Loss at iteration 260 : 0.004678505007177591
Loss at iteration 270 : 0.011272124014794827
Loss at iteration 280 : 0.0037987399846315384
Loss at iteration 290 : 0.002726837294176221
Loss at iteration 300 : 0.009137134067714214
Loss at iteration 310 : 0.004335850477218628
Loss at iteration 320 : 0.008299745619297028
Loss at iteration 330 : 0.01341954618692398
Loss at iteration 340 : 0.01506761834025383
Loss at iteration 350 : 0.008567851968109608
Loss at iteration 360 : 0.005170193966478109
Loss at iteration 370 : 0.01315809041261673
Loss at iteration 380 : 0.011278859339654446
Loss at iteration 390 : 0.006257314234972
Loss at iteration 400 : 0.007860593497753143
Loss at iteration 410 : 0.009190596640110016
Loss at iteration 420 : 0.0038697728887200356
Loss at iteration 430 : 0.004631008952856064
Loss at iteration 440 : 0.010055063292384148
Loss at iteration 450 : 0.003691188059747219
Loss at iteration 460 : 0.004136638715863228
Loss at iteration 470 : 0.00496704550459981
Loss at iteration 480 : 0.0037053702399134636
Loss at iteration 490 : 0.009775742888450623
Loss at iteration 500 : 0.006125309504568577
Loss at iteration 510 : 0.0072514209896326065
Loss at iteration 520 : 0.008882720954716206
Loss at iteration 530 : 0.008191147819161415
Loss at iteration 540 : 0.007982611656188965
Loss at iteration 550 : 0.009279209189116955
Loss at iteration 560 : 0.006951854098588228
Loss at iteration 570 : 0.010556381195783615
Loss at iteration 580 : 0.0028966879472136497
Loss at iteration 590 : 0.005330940242856741
Loss at iteration 600 : 0.005431856960058212
Loss at iteration 610 : 0.005515986122190952
Loss at iteration 620 : 0.008147754706442356
Loss at iteration 630 : 0.007793773896992207
Loss at iteration 640 : 0.019896727055311203
Loss at iteration 650 : 0.010949846357107162
Loss at iteration 660 : 0.005300378892570734
Loss at iteration 670 : 0.007027356419712305
Loss at iteration 680 : 0.012756384909152985
Loss at iteration 690 : 0.006667849607765675
Loss at iteration 700 : 0.006834276020526886
Loss at iteration 710 : 0.034091584384441376
Loss at iteration 720 : 0.005956391338258982
Loss at iteration 730 : 0.002879259642213583
Loss at iteration 740 : 0.008499865420162678
Loss at iteration 750 : 0.004233714658766985
Loss at iteration 760 : 0.004538131877779961
Loss at iteration 770 : 0.007641220930963755
Loss at iteration 780 : 0.005419578403234482
Loss at iteration 790 : 0.004987043794244528
Loss at iteration 800 : 0.015120135620236397
Loss at iteration 810 : 0.005196655634790659
Loss at iteration 820 : 0.011969899758696556
Loss at iteration 830 : 0.011325720697641373
Loss at iteration 840 : 0.008858573623001575
Loss at iteration 850 : 0.003463117638602853
Loss at iteration 860 : 0.01239742524921894
Loss at iteration 870 : 0.008192378096282482
Loss at iteration 880 : 0.004765763413161039
Loss at iteration 890 : 0.005385552532970905
Loss at iteration 900 : 0.0060380371287465096
Loss at iteration 910 : 0.007052798289805651
Loss at iteration 920 : 0.007964701391756535
Loss at iteration 930 : 0.004250708036124706
Loss at iteration 940 : 0.00866591464728117
Loss at iteration 950 : 0.015783455222845078
Loss at iteration 960 : 0.007548341061919928
Loss at iteration 970 : 0.0020527709275484085
Loss at iteration 980 : 0.002413159469142556
Loss at iteration 990 : 0.007921718060970306
Loss at iteration 1000 : 0.005465041846036911
Loss at iteration 1010 : 0.006178397685289383
Loss at iteration 1020 : 0.006612424273043871
Loss at iteration 1030 : 0.00427293311804533
Loss at iteration 1040 : 0.008386610075831413
Loss at iteration 1050 : 0.012883815914392471
Loss at iteration 1060 : 0.0018180604092776775
Loss at iteration 1070 : 0.016945157200098038
Loss at iteration 1080 : 0.01046029943972826
Loss at iteration 1090 : 0.018573278561234474
Loss at iteration 1100 : 0.0051904404535889626
Loss at iteration 1110 : 0.014282934367656708
Loss at iteration 1120 : 0.01688997820019722
Loss at iteration 1130 : 0.005567354615777731
Loss at iteration 1140 : 0.007054449059069157
Loss at iteration 1150 : 0.010348448529839516
Loss at iteration 1160 : 0.010530252009630203
Loss at iteration 1170 : 0.00186941958963871
Loss at iteration 1180 : 0.013297829777002335
Loss at iteration 1190 : 0.010731999762356281
Loss at iteration 1200 : 0.0035934532061219215
Loss at iteration 1210 : 0.016479408368468285
Loss at iteration 1220 : 0.005469494499266148
Loss at iteration 1230 : 0.010704845190048218
Loss at iteration 1240 : 0.006568877957761288
Loss at iteration 1250 : 0.014442915096879005
Loss at iteration 1260 : 0.011080012656748295
Loss at iteration 1270 : 0.0075264484621584415
Loss at iteration 1280 : 0.008482033386826515
Loss at iteration 1290 : 0.006375591736286879
Loss at iteration 1300 : 0.013150360435247421
Loss at iteration 1310 : 0.00932615902274847
Loss at iteration 1320 : 0.009305495768785477
Loss at iteration 1330 : 0.0069969575852155685
Loss at iteration 1340 : 0.01588243991136551
Loss at iteration 1350 : 0.004940190818160772
Loss at iteration 1360 : 0.014855408109724522
Loss at iteration 1370 : 0.005381528753787279
Loss at iteration 1380 : 0.008831867948174477
Loss at iteration 1390 : 0.00777494627982378
Loss at iteration 1400 : 0.008034609258174896
Loss at iteration 1410 : 0.008169468492269516
Loss at iteration 1420 : 0.007823476567864418
Loss at iteration 1430 : 0.014651140198111534
Loss at iteration 1440 : 0.004092850722372532
Loss at iteration 1450 : 0.0061230347491800785
Loss at iteration 1460 : 0.009832995012402534
Loss at iteration 1470 : 0.007912675850093365
Loss at iteration 1480 : 0.015287498943507671
Loss at iteration 1490 : 0.011138467118144035
Loss at iteration 1500 : 0.004063263535499573
Loss at iteration 1510 : 0.007589020300656557
Loss at iteration 1520 : 0.005458044353872538
Loss at iteration 1530 : 0.012378995306789875
Loss at iteration 1540 : 0.0033706952817738056
Loss at iteration 1550 : 0.007561836391687393
Loss at iteration 1560 : 0.005525838118046522
Loss at iteration 1570 : 0.008304908871650696
Loss at iteration 1580 : 0.005448252893984318
Loss at iteration 1590 : 0.0030185666400939226
Loss at iteration 1600 : 0.008321578614413738
Loss at iteration 1610 : 0.006047534290701151
Loss at iteration 1620 : 0.02366303652524948
Loss at iteration 1630 : 0.013571135699748993
Loss at iteration 1640 : 0.008079594001173973
Loss at iteration 1650 : 0.010057813487946987
Loss at iteration 1660 : 0.008398093283176422
Loss at iteration 1670 : 0.0030594721902161837
Loss at iteration 1680 : 0.01134885847568512
Loss at iteration 1690 : 0.006671018898487091
Loss at iteration 1700 : 0.007013330236077309
Loss at iteration 1710 : 0.015562611632049084
Loss at iteration 1720 : 0.004065628629177809
Loss at iteration 1730 : 0.007418692111968994
Loss at iteration 1740 : 0.006220643408596516
Loss at iteration 1750 : 0.014012244530022144
Loss at iteration 1760 : 0.0037895054556429386
Loss at iteration 1770 : 0.006873555947095156
Loss at iteration 1780 : 0.005574455484747887
Loss at iteration 1790 : 0.007055472116917372
Loss at iteration 1800 : 0.004488232079893351
Loss at iteration 1810 : 0.002506252145394683
Loss at iteration 1820 : 0.00235559418797493
Loss at iteration 1830 : 0.013172994367778301
Loss at iteration 1840 : 0.015117145143449306
Loss at iteration 1850 : 0.0034453081898391247
Loss at iteration 1860 : 0.009479821659624577
Loss at iteration 1870 : 0.008027658797800541
Loss at iteration 1880 : 0.007089918479323387
Loss at iteration 1890 : 0.01539609581232071
Loss at iteration 1900 : 0.0031889663077890873
Loss at iteration 1910 : 0.007884691469371319
Loss at iteration 1920 : 0.00996707659214735
Loss at iteration 1930 : 0.008385434746742249
Loss at iteration 1940 : 0.005300118587911129
Loss at iteration 1950 : 0.0031394523102790117
Loss at iteration 1960 : 0.009396234527230263
Loss at iteration 1970 : 0.014439232647418976
Loss at iteration 1980 : 0.0087889414280653
Loss at iteration 1990 : 0.0215635783970356
Loss at iteration 2000 : 0.005822886247187853
Loss at iteration 2010 : 0.0031362955924123526
Loss at iteration 2020 : 0.009388543665409088
Loss at iteration 2030 : 0.005974433850497007
Loss at iteration 2040 : 0.0031659724190831184
Loss at iteration 2050 : 0.006533043459057808
Loss at iteration 2060 : 0.019265079870820045
Loss at iteration 2070 : 0.01602739654481411
Loss at iteration 2080 : 0.014623441733419895
Loss at iteration 2090 : 0.006507294252514839
Loss at iteration 2100 : 0.015658900141716003
Loss at iteration 2110 : 0.007082134950906038
Loss at iteration 2120 : 0.00606573885306716
Loss at iteration 2130 : 0.011389747262001038
Loss at iteration 2140 : 0.006903433240950108
Loss at iteration 2150 : 0.00843752734363079
Loss at iteration 2160 : 0.0032997846137732267
Loss at iteration 2170 : 0.004354544915258884
Loss at iteration 2180 : 0.007274995092302561
Loss at iteration 2190 : 0.005373230669647455
Loss at iteration 2200 : 0.0016127473209053278
Loss at iteration 2210 : 0.006777717266231775
Loss at iteration 2220 : 0.008775714784860611
Loss at iteration 2230 : 0.0064860619604587555
Loss at iteration 2240 : 0.0060637397691607475
Loss at iteration 2250 : 0.006627984810620546
Loss at iteration 2260 : 0.006316613405942917
Loss at iteration 2270 : 0.011068873107433319
Loss at iteration 2280 : 0.0028986497782170773
Loss at iteration 2290 : 0.016140151768922806
Loss at iteration 2300 : 0.006243572570383549
Loss at iteration 2310 : 0.009966148063540459
Loss at iteration 2320 : 0.023295938968658447
Loss at iteration 2330 : 0.016677062958478928
Loss at iteration 2340 : 0.00937951821833849
Loss at iteration 2350 : 0.008203316479921341
Loss at iteration 2360 : 0.01158123929053545
Loss at iteration 2370 : 0.007670555263757706
Loss at iteration 2380 : 0.014529597014188766
Loss at iteration 2390 : 0.016180865466594696
Loss at iteration 2400 : 0.007510736119002104
Loss at iteration 2410 : 0.009145946241915226
Loss at iteration 2420 : 0.009946893900632858
The SSIM Value is: 0.8507334987322489
The PSNR Value is: 23.35789680480957
the highest SSIM value is: 23.35789680480957
the epoch is: 119
Loss at iteration 10 : 0.009488575160503387
Loss at iteration 20 : 0.010823993012309074
Loss at iteration 30 : 0.010539956390857697
Loss at iteration 40 : 0.013909819535911083
Loss at iteration 50 : 0.006290704943239689
Loss at iteration 60 : 0.0037783626466989517
Loss at iteration 70 : 0.02043886110186577
Loss at iteration 80 : 0.004132102243602276
Loss at iteration 90 : 0.007820894941687584
Loss at iteration 100 : 0.009113699197769165
Loss at iteration 110 : 0.0052757831290364265
Loss at iteration 120 : 0.00687166303396225
Loss at iteration 130 : 0.006760042626410723
Loss at iteration 140 : 0.008946302346885204
Loss at iteration 150 : 0.010483385995030403
Loss at iteration 160 : 0.012510620057582855
Loss at iteration 170 : 0.0023749135434627533
Loss at iteration 180 : 0.011300327256321907
Loss at iteration 190 : 0.016800405457615852
Loss at iteration 200 : 0.010256543755531311
Loss at iteration 210 : 0.007882313802838326
Loss at iteration 220 : 0.009497946128249168
Loss at iteration 230 : 0.005886763334274292
Loss at iteration 240 : 0.008269202895462513
Loss at iteration 250 : 0.006243297830224037
Loss at iteration 260 : 0.0101434625685215
Loss at iteration 270 : 0.00864646676927805
Loss at iteration 280 : 0.010787172242999077
Loss at iteration 290 : 0.0054050348699092865
Loss at iteration 300 : 0.017169222235679626
Loss at iteration 310 : 0.006606598384678364
Loss at iteration 320 : 0.007964236661791801
Loss at iteration 330 : 0.010291391052305698
Loss at iteration 340 : 0.015598302707076073
Loss at iteration 350 : 0.0071344319730997086
Loss at iteration 360 : 0.004663416184484959
Loss at iteration 370 : 0.006011454854160547
Loss at iteration 380 : 0.009065059944987297
Loss at iteration 390 : 0.004702535457909107
Loss at iteration 400 : 0.007601581048220396
Loss at iteration 410 : 0.008030736818909645
Loss at iteration 420 : 0.005736733786761761
Loss at iteration 430 : 0.006104168947786093
Loss at iteration 440 : 0.01040730345994234
Loss at iteration 450 : 0.007912757806479931
Loss at iteration 460 : 0.0034053411800414324
Loss at iteration 470 : 0.006216157227754593
Loss at iteration 480 : 0.007066226098686457
Loss at iteration 490 : 0.008646241389214993
Loss at iteration 500 : 0.009140539914369583
Loss at iteration 510 : 0.008102248422801495
Loss at iteration 520 : 0.012597877532243729
Loss at iteration 530 : 0.004921708721667528
Loss at iteration 540 : 0.0069295563735067844
Loss at iteration 550 : 0.004822976887226105
Loss at iteration 560 : 0.008351674303412437
Loss at iteration 570 : 0.004253102466464043
Loss at iteration 580 : 0.004139117896556854
Loss at iteration 590 : 0.008422808721661568
Loss at iteration 600 : 0.013437017798423767
Loss at iteration 610 : 0.0033189018722623587
Loss at iteration 620 : 0.013151274062693119
Loss at iteration 630 : 0.004061190877109766
Loss at iteration 640 : 0.00810385961085558
Loss at iteration 650 : 0.00462455814704299
Loss at iteration 660 : 0.013324538245797157
Loss at iteration 670 : 0.005707947537302971
Loss at iteration 680 : 0.008788666687905788
Loss at iteration 690 : 0.0187472365796566
Loss at iteration 700 : 0.019137172028422356
Loss at iteration 710 : 0.005446136929094791
Loss at iteration 720 : 0.00528512941673398
Loss at iteration 730 : 0.011452198959887028
Loss at iteration 740 : 0.009589184075593948
Loss at iteration 750 : 0.005473727360367775
Loss at iteration 760 : 0.00997982732951641
Loss at iteration 770 : 0.01328475121408701
Loss at iteration 780 : 0.008408395573496819
Loss at iteration 790 : 0.006297162733972073
Loss at iteration 800 : 0.0020720520988106728
Loss at iteration 810 : 0.008200209587812424
Loss at iteration 820 : 0.01668883115053177
Loss at iteration 830 : 0.0071749258786439896
Loss at iteration 840 : 0.003785384353250265
Loss at iteration 850 : 0.008954805321991444
Loss at iteration 860 : 0.008767697960138321
Loss at iteration 870 : 0.003486260771751404
Loss at iteration 880 : 0.009046681225299835
Loss at iteration 890 : 0.008367952890694141
Loss at iteration 900 : 0.008564658463001251
Loss at iteration 910 : 0.005321173463016748
Loss at iteration 920 : 0.0046591791324317455
Loss at iteration 930 : 0.00473437225446105
Loss at iteration 940 : 0.004204162396490574
Loss at iteration 950 : 0.002216014778241515
Loss at iteration 960 : 0.005701990332454443
Loss at iteration 970 : 0.007508588954806328
Loss at iteration 980 : 0.00484510837122798
Loss at iteration 990 : 0.004764170851558447
Loss at iteration 1000 : 0.014525339938700199
Loss at iteration 1010 : 0.006563290953636169
Loss at iteration 1020 : 0.00715767964720726
Loss at iteration 1030 : 0.008272371254861355
Loss at iteration 1040 : 0.008994059637188911
Loss at iteration 1050 : 0.006453595124185085
Loss at iteration 1060 : 0.007687303237617016
Loss at iteration 1070 : 0.03619082272052765
Loss at iteration 1080 : 0.013155539520084858
Loss at iteration 1090 : 0.007991197519004345
Loss at iteration 1100 : 0.005758959334343672
Loss at iteration 1110 : 0.007396433502435684
Loss at iteration 1120 : 0.01175006479024887
Loss at iteration 1130 : 0.006641918793320656
Loss at iteration 1140 : 0.0090726837515831
Loss at iteration 1150 : 0.006958946585655212
Loss at iteration 1160 : 0.007626393809914589
Loss at iteration 1170 : 0.010439220815896988
Loss at iteration 1180 : 0.008042065426707268
Loss at iteration 1190 : 0.005717987194657326
Loss at iteration 1200 : 0.009902683086693287
Loss at iteration 1210 : 0.009267855435609818
Loss at iteration 1220 : 0.007014757953584194
Loss at iteration 1230 : 0.006403034552931786
Loss at iteration 1240 : 0.007448452524840832
Loss at iteration 1250 : 0.0135969128459692
Loss at iteration 1260 : 0.0068509457632899284
Loss at iteration 1270 : 0.0031863530166447163
Loss at iteration 1280 : 0.011917198076844215
Loss at iteration 1290 : 0.007321259472519159
Loss at iteration 1300 : 0.005574075970798731
Loss at iteration 1310 : 0.007854096591472626
Loss at iteration 1320 : 0.007616893388330936
Loss at iteration 1330 : 0.004934617318212986
Loss at iteration 1340 : 0.006686829030513763
Loss at iteration 1350 : 0.016395706683397293
Loss at iteration 1360 : 0.014233343303203583
Loss at iteration 1370 : 0.007695371750742197
Loss at iteration 1380 : 0.009766737930476665
Loss at iteration 1390 : 0.008740288205444813
Loss at iteration 1400 : 0.00870184414088726
Loss at iteration 1410 : 0.006841578986495733
Loss at iteration 1420 : 0.004689497873187065
Loss at iteration 1430 : 0.005021198652684689
Loss at iteration 1440 : 0.0090815220028162
Loss at iteration 1450 : 0.008485152386128902
Loss at iteration 1460 : 0.013454151339828968
Loss at iteration 1470 : 0.006063914857804775
Loss at iteration 1480 : 0.007669457234442234
Loss at iteration 1490 : 0.008515882305800915
Loss at iteration 1500 : 0.01112130843102932
Loss at iteration 1510 : 0.009683272801339626
Loss at iteration 1520 : 0.007720017805695534
Loss at iteration 1530 : 0.012814161367714405
Loss at iteration 1540 : 0.0050949351862072945
Loss at iteration 1550 : 0.00786181353032589
Loss at iteration 1560 : 0.006547491531819105
Loss at iteration 1570 : 0.01738136261701584
Loss at iteration 1580 : 0.005118126980960369
Loss at iteration 1590 : 0.0162117388099432
Loss at iteration 1600 : 0.008914529345929623
Loss at iteration 1610 : 0.009347065351903439
Loss at iteration 1620 : 0.0038237825501710176
Loss at iteration 1630 : 0.007755731698125601
Loss at iteration 1640 : 0.005994428880512714
Loss at iteration 1650 : 0.007604545913636684
Loss at iteration 1660 : 0.003032232401892543
Loss at iteration 1670 : 0.003512363648042083
Loss at iteration 1680 : 0.004567387513816357
Loss at iteration 1690 : 0.004231666214764118
Loss at iteration 1700 : 0.009154791943728924
Loss at iteration 1710 : 0.009077461436390877
Loss at iteration 1720 : 0.004750142805278301
Loss at iteration 1730 : 0.00790320336818695
Loss at iteration 1740 : 0.007957392372190952
Loss at iteration 1750 : 0.004088317975401878
Loss at iteration 1760 : 0.007933173328638077
Loss at iteration 1770 : 0.006845167372375727
Loss at iteration 1780 : 0.007955222390592098
Loss at iteration 1790 : 0.007755196653306484
Loss at iteration 1800 : 0.0028126270044595003
Loss at iteration 1810 : 0.006085311062633991
Loss at iteration 1820 : 0.003975971601903439
Loss at iteration 1830 : 0.01570463925600052
Loss at iteration 1840 : 0.008356902748346329
Loss at iteration 1850 : 0.015631053596735
Loss at iteration 1860 : 0.010714863426983356
Loss at iteration 1870 : 0.0155888507142663
Loss at iteration 1880 : 0.00983785092830658
Loss at iteration 1890 : 0.028078382834792137
Loss at iteration 1900 : 0.008950911462306976
Loss at iteration 1910 : 0.007072873413562775
Loss at iteration 1920 : 0.005143765825778246
Loss at iteration 1930 : 0.005407147575169802
Loss at iteration 1940 : 0.004116399679332972
Loss at iteration 1950 : 0.014507047832012177
Loss at iteration 1960 : 0.01978083699941635
Loss at iteration 1970 : 0.00935689639300108
Loss at iteration 1980 : 0.010458497330546379
Loss at iteration 1990 : 0.01067457813769579
Loss at iteration 2000 : 0.0044476669281721115
Loss at iteration 2010 : 0.015282596461474895
Loss at iteration 2020 : 0.0031715717632323503
Loss at iteration 2030 : 0.011708984151482582
Loss at iteration 2040 : 0.009871309623122215
Loss at iteration 2050 : 0.00493428111076355
Loss at iteration 2060 : 0.024818597361445427
Loss at iteration 2070 : 0.003848809050396085
Loss at iteration 2080 : 0.0038642571307718754
Loss at iteration 2090 : 0.002902959007769823
Loss at iteration 2100 : 0.0068769375793635845
Loss at iteration 2110 : 0.008427516557276249
Loss at iteration 2120 : 0.003409968689084053
Loss at iteration 2130 : 0.009296311996877193
Loss at iteration 2140 : 0.01167367585003376
Loss at iteration 2150 : 0.004475426860153675
Loss at iteration 2160 : 0.008821814320981503
Loss at iteration 2170 : 0.003941658418625593
Loss at iteration 2180 : 0.014585752040147781
Loss at iteration 2190 : 0.0051898714154958725
Loss at iteration 2200 : 0.014787665568292141
Loss at iteration 2210 : 0.00508540403097868
Loss at iteration 2220 : 0.009706156328320503
Loss at iteration 2230 : 0.009478236548602581
Loss at iteration 2240 : 0.007144230417907238
Loss at iteration 2250 : 0.005758256651461124
Loss at iteration 2260 : 0.012550195679068565
Loss at iteration 2270 : 0.010733028873801231
Loss at iteration 2280 : 0.011055187322199345
Loss at iteration 2290 : 0.007573367562144995
Loss at iteration 2300 : 0.00846748799085617
Loss at iteration 2310 : 0.008440418168902397
Loss at iteration 2320 : 0.004612521268427372
Loss at iteration 2330 : 0.007172673474997282
Loss at iteration 2340 : 0.012360154651105404
Loss at iteration 2350 : 0.005979539826512337
Loss at iteration 2360 : 0.0054231006652116776
Loss at iteration 2370 : 0.022801131010055542
Loss at iteration 2380 : 0.024650640785694122
Loss at iteration 2390 : 0.012702194042503834
Loss at iteration 2400 : 0.011212332174181938
Loss at iteration 2410 : 0.010647907853126526
Loss at iteration 2420 : 0.0073060765862464905
The SSIM Value is: 0.8475230654080709
The PSNR Value is: 22.612897936503092
the epoch is: 120
Loss at iteration 10 : 0.008976517245173454
Loss at iteration 20 : 0.01415337435901165
Loss at iteration 30 : 0.0076799532398581505
Loss at iteration 40 : 0.003875645576044917
Loss at iteration 50 : 0.00749545730650425
Loss at iteration 60 : 0.010845107026398182
Loss at iteration 70 : 0.003679960034787655
Loss at iteration 80 : 0.01228092797100544
Loss at iteration 90 : 0.005962226539850235
Loss at iteration 100 : 0.006636498961597681
Loss at iteration 110 : 0.010692333802580833
Loss at iteration 120 : 0.016803767532110214
Loss at iteration 130 : 0.0034471952822059393
Loss at iteration 140 : 0.009474222548305988
Loss at iteration 150 : 0.006673982832580805
Loss at iteration 160 : 0.00496183754876256
Loss at iteration 170 : 0.01367450226098299
Loss at iteration 180 : 0.014908477663993835
Loss at iteration 190 : 0.005377854686230421
Loss at iteration 200 : 0.0056547680869698524
Loss at iteration 210 : 0.005368835758417845
Loss at iteration 220 : 0.009461856447160244
Loss at iteration 230 : 0.007006107363849878
Loss at iteration 240 : 0.0035721047315746546
Loss at iteration 250 : 0.0052080401219427586
Loss at iteration 260 : 0.007509271614253521
Loss at iteration 270 : 0.0126150231808424
Loss at iteration 280 : 0.01662367582321167
Loss at iteration 290 : 0.007997267879545689
Loss at iteration 300 : 0.006772160530090332
Loss at iteration 310 : 0.003772902302443981
Loss at iteration 320 : 0.007485165726393461
Loss at iteration 330 : 0.008548625744879246
Loss at iteration 340 : 0.014637095853686333
Loss at iteration 350 : 0.016175299882888794
Loss at iteration 360 : 0.006694427691400051
Loss at iteration 370 : 0.021746128797531128
Loss at iteration 380 : 0.02508772537112236
Loss at iteration 390 : 0.004253999795764685
Loss at iteration 400 : 0.006332207936793566
Loss at iteration 410 : 0.02488153800368309
Loss at iteration 420 : 0.0042170011438429356
Loss at iteration 430 : 0.004479769617319107
Loss at iteration 440 : 0.005349050275981426
Loss at iteration 450 : 0.005373295396566391
Loss at iteration 460 : 0.009188245981931686
Loss at iteration 470 : 0.006952371448278427
Loss at iteration 480 : 0.006318477913737297
Loss at iteration 490 : 0.007212815806269646
Loss at iteration 500 : 0.003810320980846882
Loss at iteration 510 : 0.010679135099053383
Loss at iteration 520 : 0.003107819240540266
Loss at iteration 530 : 0.00555876549333334
Loss at iteration 540 : 0.002789633348584175
Loss at iteration 550 : 0.011768285185098648
Loss at iteration 560 : 0.015857268124818802
Loss at iteration 570 : 0.009377396665513515
Loss at iteration 580 : 0.010678586550056934
Loss at iteration 590 : 0.011816101148724556
Loss at iteration 600 : 0.0038940655067563057
Loss at iteration 610 : 0.00638143764808774
Loss at iteration 620 : 0.010133426636457443
Loss at iteration 630 : 0.010324748232960701
Loss at iteration 640 : 0.010636410675942898
Loss at iteration 650 : 0.0063383327797055244
Loss at iteration 660 : 0.01935669220983982
Loss at iteration 670 : 0.009336788207292557
Loss at iteration 680 : 0.008782167918980122
Loss at iteration 690 : 0.0024339081719517708
Loss at iteration 700 : 0.007921494543552399
Loss at iteration 710 : 0.015813171863555908
Loss at iteration 720 : 0.010279251262545586
Loss at iteration 730 : 0.007284210529178381
Loss at iteration 740 : 0.007811043877154589
Loss at iteration 750 : 0.007591388188302517
Loss at iteration 760 : 0.011362225748598576
Loss at iteration 770 : 0.013018791563808918
Loss at iteration 780 : 0.009844359941780567
Loss at iteration 790 : 0.011097203940153122
Loss at iteration 800 : 0.006522724404931068
Loss at iteration 810 : 0.005395607091486454
Loss at iteration 820 : 0.012648333795368671
Loss at iteration 830 : 0.013095542788505554
Loss at iteration 840 : 0.004584422335028648
Loss at iteration 850 : 0.009997843764722347
Loss at iteration 860 : 0.011712160892784595
Loss at iteration 870 : 0.012842602096498013
Loss at iteration 880 : 0.010323286056518555
Loss at iteration 890 : 0.010226428508758545
Loss at iteration 900 : 0.0045615932904183865
Loss at iteration 910 : 0.004432449582964182
Loss at iteration 920 : 0.007887046784162521
Loss at iteration 930 : 0.004236462060362101
Loss at iteration 940 : 0.009187910705804825
Loss at iteration 950 : 0.006591008044779301
Loss at iteration 960 : 0.0033401823602616787
Loss at iteration 970 : 0.013911697082221508
Loss at iteration 980 : 0.010904604569077492
Loss at iteration 990 : 0.005400220397859812
Loss at iteration 1000 : 0.011670754291117191
Loss at iteration 1010 : 0.021207377314567566
Loss at iteration 1020 : 0.012514254078269005
Loss at iteration 1030 : 0.016737181693315506
Loss at iteration 1040 : 0.010837572626769543
Loss at iteration 1050 : 0.004870772827416658
Loss at iteration 1060 : 0.009496676735579967
Loss at iteration 1070 : 0.010210134088993073
Loss at iteration 1080 : 0.010853223502635956
Loss at iteration 1090 : 0.005943769123405218
Loss at iteration 1100 : 0.007762733846902847
Loss at iteration 1110 : 0.004445202648639679
Loss at iteration 1120 : 0.008895190432667732
Loss at iteration 1130 : 0.013759657740592957
Loss at iteration 1140 : 0.0072020175866782665
Loss at iteration 1150 : 0.0064118728041648865
Loss at iteration 1160 : 0.012468361295759678
Loss at iteration 1170 : 0.008479595184326172
Loss at iteration 1180 : 0.005153098609298468
Loss at iteration 1190 : 0.00993542280048132
Loss at iteration 1200 : 0.003417830914258957
Loss at iteration 1210 : 0.002921120263636112
Loss at iteration 1220 : 0.007945808582007885
Loss at iteration 1230 : 0.013589862734079361
Loss at iteration 1240 : 0.003833367256447673
Loss at iteration 1250 : 0.002894321922212839
Loss at iteration 1260 : 0.005017133429646492
Loss at iteration 1270 : 0.018097354099154472
Loss at iteration 1280 : 0.004291730001568794
Loss at iteration 1290 : 0.007655090186744928
Loss at iteration 1300 : 0.00897146761417389
Loss at iteration 1310 : 0.007480424828827381
Loss at iteration 1320 : 0.007221258245408535
Loss at iteration 1330 : 0.006082450971007347
Loss at iteration 1340 : 0.002167343394830823
Loss at iteration 1350 : 0.02341749146580696
Loss at iteration 1360 : 0.011971849948167801
Loss at iteration 1370 : 0.007495553232729435
Loss at iteration 1380 : 0.011445366777479649
Loss at iteration 1390 : 0.0033972961828112602
Loss at iteration 1400 : 0.021332891657948494
Loss at iteration 1410 : 0.011950665153563023
Loss at iteration 1420 : 0.011957388371229172
Loss at iteration 1430 : 0.006282472051680088
Loss at iteration 1440 : 0.013228519819676876
Loss at iteration 1450 : 0.011774391867220402
Loss at iteration 1460 : 0.007618821691721678
Loss at iteration 1470 : 0.01587674766778946
Loss at iteration 1480 : 0.20289961993694305
Loss at iteration 1490 : 1093.51708984375
Loss at iteration 1500 : 121363.6640625
Loss at iteration 1510 : 53701.6875
Loss at iteration 1520 : 130.65562438964844
Loss at iteration 1530 : 0.08821377158164978
Loss at iteration 1540 : 0.5019468665122986
Loss at iteration 1550 : 0.0296635739505291
Loss at iteration 1560 : 0.2359679788351059
Loss at iteration 1570 : 0.04757023602724075
Loss at iteration 1580 : 0.10748856514692307
Loss at iteration 1590 : 57.492027282714844
Loss at iteration 1600 : 0.31772536039352417
Loss at iteration 1610 : 6.466170310974121
Loss at iteration 1620 : 1.8329358100891113
Loss at iteration 1630 : 7.702240943908691
Loss at iteration 1640 : 0.09711197018623352
Loss at iteration 1650 : 0.018014298751950264
Loss at iteration 1660 : 6.535905838012695
Loss at iteration 1670 : 0.11920654028654099
Loss at iteration 1680 : 0.18577887117862701
Loss at iteration 1690 : 0.12842737138271332
Loss at iteration 1700 : 17.230039596557617
Loss at iteration 1710 : 2.652066946029663
Loss at iteration 1720 : 0.11016225814819336
Loss at iteration 1730 : 0.0636976957321167
Loss at iteration 1740 : 0.08677493035793304
Loss at iteration 1750 : 2.7484989166259766
Loss at iteration 1760 : 0.04381152242422104
Loss at iteration 1770 : 0.050812382251024246
Loss at iteration 1780 : 0.03953126072883606
Loss at iteration 1790 : 0.030579090118408203
Loss at iteration 1800 : 0.016698524355888367
Loss at iteration 1810 : 0.04338604211807251
Loss at iteration 1820 : 38.266700744628906
Loss at iteration 1830 : 0.03153340891003609
Loss at iteration 1840 : 0.3193245828151703
Loss at iteration 1850 : 0.875523567199707
Loss at iteration 1860 : 0.0644039511680603
Loss at iteration 1870 : 0.05297084152698517
Loss at iteration 1880 : 0.01370428130030632
Loss at iteration 1890 : 0.4956093728542328
Loss at iteration 1900 : 16.226831436157227
Loss at iteration 1910 : 0.40293416380882263
Loss at iteration 1920 : 17.637346267700195
Loss at iteration 1930 : 148.14767456054688
Loss at iteration 1940 : 1.3870755434036255
Loss at iteration 1950 : 0.7190969586372375
Loss at iteration 1960 : 3.4627883434295654
Loss at iteration 1970 : 19.177398681640625
Loss at iteration 1980 : 0.09569904953241348
Loss at iteration 1990 : 0.022281741723418236
Loss at iteration 2000 : 4.7114458084106445
Loss at iteration 2010 : 0.041016317903995514
Loss at iteration 2020 : 1.2492314577102661
Loss at iteration 2030 : 0.04373367875814438
Loss at iteration 2040 : 0.2695956826210022
Loss at iteration 2050 : 0.016805194318294525
Loss at iteration 2060 : 11.818657875061035
Loss at iteration 2070 : 0.12689054012298584
Loss at iteration 2080 : 0.11117775738239288
Loss at iteration 2090 : 16.54737091064453
Loss at iteration 2100 : 0.09126367419958115
Loss at iteration 2110 : 0.02489684522151947
Loss at iteration 2120 : 5.22070837020874
Loss at iteration 2130 : 0.09248317033052444
Loss at iteration 2140 : 0.05183560401201248
Loss at iteration 2150 : 0.036139458417892456
Loss at iteration 2160 : 0.06197979301214218
Loss at iteration 2170 : 0.07116402685642242
Loss at iteration 2180 : 1.839869737625122
Loss at iteration 2190 : 0.03271551802754402
Loss at iteration 2200 : 0.03638673946261406
Loss at iteration 2210 : 0.0335676409304142
Loss at iteration 2220 : 0.06753050535917282
Loss at iteration 2230 : 0.1070970743894577
Loss at iteration 2240 : 0.07270681858062744
Loss at iteration 2250 : 0.7307564616203308
Loss at iteration 2260 : 0.015616911463439465
Loss at iteration 2270 : 0.03016158565878868
Loss at iteration 2280 : 0.07317915558815002
Loss at iteration 2290 : 0.01754097081720829
Loss at iteration 2300 : 0.06618033349514008
Loss at iteration 2310 : 0.03301054611802101
Loss at iteration 2320 : 0.01906426250934601
Loss at iteration 2330 : 0.08089951425790787
Loss at iteration 2340 : 0.03851541131734848
Loss at iteration 2350 : 0.015415329486131668
Loss at iteration 2360 : 0.05342031270265579
Loss at iteration 2370 : 0.03285598009824753
Loss at iteration 2380 : 0.04764013737440109
Loss at iteration 2390 : 0.017933176830410957
Loss at iteration 2400 : 0.08098946511745453
Loss at iteration 2410 : 0.06207874044775963
Loss at iteration 2420 : 1.0457029342651367
The SSIM Value is: 0.3984469917913278
The PSNR Value is: 9.426400208473206
the epoch is: 121
Loss at iteration 10 : 0.022731099277734756
Loss at iteration 20 : 0.6611782908439636
Loss at iteration 30 : 0.01209111325442791
Loss at iteration 40 : 0.1268427073955536
Loss at iteration 50 : 0.01776055619120598
Loss at iteration 60 : 0.06596359610557556
Loss at iteration 70 : 0.08603976666927338
Loss at iteration 80 : 0.1843249797821045
Loss at iteration 90 : 0.031494442373514175
Loss at iteration 100 : 0.018997613340616226
Loss at iteration 110 : 0.04247505962848663
Loss at iteration 120 : 0.0579749196767807
Loss at iteration 130 : 0.0555492639541626
Loss at iteration 140 : 5.509865760803223
Loss at iteration 150 : 0.5989179015159607
Loss at iteration 160 : 0.037704113870859146
Loss at iteration 170 : 0.05057987570762634
Loss at iteration 180 : 0.02328316867351532
Loss at iteration 190 : 0.04090285673737526
Loss at iteration 200 : 0.04113874211907387
Loss at iteration 210 : 0.022920329123735428
Loss at iteration 220 : 0.04239819943904877
Loss at iteration 230 : 0.03789600729942322
Loss at iteration 240 : 0.03701715171337128
Loss at iteration 250 : 0.04016159474849701
Loss at iteration 260 : 4.6477508544921875
Loss at iteration 270 : 0.04338718205690384
Loss at iteration 280 : 0.11404453217983246
Loss at iteration 290 : 0.06804512441158295
Loss at iteration 300 : 3.765753746032715
Loss at iteration 310 : 0.03548314422369003
Loss at iteration 320 : 0.6047703623771667
Loss at iteration 330 : 0.7589206695556641
Loss at iteration 340 : 0.04558217525482178
Loss at iteration 350 : 0.054094113409519196
Loss at iteration 360 : 1.5877985954284668
Loss at iteration 370 : 0.020146755501627922
Loss at iteration 380 : 0.02419286221265793
Loss at iteration 390 : 0.04579997435212135
Loss at iteration 400 : 0.05317020043730736
Loss at iteration 410 : 6.168671607971191
Loss at iteration 420 : 0.036099497228860855
Loss at iteration 430 : 0.044615574181079865
Loss at iteration 440 : 0.07179762423038483
Loss at iteration 450 : 0.0632752925157547
Loss at iteration 460 : 1.488384485244751
Loss at iteration 470 : 0.0362480953335762
Loss at iteration 480 : 0.11654075980186462
Loss at iteration 490 : 0.12775331735610962
Loss at iteration 500 : 0.043204884976148605
Loss at iteration 510 : 1.9811755418777466
Loss at iteration 520 : 0.5384624600410461
Loss at iteration 530 : 0.031850628554821014
Loss at iteration 540 : 0.03340425342321396
Loss at iteration 550 : 0.08491157740354538
Loss at iteration 560 : 0.03072352148592472
Loss at iteration 570 : 1.8304402828216553
Loss at iteration 580 : 0.05875507742166519
Loss at iteration 590 : 0.05063910782337189
Loss at iteration 600 : 0.07303453981876373
Loss at iteration 610 : 3.2413010597229004
Loss at iteration 620 : 0.021410923451185226
Loss at iteration 630 : 0.03330715000629425
Loss at iteration 640 : 2.6324100494384766
Loss at iteration 650 : 0.06399660557508469
Loss at iteration 660 : 0.022476186975836754
Loss at iteration 670 : 0.05482403188943863
Loss at iteration 680 : 0.04480887949466705
Loss at iteration 690 : 4.212863922119141
Loss at iteration 700 : 0.04828527942299843
Loss at iteration 710 : 0.031024079769849777
Loss at iteration 720 : 0.08969064056873322
Loss at iteration 730 : 0.04958336800336838
Loss at iteration 740 : 0.056569576263427734
Loss at iteration 750 : 0.038069263100624084
Loss at iteration 760 : 0.014713956974446774
Loss at iteration 770 : 0.05816362053155899
Loss at iteration 780 : 0.042221732437610626
Loss at iteration 790 : 0.03215635567903519
Loss at iteration 800 : 0.025415288284420967
Loss at iteration 810 : 0.48078739643096924
Loss at iteration 820 : 0.03691379725933075
Loss at iteration 830 : 0.06696803867816925
Loss at iteration 840 : 0.09050361067056656
Loss at iteration 850 : 16.274776458740234
Loss at iteration 860 : 0.09799884259700775
Loss at iteration 870 : 0.03711305931210518
Loss at iteration 880 : 0.028779860585927963
Loss at iteration 890 : 0.05273202806711197
Loss at iteration 900 : 0.020313821732997894
Loss at iteration 910 : 0.03636430948972702
Loss at iteration 920 : 0.01775401458144188
Loss at iteration 930 : 0.20172375440597534
Loss at iteration 940 : 0.026611914858222008
Loss at iteration 950 : 0.2949775457382202
Loss at iteration 960 : 0.04945605248212814
Loss at iteration 970 : 0.02564491517841816
Loss at iteration 980 : 0.44466251134872437
Loss at iteration 990 : 0.030130289494991302
Loss at iteration 1000 : 0.05805341526865959
Loss at iteration 1010 : 0.10926187038421631
Loss at iteration 1020 : 0.1947099268436432
Loss at iteration 1030 : 0.5281692147254944
Loss at iteration 1040 : 0.018459677696228027
Loss at iteration 1050 : 0.03585971146821976
Loss at iteration 1060 : 0.04684807360172272
Loss at iteration 1070 : 0.035335637629032135
Loss at iteration 1080 : 0.03671865910291672
Loss at iteration 1090 : 0.6848963499069214
Loss at iteration 1100 : 0.02330935187637806
Loss at iteration 1110 : 0.03984851390123367
Loss at iteration 1120 : 0.055859699845314026
Loss at iteration 1130 : 0.010953579097986221
Loss at iteration 1140 : 0.040782708674669266
Loss at iteration 1150 : 0.03838539868593216
Loss at iteration 1160 : 0.046307265758514404
Loss at iteration 1170 : 0.01579100452363491
Loss at iteration 1180 : 0.025364797562360764
Loss at iteration 1190 : 0.024292249232530594
Loss at iteration 1200 : 75.96273803710938
Loss at iteration 1210 : 0.034512318670749664
Loss at iteration 1220 : 0.026077603921294212
Loss at iteration 1230 : 0.015038643032312393
Loss at iteration 1240 : 0.03508227691054344
Loss at iteration 1250 : 0.021665427833795547
Loss at iteration 1260 : 0.04591306671500206
Loss at iteration 1270 : 0.019439540803432465
Loss at iteration 1280 : 0.02705252543091774
Loss at iteration 1290 : 0.030343806371092796
Loss at iteration 1300 : 0.042888469994068146
Loss at iteration 1310 : 0.019923347979784012
Loss at iteration 1320 : 0.04105548933148384
Loss at iteration 1330 : 0.10152772814035416
Loss at iteration 1340 : 0.025239814072847366
Loss at iteration 1350 : 0.0854647234082222
Loss at iteration 1360 : 0.04218077287077904
Loss at iteration 1370 : 0.027920681983232498
Loss at iteration 1380 : 0.599721372127533
Loss at iteration 1390 : 0.03488313406705856
Loss at iteration 1400 : 0.02093752846121788
Loss at iteration 1410 : 0.037752263247966766
Loss at iteration 1420 : 0.06034978851675987
Loss at iteration 1430 : 0.01537234801799059
Loss at iteration 1440 : 0.05114288628101349
Loss at iteration 1450 : 0.01986190862953663
Loss at iteration 1460 : 0.01548118144273758
Loss at iteration 1470 : 0.5958879590034485
Loss at iteration 1480 : 0.031363680958747864
Loss at iteration 1490 : 0.02623051404953003
Loss at iteration 1500 : 0.026841137558221817
Loss at iteration 1510 : 0.04914794862270355
Loss at iteration 1520 : 0.0238102525472641
Loss at iteration 1530 : 1.5810816287994385
Loss at iteration 1540 : 0.019123118370771408
Loss at iteration 1550 : 0.019415516406297684
Loss at iteration 1560 : 0.15279465913772583
Loss at iteration 1570 : 0.07434023916721344
Loss at iteration 1580 : 0.01564386673271656
Loss at iteration 1590 : 0.05694214999675751
Loss at iteration 1600 : 0.08523482084274292
Loss at iteration 1610 : 0.01953095756471157
Loss at iteration 1620 : 0.041638173162937164
Loss at iteration 1630 : 0.07181620597839355
Loss at iteration 1640 : 0.08185911923646927
Loss at iteration 1650 : 0.061959028244018555
Loss at iteration 1660 : 0.03937769681215286
Loss at iteration 1670 : 0.06478655338287354
Loss at iteration 1680 : 0.03983873873949051
Loss at iteration 1690 : 0.025118978694081306
Loss at iteration 1700 : 0.027213983237743378
Loss at iteration 1710 : 0.04400196671485901
Loss at iteration 1720 : 0.025270752608776093
Loss at iteration 1730 : 0.027311524376273155
Loss at iteration 1740 : 0.05343335121870041
Loss at iteration 1750 : 0.01981639862060547
Loss at iteration 1760 : 0.03413059562444687
Loss at iteration 1770 : 25.623626708984375
Loss at iteration 1780 : 0.036317259073257446
Loss at iteration 1790 : 0.021640924736857414
Loss at iteration 1800 : 0.03178734332323074
Loss at iteration 1810 : 0.13375748693943024
Loss at iteration 1820 : 0.04279276728630066
Loss at iteration 1830 : 0.021777402609586716
Loss at iteration 1840 : 0.023752491921186447
Loss at iteration 1850 : 0.05019545927643776
Loss at iteration 1860 : 0.7881568074226379
Loss at iteration 1870 : 0.033338528126478195
Loss at iteration 1880 : 0.11100374162197113
Loss at iteration 1890 : 0.04853422939777374
Loss at iteration 1900 : 2.526693344116211
Loss at iteration 1910 : 0.01669929549098015
Loss at iteration 1920 : 0.04629076272249222
Loss at iteration 1930 : 0.031654711812734604
Loss at iteration 1940 : 0.059265825897455215
Loss at iteration 1950 : 0.1011820137500763
Loss at iteration 1960 : 0.08987502753734589
Loss at iteration 1970 : 0.2038741111755371
Loss at iteration 1980 : 0.07365914434194565
Loss at iteration 1990 : 0.02996235340833664
Loss at iteration 2000 : 0.02128106914460659
Loss at iteration 2010 : 0.03488801792263985
Loss at iteration 2020 : 0.03724471852183342
Loss at iteration 2030 : 0.5369136929512024
Loss at iteration 2040 : 0.020129717886447906
Loss at iteration 2050 : 0.03558656573295593
Loss at iteration 2060 : 0.05526450276374817
Loss at iteration 2070 : 0.01412222906947136
Loss at iteration 2080 : 0.06160644441843033
Loss at iteration 2090 : 0.028998540714383125
Loss at iteration 2100 : 0.022998273372650146
Loss at iteration 2110 : 0.8328629732131958
Loss at iteration 2120 : 0.13038188219070435
Loss at iteration 2130 : 0.01566256582736969
Loss at iteration 2140 : 0.0330643430352211
Loss at iteration 2150 : 0.036485329270362854
Loss at iteration 2160 : 0.015371613204479218
Loss at iteration 2170 : 0.032183803617954254
Loss at iteration 2180 : 0.025017593055963516
Loss at iteration 2190 : 0.08172592520713806
Loss at iteration 2200 : 0.056517526507377625
Loss at iteration 2210 : 0.019629966467618942
Loss at iteration 2220 : 0.06324420124292374
Loss at iteration 2230 : 0.016549522057175636
Loss at iteration 2240 : 0.0152034442871809
Loss at iteration 2250 : 0.049939870834350586
Loss at iteration 2260 : 0.05052865669131279
Loss at iteration 2270 : 1.203477382659912
Loss at iteration 2280 : 0.01961565762758255
Loss at iteration 2290 : 0.03513147309422493
Loss at iteration 2300 : 0.01799943670630455
Loss at iteration 2310 : 0.021115344017744064
Loss at iteration 2320 : 0.04344125837087631
Loss at iteration 2330 : 5.924866676330566
Loss at iteration 2340 : 0.039518386125564575
Loss at iteration 2350 : 1.863032579421997
Loss at iteration 2360 : 0.020499270409345627
Loss at iteration 2370 : 0.8215311765670776
Loss at iteration 2380 : 0.03254728391766548
Loss at iteration 2390 : 0.07237973809242249
Loss at iteration 2400 : 0.29392459988594055
Loss at iteration 2410 : 0.036277830600738525
Loss at iteration 2420 : 0.064263254404068
The SSIM Value is: 0.5300024887546897
The PSNR Value is: 10.68944194316864
the epoch is: 122
Loss at iteration 10 : 0.051638953387737274
Loss at iteration 20 : 0.04238962009549141
Loss at iteration 30 : 0.04341169446706772
Loss at iteration 40 : 0.21200045943260193
Loss at iteration 50 : 0.023676877841353416
Loss at iteration 60 : 0.05592208355665207
Loss at iteration 70 : 83.45948791503906
Loss at iteration 80 : 0.0456632524728775
Loss at iteration 90 : 0.05598032847046852
Loss at iteration 100 : 0.042725637555122375
Loss at iteration 110 : 0.04420416057109833
Loss at iteration 120 : 0.03999819606542587
Loss at iteration 130 : 0.02173168584704399
Loss at iteration 140 : 0.011230315081775188
Loss at iteration 150 : 0.025853721424937248
Loss at iteration 160 : 0.04077114164829254
Loss at iteration 170 : 0.05756850913167
Loss at iteration 180 : 0.01841842010617256
Loss at iteration 190 : 0.3754379153251648
Loss at iteration 200 : 0.035749804228544235
Loss at iteration 210 : 0.059145137667655945
Loss at iteration 220 : 0.03968223184347153
Loss at iteration 230 : 0.03972933813929558
Loss at iteration 240 : 0.024334542453289032
Loss at iteration 250 : 0.034483253955841064
Loss at iteration 260 : 0.04825620353221893
Loss at iteration 270 : 0.03563298285007477
Loss at iteration 280 : 0.040893785655498505
Loss at iteration 290 : 0.030651992186903954
Loss at iteration 300 : 0.05077609792351723
Loss at iteration 310 : 0.032617270946502686
Loss at iteration 320 : 0.06719189882278442
Loss at iteration 330 : 0.14493419229984283
Loss at iteration 340 : 0.029892846941947937
Loss at iteration 350 : 0.0283274594694376
Loss at iteration 360 : 0.02792229689657688
Loss at iteration 370 : 0.048465609550476074
Loss at iteration 380 : 0.035631150007247925
Loss at iteration 390 : 0.10207968205213547
Loss at iteration 400 : 0.20244838297367096
Loss at iteration 410 : 0.032015927135944366
Loss at iteration 420 : 0.6201473474502563
Loss at iteration 430 : 0.014113210141658783
Loss at iteration 440 : 0.029055319726467133
Loss at iteration 450 : 0.04945105314254761
Loss at iteration 460 : 0.03848160803318024
Loss at iteration 470 : 0.03646031394600868
Loss at iteration 480 : 0.36356934905052185
Loss at iteration 490 : 0.027826683595776558
Loss at iteration 500 : 0.024797923862934113
Loss at iteration 510 : 0.034946709871292114
Loss at iteration 520 : 0.018502984195947647
Loss at iteration 530 : 0.014030063524842262
Loss at iteration 540 : 0.061813145875930786
Loss at iteration 550 : 0.07006042450666428
Loss at iteration 560 : 0.06206582859158516
Loss at iteration 570 : 0.08395928144454956
Loss at iteration 580 : 0.034989871084690094
Loss at iteration 590 : 0.01855822093784809
Loss at iteration 600 : 0.02855205163359642
Loss at iteration 610 : 0.01909928396344185
Loss at iteration 620 : 0.04180037975311279
Loss at iteration 630 : 0.024243684485554695
Loss at iteration 640 : 0.06418005377054214
Loss at iteration 650 : 0.022931531071662903
Loss at iteration 660 : 0.06504305452108383
Loss at iteration 670 : 0.05668766424059868
Loss at iteration 680 : 0.7861322164535522
Loss at iteration 690 : 0.48855331540107727
Loss at iteration 700 : 0.059445545077323914
Loss at iteration 710 : 0.05693654716014862
Loss at iteration 720 : 0.03293994814157486
Loss at iteration 730 : 0.44419336318969727
Loss at iteration 740 : 0.02836497500538826
Loss at iteration 750 : 0.013061128556728363
Loss at iteration 760 : 0.0345480814576149
Loss at iteration 770 : 0.05318152531981468
Loss at iteration 780 : 0.044063910841941833
Loss at iteration 790 : 0.051979802548885345
Loss at iteration 800 : 0.027520913630723953
Loss at iteration 810 : 0.10388126224279404
Loss at iteration 820 : 0.016047511249780655
Loss at iteration 830 : 0.0295353252440691
Loss at iteration 840 : 0.027346894145011902
Loss at iteration 850 : 0.04118427261710167
Loss at iteration 860 : 0.025676075369119644
Loss at iteration 870 : 0.04030611738562584
Loss at iteration 880 : 0.01694767363369465
Loss at iteration 890 : 0.03338581696152687
Loss at iteration 900 : 0.38172996044158936
Loss at iteration 910 : 0.026454247534275055
Loss at iteration 920 : 0.027338599786162376
Loss at iteration 930 : 0.05233108997344971
Loss at iteration 940 : 0.04738572984933853
Loss at iteration 950 : 0.0358644463121891
Loss at iteration 960 : 0.04025624692440033
Loss at iteration 970 : 0.04567662253975868
Loss at iteration 980 : 0.025222498923540115
Loss at iteration 990 : 0.03498654067516327
Loss at iteration 1000 : 0.062194064259529114
Loss at iteration 1010 : 0.02741728350520134
Loss at iteration 1020 : 0.01657882332801819
Loss at iteration 1030 : 0.02158026024699211
Loss at iteration 1040 : 0.1323387324810028
Loss at iteration 1050 : 0.02929484099149704
Loss at iteration 1060 : 0.09459608793258667
Loss at iteration 1070 : 0.05009738355875015
Loss at iteration 1080 : 0.022908542305231094
Loss at iteration 1090 : 0.08912168443202972
Loss at iteration 1100 : 0.03845960274338722
Loss at iteration 1110 : 0.07863013446331024
Loss at iteration 1120 : 0.017984014004468918
Loss at iteration 1130 : 0.02884114533662796
Loss at iteration 1140 : 0.055789150297641754
Loss at iteration 1150 : 0.040042102336883545
Loss at iteration 1160 : 0.03525197505950928
Loss at iteration 1170 : 0.030897442251443863
Loss at iteration 1180 : 0.00975789874792099
Loss at iteration 1190 : 0.012866565026342869
Loss at iteration 1200 : 0.0254486296325922
Loss at iteration 1210 : 0.06392762809991837
Loss at iteration 1220 : 0.017625898122787476
Loss at iteration 1230 : 0.05150175839662552
Loss at iteration 1240 : 0.02318623661994934
Loss at iteration 1250 : 0.012795339338481426
Loss at iteration 1260 : 0.028788231313228607
Loss at iteration 1270 : 0.19358474016189575
Loss at iteration 1280 : 0.032796189188957214
Loss at iteration 1290 : 0.05601070821285248
Loss at iteration 1300 : 0.10439559817314148
Loss at iteration 1310 : 0.028642430901527405
Loss at iteration 1320 : 0.03055558353662491
Loss at iteration 1330 : 0.020486297085881233
Loss at iteration 1340 : 0.07516706734895706
Loss at iteration 1350 : 0.02301083691418171
Loss at iteration 1360 : 0.07414281368255615
Loss at iteration 1370 : 0.02663005329668522
Loss at iteration 1380 : 0.02131832018494606
Loss at iteration 1390 : 0.020586194470524788
Loss at iteration 1400 : 0.03615005314350128
Loss at iteration 1410 : 0.06302439421415329
Loss at iteration 1420 : 4.14532995223999
Loss at iteration 1430 : 0.015773054212331772
Loss at iteration 1440 : 0.021531544625759125
Loss at iteration 1450 : 0.021406371146440506
Loss at iteration 1460 : 0.02526986040174961
Loss at iteration 1470 : 1.2628387212753296
Loss at iteration 1480 : 0.02304607816040516
Loss at iteration 1490 : 0.01834629848599434
Loss at iteration 1500 : 0.8581154346466064
Loss at iteration 1510 : 0.03440525755286217
Loss at iteration 1520 : 0.01860342174768448
Loss at iteration 1530 : 0.033315643668174744
Loss at iteration 1540 : 0.02145896479487419
Loss at iteration 1550 : 0.06585994362831116
Loss at iteration 1560 : 0.04452841728925705
Loss at iteration 1570 : 1.1953855752944946
Loss at iteration 1580 : 0.022651396691799164
Loss at iteration 1590 : 0.018496505916118622
Loss at iteration 1600 : 3.6701693534851074
Loss at iteration 1610 : 0.024799350649118423
Loss at iteration 1620 : 0.03340115770697594
Loss at iteration 1630 : 0.03576068952679634
Loss at iteration 1640 : 0.03522935137152672
Loss at iteration 1650 : 0.03906934708356857
Loss at iteration 1660 : 0.046756431460380554
Loss at iteration 1670 : 0.031604476273059845
Loss at iteration 1680 : 0.025214511901140213
Loss at iteration 1690 : 0.02502311021089554
Loss at iteration 1700 : 0.05243491381406784
Loss at iteration 1710 : 0.04632008075714111
Loss at iteration 1720 : 0.01908878982067108
Loss at iteration 1730 : 0.318157434463501
Loss at iteration 1740 : 0.031538285315036774
Loss at iteration 1750 : 2.6648097038269043
Loss at iteration 1760 : 0.029908720403909683
Loss at iteration 1770 : 0.012429208494722843
Loss at iteration 1780 : 0.03919845074415207
Loss at iteration 1790 : 0.018203025683760643
Loss at iteration 1800 : 0.051391564309597015
Loss at iteration 1810 : 0.05976193770766258
Loss at iteration 1820 : 0.030559487640857697
Loss at iteration 1830 : 0.02011353336274624
Loss at iteration 1840 : 0.044461190700531006
Loss at iteration 1850 : 0.5990662574768066
Loss at iteration 1860 : 0.07262769341468811
Loss at iteration 1870 : 0.038222551345825195
Loss at iteration 1880 : 0.019048873335123062
Loss at iteration 1890 : 0.060849662870168686
Loss at iteration 1900 : 0.04077136516571045
Loss at iteration 1910 : 0.02998538501560688
Loss at iteration 1920 : 0.025940777733922005
Loss at iteration 1930 : 0.022443730384111404
Loss at iteration 1940 : 0.018332330510020256
Loss at iteration 1950 : 0.20849283039569855
Loss at iteration 1960 : 0.024293040856719017
Loss at iteration 1970 : 0.03578181564807892
Loss at iteration 1980 : 0.03831053897738457
Loss at iteration 1990 : 0.5560703873634338
Loss at iteration 2000 : 0.021603673696517944
Loss at iteration 2010 : 0.03525751084089279
Loss at iteration 2020 : 0.08354011178016663
Loss at iteration 2030 : 0.040428392589092255
Loss at iteration 2040 : 0.017502933740615845
Loss at iteration 2050 : 0.026399847120046616
Loss at iteration 2060 : 0.03477727621793747
Loss at iteration 2070 : 0.021217206493020058
Loss at iteration 2080 : 0.027956031262874603
Loss at iteration 2090 : 0.022967951372265816
Loss at iteration 2100 : 0.04629438370466232
Loss at iteration 2110 : 0.029134728014469147
Loss at iteration 2120 : 0.01764814555644989
Loss at iteration 2130 : 0.025844380259513855
Loss at iteration 2140 : 0.017692474648356438
Loss at iteration 2150 : 0.029605882242321968
Loss at iteration 2160 : 0.034379687160253525
Loss at iteration 2170 : 0.04518146067857742
Loss at iteration 2180 : 0.016773736104369164
Loss at iteration 2190 : 0.029049929231405258
Loss at iteration 2200 : 0.023218780755996704
Loss at iteration 2210 : 0.03644658625125885
Loss at iteration 2220 : 0.025594884529709816
Loss at iteration 2230 : 0.029504358768463135
Loss at iteration 2240 : 0.02587127313017845
Loss at iteration 2250 : 0.020800519734621048
Loss at iteration 2260 : 0.01787531189620495
Loss at iteration 2270 : 0.014879502356052399
Loss at iteration 2280 : 0.04603377357125282
Loss at iteration 2290 : 0.0292825810611248
Loss at iteration 2300 : 0.03337183594703674
Loss at iteration 2310 : 0.0333167165517807
Loss at iteration 2320 : 0.03782016783952713
Loss at iteration 2330 : 0.013855811208486557
Loss at iteration 2340 : 0.03132491558790207
Loss at iteration 2350 : 0.06460144370794296
Loss at iteration 2360 : 0.019138678908348083
Loss at iteration 2370 : 0.02179059386253357
Loss at iteration 2380 : 0.037003710865974426
Loss at iteration 2390 : 0.025854967534542084
Loss at iteration 2400 : 0.05073379725217819
Loss at iteration 2410 : 0.03298337757587433
Loss at iteration 2420 : 0.14585348963737488
The SSIM Value is: 0.5974534009893735
The PSNR Value is: 12.159655539194743
the epoch is: 123
Loss at iteration 10 : 0.015745040029287338
Loss at iteration 20 : 0.043775562196969986
Loss at iteration 30 : 0.02353762462735176
Loss at iteration 40 : 0.0346846729516983
Loss at iteration 50 : 0.033300139009952545
Loss at iteration 60 : 0.0388469398021698
Loss at iteration 70 : 0.03297337144613266
Loss at iteration 80 : 0.8640540838241577
Loss at iteration 90 : 0.024600958451628685
Loss at iteration 100 : 0.04050608351826668
Loss at iteration 110 : 0.019310038536787033
Loss at iteration 120 : 0.03160404413938522
Loss at iteration 130 : 0.059515248984098434
Loss at iteration 140 : 0.031708620488643646
Loss at iteration 150 : 0.03257988765835762
Loss at iteration 160 : 0.07948432117700577
Loss at iteration 170 : 0.030870165675878525
Loss at iteration 180 : 0.04383646696805954
Loss at iteration 190 : 0.03458534926176071
Loss at iteration 200 : 0.012258575297892094
Loss at iteration 210 : 0.0234198197722435
Loss at iteration 220 : 0.09357455372810364
Loss at iteration 230 : 0.030264753848314285
Loss at iteration 240 : 0.03522317856550217
Loss at iteration 250 : 0.0220298171043396
Loss at iteration 260 : 0.2186729460954666
Loss at iteration 270 : 0.04608626291155815
Loss at iteration 280 : 0.7102890014648438
Loss at iteration 290 : 0.027412712574005127
Loss at iteration 300 : 0.02346605248749256
Loss at iteration 310 : 0.028065018355846405
Loss at iteration 320 : 0.021636325865983963
Loss at iteration 330 : 0.022101299837231636
Loss at iteration 340 : 0.019864879548549652
Loss at iteration 350 : 0.03615458309650421
Loss at iteration 360 : 0.022665992379188538
Loss at iteration 370 : 0.017487814649939537
Loss at iteration 380 : 0.042171791195869446
Loss at iteration 390 : 0.03321390226483345
Loss at iteration 400 : 0.0196557454764843
Loss at iteration 410 : 0.03285681828856468
Loss at iteration 420 : 0.02622836083173752
Loss at iteration 430 : 0.02301175519824028
Loss at iteration 440 : 0.011302541941404343
Loss at iteration 450 : 0.046489015221595764
Loss at iteration 460 : 0.05405132472515106
Loss at iteration 470 : 0.04905914142727852
Loss at iteration 480 : 0.04166332259774208
Loss at iteration 490 : 0.03526970371603966
Loss at iteration 500 : 0.019758816808462143
Loss at iteration 510 : 0.021565554663538933
Loss at iteration 520 : 0.030110549181699753
Loss at iteration 530 : 0.04050065577030182
Loss at iteration 540 : 0.01756465435028076
Loss at iteration 550 : 0.02312162145972252
Loss at iteration 560 : 0.6146202683448792
Loss at iteration 570 : 1.1625244617462158
Loss at iteration 580 : 0.04735758155584335
Loss at iteration 590 : 0.039023615419864655
Loss at iteration 600 : 0.032688289880752563
Loss at iteration 610 : 0.04165871441364288
Loss at iteration 620 : 0.03788336366415024
Loss at iteration 630 : 0.014513818547129631
Loss at iteration 640 : 0.012656539678573608
Loss at iteration 650 : 0.12836280465126038
Loss at iteration 660 : 0.038707029074430466
Loss at iteration 670 : 0.031775448471307755
Loss at iteration 680 : 0.046903096139431
Loss at iteration 690 : 0.03703302517533302
Loss at iteration 700 : 0.03217511251568794
Loss at iteration 710 : 0.020616335794329643
Loss at iteration 720 : 0.048634711652994156
Loss at iteration 730 : 0.031219473108649254
Loss at iteration 740 : 0.0501769594848156
Loss at iteration 750 : 0.041791051626205444
Loss at iteration 760 : 0.5467774868011475
Loss at iteration 770 : 0.028422413393855095
Loss at iteration 780 : 0.24660025537014008
Loss at iteration 790 : 0.037606194615364075
Loss at iteration 800 : 0.07330043613910675
Loss at iteration 810 : 0.3188713788986206
Loss at iteration 820 : 0.11512263119220734
Loss at iteration 830 : 0.0326499380171299
Loss at iteration 840 : 0.018058400601148605
Loss at iteration 850 : 0.47797831892967224
Loss at iteration 860 : 0.040231309831142426
Loss at iteration 870 : 0.048485931009054184
Loss at iteration 880 : 0.05705120414495468
Loss at iteration 890 : 0.030436696484684944
Loss at iteration 900 : 0.051416561007499695
Loss at iteration 910 : 0.022239945828914642
Loss at iteration 920 : 0.030726652592420578
Loss at iteration 930 : 0.023286985233426094
Loss at iteration 940 : 0.031791508197784424
Loss at iteration 950 : 0.0617128387093544
Loss at iteration 960 : 0.02985738217830658
Loss at iteration 970 : 0.03808961436152458
Loss at iteration 980 : 0.033598534762859344
Loss at iteration 990 : 0.017128368839621544
Loss at iteration 1000 : 0.012974356301128864
Loss at iteration 1010 : 0.02299841307103634
Loss at iteration 1020 : 0.03729069605469704
Loss at iteration 1030 : 0.020285705104470253
Loss at iteration 1040 : 0.017267033457756042
Loss at iteration 1050 : 0.04242503643035889
Loss at iteration 1060 : 0.034181900322437286
Loss at iteration 1070 : 0.0177441518753767
Loss at iteration 1080 : 0.02466234378516674
Loss at iteration 1090 : 0.014045125804841518
Loss at iteration 1100 : 0.03625690937042236
Loss at iteration 1110 : 0.25458770990371704
Loss at iteration 1120 : 0.02311643958091736
Loss at iteration 1130 : 0.02208710089325905
Loss at iteration 1140 : 0.04288428649306297
Loss at iteration 1150 : 0.03311938792467117
Loss at iteration 1160 : 0.3362879753112793
Loss at iteration 1170 : 0.03837522864341736
Loss at iteration 1180 : 0.03037000633776188
Loss at iteration 1190 : 0.053160447627305984
Loss at iteration 1200 : 0.051652099937200546
Loss at iteration 1210 : 0.027989059686660767
Loss at iteration 1220 : 0.017594769597053528
Loss at iteration 1230 : 0.03283810615539551
Loss at iteration 1240 : 0.045865654945373535
Loss at iteration 1250 : 0.024472825229167938
Loss at iteration 1260 : 0.023396220058202744
Loss at iteration 1270 : 0.061227716505527496
Loss at iteration 1280 : 0.02142014354467392
Loss at iteration 1290 : 0.020894348621368408
Loss at iteration 1300 : 0.05125413462519646
Loss at iteration 1310 : 0.02097722515463829
Loss at iteration 1320 : 0.020529810339212418
Loss at iteration 1330 : 0.045094020664691925
Loss at iteration 1340 : 0.06866124272346497
Loss at iteration 1350 : 0.025147002190351486
Loss at iteration 1360 : 0.021671324968338013
Loss at iteration 1370 : 0.03913591057062149
Loss at iteration 1380 : 0.04462631419301033
Loss at iteration 1390 : 0.3598482310771942
Loss at iteration 1400 : 0.028042202815413475
Loss at iteration 1410 : 0.02080116979777813
Loss at iteration 1420 : 0.03409431129693985
Loss at iteration 1430 : 0.11192761361598969
Loss at iteration 1440 : 0.02079569175839424
Loss at iteration 1450 : 0.13995178043842316
Loss at iteration 1460 : 0.04770045354962349
Loss at iteration 1470 : 0.01310303807258606
Loss at iteration 1480 : 0.02056708186864853
Loss at iteration 1490 : 0.017720064148306847
Loss at iteration 1500 : 0.03859296813607216
Loss at iteration 1510 : 0.041040316224098206
Loss at iteration 1520 : 0.2158532589673996
Loss at iteration 1530 : 0.2039278745651245
Loss at iteration 1540 : 0.010797959752380848
Loss at iteration 1550 : 0.009658797644078732
Loss at iteration 1560 : 0.01948036625981331
Loss at iteration 1570 : 0.028859158977866173
Loss at iteration 1580 : 0.023266300559043884
Loss at iteration 1590 : 0.03354986384510994
Loss at iteration 1600 : 0.014604643918573856
Loss at iteration 1610 : 0.019672533497214317
Loss at iteration 1620 : 0.026098832488059998
Loss at iteration 1630 : 0.0589464046061039
Loss at iteration 1640 : 0.03679528832435608
Loss at iteration 1650 : 0.02282090112566948
Loss at iteration 1660 : 0.04138338193297386
Loss at iteration 1670 : 0.04028405621647835
Loss at iteration 1680 : 0.021867547184228897
Loss at iteration 1690 : 0.023652713745832443
Loss at iteration 1700 : 0.019793935120105743
Loss at iteration 1710 : 0.01845652237534523
Loss at iteration 1720 : 0.03530050814151764
Loss at iteration 1730 : 0.038491394370794296
Loss at iteration 1740 : 0.12311132252216339
Loss at iteration 1750 : 0.013191446661949158
Loss at iteration 1760 : 0.01793133094906807
Loss at iteration 1770 : 0.07261958718299866
Loss at iteration 1780 : 0.02913188561797142
Loss at iteration 1790 : 0.02637554705142975
Loss at iteration 1800 : 0.045305974781513214
Loss at iteration 1810 : 0.04183211177587509
Loss at iteration 1820 : 0.7495125532150269
Loss at iteration 1830 : 0.02024563029408455
Loss at iteration 1840 : 0.0319497287273407
Loss at iteration 1850 : 0.018005570396780968
Loss at iteration 1860 : 0.034907933324575424
Loss at iteration 1870 : 0.01656973734498024
Loss at iteration 1880 : 0.03844280540943146
Loss at iteration 1890 : 0.027862606570124626
Loss at iteration 1900 : 0.07378710061311722
Loss at iteration 1910 : 0.034294333308935165
Loss at iteration 1920 : 0.028240105137228966
Loss at iteration 1930 : 0.025203324854373932
Loss at iteration 1940 : 0.028730880469083786
Loss at iteration 1950 : 0.052477218210697174
Loss at iteration 1960 : 0.018853263929486275
Loss at iteration 1970 : 0.022644352167844772
Loss at iteration 1980 : 0.06885732710361481
Loss at iteration 1990 : 0.03361424431204796
Loss at iteration 2000 : 0.018776314333081245
Loss at iteration 2010 : 0.03746068477630615
Loss at iteration 2020 : 0.033388812094926834
Loss at iteration 2030 : 0.02835036814212799
Loss at iteration 2040 : 0.037166208028793335
Loss at iteration 2050 : 0.04825560748577118
Loss at iteration 2060 : 0.02815738506615162
Loss at iteration 2070 : 0.044607143849134445
Loss at iteration 2080 : 0.07352093607187271
Loss at iteration 2090 : 0.10847124457359314
Loss at iteration 2100 : 0.03871376812458038
Loss at iteration 2110 : 0.0463227853178978
Loss at iteration 2120 : 0.030663609504699707
Loss at iteration 2130 : 0.021846694871783257
Loss at iteration 2140 : 0.027973797172307968
Loss at iteration 2150 : 0.03015976771712303
Loss at iteration 2160 : 0.03933586925268173
Loss at iteration 2170 : 0.014151198789477348
Loss at iteration 2180 : 0.03676426410675049
Loss at iteration 2190 : 0.03904951363801956
Loss at iteration 2200 : 0.012715106830000877
Loss at iteration 2210 : 0.023516245186328888
Loss at iteration 2220 : 0.019068103283643723
Loss at iteration 2230 : 0.02508699707686901
Loss at iteration 2240 : 0.03222942352294922
Loss at iteration 2250 : 0.021295364946126938
Loss at iteration 2260 : 0.05342504382133484
Loss at iteration 2270 : 0.020186763256788254
Loss at iteration 2280 : 0.015694070607423782
Loss at iteration 2290 : 0.04561086744070053
Loss at iteration 2300 : 0.03061726689338684
Loss at iteration 2310 : 0.03173872083425522
Loss at iteration 2320 : 0.03145436570048332
Loss at iteration 2330 : 0.022260207682847977
Loss at iteration 2340 : 0.0234706848859787
Loss at iteration 2350 : 0.49496835470199585
Loss at iteration 2360 : 0.013731048442423344
Loss at iteration 2370 : 0.3579903244972229
Loss at iteration 2380 : 0.0694558322429657
Loss at iteration 2390 : 0.05612810701131821
Loss at iteration 2400 : 0.03500451147556305
Loss at iteration 2410 : 0.04873865842819214
Loss at iteration 2420 : 0.039476826786994934
The SSIM Value is: 0.680566452940305
The PSNR Value is: 16.278299204508464
the epoch is: 124
Loss at iteration 10 : 0.029093172401189804
Loss at iteration 20 : 0.03018254041671753
Loss at iteration 30 : 0.019803546369075775
Loss at iteration 40 : 0.9721865653991699
Loss at iteration 50 : 0.07049062848091125
Loss at iteration 60 : 0.03049325942993164
Loss at iteration 70 : 0.06536245346069336
Loss at iteration 80 : 0.02057419717311859
Loss at iteration 90 : 0.07281804084777832
Loss at iteration 100 : 0.04112262278795242
Loss at iteration 110 : 0.028788525611162186
Loss at iteration 120 : 0.020279191434383392
Loss at iteration 130 : 0.029802557080984116
Loss at iteration 140 : 0.012287665158510208
Loss at iteration 150 : 0.018325183540582657
Loss at iteration 160 : 0.013715531677007675
Loss at iteration 170 : 0.032354019582271576
Loss at iteration 180 : 0.048345547169446945
Loss at iteration 190 : 0.0162165816873312
Loss at iteration 200 : 0.024721898138523102
Loss at iteration 210 : 0.022992197424173355
Loss at iteration 220 : 0.021127965301275253
Loss at iteration 230 : 0.049128785729408264
Loss at iteration 240 : 0.044527001678943634
Loss at iteration 250 : 2.161957263946533
Loss at iteration 260 : 0.03054129332304001
Loss at iteration 270 : 0.010253841057419777
Loss at iteration 280 : 0.03687826916575432
Loss at iteration 290 : 0.020270168781280518
Loss at iteration 300 : 0.029342766851186752
Loss at iteration 310 : 0.022089175879955292
Loss at iteration 320 : 0.07087245583534241
Loss at iteration 330 : 0.026699066162109375
Loss at iteration 340 : 0.03611144423484802
Loss at iteration 350 : 0.040774524211883545
Loss at iteration 360 : 0.016248662024736404
Loss at iteration 370 : 0.023413944989442825
Loss at iteration 380 : 0.029814455658197403
Loss at iteration 390 : 0.8591383695602417
Loss at iteration 400 : 0.02150673232972622
Loss at iteration 410 : 0.023089466616511345
Loss at iteration 420 : 0.05109960585832596
Loss at iteration 430 : 0.020109759643673897
Loss at iteration 440 : 0.07347988337278366
Loss at iteration 450 : 0.06813903898000717
Loss at iteration 460 : 0.043842751532793045
Loss at iteration 470 : 0.023262619972229004
Loss at iteration 480 : 0.041257139295339584
Loss at iteration 490 : 0.02126898244023323
Loss at iteration 500 : 0.028482932597398758
Loss at iteration 510 : 0.03147132694721222
Loss at iteration 520 : 0.021617326885461807
Loss at iteration 530 : 0.03739497810602188
Loss at iteration 540 : 0.052321866154670715
Loss at iteration 550 : 0.03475488722324371
Loss at iteration 560 : 0.03178827092051506
Loss at iteration 570 : 0.023834016174077988
Loss at iteration 580 : 0.027914345264434814
Loss at iteration 590 : 0.021101828664541245
Loss at iteration 600 : 0.07324794679880142
Loss at iteration 610 : 0.024640768766403198
Loss at iteration 620 : 0.02305598370730877
Loss at iteration 630 : 0.021700790151953697
Loss at iteration 640 : 0.03438989073038101
Loss at iteration 650 : 0.2031625211238861
Loss at iteration 660 : 0.027649864554405212
Loss at iteration 670 : 0.03726428747177124
Loss at iteration 680 : 0.0380592867732048
Loss at iteration 690 : 0.03359271213412285
Loss at iteration 700 : 0.02301403135061264
Loss at iteration 710 : 0.837631106376648
Loss at iteration 720 : 0.3539543151855469
Loss at iteration 730 : 0.02160763368010521
Loss at iteration 740 : 0.029290838167071342
Loss at iteration 750 : 0.29381847381591797
Loss at iteration 760 : 0.027886291965842247
Loss at iteration 770 : 0.0961412712931633
Loss at iteration 780 : 0.037728387862443924
Loss at iteration 790 : 0.034273918718099594
Loss at iteration 800 : 0.6342592835426331
Loss at iteration 810 : 0.023753304034471512
Loss at iteration 820 : 0.019293438643217087
Loss at iteration 830 : 0.03963008522987366
Loss at iteration 840 : 0.029887959361076355
Loss at iteration 850 : 0.01772351562976837
Loss at iteration 860 : 0.022646838799118996
Loss at iteration 870 : 0.05339554697275162
Loss at iteration 880 : 0.035387467592954636
Loss at iteration 890 : 0.15112856030464172
Loss at iteration 900 : 0.03795567527413368
Loss at iteration 910 : 0.02543124556541443
Loss at iteration 920 : 0.02285618893802166
Loss at iteration 930 : 0.033521201461553574
Loss at iteration 940 : 0.015297293663024902
Loss at iteration 950 : 0.03155805915594101
Loss at iteration 960 : 0.025859978049993515
Loss at iteration 970 : 0.06707357615232468
Loss at iteration 980 : 0.03618595749139786
Loss at iteration 990 : 0.030048804357647896
Loss at iteration 1000 : 0.06290073692798615
Loss at iteration 1010 : 0.03664570674300194
Loss at iteration 1020 : 0.019834186881780624
Loss at iteration 1030 : 0.024447277188301086
Loss at iteration 1040 : 0.030104639008641243
Loss at iteration 1050 : 0.0419381707906723
Loss at iteration 1060 : 0.016982711851596832
Loss at iteration 1070 : 0.02003970742225647
Loss at iteration 1080 : 0.030911408364772797
Loss at iteration 1090 : 0.019512273371219635
Loss at iteration 1100 : 0.01828756183385849
Loss at iteration 1110 : 0.02849789336323738
Loss at iteration 1120 : 0.025614192709326744
Loss at iteration 1130 : 0.022459261119365692
Loss at iteration 1140 : 0.029108356684446335
Loss at iteration 1150 : 0.07330715656280518
Loss at iteration 1160 : 0.03655783832073212
Loss at iteration 1170 : 0.03955423831939697
Loss at iteration 1180 : 0.02024831995368004
Loss at iteration 1190 : 0.038325972855091095
Loss at iteration 1200 : 0.03485414385795593
Loss at iteration 1210 : 0.040889374911785126
Loss at iteration 1220 : 0.04045535996556282
Loss at iteration 1230 : 0.025981437414884567
Loss at iteration 1240 : 0.03294718638062477
Loss at iteration 1250 : 0.025214914232492447
Loss at iteration 1260 : 0.04727645218372345
Loss at iteration 1270 : 0.03991593420505524
Loss at iteration 1280 : 0.017511282116174698
Loss at iteration 1290 : 0.04643489792943001
Loss at iteration 1300 : 0.014836035668849945
Loss at iteration 1310 : 0.021760795265436172
Loss at iteration 1320 : 0.1954277902841568
Loss at iteration 1330 : 0.013020885176956654
Loss at iteration 1340 : 0.41341984272003174
Loss at iteration 1350 : 0.028709640726447105
Loss at iteration 1360 : 0.02732200361788273
Loss at iteration 1370 : 0.03638361766934395
Loss at iteration 1380 : 0.012826313264667988
Loss at iteration 1390 : 0.04830692708492279
Loss at iteration 1400 : 0.04055623337626457
Loss at iteration 1410 : 0.030241558328270912
Loss at iteration 1420 : 0.020586881786584854
Loss at iteration 1430 : 0.01562693528831005
Loss at iteration 1440 : 0.3876681625843048
Loss at iteration 1450 : 0.49082258343696594
Loss at iteration 1460 : 0.022884905338287354
Loss at iteration 1470 : 0.05317497253417969
Loss at iteration 1480 : 0.030846599489450455
Loss at iteration 1490 : 0.04508746787905693
Loss at iteration 1500 : 0.04367484152317047
Loss at iteration 1510 : 0.04926291108131409
Loss at iteration 1520 : 0.03555101901292801
Loss at iteration 1530 : 0.14720718562602997
Loss at iteration 1540 : 0.024967048317193985
Loss at iteration 1550 : 0.029542941600084305
Loss at iteration 1560 : 0.045392103493213654
Loss at iteration 1570 : 0.12106108665466309
Loss at iteration 1580 : 0.03919658064842224
Loss at iteration 1590 : 0.016421325504779816
Loss at iteration 1600 : 0.07137785851955414
Loss at iteration 1610 : 0.4674336016178131
Loss at iteration 1620 : 0.027964461594820023
Loss at iteration 1630 : 0.04069068282842636
Loss at iteration 1640 : 0.03055860847234726
Loss at iteration 1650 : 0.012948451563715935
Loss at iteration 1660 : 0.033726561814546585
Loss at iteration 1670 : 0.01628664880990982
Loss at iteration 1680 : 0.06612010300159454
Loss at iteration 1690 : 0.03463204950094223
Loss at iteration 1700 : 0.04957590997219086
Loss at iteration 1710 : 0.017311397939920425
Loss at iteration 1720 : 0.051781196147203445
Loss at iteration 1730 : 0.02041008323431015
Loss at iteration 1740 : 0.09836073219776154
Loss at iteration 1750 : 0.027997124940156937
Loss at iteration 1760 : 0.021722925826907158
Loss at iteration 1770 : 0.026169858872890472
Loss at iteration 1780 : 0.06279365718364716
Loss at iteration 1790 : 0.03542165458202362
Loss at iteration 1800 : 0.026185333728790283
Loss at iteration 1810 : 0.035444147884845734
Loss at iteration 1820 : 0.029042409732937813
Loss at iteration 1830 : 0.01234547607600689
Loss at iteration 1840 : 0.019440535455942154
Loss at iteration 1850 : 0.0178107637912035
Loss at iteration 1860 : 0.018338603898882866
Loss at iteration 1870 : 0.029925283044576645
Loss at iteration 1880 : 0.05104514956474304
Loss at iteration 1890 : 0.07946944981813431
Loss at iteration 1900 : 0.030950650572776794
Loss at iteration 1910 : 0.04336191341280937
Loss at iteration 1920 : 0.027100820094347
Loss at iteration 1930 : 0.019283246248960495
Loss at iteration 1940 : 0.03318245708942413
Loss at iteration 1950 : 0.018077427521348
Loss at iteration 1960 : 0.015886513516306877
Loss at iteration 1970 : 0.022871140390634537
Loss at iteration 1980 : 0.03731558844447136
Loss at iteration 1990 : 0.05981794744729996
Loss at iteration 2000 : 0.028184883296489716
Loss at iteration 2010 : 0.09479758143424988
Loss at iteration 2020 : 0.025371259078383446
Loss at iteration 2030 : 0.032726138830184937
Loss at iteration 2040 : 0.04040977358818054
Loss at iteration 2050 : 0.023083914071321487
Loss at iteration 2060 : 0.019447050988674164
Loss at iteration 2070 : 0.029438845813274384
Loss at iteration 2080 : 0.02442968264222145
Loss at iteration 2090 : 0.04698838293552399
Loss at iteration 2100 : 0.04166938364505768
Loss at iteration 2110 : 0.02015978842973709
Loss at iteration 2120 : 0.03245233744382858
Loss at iteration 2130 : 0.018264923244714737
Loss at iteration 2140 : 0.032282449305057526
Loss at iteration 2150 : 0.04897990822792053
Loss at iteration 2160 : 0.03314194828271866
Loss at iteration 2170 : 0.04590067267417908
Loss at iteration 2180 : 0.028420057147741318
Loss at iteration 2190 : 0.05191852152347565
Loss at iteration 2200 : 0.03456541895866394
Loss at iteration 2210 : 0.051121193915605545
Loss at iteration 2220 : 0.34387174248695374
Loss at iteration 2230 : 0.061707332730293274
Loss at iteration 2240 : 0.03360559046268463
Loss at iteration 2250 : 0.06539441645145416
Loss at iteration 2260 : 1.4767405986785889
Loss at iteration 2270 : 0.034662310034036636
Loss at iteration 2280 : 0.021682385355234146
Loss at iteration 2290 : 0.9361957311630249
Loss at iteration 2300 : 0.05032641440629959
Loss at iteration 2310 : 0.027776245027780533
Loss at iteration 2320 : 0.03513311967253685
Loss at iteration 2330 : 0.036580391228199005
Loss at iteration 2340 : 0.017600907012820244
Loss at iteration 2350 : 0.019898775964975357
Loss at iteration 2360 : 0.027203811332583427
Loss at iteration 2370 : 0.01761208102107048
Loss at iteration 2380 : 0.022314775735139847
Loss at iteration 2390 : 0.0167180635035038
Loss at iteration 2400 : 0.012227026745676994
Loss at iteration 2410 : 0.09711512178182602
Loss at iteration 2420 : 0.04667557775974274
The SSIM Value is: 0.5793973078330358
The PSNR Value is: 12.590657303730646
the epoch is: 125
Loss at iteration 10 : 0.027902469038963318
Loss at iteration 20 : 0.016139179468154907
Loss at iteration 30 : 0.0512814037501812
Loss at iteration 40 : 0.032120395451784134
Loss at iteration 50 : 0.021983923390507698
Loss at iteration 60 : 0.03673548251390457
Loss at iteration 70 : 0.06660515069961548
Loss at iteration 80 : 0.021194912493228912
Loss at iteration 90 : 0.03651643544435501
Loss at iteration 100 : 0.031214119866490364
Loss at iteration 110 : 0.031264446675777435
Loss at iteration 120 : 0.022659823298454285
Loss at iteration 130 : 0.059440117329359055
Loss at iteration 140 : 0.021272052079439163
Loss at iteration 150 : 0.02799791656434536
Loss at iteration 160 : 0.014815224334597588
Loss at iteration 170 : 0.026138857007026672
Loss at iteration 180 : 0.019768834114074707
Loss at iteration 190 : 0.021725019440054893
Loss at iteration 200 : 0.026954323053359985
Loss at iteration 210 : 0.04975399374961853
Loss at iteration 220 : 0.025186631828546524
Loss at iteration 230 : 0.02186393365263939
Loss at iteration 240 : 0.07453978061676025
Loss at iteration 250 : 0.03562574461102486
Loss at iteration 260 : 0.02924012579023838
Loss at iteration 270 : 0.02872471511363983
Loss at iteration 280 : 0.04317721724510193
Loss at iteration 290 : 0.028405167162418365
Loss at iteration 300 : 0.020285714417696
Loss at iteration 310 : 0.021712075918912888
Loss at iteration 320 : 0.03077293559908867
Loss at iteration 330 : 0.016582747921347618
Loss at iteration 340 : 0.026350820437073708
Loss at iteration 350 : 0.06232525408267975
Loss at iteration 360 : 0.9394374489784241
Loss at iteration 370 : 0.4094991981983185
Loss at iteration 380 : 0.06211131811141968
Loss at iteration 390 : 0.03985749930143356
Loss at iteration 400 : 0.4388306140899658
Loss at iteration 410 : 121.34254455566406
Loss at iteration 420 : 8.429178237915039
Loss at iteration 430 : 7.389601707458496
Loss at iteration 440 : 7255.935546875
Loss at iteration 450 : 0.6868830323219299
Loss at iteration 460 : 117.31599426269531
Loss at iteration 470 : 53333256.0
Loss at iteration 480 : 1261059.875
Loss at iteration 490 : 12869855.0
Loss at iteration 500 : 30710018048.0
Loss at iteration 510 : 1883914368.0
Loss at iteration 520 : 165373584.0
Loss at iteration 530 : 119045984.0
Loss at iteration 540 : 866794752.0
Loss at iteration 550 : 6378331648.0
Loss at iteration 560 : 36059709440.0
Loss at iteration 570 : 55713712.0
Loss at iteration 580 : 819596672.0
Loss at iteration 590 : 1494331904.0
Loss at iteration 600 : 678560000.0
Loss at iteration 610 : 338873664.0
Loss at iteration 620 : 64338988.0
Loss at iteration 630 : 2589958144.0
Loss at iteration 640 : 47601516544.0
Loss at iteration 650 : 37757521920.0
Loss at iteration 660 : 1848834176.0
Loss at iteration 670 : 3916414976.0
Loss at iteration 680 : 12317243392.0
Loss at iteration 690 : 3901520384.0
Loss at iteration 700 : 4454518272.0
Loss at iteration 710 : 4300045824.0
Loss at iteration 720 : 21484574720.0
Loss at iteration 730 : 3636028160.0
Loss at iteration 740 : 902962240.0
Loss at iteration 750 : 3458963200.0
Loss at iteration 760 : 6360021504.0
Loss at iteration 770 : 248222656.0
Loss at iteration 780 : 18201088.0
Loss at iteration 790 : 515401536.0
Loss at iteration 800 : 1403045504.0
Loss at iteration 810 : 137691408.0
Loss at iteration 820 : 185453392.0
Loss at iteration 830 : 125484040.0
Loss at iteration 840 : 1054790720.0
Loss at iteration 850 : 21210554.0
Loss at iteration 860 : 51928652.0
Loss at iteration 870 : 31576716.0
Loss at iteration 880 : 6254855.5
Loss at iteration 890 : 17846214.0
Loss at iteration 900 : 11499705.0
Loss at iteration 910 : 1157308.25
Loss at iteration 920 : 43133882368.0
Loss at iteration 930 : 29297772544.0
Loss at iteration 940 : 150485024.0
Loss at iteration 950 : 1633506304.0
Loss at iteration 960 : 1771466368.0
Loss at iteration 970 : 715596800.0
Loss at iteration 980 : 712236416.0
Loss at iteration 990 : 129890352.0
Loss at iteration 1000 : 95361048.0
Loss at iteration 1010 : 1092600832.0
Loss at iteration 1020 : 535277472.0
Loss at iteration 1030 : 2637107200.0
Loss at iteration 1040 : 1422788096.0
Loss at iteration 1050 : 879039616.0
Loss at iteration 1060 : 7354050048.0
Loss at iteration 1070 : 143507936.0
Loss at iteration 1080 : 917164480.0
Loss at iteration 1090 : 1074626944.0
Loss at iteration 1100 : 1801859328.0
Loss at iteration 1110 : 225318144.0
Loss at iteration 1120 : 908439936.0
Loss at iteration 1130 : 16910231552.0
Loss at iteration 1140 : 146045216.0
Loss at iteration 1150 : 702977344.0
Loss at iteration 1160 : 4094834432.0
Loss at iteration 1170 : 1445988224.0
Loss at iteration 1180 : 46858408.0
Loss at iteration 1190 : 87278160.0
Loss at iteration 1200 : 107737672.0
Loss at iteration 1210 : 161744032.0
Loss at iteration 1220 : 517743.6875
Loss at iteration 1230 : 3320012032.0
Loss at iteration 1240 : 245875120.0
Loss at iteration 1250 : 290201312.0
Loss at iteration 1260 : 6128436.0
Loss at iteration 1270 : 36871348.0
Loss at iteration 1280 : 50503608.0
Loss at iteration 1290 : 102348560.0
Loss at iteration 1300 : 104594536.0
Loss at iteration 1310 : 2414851.0
Loss at iteration 1320 : 21798854.0
Loss at iteration 1330 : 56065708.0
Loss at iteration 1340 : 28606680.0
Loss at iteration 1350 : 26299224.0
Loss at iteration 1360 : 39516924.0
Loss at iteration 1370 : 17095370.0
Loss at iteration 1380 : 4919768.5
Loss at iteration 1390 : 13484005.0
Loss at iteration 1400 : 11599954.0
Loss at iteration 1410 : 3057539.75
Loss at iteration 1420 : 43397376.0
Loss at iteration 1430 : 9763313.0
Loss at iteration 1440 : 2611720.5
Loss at iteration 1450 : 25393242.0
Loss at iteration 1460 : 37593808.0
Loss at iteration 1470 : 13812006.0
Loss at iteration 1480 : 246549872.0
Loss at iteration 1490 : 640897344.0
Loss at iteration 1500 : 22817626.0
Loss at iteration 1510 : 12770323.0
Loss at iteration 1520 : 28990224.0
Loss at iteration 1530 : 64034952.0
Loss at iteration 1540 : 28110454.0
Loss at iteration 1550 : 829620.5625
Loss at iteration 1560 : 1120770304.0
Loss at iteration 1570 : 59704392.0
Loss at iteration 1580 : 67183952.0
Loss at iteration 1590 : 6369956.5
Loss at iteration 1600 : 3535131.75
Loss at iteration 1610 : 5126010.0
Loss at iteration 1620 : 8059101.0
Loss at iteration 1630 : 4827096.0
Loss at iteration 1640 : 44309516.0
Loss at iteration 1650 : 9188106.0
Loss at iteration 1660 : 25875778.0
Loss at iteration 1670 : 3236352.75
Loss at iteration 1680 : 7116162.5
Loss at iteration 1690 : 9283957.0
Loss at iteration 1700 : 1115521.375
Loss at iteration 1710 : 24627746.0
Loss at iteration 1720 : 13672052.0
Loss at iteration 1730 : 13364182.0
Loss at iteration 1740 : 24492180.0
Loss at iteration 1750 : 12290457.0
Loss at iteration 1760 : 7373739.5
Loss at iteration 1770 : 1651039.75
Loss at iteration 1780 : 1544962.0
Loss at iteration 1790 : 49005064.0
Loss at iteration 1800 : 9649928.0
Loss at iteration 1810 : 34188008.0
Loss at iteration 1820 : 8262688.0
Loss at iteration 1830 : 8376299.0
Loss at iteration 1840 : 2370534.0
Loss at iteration 1850 : 22176408.0
Loss at iteration 1860 : 85723112.0
Loss at iteration 1870 : 5798652.5
Loss at iteration 1880 : 2094863.0
Loss at iteration 1890 : 4521616.5
Loss at iteration 1900 : 1773598.25
Loss at iteration 1910 : 25073996.0
Loss at iteration 1920 : 2396107.25
Loss at iteration 1930 : 9331080.0
Loss at iteration 1940 : 3154168.0
Loss at iteration 1950 : 5034635.0
Loss at iteration 1960 : 2302970.25
Loss at iteration 1970 : 7076009.5
Loss at iteration 1980 : 1612484.375
Loss at iteration 1990 : 36273604.0
Loss at iteration 2000 : 58733880.0
Loss at iteration 2010 : 1589008.125
Loss at iteration 2020 : 13903397.0
Loss at iteration 2030 : 5994294.0
Loss at iteration 2040 : 17913396.0
Loss at iteration 2050 : 4388053.0
Loss at iteration 2060 : 9981794.0
Loss at iteration 2070 : 6337627.0
Loss at iteration 2080 : 15597739.0
Loss at iteration 2090 : 59813924.0
Loss at iteration 2100 : 16705223.0
Loss at iteration 2110 : 92464784.0
Loss at iteration 2120 : 13872153.0
Loss at iteration 2130 : 1441301.875
Loss at iteration 2140 : 60118060.0
Loss at iteration 2150 : 6085339.5
Loss at iteration 2160 : 2957625.75
Loss at iteration 2170 : 239163296.0
Loss at iteration 2180 : 140632768.0
Loss at iteration 2190 : 107863408.0
Loss at iteration 2200 : 10677682.0
Loss at iteration 2210 : 2821331.0
Loss at iteration 2220 : 13130444.0
Loss at iteration 2230 : 10918533.0
Loss at iteration 2240 : 89590808.0
Loss at iteration 2250 : 11699035.0
Loss at iteration 2260 : 6887617.5
Loss at iteration 2270 : 16220589.0
Loss at iteration 2280 : 192702528.0
Loss at iteration 2290 : 43771788.0
Loss at iteration 2300 : 45946504.0
Loss at iteration 2310 : 34819544.0
Loss at iteration 2320 : 63283228.0
Loss at iteration 2330 : 17547738.0
Loss at iteration 2340 : 83382208.0
Loss at iteration 2350 : 21236236.0
Loss at iteration 2360 : 24232338.0
Loss at iteration 2370 : 74366944.0
Loss at iteration 2380 : 3313729.75
Loss at iteration 2390 : 7246748.0
Loss at iteration 2400 : 17376842.0
Loss at iteration 2410 : 41687608.0
Loss at iteration 2420 : 18508974.0
The SSIM Value is: 6.7831402551140245e-06
The PSNR Value is: -87.31283671061198
the epoch is: 126
Loss at iteration 10 : 7243666.0
Loss at iteration 20 : 336090272.0
Loss at iteration 30 : 48192652.0
Loss at iteration 40 : 61154296.0
Loss at iteration 50 : 18419840.0
Loss at iteration 60 : 3289433856.0
Loss at iteration 70 : 1905084.125
Loss at iteration 80 : 3490478.25
Loss at iteration 90 : 27048964.0
Loss at iteration 100 : 2658973.75
Loss at iteration 110 : 3676963.5
Loss at iteration 120 : 16366343.0
Loss at iteration 130 : 14034672.0
Loss at iteration 140 : 718701248.0
Loss at iteration 150 : 270546816.0
Loss at iteration 160 : 498576992.0
Loss at iteration 170 : 80601360.0
Loss at iteration 180 : 132148592.0
Loss at iteration 190 : 156408080.0
Loss at iteration 200 : 59358044.0
Loss at iteration 210 : 280583840.0
Loss at iteration 220 : 52867812.0
Loss at iteration 230 : 4547431.0
Loss at iteration 240 : 48889688.0
Loss at iteration 250 : 2430317.0
Loss at iteration 260 : 5448526.0
Loss at iteration 270 : 111487952.0
Loss at iteration 280 : 29633394.0
Loss at iteration 290 : 44122722304.0
Loss at iteration 300 : 37274416.0
Loss at iteration 310 : 85522480.0
Loss at iteration 320 : 4185393.5
Loss at iteration 330 : 1619048576.0
Loss at iteration 340 : 5173527552.0
Loss at iteration 350 : 5464544256.0
Loss at iteration 360 : 465905184.0
Loss at iteration 370 : 1063694464.0
Loss at iteration 380 : 588129472.0
Loss at iteration 390 : 106795856.0
Loss at iteration 400 : 222846656.0
Loss at iteration 410 : 1880162944.0
Loss at iteration 420 : 13387189248.0
Loss at iteration 430 : 177044224.0
Loss at iteration 440 : 90838128.0
Loss at iteration 450 : 304174016.0
Loss at iteration 460 : 111706248.0
Loss at iteration 470 : 35835452.0
Loss at iteration 480 : 28108686.0
Loss at iteration 490 : 30433076.0
Loss at iteration 500 : 140032464.0
Loss at iteration 510 : 55559164.0
Loss at iteration 520 : 28791684.0
Loss at iteration 530 : 37903736.0
Loss at iteration 540 : 22659298.0
Loss at iteration 550 : 151489072.0
Loss at iteration 560 : 30165276.0
Loss at iteration 570 : 46012692.0
Loss at iteration 580 : 5138331.0
Loss at iteration 590 : 4788243.5
Loss at iteration 600 : 19509486.0
Loss at iteration 610 : 8649395.0
Loss at iteration 620 : 29940530.0
Loss at iteration 630 : 8833629.0
Loss at iteration 640 : 77086456.0
Loss at iteration 650 : 59182368.0
Loss at iteration 660 : 5145363.0
Loss at iteration 670 : 16531316.0
Loss at iteration 680 : 16830010.0
Loss at iteration 690 : 291936928.0
Loss at iteration 700 : 8893927.0
Loss at iteration 710 : 19443966.0
Loss at iteration 720 : 22172964.0
Loss at iteration 730 : 29000566.0
Loss at iteration 740 : 5193557.5
Loss at iteration 750 : 2417489.5
Loss at iteration 760 : 112446168.0
Loss at iteration 770 : 11923489.0
Loss at iteration 780 : 14193477.0
Loss at iteration 790 : 19967220.0
Loss at iteration 800 : 11717015.0
Loss at iteration 810 : 17142508.0
Loss at iteration 820 : 4824535.5
Loss at iteration 830 : 3555484.25
Loss at iteration 840 : 2045646.5
Loss at iteration 850 : 2645108.75
Loss at iteration 860 : 10964960.0
Loss at iteration 870 : 5150040.5
Loss at iteration 880 : 15692602.0
Loss at iteration 890 : 23212688.0
Loss at iteration 900 : 21537678.0
Loss at iteration 910 : 6052258.0
Loss at iteration 920 : 3734888.75
Loss at iteration 930 : 13479625.0
Loss at iteration 940 : 7268256.5
Loss at iteration 950 : 5685844.5
Loss at iteration 960 : 43515336.0
Loss at iteration 970 : 31240744.0
Loss at iteration 980 : 9032669.0
Loss at iteration 990 : 21804150.0
Loss at iteration 1000 : 7998748.5
Loss at iteration 1010 : 16598971.0
Loss at iteration 1020 : 6192742.0
Loss at iteration 1030 : 51098332.0
Loss at iteration 1040 : 10505652.0
Loss at iteration 1050 : 27838430.0
Loss at iteration 1060 : 144682336.0
Loss at iteration 1070 : 2723175.25
Loss at iteration 1080 : 12357087.0
Loss at iteration 1090 : 5291090.5
Loss at iteration 1100 : 4273712.0
Loss at iteration 1110 : 7662988.5
Loss at iteration 1120 : 51215896.0
Loss at iteration 1130 : 7747961.5
Loss at iteration 1140 : 23023072.0
Loss at iteration 1150 : 3101082.0
Loss at iteration 1160 : 50210028.0
Loss at iteration 1170 : 11311661.0
Loss at iteration 1180 : 26219960.0
Loss at iteration 1190 : 103061584.0
Loss at iteration 1200 : 7682193.0
Loss at iteration 1210 : 10337110.0
Loss at iteration 1220 : 9115712.0
Loss at iteration 1230 : 3010151.25
Loss at iteration 1240 : 12292841.0
Loss at iteration 1250 : 15672774.0
Loss at iteration 1260 : 52056612.0
Loss at iteration 1270 : 24292494.0
Loss at iteration 1280 : 65892232.0
Loss at iteration 1290 : 12644040.0
Loss at iteration 1300 : 21965296.0
Loss at iteration 1310 : 14086472.0
Loss at iteration 1320 : 7727625.5
Loss at iteration 1330 : 3789543.0
Loss at iteration 1340 : 7878714.0
Loss at iteration 1350 : 29639860.0
Loss at iteration 1360 : 19696648.0
Loss at iteration 1370 : 4112858.5
Loss at iteration 1380 : 18585762.0
Loss at iteration 1390 : 5243177.0
Loss at iteration 1400 : 23201762.0
Loss at iteration 1410 : 42401640.0
Loss at iteration 1420 : 525531264.0
Loss at iteration 1430 : 1197099392.0
Loss at iteration 1440 : 442058528.0
Loss at iteration 1450 : 168167040.0
Loss at iteration 1460 : 1030276416.0
Loss at iteration 1470 : 450555264.0
Loss at iteration 1480 : 717498048.0
Loss at iteration 1490 : 235450448.0
Loss at iteration 1500 : 156552080.0
Loss at iteration 1510 : 1820215808.0
Loss at iteration 1520 : 104455848.0
Loss at iteration 1530 : 8381837824.0
Loss at iteration 1540 : 7114909696.0
Loss at iteration 1550 : 18306957312.0
Loss at iteration 1560 : 807259392.0
Loss at iteration 1570 : 89457384.0
Loss at iteration 1580 : 339051424.0
Loss at iteration 1590 : 1955394176.0
Loss at iteration 1600 : 874842.5
Loss at iteration 1610 : 259397.140625
Loss at iteration 1620 : 6443104.0
Loss at iteration 1630 : 10009260.0
Loss at iteration 1640 : 1468747.5
Loss at iteration 1650 : 23676436.0
Loss at iteration 1660 : 3983169.0
Loss at iteration 1670 : 1474785.0
Loss at iteration 1680 : 13438930.0
Loss at iteration 1690 : 1186060.125
Loss at iteration 1700 : 3121349.0
Loss at iteration 1710 : 2611351.25
Loss at iteration 1720 : 25148944.0
Loss at iteration 1730 : 7269494.0
Loss at iteration 1740 : 9721677.0
Loss at iteration 1750 : 2730313.75
Loss at iteration 1760 : 2367510.25
Loss at iteration 1770 : 1612648.125
Loss at iteration 1780 : 4407492.0
Loss at iteration 1790 : 640418.75
Loss at iteration 1800 : 1400028.875
Loss at iteration 1810 : 8559979.0
Loss at iteration 1820 : 1293635.0
Loss at iteration 1830 : 2738091.75
Loss at iteration 1840 : 1457764.375
Loss at iteration 1850 : 15510085.0
Loss at iteration 1860 : 9814036.0
Loss at iteration 1870 : 1214610.125
Loss at iteration 1880 : 11648194.0
Loss at iteration 1890 : 1545992.625
Loss at iteration 1900 : 3330542.5
Loss at iteration 1910 : 995142.875
Loss at iteration 1920 : 4689543.0
Loss at iteration 1930 : 435679.34375
Loss at iteration 1940 : 208345600.0
Loss at iteration 1950 : 252960640.0
Loss at iteration 1960 : 160548960.0
Loss at iteration 1970 : 88719928.0
Loss at iteration 1980 : 7476107.5
Loss at iteration 1990 : 12583857.0
Loss at iteration 2000 : 57359364.0
Loss at iteration 2010 : 273729536.0
Loss at iteration 2020 : 329017120.0
Loss at iteration 2030 : 513122656.0
Loss at iteration 2040 : 68401696.0
Loss at iteration 2050 : 736422528.0
Loss at iteration 2060 : 2265706752.0
Loss at iteration 2070 : 8371402240.0
Loss at iteration 2080 : 2191098368.0
Loss at iteration 2090 : 429190432.0
Loss at iteration 2100 : 465211872.0
Loss at iteration 2110 : 27652204544.0
Loss at iteration 2120 : 1513148032.0
Loss at iteration 2130 : 2143559936.0
Loss at iteration 2140 : 100947704.0
Loss at iteration 2150 : 775329984.0
Loss at iteration 2160 : 1013594496.0
Loss at iteration 2170 : 1507967360.0
Loss at iteration 2180 : 223634624.0
Loss at iteration 2190 : 734559936.0
Loss at iteration 2200 : 206785552.0
Loss at iteration 2210 : 191095056.0
Loss at iteration 2220 : 166209104.0
Loss at iteration 2230 : 395450720.0
Loss at iteration 2240 : 4189328384.0
Loss at iteration 2250 : 2242487808.0
Loss at iteration 2260 : 2565459200.0
Loss at iteration 2270 : 213063456.0
Loss at iteration 2280 : 73787328.0
Loss at iteration 2290 : 18685562.0
Loss at iteration 2300 : 273944192.0
Loss at iteration 2310 : 703058752.0
Loss at iteration 2320 : 100946120.0
Loss at iteration 2330 : 62721376.0
Loss at iteration 2340 : 51029340.0
Loss at iteration 2350 : 20201262.0
Loss at iteration 2360 : 170343968.0
Loss at iteration 2370 : 7545115.0
Loss at iteration 2380 : 55465704.0
Loss at iteration 2390 : 168824912.0
Loss at iteration 2400 : 79366632.0
Loss at iteration 2410 : 42634560.0
Loss at iteration 2420 : 82256616.0
The SSIM Value is: 3.081791946897283e-05
The PSNR Value is: -91.64114583333334
the epoch is: 127
Loss at iteration 10 : 309470304.0
Loss at iteration 20 : 94717800.0
Loss at iteration 30 : 8308367.0
Loss at iteration 40 : 26505338.0
Loss at iteration 50 : 52876240.0
Loss at iteration 60 : 121007712.0
Loss at iteration 70 : 169168400.0
Loss at iteration 80 : 12247194.0
Loss at iteration 90 : 145315248.0
Loss at iteration 100 : 71352192.0
Loss at iteration 110 : 36225916.0
Loss at iteration 120 : 3834439.25
Loss at iteration 130 : 11724447.0
Loss at iteration 140 : 1423097.75
Loss at iteration 150 : 54287580.0
Loss at iteration 160 : 5034716.0
Loss at iteration 170 : 142855488.0
Loss at iteration 180 : 4605395.5
Loss at iteration 190 : 68667872.0
Loss at iteration 200 : 45833716.0
Loss at iteration 210 : 252498.015625
Loss at iteration 220 : 49601136.0
Loss at iteration 230 : 93907168.0
Loss at iteration 240 : 20155564.0
Loss at iteration 250 : 13681158.0
Loss at iteration 260 : 16627887.0
Loss at iteration 270 : 12489667.0
Loss at iteration 280 : 6741239.0
Loss at iteration 290 : 6330357.0
Loss at iteration 300 : 21585608.0
Loss at iteration 310 : 2713237.25
Loss at iteration 320 : 7409460.0
Loss at iteration 330 : 76283504.0
Loss at iteration 340 : 2809387008.0
Loss at iteration 350 : 881476544.0
Loss at iteration 360 : 1307730816.0
Loss at iteration 370 : 520993952.0
Loss at iteration 380 : 220896656.0
Loss at iteration 390 : 237160576.0
Loss at iteration 400 : 73647848.0
Loss at iteration 410 : 143633568.0
Loss at iteration 420 : 319765344.0
Loss at iteration 430 : 537521920.0
Loss at iteration 440 : 87661280.0
Loss at iteration 450 : 52907757568.0
Loss at iteration 460 : 256516784.0
Loss at iteration 470 : 140619888.0
Loss at iteration 480 : 9032484864.0
Loss at iteration 490 : 3388024064.0
Loss at iteration 500 : 76357560.0
Loss at iteration 510 : 80678656.0
Loss at iteration 520 : 4650459136.0
Loss at iteration 530 : 17157189632.0
Loss at iteration 540 : 136961343488.0
Loss at iteration 550 : 27068749824.0
Loss at iteration 560 : 32469229568.0
Loss at iteration 570 : 5888189440.0
Loss at iteration 580 : 6985432576.0
Loss at iteration 590 : 566826368.0
Loss at iteration 600 : 5575175168.0
Loss at iteration 610 : 177933216.0
Loss at iteration 620 : 2743381760.0
Loss at iteration 630 : 821564864.0
Loss at iteration 640 : 111601528.0
Loss at iteration 650 : 30799251456.0
Loss at iteration 660 : 437950656.0
Loss at iteration 670 : 454740832.0
Loss at iteration 680 : 1487911680.0
Loss at iteration 690 : 1741342080.0
Loss at iteration 700 : 129989600.0
Loss at iteration 710 : 6137793024.0
Loss at iteration 720 : 4875805184.0
Loss at iteration 730 : 54782732.0
Loss at iteration 740 : 129384136.0
Loss at iteration 750 : 634099392.0
Loss at iteration 760 : 2927685376.0
Loss at iteration 770 : 143723392.0
Loss at iteration 780 : 4757128192.0
Loss at iteration 790 : 3519650560.0
Loss at iteration 800 : 2000425600.0
Loss at iteration 810 : 2639243008.0
Loss at iteration 820 : 27657796.0
Loss at iteration 830 : 899881472.0
Loss at iteration 840 : 2766337792.0
Loss at iteration 850 : 240469680.0
Loss at iteration 860 : 5254449152.0
Loss at iteration 870 : 695279488.0
Loss at iteration 880 : 1563784704.0
Loss at iteration 890 : 1075166208.0
Loss at iteration 900 : 4771414528.0
Loss at iteration 910 : 5344583680.0
Loss at iteration 920 : 36290170880.0
Loss at iteration 930 : 1569015168.0
Loss at iteration 940 : 5508558848.0
Loss at iteration 950 : 627597824.0
Loss at iteration 960 : 210683440.0
Loss at iteration 970 : 1322151040.0
Loss at iteration 980 : 135222496.0
Loss at iteration 990 : 130670216.0
Loss at iteration 1000 : 28210776064.0
Loss at iteration 1010 : 516543968.0
Loss at iteration 1020 : 132286947328.0
Loss at iteration 1030 : 3957899008.0
Loss at iteration 1040 : 499412832.0
Loss at iteration 1050 : 6929832960.0
Loss at iteration 1060 : 55078988.0
Loss at iteration 1070 : 345220736.0
Loss at iteration 1080 : 7080757760.0
Loss at iteration 1090 : 6625095680.0
Loss at iteration 1100 : 18249134080.0
Loss at iteration 1110 : 2340242688.0
Loss at iteration 1120 : 3559424512.0
Loss at iteration 1130 : 437366208.0
Loss at iteration 1140 : 274479776.0
Loss at iteration 1150 : 69848793088.0
Loss at iteration 1160 : 6862065664.0
Loss at iteration 1170 : 60514320384.0
Loss at iteration 1180 : 1899102720.0
Loss at iteration 1190 : 1062042496.0
Loss at iteration 1200 : 1824418432.0
Loss at iteration 1210 : 9377082368.0
Loss at iteration 1220 : 55920284.0
Loss at iteration 1230 : 1710163099648.0
Loss at iteration 1240 : 26081639792640.0
Loss at iteration 1250 : 434923470848.0
Loss at iteration 1260 : 3581975461888.0
Loss at iteration 1270 : 207424120160256.0
Loss at iteration 1280 : 46599983104.0
Loss at iteration 1290 : 557324500992.0
Loss at iteration 1300 : 254622007296.0
Loss at iteration 1310 : 353774796800.0
Loss at iteration 1320 : 428890176.0
Loss at iteration 1330 : 3888391913472.0
Loss at iteration 1340 : 32656451584.0
Loss at iteration 1350 : 77710614528.0
Loss at iteration 1360 : 283545305088.0
Loss at iteration 1370 : 36783030272.0
Loss at iteration 1380 : 10023603200.0
Loss at iteration 1390 : 10228862976.0
Loss at iteration 1400 : 173170622464.0
Loss at iteration 1410 : 73179758592.0
Loss at iteration 1420 : 4684376576.0
Loss at iteration 1430 : 8380169216.0
Loss at iteration 1440 : 117527429120.0
Loss at iteration 1450 : 44955271168.0
Loss at iteration 1460 : 409833930752.0
Loss at iteration 1470 : 9021091840.0
Loss at iteration 1480 : 3739226880.0
Loss at iteration 1490 : 3452129280.0
Loss at iteration 1500 : 29026297856.0
Loss at iteration 1510 : 124932677632.0
Loss at iteration 1520 : 415883558912.0
Loss at iteration 1530 : 9426155520.0
Loss at iteration 1540 : 202162388992.0
Loss at iteration 1550 : 36517203968.0
Loss at iteration 1560 : 27406125056.0
Loss at iteration 1570 : 96998637568.0
Loss at iteration 1580 : 373620867072.0
Loss at iteration 1590 : 308625145856.0
Loss at iteration 1600 : 9395959808.0
Loss at iteration 1610 : 23828242432.0
Loss at iteration 1620 : 21457227776.0
Loss at iteration 1630 : 12467128320.0
Loss at iteration 1640 : 13127469056.0
Loss at iteration 1650 : 8758760448.0
Loss at iteration 1660 : 116774174720.0
Loss at iteration 1670 : 23127050240.0
Loss at iteration 1680 : 37656113152.0
Loss at iteration 1690 : 37911203840.0
Loss at iteration 1700 : 372308017152.0
Loss at iteration 1710 : 27177322496.0
Loss at iteration 1720 : 8021279744.0
Loss at iteration 1730 : 14388780032.0
Loss at iteration 1740 : 3080389376.0
Loss at iteration 1750 : 43698405376.0
Loss at iteration 1760 : 24411615232.0
Loss at iteration 1770 : 19958300672.0
Loss at iteration 1780 : 26790359040.0
Loss at iteration 1790 : 357075008.0
Loss at iteration 1800 : 135077429248.0
Loss at iteration 1810 : 30247999488.0
Loss at iteration 1820 : 95940231168.0
Loss at iteration 1830 : 18872485888.0
Loss at iteration 1840 : 21927237632.0
Loss at iteration 1850 : 12496081920.0
Loss at iteration 1860 : 37362110464.0
Loss at iteration 1870 : 55391567872.0
Loss at iteration 1880 : 84109262848.0
Loss at iteration 1890 : 104012111872.0
Loss at iteration 1900 : 13030937600.0
Loss at iteration 1910 : 73735823360.0
Loss at iteration 1920 : 23083020288.0
Loss at iteration 1930 : 328293220352.0
Loss at iteration 1940 : 225107542016.0
Loss at iteration 1950 : 130469543936.0
Loss at iteration 1960 : 21302966272.0
Loss at iteration 1970 : 127816458240.0
Loss at iteration 1980 : 634471120896.0
Loss at iteration 1990 : 15355281408.0
Loss at iteration 2000 : 1812697216.0
Loss at iteration 2010 : 3316188928.0
Loss at iteration 2020 : 8514762752.0
Loss at iteration 2030 : 5836870144.0
Loss at iteration 2040 : 46872346624.0
Loss at iteration 2050 : 12059072512.0
Loss at iteration 2060 : 8983009280.0
Loss at iteration 2070 : 12062113792.0
Loss at iteration 2080 : 4672273408.0
Loss at iteration 2090 : 43781058560.0
Loss at iteration 2100 : 11831796736.0
Loss at iteration 2110 : 48610541568.0
Loss at iteration 2120 : 8152896000.0
Loss at iteration 2130 : 1604226432.0
Loss at iteration 2140 : 1199842176.0
Loss at iteration 2150 : 4351874560.0
Loss at iteration 2160 : 1558417024.0
Loss at iteration 2170 : 6386063360.0
Loss at iteration 2180 : 5930426368.0
Loss at iteration 2190 : 25761994752.0
Loss at iteration 2200 : 12225812480.0
Loss at iteration 2210 : 24523313152.0
Loss at iteration 2220 : 7079389696.0
Loss at iteration 2230 : 11922605056.0
Loss at iteration 2240 : 11697122304.0
Loss at iteration 2250 : 5436156928.0
Loss at iteration 2260 : 202838605824.0
Loss at iteration 2270 : 9888998400.0
Loss at iteration 2280 : 2250611712.0
Loss at iteration 2290 : 27757320192.0
Loss at iteration 2300 : 4820222976.0
Loss at iteration 2310 : 8682146816.0
Loss at iteration 2320 : 9370066944.0
Loss at iteration 2330 : 5523079680.0
Loss at iteration 2340 : 2751365120.0
Loss at iteration 2350 : 4165235200.0
Loss at iteration 2360 : 5409949184.0
Loss at iteration 2370 : 4012450560.0
Loss at iteration 2380 : 45722763264.0
Loss at iteration 2390 : 11022760960.0
Loss at iteration 2400 : 12948086784.0
Loss at iteration 2410 : 20926507008.0
Loss at iteration 2420 : 1518471808.0
The SSIM Value is: 4.651843717814094e-06
The PSNR Value is: -112.512841796875
the epoch is: 128
Loss at iteration 10 : 5364193792.0
Loss at iteration 20 : 12474085376.0
Loss at iteration 30 : 46136160256.0
Loss at iteration 40 : 3768860160.0
Loss at iteration 50 : 11088556032.0
Loss at iteration 60 : 4891844608.0
Loss at iteration 70 : 270278377472.0
Loss at iteration 80 : 12984970240.0
Loss at iteration 90 : 13344685056.0
Loss at iteration 100 : 12696428544.0
Loss at iteration 110 : 3621772288.0
Loss at iteration 120 : 87048699904.0
Loss at iteration 130 : 3858893824.0
Loss at iteration 140 : 21009782784.0
Loss at iteration 150 : 23994345472.0
Loss at iteration 160 : 5872220160.0
Loss at iteration 170 : 4388851712.0
Loss at iteration 180 : 2716643840.0
Loss at iteration 190 : 38076485632.0
Loss at iteration 200 : 224480002048.0
Loss at iteration 210 : 20963336192.0
Loss at iteration 220 : 7222936064.0
Loss at iteration 230 : 6531001856.0
Loss at iteration 240 : 2226695424.0
Loss at iteration 250 : 4034123008.0
Loss at iteration 260 : 35315748864.0
Loss at iteration 270 : 25464743936.0
Loss at iteration 280 : 2249267968.0
Loss at iteration 290 : 1584198784.0
Loss at iteration 300 : 34626818048.0
Loss at iteration 310 : 5605959168.0
Loss at iteration 320 : 5192126464.0
Loss at iteration 330 : 2401430528.0
Loss at iteration 340 : 3253518336.0
Loss at iteration 350 : 3361462784.0
Loss at iteration 360 : 14603755520.0
Loss at iteration 370 : 5279177728.0
Loss at iteration 380 : 6122022912.0
Loss at iteration 390 : 2364747776.0
Loss at iteration 400 : 3680689408.0
Loss at iteration 410 : 3652788224.0
Loss at iteration 420 : 3901867008.0
Loss at iteration 430 : 9283767296.0
Loss at iteration 440 : 1327976192.0
Loss at iteration 450 : 5338162688.0
Loss at iteration 460 : 9395862528.0
Loss at iteration 470 : 2508950272.0
Loss at iteration 480 : 1565881728.0
Loss at iteration 490 : 12052155392.0
Loss at iteration 500 : 2295459584.0
Loss at iteration 510 : 44135596032.0
Loss at iteration 520 : 269252480.0
Loss at iteration 530 : 5614491136.0
Loss at iteration 540 : 2333749504.0
Loss at iteration 550 : 1624131456.0
Loss at iteration 560 : 1112734592.0
Loss at iteration 570 : 1535714048.0
Loss at iteration 580 : 954915392.0
Loss at iteration 590 : 1966920448.0
Loss at iteration 600 : 2829034496.0
Loss at iteration 610 : 1674981376.0
Loss at iteration 620 : 94314440.0
Loss at iteration 630 : 2170123776.0
Loss at iteration 640 : 2730360064.0
Loss at iteration 650 : 771091584.0
Loss at iteration 660 : 760147904.0
Loss at iteration 670 : 4343986688.0
Loss at iteration 680 : 1065600640.0
Loss at iteration 690 : 1441628416.0
Loss at iteration 700 : 491591872.0
Loss at iteration 710 : 2042365184.0
Loss at iteration 720 : 3104963072.0
Loss at iteration 730 : 8997425152.0
Loss at iteration 740 : 3226009856.0
Loss at iteration 750 : 3789169408.0
Loss at iteration 760 : 780203200.0
Loss at iteration 770 : 600403328.0
Loss at iteration 780 : 862267136.0
Loss at iteration 790 : 4623338496.0
Loss at iteration 800 : 53542572032.0
Loss at iteration 810 : 5382690304.0
Loss at iteration 820 : 1200788480.0
Loss at iteration 830 : 1290619648.0
Loss at iteration 840 : 2682675456.0
Loss at iteration 850 : 5693261824.0
Loss at iteration 860 : 17401888768.0
Loss at iteration 870 : 825934976.0
Loss at iteration 880 : 3405380352.0
Loss at iteration 890 : 1252120704.0
Loss at iteration 900 : 79558787072.0
Loss at iteration 910 : 67861065728.0
Loss at iteration 920 : 11041869824.0
Loss at iteration 930 : 15040919552.0
Loss at iteration 940 : 33745711104.0
Loss at iteration 950 : 2436394240.0
Loss at iteration 960 : 2001331072.0
Loss at iteration 970 : 13485859840.0
Loss at iteration 980 : 53717762048.0
Loss at iteration 990 : 17359583232.0
Loss at iteration 1000 : 5131536384.0
Loss at iteration 1010 : 28954300416.0
Loss at iteration 1020 : 5962282496.0
Loss at iteration 1030 : 6961546752.0
Loss at iteration 1040 : 9509857280.0
Loss at iteration 1050 : 970429952.0
Loss at iteration 1060 : 3069235968.0
Loss at iteration 1070 : 115427401728.0
Loss at iteration 1080 : 80483418112.0
Loss at iteration 1090 : 34164101120.0
Loss at iteration 1100 : 7478629376.0
Loss at iteration 1110 : 5875744768.0
Loss at iteration 1120 : 38964346880.0
Loss at iteration 1130 : 48138579968.0
Loss at iteration 1140 : 4837563904.0
Loss at iteration 1150 : 7207678464.0
Loss at iteration 1160 : 17670879232.0
Loss at iteration 1170 : 3995431680.0
Loss at iteration 1180 : 485820672.0
Loss at iteration 1190 : 13178807296.0
Loss at iteration 1200 : 130123512.0
Loss at iteration 1210 : 6076964864.0
Loss at iteration 1220 : 6789785088.0
Loss at iteration 1230 : 1229291904.0
Loss at iteration 1240 : 2691581952.0
Loss at iteration 1250 : 9560085504.0
Loss at iteration 1260 : 26337470464.0
Loss at iteration 1270 : 12305788928.0
Loss at iteration 1280 : 2479502080.0
Loss at iteration 1290 : 1133038080.0
Loss at iteration 1300 : 20994119680.0
Loss at iteration 1310 : 2876622592.0
Loss at iteration 1320 : 5263040000.0
Loss at iteration 1330 : 894680256.0
Loss at iteration 1340 : 5030108160.0
Loss at iteration 1350 : 1220501760.0
Loss at iteration 1360 : 1631524352.0
Loss at iteration 1370 : 1482174208.0
Loss at iteration 1380 : 14088658944.0
Loss at iteration 1390 : 3177856768.0
Loss at iteration 1400 : 5300752896.0
Loss at iteration 1410 : 1079782016.0
Loss at iteration 1420 : 625456896.0
Loss at iteration 1430 : 1999510912.0
Loss at iteration 1440 : 548668352.0
Loss at iteration 1450 : 4778359296.0
Loss at iteration 1460 : 3550863360.0
Loss at iteration 1470 : 2647366144.0
Loss at iteration 1480 : 1791205632.0
Loss at iteration 1490 : 5180372480.0
Loss at iteration 1500 : 4568750080.0
Loss at iteration 1510 : 6648198144.0
Loss at iteration 1520 : 2231237120.0
Loss at iteration 1530 : 2620513536.0
Loss at iteration 1540 : 9475650560.0
Loss at iteration 1550 : 4061039104.0
Loss at iteration 1560 : 12612086784.0
Loss at iteration 1570 : 22962819072.0
Loss at iteration 1580 : 959714816.0
Loss at iteration 1590 : 33947289600.0
Loss at iteration 1600 : 713584640.0
Loss at iteration 1610 : 209815928832.0
Loss at iteration 1620 : 448465184.0
Loss at iteration 1630 : 2775492608.0
Loss at iteration 1640 : 3217361664.0
Loss at iteration 1650 : 3733753856.0
Loss at iteration 1660 : 2739361024.0
Loss at iteration 1670 : 787520512.0
Loss at iteration 1680 : 118290694144.0
Loss at iteration 1690 : 6474419200.0
Loss at iteration 1700 : 1410474240.0
Loss at iteration 1710 : 10130948096.0
Loss at iteration 1720 : 1114288512.0
Loss at iteration 1730 : 9276188672.0
Loss at iteration 1740 : 3269335552.0
Loss at iteration 1750 : 11712372736.0
Loss at iteration 1760 : 2234137344.0
Loss at iteration 1770 : 315319584.0
Loss at iteration 1780 : 2718939136.0
Loss at iteration 1790 : 444385376.0
Loss at iteration 1800 : 1111870592.0
Loss at iteration 1810 : 2600581632.0
Loss at iteration 1820 : 5170998784.0
Loss at iteration 1830 : 593030144.0
Loss at iteration 1840 : 1481801856.0
Loss at iteration 1850 : 1860000128.0
Loss at iteration 1860 : 13410529280.0
Loss at iteration 1870 : 1726275072.0
Loss at iteration 1880 : 4943747584.0
Loss at iteration 1890 : 12411602944.0
Loss at iteration 1900 : 343477760.0
Loss at iteration 1910 : 402047136.0
Loss at iteration 1920 : 692867392.0
Loss at iteration 1930 : 2065113984.0
Loss at iteration 1940 : 2201147648.0
Loss at iteration 1950 : 1412780416.0
Loss at iteration 1960 : 174421008.0
Loss at iteration 1970 : 2526276608.0
Loss at iteration 1980 : 3201556736.0
Loss at iteration 1990 : 9284425728.0
Loss at iteration 2000 : 2497125632.0
Loss at iteration 2010 : 1965351168.0
Loss at iteration 2020 : 2786443008.0
Loss at iteration 2030 : 3898439936.0
Loss at iteration 2040 : 5299310592.0
Loss at iteration 2050 : 3991240704.0
Loss at iteration 2060 : 2080610048.0
Loss at iteration 2070 : 14084180992.0
Loss at iteration 2080 : 7521315328.0
Loss at iteration 2090 : 3353417984.0
Loss at iteration 2100 : 15663133696.0
Loss at iteration 2110 : 1571391872.0
Loss at iteration 2120 : 2810109184.0
Loss at iteration 2130 : 11850836992.0
Loss at iteration 2140 : 937992640.0
Loss at iteration 2150 : 2906167040.0
Loss at iteration 2160 : 4798339072.0
Loss at iteration 2170 : 191376352.0
Loss at iteration 2180 : 1561713792.0
Loss at iteration 2190 : 7418700800.0
Loss at iteration 2200 : 330776992.0
Loss at iteration 2210 : 2196919296.0
Loss at iteration 2220 : 228544352.0
Loss at iteration 2230 : 2060618496.0
Loss at iteration 2240 : 248240448.0
Loss at iteration 2250 : 955960896.0
Loss at iteration 2260 : 4787167232.0
Loss at iteration 2270 : 5810636800.0
Loss at iteration 2280 : 483032891392.0
Loss at iteration 2290 : 1480322432.0
Loss at iteration 2300 : 9235667968.0
Loss at iteration 2310 : 766634048.0
Loss at iteration 2320 : 801727296.0
Loss at iteration 2330 : 2433144832.0
Loss at iteration 2340 : 3950866944.0
Loss at iteration 2350 : 454582432.0
Loss at iteration 2360 : 649861760.0
Loss at iteration 2370 : 344798080.0
Loss at iteration 2380 : 348096992.0
Loss at iteration 2390 : 24235241472.0
Loss at iteration 2400 : 1033875648.0
Loss at iteration 2410 : 2658096896.0
Loss at iteration 2420 : 4512967168.0
The SSIM Value is: 1.0859915619221284e-06
The PSNR Value is: -106.81417490641276
the epoch is: 129
Loss at iteration 10 : 5358299136.0
Loss at iteration 20 : 2178948352.0
Loss at iteration 30 : 29231499264.0
Loss at iteration 40 : 5372800512.0
Loss at iteration 50 : 275868064.0
Loss at iteration 60 : 5000419840.0
Loss at iteration 70 : 2439331584.0
Loss at iteration 80 : 206612016.0
Loss at iteration 90 : 5350619648.0
Loss at iteration 100 : 375865984.0
Loss at iteration 110 : 6341196288.0
Loss at iteration 120 : 1079103104.0
Loss at iteration 130 : 1458757504.0
Loss at iteration 140 : 7018765312.0
Loss at iteration 150 : 386824832.0
Loss at iteration 160 : 484056832.0
Loss at iteration 170 : 6671539712.0
Loss at iteration 180 : 3474699008.0
Loss at iteration 190 : 1171550080.0
Loss at iteration 200 : 522832768.0
Loss at iteration 210 : 174933152.0
Loss at iteration 220 : 106225983488.0
Loss at iteration 230 : 12900520960.0
Loss at iteration 240 : 437236832.0
Loss at iteration 250 : 2910630400.0
Loss at iteration 260 : 3728199936.0
Loss at iteration 270 : 3692269056.0
Loss at iteration 280 : 252269760.0
Loss at iteration 290 : 1365528576.0
Loss at iteration 300 : 458719904.0
Loss at iteration 310 : 559429312.0
Loss at iteration 320 : 1512058368.0
Loss at iteration 330 : 879270592.0
Loss at iteration 340 : 811099904.0
Loss at iteration 350 : 640827328.0
Loss at iteration 360 : 396942784.0
Loss at iteration 370 : 661041280.0
Loss at iteration 380 : 131400896.0
Loss at iteration 390 : 261168576.0
Loss at iteration 400 : 137039264.0
Loss at iteration 410 : 100536008.0
Loss at iteration 420 : 258447488.0
Loss at iteration 430 : 398826624.0
Loss at iteration 440 : 97704856.0
Loss at iteration 450 : 247092352.0
Loss at iteration 460 : 63572996.0
Loss at iteration 470 : 183964800.0
Loss at iteration 480 : 818209792.0
Loss at iteration 490 : 170838800.0
Loss at iteration 500 : 221999280.0
Loss at iteration 510 : 102263112.0
Loss at iteration 520 : 71910360.0
Loss at iteration 530 : 438951552.0
Loss at iteration 540 : 3013954304.0
Loss at iteration 550 : 14697712640.0
Loss at iteration 560 : 76544776.0
Loss at iteration 570 : 1481478272.0
Loss at iteration 580 : 94740936.0
Loss at iteration 590 : 1769206656.0
Loss at iteration 600 : 236397536.0
Loss at iteration 610 : 1298390272.0
Loss at iteration 620 : 40917896.0
Loss at iteration 630 : 82717648.0
Loss at iteration 640 : 885079104.0
Loss at iteration 650 : 2224982528.0
Loss at iteration 660 : 500129504.0
Loss at iteration 670 : 138804416.0
Loss at iteration 680 : 262792704.0
Loss at iteration 690 : 781292160.0
Loss at iteration 700 : 388440864.0
Loss at iteration 710 : 31408900.0
Loss at iteration 720 : 130240104.0
Loss at iteration 730 : 105976584.0
Loss at iteration 740 : 3212380416.0
Loss at iteration 750 : 2877318400.0
Loss at iteration 760 : 859235328.0
Loss at iteration 770 : 1276386944.0
Loss at iteration 780 : 501670496.0
Loss at iteration 790 : 1261932416.0
Loss at iteration 800 : 118242800.0
Loss at iteration 810 : 173132736.0
Loss at iteration 820 : 3513548032.0
Loss at iteration 830 : 1161094272.0
Loss at iteration 840 : 838930624.0
Loss at iteration 850 : 918356096.0
Loss at iteration 860 : 67201392.0
Loss at iteration 870 : 5773576.0
Loss at iteration 880 : 41030792.0
Loss at iteration 890 : 38688940.0
Loss at iteration 900 : 152431936.0
Loss at iteration 910 : 176449712.0
Loss at iteration 920 : 590078592.0
Loss at iteration 930 : 164497712.0
Loss at iteration 940 : 4254470144.0
Loss at iteration 950 : 77652352.0
Loss at iteration 960 : 356671328.0
Loss at iteration 970 : 6252913.5
Loss at iteration 980 : 259232352.0
Loss at iteration 990 : 7083628544.0
Loss at iteration 1000 : 1236513408.0
Loss at iteration 1010 : 781575808.0
Loss at iteration 1020 : 207561872.0
Loss at iteration 1030 : 202077520.0
Loss at iteration 1040 : 356268000.0
Loss at iteration 1050 : 516224320.0
Loss at iteration 1060 : 1554970496.0
Loss at iteration 1070 : 27886580.0
Loss at iteration 1080 : 563480768.0
Loss at iteration 1090 : 440000160.0
Loss at iteration 1100 : 41457276.0
Loss at iteration 1110 : 168507456.0
Loss at iteration 1120 : 1563223424.0
Loss at iteration 1130 : 597024384.0
Loss at iteration 1140 : 305994976.0
Loss at iteration 1150 : 102547672.0
Loss at iteration 1160 : 229139728.0
Loss at iteration 1170 : 254739904.0
Loss at iteration 1180 : 157430496.0
Loss at iteration 1190 : 2000960384.0
Loss at iteration 1200 : 619630400.0
Loss at iteration 1210 : 574522112.0
Loss at iteration 1220 : 16935714.0
Loss at iteration 1230 : 351887936.0
Loss at iteration 1240 : 7873007104.0
Loss at iteration 1250 : 195555936.0
Loss at iteration 1260 : 891121024.0
Loss at iteration 1270 : 1954618368.0
Loss at iteration 1280 : 69497664.0
Loss at iteration 1290 : 1419335040.0
Loss at iteration 1300 : 3346192384.0
Loss at iteration 1310 : 4303111680.0
Loss at iteration 1320 : 907762688.0
Loss at iteration 1330 : 537779200.0
Loss at iteration 1340 : 249650032.0
Loss at iteration 1350 : 253678464.0
Loss at iteration 1360 : 771535296.0
Loss at iteration 1370 : 3679537920.0
Loss at iteration 1380 : 347037312.0
Loss at iteration 1390 : 958265344.0
Loss at iteration 1400 : 10149414912.0
Loss at iteration 1410 : 5727754752.0
Loss at iteration 1420 : 1801046400.0
Loss at iteration 1430 : 298072640.0
Loss at iteration 1440 : 795413184.0
Loss at iteration 1450 : 313479360.0
Loss at iteration 1460 : 793576768.0
Loss at iteration 1470 : 78359896.0
Loss at iteration 1480 : 101186544.0
Loss at iteration 1490 : 1712936704.0
Loss at iteration 1500 : 263404880.0
Loss at iteration 1510 : 129017856.0
Loss at iteration 1520 : 155343264.0
Loss at iteration 1530 : 395545600.0
Loss at iteration 1540 : 120997304.0
Loss at iteration 1550 : 379355648.0
Loss at iteration 1560 : 298384608.0
Loss at iteration 1570 : 1548483328.0
Loss at iteration 1580 : 599259456.0
Loss at iteration 1590 : 208771632.0
Loss at iteration 1600 : 43873468.0
Loss at iteration 1610 : 235514576.0
Loss at iteration 1620 : 4598830592.0
Loss at iteration 1630 : 616586368.0
Loss at iteration 1640 : 1132658816.0
Loss at iteration 1650 : 899471040.0
Loss at iteration 1660 : 1095003648.0
Loss at iteration 1670 : 38944208.0
Loss at iteration 1680 : 80344240.0
Loss at iteration 1690 : 98051064.0
Loss at iteration 1700 : 732681472.0
Loss at iteration 1710 : 1225039232.0
Loss at iteration 1720 : 32209334.0
Loss at iteration 1730 : 5113591296.0
Loss at iteration 1740 : 93247960.0
Loss at iteration 1750 : 67349288.0
Loss at iteration 1760 : 151772208.0
Loss at iteration 1770 : 252225504.0
Loss at iteration 1780 : 257761680.0
Loss at iteration 1790 : 10104081408.0
Loss at iteration 1800 : 562730112.0
Loss at iteration 1810 : 514481632.0
Loss at iteration 1820 : 3276886528.0
Loss at iteration 1830 : 1201387904.0
Loss at iteration 1840 : 227464096.0
Loss at iteration 1850 : 1647961344.0
Loss at iteration 1860 : 147983872.0
Loss at iteration 1870 : 66492320.0
Loss at iteration 1880 : 81347680.0
Loss at iteration 1890 : 262598400.0
Loss at iteration 1900 : 208329216.0
Loss at iteration 1910 : 290067392.0
Loss at iteration 1920 : 132954232.0
Loss at iteration 1930 : 277606112.0
Loss at iteration 1940 : 1179286656.0
Loss at iteration 1950 : 142635488.0
Loss at iteration 1960 : 464985920.0
Loss at iteration 1970 : 682415040.0
Loss at iteration 1980 : 85242216.0
Loss at iteration 1990 : 869581120.0
Loss at iteration 2000 : 68505728.0
Loss at iteration 2010 : 10043510.0
Loss at iteration 2020 : 909452352.0
Loss at iteration 2030 : 82144968.0
Loss at iteration 2040 : 525013824.0
Loss at iteration 2050 : 27080230912.0
Loss at iteration 2060 : 1262640768.0
Loss at iteration 2070 : 685571520.0
Loss at iteration 2080 : 913367936.0
Loss at iteration 2090 : 4617785856.0
Loss at iteration 2100 : 1509094400.0
Loss at iteration 2110 : 255387760.0
Loss at iteration 2120 : 89551064.0
Loss at iteration 2130 : 3472133376.0
Loss at iteration 2140 : 124404576.0
Loss at iteration 2150 : 500936960.0
Loss at iteration 2160 : 2672880640.0
Loss at iteration 2170 : 398496000.0
Loss at iteration 2180 : 2060267008.0
Loss at iteration 2190 : 423113856.0
Loss at iteration 2200 : 1770383104.0
Loss at iteration 2210 : 193527648.0
Loss at iteration 2220 : 794451392.0
Loss at iteration 2230 : 1540096384.0
Loss at iteration 2240 : 98605408.0
Loss at iteration 2250 : 807211648.0
Loss at iteration 2260 : 461033856.0
Loss at iteration 2270 : 2917551616.0
Loss at iteration 2280 : 1000866240.0
Loss at iteration 2290 : 31474634.0
Loss at iteration 2300 : 320485440.0
Loss at iteration 2310 : 642380160.0
Loss at iteration 2320 : 549138176.0
Loss at iteration 2330 : 138920704.0
Loss at iteration 2340 : 1629344640.0
Loss at iteration 2350 : 37951148.0
Loss at iteration 2360 : 481320704.0
Loss at iteration 2370 : 192186112.0
Loss at iteration 2380 : 25033520.0
Loss at iteration 2390 : 9969110016.0
Loss at iteration 2400 : 34247684.0
Loss at iteration 2410 : 398657568.0
Loss at iteration 2420 : 65596744.0
The SSIM Value is: -4.7528615065554425e-06
The PSNR Value is: -96.9202372233073
the epoch is: 130
Loss at iteration 10 : 3128001024.0
Loss at iteration 20 : 193833264.0
Loss at iteration 30 : 410267072.0
Loss at iteration 40 : 204764944.0
Loss at iteration 50 : 555267008.0
Loss at iteration 60 : 126019128.0
Loss at iteration 70 : 6995065.0
Loss at iteration 80 : 26831174.0
Loss at iteration 90 : 104718024.0
Loss at iteration 100 : 70529568.0
Loss at iteration 110 : 123103728.0
Loss at iteration 120 : 75970320.0
Loss at iteration 130 : 153065152.0
Loss at iteration 140 : 40091476.0
Loss at iteration 150 : 536217152.0
Loss at iteration 160 : 183549184.0
Loss at iteration 170 : 225454368.0
Loss at iteration 180 : 2851509504.0
Loss at iteration 190 : 40684232.0
Loss at iteration 200 : 148814320.0
Loss at iteration 210 : 1227859328.0
Loss at iteration 220 : 62728532.0
Loss at iteration 230 : 475728384.0
Loss at iteration 240 : 693728896.0
Loss at iteration 250 : 1109651712.0
Loss at iteration 260 : 83822904.0
Loss at iteration 270 : 378949856.0
Loss at iteration 280 : 31864112.0
Loss at iteration 290 : 107039344.0
Loss at iteration 300 : 127805928.0
Loss at iteration 310 : 402011552.0
Loss at iteration 320 : 36532788.0
Loss at iteration 330 : 210526256.0
Loss at iteration 340 : 221544736.0
Loss at iteration 350 : 82511448.0
Loss at iteration 360 : 2438980.0
Loss at iteration 370 : 131570432.0
Loss at iteration 380 : 163117984.0
Loss at iteration 390 : 800273664.0
Loss at iteration 400 : 62386792.0
Loss at iteration 410 : 67345904.0
Loss at iteration 420 : 23356314.0
Loss at iteration 430 : 916365824.0
Loss at iteration 440 : 105758752.0
Loss at iteration 450 : 58361792.0
Loss at iteration 460 : 647914048.0
Loss at iteration 470 : 172413488.0
Loss at iteration 480 : 154478784.0
Loss at iteration 490 : 2339643.5
Loss at iteration 500 : 463455680.0
Loss at iteration 510 : 2258000640.0
Loss at iteration 520 : 1439696384.0
Loss at iteration 530 : 912659392.0
Loss at iteration 540 : 1794497536.0
Loss at iteration 550 : 1241841152.0
Loss at iteration 560 : 22898448384.0
Loss at iteration 570 : 369349216.0
Loss at iteration 580 : 160606912.0
Loss at iteration 590 : 404268864.0
Loss at iteration 600 : 4858094592.0
Loss at iteration 610 : 298261344.0
Loss at iteration 620 : 589689024.0
Loss at iteration 630 : 1003058048.0
Loss at iteration 640 : 746570112.0
Loss at iteration 650 : 1734878080.0
Loss at iteration 660 : 482259456.0
Loss at iteration 670 : 3190827008.0
Loss at iteration 680 : 1129092480.0
Loss at iteration 690 : 1253866368.0
Loss at iteration 700 : 164020096.0
Loss at iteration 710 : 191929792.0
Loss at iteration 720 : 2121647744.0
Loss at iteration 730 : 390692832.0
Loss at iteration 740 : 458161824.0
Loss at iteration 750 : 525591488.0
Loss at iteration 760 : 1847683328.0
Loss at iteration 770 : 460052384.0
Loss at iteration 780 : 177043104.0
Loss at iteration 790 : 575488384.0
Loss at iteration 800 : 39305660.0
Loss at iteration 810 : 369606400.0
Loss at iteration 820 : 4251421952.0
Loss at iteration 830 : 604663232.0
Loss at iteration 840 : 475854080.0
Loss at iteration 850 : 903884672.0
Loss at iteration 860 : 273040864.0
Loss at iteration 870 : 620882496.0
Loss at iteration 880 : 1156457216.0
Loss at iteration 890 : 149949728.0
Loss at iteration 900 : 49484619776.0
Loss at iteration 910 : 717544768.0
Loss at iteration 920 : 110461240.0
Loss at iteration 930 : 523584352.0
Loss at iteration 940 : 1274922240.0
Loss at iteration 950 : 523932512.0
Loss at iteration 960 : 788866688.0
Loss at iteration 970 : 13950411776.0
Loss at iteration 980 : 1236075264.0
Loss at iteration 990 : 780415616.0
Loss at iteration 1000 : 1092623488.0
Loss at iteration 1010 : 153198784.0
Loss at iteration 1020 : 733868352.0
Loss at iteration 1030 : 236622816.0
Loss at iteration 1040 : 167958896.0
Loss at iteration 1050 : 615121216.0
Loss at iteration 1060 : 1329994880.0
Loss at iteration 1070 : 892839808.0
Loss at iteration 1080 : 194345168.0
Loss at iteration 1090 : 2043016832.0
Loss at iteration 1100 : 85045720.0
Loss at iteration 1110 : 105340400.0
Loss at iteration 1120 : 151142544.0
Loss at iteration 1130 : 288154400.0
Loss at iteration 1140 : 75116208.0
Loss at iteration 1150 : 52526752.0
Loss at iteration 1160 : 180861728.0
Loss at iteration 1170 : 463387904.0
Loss at iteration 1180 : 96049312.0
Loss at iteration 1190 : 327480192.0
Loss at iteration 1200 : 372635840.0
Loss at iteration 1210 : 321093664.0
Loss at iteration 1220 : 78458104.0
Loss at iteration 1230 : 41075068.0
Loss at iteration 1240 : 69868920.0
Loss at iteration 1250 : 379888256.0
Loss at iteration 1260 : 55514728.0
Loss at iteration 1270 : 55198892.0
Loss at iteration 1280 : 106589576.0
Loss at iteration 1290 : 63089872.0
Loss at iteration 1300 : 293810400.0
Loss at iteration 1310 : 159463264.0
Loss at iteration 1320 : 69603304.0
Loss at iteration 1330 : 1361051008.0
Loss at iteration 1340 : 374694144.0
Loss at iteration 1350 : 176064768.0
Loss at iteration 1360 : 131421536.0
Loss at iteration 1370 : 1314726016.0
Loss at iteration 1380 : 759818880.0
Loss at iteration 1390 : 67023120.0
Loss at iteration 1400 : 228287472.0
Loss at iteration 1410 : 4226057984.0
Loss at iteration 1420 : 209780272.0
Loss at iteration 1430 : 398736992.0
Loss at iteration 1440 : 238042880.0
Loss at iteration 1450 : 877629376.0
Loss at iteration 1460 : 262929840.0
Loss at iteration 1470 : 423255264.0
Loss at iteration 1480 : 152971040.0
Loss at iteration 1490 : 159329104.0
Loss at iteration 1500 : 193122080.0
Loss at iteration 1510 : 4008334592.0
Loss at iteration 1520 : 27699046.0
Loss at iteration 1530 : 649752384.0
Loss at iteration 1540 : 331419104.0
Loss at iteration 1550 : 50896112.0
Loss at iteration 1560 : 305165238272.0
Loss at iteration 1570 : 132909848.0
Loss at iteration 1580 : 87356334080.0
Loss at iteration 1590 : 2903117312.0
Loss at iteration 1600 : 15382376448.0
Loss at iteration 1610 : 3442631424.0
Loss at iteration 1620 : 4976137469952.0
Loss at iteration 1630 : 96569311232.0
Loss at iteration 1640 : 61913100288.0
Loss at iteration 1650 : 6654355456.0
Loss at iteration 1660 : 511027776.0
Loss at iteration 1670 : 117520113664.0
Loss at iteration 1680 : 8930685.0
Loss at iteration 1690 : 55101704.0
Loss at iteration 1700 : 795509888.0
Loss at iteration 1710 : 843527936.0
Loss at iteration 1720 : 7189566976.0
Loss at iteration 1730 : 5163723776.0
Loss at iteration 1740 : 2281878016.0
Loss at iteration 1750 : 6025671168.0
Loss at iteration 1760 : 634789568.0
Loss at iteration 1770 : 2893632000.0
Loss at iteration 1780 : 2532085760.0
Loss at iteration 1790 : 754810752.0
Loss at iteration 1800 : 812838528.0
Loss at iteration 1810 : 32842612736.0
Loss at iteration 1820 : 361690976.0
Loss at iteration 1830 : 64141856768.0
Loss at iteration 1840 : 40307650560.0
Loss at iteration 1850 : 194739920.0
Loss at iteration 1860 : 696847040.0
Loss at iteration 1870 : 56539316.0
Loss at iteration 1880 : 460403296.0
Loss at iteration 1890 : 1351004416.0
Loss at iteration 1900 : 8469290496.0
Loss at iteration 1910 : 199954688.0
Loss at iteration 1920 : 1666264960.0
Loss at iteration 1930 : 83271041024.0
Loss at iteration 1940 : 3681043456.0
Loss at iteration 1950 : 5511627.0
Loss at iteration 1960 : 222302814208.0
Loss at iteration 1970 : 1919697152.0
Loss at iteration 1980 : 591023616.0
Loss at iteration 1990 : 6911635456.0
Loss at iteration 2000 : 5860007936.0
Loss at iteration 2010 : 111688040.0
Loss at iteration 2020 : 1917662848.0
Loss at iteration 2030 : 2567621120.0
Loss at iteration 2040 : 31048754.0
Loss at iteration 2050 : 568524160.0
Loss at iteration 2060 : 30966818.0
Loss at iteration 2070 : 1066088704.0
Loss at iteration 2080 : 1737350400.0
Loss at iteration 2090 : 57883464.0
Loss at iteration 2100 : 312285632.0
Loss at iteration 2110 : 8667195.0
Loss at iteration 2120 : 177601248.0
Loss at iteration 2130 : 982487040.0
Loss at iteration 2140 : 510577440.0
Loss at iteration 2150 : 21863988.0
Loss at iteration 2160 : 99606240.0
Loss at iteration 2170 : 1261665280.0
Loss at iteration 2180 : 478157440.0
Loss at iteration 2190 : 197549296.0
Loss at iteration 2200 : 27665276.0
Loss at iteration 2210 : 7956180.5
Loss at iteration 2220 : 19858218.0
Loss at iteration 2230 : 2645890048.0
Loss at iteration 2240 : 147039248.0
Loss at iteration 2250 : 109559016.0
Loss at iteration 2260 : 5471864.0
Loss at iteration 2270 : 42176492.0
Loss at iteration 2280 : 331080672.0
Loss at iteration 2290 : 89708680.0
Loss at iteration 2300 : 57262407680.0
Loss at iteration 2310 : 415490211840.0
Loss at iteration 2320 : 804231936.0
Loss at iteration 2330 : 30044557312.0
Loss at iteration 2340 : 313126813696.0
Loss at iteration 2350 : 7515027968.0
Loss at iteration 2360 : 33410156544.0
Loss at iteration 2370 : 136878161920.0
Loss at iteration 2380 : 454789312.0
Loss at iteration 2390 : 23773292.0
Loss at iteration 2400 : 44601788.0
Loss at iteration 2410 : 5629953536.0
Loss at iteration 2420 : 822961792.0
The SSIM Value is: -5.140577419145605e-07
The PSNR Value is: -97.92046813964843
the epoch is: 131
Loss at iteration 10 : 709534208.0
Loss at iteration 20 : 1085969152.0
Loss at iteration 30 : 19744522240.0
Loss at iteration 40 : 11226032.0
Loss at iteration 50 : 50846644.0
Loss at iteration 60 : 7348795.0
Loss at iteration 70 : 7335067136.0
Loss at iteration 80 : 1166734592.0
Loss at iteration 90 : 2620317952.0
Loss at iteration 100 : 6021034496.0
Loss at iteration 110 : 43985272832.0
Loss at iteration 120 : 26439786496.0
Loss at iteration 130 : 231243232.0
Loss at iteration 140 : 507816384.0
Loss at iteration 150 : 196957680.0
Loss at iteration 160 : 41290874880.0
Loss at iteration 170 : 391502112.0
Loss at iteration 180 : 25973670.0
Loss at iteration 190 : 169208576.0
Loss at iteration 200 : 230193744.0
Loss at iteration 210 : 1996792832.0
Loss at iteration 220 : 17654294.0
Loss at iteration 230 : 63681464.0
Loss at iteration 240 : 661661632.0
Loss at iteration 250 : 13980649472.0
Loss at iteration 260 : 63339479040.0
Loss at iteration 270 : 235307184.0
Loss at iteration 280 : 53364328.0
Loss at iteration 290 : 128706504.0
Loss at iteration 300 : 187000128.0
Loss at iteration 310 : 13418279936.0
Loss at iteration 320 : 93009448.0
Loss at iteration 330 : 7237999616.0
Loss at iteration 340 : 6134024372224.0
Loss at iteration 350 : 23178760.0
Loss at iteration 360 : 3115942144.0
Loss at iteration 370 : 40309520.0
Loss at iteration 380 : 618855808.0
Loss at iteration 390 : 26747273740288.0
Loss at iteration 400 : 675885023232.0
Loss at iteration 410 : 2123882624.0
Loss at iteration 420 : 4564235264.0
Loss at iteration 430 : 769105856.0
Loss at iteration 440 : 330622368.0
Loss at iteration 450 : 59246456832.0
Loss at iteration 460 : 1127229696.0
Loss at iteration 470 : 8384365056.0
Loss at iteration 480 : 2409201408.0
Loss at iteration 490 : 7692834304.0
Loss at iteration 500 : 425427936.0
Loss at iteration 510 : 6029763072.0
Loss at iteration 520 : 4482552832.0
Loss at iteration 530 : 590181760.0
Loss at iteration 540 : 9661413376.0
Loss at iteration 550 : 4336175616.0
Loss at iteration 560 : 47131811840.0
Loss at iteration 570 : 542152640.0
Loss at iteration 580 : 51478441984.0
Loss at iteration 590 : 13126531072.0
Loss at iteration 600 : 9930267648.0
Loss at iteration 610 : 996614784.0
Loss at iteration 620 : 309866784.0
Loss at iteration 630 : 55117979648.0
Loss at iteration 640 : 3504600320.0
Loss at iteration 650 : 656776232960.0
Loss at iteration 660 : 394419840.0
Loss at iteration 670 : 4103076352.0
Loss at iteration 680 : 70930008.0
Loss at iteration 690 : 6150332928.0
Loss at iteration 700 : 134845882368.0
Loss at iteration 710 : 87166064.0
Loss at iteration 720 : 812275776.0
Loss at iteration 730 : 37382048.0
Loss at iteration 740 : 102900416.0
Loss at iteration 750 : 103456152.0
Loss at iteration 760 : 910715904.0
Loss at iteration 770 : 3795216236544.0
Loss at iteration 780 : 1141393280.0
Loss at iteration 790 : 8610638848.0
Loss at iteration 800 : 495473824.0
Loss at iteration 810 : 4410373120.0
Loss at iteration 820 : 1053955200.0
Loss at iteration 830 : 363715872.0
Loss at iteration 840 : 174952120320.0
Loss at iteration 850 : 1620363444224.0
Loss at iteration 860 : 2889006710784.0
Loss at iteration 870 : 943326429184.0
Loss at iteration 880 : 996131143680.0
Loss at iteration 890 : 178787172352.0
Loss at iteration 900 : 157815717888.0
Loss at iteration 910 : 1081453117440.0
Loss at iteration 920 : 378367737856.0
Loss at iteration 930 : 518489341952.0
Loss at iteration 940 : 4746606592.0
Loss at iteration 950 : 206295168.0
Loss at iteration 960 : 112385880.0
Loss at iteration 970 : 7519579136.0
Loss at iteration 980 : 72914649088.0
Loss at iteration 990 : 27466246144.0
Loss at iteration 1000 : 37825904640.0
Loss at iteration 1010 : 21967769600.0
Loss at iteration 1020 : 3443459328.0
Loss at iteration 1030 : 1844239616.0
Loss at iteration 1040 : 15952214016.0
Loss at iteration 1050 : 1230754048.0
Loss at iteration 1060 : 4429071360.0
Loss at iteration 1070 : 10278645760.0
Loss at iteration 1080 : 965841344.0
Loss at iteration 1090 : 6398124544.0
Loss at iteration 1100 : 89892929536.0
Loss at iteration 1110 : 2651839232.0
Loss at iteration 1120 : 193812048.0
Loss at iteration 1130 : 3625605376.0
Loss at iteration 1140 : 463085088.0
Loss at iteration 1150 : 3216257536.0
Loss at iteration 1160 : 12899622912.0
Loss at iteration 1170 : 418318811136.0
Loss at iteration 1180 : 12501937152.0
Loss at iteration 1190 : 284989423616.0
Loss at iteration 1200 : 50100097024.0
Loss at iteration 1210 : 112337879040.0
Loss at iteration 1220 : 2658416640.0
Loss at iteration 1230 : 17981929472.0
Loss at iteration 1240 : 93061980160.0
Loss at iteration 1250 : 3705138176.0
Loss at iteration 1260 : 67165356032.0
Loss at iteration 1270 : 5131234967552.0
Loss at iteration 1280 : 19540488192.0
Loss at iteration 1290 : 311483400192.0
Loss at iteration 1300 : 1069510720.0
Loss at iteration 1310 : 697944178688.0
Loss at iteration 1320 : 108845121536.0
Loss at iteration 1330 : 52411846656.0
Loss at iteration 1340 : 50205831168.0
Loss at iteration 1350 : 3215719680.0
Loss at iteration 1360 : 119670816768.0
Loss at iteration 1370 : 54485377024.0
Loss at iteration 1380 : 151109419008.0
Loss at iteration 1390 : 266705862656.0
Loss at iteration 1400 : 1411670474752.0
Loss at iteration 1410 : 599128473600.0
Loss at iteration 1420 : 35949076480.0
Loss at iteration 1430 : 71499382784.0
Loss at iteration 1440 : 17808044032.0
Loss at iteration 1450 : 1130879104.0
Loss at iteration 1460 : 19711754240.0
Loss at iteration 1470 : 379877664.0
Loss at iteration 1480 : 9666372608.0
Loss at iteration 1490 : 46070845440.0
Loss at iteration 1500 : 33802334208.0
Loss at iteration 1510 : 1379862912.0
Loss at iteration 1520 : 23112685568.0
Loss at iteration 1530 : 78995357696.0
Loss at iteration 1540 : 1598607488.0
Loss at iteration 1550 : 46883119104.0
Loss at iteration 1560 : 19775232000.0
Loss at iteration 1570 : 11635872768.0
Loss at iteration 1580 : 82260688896.0
Loss at iteration 1590 : 3819778304.0
Loss at iteration 1600 : 261084208.0
Loss at iteration 1610 : 3475962624.0
Loss at iteration 1620 : 1497600128.0
Loss at iteration 1630 : 157786243072.0
Loss at iteration 1640 : 646949184.0
Loss at iteration 1650 : 2570840576.0
Loss at iteration 1660 : 102688424.0
Loss at iteration 1670 : 13200711.0
Loss at iteration 1680 : 2854198784.0
Loss at iteration 1690 : 129694024.0
Loss at iteration 1700 : 15651158016.0
Loss at iteration 1710 : 15779991552.0
Loss at iteration 1720 : 1376914560.0
Loss at iteration 1730 : 419498176.0
Loss at iteration 1740 : 7502318080.0
Loss at iteration 1750 : 103121829888.0
Loss at iteration 1760 : 1556388736.0
Loss at iteration 1770 : 8652042.0
Loss at iteration 1780 : 2060094464.0
Loss at iteration 1790 : 317806080.0
Loss at iteration 1800 : 4519202304.0
Loss at iteration 1810 : 2593053440.0
Loss at iteration 1820 : 1251722624.0
Loss at iteration 1830 : 1499188736.0
Loss at iteration 1840 : 1047839808.0
Loss at iteration 1850 : 1300258304.0
Loss at iteration 1860 : 689694144.0
Loss at iteration 1870 : 1096502144.0
Loss at iteration 1880 : 351425728.0
Loss at iteration 1890 : 31514556416.0
Loss at iteration 1900 : 11154664456192.0
Loss at iteration 1910 : 101543804928.0
Loss at iteration 1920 : 854231547904.0
Loss at iteration 1930 : 7028654080.0
Loss at iteration 1940 : 142408197079040.0
Loss at iteration 1950 : 218748977152.0
Loss at iteration 1960 : 455121141760.0
Loss at iteration 1970 : 8250992128.0
Loss at iteration 1980 : 340122075136.0
Loss at iteration 1990 : 1424553148416.0
Loss at iteration 2000 : 22785992687616.0
Loss at iteration 2010 : 24156810772480.0
Loss at iteration 2020 : 2765586694144.0
Loss at iteration 2030 : 264876802048.0
Loss at iteration 2040 : 129072136192.0
Loss at iteration 2050 : 60771749888.0
Loss at iteration 2060 : 628725907456.0
Loss at iteration 2070 : 429112197120.0
Loss at iteration 2080 : 151475617792.0
Loss at iteration 2090 : 48487694336.0
Loss at iteration 2100 : 114310791168.0
Loss at iteration 2110 : 953640484864.0
Loss at iteration 2120 : 2886813089792.0
Loss at iteration 2130 : 2264570789888.0
Loss at iteration 2140 : 136533606400.0
Loss at iteration 2150 : 353162559488.0
Loss at iteration 2160 : 19140732928.0
Loss at iteration 2170 : 1540905369600.0
Loss at iteration 2180 : 402869616640.0
Loss at iteration 2190 : 72349016064.0
Loss at iteration 2200 : 380749217792.0
Loss at iteration 2210 : 8779848704.0
Loss at iteration 2220 : 586112303104.0
Loss at iteration 2230 : 50346721280.0
Loss at iteration 2240 : 432569548800.0
Loss at iteration 2250 : 263008616448.0
Loss at iteration 2260 : 177005969408.0
Loss at iteration 2270 : 1498124386304.0
Loss at iteration 2280 : 1413856886784.0
Loss at iteration 2290 : 85436112896.0
Loss at iteration 2300 : 62741934080.0
Loss at iteration 2310 : 73720561664.0
Loss at iteration 2320 : 14959222784.0
Loss at iteration 2330 : 119167265013760.0
Loss at iteration 2340 : 27098393608192.0
Loss at iteration 2350 : 106873856000.0
Loss at iteration 2360 : 187861696512.0
Loss at iteration 2370 : 292846272512.0
Loss at iteration 2380 : 231457079296.0
Loss at iteration 2390 : 311523868672.0
Loss at iteration 2400 : 1821392240640.0
Loss at iteration 2410 : 589575487488.0
Loss at iteration 2420 : 2268768239616.0
The SSIM Value is: 4.811628975668706e-06
The PSNR Value is: -123.85026601155599
the epoch is: 132
Loss at iteration 10 : 64892989440.0
Loss at iteration 20 : 453374312448.0
Loss at iteration 30 : 27829231616.0
Loss at iteration 40 : 3500041568256.0
Loss at iteration 50 : 31261796352.0
Loss at iteration 60 : 10747967488.0
Loss at iteration 70 : 44948029440.0
Loss at iteration 80 : 746173431808.0
Loss at iteration 90 : 4046574336.0
Loss at iteration 100 : 23512834048.0
Loss at iteration 110 : 974022049792.0
Loss at iteration 120 : 163674341376.0
Loss at iteration 130 : 311291772928.0
Loss at iteration 140 : 778171252736.0
Loss at iteration 150 : 142456946688.0
Loss at iteration 160 : 590709260288.0
Loss at iteration 170 : 4750996144128.0
Loss at iteration 180 : 183575363584.0
Loss at iteration 190 : 1059137847296.0
Loss at iteration 200 : 9106675990528.0
Loss at iteration 210 : 22730701275136.0
Loss at iteration 220 : 5705514352640.0
Loss at iteration 230 : 18605399867392.0
Loss at iteration 240 : 861357539328.0
Loss at iteration 250 : 800479248384.0
Loss at iteration 260 : 57405390848.0
Loss at iteration 270 : 63144476672.0
Loss at iteration 280 : 38876082176.0
Loss at iteration 290 : 676957913088.0
Loss at iteration 300 : 1123232776192.0
Loss at iteration 310 : 17632550912.0
Loss at iteration 320 : 189962698752.0
Loss at iteration 330 : 34266304512.0
Loss at iteration 340 : 2628889600.0
Loss at iteration 350 : 37898129408.0
Loss at iteration 360 : 529537138688.0
Loss at iteration 370 : 160523993088.0
Loss at iteration 380 : 1143989338112.0
Loss at iteration 390 : 4390190317568.0
Loss at iteration 400 : 715124113408.0
Loss at iteration 410 : 1174807642112.0
Loss at iteration 420 : 1893860114432.0
Loss at iteration 430 : 304777986048.0
Loss at iteration 440 : 222496653312.0
Loss at iteration 450 : 378876952576.0
Loss at iteration 460 : 230618136576.0
Loss at iteration 470 : 112265134080.0
Loss at iteration 480 : 36227252224.0
Loss at iteration 490 : 1283462791168.0
Loss at iteration 500 : 37538115584.0
Loss at iteration 510 : 103573864448.0
Loss at iteration 520 : 12547545088.0
Loss at iteration 530 : 45423857664.0
Loss at iteration 540 : 313721520128.0
Loss at iteration 550 : 156742189056.0
Loss at iteration 560 : 1672850833408.0
Loss at iteration 570 : 14385903616.0
Loss at iteration 580 : 80037265408.0
Loss at iteration 590 : 278065774592.0
Loss at iteration 600 : 396395708416.0
Loss at iteration 610 : 367167995904.0
Loss at iteration 620 : 78986502144.0
Loss at iteration 630 : 12032827392.0
Loss at iteration 640 : 17981911040.0
Loss at iteration 650 : 134391660544.0
Loss at iteration 660 : 260737204224.0
Loss at iteration 670 : 469750349824.0
Loss at iteration 680 : 528689037312.0
Loss at iteration 690 : 478592401408.0
Loss at iteration 700 : 10969380864.0
Loss at iteration 710 : 264552595456.0
Loss at iteration 720 : 433338843136.0
Loss at iteration 730 : 38381203456.0
Loss at iteration 740 : 22088421376.0
Loss at iteration 750 : 15337466880.0
Loss at iteration 760 : 358636093440.0
Loss at iteration 770 : 87226376192.0
Loss at iteration 780 : 169933160448.0
Loss at iteration 790 : 2027704680448.0
Loss at iteration 800 : 130998681600.0
Loss at iteration 810 : 744359198720.0
Loss at iteration 820 : 138822598656.0
Loss at iteration 830 : 64263286784.0
Loss at iteration 840 : 26211340288.0
Loss at iteration 850 : 83252576256.0
Loss at iteration 860 : 26233047040.0
Loss at iteration 870 : 13635903488.0
Loss at iteration 880 : 7491037184.0
Loss at iteration 890 : 72737669120.0
Loss at iteration 900 : 57383833600.0
Loss at iteration 910 : 30417741824.0
Loss at iteration 920 : 13542240256.0
Loss at iteration 930 : 37115052032.0
Loss at iteration 940 : 43799748608.0
Loss at iteration 950 : 4812459008.0
Loss at iteration 960 : 98778079232.0
Loss at iteration 970 : 28584189952.0
Loss at iteration 980 : 11527111680.0
Loss at iteration 990 : 110872010752.0
Loss at iteration 1000 : 125997129728.0
Loss at iteration 1010 : 103662895104.0
Loss at iteration 1020 : 18281541632.0
Loss at iteration 1030 : 8520066560.0
Loss at iteration 1040 : 38662324224.0
Loss at iteration 1050 : 248232296448.0
Loss at iteration 1060 : 77248225280.0
Loss at iteration 1070 : 12602479616.0
Loss at iteration 1080 : 23492898816.0
Loss at iteration 1090 : 41351823360.0
Loss at iteration 1100 : 84397867008.0
Loss at iteration 1110 : 24501002240.0
Loss at iteration 1120 : 12425408512.0
Loss at iteration 1130 : 16367289344.0
Loss at iteration 1140 : 13337921536.0
Loss at iteration 1150 : 286695680.0
Loss at iteration 1160 : 5956293120.0
Loss at iteration 1170 : 29213698048.0
Loss at iteration 1180 : 45464268800.0
Loss at iteration 1190 : 4623885824.0
Loss at iteration 1200 : 7256623104.0
Loss at iteration 1210 : 2471579136.0
Loss at iteration 1220 : 4441025536.0
Loss at iteration 1230 : 33576972288.0
Loss at iteration 1240 : 4291128576.0
Loss at iteration 1250 : 17653757952.0
Loss at iteration 1260 : 8464150016.0
Loss at iteration 1270 : 59546660864.0
Loss at iteration 1280 : 2548548096.0
Loss at iteration 1290 : 1978013440.0
Loss at iteration 1300 : 26091991040.0
Loss at iteration 1310 : 5398584320.0
Loss at iteration 1320 : 4437975040.0
Loss at iteration 1330 : 19911327744.0
Loss at iteration 1340 : 9632873472.0
Loss at iteration 1350 : 22957756416.0
Loss at iteration 1360 : 8853451776.0
Loss at iteration 1370 : 7217432576.0
Loss at iteration 1380 : 2779944448.0
Loss at iteration 1390 : 4440709632.0
Loss at iteration 1400 : 19611316224.0
Loss at iteration 1410 : 15922600960.0
Loss at iteration 1420 : 4226064640.0
Loss at iteration 1430 : 53648089088.0
Loss at iteration 1440 : 1642245376.0
Loss at iteration 1450 : 737060800.0
Loss at iteration 1460 : 15218243584.0
Loss at iteration 1470 : 70549078016.0
Loss at iteration 1480 : 7323295232.0
Loss at iteration 1490 : 93020296.0
Loss at iteration 1500 : 111337603072.0
Loss at iteration 1510 : 144208363520.0
Loss at iteration 1520 : 26785327104.0
Loss at iteration 1530 : 1758652032.0
Loss at iteration 1540 : 1531103232.0
Loss at iteration 1550 : 66990247936.0
Loss at iteration 1560 : 2842853632.0
Loss at iteration 1570 : 65770586112.0
Loss at iteration 1580 : 3189964800.0
Loss at iteration 1590 : 16601201664.0
Loss at iteration 1600 : 3238202624.0
Loss at iteration 1610 : 18080292864.0
Loss at iteration 1620 : 4862660608.0
Loss at iteration 1630 : 1010688851968.0
Loss at iteration 1640 : 2276490752.0
Loss at iteration 1650 : 148432551936.0
Loss at iteration 1660 : 32221202432.0
Loss at iteration 1670 : 1921421056.0
Loss at iteration 1680 : 51282423808.0
Loss at iteration 1690 : 1309611264.0
Loss at iteration 1700 : 2687881472.0
Loss at iteration 1710 : 5685653504.0
Loss at iteration 1720 : 217963872256.0
Loss at iteration 1730 : 212908256.0
Loss at iteration 1740 : 58960379904.0
Loss at iteration 1750 : 7967378944.0
Loss at iteration 1760 : 45799219200.0
Loss at iteration 1770 : 18711949312.0
Loss at iteration 1780 : 7406449152.0
Loss at iteration 1790 : 7248790016.0
Loss at iteration 1800 : 708411584.0
Loss at iteration 1810 : 74820648960.0
Loss at iteration 1820 : 94950653952.0
Loss at iteration 1830 : 26421702656.0
Loss at iteration 1840 : 27485079552.0
Loss at iteration 1850 : 12645498880.0
Loss at iteration 1860 : 144143007744.0
Loss at iteration 1870 : 38975676416.0
Loss at iteration 1880 : 9583042560.0
Loss at iteration 1890 : 10874738688.0
Loss at iteration 1900 : 291112124416.0
Loss at iteration 1910 : 2499254272.0
Loss at iteration 1920 : 1719957632.0
Loss at iteration 1930 : 9656233984.0
Loss at iteration 1940 : 5829385781248.0
Loss at iteration 1950 : 758442819584.0
Loss at iteration 1960 : 29141587968.0
Loss at iteration 1970 : 540816769024.0
Loss at iteration 1980 : 1758892416.0
Loss at iteration 1990 : 182328016896.0
Loss at iteration 2000 : 41445027840.0
Loss at iteration 2010 : 2995812864.0
Loss at iteration 2020 : 533660320.0
Loss at iteration 2030 : 2009491968.0
Loss at iteration 2040 : 9360193536.0
Loss at iteration 2050 : 7375387136.0
Loss at iteration 2060 : 406614507520.0
Loss at iteration 2070 : 3724247296.0
Loss at iteration 2080 : 57854189568.0
Loss at iteration 2090 : 11815739392.0
Loss at iteration 2100 : 2659875840.0
Loss at iteration 2110 : 10195168256.0
Loss at iteration 2120 : 7893798912.0
Loss at iteration 2130 : 7951595008.0
Loss at iteration 2140 : 9236635648.0
Loss at iteration 2150 : 15559497728.0
Loss at iteration 2160 : 28557754368.0
Loss at iteration 2170 : 285429792768.0
Loss at iteration 2180 : 24704145408.0
Loss at iteration 2190 : 11985092608.0
Loss at iteration 2200 : 57869185024.0
Loss at iteration 2210 : 26346254336.0
Loss at iteration 2220 : 4124978176.0
Loss at iteration 2230 : 21074479104.0
Loss at iteration 2240 : 1053012800.0
Loss at iteration 2250 : 172318801920.0
Loss at iteration 2260 : 3302249472.0
Loss at iteration 2270 : 35790651392.0
Loss at iteration 2280 : 1049489088.0
Loss at iteration 2290 : 21019084800.0
Loss at iteration 2300 : 17137045504.0
Loss at iteration 2310 : 3150487040.0
Loss at iteration 2320 : 7916451840.0
Loss at iteration 2330 : 27381753856.0
Loss at iteration 2340 : 3171850240.0
Loss at iteration 2350 : 3177230592.0
Loss at iteration 2360 : 39881687040.0
Loss at iteration 2370 : 13242120192.0
Loss at iteration 2380 : 10523167744.0
Loss at iteration 2390 : 8774544384.0
Loss at iteration 2400 : 27862669312.0
Loss at iteration 2410 : 77044948992.0
Loss at iteration 2420 : 17035704320.0
The SSIM Value is: 2.0008716273878235e-05
The PSNR Value is: -111.06184794108073
the epoch is: 133
Loss at iteration 10 : 4364984320.0
Loss at iteration 20 : 6977668608.0
Loss at iteration 30 : 1570095232.0
Loss at iteration 40 : 4438177792.0
Loss at iteration 50 : 40506118144.0
Loss at iteration 60 : 4281320192.0
Loss at iteration 70 : 257024688128.0
Loss at iteration 80 : 5473828352.0
Loss at iteration 90 : 4128822528.0
Loss at iteration 100 : 9272192000.0
Loss at iteration 110 : 4043747840.0
Loss at iteration 120 : 24822427648.0
Loss at iteration 130 : 119255359488.0
Loss at iteration 140 : 17969803264.0
Loss at iteration 150 : 191203753984.0
Loss at iteration 160 : 14736784384.0
Loss at iteration 170 : 9814501376.0
Loss at iteration 180 : 8837725184.0
Loss at iteration 190 : 42938552320.0
Loss at iteration 200 : 722247104.0
Loss at iteration 210 : 8521819136.0
Loss at iteration 220 : 4430087168.0
Loss at iteration 230 : 6213832192.0
Loss at iteration 240 : 9760946176.0
Loss at iteration 250 : 6524070400.0
Loss at iteration 260 : 57248714752.0
Loss at iteration 270 : 1989052032.0
Loss at iteration 280 : 493964984320.0
Loss at iteration 290 : 239646883840.0
Loss at iteration 300 : 35999629312.0
Loss at iteration 310 : 16612618928128.0
Loss at iteration 320 : 128550264832.0
Loss at iteration 330 : 14689767424.0
Loss at iteration 340 : 165232246784.0
Loss at iteration 350 : 3996938240.0
Loss at iteration 360 : 16093503488.0
Loss at iteration 370 : 57320497152.0
Loss at iteration 380 : 13813198848.0
Loss at iteration 390 : 552823226368.0
Loss at iteration 400 : 7813532160.0
Loss at iteration 410 : 11843539968.0
Loss at iteration 420 : 47136141312.0
Loss at iteration 430 : 21337610240.0
Loss at iteration 440 : 846096105472.0
Loss at iteration 450 : 623627730944.0
Loss at iteration 460 : 15895939072.0
Loss at iteration 470 : 313643073536.0
Loss at iteration 480 : 42759684096.0
Loss at iteration 490 : 16915565568.0
Loss at iteration 500 : 15684847616.0
Loss at iteration 510 : 11406521344.0
Loss at iteration 520 : 198854656000.0
Loss at iteration 530 : 57834885120.0
Loss at iteration 540 : 23146409984.0
Loss at iteration 550 : 476134539264.0
Loss at iteration 560 : 16332692480.0
Loss at iteration 570 : 2379222016.0
Loss at iteration 580 : 21119432704.0
Loss at iteration 590 : 50091511808.0
Loss at iteration 600 : 336167370752.0
Loss at iteration 610 : 23720173568.0
Loss at iteration 620 : 117238276096.0
Loss at iteration 630 : 1272835211264.0
Loss at iteration 640 : 21605724160.0
Loss at iteration 650 : 12368173056.0
Loss at iteration 660 : 3440187904.0
Loss at iteration 670 : 40398061568.0
Loss at iteration 680 : 30507767808.0
Loss at iteration 690 : 81842348032.0
Loss at iteration 700 : 1495595776.0
Loss at iteration 710 : 22679478272.0
Loss at iteration 720 : 58465615872.0
Loss at iteration 730 : 83099492352.0
Loss at iteration 740 : 1654306504704.0
Loss at iteration 750 : 219187707904.0
Loss at iteration 760 : 771710844928.0
Loss at iteration 770 : 1005617872896.0
Loss at iteration 780 : 335066103808.0
Loss at iteration 790 : 1058357379072.0
Loss at iteration 800 : 252789211136.0
Loss at iteration 810 : 281185091584.0
Loss at iteration 820 : 1353719349248.0
Loss at iteration 830 : 393130508288.0
Loss at iteration 840 : 870306217984.0
Loss at iteration 850 : 7977833070592.0
Loss at iteration 860 : 14094442692608.0
Loss at iteration 870 : 1421171359744.0
Loss at iteration 880 : 2073967460352.0
Loss at iteration 890 : 1983245320192.0
Loss at iteration 900 : 295322779648.0
Loss at iteration 910 : 95758278656.0
Loss at iteration 920 : 1253636308992.0
Loss at iteration 930 : 44438274048.0
Loss at iteration 940 : 758817095680.0
Loss at iteration 950 : 323022585856.0
Loss at iteration 960 : 354552119296.0
Loss at iteration 970 : 84197376000.0
Loss at iteration 980 : 266969137152.0
Loss at iteration 990 : 60250537984.0
Loss at iteration 1000 : 11839908864.0
Loss at iteration 1010 : 170678747136.0
Loss at iteration 1020 : 119949418496.0
Loss at iteration 1030 : 285140189184.0
Loss at iteration 1040 : 95388942336.0
Loss at iteration 1050 : 76306661376.0
Loss at iteration 1060 : 10482470912.0
Loss at iteration 1070 : 9512933376.0
Loss at iteration 1080 : 14013602816.0
Loss at iteration 1090 : 147768999936.0
Loss at iteration 1100 : 32501194752.0
Loss at iteration 1110 : 31223189504.0
Loss at iteration 1120 : 353030307840.0
Loss at iteration 1130 : 52680986624.0
Loss at iteration 1140 : 531121700864.0
Loss at iteration 1150 : 151658643456.0
Loss at iteration 1160 : 78054490112.0
Loss at iteration 1170 : 479149916160.0
Loss at iteration 1180 : 37868867584.0
Loss at iteration 1190 : 458958602240.0
Loss at iteration 1200 : 258118565888.0
Loss at iteration 1210 : 172275924992.0
Loss at iteration 1220 : 39087357952.0
Loss at iteration 1230 : 3478366976.0
Loss at iteration 1240 : 31566968832.0
Loss at iteration 1250 : 23939323904.0
Loss at iteration 1260 : 203036262400.0
Loss at iteration 1270 : 24170366976.0
Loss at iteration 1280 : 23441414144.0
Loss at iteration 1290 : 26723059712.0
Loss at iteration 1300 : 51038728192.0
Loss at iteration 1310 : 64543195136.0
Loss at iteration 1320 : 138580279296.0
Loss at iteration 1330 : 58334130176.0
Loss at iteration 1340 : 85778210816.0
Loss at iteration 1350 : 88062533632.0
Loss at iteration 1360 : 18404997120.0
Loss at iteration 1370 : 793692209152.0
Loss at iteration 1380 : 45216862208.0
Loss at iteration 1390 : 3296422144.0
Loss at iteration 1400 : 160784351232.0
Loss at iteration 1410 : 19329396736.0
Loss at iteration 1420 : 48662659072.0
Loss at iteration 1430 : 10713293824.0
Loss at iteration 1440 : 35724005376.0
Loss at iteration 1450 : 851309363200.0
Loss at iteration 1460 : 196763090944.0
Loss at iteration 1470 : 14188726272.0
Loss at iteration 1480 : 13797825536.0
Loss at iteration 1490 : 45314764800.0
Loss at iteration 1500 : 168645705728.0
Loss at iteration 1510 : 50452271104.0
Loss at iteration 1520 : 11687347200.0
Loss at iteration 1530 : 2633427968.0
Loss at iteration 1540 : 9350112256.0
Loss at iteration 1550 : 63023149056.0
Loss at iteration 1560 : 47441833984.0
Loss at iteration 1570 : 17201356800.0
Loss at iteration 1580 : 126053900288.0
Loss at iteration 1590 : 6090477056.0
Loss at iteration 1600 : 13630224384.0
Loss at iteration 1610 : 131264757760.0
Loss at iteration 1620 : 63335301120.0
Loss at iteration 1630 : 9099599872.0
Loss at iteration 1640 : 5547126784.0
Loss at iteration 1650 : 162214166528.0
Loss at iteration 1660 : 81943396352.0
Loss at iteration 1670 : 31605979136.0
Loss at iteration 1680 : 58678046720.0
Loss at iteration 1690 : 20334286848.0
Loss at iteration 1700 : 19503859712.0
Loss at iteration 1710 : 2910683136.0
Loss at iteration 1720 : 24566960128.0
Loss at iteration 1730 : 4229994752.0
Loss at iteration 1740 : 838361481216.0
Loss at iteration 1750 : 17458724864.0
Loss at iteration 1760 : 20524343296.0
Loss at iteration 1770 : 10850447360.0
Loss at iteration 1780 : 12389076992.0
Loss at iteration 1790 : 9023073280.0
Loss at iteration 1800 : 2594903552.0
Loss at iteration 1810 : 11253452800.0
Loss at iteration 1820 : 65331396608.0
Loss at iteration 1830 : 8132668928.0
Loss at iteration 1840 : 15766213632.0
Loss at iteration 1850 : 16866256896.0
Loss at iteration 1860 : 32300294144.0
Loss at iteration 1870 : 14490255360.0
Loss at iteration 1880 : 14139476992.0
Loss at iteration 1890 : 5993026560.0
Loss at iteration 1900 : 736182627467264.0
Loss at iteration 1910 : 158666080.0
Loss at iteration 1920 : 235107434496.0
Loss at iteration 1930 : 743691584.0
Loss at iteration 1940 : 5218825216.0
Loss at iteration 1950 : 26609854464.0
Loss at iteration 1960 : 122519896064.0
Loss at iteration 1970 : 13961774080.0
Loss at iteration 1980 : 8923423744.0
Loss at iteration 1990 : 61516660736.0
Loss at iteration 2000 : 209094311936.0
Loss at iteration 2010 : 547397763072.0
Loss at iteration 2020 : 1130684219392.0
Loss at iteration 2030 : 76612042752.0
Loss at iteration 2040 : 278111584256.0
Loss at iteration 2050 : 277823193088.0
Loss at iteration 2060 : 330443751424.0
Loss at iteration 2070 : 208663265280.0
Loss at iteration 2080 : 1038322761728.0
Loss at iteration 2090 : 105299279872.0
Loss at iteration 2100 : 52376551424.0
Loss at iteration 2110 : 1917033644032.0
Loss at iteration 2120 : 32602714112.0
Loss at iteration 2130 : 1278511022080.0
Loss at iteration 2140 : 576575307776.0
Loss at iteration 2150 : 1281002045440.0
Loss at iteration 2160 : 606365286400.0
Loss at iteration 2170 : 56970706944.0
Loss at iteration 2180 : 25736871936.0
Loss at iteration 2190 : 9404367872.0
Loss at iteration 2200 : 40250109952.0
Loss at iteration 2210 : 1152388431872.0
Loss at iteration 2220 : 1909728346112.0
Loss at iteration 2230 : 317149216768.0
Loss at iteration 2240 : 115065487360.0
Loss at iteration 2250 : 1441499447296.0
Loss at iteration 2260 : 1947700690944.0
Loss at iteration 2270 : 312188174336.0
Loss at iteration 2280 : 314994884608.0
Loss at iteration 2290 : 604897673216.0
Loss at iteration 2300 : 6246233538560.0
Loss at iteration 2310 : 24399159754752.0
Loss at iteration 2320 : 348483354624.0
Loss at iteration 2330 : 470350987264.0
Loss at iteration 2340 : 605250519040.0
Loss at iteration 2350 : 134059636293632.0
Loss at iteration 2360 : 405069529088.0
Loss at iteration 2370 : 343755948032.0
Loss at iteration 2380 : 105625436160.0
Loss at iteration 2390 : 10473244672.0
Loss at iteration 2400 : 13178018816.0
Loss at iteration 2410 : 19785179136.0
Loss at iteration 2420 : 93815824384.0
The SSIM Value is: 3.939988875956146e-06
The PSNR Value is: -118.0658457438151
the epoch is: 134
Loss at iteration 10 : 62319476736.0
Loss at iteration 20 : 41192525824.0
Loss at iteration 30 : 31602319360.0
Loss at iteration 40 : 45907927040.0
Loss at iteration 50 : 269650182144.0
Loss at iteration 60 : 353030864896.0
Loss at iteration 70 : 234141499392.0
Loss at iteration 80 : 2185550495744.0
Loss at iteration 90 : 1750083712.0
Loss at iteration 100 : 17255143309312.0
Loss at iteration 110 : 866565376.0
Loss at iteration 120 : 16581522432.0
Loss at iteration 130 : 84735590400.0
Loss at iteration 140 : 2383766528.0
Loss at iteration 150 : 4358517248.0
Loss at iteration 160 : 2137650432.0
Loss at iteration 170 : 10565198848.0
Loss at iteration 180 : 4480914944.0
Loss at iteration 190 : 17053049856.0
Loss at iteration 200 : 460209536.0
Loss at iteration 210 : 31293245440.0
Loss at iteration 220 : 132435763200.0
Loss at iteration 230 : 30423128064.0
Loss at iteration 240 : 51938639872.0
Loss at iteration 250 : 17508020224.0
Loss at iteration 260 : 2032108306432.0
Loss at iteration 270 : 695611752448.0
Loss at iteration 280 : 651372331008.0
Loss at iteration 290 : 91623038976.0
Loss at iteration 300 : 55999119360.0
Loss at iteration 310 : 53429149696.0
Loss at iteration 320 : 17193826304.0
Loss at iteration 330 : 24416798720.0
Loss at iteration 340 : 61047885824.0
Loss at iteration 350 : 8166828544.0
Loss at iteration 360 : 1944862982144.0
Loss at iteration 370 : 3980778240.0
Loss at iteration 380 : 24469315584.0
Loss at iteration 390 : 164143792128.0
Loss at iteration 400 : 25177274368.0
Loss at iteration 410 : 55441096704.0
Loss at iteration 420 : 83242254336.0
Loss at iteration 430 : 804608540672.0
Loss at iteration 440 : 27693844480.0
Loss at iteration 450 : 1192524382208.0
Loss at iteration 460 : 1626200866816.0
Loss at iteration 470 : 6165680640.0
Loss at iteration 480 : 26551922688.0
Loss at iteration 490 : 11716563968.0
Loss at iteration 500 : 2801432526848.0
Loss at iteration 510 : 9796224000.0
Loss at iteration 520 : 134785392640.0
Loss at iteration 530 : 342141042688.0
Loss at iteration 540 : 13130927104.0
Loss at iteration 550 : 465074421760.0
Loss at iteration 560 : 27473324032.0
Loss at iteration 570 : 406092578816.0
Loss at iteration 580 : 18582874112.0
Loss at iteration 590 : 3209399808.0
Loss at iteration 600 : 72372510720.0
Loss at iteration 610 : 11083709440.0
Loss at iteration 620 : 7039690240.0
Loss at iteration 630 : 1858898304.0
Loss at iteration 640 : 3205474048.0
Loss at iteration 650 : 921998592.0
Loss at iteration 660 : 2817381376.0
Loss at iteration 670 : 405374816.0
Loss at iteration 680 : 5907629568.0
Loss at iteration 690 : 3866923520.0
Loss at iteration 700 : 11364333568.0
Loss at iteration 710 : 64355864576.0
Loss at iteration 720 : 8350042624.0
Loss at iteration 730 : 1761969408.0
Loss at iteration 740 : 105631023104.0
Loss at iteration 750 : 4732780544.0
Loss at iteration 760 : 11514304512.0
Loss at iteration 770 : 1482088832.0
Loss at iteration 780 : 14762407936.0
Loss at iteration 790 : 2276523264.0
Loss at iteration 800 : 48176738304.0
Loss at iteration 810 : 5420345856.0
Loss at iteration 820 : 3368790272.0
Loss at iteration 830 : 19105472512.0
Loss at iteration 840 : 1096400768.0
Loss at iteration 850 : 8541983232.0
Loss at iteration 860 : 9425300480.0
Loss at iteration 870 : 5987491328.0
Loss at iteration 880 : 7056883712.0
Loss at iteration 890 : 4483241984.0
Loss at iteration 900 : 24552826880.0
Loss at iteration 910 : 2529318144.0
Loss at iteration 920 : 2881893376.0
Loss at iteration 930 : 2192996864.0
Loss at iteration 940 : 6456312832.0
Loss at iteration 950 : 3028771072.0
Loss at iteration 960 : 2826084352.0
Loss at iteration 970 : 5871133696.0
Loss at iteration 980 : 366905408.0
Loss at iteration 990 : 84989034496.0
Loss at iteration 1000 : 3699464192.0
Loss at iteration 1010 : 1407635840.0
Loss at iteration 1020 : 12371715072.0
Loss at iteration 1030 : 8445365248.0
Loss at iteration 1040 : 10239081472.0
Loss at iteration 1050 : 7692741632.0
Loss at iteration 1060 : 1687105280.0
Loss at iteration 1070 : 614250240.0
Loss at iteration 1080 : 9248105472.0
Loss at iteration 1090 : 257619520.0
Loss at iteration 1100 : 461806624.0
Loss at iteration 1110 : 1459902592.0
Loss at iteration 1120 : 626327168.0
Loss at iteration 1130 : 747324864.0
Loss at iteration 1140 : 1168977280.0
Loss at iteration 1150 : 1863993216.0
Loss at iteration 1160 : 245957456.0
Loss at iteration 1170 : 84515282944.0
Loss at iteration 1180 : 2362226432.0
Loss at iteration 1190 : 452236224.0
Loss at iteration 1200 : 927759104.0
Loss at iteration 1210 : 46738726912.0
Loss at iteration 1220 : 1475188096.0
Loss at iteration 1230 : 638356608.0
Loss at iteration 1240 : 1387700992.0
Loss at iteration 1250 : 1147214720.0
Loss at iteration 1260 : 380752064.0
Loss at iteration 1270 : 14986721280.0
Loss at iteration 1280 : 552142080.0
Loss at iteration 1290 : 102170200.0
Loss at iteration 1300 : 1381848448.0
Loss at iteration 1310 : 65658970112.0
Loss at iteration 1320 : 14460155904.0
Loss at iteration 1330 : 11894898688.0
Loss at iteration 1340 : 202106144.0
Loss at iteration 1350 : 5106468352.0
Loss at iteration 1360 : 14011112448.0
Loss at iteration 1370 : 63746580480.0
Loss at iteration 1380 : 1206070272.0
Loss at iteration 1390 : 10803295232.0
Loss at iteration 1400 : 541994944.0
Loss at iteration 1410 : 9848070144.0
Loss at iteration 1420 : 23612471296.0
Loss at iteration 1430 : 32089235456.0
Loss at iteration 1440 : 60655935488.0
Loss at iteration 1450 : 5304119808.0
Loss at iteration 1460 : 46831173632.0
Loss at iteration 1470 : 22916970496.0
Loss at iteration 1480 : 23903109120.0
Loss at iteration 1490 : 117152997376.0
Loss at iteration 1500 : 56138399744.0
Loss at iteration 1510 : 39444951040.0
Loss at iteration 1520 : 5196615680.0
Loss at iteration 1530 : 832106397696.0
Loss at iteration 1540 : 24321246363648.0
Loss at iteration 1550 : 172000320421888.0
Loss at iteration 1560 : 4238583529472.0
Loss at iteration 1570 : 1146701873152.0
Loss at iteration 1580 : 4804997283840.0
Loss at iteration 1590 : 1320922513408.0
Loss at iteration 1600 : 249582534656.0
Loss at iteration 1610 : 22280883142656.0
Loss at iteration 1620 : 571507081216.0
Loss at iteration 1630 : 261636538368.0
Loss at iteration 1640 : 300660490240.0
Loss at iteration 1650 : 699140407296.0
Loss at iteration 1660 : 1081074843648.0
Loss at iteration 1670 : 122993713152.0
Loss at iteration 1680 : 128450756608.0
Loss at iteration 1690 : 599385767936.0
Loss at iteration 1700 : 272397975552.0
Loss at iteration 1710 : 513964736512.0
Loss at iteration 1720 : 188414869504.0
Loss at iteration 1730 : 1256290910208.0
Loss at iteration 1740 : 142280228864.0
Loss at iteration 1750 : 121880977408.0
Loss at iteration 1760 : 1570260516864.0
Loss at iteration 1770 : 112509435904.0
Loss at iteration 1780 : 400292970496.0
Loss at iteration 1790 : 88704647168.0
Loss at iteration 1800 : 301836795904.0
Loss at iteration 1810 : 13656585216.0
Loss at iteration 1820 : 50085928960.0
Loss at iteration 1830 : 9701588992.0
Loss at iteration 1840 : 20595580928.0
Loss at iteration 1850 : 47033499648.0
Loss at iteration 1860 : 20040773632.0
Loss at iteration 1870 : 67925590016.0
Loss at iteration 1880 : 66343047168.0
Loss at iteration 1890 : 111936421888.0
Loss at iteration 1900 : 75607392256.0
Loss at iteration 1910 : 40405983232.0
Loss at iteration 1920 : 292036182016.0
Loss at iteration 1930 : 283243937792.0
Loss at iteration 1940 : 5599218630656.0
Loss at iteration 1950 : 171070062592.0
Loss at iteration 1960 : 70319865856.0
Loss at iteration 1970 : 246008233984.0
Loss at iteration 1980 : 76991029248.0
Loss at iteration 1990 : 126014210048.0
Loss at iteration 2000 : 52796628992.0
Loss at iteration 2010 : 15864939520.0
Loss at iteration 2020 : 20862707712.0
Loss at iteration 2030 : 51068190720.0
Loss at iteration 2040 : 69710340096.0
Loss at iteration 2050 : 122494427136.0
Loss at iteration 2060 : 34776010752.0
Loss at iteration 2070 : 428747063296.0
Loss at iteration 2080 : 53071519744.0
Loss at iteration 2090 : 31971790848.0
Loss at iteration 2100 : 45137240064.0
Loss at iteration 2110 : 147606192128.0
Loss at iteration 2120 : 21564739584.0
Loss at iteration 2130 : 71049469952.0
Loss at iteration 2140 : 1389617348608.0
Loss at iteration 2150 : 9409285120.0
Loss at iteration 2160 : 25558902784.0
Loss at iteration 2170 : 192906330112.0
Loss at iteration 2180 : 32327503872.0
Loss at iteration 2190 : 7397435392.0
Loss at iteration 2200 : 108827631616.0
Loss at iteration 2210 : 17817085952.0
Loss at iteration 2220 : 281067421696.0
Loss at iteration 2230 : 40395956224.0
Loss at iteration 2240 : 25540521984.0
Loss at iteration 2250 : 19971856384.0
Loss at iteration 2260 : 10513873920.0
Loss at iteration 2270 : 90621730816.0
Loss at iteration 2280 : 52068950016.0
Loss at iteration 2290 : 29800695808.0
Loss at iteration 2300 : 65887825920.0
Loss at iteration 2310 : 15185846272.0
Loss at iteration 2320 : 5174238208.0
Loss at iteration 2330 : 10979283968.0
Loss at iteration 2340 : 5974009856.0
Loss at iteration 2350 : 9805818880.0
Loss at iteration 2360 : 2294975744.0
Loss at iteration 2370 : 102149873664.0
Loss at iteration 2380 : 13944939520.0
Loss at iteration 2390 : 16275160064.0
Loss at iteration 2400 : 31703990272.0
Loss at iteration 2410 : 7157502976.0
Loss at iteration 2420 : 16697394176.0
The SSIM Value is: 4.2523735196198235e-06
The PSNR Value is: -113.89346110026041
the epoch is: 135
Loss at iteration 10 : 190829838336.0
Loss at iteration 20 : 4314376192.0
Loss at iteration 30 : 178470928384.0
Loss at iteration 40 : 31355805696.0
Loss at iteration 50 : 22739202048.0
Loss at iteration 60 : 95351996416.0
Loss at iteration 70 : 16593637376.0
Loss at iteration 80 : 4497299968.0
Loss at iteration 90 : 7710746624.0
Loss at iteration 100 : 18479104000.0
Loss at iteration 110 : 4647772160.0
Loss at iteration 120 : 126997544960.0
Loss at iteration 130 : 31128377344.0
Loss at iteration 140 : 7373658112.0
Loss at iteration 150 : 10517618688.0
Loss at iteration 160 : 19597934592.0
Loss at iteration 170 : 44173885440.0
Loss at iteration 180 : 9588434944.0
Loss at iteration 190 : 21404160000.0
Loss at iteration 200 : 2345539072.0
Loss at iteration 210 : 15023523840.0
Loss at iteration 220 : 15246409728.0
Loss at iteration 230 : 21841348608.0
Loss at iteration 240 : 78241652736.0
Loss at iteration 250 : 5467311616.0
Loss at iteration 260 : 22037012480.0
Loss at iteration 270 : 11695607808.0
Loss at iteration 280 : 3547971328.0
Loss at iteration 290 : 95463383040.0
Loss at iteration 300 : 95503220736.0
Loss at iteration 310 : 4944674816.0
Loss at iteration 320 : 73744433152.0
Loss at iteration 330 : 467174850560.0
Loss at iteration 340 : 490640998400.0
Loss at iteration 350 : 187368783872.0
Loss at iteration 360 : 68523847680.0
Loss at iteration 370 : 363080482816.0
Loss at iteration 380 : 209974018048.0
Loss at iteration 390 : 75187896320.0
Loss at iteration 400 : 1803064573952.0
Loss at iteration 410 : 176007839744.0
Loss at iteration 420 : 227893559296.0
Loss at iteration 430 : 663185850368.0
Loss at iteration 440 : 40991440896.0
Loss at iteration 450 : 192734117888.0
Loss at iteration 460 : 323192782848.0
Loss at iteration 470 : 313993756672.0
Loss at iteration 480 : 40365539328.0
Loss at iteration 490 : 12022572032.0
Loss at iteration 500 : 38338342912.0
Loss at iteration 510 : 544342278144.0
Loss at iteration 520 : 15654754304.0
Loss at iteration 530 : 556800868352.0
Loss at iteration 540 : 63577849856.0
Loss at iteration 550 : 101693923328.0
Loss at iteration 560 : 15012535296.0
Loss at iteration 570 : 2522182844416.0
Loss at iteration 580 : 4228943446016.0
Loss at iteration 590 : 2528126697472.0
Loss at iteration 600 : 4868465491968.0
Loss at iteration 610 : 883669073920.0
Loss at iteration 620 : 3758049722368.0
Loss at iteration 630 : 160043008000.0
Loss at iteration 640 : 612879368192.0
Loss at iteration 650 : 3208803254272.0
Loss at iteration 660 : 100485578752.0
Loss at iteration 670 : 2272494616576.0
Loss at iteration 680 : 16133402624.0
Loss at iteration 690 : 594975719424.0
Loss at iteration 700 : 49505755136.0
Loss at iteration 710 : 176804954112.0
Loss at iteration 720 : 369155342336.0
Loss at iteration 730 : 73583976448.0
Loss at iteration 740 : 828541501440.0
Loss at iteration 750 : 510257922048.0
Loss at iteration 760 : 923209433088.0
Loss at iteration 770 : 4363996672.0
Loss at iteration 780 : 30558072832.0
Loss at iteration 790 : 88737816576.0
Loss at iteration 800 : 245539373056.0
Loss at iteration 810 : 244590182400.0
Loss at iteration 820 : 63409807360.0
Loss at iteration 830 : 4145590829056.0
Loss at iteration 840 : 12984013824.0
Loss at iteration 850 : 249002328064.0
Loss at iteration 860 : 267829444608.0
Loss at iteration 870 : 22314956800.0
Loss at iteration 880 : 307318194176.0
Loss at iteration 890 : 107598741504.0
Loss at iteration 900 : 1142470737920.0
Loss at iteration 910 : 77510352896.0
Loss at iteration 920 : 21110829056.0
Loss at iteration 930 : 60520992768.0
Loss at iteration 940 : 54774013952.0
Loss at iteration 950 : 21016100864.0
Loss at iteration 960 : 361623126016.0
Loss at iteration 970 : 5858825728.0
Loss at iteration 980 : 9537370112.0
Loss at iteration 990 : 4245415680.0
Loss at iteration 1000 : 8185459712.0
Loss at iteration 1010 : 5980631040.0
Loss at iteration 1020 : 13801224192.0
Loss at iteration 1030 : 21987241984.0
Loss at iteration 1040 : 3829681920.0
Loss at iteration 1050 : 6184473088.0
Loss at iteration 1060 : 7162599936.0
Loss at iteration 1070 : 152075517952.0
Loss at iteration 1080 : 4617854976.0
Loss at iteration 1090 : 1762091466752.0
Loss at iteration 1100 : 85828190208.0
Loss at iteration 1110 : 508623585280.0
Loss at iteration 1120 : 37693517824.0
Loss at iteration 1130 : 62013755392.0
Loss at iteration 1140 : 42328506368.0
Loss at iteration 1150 : 287820709888.0
Loss at iteration 1160 : 6397799424.0
Loss at iteration 1170 : 39765770240.0
Loss at iteration 1180 : 6661021184.0
Loss at iteration 1190 : 180388069376.0
Loss at iteration 1200 : 14347098112.0
Loss at iteration 1210 : 3836463808512.0
Loss at iteration 1220 : 20128851968.0
Loss at iteration 1230 : 140478152704.0
Loss at iteration 1240 : 1958809567232.0
Loss at iteration 1250 : 6274801664.0
Loss at iteration 1260 : 78936399872.0
Loss at iteration 1270 : 50176925696.0
Loss at iteration 1280 : 127505965056.0
Loss at iteration 1290 : 152126980096.0
Loss at iteration 1300 : 47560790016.0
Loss at iteration 1310 : 462019330048.0
Loss at iteration 1320 : 187748581376.0
Loss at iteration 1330 : 49194188800.0
Loss at iteration 1340 : 5897131008.0
Loss at iteration 1350 : 1118430208.0
Loss at iteration 1360 : 2922795520.0
Loss at iteration 1370 : 2071200640.0
Loss at iteration 1380 : 148383318016.0
Loss at iteration 1390 : 10996767744.0
Loss at iteration 1400 : 109182230528.0
Loss at iteration 1410 : 15126881280.0
Loss at iteration 1420 : 7112685056.0
Loss at iteration 1430 : 17111050240.0
Loss at iteration 1440 : 11312702685184.0
Loss at iteration 1450 : 4654702592.0
Loss at iteration 1460 : 45394038784.0
Loss at iteration 1470 : 1648885235712.0
Loss at iteration 1480 : 7879612416.0
Loss at iteration 1490 : 14851553280.0
Loss at iteration 1500 : 87697473536.0
Loss at iteration 1510 : 995214753792.0
Loss at iteration 1520 : 171732910080.0
Loss at iteration 1530 : 28349960192.0
Loss at iteration 1540 : 10246454272.0
Loss at iteration 1550 : 4385622016.0
Loss at iteration 1560 : 297890512896.0
Loss at iteration 1570 : 366578663424.0
Loss at iteration 1580 : 5193735680.0
Loss at iteration 1590 : 186001696.0
Loss at iteration 1600 : 30683353088.0
Loss at iteration 1610 : 9594053632.0
Loss at iteration 1620 : 16522363904.0
Loss at iteration 1630 : 123031658496.0
Loss at iteration 1640 : 46808031232.0
Loss at iteration 1650 : 32489095168.0
Loss at iteration 1660 : 15169870848.0
Loss at iteration 1670 : 7774311936.0
Loss at iteration 1680 : 71794409472.0
Loss at iteration 1690 : 8173306368.0
Loss at iteration 1700 : 32096989184.0
Loss at iteration 1710 : 344654643200.0
Loss at iteration 1720 : 534264545280.0
Loss at iteration 1730 : 1555196411904.0
Loss at iteration 1740 : 3209978183680.0
Loss at iteration 1750 : 14741072248832.0
Loss at iteration 1760 : 129492303872.0
Loss at iteration 1770 : 8394260992.0
Loss at iteration 1780 : 380044443648.0
Loss at iteration 1790 : 14830985216.0
Loss at iteration 1800 : 28648837120.0
Loss at iteration 1810 : 16350374912.0
Loss at iteration 1820 : 405391409152.0
Loss at iteration 1830 : 6645052080128.0
Loss at iteration 1840 : 580991909888.0
Loss at iteration 1850 : 163689644032.0
Loss at iteration 1860 : 15669510144.0
Loss at iteration 1870 : 135574634496.0
Loss at iteration 1880 : 87912341504.0
Loss at iteration 1890 : 77218709504.0
Loss at iteration 1900 : 16309648384.0
Loss at iteration 1910 : 43883520000.0
Loss at iteration 1920 : 25844908032.0
Loss at iteration 1930 : 18635411456.0
Loss at iteration 1940 : 69102362624.0
Loss at iteration 1950 : 268810338304.0
Loss at iteration 1960 : 115070795776.0
Loss at iteration 1970 : 117450006528.0
Loss at iteration 1980 : 88808153088.0
Loss at iteration 1990 : 125232676864.0
Loss at iteration 2000 : 103382368256.0
Loss at iteration 2010 : 141538050048.0
Loss at iteration 2020 : 179476709376.0
Loss at iteration 2030 : 43001634816.0
Loss at iteration 2040 : 67728236544.0
Loss at iteration 2050 : 231240990720.0
Loss at iteration 2060 : 284096364544.0
Loss at iteration 2070 : 62671802368.0
Loss at iteration 2080 : 14929257472.0
Loss at iteration 2090 : 186709852160.0
Loss at iteration 2100 : 28396607488.0
Loss at iteration 2110 : 162885582848.0
Loss at iteration 2120 : 8347822080.0
Loss at iteration 2130 : 12911587328.0
Loss at iteration 2140 : 153055870976.0
Loss at iteration 2150 : 298757849088.0
Loss at iteration 2160 : 29872285696.0
Loss at iteration 2170 : 157229350912.0
Loss at iteration 2180 : 67519279104.0
Loss at iteration 2190 : 134278815744.0
Loss at iteration 2200 : 210476285952.0
Loss at iteration 2210 : 20552343552.0
Loss at iteration 2220 : 64399069184.0
Loss at iteration 2230 : 36503719936.0
Loss at iteration 2240 : 9478916096.0
Loss at iteration 2250 : 60115648512.0
Loss at iteration 2260 : 17958135808.0
Loss at iteration 2270 : 30407856128.0
Loss at iteration 2280 : 198485377024.0
Loss at iteration 2290 : 19513800704.0
Loss at iteration 2300 : 8523689984.0
Loss at iteration 2310 : 45123076096.0
Loss at iteration 2320 : 20641562624.0
Loss at iteration 2330 : 36153978880.0
Loss at iteration 2340 : 4733440512.0
Loss at iteration 2350 : 45510410240.0
Loss at iteration 2360 : 261122998272.0
Loss at iteration 2370 : 208879140995072.0
Loss at iteration 2380 : 402223267840.0
Loss at iteration 2390 : 611222224896.0
Loss at iteration 2400 : 1659051704320.0
Loss at iteration 2410 : 6079687163904.0
Loss at iteration 2420 : 6348552011776.0
The SSIM Value is: 7.147004763889224e-06
The PSNR Value is: -134.14103088378906
the epoch is: 136
Loss at iteration 10 : 7982834253824.0
Loss at iteration 20 : 31851573936128.0
Loss at iteration 30 : 1894921273344.0
Loss at iteration 40 : 6433591525376.0
Loss at iteration 50 : 3214104068096.0
Loss at iteration 60 : 2309584060416.0
Loss at iteration 70 : 3407997566976.0
Loss at iteration 80 : 518169133056.0
Loss at iteration 90 : 25702584320.0
Loss at iteration 100 : 71862288384.0
Loss at iteration 110 : 929922285568.0
Loss at iteration 120 : 154069352448.0
Loss at iteration 130 : 88914649088.0
Loss at iteration 140 : 47351939072.0
Loss at iteration 150 : 52308475904.0
Loss at iteration 160 : 55949914112.0
Loss at iteration 170 : 43820597248.0
Loss at iteration 180 : 447305613312.0
Loss at iteration 190 : 322645491712.0
Loss at iteration 200 : 4169169152.0
Loss at iteration 210 : 354537734144.0
Loss at iteration 220 : 6296969728.0
Loss at iteration 230 : 8283496448.0
Loss at iteration 240 : 6220552704.0
Loss at iteration 250 : 3544140032.0
Loss at iteration 260 : 173489487872.0
Loss at iteration 270 : 38197030912.0
Loss at iteration 280 : 16782938112.0
Loss at iteration 290 : 38009053184.0
Loss at iteration 300 : 23960754176.0
Loss at iteration 310 : 46376361984.0
Loss at iteration 320 : 13582563328.0
Loss at iteration 330 : 42033332224.0
Loss at iteration 340 : 3546839552.0
Loss at iteration 350 : 23082668032.0
Loss at iteration 360 : 64547495936.0
Loss at iteration 370 : 114695184384.0
Loss at iteration 380 : 24710041600.0
Loss at iteration 390 : 65884884992.0
Loss at iteration 400 : 99438510080.0
Loss at iteration 410 : 392399552512.0
Loss at iteration 420 : 28553105408.0
Loss at iteration 430 : 17678909440.0
Loss at iteration 440 : 143648555008.0
Loss at iteration 450 : 22688468992.0
Loss at iteration 460 : 56509485056.0
Loss at iteration 470 : 40399810560.0
Loss at iteration 480 : 100320296960.0
Loss at iteration 490 : 115599122432.0
Loss at iteration 500 : 473913753600.0
Loss at iteration 510 : 120009842688.0
Loss at iteration 520 : 1180674818048.0
Loss at iteration 530 : 6029204992.0
Loss at iteration 540 : 17150888960.0
Loss at iteration 550 : 19667109888.0
Loss at iteration 560 : 52567326720.0
Loss at iteration 570 : 41945591808.0
Loss at iteration 580 : 14565708800.0
Loss at iteration 590 : 636931866624.0
Loss at iteration 600 : 8038228480.0
Loss at iteration 610 : 3189280768.0
Loss at iteration 620 : 14485364736.0
Loss at iteration 630 : 2505397504.0
Loss at iteration 640 : 18030155776.0
Loss at iteration 650 : 195915104256.0
Loss at iteration 660 : 25719480320.0
Loss at iteration 670 : 7679956480.0
Loss at iteration 680 : 12096708608.0
Loss at iteration 690 : 69086052352.0
Loss at iteration 700 : 13241293824.0
Loss at iteration 710 : 19702439936.0
Loss at iteration 720 : 20427718656.0
Loss at iteration 730 : 77460430848.0
Loss at iteration 740 : 11287897088.0
Loss at iteration 750 : 14780247040.0
Loss at iteration 760 : 9378247680.0
Loss at iteration 770 : 23538923520.0
Loss at iteration 780 : 13329021952.0
Loss at iteration 790 : 16814025728.0
Loss at iteration 800 : 87022592000.0
Loss at iteration 810 : 32235845632.0
Loss at iteration 820 : 7482069504.0
Loss at iteration 830 : 38601744384.0
Loss at iteration 840 : 12012796928.0
Loss at iteration 850 : 1398149632.0
Loss at iteration 860 : 167369441280.0
Loss at iteration 870 : 5685694976.0
Loss at iteration 880 : 132815806464.0
Loss at iteration 890 : 7275554816.0
Loss at iteration 900 : 28982069248.0
Loss at iteration 910 : 33730533376.0
Loss at iteration 920 : 35176800256.0
Loss at iteration 930 : 10906449920.0
Loss at iteration 940 : 66637176832.0
Loss at iteration 950 : 19679164416.0
Loss at iteration 960 : 25562601472.0
Loss at iteration 970 : 7655201792.0
Loss at iteration 980 : 6525322240.0
Loss at iteration 990 : 85361090560.0
Loss at iteration 1000 : 7889440256.0
Loss at iteration 1010 : 4231799552.0
Loss at iteration 1020 : 59497807872.0
Loss at iteration 1030 : 24408858624.0
Loss at iteration 1040 : 40651845632.0
Loss at iteration 1050 : 6735863808.0
Loss at iteration 1060 : 15067237376.0
Loss at iteration 1070 : 67928416256.0
Loss at iteration 1080 : 7424086016.0
Loss at iteration 1090 : 1192890240.0
Loss at iteration 1100 : 12223107072.0
Loss at iteration 1110 : 3030408192.0
Loss at iteration 1120 : 296188706816.0
Loss at iteration 1130 : 1942000384.0
Loss at iteration 1140 : 2150779136.0
Loss at iteration 1150 : 1010968448.0
Loss at iteration 1160 : 354683912192.0
Loss at iteration 1170 : 945407262720.0
Loss at iteration 1180 : 3775603968.0
Loss at iteration 1190 : 481359008.0
Loss at iteration 1200 : 2328254464.0
Loss at iteration 1210 : 325078253568.0
Loss at iteration 1220 : 17793787904.0
Loss at iteration 1230 : 11532257280.0
Loss at iteration 1240 : 2041711232.0
Loss at iteration 1250 : 2556515328.0
Loss at iteration 1260 : 172873957376.0
Loss at iteration 1270 : 1145702784.0
Loss at iteration 1280 : 18711648256.0
Loss at iteration 1290 : 468612055040.0
Loss at iteration 1300 : 9178023936.0
Loss at iteration 1310 : 89318596608.0
Loss at iteration 1320 : 10162549760.0
Loss at iteration 1330 : 549369600.0
Loss at iteration 1340 : 12008841216.0
Loss at iteration 1350 : 408949391360.0
Loss at iteration 1360 : 6726146048.0
Loss at iteration 1370 : 20562505728.0
Loss at iteration 1380 : 13549773824.0
Loss at iteration 1390 : 6448621056.0
Loss at iteration 1400 : 13032530944.0
Loss at iteration 1410 : 1115957504.0
Loss at iteration 1420 : 800267456.0
Loss at iteration 1430 : 252874129408.0
Loss at iteration 1440 : 2840972800.0
Loss at iteration 1450 : 19867129856.0
Loss at iteration 1460 : 4834383872.0
Loss at iteration 1470 : 6003465216.0
Loss at iteration 1480 : 3789032704.0
Loss at iteration 1490 : 176120414208.0
Loss at iteration 1500 : 38670069760.0
Loss at iteration 1510 : 30918588416.0
Loss at iteration 1520 : 2743901696.0
Loss at iteration 1530 : 17782429696.0
Loss at iteration 1540 : 2432049408.0
Loss at iteration 1550 : 2390994944.0
Loss at iteration 1560 : 26298677248.0
Loss at iteration 1570 : 40823554048.0
Loss at iteration 1580 : 251946762240.0
Loss at iteration 1590 : 603721728.0
Loss at iteration 1600 : 183034527744.0
Loss at iteration 1610 : 10225078272.0
Loss at iteration 1620 : 84292026368.0
Loss at iteration 1630 : 16400621568.0
Loss at iteration 1640 : 23765387264.0
Loss at iteration 1650 : 120329035776.0
Loss at iteration 1660 : 23248558080.0
Loss at iteration 1670 : 74358358016.0
Loss at iteration 1680 : 200738947072.0
Loss at iteration 1690 : 20680790016.0
Loss at iteration 1700 : 69432238080.0
Loss at iteration 1710 : 80706912256.0
Loss at iteration 1720 : 58631143424.0
Loss at iteration 1730 : 513999929344.0
Loss at iteration 1740 : 1025023606784.0
Loss at iteration 1750 : 717855195136.0
Loss at iteration 1760 : 2092870270976.0
Loss at iteration 1770 : 653349486592.0
Loss at iteration 1780 : 134846652416.0
Loss at iteration 1790 : 459554684928.0
Loss at iteration 1800 : 15992351744.0
Loss at iteration 1810 : 1150262312960.0
Loss at iteration 1820 : 45173744599040.0
Loss at iteration 1830 : 106586226688.0
Loss at iteration 1840 : 1068236406784.0
Loss at iteration 1850 : 39254863872.0
Loss at iteration 1860 : 14886429696.0
Loss at iteration 1870 : 457113141248.0
Loss at iteration 1880 : 18960924672.0
Loss at iteration 1890 : 7826961334272.0
Loss at iteration 1900 : 16926852096.0
Loss at iteration 1910 : 2984395407360.0
Loss at iteration 1920 : 2259121078272.0
Loss at iteration 1930 : 213789769728.0
Loss at iteration 1940 : 1881047171072.0
Loss at iteration 1950 : 7277813170176.0
Loss at iteration 1960 : 1553034510336.0
Loss at iteration 1970 : 775946633216.0
Loss at iteration 1980 : 212384874496.0
Loss at iteration 1990 : 365373849600.0
Loss at iteration 2000 : 135275184128.0
Loss at iteration 2010 : 76297183232.0
Loss at iteration 2020 : 181686255616.0
Loss at iteration 2030 : 127110709248.0
Loss at iteration 2040 : 117026766848.0
Loss at iteration 2050 : 31872835584.0
Loss at iteration 2060 : 235868979200.0
Loss at iteration 2070 : 547470245888.0
Loss at iteration 2080 : 108558106624.0
Loss at iteration 2090 : 69929992192.0
Loss at iteration 2100 : 81317142528.0
Loss at iteration 2110 : 475066793984.0
Loss at iteration 2120 : 59934302208.0
Loss at iteration 2130 : 67486838784.0
Loss at iteration 2140 : 147488047104.0
Loss at iteration 2150 : 1791117885440.0
Loss at iteration 2160 : 1261523959808.0
Loss at iteration 2170 : 94290558976.0
Loss at iteration 2180 : 61475741696.0
Loss at iteration 2190 : 42886791168.0
Loss at iteration 2200 : 5444306944.0
Loss at iteration 2210 : 26363451392.0
Loss at iteration 2220 : 69030535168.0
Loss at iteration 2230 : 4578983936.0
Loss at iteration 2240 : 75766415360.0
Loss at iteration 2250 : 39666544640.0
Loss at iteration 2260 : 21787174912.0
Loss at iteration 2270 : 171134664704.0
Loss at iteration 2280 : 861695872.0
Loss at iteration 2290 : 250383745024.0
Loss at iteration 2300 : 3217771008.0
Loss at iteration 2310 : 15294511104.0
Loss at iteration 2320 : 11415328768.0
Loss at iteration 2330 : 19426332672.0
Loss at iteration 2340 : 36946587648.0
Loss at iteration 2350 : 51383803904.0
Loss at iteration 2360 : 7441148416.0
Loss at iteration 2370 : 149687664640.0
Loss at iteration 2380 : 8698533888.0
Loss at iteration 2390 : 9180161024.0
Loss at iteration 2400 : 5064732160.0
Loss at iteration 2410 : 63508987904.0
Loss at iteration 2420 : 79321366528.0
The SSIM Value is: 1.0649077485898792e-06
The PSNR Value is: -113.54602762858073
the epoch is: 137
Loss at iteration 10 : 13639973888.0
Loss at iteration 20 : 32990738432.0
Loss at iteration 30 : 6333338112.0
Loss at iteration 40 : 185770213376.0
Loss at iteration 50 : 21281716224.0
Loss at iteration 60 : 434227052544.0
Loss at iteration 70 : 3405087488.0
Loss at iteration 80 : 15720453120.0
Loss at iteration 90 : 39636099072.0
Loss at iteration 100 : 9930308608.0
Loss at iteration 110 : 67984523264.0
Loss at iteration 120 : 18014908416.0
Loss at iteration 130 : 36795949056.0
Loss at iteration 140 : 12683404288.0
Loss at iteration 150 : 18411857920.0
Loss at iteration 160 : 14284674048.0
Loss at iteration 170 : 6603503104.0
Loss at iteration 180 : 45552193536.0
Loss at iteration 190 : 13408100352.0
Loss at iteration 200 : 2256735744.0
Loss at iteration 210 : 7676714496.0
Loss at iteration 220 : 4960063488.0
Loss at iteration 230 : 91645853696.0
Loss at iteration 240 : 59243368448.0
Loss at iteration 250 : 9454075904.0
Loss at iteration 260 : 33842518016.0
Loss at iteration 270 : 67310489600.0
Loss at iteration 280 : 29616027648.0
Loss at iteration 290 : 900094592.0
Loss at iteration 300 : 42747113472.0
Loss at iteration 310 : 248153014272.0
Loss at iteration 320 : 25897345024.0
Loss at iteration 330 : 9290898432.0
Loss at iteration 340 : 14092871680.0
Loss at iteration 350 : 52570030080.0
Loss at iteration 360 : 18184935424.0
Loss at iteration 370 : 5376867328.0
Loss at iteration 380 : 6335394816.0
Loss at iteration 390 : 22413611008.0
Loss at iteration 400 : 11092267008.0
Loss at iteration 410 : 11473259520.0
Loss at iteration 420 : 177566154752.0
Loss at iteration 430 : 3447529216.0
Loss at iteration 440 : 40624840704.0
Loss at iteration 450 : 39366266880.0
Loss at iteration 460 : 4611120640.0
Loss at iteration 470 : 115261325312.0
Loss at iteration 480 : 13929138176.0
Loss at iteration 490 : 15826494464.0
Loss at iteration 500 : 98709422080.0
Loss at iteration 510 : 215371612160.0
Loss at iteration 520 : 5938344448.0
Loss at iteration 530 : 946939520.0
Loss at iteration 540 : 1109556992.0
Loss at iteration 550 : 35981967360.0
Loss at iteration 560 : 24020482048.0
Loss at iteration 570 : 1420716288.0
Loss at iteration 580 : 33391976448.0
Loss at iteration 590 : 16754479104.0
Loss at iteration 600 : 74882424832.0
Loss at iteration 610 : 24767901696.0
Loss at iteration 620 : 11789789184.0
Loss at iteration 630 : 23154685952.0
Loss at iteration 640 : 4763254272.0
Loss at iteration 650 : 2139798912.0
Loss at iteration 660 : 11758679040.0
Loss at iteration 670 : 44481486848.0
Loss at iteration 680 : 12712547328.0
Loss at iteration 690 : 65170128896.0
Loss at iteration 700 : 25219782656.0
Loss at iteration 710 : 23938402304.0
Loss at iteration 720 : 43811864576.0
Loss at iteration 730 : 16141207552.0
Loss at iteration 740 : 20302440448.0
Loss at iteration 750 : 53057998848.0
Loss at iteration 760 : 15230274560.0
Loss at iteration 770 : 6988503040.0
Loss at iteration 780 : 38559531008.0
Loss at iteration 790 : 14824143872.0
Loss at iteration 800 : 35525480448.0
Loss at iteration 810 : 34700484608.0
Loss at iteration 820 : 284296806400.0
Loss at iteration 830 : 45792772096.0
Loss at iteration 840 : 14353026048.0
Loss at iteration 850 : 6903717376.0
Loss at iteration 860 : 14209184768.0
Loss at iteration 870 : 9569153024.0
Loss at iteration 880 : 8469727232.0
Loss at iteration 890 : 27136614400.0
Loss at iteration 900 : 15003054080.0
Loss at iteration 910 : 27253108736.0
Loss at iteration 920 : 83752837120.0
Loss at iteration 930 : 3145112064.0
Loss at iteration 940 : 115992657920.0
Loss at iteration 950 : 17313093632.0
Loss at iteration 960 : 6331322880.0
Loss at iteration 970 : 49352499200.0
Loss at iteration 980 : 25488582656.0
Loss at iteration 990 : 5050623488.0
Loss at iteration 1000 : 66183344128.0
Loss at iteration 1010 : 12986958848.0
Loss at iteration 1020 : 9763090432.0
Loss at iteration 1030 : 1154354304.0
Loss at iteration 1040 : 16449290240.0
Loss at iteration 1050 : 2948624640.0
Loss at iteration 1060 : 3569176832.0
Loss at iteration 1070 : 597393920.0
Loss at iteration 1080 : 5602378752.0
Loss at iteration 1090 : 6286432256.0
Loss at iteration 1100 : 4028718080.0
Loss at iteration 1110 : 7434354176.0
Loss at iteration 1120 : 90098434048.0
Loss at iteration 1130 : 3014544640.0
Loss at iteration 1140 : 13325257728.0
Loss at iteration 1150 : 9463454720.0
Loss at iteration 1160 : 6736374272.0
Loss at iteration 1170 : 3118707200.0
Loss at iteration 1180 : 15251267584.0
Loss at iteration 1190 : 2576471040.0
Loss at iteration 1200 : 71347961856.0
Loss at iteration 1210 : 1137657984.0
Loss at iteration 1220 : 13877603328.0
Loss at iteration 1230 : 142028554240.0
Loss at iteration 1240 : 2444944896.0
Loss at iteration 1250 : 14831726592.0
Loss at iteration 1260 : 2228920576.0
Loss at iteration 1270 : 839883392.0
Loss at iteration 1280 : 74173825024.0
Loss at iteration 1290 : 4151409920.0
Loss at iteration 1300 : 20364015616.0
Loss at iteration 1310 : 17442263040.0
Loss at iteration 1320 : 5868364800.0
Loss at iteration 1330 : 4995258880.0
Loss at iteration 1340 : 12893001728.0
Loss at iteration 1350 : 4009409792.0
Loss at iteration 1360 : 693791040.0
Loss at iteration 1370 : 226439643136.0
Loss at iteration 1380 : 9488471040.0
Loss at iteration 1390 : 12894937088.0
Loss at iteration 1400 : 1050856832.0
Loss at iteration 1410 : 3446596096.0
Loss at iteration 1420 : 14799513600.0
Loss at iteration 1430 : 2209100800.0
Loss at iteration 1440 : 4744524800.0
Loss at iteration 1450 : 2638896896.0
Loss at iteration 1460 : 6151697920.0
Loss at iteration 1470 : 3100045056.0
Loss at iteration 1480 : 1474717824.0
Loss at iteration 1490 : 6112626688.0
Loss at iteration 1500 : 44212649984.0
Loss at iteration 1510 : 3446005504.0
Loss at iteration 1520 : 4696266752.0
Loss at iteration 1530 : 16580333568.0
Loss at iteration 1540 : 11280984064.0
Loss at iteration 1550 : 4973211648.0
Loss at iteration 1560 : 14500967424.0
Loss at iteration 1570 : 4938043392.0
Loss at iteration 1580 : 23065853952.0
Loss at iteration 1590 : 11243830272.0
Loss at iteration 1600 : 2490232320.0
Loss at iteration 1610 : 34454953984.0
Loss at iteration 1620 : 17302822912.0
Loss at iteration 1630 : 15488206848.0
Loss at iteration 1640 : 12875544576.0
Loss at iteration 1650 : 25596962816.0
Loss at iteration 1660 : 49890484224.0
Loss at iteration 1670 : 56318636032.0
Loss at iteration 1680 : 13741795328.0
Loss at iteration 1690 : 1075896448.0
Loss at iteration 1700 : 1179490688.0
Loss at iteration 1710 : 6958750720.0
Loss at iteration 1720 : 20013053952.0
Loss at iteration 1730 : 16027942912.0
Loss at iteration 1740 : 157801447424.0
Loss at iteration 1750 : 3903034880.0
Loss at iteration 1760 : 3974986240.0
Loss at iteration 1770 : 41495097344.0
Loss at iteration 1780 : 1114647680.0
Loss at iteration 1790 : 23748894720.0
Loss at iteration 1800 : 1219991808.0
Loss at iteration 1810 : 132659011584.0
Loss at iteration 1820 : 44513632256.0
Loss at iteration 1830 : 920299438080.0
Loss at iteration 1840 : 1862147244032.0
Loss at iteration 1850 : 2862095070658560.0
Loss at iteration 1860 : 437487435776.0
Loss at iteration 1870 : 2561474560000.0
Loss at iteration 1880 : 7711194873856.0
Loss at iteration 1890 : 384933429248.0
Loss at iteration 1900 : 3170653700096.0
Loss at iteration 1910 : 518029705216.0
Loss at iteration 1920 : 5158750126080.0
Loss at iteration 1930 : 1219122823168.0
Loss at iteration 1940 : 856493391872.0
Loss at iteration 1950 : 6832566272.0
Loss at iteration 1960 : 150139420672.0
Loss at iteration 1970 : 185312346112.0
Loss at iteration 1980 : 1052425584640.0
Loss at iteration 1990 : 273457020928.0
Loss at iteration 2000 : 617657008128.0
Loss at iteration 2010 : 908232949760.0
Loss at iteration 2020 : 369041506304.0
Loss at iteration 2030 : 3240866873344.0
Loss at iteration 2040 : 153507971072.0
Loss at iteration 2050 : 222189617152.0
Loss at iteration 2060 : 3392251363328.0
Loss at iteration 2070 : 86095691776.0
Loss at iteration 2080 : 299916492800.0
Loss at iteration 2090 : 172236488704.0
Loss at iteration 2100 : 422761463808.0
Loss at iteration 2110 : 6196085915648.0
Loss at iteration 2120 : 1585338384384.0
Loss at iteration 2130 : 543332696064.0
Loss at iteration 2140 : 26182535168.0
Loss at iteration 2150 : 314110377984.0
Loss at iteration 2160 : 4092267331584.0
Loss at iteration 2170 : 21480127594496.0
Loss at iteration 2180 : 4301556023296.0
Loss at iteration 2190 : 297357443072.0
Loss at iteration 2200 : 149413822464.0
Loss at iteration 2210 : 2013338664960.0
Loss at iteration 2220 : 140994822144.0
Loss at iteration 2230 : 193900363776.0
Loss at iteration 2240 : 198973636608.0
Loss at iteration 2250 : 9900866560.0
Loss at iteration 2260 : 1343955927040.0
Loss at iteration 2270 : 608669335552.0
Loss at iteration 2280 : 44711540686848.0
Loss at iteration 2290 : 2733815365632.0
Loss at iteration 2300 : 1185240580096.0
Loss at iteration 2310 : 2462207180800.0
Loss at iteration 2320 : 6245162942464.0
Loss at iteration 2330 : 247282597888.0
Loss at iteration 2340 : 239337095168.0
Loss at iteration 2350 : 160857899008.0
Loss at iteration 2360 : 261124554752.0
Loss at iteration 2370 : 646246432768.0
Loss at iteration 2380 : 710167429120.0
Loss at iteration 2390 : 573074374656.0
Loss at iteration 2400 : 79636635648.0
Loss at iteration 2410 : 227901571072.0
Loss at iteration 2420 : 1012651720704.0
The SSIM Value is: -1.121262412269175e-05
The PSNR Value is: -125.84740142822265
the epoch is: 138
Loss at iteration 10 : 236563398656.0
Loss at iteration 20 : 268240633856.0
Loss at iteration 30 : 120811331584.0
Loss at iteration 40 : 527281979392.0
Loss at iteration 50 : 224908034048.0
Loss at iteration 60 : 349107191808.0
Loss at iteration 70 : 28926099456.0
Loss at iteration 80 : 152432148480.0
Loss at iteration 90 : 38714863616.0
Loss at iteration 100 : 46264848384.0
Loss at iteration 110 : 1382508134400.0
Loss at iteration 120 : 2808580669440.0
Loss at iteration 130 : 610058567680.0
Loss at iteration 140 : 965587501056.0
Loss at iteration 150 : 2540342607872.0
Loss at iteration 160 : 693375270912.0
Loss at iteration 170 : 92072722432.0
Loss at iteration 180 : 4188046360576.0
Loss at iteration 190 : 12676402176.0
Loss at iteration 200 : 91809275904.0
Loss at iteration 210 : 40831873024.0
Loss at iteration 220 : 210217631744.0
Loss at iteration 230 : 185376473088.0
Loss at iteration 240 : 73744785408.0
Loss at iteration 250 : 711630585856.0
Loss at iteration 260 : 34117775360.0
Loss at iteration 270 : 48366383104.0
Loss at iteration 280 : 168779841536.0
Loss at iteration 290 : 267779948544.0
Loss at iteration 300 : 25200519168.0
Loss at iteration 310 : 21357156352.0
Loss at iteration 320 : 376890949632.0
Loss at iteration 330 : 373098184704.0
Loss at iteration 340 : 40204210176.0
Loss at iteration 350 : 541705175040.0
Loss at iteration 360 : 291693887488.0
Loss at iteration 370 : 170122657792.0
Loss at iteration 380 : 67059052544.0
Loss at iteration 390 : 28195241984.0
Loss at iteration 400 : 60687769600.0
Loss at iteration 410 : 183010312192.0
Loss at iteration 420 : 1558849519616.0
Loss at iteration 430 : 158553800704.0
Loss at iteration 440 : 1608902115328.0
Loss at iteration 450 : 965536448512.0
Loss at iteration 460 : 3024873324544.0
Loss at iteration 470 : 23704934400.0
Loss at iteration 480 : 323728703488.0
Loss at iteration 490 : 124821831680.0
Loss at iteration 500 : 6154119680.0
Loss at iteration 510 : 15140067328.0
Loss at iteration 520 : 241681743872.0
Loss at iteration 530 : 88744435712.0
Loss at iteration 540 : 899035496448.0
Loss at iteration 550 : 73043312640.0
Loss at iteration 560 : 84343578624.0
Loss at iteration 570 : 33001668608.0
Loss at iteration 580 : 122157842432.0
Loss at iteration 590 : 225004994560.0
Loss at iteration 600 : 20954046464.0
Loss at iteration 610 : 2033026688.0
Loss at iteration 620 : 3565847838720.0
Loss at iteration 630 : 934548096.0
Loss at iteration 640 : 5226685440.0
Loss at iteration 650 : 9107118080.0
Loss at iteration 660 : 4228252928.0
Loss at iteration 670 : 526713913344.0
Loss at iteration 680 : 4189656320.0
Loss at iteration 690 : 8950433792.0
Loss at iteration 700 : 463334080512.0
Loss at iteration 710 : 27934900224.0
Loss at iteration 720 : 38266945536.0
Loss at iteration 730 : 25169178624.0
Loss at iteration 740 : 480428457984.0
Loss at iteration 750 : 89744236544.0
Loss at iteration 760 : 7758864896.0
Loss at iteration 770 : 4460547072.0
Loss at iteration 780 : 25877727232.0
Loss at iteration 790 : 386245001216.0
Loss at iteration 800 : 6681290240.0
Loss at iteration 810 : 77563109376.0
Loss at iteration 820 : 28017641472.0
Loss at iteration 830 : 66732331008.0
Loss at iteration 840 : 201213280256.0
Loss at iteration 850 : 13707702272.0
Loss at iteration 860 : 9966471168.0
Loss at iteration 870 : 129233018880.0
Loss at iteration 880 : 17833873408.0
Loss at iteration 890 : 44444385280.0
Loss at iteration 900 : 12201801728.0
Loss at iteration 910 : 24502179840.0
Loss at iteration 920 : 90389741568.0
Loss at iteration 930 : 32033021952.0
Loss at iteration 940 : 23636559872.0
Loss at iteration 950 : 9308526592.0
Loss at iteration 960 : 66096783360.0
Loss at iteration 970 : 25897312256.0
Loss at iteration 980 : 48096243712.0
Loss at iteration 990 : 111829917696.0
Loss at iteration 1000 : 1468544712704.0
Loss at iteration 1010 : 36141642285056.0
Loss at iteration 1020 : 30576422912.0
Loss at iteration 1030 : 301293666304.0
Loss at iteration 1040 : 43584409600.0
Loss at iteration 1050 : 30274246656.0
Loss at iteration 1060 : 251283243008.0
Loss at iteration 1070 : 35467038720.0
Loss at iteration 1080 : 230762807296.0
Loss at iteration 1090 : 7259339264.0
Loss at iteration 1100 : 115250192384.0
Loss at iteration 1110 : 444690202624.0
Loss at iteration 1120 : 11870469120.0
Loss at iteration 1130 : 7516405248.0
Loss at iteration 1140 : 6245778432.0
Loss at iteration 1150 : 21639628800.0
Loss at iteration 1160 : 62066839552.0
Loss at iteration 1170 : 78439448576.0
Loss at iteration 1180 : 15269410816.0
Loss at iteration 1190 : 180679573504.0
Loss at iteration 1200 : 47771992064.0
Loss at iteration 1210 : 1661139328.0
Loss at iteration 1220 : 1582517190656.0
Loss at iteration 1230 : 47304425472.0
Loss at iteration 1240 : 19501457408.0
Loss at iteration 1250 : 2585357189120.0
Loss at iteration 1260 : 3797490688.0
Loss at iteration 1270 : 18983194624.0
Loss at iteration 1280 : 52752445440.0
Loss at iteration 1290 : 190196432896.0
Loss at iteration 1300 : 9367575552.0
Loss at iteration 1310 : 41186598912.0
Loss at iteration 1320 : 1249761152.0
Loss at iteration 1330 : 55055990784.0
Loss at iteration 1340 : 36733739008.0
Loss at iteration 1350 : 8076005376.0
Loss at iteration 1360 : 4984653824.0
Loss at iteration 1370 : 2190212864.0
Loss at iteration 1380 : 9634637824.0
Loss at iteration 1390 : 9273907200.0
Loss at iteration 1400 : 71807361024.0
Loss at iteration 1410 : 40654581760.0
Loss at iteration 1420 : 2529499392.0
Loss at iteration 1430 : 4735510528.0
Loss at iteration 1440 : 82480717824.0
Loss at iteration 1450 : 1655379456.0
Loss at iteration 1460 : 61387964416.0
Loss at iteration 1470 : 2117419904.0
Loss at iteration 1480 : 66476851200.0
Loss at iteration 1490 : 111322893123584.0
Loss at iteration 1500 : 48476389376.0
Loss at iteration 1510 : 13303245824.0
Loss at iteration 1520 : 39214125056.0
Loss at iteration 1530 : 21563480064.0
Loss at iteration 1540 : 283799060480.0
Loss at iteration 1550 : 28168814592.0
Loss at iteration 1560 : 2916612308992.0
Loss at iteration 1570 : 72232591360.0
Loss at iteration 1580 : 15422804983808.0
Loss at iteration 1590 : 47720038400.0
Loss at iteration 1600 : 1625654689792.0
Loss at iteration 1610 : 1247932710912.0
Loss at iteration 1620 : 469291565056.0
Loss at iteration 1630 : 349887365120.0
Loss at iteration 1640 : 539664973824.0
Loss at iteration 1650 : 138143662080.0
Loss at iteration 1660 : 185574539264.0
Loss at iteration 1670 : 180431241216.0
Loss at iteration 1680 : 8766543872.0
Loss at iteration 1690 : 678122946560.0
Loss at iteration 1700 : 80027648000.0
Loss at iteration 1710 : 308977991680.0
Loss at iteration 1720 : 41595424768.0
Loss at iteration 1730 : 125122314240.0
Loss at iteration 1740 : 11681242112.0
Loss at iteration 1750 : 124668174336.0
Loss at iteration 1760 : 115859283968.0
Loss at iteration 1770 : 12962308096.0
Loss at iteration 1780 : 106257850368.0
Loss at iteration 1790 : 201535291392.0
Loss at iteration 1800 : 150671081472.0
Loss at iteration 1810 : 3866470400.0
Loss at iteration 1820 : 17842960384.0
Loss at iteration 1830 : 41356591104.0
Loss at iteration 1840 : 8411810304.0
Loss at iteration 1850 : 458708353024.0
Loss at iteration 1860 : 29522823168.0
Loss at iteration 1870 : 924143452160.0
Loss at iteration 1880 : 23281203200.0
Loss at iteration 1890 : 69432016896.0
Loss at iteration 1900 : 786972800.0
Loss at iteration 1910 : 12001499136.0
Loss at iteration 1920 : 6107749376.0
Loss at iteration 1930 : 13111576576.0
Loss at iteration 1940 : 2914505472.0
Loss at iteration 1950 : 35918376960.0
Loss at iteration 1960 : 132559872000.0
Loss at iteration 1970 : 25537140736.0
Loss at iteration 1980 : 74302963712.0
Loss at iteration 1990 : 6022396928.0
Loss at iteration 2000 : 3620307712.0
Loss at iteration 2010 : 8789053440.0
Loss at iteration 2020 : 5928156160.0
Loss at iteration 2030 : 10440298496.0
Loss at iteration 2040 : 21358358528.0
Loss at iteration 2050 : 6003558400.0
Loss at iteration 2060 : 18177826816.0
Loss at iteration 2070 : 153097388032.0
Loss at iteration 2080 : 6998827520.0
Loss at iteration 2090 : 36349890560.0
Loss at iteration 2100 : 696843456.0
Loss at iteration 2110 : 2562557440.0
Loss at iteration 2120 : 2062835968.0
Loss at iteration 2130 : 21159215104.0
Loss at iteration 2140 : 587469488128.0
Loss at iteration 2150 : 263858028544.0
Loss at iteration 2160 : 3447046144.0
Loss at iteration 2170 : 28043108352.0
Loss at iteration 2180 : 14316064768.0
Loss at iteration 2190 : 290452352.0
Loss at iteration 2200 : 15965894656.0
Loss at iteration 2210 : 4829863936.0
Loss at iteration 2220 : 1776265600.0
Loss at iteration 2230 : 831701504.0
Loss at iteration 2240 : 3665888512.0
Loss at iteration 2250 : 8276659712.0
Loss at iteration 2260 : 2102759808.0
Loss at iteration 2270 : 688049216.0
Loss at iteration 2280 : 941062016.0
Loss at iteration 2290 : 265417392128.0
Loss at iteration 2300 : 68571033600.0
Loss at iteration 2310 : 356427232.0
Loss at iteration 2320 : 22569160704.0
Loss at iteration 2330 : 168980800.0
Loss at iteration 2340 : 9728116736.0
Loss at iteration 2350 : 3820560384.0
Loss at iteration 2360 : 1091738624.0
Loss at iteration 2370 : 4280146944.0
Loss at iteration 2380 : 28751351808.0
Loss at iteration 2390 : 12630969344.0
Loss at iteration 2400 : 32239097856.0
Loss at iteration 2410 : 40243838976.0
Loss at iteration 2420 : 223535600.0
The SSIM Value is: -4.361514167309603e-06
The PSNR Value is: -101.77967071533203
the epoch is: 139
Loss at iteration 10 : 3669237248.0
Loss at iteration 20 : 13736211456.0
Loss at iteration 30 : 6958390784.0
Loss at iteration 40 : 69189550080.0
Loss at iteration 50 : 53142183936.0
Loss at iteration 60 : 4165088000.0
Loss at iteration 70 : 10419124224.0
Loss at iteration 80 : 7453129.0
Loss at iteration 90 : 5314508288.0
Loss at iteration 100 : 10310565888.0
Loss at iteration 110 : 143920971776.0
Loss at iteration 120 : 27229478912.0
Loss at iteration 130 : 9029677056.0
Loss at iteration 140 : 4128489216.0
Loss at iteration 150 : 808645440.0
Loss at iteration 160 : 717540992.0
Loss at iteration 170 : 42126229504.0
Loss at iteration 180 : 1095092736.0
Loss at iteration 190 : 131507816.0
Loss at iteration 200 : 2246028544.0
Loss at iteration 210 : 123811376.0
Loss at iteration 220 : 7103222272.0
Loss at iteration 230 : 75741528064.0
Loss at iteration 240 : 711113984.0
Loss at iteration 250 : 23555008512.0
Loss at iteration 260 : 433407520.0
Loss at iteration 270 : 1068029248.0
Loss at iteration 280 : 1565688320.0
Loss at iteration 290 : 233286467584.0
Loss at iteration 300 : 741548480.0
Loss at iteration 310 : 3133093632.0
Loss at iteration 320 : 189851840.0
Loss at iteration 330 : 54778429440.0
Loss at iteration 340 : 261556944.0
Loss at iteration 350 : 579046336.0
Loss at iteration 360 : 14906966016.0
Loss at iteration 370 : 4389772288.0
Loss at iteration 380 : 108076859392.0
Loss at iteration 390 : 163522928.0
Loss at iteration 400 : 379884077056.0
Loss at iteration 410 : 14265403392.0
Loss at iteration 420 : 6417766400.0
Loss at iteration 430 : 35878957056.0
Loss at iteration 440 : 3060513792.0
Loss at iteration 450 : 3152265216.0
Loss at iteration 460 : 759544128.0
Loss at iteration 470 : 3488149760.0
Loss at iteration 480 : 3220504064.0
Loss at iteration 490 : 2065219840.0
Loss at iteration 500 : 4383388672.0
Loss at iteration 510 : 19488086016.0
Loss at iteration 520 : 117310939136.0
Loss at iteration 530 : 42143375360.0
Loss at iteration 540 : 26124818432.0
Loss at iteration 550 : 8733452288.0
Loss at iteration 560 : 7470026752.0
Loss at iteration 570 : 4366791168.0
Loss at iteration 580 : 6560079360.0
Loss at iteration 590 : 9020912640.0
Loss at iteration 600 : 35305287680.0
Loss at iteration 610 : 5677924864.0
Loss at iteration 620 : 8890941440.0
Loss at iteration 630 : 70368329728.0
Loss at iteration 640 : 75159035904.0
Loss at iteration 650 : 8245025792.0
Loss at iteration 660 : 149464039424.0
Loss at iteration 670 : 3455570688.0
Loss at iteration 680 : 8799116288.0
Loss at iteration 690 : 76723036160.0
Loss at iteration 700 : 18809817088.0
Loss at iteration 710 : 3330874880.0
Loss at iteration 720 : 56684703744.0
Loss at iteration 730 : 11145005056.0
Loss at iteration 740 : 7885478400.0
Loss at iteration 750 : 144205332480.0
Loss at iteration 760 : 27201759232.0
Loss at iteration 770 : 834013757440.0
Loss at iteration 780 : 1070443584.0
Loss at iteration 790 : 5007730688.0
Loss at iteration 800 : 13402057728.0
Loss at iteration 810 : 14956366848.0
Loss at iteration 820 : 16285869056.0
Loss at iteration 830 : 2508392192.0
Loss at iteration 840 : 28221972480.0
Loss at iteration 850 : 5143258988544.0
Loss at iteration 860 : 1779207110656.0
Loss at iteration 870 : 43797840920576.0
Loss at iteration 880 : 13594036011008.0
Loss at iteration 890 : 620951109632.0
Loss at iteration 900 : 1665872560128.0
Loss at iteration 910 : 25730734080.0
Loss at iteration 920 : 324860575744.0
Loss at iteration 930 : 320164134912.0
Loss at iteration 940 : 167885537280.0
Loss at iteration 950 : 1904196190208.0
Loss at iteration 960 : 409708593152.0
Loss at iteration 970 : 46534934528.0
Loss at iteration 980 : 112517825167360.0
Loss at iteration 990 : 12710331809792.0
Loss at iteration 1000 : 159571329024.0
Loss at iteration 1010 : 55431258112.0
Loss at iteration 1020 : 1003118985216.0
Loss at iteration 1030 : 286707187712.0
Loss at iteration 1040 : 31238019072.0
Loss at iteration 1050 : 21641396224.0
Loss at iteration 1060 : 77080158208.0
Loss at iteration 1070 : 41574465536.0
Loss at iteration 1080 : 6754292224.0
Loss at iteration 1090 : 189916332032.0
Loss at iteration 1100 : 144089874432.0
Loss at iteration 1110 : 143489024000.0
Loss at iteration 1120 : 43046416384.0
Loss at iteration 1130 : 176153313280.0
Loss at iteration 1140 : 148450459648.0
Loss at iteration 1150 : 13653113856.0
Loss at iteration 1160 : 915867303936.0
Loss at iteration 1170 : 1360231399424.0
Loss at iteration 1180 : 153855213568.0
Loss at iteration 1190 : 69132009472.0
Loss at iteration 1200 : 139675598848.0
Loss at iteration 1210 : 40703373312.0
Loss at iteration 1220 : 12956136448.0
Loss at iteration 1230 : 201331736576.0
Loss at iteration 1240 : 71287406592.0
Loss at iteration 1250 : 160366346240.0
Loss at iteration 1260 : 154008666112.0
Loss at iteration 1270 : 86504505344.0
Loss at iteration 1280 : 437337227264.0
Loss at iteration 1290 : 18426415104.0
Loss at iteration 1300 : 181164294144.0
Loss at iteration 1310 : 2261408808960.0
Loss at iteration 1320 : 1738965778432.0
Loss at iteration 1330 : 119257497600.0
Loss at iteration 1340 : 229160534016.0
Loss at iteration 1350 : 1170098356224.0
Loss at iteration 1360 : 49050714112.0
Loss at iteration 1370 : 640030998528.0
Loss at iteration 1380 : 110131224576.0
Loss at iteration 1390 : 791465492480.0
Loss at iteration 1400 : 41585815552.0
Loss at iteration 1410 : 163991076864.0
Loss at iteration 1420 : 255196594176.0
Loss at iteration 1430 : 430128168960.0
Loss at iteration 1440 : 293246664704.0
Loss at iteration 1450 : 74622001152.0
Loss at iteration 1460 : 38911184896.0
Loss at iteration 1470 : 196739514368.0
Loss at iteration 1480 : 480177553408.0
Loss at iteration 1490 : 254709186560.0
Loss at iteration 1500 : 35651690496.0
Loss at iteration 1510 : 92340846592.0
Loss at iteration 1520 : 5356804096.0
Loss at iteration 1530 : 220073000960.0
Loss at iteration 1540 : 77518651392.0
Loss at iteration 1550 : 1050693009408.0
Loss at iteration 1560 : 622575943680.0
Loss at iteration 1570 : 529828610048.0
Loss at iteration 1580 : 676546215936.0
Loss at iteration 1590 : 3030892675072.0
Loss at iteration 1600 : 9028389306368.0
Loss at iteration 1610 : 4813686833152.0
Loss at iteration 1620 : 4351755288576.0
Loss at iteration 1630 : 720587325440.0
Loss at iteration 1640 : 760440422400.0
Loss at iteration 1650 : 908923895808.0
Loss at iteration 1660 : 1750602743808.0
Loss at iteration 1670 : 764453584896.0
Loss at iteration 1680 : 6332326871040.0
Loss at iteration 1690 : 4302720729088.0
Loss at iteration 1700 : 319310987264.0
Loss at iteration 1710 : 538832633856.0
Loss at iteration 1720 : 94222458880.0
Loss at iteration 1730 : 121674727424.0
Loss at iteration 1740 : 74558521344.0
Loss at iteration 1750 : 4276247855104.0
Loss at iteration 1760 : 842420715520.0
Loss at iteration 1770 : 4556460654592.0
Loss at iteration 1780 : 2063373959168.0
Loss at iteration 1790 : 591979085824.0
Loss at iteration 1800 : 5441729855488.0
Loss at iteration 1810 : 13142109192192.0
Loss at iteration 1820 : 4208394496.0
Loss at iteration 1830 : 4724441600.0
Loss at iteration 1840 : 51662548992.0
Loss at iteration 1850 : 111182102528.0
Loss at iteration 1860 : 106468040704.0
Loss at iteration 1870 : 25412610048.0
Loss at iteration 1880 : 1198277787648.0
Loss at iteration 1890 : 267294162944.0
Loss at iteration 1900 : 120236474368.0
Loss at iteration 1910 : 757870755840.0
Loss at iteration 1920 : 40532996096.0
Loss at iteration 1930 : 691030786048.0
Loss at iteration 1940 : 631504437248.0
Loss at iteration 1950 : 46068908032.0
Loss at iteration 1960 : 9764275748864.0
Loss at iteration 1970 : 1041122852864.0
Loss at iteration 1980 : 57542250496.0
Loss at iteration 1990 : 727029645312.0
Loss at iteration 2000 : 766874812416.0
Loss at iteration 2010 : 1447138426880.0
Loss at iteration 2020 : 4442087751680.0
Loss at iteration 2030 : 431356837888.0
Loss at iteration 2040 : 45310488576.0
Loss at iteration 2050 : 23013296128.0
Loss at iteration 2060 : 103739629568.0
Loss at iteration 2070 : 553396666368.0
Loss at iteration 2080 : 71473012736.0
Loss at iteration 2090 : 245526593536.0
Loss at iteration 2100 : 11791676416.0
Loss at iteration 2110 : 65475092480.0
Loss at iteration 2120 : 1517861470208.0
Loss at iteration 2130 : 682439147520.0
Loss at iteration 2140 : 2477098008576.0
Loss at iteration 2150 : 51698450432.0
Loss at iteration 2160 : 263759577088.0
Loss at iteration 2170 : 1650039980032.0
Loss at iteration 2180 : 486945521664.0
Loss at iteration 2190 : 255839633408.0
Loss at iteration 2200 : 3567112421376.0
Loss at iteration 2210 : 863760744448.0
Loss at iteration 2220 : 413050306560.0
Loss at iteration 2230 : 2679061348352.0
Loss at iteration 2240 : 7120589160448.0
Loss at iteration 2250 : 1324156321792.0
Loss at iteration 2260 : 53259813257216.0
Loss at iteration 2270 : 44610994176.0
Loss at iteration 2280 : 115717922816.0
Loss at iteration 2290 : 2305688338432.0
Loss at iteration 2300 : 289041252352.0
Loss at iteration 2310 : 96211525632.0
Loss at iteration 2320 : 905966649344.0
Loss at iteration 2330 : 74268745728.0
Loss at iteration 2340 : 86197354496.0
Loss at iteration 2350 : 199453229056.0
Loss at iteration 2360 : 202238115840.0
Loss at iteration 2370 : 60631855104.0
Loss at iteration 2380 : 220959227904.0
Loss at iteration 2390 : 749757661184.0
Loss at iteration 2400 : 1759320342528.0
Loss at iteration 2410 : 62339792896.0
Loss at iteration 2420 : 2846055989248.0
The SSIM Value is: 2.2583122169332152e-07
The PSNR Value is: -125.05350443522136
the epoch is: 140
Loss at iteration 10 : 368664608768.0
Loss at iteration 20 : 551551631360.0
Loss at iteration 30 : 500863991808.0
Loss at iteration 40 : 35659251712.0
Loss at iteration 50 : 50327535616.0
Loss at iteration 60 : 1249291665408.0
Loss at iteration 70 : 13897313280.0
Loss at iteration 80 : 997398282240.0
Loss at iteration 90 : 315376992256.0
Loss at iteration 100 : 3601042505728.0
Loss at iteration 110 : 31667181846528.0
Loss at iteration 120 : 2103429631574016.0
Loss at iteration 130 : 1504198262784.0
Loss at iteration 140 : 174718713856.0
Loss at iteration 150 : 250192789504.0
Loss at iteration 160 : 2.737754816104104e+18
Loss at iteration 170 : 9211592704.0
Loss at iteration 180 : 5799546368.0
Loss at iteration 190 : 185640632320.0
Loss at iteration 200 : 51042291712.0
Loss at iteration 210 : 1499971452928.0
Loss at iteration 220 : 60365852672.0
Loss at iteration 230 : 11503703949312.0
Loss at iteration 240 : 313905086464.0
Loss at iteration 250 : 17990399557632.0
Loss at iteration 260 : 1878257041408.0
Loss at iteration 270 : 309670215680.0
Loss at iteration 280 : 912621043712.0
Loss at iteration 290 : 195988996096.0
Loss at iteration 300 : 144768925696.0
Loss at iteration 310 : 184792203264.0
Loss at iteration 320 : 192575946752.0
Loss at iteration 330 : 3236422483968.0
Loss at iteration 340 : 1970876186624.0
Loss at iteration 350 : 721567481856.0
Loss at iteration 360 : 554544398336.0
Loss at iteration 370 : 3169278230528.0
Loss at iteration 380 : 2511131901952.0
Loss at iteration 390 : 277906882560.0
Loss at iteration 400 : 95958253568.0
Loss at iteration 410 : 25905958912.0
Loss at iteration 420 : 269606912000.0
Loss at iteration 430 : 71310565376.0
Loss at iteration 440 : 52288647168.0
Loss at iteration 450 : 2542552320.0
Loss at iteration 460 : 45049491456.0
Loss at iteration 470 : 874181820416.0
Loss at iteration 480 : 39532298240.0
Loss at iteration 490 : 191489048576.0
Loss at iteration 500 : 30544070656.0
Loss at iteration 510 : 53425168384.0
Loss at iteration 520 : 8296674099200.0
Loss at iteration 530 : 112489431040.0
Loss at iteration 540 : 2689731657728.0
Loss at iteration 550 : 4489370140672.0
Loss at iteration 560 : 13464640684032.0
Loss at iteration 570 : 58931619561472.0
Loss at iteration 580 : 2427444789248.0
Loss at iteration 590 : 23839140478976.0
Loss at iteration 600 : 742443450368.0
Loss at iteration 610 : 20447324160.0
Loss at iteration 620 : 11284520108032.0
Loss at iteration 630 : 128974512128.0
Loss at iteration 640 : 484103028736.0
Loss at iteration 650 : 53589618688.0
Loss at iteration 660 : 6344192000.0
Loss at iteration 670 : 147623814103040.0
Loss at iteration 680 : 4560001695744.0
Loss at iteration 690 : 21011787415552.0
Loss at iteration 700 : 268251348992.0
Loss at iteration 710 : 85497544704.0
Loss at iteration 720 : 9280671744.0
Loss at iteration 730 : 101513453568.0
Loss at iteration 740 : 2372380393472.0
Loss at iteration 750 : 798637293568.0
Loss at iteration 760 : 4206244864.0
Loss at iteration 770 : 2076367781888.0
Loss at iteration 780 : 8698451722240.0
Loss at iteration 790 : 21447961477120.0
Loss at iteration 800 : 5934022656000.0
Loss at iteration 810 : 382363533312.0
Loss at iteration 820 : 233799073792.0
Loss at iteration 830 : 1.0925259708432384e+16
Loss at iteration 840 : 2063238144.0
Loss at iteration 850 : 8350864896.0
Loss at iteration 860 : 80574005248.0
Loss at iteration 870 : 5720527360.0
Loss at iteration 880 : 13485884416.0
Loss at iteration 890 : 197333450752.0
Loss at iteration 900 : 2064107264.0
Loss at iteration 910 : 100614520832.0
Loss at iteration 920 : 354980986880.0
Loss at iteration 930 : 7365689344.0
Loss at iteration 940 : 810701291520.0
Loss at iteration 950 : 89634357248.0
Loss at iteration 960 : 636424617984.0
Loss at iteration 970 : 12567198720.0
Loss at iteration 980 : 175608840192.0
Loss at iteration 990 : 158766006272.0
Loss at iteration 1000 : 484318707712.0
Loss at iteration 1010 : 192135970816.0
Loss at iteration 1020 : 6230359670784.0
Loss at iteration 1030 : 15078080512.0
Loss at iteration 1040 : 647512653824.0
Loss at iteration 1050 : 193425342464.0
Loss at iteration 1060 : 512059441152.0
Loss at iteration 1070 : 8684581158912.0
Loss at iteration 1080 : 74463420416.0
Loss at iteration 1090 : 51838631936.0
Loss at iteration 1100 : 5530415792128.0
Loss at iteration 1110 : 9165072384.0
Loss at iteration 1120 : 297408888832.0
Loss at iteration 1130 : 322795044864.0
Loss at iteration 1140 : 936908095488.0
Loss at iteration 1150 : 6596364288.0
Loss at iteration 1160 : 8357553373184.0
Loss at iteration 1170 : 314828161024.0
Loss at iteration 1180 : 1019552896.0
Loss at iteration 1190 : 126986485760.0
Loss at iteration 1200 : 110703149056.0
Loss at iteration 1210 : 3351243915264.0
Loss at iteration 1220 : 464273080320.0
Loss at iteration 1230 : 37084663808.0
Loss at iteration 1240 : 12622148608.0
Loss at iteration 1250 : 12063743148032.0
Loss at iteration 1260 : 828449947648.0
Loss at iteration 1270 : 270657961984.0
Loss at iteration 1280 : 31887329280.0
Loss at iteration 1290 : 237548961792.0
Loss at iteration 1300 : 136825511936.0
Loss at iteration 1310 : 15227552768.0
Loss at iteration 1320 : 4113003520.0
Loss at iteration 1330 : 160426852352.0
Loss at iteration 1340 : 26001129472.0
Loss at iteration 1350 : 626085330944.0
Loss at iteration 1360 : 6383346384896.0
Loss at iteration 1370 : 42070999040.0
Loss at iteration 1380 : 71816273920.0
Loss at iteration 1390 : 54908014592.0
Loss at iteration 1400 : 76009676800.0
Loss at iteration 1410 : 8843320320.0
Loss at iteration 1420 : 102014009344.0
Loss at iteration 1430 : 14191628288.0
Loss at iteration 1440 : 1818714308608.0
Loss at iteration 1450 : 4929889280.0
Loss at iteration 1460 : 6516959232.0
Loss at iteration 1470 : 107097292800.0
Loss at iteration 1480 : 130078916608.0
Loss at iteration 1490 : 45689139200.0
Loss at iteration 1500 : 120265228288.0
Loss at iteration 1510 : 26668752896.0
Loss at iteration 1520 : 30015068160.0
Loss at iteration 1530 : 18490232832.0
Loss at iteration 1540 : 68659720192.0
Loss at iteration 1550 : 39140831232.0
Loss at iteration 1560 : 89325953024.0
Loss at iteration 1570 : 263916732416.0
Loss at iteration 1580 : 105408700416.0
Loss at iteration 1590 : 28936531968.0
Loss at iteration 1600 : 160338352.0
Loss at iteration 1610 : 1929153920.0
Loss at iteration 1620 : 198390193324032.0
Loss at iteration 1630 : 33342005248.0
Loss at iteration 1640 : 76365332480.0
Loss at iteration 1650 : 855314595840.0
Loss at iteration 1660 : 3745802240.0
Loss at iteration 1670 : 14532736974848.0
Loss at iteration 1680 : 40266182426624.0
Loss at iteration 1690 : 11412329988096.0
Loss at iteration 1700 : 2092748636160.0
Loss at iteration 1710 : 6556798156800.0
Loss at iteration 1720 : 539617427456.0
Loss at iteration 1730 : 9870084407296.0
Loss at iteration 1740 : 1325827883008.0
Loss at iteration 1750 : 1718810705920.0
Loss at iteration 1760 : 6380005621760.0
Loss at iteration 1770 : 3970796093440.0
Loss at iteration 1780 : 21055690752.0
Loss at iteration 1790 : 635123793920.0
Loss at iteration 1800 : 43332464640.0
Loss at iteration 1810 : 592327344128.0
Loss at iteration 1820 : 1362550063104.0
Loss at iteration 1830 : 33377203781632.0
Loss at iteration 1840 : 942498447360.0
Loss at iteration 1850 : 372133068800.0
Loss at iteration 1860 : 1047746248704.0
Loss at iteration 1870 : 809089957888.0
Loss at iteration 1880 : 424359657472.0
Loss at iteration 1890 : 32163351232512.0
Loss at iteration 1900 : 226942238720.0
Loss at iteration 1910 : 79457968128.0
Loss at iteration 1920 : 139579064320.0
Loss at iteration 1930 : 377508691968.0
Loss at iteration 1940 : 1004075745280.0
Loss at iteration 1950 : 2390094774272.0
Loss at iteration 1960 : 97365767749632.0
Loss at iteration 1970 : 9977798656.0
Loss at iteration 1980 : 630582083584.0
Loss at iteration 1990 : 13756785491968.0
Loss at iteration 2000 : 2074858487808.0
Loss at iteration 2010 : 57402040320.0
Loss at iteration 2020 : 212583727104.0
Loss at iteration 2030 : 3853405650944.0
Loss at iteration 2040 : 56842499653632.0
Loss at iteration 2050 : 430971715584.0
Loss at iteration 2060 : 21308242919424.0
Loss at iteration 2070 : 240240001024.0
Loss at iteration 2080 : 152013690109952.0
Loss at iteration 2090 : 212864451215360.0
Loss at iteration 2100 : 73129099526144.0
Loss at iteration 2110 : 22703648014336.0
Loss at iteration 2120 : 26201296994304.0
Loss at iteration 2130 : 36533285421056.0
Loss at iteration 2140 : 7030199287808.0
Loss at iteration 2150 : 9546404724736.0
Loss at iteration 2160 : 1512236107431936.0
Loss at iteration 2170 : 8309016363008.0
Loss at iteration 2180 : 22995414286336.0
Loss at iteration 2190 : 1868011929600.0
Loss at iteration 2200 : 9601166606336.0
Loss at iteration 2210 : 14265519964160.0
Loss at iteration 2220 : 6020820631552.0
Loss at iteration 2230 : 3885300711424.0
Loss at iteration 2240 : 1479916912640.0
Loss at iteration 2250 : 214555131904.0
Loss at iteration 2260 : 88951717101568.0
Loss at iteration 2270 : 10863162425344.0
Loss at iteration 2280 : 620609077248.0
Loss at iteration 2290 : 13492663877632.0
Loss at iteration 2300 : 6413561626624.0
Loss at iteration 2310 : 28303553462272.0
Loss at iteration 2320 : 473462177792.0
Loss at iteration 2330 : 143964389376.0
Loss at iteration 2340 : 2508504432640.0
Loss at iteration 2350 : 91641801080832.0
Loss at iteration 2360 : 199927674175488.0
Loss at iteration 2370 : 7491477831680.0
Loss at iteration 2380 : 1323330023981056.0
Loss at iteration 2390 : 37213290496.0
Loss at iteration 2400 : 23542376693760.0
Loss at iteration 2410 : 295874190114816.0
Loss at iteration 2420 : 111601311023104.0
The SSIM Value is: -8.104421453936084e-07
The PSNR Value is: -152.73877665201823
the epoch is: 141
Loss at iteration 10 : 2715210141925376.0
Loss at iteration 20 : 18103421370368.0
Loss at iteration 30 : 2189800374272.0
Loss at iteration 40 : 13200809525248.0
Loss at iteration 50 : 4791747477504.0
Loss at iteration 60 : 45061962203136.0
Loss at iteration 70 : 34780513042432.0
Loss at iteration 80 : 8252524331008.0
Loss at iteration 90 : 228998086656.0
Loss at iteration 100 : 80223264768.0
Loss at iteration 110 : 705504673792.0
Loss at iteration 120 : 24596749221888.0
Loss at iteration 130 : 1226902470656.0
Loss at iteration 140 : 1151590203392.0
Loss at iteration 150 : 578134081536.0
Loss at iteration 160 : 2517765455872.0
Loss at iteration 170 : 374669737984.0
Loss at iteration 180 : 23172009984.0
Loss at iteration 190 : 1743635840.0
Loss at iteration 200 : 1581255491584.0
Loss at iteration 210 : 2709944008704.0
Loss at iteration 220 : 401580326912.0
Loss at iteration 230 : 25490079744.0
Loss at iteration 240 : 242045632512.0
Loss at iteration 250 : 1157779030016.0
Loss at iteration 260 : 136204001280.0
Loss at iteration 270 : 404848672768.0
Loss at iteration 280 : 87158497280.0
Loss at iteration 290 : 253794385920.0
Loss at iteration 300 : 441148276736.0
Loss at iteration 310 : 761891782656.0
Loss at iteration 320 : 26978377728.0
Loss at iteration 330 : 389486968832.0
Loss at iteration 340 : 5336319131648.0
Loss at iteration 350 : 471574183936.0
Loss at iteration 360 : 565442248704.0
Loss at iteration 370 : 725772926976.0
Loss at iteration 380 : 3986659213312.0
Loss at iteration 390 : 8631697276928.0
Loss at iteration 400 : 117827551232.0
Loss at iteration 410 : 16758035447808.0
Loss at iteration 420 : 12327215104.0
Loss at iteration 430 : 107916541952.0
Loss at iteration 440 : 339604242432.0
Loss at iteration 450 : 249398411264.0
Loss at iteration 460 : 1009896652800.0
Loss at iteration 470 : 1332910227456.0
Loss at iteration 480 : 169397469184.0
Loss at iteration 490 : 23789180928.0
Loss at iteration 500 : 240214736896.0
Loss at iteration 510 : 481293402112.0
Loss at iteration 520 : 1333176434688.0
Loss at iteration 530 : 10621750272.0
Loss at iteration 540 : 21623367680.0
Loss at iteration 550 : 527056306176.0
Loss at iteration 560 : 524883296256.0
Loss at iteration 570 : 69093359616.0
Loss at iteration 580 : 301512654848.0
Loss at iteration 590 : 646009782272.0
Loss at iteration 600 : 44432433152.0
Loss at iteration 610 : 113192812544.0
Loss at iteration 620 : 503431004160.0
Loss at iteration 630 : 2375911473152.0
Loss at iteration 640 : 1120821182464.0
Loss at iteration 650 : 1444670472192.0
Loss at iteration 660 : 60991700992.0
Loss at iteration 670 : 314045333504.0
Loss at iteration 680 : 171086446592.0
Loss at iteration 690 : 304610803712.0
Loss at iteration 700 : 210739691520.0
Loss at iteration 710 : 2735792193536.0
Loss at iteration 720 : 23691884756992.0
Loss at iteration 730 : 321813774336.0
Loss at iteration 740 : 4829840146432.0
Loss at iteration 750 : 427694456832.0
Loss at iteration 760 : 184952373248.0
Loss at iteration 770 : 159112183808.0
Loss at iteration 780 : 854577512448.0
Loss at iteration 790 : 400236216320.0
Loss at iteration 800 : 22879438848.0
Loss at iteration 810 : 22148317184.0
Loss at iteration 820 : 22899215826944.0
Loss at iteration 830 : 23725781024768.0
Loss at iteration 840 : 5724697001984.0
Loss at iteration 850 : 13515383808.0
Loss at iteration 860 : 14730988544.0
Loss at iteration 870 : 56692981760.0
Loss at iteration 880 : 521040822272.0
Loss at iteration 890 : 1268368801792.0
Loss at iteration 900 : 16982300672.0
Loss at iteration 910 : 12401674027008.0
Loss at iteration 920 : 76640403456.0
Loss at iteration 930 : 182184509440.0
Loss at iteration 940 : 64159051776.0
Loss at iteration 950 : 301424115712.0
Loss at iteration 960 : 95397773312.0
Loss at iteration 970 : 165472518144.0
Loss at iteration 980 : 677667471360.0
Loss at iteration 990 : 867439411200.0
Loss at iteration 1000 : 24165087232.0
Loss at iteration 1010 : 1951486574592.0
Loss at iteration 1020 : 1592036163584.0
Loss at iteration 1030 : 687462219776.0
Loss at iteration 1040 : 98261050327040.0
Loss at iteration 1050 : 52657664000.0
Loss at iteration 1060 : 31928893440.0
Loss at iteration 1070 : 554927259648.0
Loss at iteration 1080 : 31593816064.0
Loss at iteration 1090 : 48885936128.0
Loss at iteration 1100 : 16701694976.0
Loss at iteration 1110 : 25208809324544.0
Loss at iteration 1120 : 21358319616.0
Loss at iteration 1130 : 41736835072.0
Loss at iteration 1140 : 92785475584.0
Loss at iteration 1150 : 39243284480.0
Loss at iteration 1160 : 4884635136.0
Loss at iteration 1170 : 58934288384.0
Loss at iteration 1180 : 126998716416.0
Loss at iteration 1190 : 302314094592.0
Loss at iteration 1200 : 35670253568.0
Loss at iteration 1210 : 2362691551232.0
Loss at iteration 1220 : 21999226880.0
Loss at iteration 1230 : 43350835200.0
Loss at iteration 1240 : 8330890240.0
Loss at iteration 1250 : 49978499072.0
Loss at iteration 1260 : 47590150144.0
Loss at iteration 1270 : 118124281856.0
Loss at iteration 1280 : 58690150400.0
Loss at iteration 1290 : 2112772112384.0
Loss at iteration 1300 : 117882634240.0
Loss at iteration 1310 : 903056588800.0
Loss at iteration 1320 : 6470649856.0
Loss at iteration 1330 : 12343743488.0
Loss at iteration 1340 : 10350709760.0
Loss at iteration 1350 : 9032316928.0
Loss at iteration 1360 : 112721780736.0
Loss at iteration 1370 : 185226477568.0
Loss at iteration 1380 : 590123827200.0
Loss at iteration 1390 : 324501471232.0
Loss at iteration 1400 : 34160656384.0
Loss at iteration 1410 : 8370343424.0
Loss at iteration 1420 : 49271144448.0
Loss at iteration 1430 : 2227586465792.0
Loss at iteration 1440 : 1436942336000.0
Loss at iteration 1450 : 187879309312.0
Loss at iteration 1460 : 23738703872.0
Loss at iteration 1470 : 545406582784.0
Loss at iteration 1480 : 80648052736.0
Loss at iteration 1490 : 619228954624.0
Loss at iteration 1500 : 161524842496.0
Loss at iteration 1510 : 63578783744.0
Loss at iteration 1520 : 1224070135808.0
Loss at iteration 1530 : 6626650095616.0
Loss at iteration 1540 : 17077898313728.0
Loss at iteration 1550 : 4574058381312.0
Loss at iteration 1560 : 30406625280.0
Loss at iteration 1570 : 144341057536.0
Loss at iteration 1580 : 8762593280.0
Loss at iteration 1590 : 32890025984.0
Loss at iteration 1600 : 83148668928.0
Loss at iteration 1610 : 1489292623872.0
Loss at iteration 1620 : 371809255424.0
Loss at iteration 1630 : 224993017856.0
Loss at iteration 1640 : 3679804981248.0
Loss at iteration 1650 : 3714865168384.0
Loss at iteration 1660 : 1253287133184.0
Loss at iteration 1670 : 4277311111168.0
Loss at iteration 1680 : 54719848448.0
Loss at iteration 1690 : 103832715264.0
Loss at iteration 1700 : 270680883200.0
Loss at iteration 1710 : 129366351872.0
Loss at iteration 1720 : 500858945536.0
Loss at iteration 1730 : 1068185812992.0
Loss at iteration 1740 : 3829716484096.0
Loss at iteration 1750 : 476712468480.0
Loss at iteration 1760 : 23777497088.0
Loss at iteration 1770 : 28756029440.0
Loss at iteration 1780 : 1114212925440.0
Loss at iteration 1790 : 2191496183808.0
Loss at iteration 1800 : 119749648384.0
Loss at iteration 1810 : 5585068544.0
Loss at iteration 1820 : 220544679936.0
Loss at iteration 1830 : 73760473088.0
Loss at iteration 1840 : 72315314176.0
Loss at iteration 1850 : 178719621120.0
Loss at iteration 1860 : 123732344832.0
Loss at iteration 1870 : 73415237632.0
Loss at iteration 1880 : 6144336068608.0
Loss at iteration 1890 : 216748490752.0
Loss at iteration 1900 : 23922028544.0
Loss at iteration 1910 : 70446653440.0
Loss at iteration 1920 : 6902398976.0
Loss at iteration 1930 : 1462855008256.0
Loss at iteration 1940 : 1754145488896.0
Loss at iteration 1950 : 65259237376.0
Loss at iteration 1960 : 340735885312.0
Loss at iteration 1970 : 94307475456.0
Loss at iteration 1980 : 18381225984.0
Loss at iteration 1990 : 32428926976.0
Loss at iteration 2000 : 295612416000.0
Loss at iteration 2010 : 4148609792.0
Loss at iteration 2020 : 63532597248.0
Loss at iteration 2030 : 3806909956096.0
Loss at iteration 2040 : 1001577971712.0
Loss at iteration 2050 : 327937032192.0
Loss at iteration 2060 : 48599572480.0
Loss at iteration 2070 : 393721577472.0
Loss at iteration 2080 : 32079718400.0
Loss at iteration 2090 : 8493494784.0
Loss at iteration 2100 : 384054296576.0
Loss at iteration 2110 : 32539684864.0
Loss at iteration 2120 : 762055753728.0
Loss at iteration 2130 : 595040075776.0
Loss at iteration 2140 : 992288636928.0
Loss at iteration 2150 : 3676124741632.0
Loss at iteration 2160 : 497006739456.0
Loss at iteration 2170 : 450618425344.0
Loss at iteration 2180 : 786810470400.0
Loss at iteration 2190 : 72509210624.0
Loss at iteration 2200 : 27153102848.0
Loss at iteration 2210 : 19156103168.0
Loss at iteration 2220 : 2952104192.0
Loss at iteration 2230 : 2992192356352.0
Loss at iteration 2240 : 27591770112.0
Loss at iteration 2250 : 113861533696.0
Loss at iteration 2260 : 86703325184.0
Loss at iteration 2270 : 352877608960.0
Loss at iteration 2280 : 30220226560.0
Loss at iteration 2290 : 64646656000.0
Loss at iteration 2300 : 175166947328.0
Loss at iteration 2310 : 502090530816.0
Loss at iteration 2320 : 392826683392.0
Loss at iteration 2330 : 451107815424.0
Loss at iteration 2340 : 589693911040.0
Loss at iteration 2350 : 582224314368.0
Loss at iteration 2360 : 28217266176.0
Loss at iteration 2370 : 15177584640.0
Loss at iteration 2380 : 585705979904.0
Loss at iteration 2390 : 74967097344.0
Loss at iteration 2400 : 27260729344.0
Loss at iteration 2410 : 16019894272.0
Loss at iteration 2420 : 280025169920.0
The SSIM Value is: 6.842851625776802e-06
The PSNR Value is: -121.76577707926432
the epoch is: 142
Loss at iteration 10 : 679129186304.0
Loss at iteration 20 : 1089586003968.0
Loss at iteration 30 : 43301773312.0
Loss at iteration 40 : 2316554993664.0
Loss at iteration 50 : 22627567616.0
Loss at iteration 60 : 40208113664.0
Loss at iteration 70 : 128196911104.0
Loss at iteration 80 : 11257274368.0
Loss at iteration 90 : 430965325824.0
Loss at iteration 100 : 13997667328.0
Loss at iteration 110 : 2042091405312.0
Loss at iteration 120 : 121244639232.0
Loss at iteration 130 : 2261369225216.0
Loss at iteration 140 : 297468919808.0
Loss at iteration 150 : 458112335872.0
Loss at iteration 160 : 112626253824.0
Loss at iteration 170 : 63492153344.0
Loss at iteration 180 : 58175414272.0
Loss at iteration 190 : 82277244928.0
Loss at iteration 200 : 600311463936.0
Loss at iteration 210 : 235052974080.0
Loss at iteration 220 : 125650485248.0
Loss at iteration 230 : 182389981184.0
Loss at iteration 240 : 43316867072.0
Loss at iteration 250 : 198129401856.0
Loss at iteration 260 : 30284638208.0
Loss at iteration 270 : 7951389032448.0
Loss at iteration 280 : 51794571264.0
Loss at iteration 290 : 220459810816.0
Loss at iteration 300 : 235307253760.0
Loss at iteration 310 : 214378430464.0
Loss at iteration 320 : 13525617664.0
Loss at iteration 330 : 267708334080.0
Loss at iteration 340 : 728470716416.0
Loss at iteration 350 : 122231750656.0
Loss at iteration 360 : 19588640768.0
Loss at iteration 370 : 405666725888.0
Loss at iteration 380 : 37330026496.0
Loss at iteration 390 : 191584288768.0
Loss at iteration 400 : 75191197696.0
Loss at iteration 410 : 4317348364288.0
Loss at iteration 420 : 12715445714944.0
Loss at iteration 430 : 48547336192.0
Loss at iteration 440 : 95443451904.0
Loss at iteration 450 : 138105683968.0
Loss at iteration 460 : 753367777280.0
Loss at iteration 470 : 290085797888.0
Loss at iteration 480 : 19353790464.0
Loss at iteration 490 : 324452155392.0
Loss at iteration 500 : 13275299840.0
Loss at iteration 510 : 354758426624.0
Loss at iteration 520 : 632516902912.0
Loss at iteration 530 : 545690550272.0
Loss at iteration 540 : 117356429312.0
Loss at iteration 550 : 5830871040.0
Loss at iteration 560 : 183820451840.0
Loss at iteration 570 : 166859571200.0
Loss at iteration 580 : 56286404608.0
Loss at iteration 590 : 642140930048.0
Loss at iteration 600 : 16516616192.0
Loss at iteration 610 : 132236845056.0
Loss at iteration 620 : 344572887040.0
Loss at iteration 630 : 1206124937216.0
Loss at iteration 640 : 48019308544.0
Loss at iteration 650 : 167745978368.0
Loss at iteration 660 : 57909608448.0
Loss at iteration 670 : 188377448448.0
Loss at iteration 680 : 166109478912.0
Loss at iteration 690 : 3624708866048.0
Loss at iteration 700 : 121510313984.0
Loss at iteration 710 : 12833514496.0
Loss at iteration 720 : 5136695808.0
Loss at iteration 730 : 328662515712.0
Loss at iteration 740 : 206282817536.0
Loss at iteration 750 : 25141585920.0
Loss at iteration 760 : 7175056384.0
Loss at iteration 770 : 126035705856.0
Loss at iteration 780 : 19966521344.0
Loss at iteration 790 : 85381464064.0
Loss at iteration 800 : 1687189323776.0
Loss at iteration 810 : 2164766015488.0
Loss at iteration 820 : 68271751168.0
Loss at iteration 830 : 140508430336.0
Loss at iteration 840 : 31102150656.0
Loss at iteration 850 : 36490002432.0
Loss at iteration 860 : 18599839744.0
Loss at iteration 870 : 10015234048.0
Loss at iteration 880 : 90201014272.0
Loss at iteration 890 : 17173998592.0
Loss at iteration 900 : 22622965760.0
Loss at iteration 910 : 20122478592.0
Loss at iteration 920 : 71488339968.0
Loss at iteration 930 : 135027802112.0
Loss at iteration 940 : 87188578304.0
Loss at iteration 950 : 393644867584.0
Loss at iteration 960 : 31427256320.0
Loss at iteration 970 : 284366929920.0
Loss at iteration 980 : 36750282752.0
Loss at iteration 990 : 6661620105216.0
Loss at iteration 1000 : 12497684480.0
Loss at iteration 1010 : 13090768896.0
Loss at iteration 1020 : 104295063552.0
Loss at iteration 1030 : 313743376384.0
Loss at iteration 1040 : 124634030080.0
Loss at iteration 1050 : 125323911168.0
Loss at iteration 1060 : 2079789678592.0
Loss at iteration 1070 : 3971169124352.0
Loss at iteration 1080 : 35898183680.0
Loss at iteration 1090 : 35266506752.0
Loss at iteration 1100 : 8140457472.0
Loss at iteration 1110 : 244609908736.0
Loss at iteration 1120 : 352891207680.0
Loss at iteration 1130 : 55476908032.0
Loss at iteration 1140 : 125218856960.0
Loss at iteration 1150 : 105829482496.0
Loss at iteration 1160 : 29623879680.0
Loss at iteration 1170 : 85437644800.0
Loss at iteration 1180 : 80146636800.0
Loss at iteration 1190 : 12245542912.0
Loss at iteration 1200 : 52778496000.0
Loss at iteration 1210 : 7989157376.0
Loss at iteration 1220 : 4427658240.0
Loss at iteration 1230 : 50866036736.0
Loss at iteration 1240 : 27072483328.0
Loss at iteration 1250 : 5069743616.0
Loss at iteration 1260 : 8354584330240.0
Loss at iteration 1270 : 303163998208.0
Loss at iteration 1280 : 127485329408.0
Loss at iteration 1290 : 398282784768.0
Loss at iteration 1300 : 8529774080.0
Loss at iteration 1310 : 228171153408.0
Loss at iteration 1320 : 6782798848.0
Loss at iteration 1330 : 8639251456.0
Loss at iteration 1340 : 5353271808.0
Loss at iteration 1350 : 456560214016.0
Loss at iteration 1360 : 4790087680.0
Loss at iteration 1370 : 8869059584.0
Loss at iteration 1380 : 11148091392.0
Loss at iteration 1390 : 71563255808.0
Loss at iteration 1400 : 139183603712.0
Loss at iteration 1410 : 14918506496.0
Loss at iteration 1420 : 82112626688.0
Loss at iteration 1430 : 356437950464.0
Loss at iteration 1440 : 27915323392.0
Loss at iteration 1450 : 48800296960.0
Loss at iteration 1460 : 15995229184.0
Loss at iteration 1470 : 37885530112.0
Loss at iteration 1480 : 28878292992.0
Loss at iteration 1490 : 1252291117056.0
Loss at iteration 1500 : 110049443840.0
Loss at iteration 1510 : 6797338112.0
Loss at iteration 1520 : 11191522304.0
Loss at iteration 1530 : 38242484224.0
Loss at iteration 1540 : 446560894976.0
Loss at iteration 1550 : 31409872896.0
Loss at iteration 1560 : 10199721984.0
Loss at iteration 1570 : 66523705344.0
Loss at iteration 1580 : 168305934336.0
Loss at iteration 1590 : 6277775872.0
Loss at iteration 1600 : 98146852864.0
Loss at iteration 1610 : 22260287488.0
Loss at iteration 1620 : 281906577408.0
Loss at iteration 1630 : 26213795840.0
Loss at iteration 1640 : 54888185856.0
Loss at iteration 1650 : 567770873856.0
Loss at iteration 1660 : 37790306304.0
Loss at iteration 1670 : 17667166208.0
Loss at iteration 1680 : 877611646976.0
Loss at iteration 1690 : 18271537152.0
Loss at iteration 1700 : 1152752025600.0
Loss at iteration 1710 : 241627987968.0
Loss at iteration 1720 : 22887364608.0
Loss at iteration 1730 : 4027195904.0
Loss at iteration 1740 : 313683116032.0
Loss at iteration 1750 : 155080671232.0
Loss at iteration 1760 : 27107311616.0
Loss at iteration 1770 : 10984558592.0
Loss at iteration 1780 : 100849451008.0
Loss at iteration 1790 : 9326787584.0
Loss at iteration 1800 : 25108639744.0
Loss at iteration 1810 : 553122176.0
Loss at iteration 1820 : 826174013440.0
Loss at iteration 1830 : 4813751296.0
Loss at iteration 1840 : 12611103744.0
Loss at iteration 1850 : 4364593152.0
Loss at iteration 1860 : 29608994816.0
Loss at iteration 1870 : 5185144320.0
Loss at iteration 1880 : 32476837888.0
Loss at iteration 1890 : 45398433792.0
Loss at iteration 1900 : 174132346880.0
Loss at iteration 1910 : 225650262016.0
Loss at iteration 1920 : 2832668819456.0
Loss at iteration 1930 : 12766874624.0
Loss at iteration 1940 : 23334557696.0
Loss at iteration 1950 : 245823864832.0
Loss at iteration 1960 : 14427917312.0
Loss at iteration 1970 : 794305953792.0
Loss at iteration 1980 : 45781852160.0
Loss at iteration 1990 : 49382326272.0
Loss at iteration 2000 : 3041409536.0
Loss at iteration 2010 : 152311463936.0
Loss at iteration 2020 : 14818553856.0
Loss at iteration 2030 : 4130566912.0
Loss at iteration 2040 : 12136269824.0
Loss at iteration 2050 : 7744235008.0
Loss at iteration 2060 : 39065759744.0
Loss at iteration 2070 : 36591456256.0
Loss at iteration 2080 : 51897380.0
Loss at iteration 2090 : 6893892608.0
Loss at iteration 2100 : 5581944320.0
Loss at iteration 2110 : 41590984704.0
Loss at iteration 2120 : 273511301120.0
Loss at iteration 2130 : 302150189056.0
Loss at iteration 2140 : 100426055680.0
Loss at iteration 2150 : 21101076480.0
Loss at iteration 2160 : 13020721152.0
Loss at iteration 2170 : 138637787136.0
Loss at iteration 2180 : 12566278144.0
Loss at iteration 2190 : 1652910848.0
Loss at iteration 2200 : 30733301760.0
Loss at iteration 2210 : 51836649472.0
Loss at iteration 2220 : 8153775104.0
Loss at iteration 2230 : 2350255616.0
Loss at iteration 2240 : 39734120448.0
Loss at iteration 2250 : 2235834112.0
Loss at iteration 2260 : 83497213952.0
Loss at iteration 2270 : 174613610496.0
Loss at iteration 2280 : 29735464960.0
Loss at iteration 2290 : 75968045056.0
Loss at iteration 2300 : 5152780288.0
Loss at iteration 2310 : 43480145920.0
Loss at iteration 2320 : 129686609920.0
Loss at iteration 2330 : 29671665664.0
Loss at iteration 2340 : 22594304000.0
Loss at iteration 2350 : 27240833024.0
Loss at iteration 2360 : 4791598080.0
Loss at iteration 2370 : 3955469312.0
Loss at iteration 2380 : 185090359296.0
Loss at iteration 2390 : 29444558848.0
Loss at iteration 2400 : 10476205056.0
Loss at iteration 2410 : 4746609152.0
Loss at iteration 2420 : 4509609472.0
The SSIM Value is: 8.220642019788708e-06
The PSNR Value is: -113.17273661295573
the epoch is: 143
Loss at iteration 10 : 123662229504.0
Loss at iteration 20 : 12289701888.0
Loss at iteration 30 : 23352274944.0
Loss at iteration 40 : 1008988224.0
Loss at iteration 50 : 2858989056.0
Loss at iteration 60 : 10656403456.0
Loss at iteration 70 : 58101657600.0
Loss at iteration 80 : 3414012928.0
Loss at iteration 90 : 6415856128.0
Loss at iteration 100 : 50008231936.0
Loss at iteration 110 : 17596370944.0
Loss at iteration 120 : 242979274752.0
Loss at iteration 130 : 556481344.0
Loss at iteration 140 : 204999163904.0
Loss at iteration 150 : 5710598656.0
Loss at iteration 160 : 12146227200.0
Loss at iteration 170 : 132821123072.0
Loss at iteration 180 : 85139111936.0
Loss at iteration 190 : 2581780480.0
Loss at iteration 200 : 1184982784.0
Loss at iteration 210 : 604003648.0
Loss at iteration 220 : 48987627520.0
Loss at iteration 230 : 213613664.0
Loss at iteration 240 : 2681731072.0
Loss at iteration 250 : 56306601984.0
Loss at iteration 260 : 13564414976.0
Loss at iteration 270 : 4364234752.0
Loss at iteration 280 : 1246254976.0
Loss at iteration 290 : 1367785344.0
Loss at iteration 300 : 9144206336.0
Loss at iteration 310 : 15234735104.0
Loss at iteration 320 : 252262384.0
Loss at iteration 330 : 20740573184.0
Loss at iteration 340 : 2440445440.0
Loss at iteration 350 : 8353233920.0
Loss at iteration 360 : 3639780608.0
Loss at iteration 370 : 68888780800.0
Loss at iteration 380 : 33737314304.0
Loss at iteration 390 : 18803142656.0
Loss at iteration 400 : 24140314624.0
Loss at iteration 410 : 7754591744.0
Loss at iteration 420 : 8083851776.0
Loss at iteration 430 : 2104649472.0
Loss at iteration 440 : 10006008.0
Loss at iteration 450 : 12964562944.0
Loss at iteration 460 : 3740238848.0
Loss at iteration 470 : 1114160640.0
Loss at iteration 480 : 506124763136.0
Loss at iteration 490 : 5798185472.0
Loss at iteration 500 : 23728545792.0
Loss at iteration 510 : 3134046464.0
Loss at iteration 520 : 606650560.0
Loss at iteration 530 : 8107198464.0
Loss at iteration 540 : 73845645312.0
Loss at iteration 550 : 2695454720.0
Loss at iteration 560 : 3338085888.0
Loss at iteration 570 : 98958254080.0
Loss at iteration 580 : 9072180224.0
Loss at iteration 590 : 352548128.0
Loss at iteration 600 : 92750061568.0
Loss at iteration 610 : 3120996864.0
Loss at iteration 620 : 22353303552.0
Loss at iteration 630 : 1182460288.0
Loss at iteration 640 : 4602862592.0
Loss at iteration 650 : 38216871936.0
Loss at iteration 660 : 22186012672.0
Loss at iteration 670 : 1140700288.0
Loss at iteration 680 : 13467371520.0
Loss at iteration 690 : 17461190656.0
Loss at iteration 700 : 1660917632.0
Loss at iteration 710 : 9294519296.0
Loss at iteration 720 : 919523392.0
Loss at iteration 730 : 26085572608.0
Loss at iteration 740 : 46443855872.0
Loss at iteration 750 : 39531368448.0
Loss at iteration 760 : 12163971072.0
Loss at iteration 770 : 1582240768.0
Loss at iteration 780 : 30109761536.0
Loss at iteration 790 : 10331305984.0
Loss at iteration 800 : 100919992320.0
Loss at iteration 810 : 1613253888.0
Loss at iteration 820 : 28217591808.0
Loss at iteration 830 : 16011485184.0
Loss at iteration 840 : 216206442496.0
Loss at iteration 850 : 1573551865856.0
Loss at iteration 860 : 10142368768.0
Loss at iteration 870 : 417370275840.0
Loss at iteration 880 : 428686311424.0
Loss at iteration 890 : 69054570496.0
Loss at iteration 900 : 224430080000.0
Loss at iteration 910 : 20311035904.0
Loss at iteration 920 : 330348101632.0
Loss at iteration 930 : 2156480692224.0
Loss at iteration 940 : 36060889088.0
Loss at iteration 950 : 42522947584.0
Loss at iteration 960 : 28651278336.0
Loss at iteration 970 : 18325895168.0
Loss at iteration 980 : 18235191721984.0
Loss at iteration 990 : 2562616983552.0
Loss at iteration 1000 : 19304904704.0
Loss at iteration 1010 : 48118620160.0
Loss at iteration 1020 : 8426799104.0
Loss at iteration 1030 : 574314577920.0
Loss at iteration 1040 : 92593676288.0
Loss at iteration 1050 : 26284802048.0
Loss at iteration 1060 : 49325244416.0
Loss at iteration 1070 : 82885386240.0
Loss at iteration 1080 : 106410598400.0
Loss at iteration 1090 : 15802331136.0
Loss at iteration 1100 : 41277648896.0
Loss at iteration 1110 : 1925379456.0
Loss at iteration 1120 : 4086444544.0
Loss at iteration 1130 : 1806179072.0
Loss at iteration 1140 : 1087638528.0
Loss at iteration 1150 : 7650552053760.0
Loss at iteration 1160 : 2075969847296.0
Loss at iteration 1170 : 201808134144.0
Loss at iteration 1180 : 10776981504.0
Loss at iteration 1190 : 52883480576.0
Loss at iteration 1200 : 1203620282368.0
Loss at iteration 1210 : 264019247104.0
Loss at iteration 1220 : 200568258560.0
Loss at iteration 1230 : 5495029497856.0
Loss at iteration 1240 : 1604281303040.0
Loss at iteration 1250 : 1528846090240.0
Loss at iteration 1260 : 283365539840.0
Loss at iteration 1270 : 133296242688.0
Loss at iteration 1280 : 361095299072.0
Loss at iteration 1290 : 207435300864.0
Loss at iteration 1300 : 308641267712.0
Loss at iteration 1310 : 44848230400.0
Loss at iteration 1320 : 210299256832.0
Loss at iteration 1330 : 1923980591104.0
Loss at iteration 1340 : 2583337631744.0
Loss at iteration 1350 : 135871004672.0
Loss at iteration 1360 : 1626944045056.0
Loss at iteration 1370 : 12021048279040.0
Loss at iteration 1380 : 7987520864256.0
Loss at iteration 1390 : 1280716701696.0
Loss at iteration 1400 : 3490925248512.0
Loss at iteration 1410 : 195212771328.0
Loss at iteration 1420 : 639191351296.0
Loss at iteration 1430 : 2195883556864.0
Loss at iteration 1440 : 1631838273536.0
Loss at iteration 1450 : 4609911816192.0
Loss at iteration 1460 : 8656056745984.0
Loss at iteration 1470 : 1769194782720.0
Loss at iteration 1480 : 1770868310016.0
Loss at iteration 1490 : 267934580736.0
Loss at iteration 1500 : 596935639040.0
Loss at iteration 1510 : 35530436608.0
Loss at iteration 1520 : 164458954752.0
Loss at iteration 1530 : 45417582592.0
Loss at iteration 1540 : 348232122368.0
Loss at iteration 1550 : 36522991616.0
Loss at iteration 1560 : 3485303570432.0
Loss at iteration 1570 : 478850646016.0
Loss at iteration 1580 : 1779081412608.0
Loss at iteration 1590 : 1379118088192.0
Loss at iteration 1600 : 903566458880.0
Loss at iteration 1610 : 829212131328.0
Loss at iteration 1620 : 120252686336.0
Loss at iteration 1630 : 10492293120.0
Loss at iteration 1640 : 772579655680.0
Loss at iteration 1650 : 273601658880.0
Loss at iteration 1660 : 929821884416.0
Loss at iteration 1670 : 8078788096.0
Loss at iteration 1680 : 2607315156992.0
Loss at iteration 1690 : 34098761728.0
Loss at iteration 1700 : 434609061888.0
Loss at iteration 1710 : 145879007232.0
Loss at iteration 1720 : 18903719936.0
Loss at iteration 1730 : 545214431232.0
Loss at iteration 1740 : 4603403264.0
Loss at iteration 1750 : 386094858240.0
Loss at iteration 1760 : 102846660608.0
Loss at iteration 1770 : 115762331648.0
Loss at iteration 1780 : 44181630976.0
Loss at iteration 1790 : 382797316096.0
Loss at iteration 1800 : 370145067008.0
Loss at iteration 1810 : 218300579840.0
Loss at iteration 1820 : 166106988544.0
Loss at iteration 1830 : 150599073792.0
Loss at iteration 1840 : 75356962816.0
Loss at iteration 1850 : 7678923776.0
Loss at iteration 1860 : 145173544960.0
Loss at iteration 1870 : 14340513071104.0
Loss at iteration 1880 : 385598160896.0
Loss at iteration 1890 : 231487963136.0
Loss at iteration 1900 : 130189000704.0
Loss at iteration 1910 : 795591442432.0
Loss at iteration 1920 : 23574681600.0
Loss at iteration 1930 : 421284446208.0
Loss at iteration 1940 : 236794888192.0
Loss at iteration 1950 : 887902633984.0
Loss at iteration 1960 : 77078667264.0
Loss at iteration 1970 : 95806627840.0
Loss at iteration 1980 : 44022718464.0
Loss at iteration 1990 : 2465246478336.0
Loss at iteration 2000 : 349889462272.0
Loss at iteration 2010 : 63631667200.0
Loss at iteration 2020 : 29224459042816.0
Loss at iteration 2030 : 72846483456.0
Loss at iteration 2040 : 80360669184.0
Loss at iteration 2050 : 30817812480.0
Loss at iteration 2060 : 76996231168.0
Loss at iteration 2070 : 11334414336.0
Loss at iteration 2080 : 1309414272.0
Loss at iteration 2090 : 60108632064.0
Loss at iteration 2100 : 2052133093376.0
Loss at iteration 2110 : 107151015936.0
Loss at iteration 2120 : 543966920704.0
Loss at iteration 2130 : 35973021696.0
Loss at iteration 2140 : 82255880192.0
Loss at iteration 2150 : 1794310656.0
Loss at iteration 2160 : 34643554304.0
Loss at iteration 2170 : 42864783360.0
Loss at iteration 2180 : 38519513088.0
Loss at iteration 2190 : 1277320757248.0
Loss at iteration 2200 : 2787926605824.0
Loss at iteration 2210 : 10610585600.0
Loss at iteration 2220 : 11599967232.0
Loss at iteration 2230 : 42975436800.0
Loss at iteration 2240 : 137290334208.0
Loss at iteration 2250 : 234775986176.0
Loss at iteration 2260 : 55030407168.0
Loss at iteration 2270 : 1702394880.0
Loss at iteration 2280 : 34717728505856.0
Loss at iteration 2290 : 5067959173120.0
Loss at iteration 2300 : 5252894208.0
Loss at iteration 2310 : 53290139648.0
Loss at iteration 2320 : 7402539008.0
Loss at iteration 2330 : 23811981312.0
Loss at iteration 2340 : 98821873664.0
Loss at iteration 2350 : 19633905664.0
Loss at iteration 2360 : 252780511232.0
Loss at iteration 2370 : 748610912256.0
Loss at iteration 2380 : 8941150208.0
Loss at iteration 2390 : 1063947206656.0
Loss at iteration 2400 : 40868327424.0
Loss at iteration 2410 : 1180851896320.0
Loss at iteration 2420 : 1766254976.0
The SSIM Value is: -5.459671276260754e-07
The PSNR Value is: -117.78929901123047
the epoch is: 144
Loss at iteration 10 : 21485387776.0
Loss at iteration 20 : 33478572032.0
Loss at iteration 30 : 204338954240.0
Loss at iteration 40 : 6360490496.0
Loss at iteration 50 : 25187958784.0
Loss at iteration 60 : 14174864384.0
Loss at iteration 70 : 1723628672.0
Loss at iteration 80 : 33437264117760.0
Loss at iteration 90 : 219721859072.0
Loss at iteration 100 : 34926034944.0
Loss at iteration 110 : 1953615488.0
Loss at iteration 120 : 21696878592.0
Loss at iteration 130 : 80207511552.0
Loss at iteration 140 : 85399855104.0
Loss at iteration 150 : 16081386496.0
Loss at iteration 160 : 321260421120.0
Loss at iteration 170 : 13000271872.0
Loss at iteration 180 : 16115580928.0
Loss at iteration 190 : 197403770880.0
Loss at iteration 200 : 134977241088.0
Loss at iteration 210 : 92092424192.0
Loss at iteration 220 : 36474335232.0
Loss at iteration 230 : 26270095360.0
Loss at iteration 240 : 28517474304.0
Loss at iteration 250 : 154937737216.0
Loss at iteration 260 : 15230980096.0
Loss at iteration 270 : 34911670272.0
Loss at iteration 280 : 116090470400.0
Loss at iteration 290 : 14575654912.0
Loss at iteration 300 : 2098077568.0
Loss at iteration 310 : 17249105920.0
Loss at iteration 320 : 74235346944.0
Loss at iteration 330 : 146746802176.0
Loss at iteration 340 : 555822208.0
Loss at iteration 350 : 17644169216.0
Loss at iteration 360 : 158907940864.0
Loss at iteration 370 : 23664424960.0
Loss at iteration 380 : 115141500928.0
Loss at iteration 390 : 5711450112.0
Loss at iteration 400 : 13675648000.0
Loss at iteration 410 : 23792152576.0
Loss at iteration 420 : 616749120.0
Loss at iteration 430 : 15015290880.0
Loss at iteration 440 : 36833751040.0
Loss at iteration 450 : 86417580032.0
Loss at iteration 460 : 37241204736.0
Loss at iteration 470 : 10036129792.0
Loss at iteration 480 : 2606798471168.0
Loss at iteration 490 : 36206653440.0
Loss at iteration 500 : 169966338048.0
Loss at iteration 510 : 42573283328.0
Loss at iteration 520 : 52716642304.0
Loss at iteration 530 : 491248877568.0
Loss at iteration 540 : 3117189693440.0
Loss at iteration 550 : 214740172800.0
Loss at iteration 560 : 2154488004608.0
Loss at iteration 570 : 6652324478976.0
Loss at iteration 580 : 81284882432.0
Loss at iteration 590 : 70825451520.0
Loss at iteration 600 : 676092772352.0
Loss at iteration 610 : 1173286551552.0
Loss at iteration 620 : 32322963456.0
Loss at iteration 630 : 47627943936.0
Loss at iteration 640 : 322898526208.0
Loss at iteration 650 : 2239318720512.0
Loss at iteration 660 : 102321299456.0
Loss at iteration 670 : 8549635194880.0
Loss at iteration 680 : 112140623872.0
Loss at iteration 690 : 139347673088.0
Loss at iteration 700 : 5298322931712.0
Loss at iteration 710 : 90442047488.0
Loss at iteration 720 : 119662747648.0
Loss at iteration 730 : 3998516736.0
Loss at iteration 740 : 151923556352.0
Loss at iteration 750 : 104240275456.0
Loss at iteration 760 : 59922784256.0
Loss at iteration 770 : 9096587264.0
Loss at iteration 780 : 46410661888.0
Loss at iteration 790 : 2239892291584.0
Loss at iteration 800 : 1625312854016.0
Loss at iteration 810 : 273070784512.0
Loss at iteration 820 : 923414167552.0
Loss at iteration 830 : 50029395968.0
Loss at iteration 840 : 8742001180672.0
Loss at iteration 850 : 2942877040640.0
Loss at iteration 860 : 580041834496.0
Loss at iteration 870 : 2395107753984.0
Loss at iteration 880 : 2546424348672.0
Loss at iteration 890 : 432104177664.0
Loss at iteration 900 : 3328373686272.0
Loss at iteration 910 : 11202368372736.0
Loss at iteration 920 : 28391361216512.0
Loss at iteration 930 : 4094235246592.0
Loss at iteration 940 : 41683186089984.0
Loss at iteration 950 : 3256662884352.0
Loss at iteration 960 : 3883954601984.0
Loss at iteration 970 : 8620493242368.0
Loss at iteration 980 : 11144213299200.0
Loss at iteration 990 : 2205157949440.0
Loss at iteration 1000 : 6597169905664.0
Loss at iteration 1010 : 3540728414208.0
Loss at iteration 1020 : 29612566380544.0
Loss at iteration 1030 : 11117427425280.0
Loss at iteration 1040 : 1850697449472.0
Loss at iteration 1050 : 2137703055360.0
Loss at iteration 1060 : 9931686150144.0
Loss at iteration 1070 : 10279791362048.0
Loss at iteration 1080 : 709813927936.0
Loss at iteration 1090 : 460871630848.0
Loss at iteration 1100 : 306502991872.0
Loss at iteration 1110 : 2240011304960.0
Loss at iteration 1120 : 10848919617536.0
Loss at iteration 1130 : 613001068544.0
Loss at iteration 1140 : 350705483776.0
Loss at iteration 1150 : 1360838918144.0
Loss at iteration 1160 : 2338705637376.0
Loss at iteration 1170 : 368248684544.0
Loss at iteration 1180 : 469634809856.0
Loss at iteration 1190 : 209844928512.0
Loss at iteration 1200 : 263814692864.0
Loss at iteration 1210 : 413086744576.0
Loss at iteration 1220 : 154891010048.0
Loss at iteration 1230 : 2507992989696.0
Loss at iteration 1240 : 809710649344.0
Loss at iteration 1250 : 166724435968.0
Loss at iteration 1260 : 1108312719360.0
Loss at iteration 1270 : 557924548608.0
Loss at iteration 1280 : 7018885152768.0
Loss at iteration 1290 : 8892448768000.0
Loss at iteration 1300 : 2435691839488.0
Loss at iteration 1310 : 229781913600.0
Loss at iteration 1320 : 23693434552320.0
Loss at iteration 1330 : 1073529088901120.0
Loss at iteration 1340 : 896547982147584.0
Loss at iteration 1350 : 537018115293184.0
Loss at iteration 1360 : 838572244992.0
Loss at iteration 1370 : 9495006674944.0
Loss at iteration 1380 : 675589967052800.0
Loss at iteration 1390 : 113007627599872.0
Loss at iteration 1400 : 13805274791936.0
Loss at iteration 1410 : 183253436727296.0
Loss at iteration 1420 : 70587955281920.0
Loss at iteration 1430 : 914060279808.0
Loss at iteration 1440 : 2505949839360.0
Loss at iteration 1450 : 14581880586240.0
Loss at iteration 1460 : 2368273645568.0
Loss at iteration 1470 : 556336873472.0
Loss at iteration 1480 : 114465308672.0
Loss at iteration 1490 : 725666234368.0
Loss at iteration 1500 : 31218869469184.0
Loss at iteration 1510 : 562639863808.0
Loss at iteration 1520 : 4186753466368.0
Loss at iteration 1530 : 2862679064576.0
Loss at iteration 1540 : 9666681634816.0
Loss at iteration 1550 : 1816292229120.0
Loss at iteration 1560 : 11078296666112.0
Loss at iteration 1570 : 3194528202752.0
Loss at iteration 1580 : 9975949688832.0
Loss at iteration 1590 : 746457333760.0
Loss at iteration 1600 : 1641557262336.0
Loss at iteration 1610 : 2911752159232.0
Loss at iteration 1620 : 495033057280.0
Loss at iteration 1630 : 16543696027648.0
Loss at iteration 1640 : 1141626896384.0
Loss at iteration 1650 : 4890626621440.0
Loss at iteration 1660 : 248905744384.0
Loss at iteration 1670 : 172243320832.0
Loss at iteration 1680 : 536314445824.0
Loss at iteration 1690 : 804238000128.0
Loss at iteration 1700 : 173480886272.0
Loss at iteration 1710 : 561014439936.0
Loss at iteration 1720 : 249157550080.0
Loss at iteration 1730 : 958563090432.0
Loss at iteration 1740 : 231771291648.0
Loss at iteration 1750 : 640141361152.0
Loss at iteration 1760 : 100616339456.0
Loss at iteration 1770 : 163448717312.0
Loss at iteration 1780 : 11093210562560.0
Loss at iteration 1790 : 724168998912.0
Loss at iteration 1800 : 950548496384.0
Loss at iteration 1810 : 760103960576.0
Loss at iteration 1820 : 162444902400.0
Loss at iteration 1830 : 1464486985728.0
Loss at iteration 1840 : 286188929024.0
Loss at iteration 1850 : 89156231168.0
Loss at iteration 1860 : 173811171328.0
Loss at iteration 1870 : 592405135360.0
Loss at iteration 1880 : 147080806400.0
Loss at iteration 1890 : 4730630701056.0
Loss at iteration 1900 : 1034615586816.0
Loss at iteration 1910 : 90853834752.0
Loss at iteration 1920 : 1547017650176.0
Loss at iteration 1930 : 1922985361408.0
Loss at iteration 1940 : 655818424320.0
Loss at iteration 1950 : 103110025216.0
Loss at iteration 1960 : 10376757379072.0
Loss at iteration 1970 : 2923219648512.0
Loss at iteration 1980 : 1114158268416.0
Loss at iteration 1990 : 3283294617600.0
Loss at iteration 2000 : 123850915840.0
Loss at iteration 2010 : 1317342281728.0
Loss at iteration 2020 : 921671761920.0
Loss at iteration 2030 : 250297450496.0
Loss at iteration 2040 : 188699803648.0
Loss at iteration 2050 : 143192244224.0
Loss at iteration 2060 : 1860506353664.0
Loss at iteration 2070 : 306856361984.0
Loss at iteration 2080 : 248461770752.0
Loss at iteration 2090 : 30935255040.0
Loss at iteration 2100 : 177901993984.0
Loss at iteration 2110 : 582136692736.0
Loss at iteration 2120 : 24774668288.0
Loss at iteration 2130 : 215978721280.0
Loss at iteration 2140 : 1706388750336.0
Loss at iteration 2150 : 419285008384.0
Loss at iteration 2160 : 52139778048.0
Loss at iteration 2170 : 46919483392.0
Loss at iteration 2180 : 216516067328.0
Loss at iteration 2190 : 79423635456.0
Loss at iteration 2200 : 595434471424.0
Loss at iteration 2210 : 103974838272.0
Loss at iteration 2220 : 34348163072.0
Loss at iteration 2230 : 52941393920.0
Loss at iteration 2240 : 125090955264.0
Loss at iteration 2250 : 120283619328.0
Loss at iteration 2260 : 3845483921408.0
Loss at iteration 2270 : 12598101671936.0
Loss at iteration 2280 : 4350148608000.0
Loss at iteration 2290 : 5633594097664.0
Loss at iteration 2300 : 145768775680.0
Loss at iteration 2310 : 1446280822784.0
Loss at iteration 2320 : 1555339280384.0
Loss at iteration 2330 : 82130231296.0
Loss at iteration 2340 : 1272899305472.0
Loss at iteration 2350 : 174415790080.0
Loss at iteration 2360 : 692071301120.0
Loss at iteration 2370 : 2443822497792.0
Loss at iteration 2380 : 541364060160.0
Loss at iteration 2390 : 87794466816.0
Loss at iteration 2400 : 2717999955968.0
Loss at iteration 2410 : 1787276034048.0
Loss at iteration 2420 : 57361121280.0
The SSIM Value is: -6.944394370596759e-06
The PSNR Value is: -127.78541717529296
the epoch is: 145
Loss at iteration 10 : 1163306991616.0
Loss at iteration 20 : 318712479744.0
Loss at iteration 30 : 680637956096.0
Loss at iteration 40 : 317411491840.0
Loss at iteration 50 : 4499688128512.0
Loss at iteration 60 : 150634725376.0
Loss at iteration 70 : 1462231498752.0
Loss at iteration 80 : 2093664436224.0
Loss at iteration 90 : 1116226453504.0
Loss at iteration 100 : 902795821056.0
Loss at iteration 110 : 222440325120.0
Loss at iteration 120 : 336789340160.0
Loss at iteration 130 : 420103061504.0
Loss at iteration 140 : 116802625536.0
Loss at iteration 150 : 1259684495360.0
Loss at iteration 160 : 2636095422464.0
Loss at iteration 170 : 176106700800.0
Loss at iteration 180 : 600178491392.0
Loss at iteration 190 : 817487609856.0
Loss at iteration 200 : 208340320256.0
Loss at iteration 210 : 295025475584.0
Loss at iteration 220 : 75000242176.0
Loss at iteration 230 : 5464503353344.0
Loss at iteration 240 : 1066070179840.0
Loss at iteration 250 : 2440373207040.0
Loss at iteration 260 : 151303356416.0
Loss at iteration 270 : 124167561216.0
Loss at iteration 280 : 1314272051200.0
Loss at iteration 290 : 5124538761216.0
Loss at iteration 300 : 355819683840.0
Loss at iteration 310 : 147854917632.0
Loss at iteration 320 : 80004644864.0
Loss at iteration 330 : 155683897344.0
Loss at iteration 340 : 1635154526208.0
Loss at iteration 350 : 146688081920.0
Loss at iteration 360 : 53513928704.0
Loss at iteration 370 : 51393380352.0
Loss at iteration 380 : 760552226816.0
Loss at iteration 390 : 162343124992.0
Loss at iteration 400 : 470172041216.0
Loss at iteration 410 : 1913195986944.0
Loss at iteration 420 : 729708494848.0
Loss at iteration 430 : 3198605328384.0
Loss at iteration 440 : 217835892637696.0
Loss at iteration 450 : 931765908668416.0
Loss at iteration 460 : 82816614400.0
Loss at iteration 470 : 32929191297024.0
Loss at iteration 480 : 4607275171840.0
Loss at iteration 490 : 5923395338240.0
Loss at iteration 500 : 1628330000384.0
Loss at iteration 510 : 782155317248.0
Loss at iteration 520 : 807914242048.0
Loss at iteration 530 : 378092158976.0
Loss at iteration 540 : 215617978368.0
Loss at iteration 550 : 1685987524608.0
Loss at iteration 560 : 2807205986304.0
Loss at iteration 570 : 162378924032.0
Loss at iteration 580 : 134049325056.0
Loss at iteration 590 : 318259003392.0
Loss at iteration 600 : 1012183531520.0
Loss at iteration 610 : 68637945856.0
Loss at iteration 620 : 16275427328.0
Loss at iteration 630 : 74629881856.0
Loss at iteration 640 : 29849884672.0
Loss at iteration 650 : 127869108224.0
Loss at iteration 660 : 203909922816.0
Loss at iteration 670 : 130419236864.0
Loss at iteration 680 : 4881530880.0
Loss at iteration 690 : 460726501376.0
Loss at iteration 700 : 12592307200.0
Loss at iteration 710 : 167042351104.0
Loss at iteration 720 : 407541874688.0
Loss at iteration 730 : 314004471808.0
Loss at iteration 740 : 139797151744.0
Loss at iteration 750 : 210043928576.0
Loss at iteration 760 : 142903590912.0
Loss at iteration 770 : 61322969088.0
Loss at iteration 780 : 129437859840.0
Loss at iteration 790 : 614381060096.0
Loss at iteration 800 : 342526033920.0
Loss at iteration 810 : 256125747200.0
Loss at iteration 820 : 24713433088.0
Loss at iteration 830 : 328485470208.0
Loss at iteration 840 : 155041972224.0
Loss at iteration 850 : 197083316224.0
Loss at iteration 860 : 351502663680.0
Loss at iteration 870 : 126450556928.0
Loss at iteration 880 : 85469700096.0
Loss at iteration 890 : 1424803627008.0
Loss at iteration 900 : 75477164032.0
Loss at iteration 910 : 118467543040.0
Loss at iteration 920 : 153744326656.0
Loss at iteration 930 : 332049940480.0
Loss at iteration 940 : 23431954432.0
Loss at iteration 950 : 31198709760.0
Loss at iteration 960 : 271521038336.0
Loss at iteration 970 : 216397938688.0
Loss at iteration 980 : 91897954304.0
Loss at iteration 990 : 128431579136.0
Loss at iteration 1000 : 19801163776.0
Loss at iteration 1010 : 104425373696.0
Loss at iteration 1020 : 541267001344.0
Loss at iteration 1030 : 39081807872.0
Loss at iteration 1040 : 56829845504.0
Loss at iteration 1050 : 71406313472.0
Loss at iteration 1060 : 1331905036288.0
Loss at iteration 1070 : 13129077489664.0
Loss at iteration 1080 : 15233850540032.0
Loss at iteration 1090 : 336140280266752.0
Loss at iteration 1100 : 7174030884864.0
Loss at iteration 1110 : 9068284477440.0
Loss at iteration 1120 : 1853558095872.0
Loss at iteration 1130 : 13141097316352.0
Loss at iteration 1140 : 407934599168.0
Loss at iteration 1150 : 6410294788096.0
Loss at iteration 1160 : 1553337155584.0
Loss at iteration 1170 : 3628404834304.0
Loss at iteration 1180 : 347517517824.0
Loss at iteration 1190 : 1635260694528.0
Loss at iteration 1200 : 862160814080.0
Loss at iteration 1210 : 8278691020800.0
Loss at iteration 1220 : 18058439557120.0
Loss at iteration 1230 : 26275181756416.0
Loss at iteration 1240 : 4466087559168.0
Loss at iteration 1250 : 521159213056.0
Loss at iteration 1260 : 136327512064.0
Loss at iteration 1270 : 374853566464.0
Loss at iteration 1280 : 4486085476352.0
Loss at iteration 1290 : 21813004288.0
Loss at iteration 1300 : 188258385920.0
Loss at iteration 1310 : 70905536512.0
Loss at iteration 1320 : 845220282368.0
Loss at iteration 1330 : 146905464832.0
Loss at iteration 1340 : 1436162326528.0
Loss at iteration 1350 : 4973758775296.0
Loss at iteration 1360 : 9926942392320.0
Loss at iteration 1370 : 595157778432.0
Loss at iteration 1380 : 161903788032.0
Loss at iteration 1390 : 2164816609280.0
Loss at iteration 1400 : 3926322053120.0
Loss at iteration 1410 : 79544942592.0
Loss at iteration 1420 : 200420048896.0
Loss at iteration 1430 : 594321145856.0
Loss at iteration 1440 : 915513868288.0
Loss at iteration 1450 : 2835199557632.0
Loss at iteration 1460 : 497619337216.0
Loss at iteration 1470 : 773220728832.0
Loss at iteration 1480 : 1300128333824.0
Loss at iteration 1490 : 132780146688.0
Loss at iteration 1500 : 49450668032.0
Loss at iteration 1510 : 371503005696.0
Loss at iteration 1520 : 4439720067072.0
Loss at iteration 1530 : 4173667500032.0
Loss at iteration 1540 : 3078812598272.0
Loss at iteration 1550 : 780745244672.0
Loss at iteration 1560 : 494567063552.0
Loss at iteration 1570 : 580098457600.0
Loss at iteration 1580 : 511595511808.0
Loss at iteration 1590 : 188991619072.0
Loss at iteration 1600 : 762649772032.0
Loss at iteration 1610 : 701166452736.0
Loss at iteration 1620 : 1290627186688.0
Loss at iteration 1630 : 210249252864.0
Loss at iteration 1640 : 337909383168.0
Loss at iteration 1650 : 37494517760.0
Loss at iteration 1660 : 199933558784.0
Loss at iteration 1670 : 486752714752.0
Loss at iteration 1680 : 224905248768.0
Loss at iteration 1690 : 429574815744.0
Loss at iteration 1700 : 96888127488.0
Loss at iteration 1710 : 419956391936.0
Loss at iteration 1720 : 39254007808.0
Loss at iteration 1730 : 730056753152.0
Loss at iteration 1740 : 381960781824.0
Loss at iteration 1750 : 3687306493952.0
Loss at iteration 1760 : 4113684234240.0
Loss at iteration 1770 : 7274862477312.0
Loss at iteration 1780 : 8052676755456.0
Loss at iteration 1790 : 18482963939328.0
Loss at iteration 1800 : 1226472816640.0
Loss at iteration 1810 : 4611854827520.0
Loss at iteration 1820 : 4389909823488.0
Loss at iteration 1830 : 3906266726400.0
Loss at iteration 1840 : 5752205344768.0
Loss at iteration 1850 : 397240827904.0
Loss at iteration 1860 : 348643295232.0
Loss at iteration 1870 : 4150583623680.0
Loss at iteration 1880 : 1627402141696.0
Loss at iteration 1890 : 352075874304.0
Loss at iteration 1900 : 1257176170496.0
Loss at iteration 1910 : 210659934208.0
Loss at iteration 1920 : 54001924046848.0
Loss at iteration 1930 : 48322765127680.0
Loss at iteration 1940 : 7450036011008.0
Loss at iteration 1950 : 80866107392.0
Loss at iteration 1960 : 1210486882304.0
Loss at iteration 1970 : 2145210466304.0
Loss at iteration 1980 : 1826263531520.0
Loss at iteration 1990 : 548250124288.0
Loss at iteration 2000 : 73918586880.0
Loss at iteration 2010 : 231058234671104.0
Loss at iteration 2020 : 898800418816.0
Loss at iteration 2030 : 380306685952.0
Loss at iteration 2040 : 32117604352.0
Loss at iteration 2050 : 3633389240320.0
Loss at iteration 2060 : 3280787996672.0
Loss at iteration 2070 : 608594493440.0
Loss at iteration 2080 : 782704377856.0
Loss at iteration 2090 : 316773695488.0
Loss at iteration 2100 : 55288852480.0
Loss at iteration 2110 : 361358098432.0
Loss at iteration 2120 : 537129943040.0
Loss at iteration 2130 : 158877974528.0
Loss at iteration 2140 : 213705375744.0
Loss at iteration 2150 : 45497245696.0
Loss at iteration 2160 : 386136211456.0
Loss at iteration 2170 : 650770186240.0
Loss at iteration 2180 : 1349737775104.0
Loss at iteration 2190 : 399202680832.0
Loss at iteration 2200 : 794941456384.0
Loss at iteration 2210 : 245524430848.0
Loss at iteration 2220 : 323447914496.0
Loss at iteration 2230 : 1367245717504.0
Loss at iteration 2240 : 320641302528.0
Loss at iteration 2250 : 268319424512.0
Loss at iteration 2260 : 2029529202688.0
Loss at iteration 2270 : 946351767552.0
Loss at iteration 2280 : 1911713693696.0
Loss at iteration 2290 : 1841404182528.0
Loss at iteration 2300 : 93080150016.0
Loss at iteration 2310 : 1277763911680.0
Loss at iteration 2320 : 361709109248.0
Loss at iteration 2330 : 271070347264.0
Loss at iteration 2340 : 5493125283840.0
Loss at iteration 2350 : 1382247563264.0
Loss at iteration 2360 : 116157956096.0
Loss at iteration 2370 : 577364885504.0
Loss at iteration 2380 : 85856919552.0
Loss at iteration 2390 : 997066801152.0
Loss at iteration 2400 : 417794392064.0
Loss at iteration 2410 : 125815595008.0
Loss at iteration 2420 : 210837815296.0
The SSIM Value is: 6.5607297944580974e-06
The PSNR Value is: -121.83245900472005
the epoch is: 146
Loss at iteration 10 : 207156133888.0
Loss at iteration 20 : 256964624384.0
Loss at iteration 30 : 960061898752.0
Loss at iteration 40 : 226650423296.0
Loss at iteration 50 : 408245403648.0
Loss at iteration 60 : 207624650752.0
Loss at iteration 70 : 574231543808.0
Loss at iteration 80 : 52237283328.0
Loss at iteration 90 : 278263463936.0
Loss at iteration 100 : 412474343424.0
Loss at iteration 110 : 657558470656.0
Loss at iteration 120 : 205639647232.0
Loss at iteration 130 : 667293974528.0
Loss at iteration 140 : 348049375232.0
Loss at iteration 150 : 1242664009728.0
Loss at iteration 160 : 311309434880.0
Loss at iteration 170 : 110006083584.0
Loss at iteration 180 : 8205275496448.0
Loss at iteration 190 : 271384576000.0
Loss at iteration 200 : 276078362624.0
Loss at iteration 210 : 115279405056.0
Loss at iteration 220 : 67197562880.0
Loss at iteration 230 : 50309513216.0
Loss at iteration 240 : 739235004416.0
Loss at iteration 250 : 227199713280.0
Loss at iteration 260 : 144444866560.0
Loss at iteration 270 : 138084679680.0
Loss at iteration 280 : 628966096896.0
Loss at iteration 290 : 242003935232.0
Loss at iteration 300 : 284867461120.0
Loss at iteration 310 : 6913265238016.0
Loss at iteration 320 : 1849996214272.0
Loss at iteration 330 : 140556746752.0
Loss at iteration 340 : 8903406387200.0
Loss at iteration 350 : 207500984320.0
Loss at iteration 360 : 1189351784448.0
Loss at iteration 370 : 7843479040.0
Loss at iteration 380 : 183036821504.0
Loss at iteration 390 : 18551289856.0
Loss at iteration 400 : 60070645760.0
Loss at iteration 410 : 27541626880.0
Loss at iteration 420 : 7316500480.0
Loss at iteration 430 : 4860975513600.0
Loss at iteration 440 : 25788876800.0
Loss at iteration 450 : 362500620288.0
Loss at iteration 460 : 73136300032.0
Loss at iteration 470 : 61491171328.0
Loss at iteration 480 : 183348346880.0
Loss at iteration 490 : 553337028608.0
Loss at iteration 500 : 986792132608.0
Loss at iteration 510 : 291108093952.0
Loss at iteration 520 : 52958339072.0
Loss at iteration 530 : 57285529600.0
Loss at iteration 540 : 14249094144.0
Loss at iteration 550 : 361549004800.0
Loss at iteration 560 : 27028926464.0
Loss at iteration 570 : 66883477504.0
Loss at iteration 580 : 143963111424.0
Loss at iteration 590 : 81058119680.0
Loss at iteration 600 : 695221420032.0
Loss at iteration 610 : 938372104192.0
Loss at iteration 620 : 250297237504.0
Loss at iteration 630 : 146617057280.0
Loss at iteration 640 : 52759584768.0
Loss at iteration 650 : 100823326720.0
Loss at iteration 660 : 35081117696.0
Loss at iteration 670 : 287191040000.0
Loss at iteration 680 : 57808031744.0
Loss at iteration 690 : 83362545664.0
Loss at iteration 700 : 29460332544.0
Loss at iteration 710 : 218625441792.0
Loss at iteration 720 : 180559708160.0
Loss at iteration 730 : 152825380864.0
Loss at iteration 740 : 142807367680.0
Loss at iteration 750 : 115442810880.0
Loss at iteration 760 : 6043289088.0
Loss at iteration 770 : 22076518400.0
Loss at iteration 780 : 57802489856.0
Loss at iteration 790 : 3301381505024.0
Loss at iteration 800 : 4130759168.0
Loss at iteration 810 : 53883424768.0
Loss at iteration 820 : 170694393856.0
Loss at iteration 830 : 93101228032.0
Loss at iteration 840 : 216516395008.0
Loss at iteration 850 : 20249001984.0
Loss at iteration 860 : 420189732864.0
Loss at iteration 870 : 237377765376.0
Loss at iteration 880 : 72106033152.0
Loss at iteration 890 : 53638184960.0
Loss at iteration 900 : 85093187584.0
Loss at iteration 910 : 142545207296.0
Loss at iteration 920 : 40067358720.0
Loss at iteration 930 : 2033790353408.0
Loss at iteration 940 : 112588439552.0
Loss at iteration 950 : 119234232320.0
Loss at iteration 960 : 78746697728.0
Loss at iteration 970 : 224766164992.0
Loss at iteration 980 : 56833658880.0
Loss at iteration 990 : 86215860224.0
Loss at iteration 1000 : 48468492288.0
Loss at iteration 1010 : 51025883136.0
Loss at iteration 1020 : 95981068288.0
Loss at iteration 1030 : 27356450816.0
Loss at iteration 1040 : 317609639936.0
Loss at iteration 1050 : 13732355072.0
Loss at iteration 1060 : 85844262912.0
Loss at iteration 1070 : 1001859055616.0
Loss at iteration 1080 : 267481825280.0
Loss at iteration 1090 : 104414797824.0
Loss at iteration 1100 : 69191401472.0
Loss at iteration 1110 : 101331181568.0
Loss at iteration 1120 : 26338541568.0
Loss at iteration 1130 : 141062160384.0
Loss at iteration 1140 : 156468936704.0
Loss at iteration 1150 : 28348407808.0
Loss at iteration 1160 : 61074239488.0
Loss at iteration 1170 : 46760591360.0
Loss at iteration 1180 : 83626016768.0
Loss at iteration 1190 : 30854567936.0
Loss at iteration 1200 : 36421562368.0
Loss at iteration 1210 : 240494379008.0
Loss at iteration 1220 : 138592665600.0
Loss at iteration 1230 : 97518370816.0
Loss at iteration 1240 : 225367638016.0
Loss at iteration 1250 : 15993279488.0
Loss at iteration 1260 : 171898699776.0
Loss at iteration 1270 : 105948954624.0
Loss at iteration 1280 : 36330332160.0
Loss at iteration 1290 : 55020060672.0
Loss at iteration 1300 : 186036224000.0
Loss at iteration 1310 : 43058745344.0
Loss at iteration 1320 : 1513292955648.0
Loss at iteration 1330 : 182224945152.0
Loss at iteration 1340 : 76172845056.0
Loss at iteration 1350 : 67401945088.0
Loss at iteration 1360 : 187922268160.0
Loss at iteration 1370 : 387780214784.0
Loss at iteration 1380 : 110104182784.0
Loss at iteration 1390 : 286368661504.0
Loss at iteration 1400 : 41545760768.0
Loss at iteration 1410 : 89381298176.0
Loss at iteration 1420 : 84793147392.0
Loss at iteration 1430 : 189112385536.0
Loss at iteration 1440 : 30280826880.0
Loss at iteration 1450 : 16776980480.0
Loss at iteration 1460 : 215795892224.0
Loss at iteration 1470 : 101728747520.0
Loss at iteration 1480 : 56043307008.0
Loss at iteration 1490 : 7267012608.0
Loss at iteration 1500 : 19982950400.0
Loss at iteration 1510 : 158493671424.0
Loss at iteration 1520 : 100077805568.0
Loss at iteration 1530 : 512204177408.0
Loss at iteration 1540 : 151948984320.0
Loss at iteration 1550 : 53764390912.0
Loss at iteration 1560 : 140542132224.0
Loss at iteration 1570 : 898017001472.0
Loss at iteration 1580 : 362175594496.0
Loss at iteration 1590 : 25746523291648.0
Loss at iteration 1600 : 463604678656.0
Loss at iteration 1610 : 37414785024.0
Loss at iteration 1620 : 494122434560.0
Loss at iteration 1630 : 189161013248.0
Loss at iteration 1640 : 1136659922944.0
Loss at iteration 1650 : 8517164990464.0
Loss at iteration 1660 : 112220071526400.0
Loss at iteration 1670 : 5760867106816.0
Loss at iteration 1680 : 1483404476416.0
Loss at iteration 1690 : 2272357253120.0
Loss at iteration 1700 : 5852017197056.0
Loss at iteration 1710 : 967901511680.0
Loss at iteration 1720 : 6892181520384.0
Loss at iteration 1730 : 8861017702400.0
Loss at iteration 1740 : 3655944110080.0
Loss at iteration 1750 : 2864780935168.0
Loss at iteration 1760 : 8365352157184.0
Loss at iteration 1770 : 1072869801984.0
Loss at iteration 1780 : 262480265216.0
Loss at iteration 1790 : 2516067811328.0
Loss at iteration 1800 : 129301864448.0
Loss at iteration 1810 : 2733016350720.0
Loss at iteration 1820 : 1089336639488.0
Loss at iteration 1830 : 679212089344.0
Loss at iteration 1840 : 150250307584.0
Loss at iteration 1850 : 2219776933888.0
Loss at iteration 1860 : 365309689856.0
Loss at iteration 1870 : 319884853248.0
Loss at iteration 1880 : 67355840512.0
Loss at iteration 1890 : 353450983424.0
Loss at iteration 1900 : 173671071744.0
Loss at iteration 1910 : 587762368512.0
Loss at iteration 1920 : 73587236864.0
Loss at iteration 1930 : 265035808768.0
Loss at iteration 1940 : 1031049117696.0
Loss at iteration 1950 : 472513806336.0
Loss at iteration 1960 : 3448916148224.0
Loss at iteration 1970 : 2833907712000.0
Loss at iteration 1980 : 33443565568.0
Loss at iteration 1990 : 6582361600.0
Loss at iteration 2000 : 83026092032.0
Loss at iteration 2010 : 89223995392.0
Loss at iteration 2020 : 12398905786368.0
Loss at iteration 2030 : 2135460020224.0
Loss at iteration 2040 : 1506602385408.0
Loss at iteration 2050 : 175647375360.0
Loss at iteration 2060 : 43387838464.0
Loss at iteration 2070 : 453329813504.0
Loss at iteration 2080 : 301101809664.0
Loss at iteration 2090 : 26855071744.0
Loss at iteration 2100 : 299396857856.0
Loss at iteration 2110 : 52114616320.0
Loss at iteration 2120 : 20061032448.0
Loss at iteration 2130 : 30113525760.0
Loss at iteration 2140 : 39010414592.0
Loss at iteration 2150 : 2187549343744.0
Loss at iteration 2160 : 565526069248.0
Loss at iteration 2170 : 13508434460672.0
Loss at iteration 2180 : 2631385481216.0
Loss at iteration 2190 : 449137803264.0
Loss at iteration 2200 : 2627870392320.0
Loss at iteration 2210 : 208473341952.0
Loss at iteration 2220 : 88935342080.0
Loss at iteration 2230 : 230617022464.0
Loss at iteration 2240 : 1186436349952.0
Loss at iteration 2250 : 226216968192.0
Loss at iteration 2260 : 205681950720.0
Loss at iteration 2270 : 49889787904.0
Loss at iteration 2280 : 2794031415296.0
Loss at iteration 2290 : 195215572992.0
Loss at iteration 2300 : 2911195365376.0
Loss at iteration 2310 : 2033188077568.0
Loss at iteration 2320 : 83753009152.0
Loss at iteration 2330 : 433707286528.0
Loss at iteration 2340 : 29282482176.0
Loss at iteration 2350 : 234909433856.0
Loss at iteration 2360 : 57356828672.0
Loss at iteration 2370 : 106426744832.0
Loss at iteration 2380 : 81326473216.0
Loss at iteration 2390 : 177942446080.0
Loss at iteration 2400 : 24766066688.0
Loss at iteration 2410 : 204912508928.0
Loss at iteration 2420 : 141379485696.0
The SSIM Value is: 1.9846104976295465e-06
The PSNR Value is: -119.26519012451172
the epoch is: 147
Loss at iteration 10 : 486590251008.0
Loss at iteration 20 : 695164207104.0
Loss at iteration 30 : 28603322368.0
Loss at iteration 40 : 65354555392.0
Loss at iteration 50 : 120259731456.0
Loss at iteration 60 : 409923485696.0
Loss at iteration 70 : 394378543104.0
Loss at iteration 80 : 11272801280.0
Loss at iteration 90 : 12301434880.0
Loss at iteration 100 : 47912218624.0
Loss at iteration 110 : 86074056704.0
Loss at iteration 120 : 119339606016.0
Loss at iteration 130 : 1071529590784.0
Loss at iteration 140 : 259485188096.0
Loss at iteration 150 : 128639737856.0
Loss at iteration 160 : 52862337024.0
Loss at iteration 170 : 18876649472.0
Loss at iteration 180 : 94677475328.0
Loss at iteration 190 : 79140003840.0
Loss at iteration 200 : 46714458112.0
Loss at iteration 210 : 282077691904.0
Loss at iteration 220 : 130812534784.0
Loss at iteration 230 : 37144211456.0
Loss at iteration 240 : 145036296192.0
Loss at iteration 250 : 89219194880.0
Loss at iteration 260 : 477353312256.0
Loss at iteration 270 : 37372141568.0
Loss at iteration 280 : 26528378880.0
Loss at iteration 290 : 19627456512.0
Loss at iteration 300 : 21141766144.0
Loss at iteration 310 : 47166042112.0
Loss at iteration 320 : 4253629440.0
Loss at iteration 330 : 182711697408.0
Loss at iteration 340 : 32130281472.0
Loss at iteration 350 : 87104225280.0
Loss at iteration 360 : 112024051712.0
Loss at iteration 370 : 36202934272.0
Loss at iteration 380 : 16298360832.0
Loss at iteration 390 : 4838509056.0
Loss at iteration 400 : 9176687616.0
Loss at iteration 410 : 22432753664.0
Loss at iteration 420 : 16692508672.0
Loss at iteration 430 : 2244629495808.0
Loss at iteration 440 : 144779657216.0
Loss at iteration 450 : 71504773120.0
Loss at iteration 460 : 43645292544.0
Loss at iteration 470 : 42715697152.0
Loss at iteration 480 : 445623173120.0
Loss at iteration 490 : 117021138944.0
Loss at iteration 500 : 27368278016.0
Loss at iteration 510 : 115670048768.0
Loss at iteration 520 : 78763786240.0
Loss at iteration 530 : 128235552768.0
Loss at iteration 540 : 835255205888.0
Loss at iteration 550 : 141006602240.0
Loss at iteration 560 : 57783222272.0
Loss at iteration 570 : 9375372288.0
Loss at iteration 580 : 18184419328.0
Loss at iteration 590 : 7961973248.0
Loss at iteration 600 : 36233293824.0
Loss at iteration 610 : 631966728192.0
Loss at iteration 620 : 10453376000.0
Loss at iteration 630 : 941159809024.0
Loss at iteration 640 : 597325185024.0
Loss at iteration 650 : 29032568832.0
Loss at iteration 660 : 75849416704.0
Loss at iteration 670 : 182075441152.0
Loss at iteration 680 : 505945915392.0
Loss at iteration 690 : 300828295168.0
Loss at iteration 700 : 120442642432.0
Loss at iteration 710 : 70601629696.0
Loss at iteration 720 : 71476846592.0
Loss at iteration 730 : 59774427136.0
Loss at iteration 740 : 261611126784.0
Loss at iteration 750 : 26066085888.0
Loss at iteration 760 : 60173307904.0
Loss at iteration 770 : 434974851072.0
Loss at iteration 780 : 12316506112.0
Loss at iteration 790 : 10604938240.0
Loss at iteration 800 : 3116998656.0
Loss at iteration 810 : 5308772352.0
Loss at iteration 820 : 2856200192.0
Loss at iteration 830 : 107043586048.0
Loss at iteration 840 : 26206844928.0
Loss at iteration 850 : 7375301120.0
Loss at iteration 860 : 81994170368.0
Loss at iteration 870 : 106975903744.0
Loss at iteration 880 : 14381963264.0
Loss at iteration 890 : 1904648576.0
Loss at iteration 900 : 56953389056.0
Loss at iteration 910 : 7037640192.0
Loss at iteration 920 : 25355778048.0
Loss at iteration 930 : 1960794624.0
Loss at iteration 940 : 43503521792.0
Loss at iteration 950 : 14030092288.0
Loss at iteration 960 : 35261444096.0
Loss at iteration 970 : 33171529728.0
Loss at iteration 980 : 8905607168.0
Loss at iteration 990 : 20063557632.0
Loss at iteration 1000 : 26642008064.0
Loss at iteration 1010 : 10228667392.0
Loss at iteration 1020 : 11270718464.0
Loss at iteration 1030 : 2591481856.0
Loss at iteration 1040 : 19496230912.0
Loss at iteration 1050 : 13370055680.0
Loss at iteration 1060 : 41991954432.0
Loss at iteration 1070 : 1506409856.0
Loss at iteration 1080 : 13086775296.0
Loss at iteration 1090 : 3415287040.0
Loss at iteration 1100 : 47634845696.0
Loss at iteration 1110 : 186540949504.0
Loss at iteration 1120 : 22621687808.0
Loss at iteration 1130 : 74202046464.0
Loss at iteration 1140 : 14486680576.0
Loss at iteration 1150 : 864853952.0
Loss at iteration 1160 : 3015263744.0
Loss at iteration 1170 : 15413550080.0
Loss at iteration 1180 : 1825927296.0
Loss at iteration 1190 : 4989472768.0
Loss at iteration 1200 : 43904450560.0
Loss at iteration 1210 : 17942026240.0
Loss at iteration 1220 : 34367795200.0
Loss at iteration 1230 : 235616092160.0
Loss at iteration 1240 : 26526386176.0
Loss at iteration 1250 : 7624676352.0
Loss at iteration 1260 : 12604524544.0
Loss at iteration 1270 : 4276468480.0
Loss at iteration 1280 : 3974965504.0
Loss at iteration 1290 : 608633280.0
Loss at iteration 1300 : 6813312000.0
Loss at iteration 1310 : 686557952.0
Loss at iteration 1320 : 2017216256.0
Loss at iteration 1330 : 3516392448.0
Loss at iteration 1340 : 354673504.0
Loss at iteration 1350 : 23243200512.0
Loss at iteration 1360 : 18594641920.0
Loss at iteration 1370 : 23822090240.0
Loss at iteration 1380 : 20330215424.0
Loss at iteration 1390 : 29392707584.0
Loss at iteration 1400 : 100012048384.0
Loss at iteration 1410 : 9390002176.0
Loss at iteration 1420 : 10552446976.0
Loss at iteration 1430 : 58500857856.0
Loss at iteration 1440 : 4556579328.0
Loss at iteration 1450 : 4323161088.0
Loss at iteration 1460 : 40424960000.0
Loss at iteration 1470 : 33733773312.0
Loss at iteration 1480 : 375493088.0
Loss at iteration 1490 : 1820998912.0
Loss at iteration 1500 : 401913920.0
Loss at iteration 1510 : 155012792320.0
Loss at iteration 1520 : 1554673152.0
Loss at iteration 1530 : 15020763136.0
Loss at iteration 1540 : 32120608768.0
Loss at iteration 1550 : 12044567552.0
Loss at iteration 1560 : 2485515008.0
Loss at iteration 1570 : 22870003712.0
Loss at iteration 1580 : 9184293888.0
Loss at iteration 1590 : 27239063552.0
Loss at iteration 1600 : 52611964928.0
Loss at iteration 1610 : 36145451008.0
Loss at iteration 1620 : 1342334592.0
Loss at iteration 1630 : 18020114432.0
Loss at iteration 1640 : 1601839360.0
Loss at iteration 1650 : 47458263040.0
Loss at iteration 1660 : 1699159552.0
Loss at iteration 1670 : 93463609344.0
Loss at iteration 1680 : 114533548032.0
Loss at iteration 1690 : 32119052288.0
Loss at iteration 1700 : 41211928576.0
Loss at iteration 1710 : 18715664384.0
Loss at iteration 1720 : 30756786176.0
Loss at iteration 1730 : 86013313024.0
Loss at iteration 1740 : 119169179648.0
Loss at iteration 1750 : 33112012800.0
Loss at iteration 1760 : 341594046464.0
Loss at iteration 1770 : 5474077696.0
Loss at iteration 1780 : 2763033600.0
Loss at iteration 1790 : 47231533056.0
Loss at iteration 1800 : 10595277824.0
Loss at iteration 1810 : 31014320128.0
Loss at iteration 1820 : 69777530880.0
Loss at iteration 1830 : 231074840576.0
Loss at iteration 1840 : 31785660416.0
Loss at iteration 1850 : 49584775168.0
Loss at iteration 1860 : 38158585856.0
Loss at iteration 1870 : 175352872960.0
Loss at iteration 1880 : 91839373312.0
Loss at iteration 1890 : 41497337856.0
Loss at iteration 1900 : 77515923456.0
Loss at iteration 1910 : 227138912256.0
Loss at iteration 1920 : 21476169728.0
Loss at iteration 1930 : 30383316992.0
Loss at iteration 1940 : 13383158784.0
Loss at iteration 1950 : 116670824448.0
Loss at iteration 1960 : 9839080448.0
Loss at iteration 1970 : 5000623616.0
Loss at iteration 1980 : 14992868352.0
Loss at iteration 1990 : 50226135040.0
Loss at iteration 2000 : 40979730432.0
Loss at iteration 2010 : 6349058560.0
Loss at iteration 2020 : 18011080704.0
Loss at iteration 2030 : 12536702976.0
Loss at iteration 2040 : 26577154048.0
Loss at iteration 2050 : 951865966592.0
Loss at iteration 2060 : 168550940672.0
Loss at iteration 2070 : 12121623552.0
Loss at iteration 2080 : 50980487168.0
Loss at iteration 2090 : 18207623168.0
Loss at iteration 2100 : 208393781248.0
Loss at iteration 2110 : 9981306880.0
Loss at iteration 2120 : 25647761408.0
Loss at iteration 2130 : 2769381120.0
Loss at iteration 2140 : 63482949632.0
Loss at iteration 2150 : 14361066496.0
Loss at iteration 2160 : 51882819584.0
Loss at iteration 2170 : 15339046912.0
Loss at iteration 2180 : 97855725568.0
Loss at iteration 2190 : 10869614592.0
Loss at iteration 2200 : 55067029504.0
Loss at iteration 2210 : 33879308288.0
Loss at iteration 2220 : 6817804288.0
Loss at iteration 2230 : 28186439680.0
Loss at iteration 2240 : 2889694976.0
Loss at iteration 2250 : 3345697280.0
Loss at iteration 2260 : 24295520256.0
Loss at iteration 2270 : 70949830656.0
Loss at iteration 2280 : 7054121472.0
Loss at iteration 2290 : 42193793024.0
Loss at iteration 2300 : 4253517312.0
Loss at iteration 2310 : 2212678912.0
Loss at iteration 2320 : 1232115990528.0
Loss at iteration 2330 : 8450555392.0
Loss at iteration 2340 : 25435469824.0
Loss at iteration 2350 : 448517406720.0
Loss at iteration 2360 : 60758622208.0
Loss at iteration 2370 : 5439759872.0
Loss at iteration 2380 : 3619396255744.0
Loss at iteration 2390 : 31931736064.0
Loss at iteration 2400 : 8192584704.0
Loss at iteration 2410 : 13611107328.0
Loss at iteration 2420 : 27118215168.0
The SSIM Value is: 1.4159018593318252e-05
The PSNR Value is: -116.65045776367188
the epoch is: 148
Loss at iteration 10 : 39566057472.0
Loss at iteration 20 : 39064084480.0
Loss at iteration 30 : 13596229632.0
Loss at iteration 40 : 105979273216.0
Loss at iteration 50 : 58654019584.0
Loss at iteration 60 : 90607099904.0
Loss at iteration 70 : 20560033792.0
Loss at iteration 80 : 4592296960.0
Loss at iteration 90 : 19308736512.0
Loss at iteration 100 : 19358820352.0
Loss at iteration 110 : 18251433984.0
Loss at iteration 120 : 30633695232.0
Loss at iteration 130 : 58780524544.0
Loss at iteration 140 : 211707887616.0
Loss at iteration 150 : 9291022336.0
Loss at iteration 160 : 21954287616.0
Loss at iteration 170 : 35450851328.0
Loss at iteration 180 : 426125230080.0
Loss at iteration 190 : 301736558592.0
Loss at iteration 200 : 163798564864.0
Loss at iteration 210 : 72880103424.0
Loss at iteration 220 : 57460891648.0
Loss at iteration 230 : 18369196032.0
Loss at iteration 240 : 76652666880.0
Loss at iteration 250 : 2525468160.0
Loss at iteration 260 : 16832798720.0
Loss at iteration 270 : 62961238016.0
Loss at iteration 280 : 22632542208.0
Loss at iteration 290 : 49410330624.0
Loss at iteration 300 : 28542883840.0
Loss at iteration 310 : 26058938368.0
Loss at iteration 320 : 13562104832.0
Loss at iteration 330 : 1586009997312.0
Loss at iteration 340 : 106836189184.0
Loss at iteration 350 : 6950827008.0
Loss at iteration 360 : 61693874176.0
Loss at iteration 370 : 19387604992.0
Loss at iteration 380 : 4926909440.0
Loss at iteration 390 : 12156069888.0
Loss at iteration 400 : 5939179520.0
Loss at iteration 410 : 17048327168.0
Loss at iteration 420 : 4762647552.0
Loss at iteration 430 : 470785632.0
Loss at iteration 440 : 270168608.0
Loss at iteration 450 : 21418475520.0
Loss at iteration 460 : 19768002560.0
Loss at iteration 470 : 21209157632.0
Loss at iteration 480 : 15814237184.0
Loss at iteration 490 : 60891467776.0
Loss at iteration 500 : 53966352384.0
Loss at iteration 510 : 47835852.0
Loss at iteration 520 : 859507456.0
Loss at iteration 530 : 45794426880.0
Loss at iteration 540 : 3243026432.0
Loss at iteration 550 : 1911456128.0
Loss at iteration 560 : 35600461824.0
Loss at iteration 570 : 58855641088.0
Loss at iteration 580 : 21439932416.0
Loss at iteration 590 : 105148512.0
Loss at iteration 600 : 6719373824.0
Loss at iteration 610 : 6119716864.0
Loss at iteration 620 : 12670837760.0
Loss at iteration 630 : 41698357248.0
Loss at iteration 640 : 17221328896.0
Loss at iteration 650 : 2947581184.0
Loss at iteration 660 : 858977861632.0
Loss at iteration 670 : 10518626304.0
Loss at iteration 680 : 16897784832.0
Loss at iteration 690 : 59749744640.0
Loss at iteration 700 : 5665042944.0
Loss at iteration 710 : 17413052416.0
Loss at iteration 720 : 144542768.0
Loss at iteration 730 : 24330952704.0
Loss at iteration 740 : 5574353920.0
Loss at iteration 750 : 69282095104.0
Loss at iteration 760 : 16109367296.0
Loss at iteration 770 : 9042820096.0
Loss at iteration 780 : 12498542592.0
Loss at iteration 790 : 71064788992.0
Loss at iteration 800 : 6839390437376.0
Loss at iteration 810 : 16347379531776.0
Loss at iteration 820 : 129272668160.0
Loss at iteration 830 : 970532061184.0
Loss at iteration 840 : 20754540544.0
Loss at iteration 850 : 586884120576.0
Loss at iteration 860 : 53966753792.0
Loss at iteration 870 : 219349876736.0
Loss at iteration 880 : 56654671872.0
Loss at iteration 890 : 333846872064.0
Loss at iteration 900 : 183078633472.0
Loss at iteration 910 : 507231010816.0
Loss at iteration 920 : 1039903227904.0
Loss at iteration 930 : 28663543808.0
Loss at iteration 940 : 967400423424.0
Loss at iteration 950 : 379048722432.0
Loss at iteration 960 : 9292659712.0
Loss at iteration 970 : 23929167872.0
Loss at iteration 980 : 35847798784.0
Loss at iteration 990 : 63330533376.0
Loss at iteration 1000 : 113088823296.0
Loss at iteration 1010 : 141052461056.0
Loss at iteration 1020 : 52348219392.0
Loss at iteration 1030 : 469999058944.0
Loss at iteration 1040 : 76354830336.0
Loss at iteration 1050 : 13504882688.0
Loss at iteration 1060 : 9544856576.0
Loss at iteration 1070 : 149225668608.0
Loss at iteration 1080 : 33133516800.0
Loss at iteration 1090 : 21049786368.0
Loss at iteration 1100 : 2006040832.0
Loss at iteration 1110 : 2006923776.0
Loss at iteration 1120 : 8727329792.0
Loss at iteration 1130 : 208173809664.0
Loss at iteration 1140 : 32202717184.0
Loss at iteration 1150 : 4812581376.0
Loss at iteration 1160 : 28161394688.0
Loss at iteration 1170 : 20512671744.0
Loss at iteration 1180 : 33412227072.0
Loss at iteration 1190 : 50103140352.0
Loss at iteration 1200 : 11062893568.0
Loss at iteration 1210 : 19029075968.0
Loss at iteration 1220 : 15860026368.0
Loss at iteration 1230 : 12864666624.0
Loss at iteration 1240 : 1415614080.0
Loss at iteration 1250 : 2441771776.0
Loss at iteration 1260 : 33686673408.0
Loss at iteration 1270 : 88103485440.0
Loss at iteration 1280 : 8246729728.0
Loss at iteration 1290 : 9768441856.0
Loss at iteration 1300 : 4068779008.0
Loss at iteration 1310 : 28117682176.0
Loss at iteration 1320 : 5976136704.0
Loss at iteration 1330 : 10749822976.0
Loss at iteration 1340 : 1432672000.0
Loss at iteration 1350 : 2368192000.0
Loss at iteration 1360 : 2070582272.0
Loss at iteration 1370 : 16047422464.0
Loss at iteration 1380 : 10125960192.0
Loss at iteration 1390 : 4927933440.0
Loss at iteration 1400 : 27362324480.0
Loss at iteration 1410 : 948009472.0
Loss at iteration 1420 : 23716548608.0
Loss at iteration 1430 : 33615204352.0
Loss at iteration 1440 : 83659522048.0
Loss at iteration 1450 : 29577406464.0
Loss at iteration 1460 : 1411079552.0
Loss at iteration 1470 : 1247691014144.0
Loss at iteration 1480 : 5348892672.0
Loss at iteration 1490 : 3179329024.0
Loss at iteration 1500 : 98718998528.0
Loss at iteration 1510 : 21753364480.0
Loss at iteration 1520 : 10518809600.0
Loss at iteration 1530 : 771693056.0
Loss at iteration 1540 : 15147947008.0
Loss at iteration 1550 : 34425696256.0
Loss at iteration 1560 : 1586724608.0
Loss at iteration 1570 : 4288070144.0
Loss at iteration 1580 : 1559364480.0
Loss at iteration 1590 : 102179824.0
Loss at iteration 1600 : 230176192.0
Loss at iteration 1610 : 7835085312.0
Loss at iteration 1620 : 30789099520.0
Loss at iteration 1630 : 45277790208.0
Loss at iteration 1640 : 4773510656.0
Loss at iteration 1650 : 3255638272.0
Loss at iteration 1660 : 9422544896.0
Loss at iteration 1670 : 13333655552.0
Loss at iteration 1680 : 30321434624.0
Loss at iteration 1690 : 33595494400.0
Loss at iteration 1700 : 26073354240.0
Loss at iteration 1710 : 5267803136.0
Loss at iteration 1720 : 378837472.0
Loss at iteration 1730 : 157325344768.0
Loss at iteration 1740 : 1451834112.0
Loss at iteration 1750 : 10048142336.0
Loss at iteration 1760 : 32281264128.0
Loss at iteration 1770 : 5413702144.0
Loss at iteration 1780 : 5868284928.0
Loss at iteration 1790 : 11398103040.0
Loss at iteration 1800 : 305675567104.0
Loss at iteration 1810 : 17702649856.0
Loss at iteration 1820 : 22798987264.0
Loss at iteration 1830 : 28191965184.0
Loss at iteration 1840 : 39431659520.0
Loss at iteration 1850 : 46832480256.0
Loss at iteration 1860 : 314725761024.0
Loss at iteration 1870 : 20125118464.0
Loss at iteration 1880 : 224075923456.0
Loss at iteration 1890 : 233805348864.0
Loss at iteration 1900 : 3070835968.0
Loss at iteration 1910 : 57513861120.0
Loss at iteration 1920 : 47728590848.0
Loss at iteration 1930 : 371418726400.0
Loss at iteration 1940 : 6656524800.0
Loss at iteration 1950 : 8704949248.0
Loss at iteration 1960 : 452754368.0
Loss at iteration 1970 : 5475460096.0
Loss at iteration 1980 : 2527164928.0
Loss at iteration 1990 : 11022483456.0
Loss at iteration 2000 : 762385472.0
Loss at iteration 2010 : 22980796416.0
Loss at iteration 2020 : 1476162560.0
Loss at iteration 2030 : 43195895808.0
Loss at iteration 2040 : 26968944640.0
Loss at iteration 2050 : 27422064640.0
Loss at iteration 2060 : 21412550656.0
Loss at iteration 2070 : 6309422080.0
Loss at iteration 2080 : 10410237952.0
Loss at iteration 2090 : 34034651136.0
Loss at iteration 2100 : 50959081472.0
Loss at iteration 2110 : 10549208064.0
Loss at iteration 2120 : 115543638016.0
Loss at iteration 2130 : 7629853184.0
Loss at iteration 2140 : 60953083904.0
Loss at iteration 2150 : 8418355200.0
Loss at iteration 2160 : 31192829952.0
Loss at iteration 2170 : 12751896576.0
Loss at iteration 2180 : 17140714496.0
Loss at iteration 2190 : 2816504064.0
Loss at iteration 2200 : 65021513728.0
Loss at iteration 2210 : 19328503808.0
Loss at iteration 2220 : 8652848128.0
Loss at iteration 2230 : 248921309184.0
Loss at iteration 2240 : 59892682752.0
Loss at iteration 2250 : 6894570496.0
Loss at iteration 2260 : 6674120704.0
Loss at iteration 2270 : 85504598016.0
Loss at iteration 2280 : 15921703936.0
Loss at iteration 2290 : 53198139392.0
Loss at iteration 2300 : 27454670848.0
Loss at iteration 2310 : 10482160640.0
Loss at iteration 2320 : 224128122880.0
Loss at iteration 2330 : 1249617536.0
Loss at iteration 2340 : 22548332544.0
Loss at iteration 2350 : 21985130496.0
Loss at iteration 2360 : 35036192768.0
Loss at iteration 2370 : 62191714304.0
Loss at iteration 2380 : 37067083776.0
Loss at iteration 2390 : 3154445312.0
Loss at iteration 2400 : 2596268288.0
Loss at iteration 2410 : 2982739456.0
Loss at iteration 2420 : 11555495936.0
The SSIM Value is: 3.2266445676517225e-06
The PSNR Value is: -109.02645975748698
the epoch is: 149
Loss at iteration 10 : 4578520576.0
Loss at iteration 20 : 61166297088.0
Loss at iteration 30 : 10000698368.0
Loss at iteration 40 : 8817636352.0
Loss at iteration 50 : 19548352512.0
Loss at iteration 60 : 1100541696.0
Loss at iteration 70 : 24004612096.0
Loss at iteration 80 : 7924488192.0
Loss at iteration 90 : 1974418816.0
Loss at iteration 100 : 11087106048.0
Loss at iteration 110 : 2494604544.0
Loss at iteration 120 : 7682004480.0
Loss at iteration 130 : 2443197952.0
Loss at iteration 140 : 18509047808.0
Loss at iteration 150 : 1501770112.0
Loss at iteration 160 : 18030317568.0
Loss at iteration 170 : 28888047616.0
Loss at iteration 180 : 552901120.0
Loss at iteration 190 : 2823008768.0
Loss at iteration 200 : 656265600.0
Loss at iteration 210 : 8735509504.0
Loss at iteration 220 : 14882323456.0
Loss at iteration 230 : 2027548160.0
Loss at iteration 240 : 808623104.0
Loss at iteration 250 : 11577949184.0
Loss at iteration 260 : 1767030400.0
Loss at iteration 270 : 7459973632.0
Loss at iteration 280 : 5500512256.0
Loss at iteration 290 : 20817709056.0
Loss at iteration 300 : 1154202624.0
Loss at iteration 310 : 6699951616.0
Loss at iteration 320 : 28267571200.0
Loss at iteration 330 : 897506880.0
Loss at iteration 340 : 1623977600.0
Loss at iteration 350 : 8440174592.0
Loss at iteration 360 : 48314257408.0
Loss at iteration 370 : 9839339520.0
Loss at iteration 380 : 9930997760.0
Loss at iteration 390 : 9116956672.0
Loss at iteration 400 : 820757312.0
Loss at iteration 410 : 1152114432.0
Loss at iteration 420 : 2661716992.0
Loss at iteration 430 : 19059302400.0
Loss at iteration 440 : 21062103040.0
Loss at iteration 450 : 12203390976.0
Loss at iteration 460 : 2009106176.0
Loss at iteration 470 : 2347771136.0
Loss at iteration 480 : 7316482048.0
Loss at iteration 490 : 1105554688.0
Loss at iteration 500 : 2104391296.0
Loss at iteration 510 : 4885650944.0
Loss at iteration 520 : 8921933824.0
Loss at iteration 530 : 1384967296.0
Loss at iteration 540 : 21643423744.0
Loss at iteration 550 : 10651975680.0
Loss at iteration 560 : 18085711872.0
Loss at iteration 570 : 7887038976.0
Loss at iteration 580 : 1180627840.0
Loss at iteration 590 : 71471652864.0
Loss at iteration 600 : 974134336.0
Loss at iteration 610 : 10477208576.0
Loss at iteration 620 : 10232433664.0
Loss at iteration 630 : 1590066176.0
Loss at iteration 640 : 1458081024.0
Loss at iteration 650 : 7948970496.0
Loss at iteration 660 : 774031104.0
Loss at iteration 670 : 3909673984.0
Loss at iteration 680 : 307149312.0
Loss at iteration 690 : 635788416.0
Loss at iteration 700 : 372549376.0
Loss at iteration 710 : 362504224.0
Loss at iteration 720 : 1055143744.0
Loss at iteration 730 : 5589177344.0
Loss at iteration 740 : 812566208.0
Loss at iteration 750 : 1923191936.0
Loss at iteration 760 : 1192181632.0
Loss at iteration 770 : 2429088512.0
Loss at iteration 780 : 7314697216.0
Loss at iteration 790 : 7598870016.0
Loss at iteration 800 : 8876750848.0
Loss at iteration 810 : 3577176320.0
Loss at iteration 820 : 3053071616.0
Loss at iteration 830 : 2322326272.0
Loss at iteration 840 : 2372716032.0
Loss at iteration 850 : 7493940224.0
Loss at iteration 860 : 41076285440.0
Loss at iteration 870 : 3362277120.0
Loss at iteration 880 : 3840702208.0
Loss at iteration 890 : 6692319232.0
Loss at iteration 900 : 1452653696.0
Loss at iteration 910 : 2176849152.0
Loss at iteration 920 : 308936736.0
Loss at iteration 930 : 4894726656.0
Loss at iteration 940 : 3631864064.0
Loss at iteration 950 : 19118000128.0
Loss at iteration 960 : 8200950784.0
Loss at iteration 970 : 6255622144.0
Loss at iteration 980 : 3116364288.0
Loss at iteration 990 : 2216039424.0
Loss at iteration 1000 : 3031198208.0
Loss at iteration 1010 : 1242416768.0
Loss at iteration 1020 : 1295660544.0
Loss at iteration 1030 : 1254510080.0
Loss at iteration 1040 : 104597168128.0
Loss at iteration 1050 : 1509979193344.0
Loss at iteration 1060 : 18944479232.0
Loss at iteration 1070 : 16506701824.0
Loss at iteration 1080 : 2823711621120.0
Loss at iteration 1090 : 2258750406656.0
Loss at iteration 1100 : 5827131392.0
Loss at iteration 1110 : 406186393600.0
Loss at iteration 1120 : 638243438592.0
Loss at iteration 1130 : 92918292480.0
Loss at iteration 1140 : 1345487488.0
Loss at iteration 1150 : 20522739712.0
Loss at iteration 1160 : 28023767040.0
Loss at iteration 1170 : 16670467072.0
Loss at iteration 1180 : 55735578624.0
Loss at iteration 1190 : 61671309312.0
Loss at iteration 1200 : 316010332160.0
Loss at iteration 1210 : 917768044544.0
Loss at iteration 1220 : 85095112704.0
Loss at iteration 1230 : 2159123890176.0
Loss at iteration 1240 : 45051035648.0
Loss at iteration 1250 : 705582333952.0
Loss at iteration 1260 : 79310479360.0
Loss at iteration 1270 : 55357648896.0
Loss at iteration 1280 : 35592970240.0
Loss at iteration 1290 : 1260387827712.0
Loss at iteration 1300 : 175201386496.0
Loss at iteration 1310 : 789651914752.0
Loss at iteration 1320 : 48516788224.0
Loss at iteration 1330 : 1257155330048.0
Loss at iteration 1340 : 18036142080.0
Loss at iteration 1350 : 5999768064.0
Loss at iteration 1360 : 204462899200.0
Loss at iteration 1370 : 215130849280.0
Loss at iteration 1380 : 388007526400.0
Loss at iteration 1390 : 29186668544.0
Loss at iteration 1400 : 173947125760.0
Loss at iteration 1410 : 552823750656.0
Loss at iteration 1420 : 2179801546752.0
Loss at iteration 1430 : 690661097472.0
Loss at iteration 1440 : 52612128768.0
Loss at iteration 1450 : 5631296512.0
Loss at iteration 1460 : 77942972416.0
Loss at iteration 1470 : 15629445120.0
Loss at iteration 1480 : 5939901952.0
Loss at iteration 1490 : 216877170688.0
Loss at iteration 1500 : 409822855168.0
Loss at iteration 1510 : 227247800320.0
Loss at iteration 1520 : 14941600768.0
Loss at iteration 1530 : 24113635328.0
Loss at iteration 1540 : 1163356930048.0
Loss at iteration 1550 : 8658684928.0
Loss at iteration 1560 : 80725311488.0
Loss at iteration 1570 : 9083146240.0
Loss at iteration 1580 : 75784593408.0
Loss at iteration 1590 : 36037885952.0
Loss at iteration 1600 : 136759336960.0
Loss at iteration 1610 : 384856358912.0
Loss at iteration 1620 : 618504781824.0
Loss at iteration 1630 : 52077334528.0
Loss at iteration 1640 : 135960731648.0
Loss at iteration 1650 : 46929375232.0
Loss at iteration 1660 : 3341720320.0
Loss at iteration 1670 : 442212122624.0
Loss at iteration 1680 : 173100318720.0
Loss at iteration 1690 : 420394369024.0
Loss at iteration 1700 : 23337353216.0
Loss at iteration 1710 : 24312150016.0
Loss at iteration 1720 : 649778298880.0
Loss at iteration 1730 : 3440498442240.0
Loss at iteration 1740 : 625559863296.0
Loss at iteration 1750 : 866173976576.0
Loss at iteration 1760 : 47663534080.0
Loss at iteration 1770 : 61221499830272.0
Loss at iteration 1780 : 190663983366144.0
Loss at iteration 1790 : 25925998592.0
Loss at iteration 1800 : 1159477460992.0
Loss at iteration 1810 : 23430428672.0
Loss at iteration 1820 : 185793724416.0
Loss at iteration 1830 : 57059749888.0
Loss at iteration 1840 : 4284908568576.0
Loss at iteration 1850 : 252266102784.0
Loss at iteration 1860 : 604811821056.0
Loss at iteration 1870 : 71276773376.0
Loss at iteration 1880 : 22823038976.0
Loss at iteration 1890 : 36386750464.0
Loss at iteration 1900 : 30060433408.0
Loss at iteration 1910 : 165426266112.0
Loss at iteration 1920 : 35497082880.0
Loss at iteration 1930 : 251061747712.0
Loss at iteration 1940 : 5226070016.0
Loss at iteration 1950 : 767506432.0
Loss at iteration 1960 : 5610118144.0
Loss at iteration 1970 : 6966763520.0
Loss at iteration 1980 : 170323263488.0
Loss at iteration 1990 : 74978492416.0
Loss at iteration 2000 : 3734568435712.0
Loss at iteration 2010 : 6960193208320.0
Loss at iteration 2020 : 210492293120.0
Loss at iteration 2030 : 481532444672.0
Loss at iteration 2040 : 1107766018048.0
Loss at iteration 2050 : 1074408849408.0
Loss at iteration 2060 : 640423165952.0
Loss at iteration 2070 : 47969697792.0
Loss at iteration 2080 : 28531281920.0
Loss at iteration 2090 : 21263749120.0
Loss at iteration 2100 : 3819690752.0
Loss at iteration 2110 : 35441754112.0
Loss at iteration 2120 : 1399356260352.0
Loss at iteration 2130 : 69181579264.0
Loss at iteration 2140 : 16443611136.0
Loss at iteration 2150 : 194664939520.0
Loss at iteration 2160 : 494302986240.0
Loss at iteration 2170 : 57166786560.0
Loss at iteration 2180 : 139035099136.0
Loss at iteration 2190 : 32174338048.0
Loss at iteration 2200 : 1301448192.0
Loss at iteration 2210 : 3971622912.0
Loss at iteration 2220 : 12189821952.0
Loss at iteration 2230 : 38342688768.0
Loss at iteration 2240 : 23228608512.0
Loss at iteration 2250 : 14951593984.0
Loss at iteration 2260 : 24340901888.0
Loss at iteration 2270 : 22712938496.0
Loss at iteration 2280 : 6788040704.0
Loss at iteration 2290 : 49629736960.0
Loss at iteration 2300 : 20678025216.0
Loss at iteration 2310 : 13795766272.0
Loss at iteration 2320 : 4174274048.0
Loss at iteration 2330 : 100346462208.0
Loss at iteration 2340 : 33082705920.0
Loss at iteration 2350 : 100112867328.0
Loss at iteration 2360 : 34511486976.0
Loss at iteration 2370 : 30275905536.0
Loss at iteration 2380 : 99609108480.0
Loss at iteration 2390 : 35106758656.0
Loss at iteration 2400 : 6769004032.0
Loss at iteration 2410 : 886766043136.0
Loss at iteration 2420 : 229557878784.0
The SSIM Value is: 4.8416455911137746e-06
The PSNR Value is: -119.55152486165365
the epoch is: 150
Loss at iteration 10 : 1044455030784.0
Loss at iteration 20 : 64137916416.0
Loss at iteration 30 : 13852050432.0
Loss at iteration 40 : 160204455936.0
Loss at iteration 50 : 24978012160.0
Loss at iteration 60 : 118842630144.0
Loss at iteration 70 : 279929520128.0
Loss at iteration 80 : 40551362560.0
Loss at iteration 90 : 22300102656.0
Loss at iteration 100 : 63961567232.0
Loss at iteration 110 : 46427680768.0
Loss at iteration 120 : 34699481088.0
Loss at iteration 130 : 14788673536.0
Loss at iteration 140 : 686805942272.0
Loss at iteration 150 : 8090928128.0
Loss at iteration 160 : 406739484672.0
Loss at iteration 170 : 8672020480.0
Loss at iteration 180 : 24871423705088.0
Loss at iteration 190 : 19509012480.0
Loss at iteration 200 : 232911847424.0
Loss at iteration 210 : 101367128064.0
Loss at iteration 220 : 553836609536.0
Loss at iteration 230 : 50907555299328.0
Loss at iteration 240 : 539761794088960.0
Loss at iteration 250 : 2425148720283648.0
Loss at iteration 260 : 2.001271150084096e+16
Loss at iteration 270 : 7342866141544448.0
Loss at iteration 280 : 493096437547008.0
Loss at iteration 290 : 701677568000.0
Loss at iteration 300 : 7026319032320.0
Loss at iteration 310 : 326958383104.0
Loss at iteration 320 : 4692134330368.0
Loss at iteration 330 : 320053837824.0
Loss at iteration 340 : 2721619902464.0
Loss at iteration 350 : 52178026496.0
Loss at iteration 360 : 3348577386496.0
Loss at iteration 370 : 1858573303808.0
Loss at iteration 380 : 60042891264.0
Loss at iteration 390 : 1375402065920.0
Loss at iteration 400 : 4911613345792.0
Loss at iteration 410 : 1412471533338624.0
Loss at iteration 420 : 9067498448093184.0
Loss at iteration 430 : 8058658948644864.0
Loss at iteration 440 : 303487623626752.0
Loss at iteration 450 : 275537536745472.0
Loss at iteration 460 : 1254454183591936.0
Loss at iteration 470 : 8664027609694208.0
Loss at iteration 480 : 46609660379136.0
Loss at iteration 490 : 2344005926912.0
Loss at iteration 500 : 562612295172096.0
Loss at iteration 510 : 2254727282688.0
Loss at iteration 520 : 5875111534002176.0
Loss at iteration 530 : 71830224240640.0
Loss at iteration 540 : 27733031649280.0
Loss at iteration 550 : 4178149554257920.0
Loss at iteration 560 : 503078813958144.0
Loss at iteration 570 : 2120268721946624.0
Loss at iteration 580 : 55999851397120.0
Loss at iteration 590 : 68307172458496.0
Loss at iteration 600 : 2288092287336448.0
Loss at iteration 610 : 4827621883904.0
Loss at iteration 620 : 18511791390720.0
Loss at iteration 630 : 2552298733568.0
Loss at iteration 640 : 501592227840.0
Loss at iteration 650 : 6630574391296.0
Loss at iteration 660 : 28974910537728.0
Loss at iteration 670 : 138846486528.0
Loss at iteration 680 : 1789853958144.0
Loss at iteration 690 : 8979177537536.0
Loss at iteration 700 : 238154104832.0
Loss at iteration 710 : 1990396215296.0
Loss at iteration 720 : 20186316931072.0
Loss at iteration 730 : 2866780569600.0
Loss at iteration 740 : 519881097216.0
Loss at iteration 750 : 2726215024640.0
Loss at iteration 760 : 2438111952896.0
Loss at iteration 770 : 14899842383872.0
Loss at iteration 780 : 22870671491072.0
Loss at iteration 790 : 14942758502400.0
Loss at iteration 800 : 45138239815680.0
Loss at iteration 810 : 59656584036352.0
Loss at iteration 820 : 254259077578752.0
Loss at iteration 830 : 1936149245329408.0
Loss at iteration 840 : 198609068883968.0
Loss at iteration 850 : 40126449188864.0
Loss at iteration 860 : 561587744145408.0
Loss at iteration 870 : 119088437264384.0
Loss at iteration 880 : 138500959633408.0
Loss at iteration 890 : 322111306465280.0
Loss at iteration 900 : 188268196921344.0
Loss at iteration 910 : 17650960826368.0
Loss at iteration 920 : 63403188027392.0
Loss at iteration 930 : 149834380083200.0
Loss at iteration 940 : 14498144452608.0
Loss at iteration 950 : 1.6973293068222464e+16
Loss at iteration 960 : 642899763003392.0
Loss at iteration 970 : 354860801196032.0
Loss at iteration 980 : 233247460032512.0
Loss at iteration 990 : 170055337771008.0
Loss at iteration 1000 : 117215672139776.0
Loss at iteration 1010 : 20185094291456.0
Loss at iteration 1020 : 668302212857856.0
Loss at iteration 1030 : 1191791684485120.0
Loss at iteration 1040 : 471780347084800.0
Loss at iteration 1050 : 6162797033422848.0
Loss at iteration 1060 : 287090814222336.0
Loss at iteration 1070 : 691134862983168.0
Loss at iteration 1080 : 12442047348736.0
Loss at iteration 1090 : 287998360944640.0
Loss at iteration 1100 : 81609302736896.0
Loss at iteration 1110 : 41649048649728.0
Loss at iteration 1120 : 136738706030592.0
Loss at iteration 1130 : 40744370831360.0
Loss at iteration 1140 : 622207013224448.0
Loss at iteration 1150 : 11505034592256.0
Loss at iteration 1160 : 5231739404288.0
Loss at iteration 1170 : 6340728061952.0
Loss at iteration 1180 : 60193782104064.0
Loss at iteration 1190 : 41297092018176.0
Loss at iteration 1200 : 1683426524528640.0
Loss at iteration 1210 : 120637754441728.0
Loss at iteration 1220 : 87266605137920.0
Loss at iteration 1230 : 5596880306176.0
Loss at iteration 1240 : 2664858361266176.0
Loss at iteration 1250 : 135443555287040.0
Loss at iteration 1260 : 21954675343360.0
Loss at iteration 1270 : 661818557071360.0
Loss at iteration 1280 : 103277127532544.0
Loss at iteration 1290 : 320603470954496.0
Loss at iteration 1300 : 13459737542656.0
Loss at iteration 1310 : 85576761999360.0
Loss at iteration 1320 : 44867019341824.0
Loss at iteration 1330 : 351715979165696.0
Loss at iteration 1340 : 77032788590592.0
Loss at iteration 1350 : 2319897067520.0
Loss at iteration 1360 : 62324245266432.0
Loss at iteration 1370 : 924253224960.0
Loss at iteration 1380 : 22195210289152.0
Loss at iteration 1390 : 3666900156416.0
Loss at iteration 1400 : 23211834081280.0
Loss at iteration 1410 : 45434634502144.0
Loss at iteration 1420 : 688172342181888.0
Loss at iteration 1430 : 3221509476712448.0
Loss at iteration 1440 : 268260503191552.0
Loss at iteration 1450 : 791208272068608.0
Loss at iteration 1460 : 581241682264064.0
Loss at iteration 1470 : 39502311587840.0
Loss at iteration 1480 : 635317132460032.0
Loss at iteration 1490 : 618572464259072.0
Loss at iteration 1500 : 15016383217664.0
Loss at iteration 1510 : 1792907018240.0
Loss at iteration 1520 : 46277140152320.0
Loss at iteration 1530 : 185938445598720.0
Loss at iteration 1540 : 32460955975680.0
Loss at iteration 1550 : 265704309784576.0
Loss at iteration 1560 : 10984227864576.0
Loss at iteration 1570 : 7849955033088.0
Loss at iteration 1580 : 19802399703040.0
Loss at iteration 1590 : 30850026569728.0
Loss at iteration 1600 : 34838348300288.0
Loss at iteration 1610 : 28910739783680.0
Loss at iteration 1620 : 16114986778624.0
Loss at iteration 1630 : 14973885480960.0
Loss at iteration 1640 : 21761087242240.0
Loss at iteration 1650 : 990755422208.0
Loss at iteration 1660 : 139782302728192.0
Loss at iteration 1670 : 4828874407936.0
Loss at iteration 1680 : 22127656828928.0
Loss at iteration 1690 : 18213639290880.0
Loss at iteration 1700 : 4238582480896.0
Loss at iteration 1710 : 10840033984512.0
Loss at iteration 1720 : 13792661471232.0
Loss at iteration 1730 : 37583845326848.0
Loss at iteration 1740 : 1387727421440.0
Loss at iteration 1750 : 7103886393344.0
Loss at iteration 1760 : 16959850676224.0
Loss at iteration 1770 : 32501617655808.0
Loss at iteration 1780 : 1754911211520.0
Loss at iteration 1790 : 37169422925824.0
Loss at iteration 1800 : 159992380391424.0
Loss at iteration 1810 : 8729779503104.0
Loss at iteration 1820 : 41419238539264.0
Loss at iteration 1830 : 19833479495680.0
Loss at iteration 1840 : 2859155062784.0
Loss at iteration 1850 : 11170470690816.0
Loss at iteration 1860 : 146164749959168.0
Loss at iteration 1870 : 42017820246016.0
Loss at iteration 1880 : 503103750144.0
Loss at iteration 1890 : 16974981627904.0
Loss at iteration 1900 : 9001810001920.0
Loss at iteration 1910 : 5004009144320.0
Loss at iteration 1920 : 32313220005888.0
Loss at iteration 1930 : 3019001036800.0
Loss at iteration 1940 : 2389954002944.0
Loss at iteration 1950 : 7453384114176.0
Loss at iteration 1960 : 10393272451072.0
Loss at iteration 1970 : 68461707395072.0
Loss at iteration 1980 : 4482896232448.0
Loss at iteration 1990 : 9179700920320.0
Loss at iteration 2000 : 3944106688512.0
Loss at iteration 2010 : 571662204928.0
Loss at iteration 2020 : 8996900569088.0
Loss at iteration 2030 : 739673295028224.0
Loss at iteration 2040 : 600062492672.0
Loss at iteration 2050 : 559680389120.0
Loss at iteration 2060 : 5873085186048.0
Loss at iteration 2070 : 13152982925312.0
Loss at iteration 2080 : 828733718528.0
Loss at iteration 2090 : 27688133722112.0
Loss at iteration 2100 : 41876648361984.0
Loss at iteration 2110 : 896491585536.0
Loss at iteration 2120 : 458872487936.0
Loss at iteration 2130 : 665923747840.0
Loss at iteration 2140 : 1312033603584.0
Loss at iteration 2150 : 697382010880.0
Loss at iteration 2160 : 1821978525696.0
Loss at iteration 2170 : 2714475429888.0
Loss at iteration 2180 : 8511795757056.0
Loss at iteration 2190 : 66532256251904.0
Loss at iteration 2200 : 4157058056192.0
Loss at iteration 2210 : 9659166490624.0
Loss at iteration 2220 : 18460501344256.0
Loss at iteration 2230 : 3155197165568.0
Loss at iteration 2240 : 7035975892992.0
Loss at iteration 2250 : 4784697376768.0
Loss at iteration 2260 : 55167076532224.0
Loss at iteration 2270 : 11516452536320.0
Loss at iteration 2280 : 48731118370816.0
Loss at iteration 2290 : 19141622759424.0
Loss at iteration 2300 : 5614769537024.0
Loss at iteration 2310 : 6391677845504.0
Loss at iteration 2320 : 3177504833536.0
Loss at iteration 2330 : 1264939565056.0
Loss at iteration 2340 : 1540684906496.0
Loss at iteration 2350 : 2361638256640.0
Loss at iteration 2360 : 1355278581760.0
Loss at iteration 2370 : 3501506953216.0
Loss at iteration 2380 : 51155040206848.0
Loss at iteration 2390 : 2632014364672.0
Loss at iteration 2400 : 1096245444608.0
Loss at iteration 2410 : 16867364175872.0
Loss at iteration 2420 : 3751291387904.0
The SSIM Value is: -3.483276221534955e-07
The PSNR Value is: -135.99439442952473
the epoch is: 151
Loss at iteration 10 : 16373157724160.0
Loss at iteration 20 : 15719499563008.0
Loss at iteration 30 : 4473757892608.0
Loss at iteration 40 : 890317045760.0
Loss at iteration 50 : 503111942144.0
Loss at iteration 60 : 43868472999936.0
Loss at iteration 70 : 16518611992576.0
Loss at iteration 80 : 229912887689216.0
Loss at iteration 90 : 2876037398528.0
Loss at iteration 100 : 1090390786048.0
Loss at iteration 110 : 8687046885376.0
Loss at iteration 120 : 2288833003520.0
Loss at iteration 130 : 315268661248.0
Loss at iteration 140 : 6020957470720.0
Loss at iteration 150 : 8992450412544.0
Loss at iteration 160 : 7341842890752.0
Loss at iteration 170 : 1614838890496.0
Loss at iteration 180 : 5592378769408.0
Loss at iteration 190 : 9170331893760.0
Loss at iteration 200 : 121370532904960.0
Loss at iteration 210 : 1305751060480.0
Loss at iteration 220 : 39775469830144.0
Loss at iteration 230 : 1827209084928.0
Loss at iteration 240 : 1284025614336.0
Loss at iteration 250 : 3793857806336.0
Loss at iteration 260 : 1660851978240.0
Loss at iteration 270 : 2367509233664.0
Loss at iteration 280 : 29493695610880.0
Loss at iteration 290 : 1720990433280.0
Loss at iteration 300 : 5338636484608.0
Loss at iteration 310 : 8581021696000.0
Loss at iteration 320 : 3894824402944.0
Loss at iteration 330 : 17381352013824.0
Loss at iteration 340 : 3604334772224.0
Loss at iteration 350 : 21157711446016.0
Loss at iteration 360 : 2261050458112.0
Loss at iteration 370 : 1253375606784.0
Loss at iteration 380 : 791260102656.0
Loss at iteration 390 : 27477403500544.0
Loss at iteration 400 : 4546999877632.0
Loss at iteration 410 : 3452942155776.0
Loss at iteration 420 : 5373630087168.0
Loss at iteration 430 : 6246111379456.0
Loss at iteration 440 : 1544493727744.0
Loss at iteration 450 : 1006098120704.0
Loss at iteration 460 : 5295559409664.0
Loss at iteration 470 : 92208652877824.0
Loss at iteration 480 : 677522964480.0
Loss at iteration 490 : 437307080704.0
Loss at iteration 500 : 2175278252032.0
Loss at iteration 510 : 3817658384384.0
Loss at iteration 520 : 54683091599360.0
Loss at iteration 530 : 5644058361856.0
Loss at iteration 540 : 8892316647424.0
Loss at iteration 550 : 25990063456256.0
Loss at iteration 560 : 1282411331584.0
Loss at iteration 570 : 1375364972544.0
Loss at iteration 580 : 22474032939008.0
Loss at iteration 590 : 5481827401728.0
Loss at iteration 600 : 39506610749440.0
Loss at iteration 610 : 43565384204288.0
Loss at iteration 620 : 9572663164928.0
Loss at iteration 630 : 2452257767424.0
Loss at iteration 640 : 11170336473088.0
Loss at iteration 650 : 684838223872.0
Loss at iteration 660 : 79006277632.0
Loss at iteration 670 : 1371769536512.0
Loss at iteration 680 : 692610859008.0
Loss at iteration 690 : 2646589308928.0
Loss at iteration 700 : 1541687083008.0
Loss at iteration 710 : 64246880665600.0
Loss at iteration 720 : 1964221792256.0
Loss at iteration 730 : 16047754182656.0
Loss at iteration 740 : 8901623808000.0
Loss at iteration 750 : 690289770496.0
Loss at iteration 760 : 5249802698752.0
Loss at iteration 770 : 1014509993984.0
Loss at iteration 780 : 343084007424.0
Loss at iteration 790 : 2112302612480.0
Loss at iteration 800 : 2991032107008.0
Loss at iteration 810 : 623242182656.0
Loss at iteration 820 : 1296360407040.0
Loss at iteration 830 : 1304272437248.0
Loss at iteration 840 : 831964839936.0
Loss at iteration 850 : 1612865470464.0
Loss at iteration 860 : 6123137007616.0
Loss at iteration 870 : 9108956643328.0
Loss at iteration 880 : 404939309056.0
Loss at iteration 890 : 15688306524160.0
Loss at iteration 900 : 10398656888832.0
Loss at iteration 910 : 1548900761600.0
Loss at iteration 920 : 699740913664.0
Loss at iteration 930 : 849601691648.0
Loss at iteration 940 : 12007373799424.0
Loss at iteration 950 : 183334403571712.0
Loss at iteration 960 : 138113573715968.0
Loss at iteration 970 : 131619499278336.0
Loss at iteration 980 : 57931777179648.0
Loss at iteration 990 : 31712694239232.0
Loss at iteration 1000 : 36035048243200.0
Loss at iteration 1010 : 14964818444288.0
Loss at iteration 1020 : 7594971234304.0
Loss at iteration 1030 : 30552069505024.0
Loss at iteration 1040 : 12826708017152.0
Loss at iteration 1050 : 212144046080.0
Loss at iteration 1060 : 20873922740224.0
Loss at iteration 1070 : 4131009593344.0
Loss at iteration 1080 : 23340903301120.0
Loss at iteration 1090 : 39835553234944.0
Loss at iteration 1100 : 2450618056704.0
Loss at iteration 1110 : 3919248621568.0
Loss at iteration 1120 : 1706674225152.0
Loss at iteration 1130 : 11468859768832.0
Loss at iteration 1140 : 521865297920.0
Loss at iteration 1150 : 7020732219392.0
Loss at iteration 1160 : 1646863056896.0
Loss at iteration 1170 : 2018078621696.0
Loss at iteration 1180 : 939233378304.0
Loss at iteration 1190 : 33914601078784.0
Loss at iteration 1200 : 2734161920000.0
Loss at iteration 1210 : 37021393354752.0
Loss at iteration 1220 : 886910746624.0
Loss at iteration 1230 : 3516289777664.0
Loss at iteration 1240 : 6510271791104.0
Loss at iteration 1250 : 1201890656256.0
Loss at iteration 1260 : 736111820800.0
Loss at iteration 1270 : 5917011607552.0
Loss at iteration 1280 : 2222165065728.0
Loss at iteration 1290 : 386512683008.0
Loss at iteration 1300 : 1421452378112.0
Loss at iteration 1310 : 8291142860800.0
Loss at iteration 1320 : 257532559360.0
Loss at iteration 1330 : 2927089680384.0
Loss at iteration 1340 : 336163078144.0
Loss at iteration 1350 : 2974153441280.0
Loss at iteration 1360 : 13742246985728.0
Loss at iteration 1370 : 4417522761728.0
Loss at iteration 1380 : 4326305038336.0
Loss at iteration 1390 : 3418592116736.0
Loss at iteration 1400 : 87797178368.0
Loss at iteration 1410 : 209593614336.0
Loss at iteration 1420 : 781580369920.0
Loss at iteration 1430 : 1540747821056.0
Loss at iteration 1440 : 6436674863104.0
Loss at iteration 1450 : 32868080287744.0
Loss at iteration 1460 : 232427847680.0
Loss at iteration 1470 : 3111788216320.0
Loss at iteration 1480 : 1008642162688.0
Loss at iteration 1490 : 1577292529664.0
Loss at iteration 1500 : 82692816896.0
Loss at iteration 1510 : 244460716032.0
Loss at iteration 1520 : 1268236025856.0
Loss at iteration 1530 : 1258802642944.0
Loss at iteration 1540 : 595366838272.0
Loss at iteration 1550 : 346055704576.0
Loss at iteration 1560 : 5661590552576.0
Loss at iteration 1570 : 7663056846848.0
Loss at iteration 1580 : 1160351318016.0
Loss at iteration 1590 : 3185222877184.0
Loss at iteration 1600 : 1240194220032.0
Loss at iteration 1610 : 7885975191552.0
Loss at iteration 1620 : 944098181120.0
Loss at iteration 1630 : 583196278784.0
Loss at iteration 1640 : 235642257408.0
Loss at iteration 1650 : 229286559744.0
Loss at iteration 1660 : 408986451968.0
Loss at iteration 1670 : 1396231503872.0
Loss at iteration 1680 : 55133203333120.0
Loss at iteration 1690 : 25598558732288.0
Loss at iteration 1700 : 3173098455040.0
Loss at iteration 1710 : 13491428655104.0
Loss at iteration 1720 : 493055508480.0
Loss at iteration 1730 : 13597861216256.0
Loss at iteration 1740 : 3200774045696.0
Loss at iteration 1750 : 8282043842560.0
Loss at iteration 1760 : 255485493248.0
Loss at iteration 1770 : 18783106236416.0
Loss at iteration 1780 : 44423409664.0
Loss at iteration 1790 : 709914722304.0
Loss at iteration 1800 : 1714270502912.0
Loss at iteration 1810 : 2293736144896.0
Loss at iteration 1820 : 63487991808.0
Loss at iteration 1830 : 11905963917312.0
Loss at iteration 1840 : 524587663360.0
Loss at iteration 1850 : 60716036096.0
Loss at iteration 1860 : 858660274176.0
Loss at iteration 1870 : 1346269478912.0
Loss at iteration 1880 : 3132887662592.0
Loss at iteration 1890 : 2352136847360.0
Loss at iteration 1900 : 1187069689856.0
Loss at iteration 1910 : 83134734336.0
Loss at iteration 1920 : 268702285824.0
Loss at iteration 1930 : 332841156608.0
Loss at iteration 1940 : 8744661942272.0
Loss at iteration 1950 : 328292270080.0
Loss at iteration 1960 : 500489945088.0
Loss at iteration 1970 : 4598107471872.0
Loss at iteration 1980 : 488731607040.0
Loss at iteration 1990 : 368289415168.0
Loss at iteration 2000 : 197012291584.0
Loss at iteration 2010 : 269293256704.0
Loss at iteration 2020 : 686581940224.0
Loss at iteration 2030 : 51592433664.0
Loss at iteration 2040 : 3195315159040.0
Loss at iteration 2050 : 509619732480.0
Loss at iteration 2060 : 524453740544.0
Loss at iteration 2070 : 235487576064.0
Loss at iteration 2080 : 299995987968.0
Loss at iteration 2090 : 1010994774016.0
Loss at iteration 2100 : 214790225920.0
Loss at iteration 2110 : 167893598208.0
Loss at iteration 2120 : 1113584435200.0
Loss at iteration 2130 : 231676280832.0
Loss at iteration 2140 : 3151394504704.0
Loss at iteration 2150 : 560482680832.0
Loss at iteration 2160 : 507382530048.0
Loss at iteration 2170 : 1957044027392.0
Loss at iteration 2180 : 2733136412672.0
Loss at iteration 2190 : 93773152256.0
Loss at iteration 2200 : 144173088768.0
Loss at iteration 2210 : 919170777088.0
Loss at iteration 2220 : 112878444544.0
Loss at iteration 2230 : 312899993600.0
Loss at iteration 2240 : 300474531840.0
Loss at iteration 2250 : 1014224584704.0
Loss at iteration 2260 : 1131579310080.0
Loss at iteration 2270 : 156032090112.0
Loss at iteration 2280 : 1748399030272.0
Loss at iteration 2290 : 280104697856.0
Loss at iteration 2300 : 1193609789440.0
Loss at iteration 2310 : 273762893824.0
Loss at iteration 2320 : 165904564224.0
Loss at iteration 2330 : 20890593280.0
Loss at iteration 2340 : 961935507456.0
Loss at iteration 2350 : 664201461760.0
Loss at iteration 2360 : 28907083776.0
Loss at iteration 2370 : 69359280128.0
Loss at iteration 2380 : 9683372032.0
Loss at iteration 2390 : 90258751488.0
Loss at iteration 2400 : 134215647232.0
Loss at iteration 2410 : 306003476480.0
Loss at iteration 2420 : 23004473344.0
The SSIM Value is: 6.090042590282489e-06
The PSNR Value is: -126.8105692545573
the epoch is: 152
Loss at iteration 10 : 108359876608.0
Loss at iteration 20 : 1903007105024.0
Loss at iteration 30 : 478308401152.0
Loss at iteration 40 : 215093002240.0
Loss at iteration 50 : 98303844352.0
Loss at iteration 60 : 2539079073792.0
Loss at iteration 70 : 264869068800.0
Loss at iteration 80 : 189832560640.0
Loss at iteration 90 : 526920744960.0
Loss at iteration 100 : 41683664896.0
Loss at iteration 110 : 30794414080.0
Loss at iteration 120 : 15050507264.0
Loss at iteration 130 : 475073544192.0
Loss at iteration 140 : 343157243904.0
Loss at iteration 150 : 535151542272.0
Loss at iteration 160 : 221821386752.0
Loss at iteration 170 : 3082732699648.0
Loss at iteration 180 : 217216057344.0
Loss at iteration 190 : 391412973568.0
Loss at iteration 200 : 417659912192.0
Loss at iteration 210 : 696833409024.0
Loss at iteration 220 : 63974596608.0
Loss at iteration 230 : 313426837504.0
Loss at iteration 240 : 421039865856.0
Loss at iteration 250 : 214253469696.0
Loss at iteration 260 : 102504103936.0
Loss at iteration 270 : 128548708352.0
Loss at iteration 280 : 132819664896.0
Loss at iteration 290 : 77216555008.0
Loss at iteration 300 : 33956902912.0
Loss at iteration 310 : 1404878585856.0
Loss at iteration 320 : 79180668928.0
Loss at iteration 330 : 94319140864.0
Loss at iteration 340 : 143555313664.0
Loss at iteration 350 : 528532668416.0
Loss at iteration 360 : 93056385024.0
Loss at iteration 370 : 147297402880.0
Loss at iteration 380 : 61063524352.0
Loss at iteration 390 : 47053381632.0
Loss at iteration 400 : 560076685312.0
Loss at iteration 410 : 55861768192.0
Loss at iteration 420 : 125143826432.0
Loss at iteration 430 : 2716259319808.0
Loss at iteration 440 : 327570620416.0
Loss at iteration 450 : 107890466816.0
Loss at iteration 460 : 3433658843136.0
Loss at iteration 470 : 130076016640.0
Loss at iteration 480 : 13664804864.0
Loss at iteration 490 : 167793508352.0
Loss at iteration 500 : 810021814272.0
Loss at iteration 510 : 349341155328.0
Loss at iteration 520 : 576092504064.0
Loss at iteration 530 : 511057461248.0
Loss at iteration 540 : 52359606272.0
Loss at iteration 550 : 687429255168.0
Loss at iteration 560 : 60129681408.0
Loss at iteration 570 : 278756065280.0
Loss at iteration 580 : 6301186785280.0
Loss at iteration 590 : 5600260915200.0
Loss at iteration 600 : 196875714560.0
Loss at iteration 610 : 515302293504.0
Loss at iteration 620 : 30373111808.0
Loss at iteration 630 : 372997685248.0
Loss at iteration 640 : 181697855488.0
Loss at iteration 650 : 132834394112.0
Loss at iteration 660 : 150492446720.0
Loss at iteration 670 : 92071870464.0
Loss at iteration 680 : 275413237760.0
Loss at iteration 690 : 105788129280.0
Loss at iteration 700 : 160687112192.0
Loss at iteration 710 : 124908789760.0
Loss at iteration 720 : 227334979584.0
Loss at iteration 730 : 100260741120.0
Loss at iteration 740 : 96076611584.0
Loss at iteration 750 : 100333051904.0
Loss at iteration 760 : 1057629863936.0
Loss at iteration 770 : 92441976832.0
Loss at iteration 780 : 35682324480.0
Loss at iteration 790 : 31014774784.0
Loss at iteration 800 : 2282423582720.0
Loss at iteration 810 : 94771716096.0
Loss at iteration 820 : 2251259379712.0
Loss at iteration 830 : 178790563840.0
Loss at iteration 840 : 178454790144.0
Loss at iteration 850 : 2245145395200.0
Loss at iteration 860 : 105224945664.0
Loss at iteration 870 : 774757220352.0
Loss at iteration 880 : 1207226990592.0
Loss at iteration 890 : 1653991407616.0
Loss at iteration 900 : 146957991936.0
Loss at iteration 910 : 431310405632.0
Loss at iteration 920 : 619986223104.0
Loss at iteration 930 : 58591412224.0
Loss at iteration 940 : 131462586368.0
Loss at iteration 950 : 729179684864.0
Loss at iteration 960 : 192714260480.0
Loss at iteration 970 : 29231855616.0
Loss at iteration 980 : 371943112704.0
Loss at iteration 990 : 83862790144.0
Loss at iteration 1000 : 35205353472.0
Loss at iteration 1010 : 376564875264.0
Loss at iteration 1020 : 994839298048.0
Loss at iteration 1030 : 362833149952.0
Loss at iteration 1040 : 228310351872.0
Loss at iteration 1050 : 128470278144.0
Loss at iteration 1060 : 161521795072.0
Loss at iteration 1070 : 54369480704.0
Loss at iteration 1080 : 127196364800.0
Loss at iteration 1090 : 116171816960.0
Loss at iteration 1100 : 181893120000.0
Loss at iteration 1110 : 64894750720.0
Loss at iteration 1120 : 255536070656.0
Loss at iteration 1130 : 1720575852544.0
Loss at iteration 1140 : 139850448896.0
Loss at iteration 1150 : 221792468992.0
Loss at iteration 1160 : 473388646400.0
Loss at iteration 1170 : 56333037568.0
Loss at iteration 1180 : 81696342016.0
Loss at iteration 1190 : 45928062976.0
Loss at iteration 1200 : 23346558976.0
Loss at iteration 1210 : 16453242880.0
Loss at iteration 1220 : 604555902976.0
Loss at iteration 1230 : 865988968448.0
Loss at iteration 1240 : 239534030848.0
Loss at iteration 1250 : 98291875840.0
Loss at iteration 1260 : 67300577280.0
Loss at iteration 1270 : 142824341504.0
Loss at iteration 1280 : 72404369408.0
Loss at iteration 1290 : 319846252544.0
Loss at iteration 1300 : 309320122368.0
Loss at iteration 1310 : 176951967744.0
Loss at iteration 1320 : 74846601216.0
Loss at iteration 1330 : 112880648192.0
Loss at iteration 1340 : 345381470208.0
Loss at iteration 1350 : 523445436416.0
Loss at iteration 1360 : 137131884544.0
Loss at iteration 1370 : 46174793728.0
Loss at iteration 1380 : 240099934208.0
Loss at iteration 1390 : 32094255104.0
Loss at iteration 1400 : 106447331328.0
Loss at iteration 1410 : 16809177088.0
Loss at iteration 1420 : 64539406336.0
Loss at iteration 1430 : 183389470720.0
Loss at iteration 1440 : 80093978624.0
Loss at iteration 1450 : 745792274432.0
Loss at iteration 1460 : 6088597962752.0
Loss at iteration 1470 : 148642922496.0
Loss at iteration 1480 : 646274023424.0
Loss at iteration 1490 : 119132938240.0
Loss at iteration 1500 : 553539993600.0
Loss at iteration 1510 : 138336813056.0
Loss at iteration 1520 : 25944928256.0
Loss at iteration 1530 : 534348955648.0
Loss at iteration 1540 : 61364969472.0
Loss at iteration 1550 : 144693329920.0
Loss at iteration 1560 : 235828035584.0
Loss at iteration 1570 : 145533534208.0
Loss at iteration 1580 : 3272515518464.0
Loss at iteration 1590 : 612616765440.0
Loss at iteration 1600 : 59042439168.0
Loss at iteration 1610 : 699701788672.0
Loss at iteration 1620 : 402389893120.0
Loss at iteration 1630 : 46210859008.0
Loss at iteration 1640 : 32926621696.0
Loss at iteration 1650 : 255898697728.0
Loss at iteration 1660 : 16113582080.0
Loss at iteration 1670 : 193973616640.0
Loss at iteration 1680 : 210094522368.0
Loss at iteration 1690 : 267730092032.0
Loss at iteration 1700 : 71265910784.0
Loss at iteration 1710 : 586428776448.0
Loss at iteration 1720 : 58065469440.0
Loss at iteration 1730 : 104408064000.0
Loss at iteration 1740 : 1079679778816.0
Loss at iteration 1750 : 30738442240.0
Loss at iteration 1760 : 233904373760.0
Loss at iteration 1770 : 568513134592.0
Loss at iteration 1780 : 42494935040.0
Loss at iteration 1790 : 3837689856.0
Loss at iteration 1800 : 104563433472.0
Loss at iteration 1810 : 237561905152.0
Loss at iteration 1820 : 50965569536.0
Loss at iteration 1830 : 39453184000.0
Loss at iteration 1840 : 259788619776.0
Loss at iteration 1850 : 65097068544.0
Loss at iteration 1860 : 138821599232.0
Loss at iteration 1870 : 46156722176.0
Loss at iteration 1880 : 45641211904.0
Loss at iteration 1890 : 211994017792.0
Loss at iteration 1900 : 146251956224.0
Loss at iteration 1910 : 449140359168.0
Loss at iteration 1920 : 110540283904.0
Loss at iteration 1930 : 36928389120.0
Loss at iteration 1940 : 949880160256.0
Loss at iteration 1950 : 64873082880.0
Loss at iteration 1960 : 10730362372096.0
Loss at iteration 1970 : 228655874048.0
Loss at iteration 1980 : 27646435328.0
Loss at iteration 1990 : 353949810688.0
Loss at iteration 2000 : 98263269376.0
Loss at iteration 2010 : 8452459520.0
Loss at iteration 2020 : 161625915392.0
Loss at iteration 2030 : 341421686784.0
Loss at iteration 2040 : 2669131595776.0
Loss at iteration 2050 : 12500023296.0
Loss at iteration 2060 : 147910541312.0
Loss at iteration 2070 : 86555156480.0
Loss at iteration 2080 : 69895602176.0
Loss at iteration 2090 : 58597916672.0
Loss at iteration 2100 : 45759799296.0
Loss at iteration 2110 : 89444851712.0
Loss at iteration 2120 : 85852585984.0
Loss at iteration 2130 : 177253007360.0
Loss at iteration 2140 : 541558472704.0
Loss at iteration 2150 : 904245739520.0
Loss at iteration 2160 : 57503236096.0
Loss at iteration 2170 : 406459711488.0
Loss at iteration 2180 : 89996288000.0
Loss at iteration 2190 : 76891553792.0
Loss at iteration 2200 : 90342776832.0
Loss at iteration 2210 : 101011824640.0
Loss at iteration 2220 : 149130838016.0
Loss at iteration 2230 : 27166320640.0
Loss at iteration 2240 : 79067242496.0
Loss at iteration 2250 : 71770546176.0
Loss at iteration 2260 : 36340830208.0
Loss at iteration 2270 : 1571512123392.0
Loss at iteration 2280 : 1161770696704.0
Loss at iteration 2290 : 319983747072.0
Loss at iteration 2300 : 8289682432.0
Loss at iteration 2310 : 48852312064.0
Loss at iteration 2320 : 85896019968.0
Loss at iteration 2330 : 1475606609920.0
Loss at iteration 2340 : 60996038656.0
Loss at iteration 2350 : 202669490176.0
Loss at iteration 2360 : 5536475136.0
Loss at iteration 2370 : 102378643456.0
Loss at iteration 2380 : 278267428864.0
Loss at iteration 2390 : 84763369472.0
Loss at iteration 2400 : 76914212864.0
Loss at iteration 2410 : 207038873600.0
Loss at iteration 2420 : 56215158784.0
The SSIM Value is: 3.1615004293901924e-06
The PSNR Value is: -120.88624776204428
the epoch is: 153
Loss at iteration 10 : 183076339712.0
Loss at iteration 20 : 120215650304.0
Loss at iteration 30 : 20432142336.0
Loss at iteration 40 : 84756545536.0
Loss at iteration 50 : 371730415616.0
Loss at iteration 60 : 33434658816.0
Loss at iteration 70 : 1498969538560.0
Loss at iteration 80 : 393112190976.0
Loss at iteration 90 : 96070393856.0
Loss at iteration 100 : 33909977088.0
Loss at iteration 110 : 46523822080.0
Loss at iteration 120 : 73633636352.0
Loss at iteration 130 : 25291560960.0
Loss at iteration 140 : 301730332672.0
Loss at iteration 150 : 12555643904.0
Loss at iteration 160 : 16155993088.0
Loss at iteration 170 : 46395932672.0
Loss at iteration 180 : 124417392640.0
Loss at iteration 190 : 812841566208.0
Loss at iteration 200 : 502180347904.0
Loss at iteration 210 : 1089650425856.0
Loss at iteration 220 : 346340392960.0
Loss at iteration 230 : 91439874048.0
Loss at iteration 240 : 432644096000.0
Loss at iteration 250 : 236334333952.0
Loss at iteration 260 : 855774593024.0
Loss at iteration 270 : 61122949120.0
Loss at iteration 280 : 632219566080.0
Loss at iteration 290 : 168403402752.0
Loss at iteration 300 : 256020742144.0
Loss at iteration 310 : 45169954816.0
Loss at iteration 320 : 1899438145536.0
Loss at iteration 330 : 2821962072064.0
Loss at iteration 340 : 68672454656.0
Loss at iteration 350 : 340095729664.0
Loss at iteration 360 : 37397880832.0
Loss at iteration 370 : 136972640256.0
Loss at iteration 380 : 67936702464.0
Loss at iteration 390 : 45904658432.0
Loss at iteration 400 : 130846941184.0
Loss at iteration 410 : 462376763392.0
Loss at iteration 420 : 3177732898816.0
Loss at iteration 430 : 61810917376.0
Loss at iteration 440 : 244446527488.0
Loss at iteration 450 : 182954196992.0
Loss at iteration 460 : 29874601984.0
Loss at iteration 470 : 210682085376.0
Loss at iteration 480 : 154089422848.0
Loss at iteration 490 : 319355125760.0
Loss at iteration 500 : 49839562752.0
Loss at iteration 510 : 72558837760.0
Loss at iteration 520 : 14530836480.0
Loss at iteration 530 : 156451454976.0
Loss at iteration 540 : 65806917632.0
Loss at iteration 550 : 398308933632.0
Loss at iteration 560 : 55403524096.0
Loss at iteration 570 : 135140081664.0
Loss at iteration 580 : 26930163712.0
Loss at iteration 590 : 97561370624.0
Loss at iteration 600 : 2005858648064.0
Loss at iteration 610 : 255171346432.0
Loss at iteration 620 : 410545029120.0
Loss at iteration 630 : 11141058134016.0
Loss at iteration 640 : 261107613696.0
Loss at iteration 650 : 41767264256.0
Loss at iteration 660 : 25135452160.0
Loss at iteration 670 : 88501116928.0
Loss at iteration 680 : 26904920064.0
Loss at iteration 690 : 68721893376.0
Loss at iteration 700 : 664494997504.0
Loss at iteration 710 : 104707063808.0
Loss at iteration 720 : 378262159360.0
Loss at iteration 730 : 104340094976.0
Loss at iteration 740 : 285388242944.0
Loss at iteration 750 : 31961856000.0
Loss at iteration 760 : 245384691712.0
Loss at iteration 770 : 71915184128.0
Loss at iteration 780 : 844080480256.0
Loss at iteration 790 : 139546148864.0
Loss at iteration 800 : 58419167232.0
Loss at iteration 810 : 8177008640.0
Loss at iteration 820 : 188521152512.0
Loss at iteration 830 : 116858798080.0
Loss at iteration 840 : 13260300288.0
Loss at iteration 850 : 24725706752.0
Loss at iteration 860 : 184304795648.0
Loss at iteration 870 : 13156560666624.0
Loss at iteration 880 : 11079971840.0
Loss at iteration 890 : 143887319040.0
Loss at iteration 900 : 14111712256.0
Loss at iteration 910 : 209468440576.0
Loss at iteration 920 : 193798897664.0
Loss at iteration 930 : 120122425344.0
Loss at iteration 940 : 188272676438016.0
Loss at iteration 950 : 121327725838336.0
Loss at iteration 960 : 7683129212928.0
Loss at iteration 970 : 32372724596736.0
Loss at iteration 980 : 49592737464320.0
Loss at iteration 990 : 1478326484992.0
Loss at iteration 1000 : 458292363264.0
Loss at iteration 1010 : 1031741898752.0
Loss at iteration 1020 : 452443832320.0
Loss at iteration 1030 : 591664644096.0
Loss at iteration 1040 : 57493220753408.0
Loss at iteration 1050 : 273054285824.0
Loss at iteration 1060 : 6340935633862656.0
Loss at iteration 1070 : 1314565390336.0
Loss at iteration 1080 : 8335659106304.0
Loss at iteration 1090 : 379231731712.0
Loss at iteration 1100 : 719041265664.0
Loss at iteration 1110 : 293761122304.0
Loss at iteration 1120 : 306046205952.0
Loss at iteration 1130 : 770551119872.0
Loss at iteration 1140 : 1035286413312.0
Loss at iteration 1150 : 185665847296.0
Loss at iteration 1160 : 28129085440.0
Loss at iteration 1170 : 298824564736.0
Loss at iteration 1180 : 21824819200.0
Loss at iteration 1190 : 338307940352.0
Loss at iteration 1200 : 48655138553856.0
Loss at iteration 1210 : 1318963511296.0
Loss at iteration 1220 : 380129837056.0
Loss at iteration 1230 : 285468950528.0
Loss at iteration 1240 : 606368759808.0
Loss at iteration 1250 : 1734487703552.0
Loss at iteration 1260 : 7967964921856.0
Loss at iteration 1270 : 2419273498624.0
Loss at iteration 1280 : 590226784256.0
Loss at iteration 1290 : 116860059648.0
Loss at iteration 1300 : 354969681920.0
Loss at iteration 1310 : 228578082816.0
Loss at iteration 1320 : 371789594624.0
Loss at iteration 1330 : 140323897344.0
Loss at iteration 1340 : 112833445888.0
Loss at iteration 1350 : 337993269248.0
Loss at iteration 1360 : 3079367557120.0
Loss at iteration 1370 : 62630924288.0
Loss at iteration 1380 : 86498492416.0
Loss at iteration 1390 : 1101340344320.0
Loss at iteration 1400 : 148915388416.0
Loss at iteration 1410 : 7700527185920.0
Loss at iteration 1420 : 2176515571712.0
Loss at iteration 1430 : 5572756766720.0
Loss at iteration 1440 : 6987973132288.0
Loss at iteration 1450 : 291069034496.0
Loss at iteration 1460 : 327548469248.0
Loss at iteration 1470 : 184792104960.0
Loss at iteration 1480 : 7057227382784.0
Loss at iteration 1490 : 14217710141440.0
Loss at iteration 1500 : 8298313023488.0
Loss at iteration 1510 : 298612228096.0
Loss at iteration 1520 : 2342305398784.0
Loss at iteration 1530 : 3580267331584.0
Loss at iteration 1540 : 406374514688.0
Loss at iteration 1550 : 120092450816.0
Loss at iteration 1560 : 564844494848.0
Loss at iteration 1570 : 481432043520.0
Loss at iteration 1580 : 30052242685952.0
Loss at iteration 1590 : 530908479488.0
Loss at iteration 1600 : 108789882880.0
Loss at iteration 1610 : 794962100224.0
Loss at iteration 1620 : 62226272256.0
Loss at iteration 1630 : 73582239744.0
Loss at iteration 1640 : 394957324288.0
Loss at iteration 1650 : 73904488448.0
Loss at iteration 1660 : 136045305856.0
Loss at iteration 1670 : 91213750272.0
Loss at iteration 1680 : 512018841600.0
Loss at iteration 1690 : 614036078592.0
Loss at iteration 1700 : 157575954432.0
Loss at iteration 1710 : 190297751552.0
Loss at iteration 1720 : 99790553088.0
Loss at iteration 1730 : 164149886976.0
Loss at iteration 1740 : 42947551232.0
Loss at iteration 1750 : 203801313280.0
Loss at iteration 1760 : 317020700672.0
Loss at iteration 1770 : 178263932928.0
Loss at iteration 1780 : 155982184448.0
Loss at iteration 1790 : 74414268416.0
Loss at iteration 1800 : 380413575168.0
Loss at iteration 1810 : 845452476416.0
Loss at iteration 1820 : 36065992704.0
Loss at iteration 1830 : 1241015648256.0
Loss at iteration 1840 : 140270895104.0
Loss at iteration 1850 : 670852841472.0
Loss at iteration 1860 : 47019425792.0
Loss at iteration 1870 : 277582217216.0
Loss at iteration 1880 : 541902995456.0
Loss at iteration 1890 : 578530705408.0
Loss at iteration 1900 : 80694296576.0
Loss at iteration 1910 : 598438182912.0
Loss at iteration 1920 : 568814534656.0
Loss at iteration 1930 : 145788633088.0
Loss at iteration 1940 : 1842876383232.0
Loss at iteration 1950 : 262484410368.0
Loss at iteration 1960 : 419414671360.0
Loss at iteration 1970 : 292568170496.0
Loss at iteration 1980 : 462107967488.0
Loss at iteration 1990 : 13822175232.0
Loss at iteration 2000 : 50486771712.0
Loss at iteration 2010 : 793885933568.0
Loss at iteration 2020 : 36784201728.0
Loss at iteration 2030 : 509705945088.0
Loss at iteration 2040 : 28071591936.0
Loss at iteration 2050 : 83913293824.0
Loss at iteration 2060 : 1086559813632.0
Loss at iteration 2070 : 10296179556352.0
Loss at iteration 2080 : 52266258432.0
Loss at iteration 2090 : 674954674176.0
Loss at iteration 2100 : 5988450566144.0
Loss at iteration 2110 : 64239505408.0
Loss at iteration 2120 : 846271610880.0
Loss at iteration 2130 : 113728258048.0
Loss at iteration 2140 : 879343108096.0
Loss at iteration 2150 : 31439882240.0
Loss at iteration 2160 : 37969276928.0
Loss at iteration 2170 : 17096632320.0
Loss at iteration 2180 : 58305388544.0
Loss at iteration 2190 : 15450100736.0
Loss at iteration 2200 : 620774359040.0
Loss at iteration 2210 : 186562084864.0
Loss at iteration 2220 : 846395604992.0
Loss at iteration 2230 : 1185849278464.0
Loss at iteration 2240 : 98376736768.0
Loss at iteration 2250 : 377316442112.0
Loss at iteration 2260 : 264946515968.0
Loss at iteration 2270 : 1208068079616.0
Loss at iteration 2280 : 798074535936.0
Loss at iteration 2290 : 6541409255424.0
Loss at iteration 2300 : 71011958784.0
Loss at iteration 2310 : 338476367872.0
Loss at iteration 2320 : 80766533632.0
Loss at iteration 2330 : 12793577472.0
Loss at iteration 2340 : 83179732992.0
Loss at iteration 2350 : 340512604160.0
Loss at iteration 2360 : 10969428262912.0
Loss at iteration 2370 : 746658988032.0
Loss at iteration 2380 : 32723873824768.0
Loss at iteration 2390 : 164094590976.0
Loss at iteration 2400 : 147000246272.0
Loss at iteration 2410 : 6186858971136.0
Loss at iteration 2420 : 201501097984.0
The SSIM Value is: -5.864353752826901e-06
The PSNR Value is: -124.38077392578126
the epoch is: 154
Loss at iteration 10 : 19247790080.0
Loss at iteration 20 : 979295600640.0
Loss at iteration 30 : 281254821888.0
Loss at iteration 40 : 105780961280.0
Loss at iteration 50 : 514000879616.0
Loss at iteration 60 : 2749717282816.0
Loss at iteration 70 : 123652145152.0
Loss at iteration 80 : 553908305920.0
Loss at iteration 90 : 6267263778816.0
Loss at iteration 100 : 119160627200.0
Loss at iteration 110 : 32116215808.0
Loss at iteration 120 : 167414939648.0
Loss at iteration 130 : 898505637888.0
Loss at iteration 140 : 121916473344.0
Loss at iteration 150 : 179583156224.0
Loss at iteration 160 : 3961852526592.0
Loss at iteration 170 : 69475024896.0
Loss at iteration 180 : 123095965696.0
Loss at iteration 190 : 927186157568.0
Loss at iteration 200 : 104814223360.0
Loss at iteration 210 : 696798806016.0
Loss at iteration 220 : 44025597952.0
Loss at iteration 230 : 3523372646400.0
Loss at iteration 240 : 71015589740544.0
Loss at iteration 250 : 172636635136.0
Loss at iteration 260 : 51127664640.0
Loss at iteration 270 : 5642389028864.0
Loss at iteration 280 : 123614920704.0
Loss at iteration 290 : 157248225280.0
Loss at iteration 300 : 37192781824.0
Loss at iteration 310 : 1137345560576.0
Loss at iteration 320 : 176750264320.0
Loss at iteration 330 : 1068856180736.0
Loss at iteration 340 : 73209962496.0
Loss at iteration 350 : 119727210496.0
Loss at iteration 360 : 1587017678848.0
Loss at iteration 370 : 3999270436864.0
Loss at iteration 380 : 2771373260800.0
Loss at iteration 390 : 318907875328.0
Loss at iteration 400 : 1046633512960.0
Loss at iteration 410 : 45844205568.0
Loss at iteration 420 : 424736784384.0
Loss at iteration 430 : 668757262336.0
Loss at iteration 440 : 6027322327040.0
Loss at iteration 450 : 736841498624.0
Loss at iteration 460 : 410498990080.0
Loss at iteration 470 : 70066692096.0
Loss at iteration 480 : 69019590656.0
Loss at iteration 490 : 96775135232.0
Loss at iteration 500 : 974783053824.0
Loss at iteration 510 : 44387004416.0
Loss at iteration 520 : 97100169216.0
Loss at iteration 530 : 49451859968.0
Loss at iteration 540 : 16429612032.0
Loss at iteration 550 : 242108530688.0
Loss at iteration 560 : 16433123328.0
Loss at iteration 570 : 1307449098240.0
Loss at iteration 580 : 93859790979072.0
Loss at iteration 590 : 6060155338752.0
Loss at iteration 600 : 32352522731520.0
Loss at iteration 610 : 2104173658112.0
Loss at iteration 620 : 483415916544.0
Loss at iteration 630 : 1110758522880.0
Loss at iteration 640 : 5859747299328.0
Loss at iteration 650 : 440888459264.0
Loss at iteration 660 : 7229648384.0
Loss at iteration 670 : 57139175424.0
Loss at iteration 680 : 23601963008.0
Loss at iteration 690 : 12918100852736.0
Loss at iteration 700 : 62442610688.0
Loss at iteration 710 : 2058551689216.0
Loss at iteration 720 : 2627194112.0
Loss at iteration 730 : 241432707072.0
Loss at iteration 740 : 201080815616.0
Loss at iteration 750 : 383707971584.0
Loss at iteration 760 : 301255032832.0
Loss at iteration 770 : 330915676160.0
Loss at iteration 780 : 82395144192.0
Loss at iteration 790 : 1085468704768.0
Loss at iteration 800 : 214900391936.0
Loss at iteration 810 : 8631717199872.0
Loss at iteration 820 : 93154140160.0
Loss at iteration 830 : 150052929536.0
Loss at iteration 840 : 8101334016.0
Loss at iteration 850 : 11698285568.0
Loss at iteration 860 : 41408895385600.0
Loss at iteration 870 : 461263372288.0
Loss at iteration 880 : 2861500465152.0
Loss at iteration 890 : 183848625242112.0
Loss at iteration 900 : 21195273535488.0
Loss at iteration 910 : 477837458931712.0
Loss at iteration 920 : 2726279774208.0
Loss at iteration 930 : 3131771977728.0
Loss at iteration 940 : 11879216840704.0
Loss at iteration 950 : 9658169294848.0
Loss at iteration 960 : 83561373761536.0
Loss at iteration 970 : 503781556224.0
Loss at iteration 980 : 331937644544.0
Loss at iteration 990 : 1899149524992.0
Loss at iteration 1000 : 1350700236800.0
Loss at iteration 1010 : 1608760426496.0
Loss at iteration 1020 : 3888517480448.0
Loss at iteration 1030 : 1191024263168.0
Loss at iteration 1040 : 4277853487104.0
Loss at iteration 1050 : 7903305007104.0
Loss at iteration 1060 : 4011778113536.0
Loss at iteration 1070 : 422036439040.0
Loss at iteration 1080 : 283723235328.0
Loss at iteration 1090 : 698429079552.0
Loss at iteration 1100 : 214701490176.0
Loss at iteration 1110 : 8294402883584.0
Loss at iteration 1120 : 1008004890624.0
Loss at iteration 1130 : 106751967232.0
Loss at iteration 1140 : 268328484864.0
Loss at iteration 1150 : 1929921560576.0
Loss at iteration 1160 : 530133516288.0
Loss at iteration 1170 : 571972583424.0
Loss at iteration 1180 : 33824169787392.0
Loss at iteration 1190 : 704830701568.0
Loss at iteration 1200 : 370796331008.0
Loss at iteration 1210 : 166032687104.0
Loss at iteration 1220 : 630142730240.0
Loss at iteration 1230 : 615553957888.0
Loss at iteration 1240 : 39273394176.0
Loss at iteration 1250 : 3058927927296.0
Loss at iteration 1260 : 1174849978368.0
Loss at iteration 1270 : 16947815424.0
Loss at iteration 1280 : 128031776768.0
Loss at iteration 1290 : 12410270720.0
Loss at iteration 1300 : 848084140032.0
Loss at iteration 1310 : 2396203515904.0
Loss at iteration 1320 : 66630606848.0
Loss at iteration 1330 : 778832248832.0
Loss at iteration 1340 : 1015328407552.0
Loss at iteration 1350 : 952098750464.0
Loss at iteration 1360 : 109914030080.0
Loss at iteration 1370 : 685165838336.0
Loss at iteration 1380 : 50933866168320.0
Loss at iteration 1390 : 71576653398016.0
Loss at iteration 1400 : 10905784942592.0
Loss at iteration 1410 : 3364893491200.0
Loss at iteration 1420 : 3229678305280.0
Loss at iteration 1430 : 210116247552.0
Loss at iteration 1440 : 818829524992.0
Loss at iteration 1450 : 535110615040.0
Loss at iteration 1460 : 772335730688.0
Loss at iteration 1470 : 45457879334912.0
Loss at iteration 1480 : 176481845248.0
Loss at iteration 1490 : 5154620309504.0
Loss at iteration 1500 : 568996265984.0
Loss at iteration 1510 : 125268738048.0
Loss at iteration 1520 : 582437568512.0
Loss at iteration 1530 : 161634041856.0
Loss at iteration 1540 : 30190632960.0
Loss at iteration 1550 : 64095850496.0
Loss at iteration 1560 : 63633838080.0
Loss at iteration 1570 : 1439733514240.0
Loss at iteration 1580 : 68149002240.0
Loss at iteration 1590 : 1879386882048.0
Loss at iteration 1600 : 745084747776.0
Loss at iteration 1610 : 243479822336.0
Loss at iteration 1620 : 1223674167296.0
Loss at iteration 1630 : 1671996375040.0
Loss at iteration 1640 : 7061927624704.0
Loss at iteration 1650 : 1316753375232.0
Loss at iteration 1660 : 160974651392.0
Loss at iteration 1670 : 201854500864.0
Loss at iteration 1680 : 110124548096.0
Loss at iteration 1690 : 16371427573760.0
Loss at iteration 1700 : 3588558684160.0
Loss at iteration 1710 : 66529468416.0
Loss at iteration 1720 : 31281311744.0
Loss at iteration 1730 : 1445339070464.0
Loss at iteration 1740 : 398446428160.0
Loss at iteration 1750 : 323567976448.0
Loss at iteration 1760 : 22462124032.0
Loss at iteration 1770 : 776676442112.0
Loss at iteration 1780 : 2930148638720.0
Loss at iteration 1790 : 292891033600.0
Loss at iteration 1800 : 126012055552.0
Loss at iteration 1810 : 736025640960.0
Loss at iteration 1820 : 25373993598976.0
Loss at iteration 1830 : 142754873344.0
Loss at iteration 1840 : 1330480545792.0
Loss at iteration 1850 : 39392571392.0
Loss at iteration 1860 : 13039150080.0
Loss at iteration 1870 : 1128586936320.0
Loss at iteration 1880 : 319287427072.0
Loss at iteration 1890 : 1768727511040.0
Loss at iteration 1900 : 217124257792.0
Loss at iteration 1910 : 1511248625664.0
Loss at iteration 1920 : 69434277888.0
Loss at iteration 1930 : 42688106496.0
Loss at iteration 1940 : 442618609664.0
Loss at iteration 1950 : 96613957632.0
Loss at iteration 1960 : 180261027840.0
Loss at iteration 1970 : 193870757888.0
Loss at iteration 1980 : 190912200704.0
Loss at iteration 1990 : 276282638336.0
Loss at iteration 2000 : 192307494912.0
Loss at iteration 2010 : 163787079680.0
Loss at iteration 2020 : 123944837120.0
Loss at iteration 2030 : 30648289280.0
Loss at iteration 2040 : 160669499392.0
Loss at iteration 2050 : 160777207808.0
Loss at iteration 2060 : 377513443328.0
Loss at iteration 2070 : 675855728640.0
Loss at iteration 2080 : 63500017664.0
Loss at iteration 2090 : 125031120896.0
Loss at iteration 2100 : 241703878656.0
Loss at iteration 2110 : 113020420096.0
Loss at iteration 2120 : 18155405312.0
Loss at iteration 2130 : 280056201216.0
Loss at iteration 2140 : 180448968704.0
Loss at iteration 2150 : 152910888960.0
Loss at iteration 2160 : 318731091968.0
Loss at iteration 2170 : 6873125376.0
Loss at iteration 2180 : 574040702976.0
Loss at iteration 2190 : 41963507712.0
Loss at iteration 2200 : 538651787264.0
Loss at iteration 2210 : 172068880384.0
Loss at iteration 2220 : 391875493888.0
Loss at iteration 2230 : 6738477056.0
Loss at iteration 2240 : 395821776896.0
Loss at iteration 2250 : 197135728640.0
Loss at iteration 2260 : 21911810048.0
Loss at iteration 2270 : 48065863680.0
Loss at iteration 2280 : 27295504384.0
Loss at iteration 2290 : 8745953280.0
Loss at iteration 2300 : 94876401664.0
Loss at iteration 2310 : 230884245504.0
Loss at iteration 2320 : 143859810304.0
Loss at iteration 2330 : 29485893632.0
Loss at iteration 2340 : 97561378816.0
Loss at iteration 2350 : 239844671488.0
Loss at iteration 2360 : 268755025920.0
Loss at iteration 2370 : 48306081792.0
Loss at iteration 2380 : 77678190592.0
Loss at iteration 2390 : 312377344000.0
Loss at iteration 2400 : 1362920960.0
Loss at iteration 2410 : 46986719232.0
Loss at iteration 2420 : 21611102208.0
The SSIM Value is: 7.771090200966076e-07
The PSNR Value is: -121.23540344238282
the epoch is: 155
Loss at iteration 10 : 243985022976.0
Loss at iteration 20 : 545035059200.0
Loss at iteration 30 : 35987406848.0
Loss at iteration 40 : 10701742080.0
Loss at iteration 50 : 177763778560.0
Loss at iteration 60 : 65438134272.0
Loss at iteration 70 : 720555278336.0
Loss at iteration 80 : 8874313728.0
Loss at iteration 90 : 5465280512.0
Loss at iteration 100 : 74796843008.0
Loss at iteration 110 : 80223313920.0
Loss at iteration 120 : 124943360000.0
Loss at iteration 130 : 6849256448.0
Loss at iteration 140 : 55457189888.0
Loss at iteration 150 : 426065428480.0
Loss at iteration 160 : 3466814029824.0
Loss at iteration 170 : 624433561600.0
Loss at iteration 180 : 641331298304.0
Loss at iteration 190 : 147328647168.0
Loss at iteration 200 : 7226880000.0
Loss at iteration 210 : 52820430848.0
Loss at iteration 220 : 105653141504.0
Loss at iteration 230 : 30406172737536.0
Loss at iteration 240 : 7622021120.0
Loss at iteration 250 : 104798625792.0
Loss at iteration 260 : 21301051392.0
Loss at iteration 270 : 26201841664.0
Loss at iteration 280 : 277019525120.0
Loss at iteration 290 : 58687356928.0
Loss at iteration 300 : 128658276352.0
Loss at iteration 310 : 1118548787200.0
Loss at iteration 320 : 60455661568.0
Loss at iteration 330 : 42318254080.0
Loss at iteration 340 : 288921681920.0
Loss at iteration 350 : 98694725632.0
Loss at iteration 360 : 600684429312.0
Loss at iteration 370 : 52235878400.0
Loss at iteration 380 : 55250800640.0
Loss at iteration 390 : 151806885888.0
Loss at iteration 400 : 115562545152.0
Loss at iteration 410 : 38980603904.0
Loss at iteration 420 : 1189959172096.0
Loss at iteration 430 : 747940675584.0
Loss at iteration 440 : 467753631744.0
Loss at iteration 450 : 220187033600.0
Loss at iteration 460 : 249058426880.0
Loss at iteration 470 : 929582350336.0
Loss at iteration 480 : 225199210496.0
Loss at iteration 490 : 312446812160.0
Loss at iteration 500 : 1733915181056.0
Loss at iteration 510 : 366176174080.0
Loss at iteration 520 : 284187328512.0
Loss at iteration 530 : 2932380794880.0
Loss at iteration 540 : 1721857343488.0
Loss at iteration 550 : 9539979051008.0
Loss at iteration 560 : 29007919104.0
Loss at iteration 570 : 834047639552.0
Loss at iteration 580 : 543826935808.0
Loss at iteration 590 : 21530593460224.0
Loss at iteration 600 : 7080968192000.0
Loss at iteration 610 : 2131292848128.0
Loss at iteration 620 : 1744898359296.0
Loss at iteration 630 : 43380113408.0
Loss at iteration 640 : 544396378112.0
Loss at iteration 650 : 79556689920.0
Loss at iteration 660 : 593188880384.0
Loss at iteration 670 : 269514309632.0
Loss at iteration 680 : 118049398784.0
Loss at iteration 690 : 32302626816.0
Loss at iteration 700 : 6626014658560.0
Loss at iteration 710 : 907019681792.0
Loss at iteration 720 : 417063829504.0
Loss at iteration 730 : 105982230528.0
Loss at iteration 740 : 2302931107840.0
Loss at iteration 750 : 4813338624.0
Loss at iteration 760 : 411615690752.0
Loss at iteration 770 : 130011684864.0
Loss at iteration 780 : 1238334439424.0
Loss at iteration 790 : 116537131008.0
Loss at iteration 800 : 1175178969088.0
Loss at iteration 810 : 1627982790656.0
Loss at iteration 820 : 43602173952.0
Loss at iteration 830 : 116285857792.0
Loss at iteration 840 : 9678168064.0
Loss at iteration 850 : 124978872320.0
Loss at iteration 860 : 111290769408.0
Loss at iteration 870 : 102977798144.0
Loss at iteration 880 : 484800331776.0
Loss at iteration 890 : 422429949952.0
Loss at iteration 900 : 66304671744.0
Loss at iteration 910 : 260941987840.0
Loss at iteration 920 : 1112909676544.0
Loss at iteration 930 : 3213679656960.0
Loss at iteration 940 : 65218465792.0
Loss at iteration 950 : 24565579776.0
Loss at iteration 960 : 83730284544.0
Loss at iteration 970 : 83584729088.0
Loss at iteration 980 : 3468567040.0
Loss at iteration 990 : 6554691584.0
Loss at iteration 1000 : 593477500928.0
Loss at iteration 1010 : 10162988032.0
Loss at iteration 1020 : 1320484224.0
Loss at iteration 1030 : 443971862528.0
Loss at iteration 1040 : 73516425216.0
Loss at iteration 1050 : 46288949248.0
Loss at iteration 1060 : 190458314752.0
Loss at iteration 1070 : 6445112832.0
Loss at iteration 1080 : 618543120384.0
Loss at iteration 1090 : 357427019776.0
Loss at iteration 1100 : 188207316992.0
Loss at iteration 1110 : 95409356800.0
Loss at iteration 1120 : 14564701184.0
Loss at iteration 1130 : 685413105664.0
Loss at iteration 1140 : 1225312043008.0
Loss at iteration 1150 : 42885402624.0
Loss at iteration 1160 : 8250866176.0
Loss at iteration 1170 : 78018666496.0
Loss at iteration 1180 : 33085417472.0
Loss at iteration 1190 : 135296647168.0
Loss at iteration 1200 : 251704475648.0
Loss at iteration 1210 : 178956828672.0
Loss at iteration 1220 : 33721118720.0
Loss at iteration 1230 : 156900704256.0
Loss at iteration 1240 : 145217765376.0
Loss at iteration 1250 : 154037272576.0
Loss at iteration 1260 : 3723947520.0
Loss at iteration 1270 : 91738046464.0
Loss at iteration 1280 : 95448489984.0
Loss at iteration 1290 : 325820416000.0
Loss at iteration 1300 : 42261696512.0
Loss at iteration 1310 : 97118765056.0
Loss at iteration 1320 : 55120666624.0
Loss at iteration 1330 : 37555974144.0
Loss at iteration 1340 : 310037741568.0
Loss at iteration 1350 : 54097920000.0
Loss at iteration 1360 : 4684562432.0
Loss at iteration 1370 : 83155386368.0
Loss at iteration 1380 : 70982443008.0
Loss at iteration 1390 : 90971889664.0
Loss at iteration 1400 : 124325789696.0
Loss at iteration 1410 : 104094007296.0
Loss at iteration 1420 : 14169579520.0
Loss at iteration 1430 : 62231093248.0
Loss at iteration 1440 : 969587425280.0
Loss at iteration 1450 : 510014128128.0
Loss at iteration 1460 : 314867253248.0
Loss at iteration 1470 : 10733293568.0
Loss at iteration 1480 : 50875269120.0
Loss at iteration 1490 : 1281895301120.0
Loss at iteration 1500 : 31683065856.0
Loss at iteration 1510 : 201388769280.0
Loss at iteration 1520 : 1471764234240.0
Loss at iteration 1530 : 162269413376.0
Loss at iteration 1540 : 97743265792.0
Loss at iteration 1550 : 573410639872.0
Loss at iteration 1560 : 68177920000.0
Loss at iteration 1570 : 262741671936.0
Loss at iteration 1580 : 8350331830272.0
Loss at iteration 1590 : 26495672320.0
Loss at iteration 1600 : 109816266752.0
Loss at iteration 1610 : 11869773824.0
Loss at iteration 1620 : 7561234944.0
Loss at iteration 1630 : 392214216704.0
Loss at iteration 1640 : 198522798080.0
Loss at iteration 1650 : 79776841728.0
Loss at iteration 1660 : 19941117952.0
Loss at iteration 1670 : 551915094016.0
Loss at iteration 1680 : 163606904832.0
Loss at iteration 1690 : 88141185024.0
Loss at iteration 1700 : 29716504576.0
Loss at iteration 1710 : 9453863936.0
Loss at iteration 1720 : 34880090112.0
Loss at iteration 1730 : 77299367936.0
Loss at iteration 1740 : 9556970496.0
Loss at iteration 1750 : 140155633664.0
Loss at iteration 1760 : 91683315712.0
Loss at iteration 1770 : 84416593920.0
Loss at iteration 1780 : 19654207488.0
Loss at iteration 1790 : 11390323712.0
Loss at iteration 1800 : 32142684160.0
Loss at iteration 1810 : 10923369472.0
Loss at iteration 1820 : 206308409344.0
Loss at iteration 1830 : 46097342464.0
Loss at iteration 1840 : 21493241856.0
Loss at iteration 1850 : 51744681984.0
Loss at iteration 1860 : 973714423808.0
Loss at iteration 1870 : 169997795328.0
Loss at iteration 1880 : 6024264704.0
Loss at iteration 1890 : 113478033408.0
Loss at iteration 1900 : 74087235584.0
Loss at iteration 1910 : 34654658560.0
Loss at iteration 1920 : 671276990464.0
Loss at iteration 1930 : 370081792000.0
Loss at iteration 1940 : 273191174144.0
Loss at iteration 1950 : 135728324608.0
Loss at iteration 1960 : 17663170560.0
Loss at iteration 1970 : 1402734208.0
Loss at iteration 1980 : 18481973248.0
Loss at iteration 1990 : 64116084736.0
Loss at iteration 2000 : 3822736128.0
Loss at iteration 2010 : 119109402624.0
Loss at iteration 2020 : 3791857408.0
Loss at iteration 2030 : 87559233536.0
Loss at iteration 2040 : 32261296128.0
Loss at iteration 2050 : 31255488512.0
Loss at iteration 2060 : 40982880256.0
Loss at iteration 2070 : 68628705280.0
Loss at iteration 2080 : 923150581760.0
Loss at iteration 2090 : 63678799872.0
Loss at iteration 2100 : 11561831424.0
Loss at iteration 2110 : 37323255808.0
Loss at iteration 2120 : 3849478912.0
Loss at iteration 2130 : 86821511168.0
Loss at iteration 2140 : 110958362624.0
Loss at iteration 2150 : 52407779328.0
Loss at iteration 2160 : 68979236864.0
Loss at iteration 2170 : 100039573504.0
Loss at iteration 2180 : 5004003328.0
Loss at iteration 2190 : 956111680.0
Loss at iteration 2200 : 13282463744.0
Loss at iteration 2210 : 348326068224.0
Loss at iteration 2220 : 96762462208.0
Loss at iteration 2230 : 1262058624.0
Loss at iteration 2240 : 28553820160.0
Loss at iteration 2250 : 549280874496.0
Loss at iteration 2260 : 37389320192.0
Loss at iteration 2270 : 10655759360.0
Loss at iteration 2280 : 1323891328.0
Loss at iteration 2290 : 5816034304.0
Loss at iteration 2300 : 63104458752.0
Loss at iteration 2310 : 96146169856.0
Loss at iteration 2320 : 348287072.0
Loss at iteration 2330 : 1366999040.0
Loss at iteration 2340 : 8453698560.0
Loss at iteration 2350 : 852181824.0
Loss at iteration 2360 : 1837026560.0
Loss at iteration 2370 : 4207981312.0
Loss at iteration 2380 : 92123299840.0
Loss at iteration 2390 : 32821993472.0
Loss at iteration 2400 : 19734923264.0
Loss at iteration 2410 : 13449555968.0
Loss at iteration 2420 : 239936471040.0
The SSIM Value is: 5.310713779257033e-06
The PSNR Value is: -118.5946055094401
the epoch is: 156
Loss at iteration 10 : 69076721664.0
Loss at iteration 20 : 260134436864.0
Loss at iteration 30 : 170346348544.0
Loss at iteration 40 : 257420492800.0
Loss at iteration 50 : 603720253440.0
Loss at iteration 60 : 22152505344.0
Loss at iteration 70 : 3987144704.0
Loss at iteration 80 : 6089169408.0
Loss at iteration 90 : 59486860.0
Loss at iteration 100 : 6762131968.0
Loss at iteration 110 : 5007043072.0
Loss at iteration 120 : 1215062144.0
Loss at iteration 130 : 2097754112.0
Loss at iteration 140 : 19324030976.0
Loss at iteration 150 : 4188673024.0
Loss at iteration 160 : 12755703808.0
Loss at iteration 170 : 477376000.0
Loss at iteration 180 : 3482497280.0
Loss at iteration 190 : 4074371840.0
Loss at iteration 200 : 5076782592.0
Loss at iteration 210 : 1997223168.0
Loss at iteration 220 : 1810991360.0
Loss at iteration 230 : 1248035456.0
Loss at iteration 240 : 3884929792.0
Loss at iteration 250 : 19665084416.0
Loss at iteration 260 : 3651832832.0
Loss at iteration 270 : 5437182976.0
Loss at iteration 280 : 7365287424.0
Loss at iteration 290 : 1499570176.0
Loss at iteration 300 : 4770252800.0
Loss at iteration 310 : 20968493056.0
Loss at iteration 320 : 5554038272.0
Loss at iteration 330 : 4871683584.0
Loss at iteration 340 : 2027267328.0
Loss at iteration 350 : 21113253888.0
Loss at iteration 360 : 1496119808.0
Loss at iteration 370 : 6504711680.0
Loss at iteration 380 : 75814488.0
Loss at iteration 390 : 134586531840.0
Loss at iteration 400 : 70978396160.0
Loss at iteration 410 : 25961091072.0
Loss at iteration 420 : 3481348096.0
Loss at iteration 430 : 27560413184.0
Loss at iteration 440 : 114114789376.0
Loss at iteration 450 : 31589644288.0
Loss at iteration 460 : 18654005248.0
Loss at iteration 470 : 6264918528.0
Loss at iteration 480 : 5749547008.0
Loss at iteration 490 : 11780366336.0
Loss at iteration 500 : 1180542464.0
Loss at iteration 510 : 39258591232.0
Loss at iteration 520 : 120854798336.0
Loss at iteration 530 : 5757186560.0
Loss at iteration 540 : 1084197888.0
Loss at iteration 550 : 22437474304.0
Loss at iteration 560 : 2301001472.0
Loss at iteration 570 : 7994105856.0
Loss at iteration 580 : 6988314624.0
Loss at iteration 590 : 3747963648.0
Loss at iteration 600 : 27526176768.0
Loss at iteration 610 : 4036430080.0
Loss at iteration 620 : 89995157504.0
Loss at iteration 630 : 167410576.0
Loss at iteration 640 : 970130048.0
Loss at iteration 650 : 10725899264.0
Loss at iteration 660 : 136782249984.0
Loss at iteration 670 : 12938217472.0
Loss at iteration 680 : 1649498752.0
Loss at iteration 690 : 866280000.0
Loss at iteration 700 : 2096923904.0
Loss at iteration 710 : 3606669568.0
Loss at iteration 720 : 7703191552.0
Loss at iteration 730 : 42269945856.0
Loss at iteration 740 : 3953697280.0
Loss at iteration 750 : 14499000320.0
Loss at iteration 760 : 7894493184.0
Loss at iteration 770 : 1458651392.0
Loss at iteration 780 : 6880963072.0
Loss at iteration 790 : 7500179968.0
Loss at iteration 800 : 6789854208.0
Loss at iteration 810 : 4589734912.0
Loss at iteration 820 : 1194671488.0
Loss at iteration 830 : 7103564288.0
Loss at iteration 840 : 845415251968.0
Loss at iteration 850 : 3416331776.0
Loss at iteration 860 : 21707452416.0
Loss at iteration 870 : 794957376.0
Loss at iteration 880 : 5041138176.0
Loss at iteration 890 : 39312056320.0
Loss at iteration 900 : 1146509568.0
Loss at iteration 910 : 3184947101696.0
Loss at iteration 920 : 5558379520.0
Loss at iteration 930 : 1377415069696.0
Loss at iteration 940 : 302942453760.0
Loss at iteration 950 : 13357241344.0
Loss at iteration 960 : 1175585408.0
Loss at iteration 970 : 4530407936.0
Loss at iteration 980 : 12118569984.0
Loss at iteration 990 : 27372210176.0
Loss at iteration 1000 : 910858560.0
Loss at iteration 1010 : 5673132544.0
Loss at iteration 1020 : 1904189568.0
Loss at iteration 1030 : 9851338752.0
Loss at iteration 1040 : 9721776128.0
Loss at iteration 1050 : 4446893568.0
Loss at iteration 1060 : 17493389312.0
Loss at iteration 1070 : 39219499008.0
Loss at iteration 1080 : 23642286080.0
Loss at iteration 1090 : 925352832.0
Loss at iteration 1100 : 31030118400.0
Loss at iteration 1110 : 22106777600.0
Loss at iteration 1120 : 16977528832.0
Loss at iteration 1130 : 7437545984.0
Loss at iteration 1140 : 794221568.0
Loss at iteration 1150 : 3496906752.0
Loss at iteration 1160 : 10583198720.0
Loss at iteration 1170 : 4396771328.0
Loss at iteration 1180 : 981555200.0
Loss at iteration 1190 : 14904785920.0
Loss at iteration 1200 : 15059253248.0
Loss at iteration 1210 : 38751117312.0
Loss at iteration 1220 : 109576445952.0
Loss at iteration 1230 : 11089845248.0
Loss at iteration 1240 : 102496239616.0
Loss at iteration 1250 : 268179406848.0
Loss at iteration 1260 : 301576552448.0
Loss at iteration 1270 : 22208702464.0
Loss at iteration 1280 : 1025470758912.0
Loss at iteration 1290 : 2245229543424.0
Loss at iteration 1300 : 34947379200.0
Loss at iteration 1310 : 63241744384.0
Loss at iteration 1320 : 51106750464.0
Loss at iteration 1330 : 11904890880.0
Loss at iteration 1340 : 415667650560.0
Loss at iteration 1350 : 94629978112.0
Loss at iteration 1360 : 127267315712.0
Loss at iteration 1370 : 17214334976.0
Loss at iteration 1380 : 34262534144.0
Loss at iteration 1390 : 20475752448.0
Loss at iteration 1400 : 19519657984.0
Loss at iteration 1410 : 305346281472.0
Loss at iteration 1420 : 63077048320.0
Loss at iteration 1430 : 39397560320.0
Loss at iteration 1440 : 5604882944.0
Loss at iteration 1450 : 91975622656.0
Loss at iteration 1460 : 1596825010176.0
Loss at iteration 1470 : 584050737152.0
Loss at iteration 1480 : 8720805888.0
Loss at iteration 1490 : 45147136000.0
Loss at iteration 1500 : 50238509056.0
Loss at iteration 1510 : 32724758528.0
Loss at iteration 1520 : 33850986496.0
Loss at iteration 1530 : 53472514048.0
Loss at iteration 1540 : 21937897472.0
Loss at iteration 1550 : 26248660992.0
Loss at iteration 1560 : 112914579456.0
Loss at iteration 1570 : 10968293376.0
Loss at iteration 1580 : 52593618944.0
Loss at iteration 1590 : 34402103296.0
Loss at iteration 1600 : 46522449920.0
Loss at iteration 1610 : 40884465664.0
Loss at iteration 1620 : 3896186112.0
Loss at iteration 1630 : 376156880896.0
Loss at iteration 1640 : 23433891840.0
Loss at iteration 1650 : 86906519552.0
Loss at iteration 1660 : 2652461056.0
Loss at iteration 1670 : 23186714624.0
Loss at iteration 1680 : 29110226944.0
Loss at iteration 1690 : 110520918016.0
Loss at iteration 1700 : 26781667328.0
Loss at iteration 1710 : 18828421120.0
Loss at iteration 1720 : 11279353856.0
Loss at iteration 1730 : 74089996288.0
Loss at iteration 1740 : 3712204288.0
Loss at iteration 1750 : 38297190400.0
Loss at iteration 1760 : 751436416.0
Loss at iteration 1770 : 109253140480.0
Loss at iteration 1780 : 9647343616.0
Loss at iteration 1790 : 45349134336.0
Loss at iteration 1800 : 28284604416.0
Loss at iteration 1810 : 19532017664.0
Loss at iteration 1820 : 24358856704.0
Loss at iteration 1830 : 23501965312.0
Loss at iteration 1840 : 10638589952.0
Loss at iteration 1850 : 13197619200.0
Loss at iteration 1860 : 6568720896.0
Loss at iteration 1870 : 9666428928.0
Loss at iteration 1880 : 46730383360.0
Loss at iteration 1890 : 19077345280.0
Loss at iteration 1900 : 146282676224.0
Loss at iteration 1910 : 15917604864.0
Loss at iteration 1920 : 31437531136.0
Loss at iteration 1930 : 44022132736.0
Loss at iteration 1940 : 8225897984.0
Loss at iteration 1950 : 12245167104.0
Loss at iteration 1960 : 644448845824.0
Loss at iteration 1970 : 64500588544.0
Loss at iteration 1980 : 26465540096.0
Loss at iteration 1990 : 91592761344.0
Loss at iteration 2000 : 19340847104.0
Loss at iteration 2010 : 6703664128.0
Loss at iteration 2020 : 139717984256.0
Loss at iteration 2030 : 239962161152.0
Loss at iteration 2040 : 61332299776.0
Loss at iteration 2050 : 1322078592.0
Loss at iteration 2060 : 5004979712.0
Loss at iteration 2070 : 51246190592.0
Loss at iteration 2080 : 4250117888.0
Loss at iteration 2090 : 627546456064.0
Loss at iteration 2100 : 28514512896.0
Loss at iteration 2110 : 8746830848.0
Loss at iteration 2120 : 5323635712.0
Loss at iteration 2130 : 1135421030400.0
Loss at iteration 2140 : 455524483072.0
Loss at iteration 2150 : 98575179776.0
Loss at iteration 2160 : 247115202560.0
Loss at iteration 2170 : 167734444032.0
Loss at iteration 2180 : 134941474816.0
Loss at iteration 2190 : 307802767360.0
Loss at iteration 2200 : 9751995392.0
Loss at iteration 2210 : 179564380160.0
Loss at iteration 2220 : 41758269440.0
Loss at iteration 2230 : 33966104576.0
Loss at iteration 2240 : 8586151424.0
Loss at iteration 2250 : 72418951168.0
Loss at iteration 2260 : 11717368832.0
Loss at iteration 2270 : 19166537728.0
Loss at iteration 2280 : 5791828992.0
Loss at iteration 2290 : 23257862144.0
Loss at iteration 2300 : 117741715456.0
Loss at iteration 2310 : 28388200448.0
Loss at iteration 2320 : 12654698496.0
Loss at iteration 2330 : 10145790976.0
Loss at iteration 2340 : 35792941056.0
Loss at iteration 2350 : 3761382912.0
Loss at iteration 2360 : 13775083520.0
Loss at iteration 2370 : 1502620942336.0
Loss at iteration 2380 : 105609912320.0
Loss at iteration 2390 : 51476054016.0
Loss at iteration 2400 : 79680520192.0
Loss at iteration 2410 : 5542087168.0
Loss at iteration 2420 : 268761726976.0
The SSIM Value is: 1.4768413147218478e-07
The PSNR Value is: -119.01885782877604
the epoch is: 157
Loss at iteration 10 : 151929257984.0
Loss at iteration 20 : 48883523584.0
Loss at iteration 30 : 378478592000.0
Loss at iteration 40 : 224307724288.0
Loss at iteration 50 : 248906219520.0
Loss at iteration 60 : 1210364723200.0
Loss at iteration 70 : 191244271616.0
Loss at iteration 80 : 24550754304.0
Loss at iteration 90 : 54641500160.0
Loss at iteration 100 : 9283786752.0
Loss at iteration 110 : 392361705472.0
Loss at iteration 120 : 74690682880.0
Loss at iteration 130 : 52412735488.0
Loss at iteration 140 : 18415056896.0
Loss at iteration 150 : 9186715648.0
Loss at iteration 160 : 10271365120.0
Loss at iteration 170 : 136891473920.0
Loss at iteration 180 : 15040766976.0
Loss at iteration 190 : 16029784064.0
Loss at iteration 200 : 107683790848.0
Loss at iteration 210 : 20864442368.0
Loss at iteration 220 : 13809741824.0
Loss at iteration 230 : 146355404800.0
Loss at iteration 240 : 60531105792.0
Loss at iteration 250 : 62327271424.0
Loss at iteration 260 : 17471199232.0
Loss at iteration 270 : 8055330816.0
Loss at iteration 280 : 1022138944.0
Loss at iteration 290 : 42191294464.0
Loss at iteration 300 : 39298818048.0
Loss at iteration 310 : 285919313920.0
Loss at iteration 320 : 4583724032.0
Loss at iteration 330 : 7045855232.0
Loss at iteration 340 : 2007357952.0
Loss at iteration 350 : 28118411264.0
Loss at iteration 360 : 3074171904.0
Loss at iteration 370 : 7151144448.0
Loss at iteration 380 : 7407204864.0
Loss at iteration 390 : 13420208128.0
Loss at iteration 400 : 40201584640.0
Loss at iteration 410 : 20249223168.0
Loss at iteration 420 : 5308129792.0
Loss at iteration 430 : 3644777216.0
Loss at iteration 440 : 24141088768.0
Loss at iteration 450 : 2757467136.0
Loss at iteration 460 : 10913802240.0
Loss at iteration 470 : 29459881984.0
Loss at iteration 480 : 33674229760.0
Loss at iteration 490 : 5513726464.0
Loss at iteration 500 : 21443198976.0
Loss at iteration 510 : 9157969920.0
Loss at iteration 520 : 4603482112.0
Loss at iteration 530 : 853360768.0
Loss at iteration 540 : 8543560704.0
Loss at iteration 550 : 4351205888.0
Loss at iteration 560 : 7286823424.0
Loss at iteration 570 : 2230326528.0
Loss at iteration 580 : 2923438080.0
Loss at iteration 590 : 20180187136.0
Loss at iteration 600 : 3698653696.0
Loss at iteration 610 : 2504558592.0
Loss at iteration 620 : 766696000.0
Loss at iteration 630 : 1090910464.0
Loss at iteration 640 : 2347801344.0
Loss at iteration 650 : 4868673024.0
Loss at iteration 660 : 5819809280.0
Loss at iteration 670 : 7072111616.0
Loss at iteration 680 : 1517004288.0
Loss at iteration 690 : 15102791680.0
Loss at iteration 700 : 43208957952.0
Loss at iteration 710 : 8673362944.0
Loss at iteration 720 : 9114661888.0
Loss at iteration 730 : 2759136000.0
Loss at iteration 740 : 2130727040.0
Loss at iteration 750 : 15106348032.0
Loss at iteration 760 : 6504177664.0
Loss at iteration 770 : 184696209408.0
Loss at iteration 780 : 14229161984.0
Loss at iteration 790 : 3258463744.0
Loss at iteration 800 : 18502928384.0
Loss at iteration 810 : 282143719424.0
Loss at iteration 820 : 28472702976.0
Loss at iteration 830 : 17461411840.0
Loss at iteration 840 : 21007937536.0
Loss at iteration 850 : 33477511168.0
Loss at iteration 860 : 32880080896.0
Loss at iteration 870 : 14403928064.0
Loss at iteration 880 : 26132166656.0
Loss at iteration 890 : 1726832512.0
Loss at iteration 900 : 12955111424.0
Loss at iteration 910 : 6662983680.0
Loss at iteration 920 : 3049042432.0
Loss at iteration 930 : 3010470144.0
Loss at iteration 940 : 9435297792.0
Loss at iteration 950 : 9971304448.0
Loss at iteration 960 : 11479779328.0
Loss at iteration 970 : 168321957888.0
Loss at iteration 980 : 534075424.0
Loss at iteration 990 : 19074727936.0
Loss at iteration 1000 : 19557453824.0
Loss at iteration 1010 : 17026034688.0
Loss at iteration 1020 : 4272733440.0
Loss at iteration 1030 : 12043077632.0
Loss at iteration 1040 : 4768147456.0
Loss at iteration 1050 : 34111776768.0
Loss at iteration 1060 : 665793462272.0
Loss at iteration 1070 : 6118029312.0
Loss at iteration 1080 : 8313945088.0
Loss at iteration 1090 : 23292233728.0
Loss at iteration 1100 : 114259304448.0
Loss at iteration 1110 : 28367865856.0
Loss at iteration 1120 : 10198384640.0
Loss at iteration 1130 : 2100397184.0
Loss at iteration 1140 : 46472704000.0
Loss at iteration 1150 : 12155490304.0
Loss at iteration 1160 : 9885666304.0
Loss at iteration 1170 : 15036582912.0
Loss at iteration 1180 : 5363072512.0
Loss at iteration 1190 : 52381257728.0
Loss at iteration 1200 : 12299709440.0
Loss at iteration 1210 : 2465778176.0
Loss at iteration 1220 : 58317918208.0
Loss at iteration 1230 : 1275244672.0
Loss at iteration 1240 : 103420944384.0
Loss at iteration 1250 : 7453623808.0
Loss at iteration 1260 : 11203662848.0
Loss at iteration 1270 : 3899810304.0
Loss at iteration 1280 : 419276544.0
Loss at iteration 1290 : 213690580992.0
Loss at iteration 1300 : 54690877440.0
Loss at iteration 1310 : 6933505024.0
Loss at iteration 1320 : 1230296960.0
Loss at iteration 1330 : 12811023360.0
Loss at iteration 1340 : 4337871360.0
Loss at iteration 1350 : 1155353728.0
Loss at iteration 1360 : 8596002816.0
Loss at iteration 1370 : 16379182080.0
Loss at iteration 1380 : 839611264.0
Loss at iteration 1390 : 17830107136.0
Loss at iteration 1400 : 14544358400.0
Loss at iteration 1410 : 5824355328.0
Loss at iteration 1420 : 1856861056.0
Loss at iteration 1430 : 3974062080.0
Loss at iteration 1440 : 2634475008.0
Loss at iteration 1450 : 5770129408.0
Loss at iteration 1460 : 1819535616.0
Loss at iteration 1470 : 8953400320.0
Loss at iteration 1480 : 18121336832.0
Loss at iteration 1490 : 3496066816.0
Loss at iteration 1500 : 3914855680.0
Loss at iteration 1510 : 13300347904.0
Loss at iteration 1520 : 2225046016.0
Loss at iteration 1530 : 11871583232.0
Loss at iteration 1540 : 1053774464.0
Loss at iteration 1550 : 6262875136.0
Loss at iteration 1560 : 13495788544.0
Loss at iteration 1570 : 532528128.0
Loss at iteration 1580 : 4407512064.0
Loss at iteration 1590 : 2556528384.0
Loss at iteration 1600 : 3220272128.0
Loss at iteration 1610 : 14992625664.0
Loss at iteration 1620 : 5045232128.0
Loss at iteration 1630 : 12956717056.0
Loss at iteration 1640 : 10942268416.0
Loss at iteration 1650 : 9712811008.0
Loss at iteration 1660 : 9209039872.0
Loss at iteration 1670 : 552847424.0
Loss at iteration 1680 : 10169231360.0
Loss at iteration 1690 : 135503257600.0
Loss at iteration 1700 : 22015707136.0
Loss at iteration 1710 : 59333005312.0
Loss at iteration 1720 : 405216992.0
Loss at iteration 1730 : 1087001216.0
Loss at iteration 1740 : 6361616896.0
Loss at iteration 1750 : 3312134400.0
Loss at iteration 1760 : 67199918080.0
Loss at iteration 1770 : 8984645632.0
Loss at iteration 1780 : 97585544.0
Loss at iteration 1790 : 1501307136.0
Loss at iteration 1800 : 4192377856.0
Loss at iteration 1810 : 1843573120.0
Loss at iteration 1820 : 330971008.0
Loss at iteration 1830 : 15033592832.0
Loss at iteration 1840 : 49952022528.0
Loss at iteration 1850 : 6091121664.0
Loss at iteration 1860 : 3915598848.0
Loss at iteration 1870 : 3080831744.0
Loss at iteration 1880 : 13797738496.0
Loss at iteration 1890 : 2654485760.0
Loss at iteration 1900 : 2522976512.0
Loss at iteration 1910 : 3727967744.0
Loss at iteration 1920 : 8120753152.0
Loss at iteration 1930 : 877113472.0
Loss at iteration 1940 : 882575872.0
Loss at iteration 1950 : 3341142016.0
Loss at iteration 1960 : 853061824.0
Loss at iteration 1970 : 25965797376.0
Loss at iteration 1980 : 2721339392.0
Loss at iteration 1990 : 10432068608.0
Loss at iteration 2000 : 9511842816.0
Loss at iteration 2010 : 293749760.0
Loss at iteration 2020 : 3109344256.0
Loss at iteration 2030 : 8198129664.0
Loss at iteration 2040 : 3870351104.0
Loss at iteration 2050 : 4488481280.0
Loss at iteration 2060 : 7135290368.0
Loss at iteration 2070 : 2220003072.0
Loss at iteration 2080 : 2957889792.0
Loss at iteration 2090 : 1931802496.0
Loss at iteration 2100 : 811554880.0
Loss at iteration 2110 : 16979733504.0
Loss at iteration 2120 : 256872656.0
Loss at iteration 2130 : 16405118976.0
Loss at iteration 2140 : 44639293440.0
Loss at iteration 2150 : 1296457728.0
Loss at iteration 2160 : 130656752.0
Loss at iteration 2170 : 457881696.0
Loss at iteration 2180 : 738329280.0
Loss at iteration 2190 : 38368488.0
Loss at iteration 2200 : 125988432.0
Loss at iteration 2210 : 471467616.0
Loss at iteration 2220 : 682157248.0
Loss at iteration 2230 : 1654970624.0
Loss at iteration 2240 : 1826952576.0
Loss at iteration 2250 : 5346553344.0
Loss at iteration 2260 : 51994370048.0
Loss at iteration 2270 : 4601029120.0
Loss at iteration 2280 : 650926208.0
Loss at iteration 2290 : 26767548416.0
Loss at iteration 2300 : 173164896.0
Loss at iteration 2310 : 2370243328.0
Loss at iteration 2320 : 545874624.0
Loss at iteration 2330 : 12445285376.0
Loss at iteration 2340 : 547618624.0
Loss at iteration 2350 : 2176898560.0
Loss at iteration 2360 : 1845242624.0
Loss at iteration 2370 : 2798516224.0
Loss at iteration 2380 : 17543100416.0
Loss at iteration 2390 : 52703056.0
Loss at iteration 2400 : 5432780800.0
Loss at iteration 2410 : 12316039168.0
Loss at iteration 2420 : 9640680448.0
The SSIM Value is: 7.678619302472119e-07
The PSNR Value is: -99.45581461588542
the epoch is: 158
Loss at iteration 10 : 2189187584.0
Loss at iteration 20 : 5825080832.0
Loss at iteration 30 : 5846230528.0
Loss at iteration 40 : 5813572096.0
Loss at iteration 50 : 488434880.0
Loss at iteration 60 : 2446882560.0
Loss at iteration 70 : 520694496.0
Loss at iteration 80 : 803038720.0
Loss at iteration 90 : 2401830912.0
Loss at iteration 100 : 10422369280.0
Loss at iteration 110 : 7533129728.0
Loss at iteration 120 : 4692974592.0
Loss at iteration 130 : 8937546752.0
Loss at iteration 140 : 28203106304.0
Loss at iteration 150 : 15504948224.0
Loss at iteration 160 : 2978439680.0
Loss at iteration 170 : 2814255104.0
Loss at iteration 180 : 4341771264.0
Loss at iteration 190 : 1430888192.0
Loss at iteration 200 : 9189678080.0
Loss at iteration 210 : 8047963136.0
Loss at iteration 220 : 3246784000.0
Loss at iteration 230 : 8576785408.0
Loss at iteration 240 : 3904580352.0
Loss at iteration 250 : 1336761472.0
Loss at iteration 260 : 10104189952.0
Loss at iteration 270 : 918071872.0
Loss at iteration 280 : 2559144960.0
Loss at iteration 290 : 3651487488.0
Loss at iteration 300 : 54856343552.0
Loss at iteration 310 : 11838441472.0
Loss at iteration 320 : 2258046976.0
Loss at iteration 330 : 892953280.0
Loss at iteration 340 : 4022865408.0
Loss at iteration 350 : 3238666240.0
Loss at iteration 360 : 6789175808.0
Loss at iteration 370 : 6543952384.0
Loss at iteration 380 : 2956187904.0
Loss at iteration 390 : 2171996416.0
Loss at iteration 400 : 1425756672.0
Loss at iteration 410 : 1026612032.0
Loss at iteration 420 : 474794528.0
Loss at iteration 430 : 289557056.0
Loss at iteration 440 : 4898565632.0
Loss at iteration 450 : 660338944.0
Loss at iteration 460 : 8414004224.0
Loss at iteration 470 : 351451744.0
Loss at iteration 480 : 1971502336.0
Loss at iteration 490 : 734266560.0
Loss at iteration 500 : 13297210368.0
Loss at iteration 510 : 11597517824.0
Loss at iteration 520 : 1525789184.0
Loss at iteration 530 : 3248705536.0
Loss at iteration 540 : 6210713088.0
Loss at iteration 550 : 2039359104.0
Loss at iteration 560 : 9223866368.0
Loss at iteration 570 : 22102558720.0
Loss at iteration 580 : 846513600.0
Loss at iteration 590 : 237947040.0
Loss at iteration 600 : 8851377152.0
Loss at iteration 610 : 2968565760.0
Loss at iteration 620 : 17043806208.0
Loss at iteration 630 : 1310186496.0
Loss at iteration 640 : 1646458880.0
Loss at iteration 650 : 9390947328.0
Loss at iteration 660 : 922866752.0
Loss at iteration 670 : 6436765184.0
Loss at iteration 680 : 1653351680.0
Loss at iteration 690 : 143710240768.0
Loss at iteration 700 : 4208427520.0
Loss at iteration 710 : 33715890176.0
Loss at iteration 720 : 82092556288.0
Loss at iteration 730 : 812465061888.0
Loss at iteration 740 : 69509341184.0
Loss at iteration 750 : 55134420992.0
Loss at iteration 760 : 1937121280.0
Loss at iteration 770 : 3844014336.0
Loss at iteration 780 : 31716272128.0
Loss at iteration 790 : 465086048.0
Loss at iteration 800 : 4667156480.0
Loss at iteration 810 : 884827200.0
Loss at iteration 820 : 1002586176.0
Loss at iteration 830 : 230896240.0
Loss at iteration 840 : 3140342784.0
Loss at iteration 850 : 2310949632.0
Loss at iteration 860 : 5905694720.0
Loss at iteration 870 : 14536511488.0
Loss at iteration 880 : 5234026496.0
Loss at iteration 890 : 6444042752.0
Loss at iteration 900 : 3918110976.0
Loss at iteration 910 : 137978281984.0
Loss at iteration 920 : 400333760.0
Loss at iteration 930 : 2435991552.0
Loss at iteration 940 : 10239594496.0
Loss at iteration 950 : 352479346688.0
Loss at iteration 960 : 494724481024.0
Loss at iteration 970 : 485231427584.0
Loss at iteration 980 : 482857615360.0
Loss at iteration 990 : 841123627008.0
Loss at iteration 1000 : 1966578204672.0
Loss at iteration 1010 : 593175379968.0
Loss at iteration 1020 : 117538103296.0
Loss at iteration 1030 : 999492747264.0
Loss at iteration 1040 : 564124647424.0
Loss at iteration 1050 : 938358800384.0
Loss at iteration 1060 : 114662580224.0
Loss at iteration 1070 : 6152363966464.0
Loss at iteration 1080 : 13360710025216.0
Loss at iteration 1090 : 119931674624.0
Loss at iteration 1100 : 43844116480.0
Loss at iteration 1110 : 48041070592.0
Loss at iteration 1120 : 452464148480.0
Loss at iteration 1130 : 113596907520.0
Loss at iteration 1140 : 1329680089088.0
Loss at iteration 1150 : 108447866880.0
Loss at iteration 1160 : 274248122368.0
Loss at iteration 1170 : 165624791040.0
Loss at iteration 1180 : 1174195929088.0
Loss at iteration 1190 : 406177316864.0
Loss at iteration 1200 : 1771981373440.0
Loss at iteration 1210 : 266974806016.0
Loss at iteration 1220 : 134958333952.0
Loss at iteration 1230 : 40884883456.0
Loss at iteration 1240 : 85135772876800.0
Loss at iteration 1250 : 49532876357632.0
Loss at iteration 1260 : 17342114299904.0
Loss at iteration 1270 : 2857139961856.0
Loss at iteration 1280 : 51874979905536.0
Loss at iteration 1290 : 19428458627072.0
Loss at iteration 1300 : 47404447432704.0
Loss at iteration 1310 : 204263510769664.0
Loss at iteration 1320 : 135041908736.0
Loss at iteration 1330 : 268933332992.0
Loss at iteration 1340 : 895762875547648.0
Loss at iteration 1350 : 253216356827136.0
Loss at iteration 1360 : 13943615520768.0
Loss at iteration 1370 : 11882719084544.0
Loss at iteration 1380 : 6556499312640.0
Loss at iteration 1390 : 27156801388544.0
Loss at iteration 1400 : 301537624064.0
Loss at iteration 1410 : 4629260664832.0
Loss at iteration 1420 : 3518563876864.0
Loss at iteration 1430 : 25984308871168.0
Loss at iteration 1440 : 24403578454016.0
Loss at iteration 1450 : 335707308032.0
Loss at iteration 1460 : 299565187072.0
Loss at iteration 1470 : 3484727377920.0
Loss at iteration 1480 : 102421506293760.0
Loss at iteration 1490 : 6804348600320.0
Loss at iteration 1500 : 3721757196288.0
Loss at iteration 1510 : 1390083964928.0
Loss at iteration 1520 : 6131031736320.0
Loss at iteration 1530 : 5118875926528.0
Loss at iteration 1540 : 63849299968.0
Loss at iteration 1550 : 48145141760.0
Loss at iteration 1560 : 10509675921408.0
Loss at iteration 1570 : 85757435838464.0
Loss at iteration 1580 : 4783778299904.0
Loss at iteration 1590 : 37073142677504.0
Loss at iteration 1600 : 134095814656.0
Loss at iteration 1610 : 2235885158400.0
Loss at iteration 1620 : 4007284703232.0
Loss at iteration 1630 : 735349768192.0
Loss at iteration 1640 : 28660889288704.0
Loss at iteration 1650 : 7173981077504.0
Loss at iteration 1660 : 12296480882688.0
Loss at iteration 1670 : 1417913827328.0
Loss at iteration 1680 : 24309351317504.0
Loss at iteration 1690 : 1340991078400.0
Loss at iteration 1700 : 15207968538624.0
Loss at iteration 1710 : 5193011298304.0
Loss at iteration 1720 : 1252186259456.0
Loss at iteration 1730 : 1400425545728.0
Loss at iteration 1740 : 446197727232.0
Loss at iteration 1750 : 3474636406784.0
Loss at iteration 1760 : 80260366336.0
Loss at iteration 1770 : 79261499392.0
Loss at iteration 1780 : 138532391747584.0
Loss at iteration 1790 : 1033548857344.0
Loss at iteration 1800 : 1020655042560.0
Loss at iteration 1810 : 152758059008.0
Loss at iteration 1820 : 485516181504.0
Loss at iteration 1830 : 1867669045248.0
Loss at iteration 1840 : 830255464448.0
Loss at iteration 1850 : 13660106752.0
Loss at iteration 1860 : 620340641792.0
Loss at iteration 1870 : 1257350365184.0
Loss at iteration 1880 : 232484896768.0
Loss at iteration 1890 : 445169696768.0
Loss at iteration 1900 : 1234072633344.0
Loss at iteration 1910 : 1016560746496.0
Loss at iteration 1920 : 2503486996480.0
Loss at iteration 1930 : 5963957403648.0
Loss at iteration 1940 : 1555813367808.0
Loss at iteration 1950 : 5077804777472.0
Loss at iteration 1960 : 9775157870592.0
Loss at iteration 1970 : 1014946922496.0
Loss at iteration 1980 : 2739699712000.0
Loss at iteration 1990 : 43072602112.0
Loss at iteration 2000 : 8531896434688.0
Loss at iteration 2010 : 2108391948288.0
Loss at iteration 2020 : 92634603520.0
Loss at iteration 2030 : 6737521803264.0
Loss at iteration 2040 : 1055651135488.0
Loss at iteration 2050 : 24310255190016.0
Loss at iteration 2060 : 10799870377984.0
Loss at iteration 2070 : 8420899422208.0
Loss at iteration 2080 : 2182081806336.0
Loss at iteration 2090 : 2254148730880.0
Loss at iteration 2100 : 1085281009664.0
Loss at iteration 2110 : 1327976284160.0
Loss at iteration 2120 : 4574898814976.0
Loss at iteration 2130 : 158171758592.0
Loss at iteration 2140 : 1996962398208.0
Loss at iteration 2150 : 800692502528.0
Loss at iteration 2160 : 761238126592.0
Loss at iteration 2170 : 746331701248.0
Loss at iteration 2180 : 3235259088896.0
Loss at iteration 2190 : 664497487872.0
Loss at iteration 2200 : 850230050816.0
Loss at iteration 2210 : 2096996548608.0
Loss at iteration 2220 : 678838861824.0
Loss at iteration 2230 : 339009896448.0
Loss at iteration 2240 : 437793488896.0
Loss at iteration 2250 : 11239749058560.0
Loss at iteration 2260 : 6005058437120.0
Loss at iteration 2270 : 15882806886400.0
Loss at iteration 2280 : 839540473856.0
Loss at iteration 2290 : 36613246976.0
Loss at iteration 2300 : 3046199525376.0
Loss at iteration 2310 : 454990036992.0
Loss at iteration 2320 : 778449715200.0
Loss at iteration 2330 : 427017240576.0
Loss at iteration 2340 : 1944454692864.0
Loss at iteration 2350 : 2353489248256.0
Loss at iteration 2360 : 146722177024.0
Loss at iteration 2370 : 617369829376.0
Loss at iteration 2380 : 185216040960.0
Loss at iteration 2390 : 2495065358336.0
Loss at iteration 2400 : 348272099328.0
Loss at iteration 2410 : 73243475968.0
Loss at iteration 2420 : 177156734976.0
The SSIM Value is: -1.5440898247713145e-06
The PSNR Value is: -126.42453053792318
the epoch is: 159
Loss at iteration 10 : 2751427248128.0
Loss at iteration 20 : 1899570528256.0
Loss at iteration 30 : 2434752577536.0
Loss at iteration 40 : 2247808253952.0
Loss at iteration 50 : 349228498944.0
Loss at iteration 60 : 2369890549760.0
Loss at iteration 70 : 255125094400.0
Loss at iteration 80 : 485984600064.0
Loss at iteration 90 : 1997684342784.0
Loss at iteration 100 : 1765200887808.0
Loss at iteration 110 : 428097961984.0
Loss at iteration 120 : 682110550016.0
Loss at iteration 130 : 707602284544.0
Loss at iteration 140 : 158486478848.0
Loss at iteration 150 : 3015339147264.0
Loss at iteration 160 : 6399101239296.0
Loss at iteration 170 : 5386303176704.0
Loss at iteration 180 : 239401500672.0
Loss at iteration 190 : 300117819392.0
Loss at iteration 200 : 403532316672.0
Loss at iteration 210 : 1211171995648.0
Loss at iteration 220 : 2500194992128.0
Loss at iteration 230 : 126423482368.0
Loss at iteration 240 : 46226825216.0
Loss at iteration 250 : 371148587008.0
Loss at iteration 260 : 31111124992.0
Loss at iteration 270 : 404234993664.0
Loss at iteration 280 : 3618157887488.0
Loss at iteration 290 : 752696557568.0
Loss at iteration 300 : 176515661824.0
Loss at iteration 310 : 161763917824.0
Loss at iteration 320 : 204960284672.0
Loss at iteration 330 : 379481030656.0
Loss at iteration 340 : 292455940096.0
Loss at iteration 350 : 121559343104.0
Loss at iteration 360 : 79038595072.0
Loss at iteration 370 : 210824331264.0
Loss at iteration 380 : 344660049920.0
Loss at iteration 390 : 152316329984.0
Loss at iteration 400 : 509765025792.0
Loss at iteration 410 : 81609850880.0
Loss at iteration 420 : 384488636416.0
Loss at iteration 430 : 62390333440.0
Loss at iteration 440 : 258001747968.0
Loss at iteration 450 : 336251486208.0
Loss at iteration 460 : 203291377664.0
Loss at iteration 470 : 278360195072.0
Loss at iteration 480 : 469813493760.0
Loss at iteration 490 : 56547426304.0
Loss at iteration 500 : 69222662144.0
Loss at iteration 510 : 3526748798976.0
Loss at iteration 520 : 3119979167744.0
Loss at iteration 530 : 478004772864.0
Loss at iteration 540 : 598284042240.0
Loss at iteration 550 : 624931897344.0
Loss at iteration 560 : 1306610630656.0
Loss at iteration 570 : 981696774144.0
Loss at iteration 580 : 963546906624.0
Loss at iteration 590 : 3535995666432.0
Loss at iteration 600 : 2486676750336.0
Loss at iteration 610 : 427180359680.0
Loss at iteration 620 : 1254064390144.0
Loss at iteration 630 : 40540045312.0
Loss at iteration 640 : 193286012928.0
Loss at iteration 650 : 514167144448.0
Loss at iteration 660 : 17151200067584.0
Loss at iteration 670 : 1525110538240.0
Loss at iteration 680 : 673347403776.0
Loss at iteration 690 : 253555769344.0
Loss at iteration 700 : 165820383232.0
Loss at iteration 710 : 758460383232.0
Loss at iteration 720 : 228827807744.0
Loss at iteration 730 : 144244834304.0
Loss at iteration 740 : 755307970560.0
Loss at iteration 750 : 1683499646976.0
Loss at iteration 760 : 76254044160.0
Loss at iteration 770 : 54170660864.0
Loss at iteration 780 : 18106434977792.0
Loss at iteration 790 : 241503813632.0
Loss at iteration 800 : 516584701952.0
Loss at iteration 810 : 1527478616064.0
Loss at iteration 820 : 1816562630656.0
Loss at iteration 830 : 688159326208.0
Loss at iteration 840 : 466487148544.0
Loss at iteration 850 : 463819145216.0
Loss at iteration 860 : 307037732864.0
Loss at iteration 870 : 621999030272.0
Loss at iteration 880 : 667440775168.0
Loss at iteration 890 : 49713180672.0
Loss at iteration 900 : 1334503407616.0
Loss at iteration 910 : 135483899904.0
Loss at iteration 920 : 31843880960.0
Loss at iteration 930 : 779859329024.0
Loss at iteration 940 : 480909393920.0
Loss at iteration 950 : 800032751616.0
Loss at iteration 960 : 777753788416.0
Loss at iteration 970 : 171495866368.0
Loss at iteration 980 : 13557433368576.0
Loss at iteration 990 : 777929293824.0
Loss at iteration 1000 : 494068760576.0
Loss at iteration 1010 : 560203563008.0
Loss at iteration 1020 : 1427420086272.0
Loss at iteration 1030 : 58596331520.0
Loss at iteration 1040 : 739574153216.0
Loss at iteration 1050 : 792985862144.0
Loss at iteration 1060 : 1326619033600.0
Loss at iteration 1070 : 4041016082432.0
Loss at iteration 1080 : 1051807645696.0
Loss at iteration 1090 : 18362540032.0
Loss at iteration 1100 : 47390412800.0
Loss at iteration 1110 : 296728363008.0
Loss at iteration 1120 : 1006389231616.0
Loss at iteration 1130 : 475141832704.0
Loss at iteration 1140 : 1676661358592.0
Loss at iteration 1150 : 3672785289216.0
Loss at iteration 1160 : 119554605056.0
Loss at iteration 1170 : 49475727360.0
Loss at iteration 1180 : 153082920960.0
Loss at iteration 1190 : 513017839616.0
Loss at iteration 1200 : 712199241728.0
Loss at iteration 1210 : 49035419648.0
Loss at iteration 1220 : 237221920768.0
Loss at iteration 1230 : 116279697408.0
Loss at iteration 1240 : 225608957952.0
Loss at iteration 1250 : 561730748416.0
Loss at iteration 1260 : 601342279680.0
Loss at iteration 1270 : 20727656448.0
Loss at iteration 1280 : 332709036032.0
Loss at iteration 1290 : 117890064384.0
Loss at iteration 1300 : 1871131049984.0
Loss at iteration 1310 : 73872670720.0
Loss at iteration 1320 : 614983073792.0
Loss at iteration 1330 : 57404379136.0
Loss at iteration 1340 : 6213732401152.0
Loss at iteration 1350 : 7538225446912.0
Loss at iteration 1360 : 4619677204480.0
Loss at iteration 1370 : 32988716859392.0
Loss at iteration 1380 : 41442816000.0
Loss at iteration 1390 : 71263657984.0
Loss at iteration 1400 : 5100377997312.0
Loss at iteration 1410 : 667575713792.0
Loss at iteration 1420 : 363605590016.0
Loss at iteration 1430 : 65455116288.0
Loss at iteration 1440 : 258190770176.0
Loss at iteration 1450 : 88356667392.0
Loss at iteration 1460 : 983054680064.0
Loss at iteration 1470 : 246104899584.0
Loss at iteration 1480 : 1564392685568.0
Loss at iteration 1490 : 4773424136192.0
Loss at iteration 1500 : 317903699968.0
Loss at iteration 1510 : 588196675584.0
Loss at iteration 1520 : 358658932736.0
Loss at iteration 1530 : 1765439963136.0
Loss at iteration 1540 : 1861207326720.0
Loss at iteration 1550 : 515485401088.0
Loss at iteration 1560 : 390324813824.0
Loss at iteration 1570 : 268655001600.0
Loss at iteration 1580 : 152398069760.0
Loss at iteration 1590 : 537194070016.0
Loss at iteration 1600 : 93512024064.0
Loss at iteration 1610 : 248270979072.0
Loss at iteration 1620 : 111224864768.0
Loss at iteration 1630 : 4512671596544.0
Loss at iteration 1640 : 70992773120.0
Loss at iteration 1650 : 179862601728.0
Loss at iteration 1660 : 929102233600.0
Loss at iteration 1670 : 811017568256.0
Loss at iteration 1680 : 727551246336.0
Loss at iteration 1690 : 62061436928.0
Loss at iteration 1700 : 13359859712.0
Loss at iteration 1710 : 582788841472.0
Loss at iteration 1720 : 84641767751680.0
Loss at iteration 1730 : 119257800704.0
Loss at iteration 1740 : 6415317991424.0
Loss at iteration 1750 : 1745488314368.0
Loss at iteration 1760 : 1386068049920.0
Loss at iteration 1770 : 136200159232.0
Loss at iteration 1780 : 695796695040.0
Loss at iteration 1790 : 2843320778752.0
Loss at iteration 1800 : 262673825792.0
Loss at iteration 1810 : 1894973177856.0
Loss at iteration 1820 : 319051628544.0
Loss at iteration 1830 : 609466056704.0
Loss at iteration 1840 : 81237164032.0
Loss at iteration 1850 : 2186151067648.0
Loss at iteration 1860 : 326181224448.0
Loss at iteration 1870 : 428512280576.0
Loss at iteration 1880 : 74537517056.0
Loss at iteration 1890 : 1101030752256.0
Loss at iteration 1900 : 139750768640.0
Loss at iteration 1910 : 1917811163136.0
Loss at iteration 1920 : 4272955648.0
Loss at iteration 1930 : 264025554944.0
Loss at iteration 1940 : 386972418048.0
Loss at iteration 1950 : 2773762179072.0
Loss at iteration 1960 : 277394948096.0
Loss at iteration 1970 : 278873800704.0
Loss at iteration 1980 : 85506105344.0
Loss at iteration 1990 : 1252901519360.0
Loss at iteration 2000 : 9463298785280.0
Loss at iteration 2010 : 158801543168.0
Loss at iteration 2020 : 42477981696.0
Loss at iteration 2030 : 703661998080.0
Loss at iteration 2040 : 60109866663936.0
Loss at iteration 2050 : 1400035344384.0
Loss at iteration 2060 : 1384443281408.0
Loss at iteration 2070 : 2274937536512.0
Loss at iteration 2080 : 18116415488.0
Loss at iteration 2090 : 1926900875264.0
Loss at iteration 2100 : 1073160060928.0
Loss at iteration 2110 : 547145973760.0
Loss at iteration 2120 : 277930082304.0
Loss at iteration 2130 : 36324892672.0
Loss at iteration 2140 : 911792209920.0
Loss at iteration 2150 : 252835037184.0
Loss at iteration 2160 : 661399928832.0
Loss at iteration 2170 : 60330229760.0
Loss at iteration 2180 : 421119688704.0
Loss at iteration 2190 : 1097156853760.0
Loss at iteration 2200 : 692919926784.0
Loss at iteration 2210 : 641093992448.0
Loss at iteration 2220 : 141353484288.0
Loss at iteration 2230 : 956731490304.0
Loss at iteration 2240 : 1731640033280.0
Loss at iteration 2250 : 421325504512.0
Loss at iteration 2260 : 232950087680.0
Loss at iteration 2270 : 1001786816.0
Loss at iteration 2280 : 403373326336.0
Loss at iteration 2290 : 1928184725504.0
Loss at iteration 2300 : 641977352192.0
Loss at iteration 2310 : 40228593664.0
Loss at iteration 2320 : 517025988608.0
Loss at iteration 2330 : 6419218169856.0
Loss at iteration 2340 : 224259276800.0
Loss at iteration 2350 : 213744451584.0
Loss at iteration 2360 : 1996559745024.0
Loss at iteration 2370 : 31546712064.0
Loss at iteration 2380 : 462024736768.0
Loss at iteration 2390 : 225084375040.0
Loss at iteration 2400 : 20453529600.0
Loss at iteration 2410 : 238254292992.0
Loss at iteration 2420 : 949384183808.0
The SSIM Value is: 1.333447158913259e-05
The PSNR Value is: -124.09927775065104
the epoch is: 160
Loss at iteration 10 : 92919119872.0
Loss at iteration 20 : 216743510016.0
Loss at iteration 30 : 344818450432.0
Loss at iteration 40 : 442627620864.0
Loss at iteration 50 : 148076199936.0
Loss at iteration 60 : 858170523648.0
Loss at iteration 70 : 652123373568.0
Loss at iteration 80 : 40920354816.0
Loss at iteration 90 : 85541953536.0
Loss at iteration 100 : 54192955392.0
Loss at iteration 110 : 57626206208.0
Loss at iteration 120 : 109027147776.0
Loss at iteration 130 : 246261579776.0
Loss at iteration 140 : 9346784256.0
Loss at iteration 150 : 699500789760.0
Loss at iteration 160 : 95419244544.0
Loss at iteration 170 : 917107048448.0
Loss at iteration 180 : 97961992192.0
Loss at iteration 190 : 54023962624.0
Loss at iteration 200 : 269665239040.0
Loss at iteration 210 : 26469734400.0
Loss at iteration 220 : 1997618675712.0
Loss at iteration 230 : 555470553088.0
Loss at iteration 240 : 18932357120.0
Loss at iteration 250 : 161470758912.0
Loss at iteration 260 : 3678718464.0
Loss at iteration 270 : 331925946368.0
Loss at iteration 280 : 215270113280.0
Loss at iteration 290 : 785765367808.0
Loss at iteration 300 : 3228980215808.0
Loss at iteration 310 : 118306209792.0
Loss at iteration 320 : 2496555122688.0
Loss at iteration 330 : 182543908864.0
Loss at iteration 340 : 113814159360.0
Loss at iteration 350 : 168726872064.0
Loss at iteration 360 : 184235376640.0
Loss at iteration 370 : 215816208384.0
Loss at iteration 380 : 28688476160.0
Loss at iteration 390 : 148886765568.0
Loss at iteration 400 : 85380521984.0
Loss at iteration 410 : 75187568640.0
Loss at iteration 420 : 863077269504.0
Loss at iteration 430 : 14407259136.0
Loss at iteration 440 : 318691508224.0
Loss at iteration 450 : 2397176856576.0
Loss at iteration 460 : 261048074240.0
Loss at iteration 470 : 503437885440.0
Loss at iteration 480 : 296539947008.0
Loss at iteration 490 : 240309403648.0
Loss at iteration 500 : 108679725056.0
Loss at iteration 510 : 68448043008.0
Loss at iteration 520 : 1499217526784.0
Loss at iteration 530 : 2134723264512.0
Loss at iteration 540 : 765178675200.0
Loss at iteration 550 : 14179102720.0
Loss at iteration 560 : 289091780608.0
Loss at iteration 570 : 19607586816.0
Loss at iteration 580 : 161433354240.0
Loss at iteration 590 : 157308370944.0
Loss at iteration 600 : 125538082816.0
Loss at iteration 610 : 613047271424.0
Loss at iteration 620 : 521173401600.0
Loss at iteration 630 : 310174515200.0
Loss at iteration 640 : 83042746368.0
Loss at iteration 650 : 242350145536.0
Loss at iteration 660 : 102133530624.0
Loss at iteration 670 : 29277345792.0
Loss at iteration 680 : 284641034240.0
Loss at iteration 690 : 679599996928.0
Loss at iteration 700 : 96699498496.0
Loss at iteration 710 : 122985873408.0
Loss at iteration 720 : 1810577883136.0
Loss at iteration 730 : 60389384192.0
Loss at iteration 740 : 77595820032.0
Loss at iteration 750 : 89554337792.0
Loss at iteration 760 : 26115166208.0
Loss at iteration 770 : 16206440448.0
Loss at iteration 780 : 55763394560.0
Loss at iteration 790 : 227153281024.0
Loss at iteration 800 : 55220576256.0
Loss at iteration 810 : 119007756288.0
Loss at iteration 820 : 77034078208.0
Loss at iteration 830 : 34820227072.0
Loss at iteration 840 : 67304435712.0
Loss at iteration 850 : 158525374464.0
Loss at iteration 860 : 1337762512896.0
Loss at iteration 870 : 206421999616.0
Loss at iteration 880 : 543698059264.0
Loss at iteration 890 : 71977680896.0
Loss at iteration 900 : 138810818560.0
Loss at iteration 910 : 11184017408.0
Loss at iteration 920 : 389098897408.0
Loss at iteration 930 : 41624158208.0
Loss at iteration 940 : 1519051210752.0
Loss at iteration 950 : 8055159296.0
Loss at iteration 960 : 91690663936.0
Loss at iteration 970 : 434570821632.0
Loss at iteration 980 : 295675822080.0
Loss at iteration 990 : 520684175360.0
Loss at iteration 1000 : 472024252416.0
Loss at iteration 1010 : 382989467648.0
Loss at iteration 1020 : 302932492288.0
Loss at iteration 1030 : 126176600064.0
Loss at iteration 1040 : 40119070720.0
Loss at iteration 1050 : 16632585216.0
Loss at iteration 1060 : 162944434176.0
Loss at iteration 1070 : 50156490752.0
Loss at iteration 1080 : 63085875200.0
Loss at iteration 1090 : 264922415104.0
Loss at iteration 1100 : 2677025792.0
Loss at iteration 1110 : 64194895872.0
Loss at iteration 1120 : 157477076992.0
Loss at iteration 1130 : 2749170176.0
Loss at iteration 1140 : 137387393024.0
Loss at iteration 1150 : 60269654016.0
Loss at iteration 1160 : 106925596672.0
Loss at iteration 1170 : 160738213888.0
Loss at iteration 1180 : 70149947392.0
Loss at iteration 1190 : 640755008.0
Loss at iteration 1200 : 17465812992.0
Loss at iteration 1210 : 98826338304.0
Loss at iteration 1220 : 53194563584.0
Loss at iteration 1230 : 60854550528.0
Loss at iteration 1240 : 80349773824.0
Loss at iteration 1250 : 40663687168.0
Loss at iteration 1260 : 109564026880.0
Loss at iteration 1270 : 134739353600.0
Loss at iteration 1280 : 1396530872320.0
Loss at iteration 1290 : 16277804032.0
Loss at iteration 1300 : 305619468288.0
Loss at iteration 1310 : 3086498136064.0
Loss at iteration 1320 : 85722267648.0
Loss at iteration 1330 : 1620621393920.0
Loss at iteration 1340 : 25410789376.0
Loss at iteration 1350 : 98198618112.0
Loss at iteration 1360 : 53476298752.0
Loss at iteration 1370 : 43200786432.0
Loss at iteration 1380 : 3718884360192.0
Loss at iteration 1390 : 31772239872.0
Loss at iteration 1400 : 17980987392.0
Loss at iteration 1410 : 21069023232.0
Loss at iteration 1420 : 245630304256.0
Loss at iteration 1430 : 62009212928.0
Loss at iteration 1440 : 25915326464.0
Loss at iteration 1450 : 8144765952.0
Loss at iteration 1460 : 66823835648.0
Loss at iteration 1470 : 150351265792.0
Loss at iteration 1480 : 59948093440.0
Loss at iteration 1490 : 23318228992.0
Loss at iteration 1500 : 75192279040.0
Loss at iteration 1510 : 4395224576.0
Loss at iteration 1520 : 146627690496.0
Loss at iteration 1530 : 157289119744.0
Loss at iteration 1540 : 199611105280.0
Loss at iteration 1550 : 120851865600.0
Loss at iteration 1560 : 55783653376.0
Loss at iteration 1570 : 72803713024.0
Loss at iteration 1580 : 8815352832.0
Loss at iteration 1590 : 18576904192.0
Loss at iteration 1600 : 64222150656.0
Loss at iteration 1610 : 243487670272.0
Loss at iteration 1620 : 33567776768.0
Loss at iteration 1630 : 1480456404992.0
Loss at iteration 1640 : 90331840512.0
Loss at iteration 1650 : 146169004032.0
Loss at iteration 1660 : 272074113024.0
Loss at iteration 1670 : 74404175872.0
Loss at iteration 1680 : 21228476416.0
Loss at iteration 1690 : 4023443200.0
Loss at iteration 1700 : 10255843328.0
Loss at iteration 1710 : 33720985600.0
Loss at iteration 1720 : 23036631040.0
Loss at iteration 1730 : 246654500864.0
Loss at iteration 1740 : 11699847168.0
Loss at iteration 1750 : 8525307392.0
Loss at iteration 1760 : 25580572672.0
Loss at iteration 1770 : 299975704576.0
Loss at iteration 1780 : 35797086208.0
Loss at iteration 1790 : 39293833216.0
Loss at iteration 1800 : 28531705856.0
Loss at iteration 1810 : 12881214464.0
Loss at iteration 1820 : 10511325184.0
Loss at iteration 1830 : 4703481856.0
Loss at iteration 1840 : 145143873536.0
Loss at iteration 1850 : 126524653568.0
Loss at iteration 1860 : 728501977088.0
Loss at iteration 1870 : 101822996480.0
Loss at iteration 1880 : 31261202432.0
Loss at iteration 1890 : 59659997184.0
Loss at iteration 1900 : 50327764992.0
Loss at iteration 1910 : 32053741568.0
Loss at iteration 1920 : 35841966080.0
Loss at iteration 1930 : 187975073792.0
Loss at iteration 1940 : 44392431616.0
Loss at iteration 1950 : 2882395648.0
Loss at iteration 1960 : 165777342464.0
Loss at iteration 1970 : 79735201792.0
Loss at iteration 1980 : 26708221952.0
Loss at iteration 1990 : 7007161344.0
Loss at iteration 2000 : 3244614221824.0
Loss at iteration 2010 : 102708690944.0
Loss at iteration 2020 : 37657149440.0
Loss at iteration 2030 : 175915352064.0
Loss at iteration 2040 : 228707762176.0
Loss at iteration 2050 : 17935175680.0
Loss at iteration 2060 : 273649139712.0
Loss at iteration 2070 : 59711447040.0
Loss at iteration 2080 : 128055713792.0
Loss at iteration 2090 : 51443306496.0
Loss at iteration 2100 : 429880541184.0
Loss at iteration 2110 : 39874928640.0
Loss at iteration 2120 : 125151420416.0
Loss at iteration 2130 : 110456094720.0
Loss at iteration 2140 : 55828398080.0
Loss at iteration 2150 : 28744980480.0
Loss at iteration 2160 : 1778643107840.0
Loss at iteration 2170 : 391761526784.0
Loss at iteration 2180 : 40458596352.0
Loss at iteration 2190 : 195747528704.0
Loss at iteration 2200 : 26163961856.0
Loss at iteration 2210 : 59913359360.0
Loss at iteration 2220 : 172491980800.0
Loss at iteration 2230 : 12126261248.0
Loss at iteration 2240 : 702857609216.0
Loss at iteration 2250 : 14483747840.0
Loss at iteration 2260 : 21034287104.0
Loss at iteration 2270 : 40598454272.0
Loss at iteration 2280 : 53225017344.0
Loss at iteration 2290 : 152062705664.0
Loss at iteration 2300 : 892725886976.0
Loss at iteration 2310 : 17797113856.0
Loss at iteration 2320 : 74815561728.0
Loss at iteration 2330 : 23974967296.0
Loss at iteration 2340 : 376626053120.0
Loss at iteration 2350 : 38474952704.0
Loss at iteration 2360 : 56795357184.0
Loss at iteration 2370 : 7141201408.0
Loss at iteration 2380 : 13806003200.0
Loss at iteration 2390 : 56174235648.0
Loss at iteration 2400 : 8915460096.0
Loss at iteration 2410 : 71265222656.0
Loss at iteration 2420 : 14489873408.0
The SSIM Value is: 1.5569194105561715e-05
The PSNR Value is: -115.9488530476888
the epoch is: 161
Loss at iteration 10 : 64176594944.0
Loss at iteration 20 : 25740906496.0
Loss at iteration 30 : 92541313024.0
Loss at iteration 40 : 29672595456.0
Loss at iteration 50 : 15793396736.0
Loss at iteration 60 : 5884101120.0
Loss at iteration 70 : 17403680768.0
Loss at iteration 80 : 116380590080.0
Loss at iteration 90 : 22680367104.0
Loss at iteration 100 : 18794469376.0
Loss at iteration 110 : 34924167168.0
Loss at iteration 120 : 5326219776.0
Loss at iteration 130 : 68580474880.0
Loss at iteration 140 : 35138027520.0
Loss at iteration 150 : 110690467840.0
Loss at iteration 160 : 11395973120.0
Loss at iteration 170 : 197091803136.0
Loss at iteration 180 : 5999769088.0
Loss at iteration 190 : 92848242688.0
Loss at iteration 200 : 21054291968.0
Loss at iteration 210 : 15752583168.0
Loss at iteration 220 : 38961917952.0
Loss at iteration 230 : 13659661312.0
Loss at iteration 240 : 362897965056.0
Loss at iteration 250 : 10352398336.0
Loss at iteration 260 : 63111065600.0
Loss at iteration 270 : 202805657600.0
Loss at iteration 280 : 14118312960.0
Loss at iteration 290 : 31166863360.0
Loss at iteration 300 : 70292242432.0
Loss at iteration 310 : 27835095040.0
Loss at iteration 320 : 130763218944.0
Loss at iteration 330 : 9383262208.0
Loss at iteration 340 : 6410588160.0
Loss at iteration 350 : 106332839936.0
Loss at iteration 360 : 37312102400.0
Loss at iteration 370 : 43311452160.0
Loss at iteration 380 : 95000870912.0
Loss at iteration 390 : 5093894656.0
Loss at iteration 400 : 8560380416.0
Loss at iteration 410 : 6108260864.0
Loss at iteration 420 : 12817169408.0
Loss at iteration 430 : 76501565440.0
Loss at iteration 440 : 36671844352.0
Loss at iteration 450 : 10218593280.0
Loss at iteration 460 : 17741758464.0
Loss at iteration 470 : 3252550656.0
Loss at iteration 480 : 183568269312.0
Loss at iteration 490 : 60810588160.0
Loss at iteration 500 : 61807206400.0
Loss at iteration 510 : 56294973440.0
Loss at iteration 520 : 3266649088.0
Loss at iteration 530 : 83256287232.0
Loss at iteration 540 : 22269526016.0
Loss at iteration 550 : 4149383936.0
Loss at iteration 560 : 30403020800.0
Loss at iteration 570 : 195011297280.0
Loss at iteration 580 : 4327500288.0
Loss at iteration 590 : 479286496.0
Loss at iteration 600 : 19292604416.0
Loss at iteration 610 : 34234888192.0
Loss at iteration 620 : 22667114496.0
Loss at iteration 630 : 44168130560.0
Loss at iteration 640 : 17181704192.0
Loss at iteration 650 : 82200240128.0
Loss at iteration 660 : 8118000640.0
Loss at iteration 670 : 14225582080.0
Loss at iteration 680 : 12043763712.0
Loss at iteration 690 : 29519630336.0
Loss at iteration 700 : 19684466688.0
Loss at iteration 710 : 106954604544.0
Loss at iteration 720 : 120388984832.0
Loss at iteration 730 : 1305983872.0
Loss at iteration 740 : 30350247936.0
Loss at iteration 750 : 4453095424.0
Loss at iteration 760 : 6265931776.0
Loss at iteration 770 : 193830322176.0
Loss at iteration 780 : 21062074368.0
Loss at iteration 790 : 3106714157056.0
Loss at iteration 800 : 30331312799744.0
Loss at iteration 810 : 86958358528.0
Loss at iteration 820 : 48321560576.0
Loss at iteration 830 : 820435943424.0
Loss at iteration 840 : 1707266670592.0
Loss at iteration 850 : 1140098072576.0
Loss at iteration 860 : 5314410184704.0
Loss at iteration 870 : 33791830016.0
Loss at iteration 880 : 14154793484288.0
Loss at iteration 890 : 432048373760.0
Loss at iteration 900 : 20975519268864.0
Loss at iteration 910 : 1916930490368.0
Loss at iteration 920 : 5155410411520.0
Loss at iteration 930 : 1671066288128.0
Loss at iteration 940 : 2127763472384.0
Loss at iteration 950 : 79945464283136.0
Loss at iteration 960 : 298806706176.0
Loss at iteration 970 : 7691584929792.0
Loss at iteration 980 : 5645810008064.0
Loss at iteration 990 : 3516931506176.0
Loss at iteration 1000 : 2035086131200.0
Loss at iteration 1010 : 637406806016.0
Loss at iteration 1020 : 1080347197440.0
Loss at iteration 1030 : 719939239936.0
Loss at iteration 1040 : 7059179831296.0
Loss at iteration 1050 : 457005432832.0
Loss at iteration 1060 : 341994766336.0
Loss at iteration 1070 : 647290421248.0
Loss at iteration 1080 : 215313580032.0
Loss at iteration 1090 : 3557745754112.0
Loss at iteration 1100 : 180942356480.0
Loss at iteration 1110 : 946930843648.0
Loss at iteration 1120 : 42106376192.0
Loss at iteration 1130 : 1211695759360.0
Loss at iteration 1140 : 111895789568.0
Loss at iteration 1150 : 423018332160.0
Loss at iteration 1160 : 10165670641664.0
Loss at iteration 1170 : 46204784640.0
Loss at iteration 1180 : 2666592993280.0
Loss at iteration 1190 : 1050416775168.0
Loss at iteration 1200 : 128026148864.0
Loss at iteration 1210 : 6979293544448.0
Loss at iteration 1220 : 1980043755520.0
Loss at iteration 1230 : 2018009677824.0
Loss at iteration 1240 : 105576341504.0
Loss at iteration 1250 : 1005332332544.0
Loss at iteration 1260 : 153611845632.0
Loss at iteration 1270 : 2781160669184.0
Loss at iteration 1280 : 797075963904.0
Loss at iteration 1290 : 374185033728.0
Loss at iteration 1300 : 286330978304.0
Loss at iteration 1310 : 396970983424.0
Loss at iteration 1320 : 1037795983360.0
Loss at iteration 1330 : 384448364544.0
Loss at iteration 1340 : 71745568768.0
Loss at iteration 1350 : 131753746432.0
Loss at iteration 1360 : 7883643392.0
Loss at iteration 1370 : 91010801664.0
Loss at iteration 1380 : 688132849664.0
Loss at iteration 1390 : 51412033536.0
Loss at iteration 1400 : 199812825088.0
Loss at iteration 1410 : 33968175104.0
Loss at iteration 1420 : 43830312960.0
Loss at iteration 1430 : 247793221632.0
Loss at iteration 1440 : 100545740800.0
Loss at iteration 1450 : 4772134400.0
Loss at iteration 1460 : 16314399744.0
Loss at iteration 1470 : 36484653056.0
Loss at iteration 1480 : 80366968832.0
Loss at iteration 1490 : 192221872128.0
Loss at iteration 1500 : 495031681024.0
Loss at iteration 1510 : 38376046592.0
Loss at iteration 1520 : 39089594368.0
Loss at iteration 1530 : 180054392832.0
Loss at iteration 1540 : 44144656384.0
Loss at iteration 1550 : 7351251456.0
Loss at iteration 1560 : 571158298624.0
Loss at iteration 1570 : 224191365120.0
Loss at iteration 1580 : 761075924992.0
Loss at iteration 1590 : 2144329472.0
Loss at iteration 1600 : 62695370752.0
Loss at iteration 1610 : 257572356096.0
Loss at iteration 1620 : 214921641984.0
Loss at iteration 1630 : 286955601920.0
Loss at iteration 1640 : 27311355904.0
Loss at iteration 1650 : 803426009088.0
Loss at iteration 1660 : 23010689024.0
Loss at iteration 1670 : 114231386112.0
Loss at iteration 1680 : 200091860992.0
Loss at iteration 1690 : 7338474496.0
Loss at iteration 1700 : 17413734400.0
Loss at iteration 1710 : 129975279616.0
Loss at iteration 1720 : 65658695680.0
Loss at iteration 1730 : 118460096512.0
Loss at iteration 1740 : 79056764928.0
Loss at iteration 1750 : 50599325696.0
Loss at iteration 1760 : 44127875072.0
Loss at iteration 1770 : 37216182272.0
Loss at iteration 1780 : 33108180992.0
Loss at iteration 1790 : 278407446528.0
Loss at iteration 1800 : 35911254016.0
Loss at iteration 1810 : 12631094272.0
Loss at iteration 1820 : 289389248512.0
Loss at iteration 1830 : 130823897088.0
Loss at iteration 1840 : 24798339072.0
Loss at iteration 1850 : 12064669696.0
Loss at iteration 1860 : 44503986176.0
Loss at iteration 1870 : 33711816704.0
Loss at iteration 1880 : 176452747264.0
Loss at iteration 1890 : 486979502080.0
Loss at iteration 1900 : 64330059776.0
Loss at iteration 1910 : 6304696832.0
Loss at iteration 1920 : 30047703040.0
Loss at iteration 1930 : 23917975552.0
Loss at iteration 1940 : 25353715712.0
Loss at iteration 1950 : 11219192832.0
Loss at iteration 1960 : 95403368448.0
Loss at iteration 1970 : 31749234688.0
Loss at iteration 1980 : 10815881216.0
Loss at iteration 1990 : 16152518656.0
Loss at iteration 2000 : 15577383936.0
Loss at iteration 2010 : 20320657408.0
Loss at iteration 2020 : 27425728512.0
Loss at iteration 2030 : 33210904576.0
Loss at iteration 2040 : 4976041472.0
Loss at iteration 2050 : 17493929984.0
Loss at iteration 2060 : 25819500544.0
Loss at iteration 2070 : 31544276992.0
Loss at iteration 2080 : 19819567104.0
Loss at iteration 2090 : 17319292928.0
Loss at iteration 2100 : 28059260928.0
Loss at iteration 2110 : 57792552960.0
Loss at iteration 2120 : 3670114560.0
Loss at iteration 2130 : 28242550784.0
Loss at iteration 2140 : 14834507776.0
Loss at iteration 2150 : 85937127424.0
Loss at iteration 2160 : 55022690304.0
Loss at iteration 2170 : 55846510592.0
Loss at iteration 2180 : 17324675072.0
Loss at iteration 2190 : 639795068928.0
Loss at iteration 2200 : 2041389568.0
Loss at iteration 2210 : 39752130560.0
Loss at iteration 2220 : 25529810944.0
Loss at iteration 2230 : 5875528704.0
Loss at iteration 2240 : 41327034368.0
Loss at iteration 2250 : 8604875776.0
Loss at iteration 2260 : 13579773952.0
Loss at iteration 2270 : 42815700992.0
Loss at iteration 2280 : 5197622272.0
Loss at iteration 2290 : 6267802112.0
Loss at iteration 2300 : 14015305728.0
Loss at iteration 2310 : 229629460480.0
Loss at iteration 2320 : 569002885120.0
Loss at iteration 2330 : 310193684480.0
Loss at iteration 2340 : 84404469760.0
Loss at iteration 2350 : 190952587264.0
Loss at iteration 2360 : 22417401856.0
Loss at iteration 2370 : 1062839123968.0
Loss at iteration 2380 : 1713188503552.0
Loss at iteration 2390 : 135038287872.0
Loss at iteration 2400 : 1888756039680.0
Loss at iteration 2410 : 49707012096.0
Loss at iteration 2420 : 14248759296.0
The SSIM Value is: 1.3641869969660547e-06
The PSNR Value is: -120.69927673339843
the epoch is: 162
Loss at iteration 10 : 58985406464.0
Loss at iteration 20 : 106942676992.0
Loss at iteration 30 : 33763594240.0
Loss at iteration 40 : 1098940612608.0
Loss at iteration 50 : 110809792512.0
Loss at iteration 60 : 198070419456.0
Loss at iteration 70 : 2279753216.0
Loss at iteration 80 : 69478408192.0
Loss at iteration 90 : 106673373184.0
Loss at iteration 100 : 534070984704.0
Loss at iteration 110 : 9578157056.0
Loss at iteration 120 : 5084164096.0
Loss at iteration 130 : 4514641408.0
Loss at iteration 140 : 3687946496.0
Loss at iteration 150 : 12453151744.0
Loss at iteration 160 : 1143029120.0
Loss at iteration 170 : 24920551424.0
Loss at iteration 180 : 59282386944.0
Loss at iteration 190 : 25822644224.0
Loss at iteration 200 : 19696214016.0
Loss at iteration 210 : 27913230336.0
Loss at iteration 220 : 46830116864.0
Loss at iteration 230 : 442144915456.0
Loss at iteration 240 : 164804149248.0
Loss at iteration 250 : 106154655744.0
Loss at iteration 260 : 3369585344512.0
Loss at iteration 270 : 21151676416.0
Loss at iteration 280 : 37299572736.0
Loss at iteration 290 : 45503242240.0
Loss at iteration 300 : 3314312192.0
Loss at iteration 310 : 10363703296.0
Loss at iteration 320 : 19189116928.0
Loss at iteration 330 : 16272325632.0
Loss at iteration 340 : 47636721664.0
Loss at iteration 350 : 18827026432.0
Loss at iteration 360 : 5275040256.0
Loss at iteration 370 : 35228954624.0
Loss at iteration 380 : 39841955840.0
Loss at iteration 390 : 53810003968.0
Loss at iteration 400 : 31944419328.0
Loss at iteration 410 : 4965407744.0
Loss at iteration 420 : 57050484736.0
Loss at iteration 430 : 18366007296.0
Loss at iteration 440 : 343386980352.0
Loss at iteration 450 : 86641033216.0
Loss at iteration 460 : 1733909151744.0
Loss at iteration 470 : 160027377664.0
Loss at iteration 480 : 1219073409024.0
Loss at iteration 490 : 1346562686976.0
Loss at iteration 500 : 99716857856.0
Loss at iteration 510 : 595839025152.0
Loss at iteration 520 : 229360140288.0
Loss at iteration 530 : 11808646627328.0
Loss at iteration 540 : 16404989952.0
Loss at iteration 550 : 266241671168.0
Loss at iteration 560 : 35547938816.0
Loss at iteration 570 : 163285893120.0
Loss at iteration 580 : 199426310144.0
Loss at iteration 590 : 403686621184.0
Loss at iteration 600 : 254990761984.0
Loss at iteration 610 : 449763442688.0
Loss at iteration 620 : 536759697408.0
Loss at iteration 630 : 2253886062592.0
Loss at iteration 640 : 817641947136.0
Loss at iteration 650 : 89803014144.0
Loss at iteration 660 : 14217929728.0
Loss at iteration 670 : 145976639488.0
Loss at iteration 680 : 69663653888.0
Loss at iteration 690 : 126455119872.0
Loss at iteration 700 : 66622169088.0
Loss at iteration 710 : 67320446976.0
Loss at iteration 720 : 63481311232.0
Loss at iteration 730 : 26458363904.0
Loss at iteration 740 : 139428937728.0
Loss at iteration 750 : 37963644928.0
Loss at iteration 760 : 114378072064.0
Loss at iteration 770 : 45770387456.0
Loss at iteration 780 : 770472345600.0
Loss at iteration 790 : 22389647360.0
Loss at iteration 800 : 31280922624.0
Loss at iteration 810 : 31079376896.0
Loss at iteration 820 : 119555735552.0
Loss at iteration 830 : 507906424832.0
Loss at iteration 840 : 1999501787136.0
Loss at iteration 850 : 169265233920.0
Loss at iteration 860 : 69028241408.0
Loss at iteration 870 : 11527299072.0
Loss at iteration 880 : 218046922752.0
Loss at iteration 890 : 1223036370944.0
Loss at iteration 900 : 186469875712.0
Loss at iteration 910 : 185774440448.0
Loss at iteration 920 : 6967632384.0
Loss at iteration 930 : 88596832256.0
Loss at iteration 940 : 37969223680.0
Loss at iteration 950 : 5158831616.0
Loss at iteration 960 : 89687285760.0
Loss at iteration 970 : 46546477056.0
Loss at iteration 980 : 20490977280.0
Loss at iteration 990 : 55998025728.0
Loss at iteration 1000 : 94228914176.0
Loss at iteration 1010 : 10428478464.0
Loss at iteration 1020 : 19668125696.0
Loss at iteration 1030 : 9567089664.0
Loss at iteration 1040 : 71357603840.0
Loss at iteration 1050 : 27259717632.0
Loss at iteration 1060 : 5845992448.0
Loss at iteration 1070 : 2751605504.0
Loss at iteration 1080 : 103833673728.0
Loss at iteration 1090 : 165681987584.0
Loss at iteration 1100 : 883258097664.0
Loss at iteration 1110 : 6191921664.0
Loss at iteration 1120 : 73660448768.0
Loss at iteration 1130 : 177247846400.0
Loss at iteration 1140 : 76363980800.0
Loss at iteration 1150 : 33011662848.0
Loss at iteration 1160 : 43042660352.0
Loss at iteration 1170 : 104365047808.0
Loss at iteration 1180 : 119314415616.0
Loss at iteration 1190 : 25996161024.0
Loss at iteration 1200 : 233928032256.0
Loss at iteration 1210 : 16688050176.0
Loss at iteration 1220 : 83909492736.0
Loss at iteration 1230 : 80195198976.0
Loss at iteration 1240 : 14397170688.0
Loss at iteration 1250 : 7618686976.0
Loss at iteration 1260 : 63116206080.0
Loss at iteration 1270 : 17551814656.0
Loss at iteration 1280 : 14033853440.0
Loss at iteration 1290 : 14136263680.0
Loss at iteration 1300 : 66581155840.0
Loss at iteration 1310 : 44749860864.0
Loss at iteration 1320 : 7154335744.0
Loss at iteration 1330 : 205386842112.0
Loss at iteration 1340 : 128441057280.0
Loss at iteration 1350 : 26512637952.0
Loss at iteration 1360 : 34487267328.0
Loss at iteration 1370 : 69270913024.0
Loss at iteration 1380 : 6438772736.0
Loss at iteration 1390 : 16073799680.0
Loss at iteration 1400 : 5992023040.0
Loss at iteration 1410 : 13973450752.0
Loss at iteration 1420 : 40471588864.0
Loss at iteration 1430 : 32284698624.0
Loss at iteration 1440 : 38434648064.0
Loss at iteration 1450 : 252911730688.0
Loss at iteration 1460 : 14867742720.0
Loss at iteration 1470 : 45709303808.0
Loss at iteration 1480 : 4062708224.0
Loss at iteration 1490 : 23153252352.0
Loss at iteration 1500 : 1523708800.0
Loss at iteration 1510 : 25201997824.0
Loss at iteration 1520 : 13886999552.0
Loss at iteration 1530 : 1804424192.0
Loss at iteration 1540 : 8132702720.0
Loss at iteration 1550 : 17150307328.0
Loss at iteration 1560 : 114226167808.0
Loss at iteration 1570 : 19989028864.0
Loss at iteration 1580 : 339191234560.0
Loss at iteration 1590 : 11165572096.0
Loss at iteration 1600 : 3096863571968.0
Loss at iteration 1610 : 66761027584.0
Loss at iteration 1620 : 464596140032.0
Loss at iteration 1630 : 36982456320.0
Loss at iteration 1640 : 138701127680.0
Loss at iteration 1650 : 422503809024.0
Loss at iteration 1660 : 119942397952.0
Loss at iteration 1670 : 10166792192.0
Loss at iteration 1680 : 8875608064.0
Loss at iteration 1690 : 2431298304.0
Loss at iteration 1700 : 12754677760.0
Loss at iteration 1710 : 51753021440.0
Loss at iteration 1720 : 16725114880.0
Loss at iteration 1730 : 46807367680.0
Loss at iteration 1740 : 39964184576.0
Loss at iteration 1750 : 79586402304.0
Loss at iteration 1760 : 165691146240.0
Loss at iteration 1770 : 498320703488.0
Loss at iteration 1780 : 6299542528.0
Loss at iteration 1790 : 616473624576.0
Loss at iteration 1800 : 280680857600.0
Loss at iteration 1810 : 34952847360.0
Loss at iteration 1820 : 13966732288.0
Loss at iteration 1830 : 57709707264.0
Loss at iteration 1840 : 189251944448.0
Loss at iteration 1850 : 834387968000.0
Loss at iteration 1860 : 651438129152.0
Loss at iteration 1870 : 21310666752.0
Loss at iteration 1880 : 1098057515008.0
Loss at iteration 1890 : 51717046272.0
Loss at iteration 1900 : 15409485824.0
Loss at iteration 1910 : 66937602048.0
Loss at iteration 1920 : 4189713152.0
Loss at iteration 1930 : 178312912.0
Loss at iteration 1940 : 2580888576.0
Loss at iteration 1950 : 29045760000.0
Loss at iteration 1960 : 1270999424.0
Loss at iteration 1970 : 8950628352.0
Loss at iteration 1980 : 2760572416.0
Loss at iteration 1990 : 25740744704.0
Loss at iteration 2000 : 1643414784.0
Loss at iteration 2010 : 160186400768.0
Loss at iteration 2020 : 2617449472.0
Loss at iteration 2030 : 741124014080.0
Loss at iteration 2040 : 64784494592.0
Loss at iteration 2050 : 626653724672.0
Loss at iteration 2060 : 141593149440.0
Loss at iteration 2070 : 621107544064.0
Loss at iteration 2080 : 4719877554176.0
Loss at iteration 2090 : 191677022208.0
Loss at iteration 2100 : 14664981504.0
Loss at iteration 2110 : 579466100736.0
Loss at iteration 2120 : 118635290624.0
Loss at iteration 2130 : 87078215680.0
Loss at iteration 2140 : 291799826432.0
Loss at iteration 2150 : 78975467520.0
Loss at iteration 2160 : 51553705984.0
Loss at iteration 2170 : 13788557312.0
Loss at iteration 2180 : 26345707520.0
Loss at iteration 2190 : 337022484480.0
Loss at iteration 2200 : 13769948160.0
Loss at iteration 2210 : 87079428096.0
Loss at iteration 2220 : 7101521920.0
Loss at iteration 2230 : 42598789120.0
Loss at iteration 2240 : 83447586816.0
Loss at iteration 2250 : 358168788992.0
Loss at iteration 2260 : 14473366528.0
Loss at iteration 2270 : 4796748800.0
Loss at iteration 2280 : 72709857280.0
Loss at iteration 2290 : 21787326464.0
Loss at iteration 2300 : 65674383360.0
Loss at iteration 2310 : 862737920.0
Loss at iteration 2320 : 419588997120.0
Loss at iteration 2330 : 3809705459712.0
Loss at iteration 2340 : 62957534838784.0
Loss at iteration 2350 : 4091841347584.0
Loss at iteration 2360 : 22968822398976.0
Loss at iteration 2370 : 4701797335695360.0
Loss at iteration 2380 : 3729206823354368.0
Loss at iteration 2390 : 718318583414784.0
Loss at iteration 2400 : 123721993945088.0
Loss at iteration 2410 : 3672817532928.0
Loss at iteration 2420 : 269356810240.0
The SSIM Value is: 2.692795087474072e-06
The PSNR Value is: -137.08082936604816
the epoch is: 163
Loss at iteration 10 : 30830900543488.0
Loss at iteration 20 : 1608269955072.0
Loss at iteration 30 : 1134874591232.0
Loss at iteration 40 : 16994998272.0
Loss at iteration 50 : 444341649408.0
Loss at iteration 60 : 4412515811328.0
Loss at iteration 70 : 421473419264.0
Loss at iteration 80 : 3248912859136.0
Loss at iteration 90 : 489540157440.0
Loss at iteration 100 : 2135415455744.0
Loss at iteration 110 : 263866761216.0
Loss at iteration 120 : 992463749120.0
Loss at iteration 130 : 53525631467520.0
Loss at iteration 140 : 3974801915904.0
Loss at iteration 150 : 5920987283456.0
Loss at iteration 160 : 16860478177280.0
Loss at iteration 170 : 945404641280.0
Loss at iteration 180 : 316753444864.0
Loss at iteration 190 : 280478449664.0
Loss at iteration 200 : 1832416313344.0
Loss at iteration 210 : 284199865024512.0
Loss at iteration 220 : 10555044659200.0
Loss at iteration 230 : 23955963904.0
Loss at iteration 240 : 4146624462848.0
Loss at iteration 250 : 2688945487872.0
Loss at iteration 260 : 508872458240.0
Loss at iteration 270 : 392093171712.0
Loss at iteration 280 : 315835023360.0
Loss at iteration 290 : 1168361914368.0
Loss at iteration 300 : 358497812480.0
Loss at iteration 310 : 173490241536.0
Loss at iteration 320 : 219420262400.0
Loss at iteration 330 : 835250946048.0
Loss at iteration 340 : 100440023040.0
Loss at iteration 350 : 289926348800.0
Loss at iteration 360 : 616018935808.0
Loss at iteration 370 : 1328208412672.0
Loss at iteration 380 : 1531246542848.0
Loss at iteration 390 : 670036000768.0
Loss at iteration 400 : 40880726016.0
Loss at iteration 410 : 1120510148608.0
Loss at iteration 420 : 15726245052416.0
Loss at iteration 430 : 850342051840.0
Loss at iteration 440 : 51044028416.0
Loss at iteration 450 : 131249905664.0
Loss at iteration 460 : 2944313851904.0
Loss at iteration 470 : 284843900928.0
Loss at iteration 480 : 246228172800.0
Loss at iteration 490 : 1109448851456.0
Loss at iteration 500 : 3097735462912.0
Loss at iteration 510 : 138071490560.0
Loss at iteration 520 : 586255040512.0
Loss at iteration 530 : 535410475008.0
Loss at iteration 540 : 470939959296.0
Loss at iteration 550 : 10292485423104.0
Loss at iteration 560 : 703356010496.0
Loss at iteration 570 : 1223079493632.0
Loss at iteration 580 : 546996387840.0
Loss at iteration 590 : 91872829440.0
Loss at iteration 600 : 427677515776.0
Loss at iteration 610 : 298371940352.0
Loss at iteration 620 : 1687175692288.0
Loss at iteration 630 : 32948933885952.0
Loss at iteration 640 : 79359478071296.0
Loss at iteration 650 : 98066107465728.0
Loss at iteration 660 : 4032577142784.0
Loss at iteration 670 : 15393045348352.0
Loss at iteration 680 : 5694339678208.0
Loss at iteration 690 : 2029102432256.0
Loss at iteration 700 : 40740314939392.0
Loss at iteration 710 : 2658913484800.0
Loss at iteration 720 : 12452541497344.0
Loss at iteration 730 : 129051893760.0
Loss at iteration 740 : 632108220416.0
Loss at iteration 750 : 7426977824768.0
Loss at iteration 760 : 1932762808320.0
Loss at iteration 770 : 1970308644864.0
Loss at iteration 780 : 1832682258432.0
Loss at iteration 790 : 4796414689280.0
Loss at iteration 800 : 274806243328.0
Loss at iteration 810 : 130800148480.0
Loss at iteration 820 : 8502341271552.0
Loss at iteration 830 : 4899548430336.0
Loss at iteration 840 : 177704665088.0
Loss at iteration 850 : 209779064832.0
Loss at iteration 860 : 141486030848.0
Loss at iteration 870 : 1056962772992.0
Loss at iteration 880 : 2309066850304.0
Loss at iteration 890 : 249345425408.0
Loss at iteration 900 : 835373432832.0
Loss at iteration 910 : 527086714880.0
Loss at iteration 920 : 440688541696.0
Loss at iteration 930 : 51694153728.0
Loss at iteration 940 : 1865971531776.0
Loss at iteration 950 : 437943894016.0
Loss at iteration 960 : 4491469914112.0
Loss at iteration 970 : 878449197056.0
Loss at iteration 980 : 68731162066944.0
Loss at iteration 990 : 11261299392512.0
Loss at iteration 1000 : 407055958016.0
Loss at iteration 1010 : 5164884819968.0
Loss at iteration 1020 : 2249133654016.0
Loss at iteration 1030 : 10812531933184.0
Loss at iteration 1040 : 4134830342144.0
Loss at iteration 1050 : 969466380288.0
Loss at iteration 1060 : 4011820580864.0
Loss at iteration 1070 : 653364953088.0
Loss at iteration 1080 : 182262824960.0
Loss at iteration 1090 : 675977035776.0
Loss at iteration 1100 : 182659350528.0
Loss at iteration 1110 : 17603984621568.0
Loss at iteration 1120 : 1238310846464.0
Loss at iteration 1130 : 1490934824960.0
Loss at iteration 1140 : 4046904623104.0
Loss at iteration 1150 : 5604685905920.0
Loss at iteration 1160 : 452186996736.0
Loss at iteration 1170 : 1602115731456.0
Loss at iteration 1180 : 972312543232.0
Loss at iteration 1190 : 4600705843200.0
Loss at iteration 1200 : 309753741312.0
Loss at iteration 1210 : 17789861494784.0
Loss at iteration 1220 : 55385616384.0
Loss at iteration 1230 : 109462085632.0
Loss at iteration 1240 : 511810338816.0
Loss at iteration 1250 : 111398010880.0
Loss at iteration 1260 : 291266101248.0
Loss at iteration 1270 : 582126796800.0
Loss at iteration 1280 : 249539035136.0
Loss at iteration 1290 : 1268924547072.0
Loss at iteration 1300 : 654595391488.0
Loss at iteration 1310 : 17839324921856.0
Loss at iteration 1320 : 368899194880.0
Loss at iteration 1330 : 228947181568.0
Loss at iteration 1340 : 614094536704.0
Loss at iteration 1350 : 1638414811136.0
Loss at iteration 1360 : 1398121693184.0
Loss at iteration 1370 : 538955546624.0
Loss at iteration 1380 : 2065231511552.0
Loss at iteration 1390 : 982230171648.0
Loss at iteration 1400 : 1928384217088.0
Loss at iteration 1410 : 2548545355776.0
Loss at iteration 1420 : 22349554384896.0
Loss at iteration 1430 : 1920149356544.0
Loss at iteration 1440 : 13518080311296.0
Loss at iteration 1450 : 15309631127552.0
Loss at iteration 1460 : 5630564237312.0
Loss at iteration 1470 : 4876939034624.0
Loss at iteration 1480 : 739097182208.0
Loss at iteration 1490 : 202270801920.0
Loss at iteration 1500 : 5301858205696.0
Loss at iteration 1510 : 939351080960.0
Loss at iteration 1520 : 658242011136.0
Loss at iteration 1530 : 136446992384.0
Loss at iteration 1540 : 666480803840.0
Loss at iteration 1550 : 79785213952.0
Loss at iteration 1560 : 80068845568.0
Loss at iteration 1570 : 1077490810880.0
Loss at iteration 1580 : 97679302656.0
Loss at iteration 1590 : 9398607937536.0
Loss at iteration 1600 : 8421546393600.0
Loss at iteration 1610 : 863276957696.0
Loss at iteration 1620 : 506918076416.0
Loss at iteration 1630 : 2778193985536.0
Loss at iteration 1640 : 121174106112.0
Loss at iteration 1650 : 312456019968.0
Loss at iteration 1660 : 444843720704.0
Loss at iteration 1670 : 276783202304.0
Loss at iteration 1680 : 613177884672.0
Loss at iteration 1690 : 3424653148160.0
Loss at iteration 1700 : 211305054208.0
Loss at iteration 1710 : 362391666688.0
Loss at iteration 1720 : 545274691584.0
Loss at iteration 1730 : 249710280704.0
Loss at iteration 1740 : 226808168448.0
Loss at iteration 1750 : 5133801357312.0
Loss at iteration 1760 : 92027584512.0
Loss at iteration 1770 : 675130703872.0
Loss at iteration 1780 : 394961747968.0
Loss at iteration 1790 : 126156734464.0
Loss at iteration 1800 : 328105525248.0
Loss at iteration 1810 : 177427660800.0
Loss at iteration 1820 : 568068669440.0
Loss at iteration 1830 : 2154530734080.0
Loss at iteration 1840 : 68796104704.0
Loss at iteration 1850 : 524935528448.0
Loss at iteration 1860 : 818105548800.0
Loss at iteration 1870 : 975949266944.0
Loss at iteration 1880 : 566854746112.0
Loss at iteration 1890 : 15322529792.0
Loss at iteration 1900 : 111952601088.0
Loss at iteration 1910 : 152009981952.0
Loss at iteration 1920 : 456907161600.0
Loss at iteration 1930 : 24393789440.0
Loss at iteration 1940 : 172994150400.0
Loss at iteration 1950 : 773723652096.0
Loss at iteration 1960 : 2001599463424.0
Loss at iteration 1970 : 290871541760.0
Loss at iteration 1980 : 272842293248.0
Loss at iteration 1990 : 63465472000.0
Loss at iteration 2000 : 16304769024.0
Loss at iteration 2010 : 21027522560.0
Loss at iteration 2020 : 74391134208.0
Loss at iteration 2030 : 1082134626304.0
Loss at iteration 2040 : 916918697984.0
Loss at iteration 2050 : 116830191616.0
Loss at iteration 2060 : 56384937984.0
Loss at iteration 2070 : 77744947200.0
Loss at iteration 2080 : 126016585728.0
Loss at iteration 2090 : 1014669967360.0
Loss at iteration 2100 : 579753607168.0
Loss at iteration 2110 : 94951972864.0
Loss at iteration 2120 : 44639739904.0
Loss at iteration 2130 : 466169462784.0
Loss at iteration 2140 : 395418828800.0
Loss at iteration 2150 : 1378803122176.0
Loss at iteration 2160 : 33214496768.0
Loss at iteration 2170 : 267557568512.0
Loss at iteration 2180 : 15055733760.0
Loss at iteration 2190 : 77761126400.0
Loss at iteration 2200 : 797066002432.0
Loss at iteration 2210 : 1970844598272.0
Loss at iteration 2220 : 140707364864.0
Loss at iteration 2230 : 1313837678592.0
Loss at iteration 2240 : 3787161337856.0
Loss at iteration 2250 : 3990882091008.0
Loss at iteration 2260 : 1505326661632.0
Loss at iteration 2270 : 2730704764928.0
Loss at iteration 2280 : 3439030960128.0
Loss at iteration 2290 : 1438875123712.0
Loss at iteration 2300 : 904220966912.0
Loss at iteration 2310 : 787090702336.0
Loss at iteration 2320 : 401933074432.0
Loss at iteration 2330 : 243854819328.0
Loss at iteration 2340 : 618593124352.0
Loss at iteration 2350 : 610088386560.0
Loss at iteration 2360 : 350317150208.0
Loss at iteration 2370 : 874395729920.0
Loss at iteration 2380 : 1330629967872.0
Loss at iteration 2390 : 1596196519936.0
Loss at iteration 2400 : 148617396224.0
Loss at iteration 2410 : 1326098022400.0
Loss at iteration 2420 : 393234743296.0
The SSIM Value is: 3.3436065147422293e-06
The PSNR Value is: -127.24888865152995
the epoch is: 164
Loss at iteration 10 : 1388822134784.0
Loss at iteration 20 : 207160180736.0
Loss at iteration 30 : 3527940243456.0
Loss at iteration 40 : 360651489280.0
Loss at iteration 50 : 90457227264.0
Loss at iteration 60 : 596836417536.0
Loss at iteration 70 : 561316954112.0
Loss at iteration 80 : 872662106112.0
Loss at iteration 90 : 189144088576.0
Loss at iteration 100 : 290266742784.0
Loss at iteration 110 : 403944177664.0
Loss at iteration 120 : 6267914944512.0
Loss at iteration 130 : 76912263168.0
Loss at iteration 140 : 734136107008.0
Loss at iteration 150 : 3134299308032.0
Loss at iteration 160 : 612514856960.0
Loss at iteration 170 : 1161684189184.0
Loss at iteration 180 : 6112126435328.0
Loss at iteration 190 : 45481914368.0
Loss at iteration 200 : 1402943963136.0
Loss at iteration 210 : 36535148544.0
Loss at iteration 220 : 476743401472.0
Loss at iteration 230 : 1909210087424.0
Loss at iteration 240 : 2819875930112.0
Loss at iteration 250 : 18869156577280.0
Loss at iteration 260 : 49946250182656.0
Loss at iteration 270 : 480939212800.0
Loss at iteration 280 : 2296929058816.0
Loss at iteration 290 : 458197270528.0
Loss at iteration 300 : 3293958635520.0
Loss at iteration 310 : 854109585408.0
Loss at iteration 320 : 4678295224320.0
Loss at iteration 330 : 174351532032.0
Loss at iteration 340 : 147060785152.0
Loss at iteration 350 : 406667526144.0
Loss at iteration 360 : 66068344832.0
Loss at iteration 370 : 604301361152.0
Loss at iteration 380 : 64102117376.0
Loss at iteration 390 : 772340842496.0
Loss at iteration 400 : 86496378880.0
Loss at iteration 410 : 143695790080.0
Loss at iteration 420 : 1635996139520.0
Loss at iteration 430 : 1494457909248.0
Loss at iteration 440 : 59845001216.0
Loss at iteration 450 : 668082176000.0
Loss at iteration 460 : 1004063555584.0
Loss at iteration 470 : 107506360320.0
Loss at iteration 480 : 209915985920.0
Loss at iteration 490 : 1595200372736.0
Loss at iteration 500 : 153694961664.0
Loss at iteration 510 : 29315059712.0
Loss at iteration 520 : 202067804160.0
Loss at iteration 530 : 249669206016.0
Loss at iteration 540 : 63781662720.0
Loss at iteration 550 : 501794865152.0
Loss at iteration 560 : 429087653888.0
Loss at iteration 570 : 168426307584.0
Loss at iteration 580 : 3933048406016.0
Loss at iteration 590 : 42086567936.0
Loss at iteration 600 : 918636855296.0
Loss at iteration 610 : 175047917568.0
Loss at iteration 620 : 383926960128.0
Loss at iteration 630 : 147386875904.0
Loss at iteration 640 : 50827239424.0
Loss at iteration 650 : 3364195663872.0
Loss at iteration 660 : 155626078208.0
Loss at iteration 670 : 138871701504.0
Loss at iteration 680 : 557239959552.0
Loss at iteration 690 : 481551974400.0
Loss at iteration 700 : 264683323392.0
Loss at iteration 710 : 930191808.0
Loss at iteration 720 : 435826458624.0
Loss at iteration 730 : 1260673826816.0
Loss at iteration 740 : 308134674432.0
Loss at iteration 750 : 53537521664.0
Loss at iteration 760 : 101374197760.0
Loss at iteration 770 : 121897959424.0
Loss at iteration 780 : 42316713984.0
Loss at iteration 790 : 445135323136.0
Loss at iteration 800 : 267157749760.0
Loss at iteration 810 : 66103398400.0
Loss at iteration 820 : 54678667264.0
Loss at iteration 830 : 102761431040.0
Loss at iteration 840 : 5404809728.0
Loss at iteration 850 : 1297243439104.0
Loss at iteration 860 : 95817981952.0
Loss at iteration 870 : 93609975808.0
Loss at iteration 880 : 77417635840.0
Loss at iteration 890 : 401353572352.0
Loss at iteration 900 : 229824315392.0
Loss at iteration 910 : 201584918528.0
Loss at iteration 920 : 323544580096.0
Loss at iteration 930 : 286003593216.0
Loss at iteration 940 : 451779493888.0
Loss at iteration 950 : 159733596160.0
Loss at iteration 960 : 544341950464.0
Loss at iteration 970 : 272560259072.0
Loss at iteration 980 : 211244630016.0
Loss at iteration 990 : 100425400320.0
Loss at iteration 1000 : 654973206528.0
Loss at iteration 1010 : 419949641728.0
Loss at iteration 1020 : 19484530180096.0
Loss at iteration 1030 : 107518050304.0
Loss at iteration 1040 : 16647220224.0
Loss at iteration 1050 : 135384252416.0
Loss at iteration 1060 : 74880720896.0
Loss at iteration 1070 : 789799239680.0
Loss at iteration 1080 : 189957652480.0
Loss at iteration 1090 : 61486870528.0
Loss at iteration 1100 : 1774833369088.0
Loss at iteration 1110 : 66196414464.0
Loss at iteration 1120 : 22881988608.0
Loss at iteration 1130 : 471895932928.0
Loss at iteration 1140 : 115895484416.0
Loss at iteration 1150 : 82765029376.0
Loss at iteration 1160 : 343923359744.0
Loss at iteration 1170 : 34703839232.0
Loss at iteration 1180 : 80190857216.0
Loss at iteration 1190 : 61592473600.0
Loss at iteration 1200 : 7463699480576.0
Loss at iteration 1210 : 456115355648.0
Loss at iteration 1220 : 264380907520.0
Loss at iteration 1230 : 29128427520.0
Loss at iteration 1240 : 77802364928.0
Loss at iteration 1250 : 1454064664576.0
Loss at iteration 1260 : 197287100416.0
Loss at iteration 1270 : 268858097664.0
Loss at iteration 1280 : 42337316864.0
Loss at iteration 1290 : 101503705088.0
Loss at iteration 1300 : 3786969856.0
Loss at iteration 1310 : 72382005248.0
Loss at iteration 1320 : 31719964672.0
Loss at iteration 1330 : 102036332544.0
Loss at iteration 1340 : 249053184000.0
Loss at iteration 1350 : 125985734656.0
Loss at iteration 1360 : 108794478592.0
Loss at iteration 1370 : 19222417408.0
Loss at iteration 1380 : 33727387648.0
Loss at iteration 1390 : 129309491200.0
Loss at iteration 1400 : 128025616384.0
Loss at iteration 1410 : 69733359616.0
Loss at iteration 1420 : 44181725184.0
Loss at iteration 1430 : 185739640832.0
Loss at iteration 1440 : 186783481856.0
Loss at iteration 1450 : 70040354816.0
Loss at iteration 1460 : 23318847488.0
Loss at iteration 1470 : 62917251072.0
Loss at iteration 1480 : 89866633216.0
Loss at iteration 1490 : 439435952128.0
Loss at iteration 1500 : 63721181184.0
Loss at iteration 1510 : 25002426368.0
Loss at iteration 1520 : 75909210112.0
Loss at iteration 1530 : 99068944384.0
Loss at iteration 1540 : 27223119872.0
Loss at iteration 1550 : 666053640192.0
Loss at iteration 1560 : 62394892288.0
Loss at iteration 1570 : 115881181184.0
Loss at iteration 1580 : 67051913216.0
Loss at iteration 1590 : 53748899840.0
Loss at iteration 1600 : 45640642560.0
Loss at iteration 1610 : 21382918144.0
Loss at iteration 1620 : 336310960128.0
Loss at iteration 1630 : 228171726848.0
Loss at iteration 1640 : 86439403520.0
Loss at iteration 1650 : 410042597376.0
Loss at iteration 1660 : 17921157120.0
Loss at iteration 1670 : 93812621312.0
Loss at iteration 1680 : 140593577984.0
Loss at iteration 1690 : 62569803776.0
Loss at iteration 1700 : 16668290048.0
Loss at iteration 1710 : 109144989696.0
Loss at iteration 1720 : 222075535360.0
Loss at iteration 1730 : 66969325568.0
Loss at iteration 1740 : 29705074688.0
Loss at iteration 1750 : 2921809051648.0
Loss at iteration 1760 : 156110962688.0
Loss at iteration 1770 : 217829408768.0
Loss at iteration 1780 : 90696138752.0
Loss at iteration 1790 : 71945560064.0
Loss at iteration 1800 : 115682705408.0
Loss at iteration 1810 : 33971351552.0
Loss at iteration 1820 : 124878831616.0
Loss at iteration 1830 : 36890423296.0
Loss at iteration 1840 : 24474445824.0
Loss at iteration 1850 : 10525807214592.0
Loss at iteration 1860 : 65488498688.0
Loss at iteration 1870 : 40249704448.0
Loss at iteration 1880 : 344263950336.0
Loss at iteration 1890 : 91983388672.0
Loss at iteration 1900 : 18629052416.0
Loss at iteration 1910 : 56081817600.0
Loss at iteration 1920 : 289687044096.0
Loss at iteration 1930 : 55716585472.0
Loss at iteration 1940 : 4575683149824.0
Loss at iteration 1950 : 58813710336.0
Loss at iteration 1960 : 305710301184.0
Loss at iteration 1970 : 161016561664.0
Loss at iteration 1980 : 122752188416.0
Loss at iteration 1990 : 77023551488.0
Loss at iteration 2000 : 66875920384.0
Loss at iteration 2010 : 18131066880.0
Loss at iteration 2020 : 316480552960.0
Loss at iteration 2030 : 199231324160.0
Loss at iteration 2040 : 104332410880.0
Loss at iteration 2050 : 349443817472.0
Loss at iteration 2060 : 93794402304.0
Loss at iteration 2070 : 8895949963264.0
Loss at iteration 2080 : 29815459840.0
Loss at iteration 2090 : 50449940480.0
Loss at iteration 2100 : 144888381440.0
Loss at iteration 2110 : 1450884333568.0
Loss at iteration 2120 : 515410329600.0
Loss at iteration 2130 : 38882959360.0
Loss at iteration 2140 : 836722884608.0
Loss at iteration 2150 : 171575902208.0
Loss at iteration 2160 : 379784265728.0
Loss at iteration 2170 : 39686950912.0
Loss at iteration 2180 : 1094232309760.0
Loss at iteration 2190 : 176402661376.0
Loss at iteration 2200 : 83402899456.0
Loss at iteration 2210 : 122856202240.0
Loss at iteration 2220 : 330698981376.0
Loss at iteration 2230 : 57843941376.0
Loss at iteration 2240 : 46701932544.0
Loss at iteration 2250 : 2346904190976.0
Loss at iteration 2260 : 81684463616.0
Loss at iteration 2270 : 35905363968.0
Loss at iteration 2280 : 12119407616.0
Loss at iteration 2290 : 52382969856.0
Loss at iteration 2300 : 39988645888.0
Loss at iteration 2310 : 1519724658688.0
Loss at iteration 2320 : 236251365376.0
Loss at iteration 2330 : 64412909568.0
Loss at iteration 2340 : 76162842624.0
Loss at iteration 2350 : 21213855744.0
Loss at iteration 2360 : 20094607360.0
Loss at iteration 2370 : 533016215552.0
Loss at iteration 2380 : 75231805440.0
Loss at iteration 2390 : 54635819008.0
Loss at iteration 2400 : 363369398272.0
Loss at iteration 2410 : 65804648448.0
Loss at iteration 2420 : 43721879552.0
The SSIM Value is: 9.537910561145205e-06
The PSNR Value is: -123.83646952311197
the epoch is: 165
Loss at iteration 10 : 110067359744.0
Loss at iteration 20 : 241686216704.0
Loss at iteration 30 : 348004876288.0
Loss at iteration 40 : 46057369600.0
Loss at iteration 50 : 896846397440.0
Loss at iteration 60 : 1145488015360.0
Loss at iteration 70 : 211693125632.0
Loss at iteration 80 : 35845890048.0
Loss at iteration 90 : 784941252608.0
Loss at iteration 100 : 174982348800.0
Loss at iteration 110 : 161917321216.0
Loss at iteration 120 : 189229498368.0
Loss at iteration 130 : 64575737856.0
Loss at iteration 140 : 156197715968.0
Loss at iteration 150 : 272501325824.0
Loss at iteration 160 : 302688272384.0
Loss at iteration 170 : 6808341053440.0
Loss at iteration 180 : 2287426076672.0
Loss at iteration 190 : 21047936024576.0
Loss at iteration 200 : 4686472019968.0
Loss at iteration 210 : 529569808384.0
Loss at iteration 220 : 437165555712.0
Loss at iteration 230 : 1632895107072.0
Loss at iteration 240 : 135399768064.0
Loss at iteration 250 : 19546759168.0
Loss at iteration 260 : 257444134912.0
Loss at iteration 270 : 7208771256320.0
Loss at iteration 280 : 197190860800.0
Loss at iteration 290 : 43716304896.0
Loss at iteration 300 : 108172140544.0
Loss at iteration 310 : 278176792576.0
Loss at iteration 320 : 77208838144.0
Loss at iteration 330 : 98600673280.0
Loss at iteration 340 : 24849526784.0
Loss at iteration 350 : 192069517312.0
Loss at iteration 360 : 40524472320.0
Loss at iteration 370 : 2997654126592.0
Loss at iteration 380 : 238976679936.0
Loss at iteration 390 : 1066350542848.0
Loss at iteration 400 : 148620853248.0
Loss at iteration 410 : 179982401536.0
Loss at iteration 420 : 3110141184.0
Loss at iteration 430 : 596019707904.0
Loss at iteration 440 : 38806233088.0
Loss at iteration 450 : 76635054080.0
Loss at iteration 460 : 61868584960.0
Loss at iteration 470 : 101297045504.0
Loss at iteration 480 : 32740337664.0
Loss at iteration 490 : 106652229632.0
Loss at iteration 500 : 17013158912.0
Loss at iteration 510 : 287524749312.0
Loss at iteration 520 : 27709335552.0
Loss at iteration 530 : 654582415360.0
Loss at iteration 540 : 47003185152.0
Loss at iteration 550 : 32033638400.0
Loss at iteration 560 : 34619498496.0
Loss at iteration 570 : 47442059264.0
Loss at iteration 580 : 525966180352.0
Loss at iteration 590 : 27329939456.0
Loss at iteration 600 : 277710503936.0
Loss at iteration 610 : 18482900992.0
Loss at iteration 620 : 14666985472.0
Loss at iteration 630 : 31116693504.0
Loss at iteration 640 : 26600310784.0
Loss at iteration 650 : 22623408128.0
Loss at iteration 660 : 26266732544.0
Loss at iteration 670 : 1492787456.0
Loss at iteration 680 : 181084225536.0
Loss at iteration 690 : 165467914240.0
Loss at iteration 700 : 10116523008.0
Loss at iteration 710 : 25266145280.0
Loss at iteration 720 : 34251274240.0
Loss at iteration 730 : 277276229632.0
Loss at iteration 740 : 49700327424.0
Loss at iteration 750 : 24188776448.0
Loss at iteration 760 : 48404193280.0
Loss at iteration 770 : 14465597440.0
Loss at iteration 780 : 31905945600.0
Loss at iteration 790 : 35667238912.0
Loss at iteration 800 : 15389624320.0
Loss at iteration 810 : 85090426880.0
Loss at iteration 820 : 45903609856.0
Loss at iteration 830 : 67431825408.0
Loss at iteration 840 : 38743826432.0
Loss at iteration 850 : 90073260032.0
Loss at iteration 860 : 177323851776.0
Loss at iteration 870 : 24979107840.0
Loss at iteration 880 : 6084549632.0
Loss at iteration 890 : 51438080000.0
Loss at iteration 900 : 357333270528.0
Loss at iteration 910 : 856340299776.0
Loss at iteration 920 : 192311492608.0
Loss at iteration 930 : 76029468672.0
Loss at iteration 940 : 7426436608.0
Loss at iteration 950 : 91835351040.0
Loss at iteration 960 : 15717170176.0
Loss at iteration 970 : 28397524992.0
Loss at iteration 980 : 28027256832.0
Loss at iteration 990 : 27307315200.0
Loss at iteration 1000 : 42331967488.0
Loss at iteration 1010 : 33140228096.0
Loss at iteration 1020 : 259278635008.0
Loss at iteration 1030 : 512896630784.0
Loss at iteration 1040 : 52995190784.0
Loss at iteration 1050 : 55003226112.0
Loss at iteration 1060 : 259592372224.0
Loss at iteration 1070 : 23728627712.0
Loss at iteration 1080 : 427034935296.0
Loss at iteration 1090 : 131882008576.0
Loss at iteration 1100 : 33759985664.0
Loss at iteration 1110 : 56315027456.0
Loss at iteration 1120 : 68084985856.0
Loss at iteration 1130 : 31160190976.0
Loss at iteration 1140 : 78578860032.0
Loss at iteration 1150 : 61958750208.0
Loss at iteration 1160 : 34084337664.0
Loss at iteration 1170 : 23780483072.0
Loss at iteration 1180 : 6645276160.0
Loss at iteration 1190 : 31186960384.0
Loss at iteration 1200 : 62697324544.0
Loss at iteration 1210 : 56687226880.0
Loss at iteration 1220 : 26590636032.0
Loss at iteration 1230 : 512074208.0
Loss at iteration 1240 : 20259964928.0
Loss at iteration 1250 : 14952748032.0
Loss at iteration 1260 : 89621012480.0
Loss at iteration 1270 : 26064947200.0
Loss at iteration 1280 : 85645524992.0
Loss at iteration 1290 : 27336370176.0
Loss at iteration 1300 : 24694513664.0
Loss at iteration 1310 : 14309905408.0
Loss at iteration 1320 : 27791058944.0
Loss at iteration 1330 : 154270154752.0
Loss at iteration 1340 : 10169183232.0
Loss at iteration 1350 : 108172836864.0
Loss at iteration 1360 : 76394897408.0
Loss at iteration 1370 : 32541886464.0
Loss at iteration 1380 : 17715159040.0
Loss at iteration 1390 : 23049961472.0
Loss at iteration 1400 : 29868838912.0
Loss at iteration 1410 : 40865624064.0
Loss at iteration 1420 : 2995031113728.0
Loss at iteration 1430 : 47841247232.0
Loss at iteration 1440 : 11776411648.0
Loss at iteration 1450 : 4685687160832.0
Loss at iteration 1460 : 969243164672.0
Loss at iteration 1470 : 3143627177984.0
Loss at iteration 1480 : 17131034902528.0
Loss at iteration 1490 : 9642009379733504.0
Loss at iteration 1500 : 4570623246336.0
Loss at iteration 1510 : 440765549379584.0
Loss at iteration 1520 : 56384737509376.0
Loss at iteration 1530 : 12860143960064.0
Loss at iteration 1540 : 572542494441472.0
Loss at iteration 1550 : 8646814072832.0
Loss at iteration 1560 : 885517254656.0
Loss at iteration 1570 : 3680399523840.0
Loss at iteration 1580 : 607706546176.0
Loss at iteration 1590 : 188500017152.0
Loss at iteration 1600 : 21282408103936.0
Loss at iteration 1610 : 12951204397056.0
Loss at iteration 1620 : 1059654860800.0
Loss at iteration 1630 : 899803119616.0
Loss at iteration 1640 : 39240093696.0
Loss at iteration 1650 : 1268414152704.0
Loss at iteration 1660 : 16668463988736.0
Loss at iteration 1670 : 17005194248192.0
Loss at iteration 1680 : 89431687168.0
Loss at iteration 1690 : 189578903552.0
Loss at iteration 1700 : 2916076486656.0
Loss at iteration 1710 : 450102558720.0
Loss at iteration 1720 : 219643969536.0
Loss at iteration 1730 : 11515619966976.0
Loss at iteration 1740 : 483530145792.0
Loss at iteration 1750 : 118321618944.0
Loss at iteration 1760 : 588053676032.0
Loss at iteration 1770 : 35154454118400.0
Loss at iteration 1780 : 93453918208.0
Loss at iteration 1790 : 16226195603456.0
Loss at iteration 1800 : 73993633792.0
Loss at iteration 1810 : 1283235119104.0
Loss at iteration 1820 : 2995002277888.0
Loss at iteration 1830 : 2018344832.0
Loss at iteration 1840 : 223925420032.0
Loss at iteration 1850 : 1635862839296.0
Loss at iteration 1860 : 57150144512.0
Loss at iteration 1870 : 4488358400.0
Loss at iteration 1880 : 57344303104.0
Loss at iteration 1890 : 16537577586688.0
Loss at iteration 1900 : 11183761408.0
Loss at iteration 1910 : 993759199232.0
Loss at iteration 1920 : 5836029558784.0
Loss at iteration 1930 : 178198528655360.0
Loss at iteration 1940 : 6442621861888.0
Loss at iteration 1950 : 5180663791616.0
Loss at iteration 1960 : 182877044736.0
Loss at iteration 1970 : 533047377920.0
Loss at iteration 1980 : 6347598856192.0
Loss at iteration 1990 : 340230635520.0
Loss at iteration 2000 : 28124848848896.0
Loss at iteration 2010 : 328873672704.0
Loss at iteration 2020 : 5466876280832.0
Loss at iteration 2030 : 7226727596032.0
Loss at iteration 2040 : 5280051494912.0
Loss at iteration 2050 : 1168252469248.0
Loss at iteration 2060 : 132250984448.0
Loss at iteration 2070 : 22298396459008.0
Loss at iteration 2080 : 164084776960.0
Loss at iteration 2090 : 1257017573376.0
Loss at iteration 2100 : 976380887040.0
Loss at iteration 2110 : 451040215040.0
Loss at iteration 2120 : 19661606912.0
Loss at iteration 2130 : 90537365340160.0
Loss at iteration 2140 : 17450205184.0
Loss at iteration 2150 : 49132511232.0
Loss at iteration 2160 : 426465853440.0
Loss at iteration 2170 : 544846512128.0
Loss at iteration 2180 : 22061252608.0
Loss at iteration 2190 : 2150703300608.0
Loss at iteration 2200 : 259530506240.0
Loss at iteration 2210 : 329059336192.0
Loss at iteration 2220 : 93273260032.0
Loss at iteration 2230 : 315908161536.0
Loss at iteration 2240 : 23832915968.0
Loss at iteration 2250 : 428924993536.0
Loss at iteration 2260 : 13417029632.0
Loss at iteration 2270 : 359155269632.0
Loss at iteration 2280 : 14307442688.0
Loss at iteration 2290 : 242662408192.0
Loss at iteration 2300 : 890648657920.0
Loss at iteration 2310 : 82154528768.0
Loss at iteration 2320 : 88774754304.0
Loss at iteration 2330 : 136875409408.0
Loss at iteration 2340 : 982993534976.0
Loss at iteration 2350 : 5037879721984.0
Loss at iteration 2360 : 726594027520.0
Loss at iteration 2370 : 667807252480.0
Loss at iteration 2380 : 284630974464.0
Loss at iteration 2390 : 130016116736.0
Loss at iteration 2400 : 3659479646208.0
Loss at iteration 2410 : 64298450944.0
Loss at iteration 2420 : 25058461696.0
The SSIM Value is: 7.869670609276606e-06
The PSNR Value is: -116.52708536783854
the epoch is: 166
Loss at iteration 10 : 403492044800.0
Loss at iteration 20 : 29862729728.0
Loss at iteration 30 : 94732140544.0
Loss at iteration 40 : 51273011200.0
Loss at iteration 50 : 32496218112.0
Loss at iteration 60 : 840397750272.0
Loss at iteration 70 : 3573347584.0
Loss at iteration 80 : 7429003776.0
Loss at iteration 90 : 114794823680.0
Loss at iteration 100 : 10833478656.0
Loss at iteration 110 : 76696559616.0
Loss at iteration 120 : 36287320064.0
Loss at iteration 130 : 56095600640.0
Loss at iteration 140 : 25595250688.0
Loss at iteration 150 : 8588276224.0
Loss at iteration 160 : 188744826880.0
Loss at iteration 170 : 238231994368.0
Loss at iteration 180 : 156112633856.0
Loss at iteration 190 : 24785096704.0
Loss at iteration 200 : 11128249344.0
Loss at iteration 210 : 61767745536.0
Loss at iteration 220 : 16020867072.0
Loss at iteration 230 : 52085309440.0
Loss at iteration 240 : 631038935040.0
Loss at iteration 250 : 19686572032.0
Loss at iteration 260 : 22080169984.0
Loss at iteration 270 : 62835236864.0
Loss at iteration 280 : 96530620416.0
Loss at iteration 290 : 123008671744.0
Loss at iteration 300 : 10020926464.0
Loss at iteration 310 : 226619801600.0
Loss at iteration 320 : 103537909760.0
Loss at iteration 330 : 26721409024.0
Loss at iteration 340 : 12240476160.0
Loss at iteration 350 : 21597669376.0
Loss at iteration 360 : 59434057728.0
Loss at iteration 370 : 90201038848.0
Loss at iteration 380 : 88296464384.0
Loss at iteration 390 : 17052615680.0
Loss at iteration 400 : 101129551872.0
Loss at iteration 410 : 33342124032.0
Loss at iteration 420 : 27646138368.0
Loss at iteration 430 : 28801595392.0
Loss at iteration 440 : 41385443328.0
Loss at iteration 450 : 20123045888.0
Loss at iteration 460 : 350293295104.0
Loss at iteration 470 : 760392253440.0
Loss at iteration 480 : 46375055360.0
Loss at iteration 490 : 182455468032.0
Loss at iteration 500 : 14731936768.0
Loss at iteration 510 : 15789023232.0
Loss at iteration 520 : 10526282752.0
Loss at iteration 530 : 164939251712.0
Loss at iteration 540 : 45717032960.0
Loss at iteration 550 : 34858459136.0
Loss at iteration 560 : 369557766144.0
Loss at iteration 570 : 6750413824.0
Loss at iteration 580 : 42936365056.0
Loss at iteration 590 : 5234942976.0
Loss at iteration 600 : 135999324160.0
Loss at iteration 610 : 25779427328.0
Loss at iteration 620 : 9452773376.0
Loss at iteration 630 : 44862300160.0
Loss at iteration 640 : 23864168448.0
Loss at iteration 650 : 106319601664.0
Loss at iteration 660 : 1473376944128.0
Loss at iteration 670 : 609848393728.0
Loss at iteration 680 : 11784799911936.0
Loss at iteration 690 : 178625173258240.0
Loss at iteration 700 : 5607746560.0
Loss at iteration 710 : 539338309632.0
Loss at iteration 720 : 155541209088.0
Loss at iteration 730 : 2241631879168.0
Loss at iteration 740 : 596001554432.0
Loss at iteration 750 : 1115808727040.0
Loss at iteration 760 : 22031646720.0
Loss at iteration 770 : 27308255608832.0
Loss at iteration 780 : 9309400334336.0
Loss at iteration 790 : 15195354169344.0
Loss at iteration 800 : 822182739968.0
Loss at iteration 810 : 4226948792320.0
Loss at iteration 820 : 185736019968.0
Loss at iteration 830 : 22161154637824.0
Loss at iteration 840 : 152181395161088.0
Loss at iteration 850 : 16784632578048.0
Loss at iteration 860 : 9479568490496.0
Loss at iteration 870 : 4449596080128.0
Loss at iteration 880 : 8244107935744.0
Loss at iteration 890 : 8918972497920.0
Loss at iteration 900 : 21158418186240.0
Loss at iteration 910 : 5973266137088.0
Loss at iteration 920 : 7560422752256.0
Loss at iteration 930 : 102881294286848.0
Loss at iteration 940 : 537234800640.0
Loss at iteration 950 : 286733023313920.0
Loss at iteration 960 : 15967345180672.0
Loss at iteration 970 : 6591509692416.0
Loss at iteration 980 : 66836381040640.0
Loss at iteration 990 : 25166048395264.0
Loss at iteration 1000 : 69777691246592.0
Loss at iteration 1010 : 5600515719168.0
Loss at iteration 1020 : 452329897984.0
Loss at iteration 1030 : 137094064242688.0
Loss at iteration 1040 : 35004656648192.0
Loss at iteration 1050 : 1165245415424.0
Loss at iteration 1060 : 23394116435968.0
Loss at iteration 1070 : 8254134943744.0
Loss at iteration 1080 : 14140713205760.0
Loss at iteration 1090 : 9475146645504.0
Loss at iteration 1100 : 16363516067840.0
Loss at iteration 1110 : 779745608335360.0
Loss at iteration 1120 : 653903133671424.0
Loss at iteration 1130 : 1.2737454586986496e+16
Loss at iteration 1140 : 27487868289024.0
Loss at iteration 1150 : 2288534683648.0
Loss at iteration 1160 : 1749733081088.0
Loss at iteration 1170 : 430349156352.0
Loss at iteration 1180 : 21252966187008.0
Loss at iteration 1190 : 16377709592576.0
Loss at iteration 1200 : 561951932416.0
Loss at iteration 1210 : 1243046871040.0
Loss at iteration 1220 : 68829866622976.0
Loss at iteration 1230 : 1968845881344.0
Loss at iteration 1240 : 2335490703360.0
Loss at iteration 1250 : 52052214415360.0
Loss at iteration 1260 : 14520159305728.0
Loss at iteration 1270 : 2888478228480.0
Loss at iteration 1280 : 1026218786816.0
Loss at iteration 1290 : 7249581834240.0
Loss at iteration 1300 : 4738229731328.0
Loss at iteration 1310 : 18538869817344.0
Loss at iteration 1320 : 60165067898880.0
Loss at iteration 1330 : 184671849676800.0
Loss at iteration 1340 : 271558937411584.0
Loss at iteration 1350 : 1084753985929216.0
Loss at iteration 1360 : 41071623012352.0
Loss at iteration 1370 : 71743746080768.0
Loss at iteration 1380 : 2561260388352.0
Loss at iteration 1390 : 65306106003456.0
Loss at iteration 1400 : 2834087018496.0
Loss at iteration 1410 : 15376299589632.0
Loss at iteration 1420 : 4684013109248.0
Loss at iteration 1430 : 16759241310208.0
Loss at iteration 1440 : 5068019990528.0
Loss at iteration 1450 : 387198713856.0
Loss at iteration 1460 : 4272490807296.0
Loss at iteration 1470 : 375045160960.0
Loss at iteration 1480 : 1467631796224.0
Loss at iteration 1490 : 1427033686016.0
Loss at iteration 1500 : 31276692144128.0
Loss at iteration 1510 : 3394290057216.0
Loss at iteration 1520 : 3614675828736.0
Loss at iteration 1530 : 514557018112.0
Loss at iteration 1540 : 4416920879104.0
Loss at iteration 1550 : 5367119478784.0
Loss at iteration 1560 : 8477305470976.0
Loss at iteration 1570 : 8022333063168.0
Loss at iteration 1580 : 28405695250432.0
Loss at iteration 1590 : 659340591104.0
Loss at iteration 1600 : 28490959159296.0
Loss at iteration 1610 : 262980239360.0
Loss at iteration 1620 : 340411514880.0
Loss at iteration 1630 : 1609124020224.0
Loss at iteration 1640 : 14370281095168.0
Loss at iteration 1650 : 45161757278208.0
Loss at iteration 1660 : 759474749440.0
Loss at iteration 1670 : 326083051520.0
Loss at iteration 1680 : 1192237989888.0
Loss at iteration 1690 : 5200986243072.0
Loss at iteration 1700 : 3634937200640.0
Loss at iteration 1710 : 1732312956928.0
Loss at iteration 1720 : 13546955997184.0
Loss at iteration 1730 : 806058590208.0
Loss at iteration 1740 : 32709986484224.0
Loss at iteration 1750 : 13025580941312.0
Loss at iteration 1760 : 1953679409152.0
Loss at iteration 1770 : 7176408530944.0
Loss at iteration 1780 : 1885724868608.0
Loss at iteration 1790 : 332357074944.0
Loss at iteration 1800 : 305738252288.0
Loss at iteration 1810 : 1356342362112.0
Loss at iteration 1820 : 977663754240.0
Loss at iteration 1830 : 2540676841472.0
Loss at iteration 1840 : 1700052598784.0
Loss at iteration 1850 : 7002086965248.0
Loss at iteration 1860 : 3782003130368.0
Loss at iteration 1870 : 3182421868544.0
Loss at iteration 1880 : 584257044480.0
Loss at iteration 1890 : 2217313566720.0
Loss at iteration 1900 : 3675935211520.0
Loss at iteration 1910 : 363208998912.0
Loss at iteration 1920 : 1008673357824.0
Loss at iteration 1930 : 939494408192.0
Loss at iteration 1940 : 2357815934976.0
Loss at iteration 1950 : 4221076242432.0
Loss at iteration 1960 : 419317907456.0
Loss at iteration 1970 : 1751967072256.0
Loss at iteration 1980 : 1859476652032.0
Loss at iteration 1990 : 897280966656.0
Loss at iteration 2000 : 5321366437888.0
Loss at iteration 2010 : 1166953414656.0
Loss at iteration 2020 : 3671646535680.0
Loss at iteration 2030 : 7317170946048.0
Loss at iteration 2040 : 729355845632.0
Loss at iteration 2050 : 804623745024.0
Loss at iteration 2060 : 794405634048.0
Loss at iteration 2070 : 2044666445824.0
Loss at iteration 2080 : 1753503629312.0
Loss at iteration 2090 : 571547516928.0
Loss at iteration 2100 : 1243431305216.0
Loss at iteration 2110 : 8972520128512.0
Loss at iteration 2120 : 6934163881984.0
Loss at iteration 2130 : 1635664920576.0
Loss at iteration 2140 : 2299701231616.0
Loss at iteration 2150 : 3745373749248.0
Loss at iteration 2160 : 562739806208.0
Loss at iteration 2170 : 1247032115200.0
Loss at iteration 2180 : 1889536573440.0
Loss at iteration 2190 : 2523687288832.0
Loss at iteration 2200 : 3989150629888.0
Loss at iteration 2210 : 32752749510656.0
Loss at iteration 2220 : 11652215865344.0
Loss at iteration 2230 : 1588883488768.0
Loss at iteration 2240 : 46477304922112.0
Loss at iteration 2250 : 177791303680.0
Loss at iteration 2260 : 7116707856384.0
Loss at iteration 2270 : 109814311026688.0
Loss at iteration 2280 : 1.150199526133334e+18
Loss at iteration 2290 : 1115170407448576.0
Loss at iteration 2300 : 58494388535296.0
Loss at iteration 2310 : 2449876726054912.0
Loss at iteration 2320 : 5083683815948288.0
Loss at iteration 2330 : 132895758876672.0
Loss at iteration 2340 : 6465125686968320.0
Loss at iteration 2350 : 27918772207616.0
Loss at iteration 2360 : 23880693448704.0
Loss at iteration 2370 : 46423978541056.0
Loss at iteration 2380 : 14529231585280.0
Loss at iteration 2390 : 33252802822144.0
Loss at iteration 2400 : 6803889848320.0
Loss at iteration 2410 : 29132849152000.0
Loss at iteration 2420 : 121033898065920.0
The SSIM Value is: 6.759484402370693e-06
The PSNR Value is: -149.31404520670574
the epoch is: 167
Loss at iteration 10 : 5027387670528.0
Loss at iteration 20 : 70550340763648.0
Loss at iteration 30 : 23726018002944.0
Loss at iteration 40 : 41143576297472.0
Loss at iteration 50 : 67347356319744.0
Loss at iteration 60 : 39326113071104.0
Loss at iteration 70 : 2359237017600.0
Loss at iteration 80 : 112027376812032.0
Loss at iteration 90 : 188793558663168.0
Loss at iteration 100 : 3128565956608.0
Loss at iteration 110 : 10969631686656.0
Loss at iteration 120 : 3431395753984.0
Loss at iteration 130 : 308898040905728.0
Loss at iteration 140 : 153364676608.0
Loss at iteration 150 : 23706019561472.0
Loss at iteration 160 : 368511314558976.0
Loss at iteration 170 : 2374190497792.0
Loss at iteration 180 : 24613694210048.0
Loss at iteration 190 : 32654101577728.0
Loss at iteration 200 : 3257140248576.0
Loss at iteration 210 : 8685648084992.0
Loss at iteration 220 : 13078728015872.0
Loss at iteration 230 : 30787856498688.0
Loss at iteration 240 : 132317087531008.0
Loss at iteration 250 : 321268385579008.0
Loss at iteration 260 : 2357088747520.0
Loss at iteration 270 : 19760880287744.0
Loss at iteration 280 : 71891595296768.0
Loss at iteration 290 : 55666022547456.0
Loss at iteration 300 : 148838081888256.0
Loss at iteration 310 : 196998607142912.0
Loss at iteration 320 : 53871850291200.0
Loss at iteration 330 : 24889176096768.0
Loss at iteration 340 : 27706276184064.0
Loss at iteration 350 : 5158947258368.0
Loss at iteration 360 : 6759226802176.0
Loss at iteration 370 : 2370430042112.0
Loss at iteration 380 : 15596534104064.0
Loss at iteration 390 : 481113767936.0
Loss at iteration 400 : 4635223916544.0
Loss at iteration 410 : 6534514868224.0
Loss at iteration 420 : 35768768659456.0
Loss at iteration 430 : 952724750336.0
Loss at iteration 440 : 4654416527360.0
Loss at iteration 450 : 108316583788544.0
Loss at iteration 460 : 343657021440.0
Loss at iteration 470 : 12820390346752.0
Loss at iteration 480 : 12344788779008.0
Loss at iteration 490 : 141605440847872.0
Loss at iteration 500 : 7148438290432.0
Loss at iteration 510 : 163025701044224.0
Loss at iteration 520 : 87134602002432.0
Loss at iteration 530 : 25919039209472.0
Loss at iteration 540 : 3943626440704.0
Loss at iteration 550 : 4582005538816.0
Loss at iteration 560 : 8251885223936.0
Loss at iteration 570 : 15684591419392.0
Loss at iteration 580 : 38987414634496.0
Loss at iteration 590 : 2999073374208.0
Loss at iteration 600 : 26241719599104.0
Loss at iteration 610 : 16704836993024.0
Loss at iteration 620 : 11465379545088.0
Loss at iteration 630 : 1024332660736.0
Loss at iteration 640 : 17744850321408.0
Loss at iteration 650 : 104502501834752.0
Loss at iteration 660 : 1654431940608.0
Loss at iteration 670 : 5490734006272.0
Loss at iteration 680 : 948938080256.0
Loss at iteration 690 : 9034548641792.0
Loss at iteration 700 : 8019761954816.0
Loss at iteration 710 : 5672108294144.0
Loss at iteration 720 : 5455630827520.0
Loss at iteration 730 : 5475538567168.0
Loss at iteration 740 : 3750324862976.0
Loss at iteration 750 : 11861873393664.0
Loss at iteration 760 : 11312965877760.0
Loss at iteration 770 : 40006508871680.0
Loss at iteration 780 : 2522068025344.0
Loss at iteration 790 : 22671202975744.0
Loss at iteration 800 : 9175206723584.0
Loss at iteration 810 : 45976408555520.0
Loss at iteration 820 : 12396926074880.0
Loss at iteration 830 : 3366035390464.0
Loss at iteration 840 : 5328280748032.0
Loss at iteration 850 : 8978041929728.0
Loss at iteration 860 : 3101414916096.0
Loss at iteration 870 : 7964162260992.0
Loss at iteration 880 : 10231108075520.0
Loss at iteration 890 : 1023971557376.0
Loss at iteration 900 : 231991534419968.0
Loss at iteration 910 : 896338427904.0
Loss at iteration 920 : 2603484184576.0
Loss at iteration 930 : 25893017747456.0
Loss at iteration 940 : 582696566784.0
Loss at iteration 950 : 329713667014656.0
Loss at iteration 960 : 578802073731072.0
Loss at iteration 970 : 99196027797504.0
Loss at iteration 980 : 48161930346496.0
Loss at iteration 990 : 1852984918016.0
Loss at iteration 1000 : 12407968628736.0
Loss at iteration 1010 : 12067070279680.0
Loss at iteration 1020 : 2442537730048.0
Loss at iteration 1030 : 5878526246912.0
Loss at iteration 1040 : 8686167130112.0
Loss at iteration 1050 : 5001568059392.0
Loss at iteration 1060 : 2129880678400.0
Loss at iteration 1070 : 4775217201152.0
Loss at iteration 1080 : 44583970930688.0
Loss at iteration 1090 : 512066519040.0
Loss at iteration 1100 : 14162802507776.0
Loss at iteration 1110 : 2468411604992.0
Loss at iteration 1120 : 4226125135872.0
Loss at iteration 1130 : 10211487121408.0
Loss at iteration 1140 : 1869846937600.0
Loss at iteration 1150 : 15873592000512.0
Loss at iteration 1160 : 14652897492992.0
Loss at iteration 1170 : 563680641024.0
Loss at iteration 1180 : 4015992602624.0
Loss at iteration 1190 : 101384568832.0
Loss at iteration 1200 : 1193589997568.0
Loss at iteration 1210 : 5571279323136.0
Loss at iteration 1220 : 8069366415360.0
Loss at iteration 1230 : 11898530562048.0
Loss at iteration 1240 : 4897019265024.0
Loss at iteration 1250 : 1691094876160.0
Loss at iteration 1260 : 2301523918848.0
Loss at iteration 1270 : 1166745796608.0
Loss at iteration 1280 : 2088548302848.0
Loss at iteration 1290 : 553825861632.0
Loss at iteration 1300 : 3187156713472.0
Loss at iteration 1310 : 70567831011328.0
Loss at iteration 1320 : 32298409918464.0
Loss at iteration 1330 : 471889608704.0
Loss at iteration 1340 : 2511652257792.0
Loss at iteration 1350 : 1327481749504.0
Loss at iteration 1360 : 2212447649792.0
Loss at iteration 1370 : 22007376773120.0
Loss at iteration 1380 : 535657021440.0
Loss at iteration 1390 : 5772982878208.0
Loss at iteration 1400 : 8113368858624.0
Loss at iteration 1410 : 5653553217536.0
Loss at iteration 1420 : 1079618961408.0
Loss at iteration 1430 : 18044348792832.0
Loss at iteration 1440 : 395129978880.0
Loss at iteration 1450 : 2493377413120.0
Loss at iteration 1460 : 1776097034240.0
Loss at iteration 1470 : 2236814721024.0
Loss at iteration 1480 : 542982078464.0
Loss at iteration 1490 : 5665157283840.0
Loss at iteration 1500 : 816347676672.0
Loss at iteration 1510 : 975199797248.0
Loss at iteration 1520 : 121482502144.0
Loss at iteration 1530 : 1689991249920.0
Loss at iteration 1540 : 3325341990912.0
Loss at iteration 1550 : 2687711313920.0
Loss at iteration 1560 : 1259441881088.0
Loss at iteration 1570 : 1476041900032.0
Loss at iteration 1580 : 14943447416832.0
Loss at iteration 1590 : 2112073891840.0
Loss at iteration 1600 : 181483339776.0
Loss at iteration 1610 : 1396087455744.0
Loss at iteration 1620 : 523212193792.0
Loss at iteration 1630 : 26385986879488.0
Loss at iteration 1640 : 4696938381312.0
Loss at iteration 1650 : 490094428160.0
Loss at iteration 1660 : 10578992037888.0
Loss at iteration 1670 : 3945863053312.0
Loss at iteration 1680 : 23180351635456.0
Loss at iteration 1690 : 1419149443072.0
Loss at iteration 1700 : 44554216538112.0
Loss at iteration 1710 : 1619780698112.0
Loss at iteration 1720 : 10498254831616.0
Loss at iteration 1730 : 12411507572736.0
Loss at iteration 1740 : 15755386028032.0
Loss at iteration 1750 : 3722286465024.0
Loss at iteration 1760 : 7690714087424.0
Loss at iteration 1770 : 4449025654784.0
Loss at iteration 1780 : 36437554626560.0
Loss at iteration 1790 : 2459697414144.0
Loss at iteration 1800 : 921099370496.0
Loss at iteration 1810 : 675863855104.0
Loss at iteration 1820 : 2334577131520.0
Loss at iteration 1830 : 2.8357281053671424e+16
Loss at iteration 1840 : 12037078908928.0
Loss at iteration 1850 : 82392320573440.0
Loss at iteration 1860 : 1.4432859641085952e+16
Loss at iteration 1870 : 1.9177534751988777e+18
Loss at iteration 1880 : 2901863246594048.0
Loss at iteration 1890 : 3913490448252928.0
Loss at iteration 1900 : 206212989714432.0
Loss at iteration 1910 : 1061528614731776.0
Loss at iteration 1920 : 3012795272527872.0
Loss at iteration 1930 : 92536513232896.0
Loss at iteration 1940 : 17392451190784.0
Loss at iteration 1950 : 1677551277703168.0
Loss at iteration 1960 : 159558823575552.0
Loss at iteration 1970 : 106212343414784.0
Loss at iteration 1980 : 22952116486144.0
Loss at iteration 1990 : 28470136537088.0
Loss at iteration 2000 : 45042962006016.0
Loss at iteration 2010 : 38109500669952.0
Loss at iteration 2020 : 12040263434240.0
Loss at iteration 2030 : 7442463195136.0
Loss at iteration 2040 : 12076214910976.0
Loss at iteration 2050 : 2410100497055744.0
Loss at iteration 2060 : 1294950490701824.0
Loss at iteration 2070 : 13890527166464.0
Loss at iteration 2080 : 153771707465728.0
Loss at iteration 2090 : 23345586241536.0
Loss at iteration 2100 : 163168676478976.0
Loss at iteration 2110 : 35373891715072.0
Loss at iteration 2120 : 4478688821248.0
Loss at iteration 2130 : 17917636771840.0
Loss at iteration 2140 : 371266368307200.0
Loss at iteration 2150 : 10118593773568.0
Loss at iteration 2160 : 37788879683584.0
Loss at iteration 2170 : 38555384545280.0
Loss at iteration 2180 : 5931601494016.0
Loss at iteration 2190 : 16206284193792.0
Loss at iteration 2200 : 9300296597504.0
Loss at iteration 2210 : 2926627520512.0
Loss at iteration 2220 : 5245903568896.0
Loss at iteration 2230 : 32807634075648.0
Loss at iteration 2240 : 4566004793344.0
Loss at iteration 2250 : 10852496310272.0
Loss at iteration 2260 : 310975228018688.0
Loss at iteration 2270 : 22237180592128.0
Loss at iteration 2280 : 83144619327488.0
Loss at iteration 2290 : 910364442624.0
Loss at iteration 2300 : 2238099488768.0
Loss at iteration 2310 : 5328416014336.0
Loss at iteration 2320 : 7466217111552.0
Loss at iteration 2330 : 16702220795904.0
Loss at iteration 2340 : 5158370017280.0
Loss at iteration 2350 : 6451623886848.0
Loss at iteration 2360 : 2741596061696.0
Loss at iteration 2370 : 1552885874688.0
Loss at iteration 2380 : 22589663608832.0
Loss at iteration 2390 : 45805243203584.0
Loss at iteration 2400 : 1058499854336.0
Loss at iteration 2410 : 77729420541952.0
Loss at iteration 2420 : 544268943360.0
The SSIM Value is: 1.0207435671816257e-06
The PSNR Value is: -137.121435546875
the epoch is: 168
Loss at iteration 10 : 2812012920832.0
Loss at iteration 20 : 26935698653184.0
Loss at iteration 30 : 47917784104960.0
Loss at iteration 40 : 70184295464960.0
Loss at iteration 50 : 68450739290112.0
Loss at iteration 60 : 54955822022656.0
Loss at iteration 70 : 249267537051648.0
Loss at iteration 80 : 398508406341632.0
Loss at iteration 90 : 193654387900416.0
Loss at iteration 100 : 11291306491904.0
Loss at iteration 110 : 2423620894720.0
Loss at iteration 120 : 4974518992896.0
Loss at iteration 130 : 7161756778496.0
Loss at iteration 140 : 1809254449152.0
Loss at iteration 150 : 23504487448576.0
Loss at iteration 160 : 9473187905536.0
Loss at iteration 170 : 14584276582400.0
Loss at iteration 180 : 26879144755200.0
Loss at iteration 190 : 10661011652608.0
Loss at iteration 200 : 1063848181760.0
Loss at iteration 210 : 2682277593088.0
Loss at iteration 220 : 2166982311936.0
Loss at iteration 230 : 286218780672.0
Loss at iteration 240 : 15374497087488.0
Loss at iteration 250 : 9456457875456.0
Loss at iteration 260 : 6365821534208.0
Loss at iteration 270 : 4945578295296.0
Loss at iteration 280 : 3703484186624.0
Loss at iteration 290 : 735164432384.0
Loss at iteration 300 : 1369054380032.0
Loss at iteration 310 : 2507336581120.0
Loss at iteration 320 : 2176895680512.0
Loss at iteration 330 : 4566650191872.0
Loss at iteration 340 : 1837158236160.0
Loss at iteration 350 : 266885808128.0
Loss at iteration 360 : 24140471861248.0
Loss at iteration 370 : 27713211465728.0
Loss at iteration 380 : 13506680193024.0
Loss at iteration 390 : 48859434713088.0
Loss at iteration 400 : 100047991603200.0
Loss at iteration 410 : 92532537032704.0
Loss at iteration 420 : 75291305181184.0
Loss at iteration 430 : 19386062602240.0
Loss at iteration 440 : 9321156968448.0
Loss at iteration 450 : 339534915043328.0
Loss at iteration 460 : 4088517885952.0
Loss at iteration 470 : 10288596254720.0
Loss at iteration 480 : 1354756390912.0
Loss at iteration 490 : 312614912000.0
Loss at iteration 500 : 5140208156672.0
Loss at iteration 510 : 3097626411008.0
Loss at iteration 520 : 22750173331456.0
Loss at iteration 530 : 18507192336384.0
Loss at iteration 540 : 30027057987584.0
Loss at iteration 550 : 4753410490368.0
Loss at iteration 560 : 21092334829568.0
Loss at iteration 570 : 3256174247936.0
Loss at iteration 580 : 4790748708864.0
Loss at iteration 590 : 5461652799488.0
Loss at iteration 600 : 84223184601088.0
Loss at iteration 610 : 10634933567488.0
Loss at iteration 620 : 788574896128.0
Loss at iteration 630 : 47557950570496.0
Loss at iteration 640 : 17014982705152.0
Loss at iteration 650 : 3539230785536.0
Loss at iteration 660 : 12408081874944.0
Loss at iteration 670 : 3515540045824.0
Loss at iteration 680 : 5183465586688.0
Loss at iteration 690 : 6595470688256.0
Loss at iteration 700 : 286080073728.0
Loss at iteration 710 : 6901519089664.0
Loss at iteration 720 : 7526905544704.0
Loss at iteration 730 : 10493868638208.0
Loss at iteration 740 : 4400572530688.0
Loss at iteration 750 : 21988525473792.0
Loss at iteration 760 : 114413395968.0
Loss at iteration 770 : 5625336037376.0
Loss at iteration 780 : 419984998400.0
Loss at iteration 790 : 2321852399616.0
Loss at iteration 800 : 7144165343232.0
Loss at iteration 810 : 1108236828672.0
Loss at iteration 820 : 7275614830592.0
Loss at iteration 830 : 1540282515456.0
Loss at iteration 840 : 15303707721728.0
Loss at iteration 850 : 16017368547328.0
Loss at iteration 860 : 2285280690176.0
Loss at iteration 870 : 1861915770880.0
Loss at iteration 880 : 3016951070720.0
Loss at iteration 890 : 82561384448.0
Loss at iteration 900 : 4332995215360.0
Loss at iteration 910 : 8234941808640.0
Loss at iteration 920 : 1417846325248.0
Loss at iteration 930 : 2493583720448.0
Loss at iteration 940 : 555294392320.0
Loss at iteration 950 : 141805240320.0
Loss at iteration 960 : 284952526848.0
Loss at iteration 970 : 27753795584.0
Loss at iteration 980 : 1442520236032.0
Loss at iteration 990 : 32360328331264.0
Loss at iteration 1000 : 302475837440.0
Loss at iteration 1010 : 4358380191744.0
Loss at iteration 1020 : 2163211370496.0
Loss at iteration 1030 : 4094471438336.0
Loss at iteration 1040 : 351442829312.0
Loss at iteration 1050 : 7040706543616.0
Loss at iteration 1060 : 1200201269248.0
Loss at iteration 1070 : 2089880125440.0
Loss at iteration 1080 : 215011475456.0
Loss at iteration 1090 : 16762311680.0
Loss at iteration 1100 : 1415929528320.0
Loss at iteration 1110 : 306595627008.0
Loss at iteration 1120 : 269839122432.0
Loss at iteration 1130 : 1785726369792.0
Loss at iteration 1140 : 77965492224.0
Loss at iteration 1150 : 22318629781504.0
Loss at iteration 1160 : 17504430080.0
Loss at iteration 1170 : 519432732672.0
Loss at iteration 1180 : 117862056329216.0
Loss at iteration 1190 : 991282135040.0
Loss at iteration 1200 : 3393981775872.0
Loss at iteration 1210 : 1399571349504.0
Loss at iteration 1220 : 10626207318016.0
Loss at iteration 1230 : 463150055424.0
Loss at iteration 1240 : 28603030962176.0
Loss at iteration 1250 : 6097729486848.0
Loss at iteration 1260 : 4732230303744.0
Loss at iteration 1270 : 426521592332288.0
Loss at iteration 1280 : 11420155510784.0
Loss at iteration 1290 : 150587056324608.0
Loss at iteration 1300 : 6352168550400.0
Loss at iteration 1310 : 561829773312.0
Loss at iteration 1320 : 11433617129472.0
Loss at iteration 1330 : 6715623342080.0
Loss at iteration 1340 : 4095669960704.0
Loss at iteration 1350 : 3798902243328.0
Loss at iteration 1360 : 2166789636096.0
Loss at iteration 1370 : 2078526537728.0
Loss at iteration 1380 : 540136701952.0
Loss at iteration 1390 : 31381574909952.0
Loss at iteration 1400 : 5658727415808.0
Loss at iteration 1410 : 4493109886976.0
Loss at iteration 1420 : 5473408909312.0
Loss at iteration 1430 : 74688709525504.0
Loss at iteration 1440 : 1434360479744.0
Loss at iteration 1450 : 2018582724608.0
Loss at iteration 1460 : 377700941824.0
Loss at iteration 1470 : 5207013982208.0
Loss at iteration 1480 : 13440767754240.0
Loss at iteration 1490 : 18084412784640.0
Loss at iteration 1500 : 7229815128064.0
Loss at iteration 1510 : 2545510776832.0
Loss at iteration 1520 : 4001448067072.0
Loss at iteration 1530 : 11955280543744.0
Loss at iteration 1540 : 2026555441152.0
Loss at iteration 1550 : 11515194245120.0
Loss at iteration 1560 : 359369015296.0
Loss at iteration 1570 : 19414103621632.0
Loss at iteration 1580 : 11704748474368.0
Loss at iteration 1590 : 3265569488896.0
Loss at iteration 1600 : 917451990630400.0
Loss at iteration 1610 : 5750968025088.0
Loss at iteration 1620 : 25545614032896.0
Loss at iteration 1630 : 1391457730560.0
Loss at iteration 1640 : 36232272805888.0
Loss at iteration 1650 : 9389325942784.0
Loss at iteration 1660 : 2271852101632.0
Loss at iteration 1670 : 9717035302912.0
Loss at iteration 1680 : 3448909594624.0
Loss at iteration 1690 : 1415960723456.0
Loss at iteration 1700 : 604930441216.0
Loss at iteration 1710 : 980950253568.0
Loss at iteration 1720 : 4171783733248.0
Loss at iteration 1730 : 3202311258112.0
Loss at iteration 1740 : 2616557568000.0
Loss at iteration 1750 : 2535838973952.0
Loss at iteration 1760 : 1267567820800.0
Loss at iteration 1770 : 10774449750016.0
Loss at iteration 1780 : 2947872194560.0
Loss at iteration 1790 : 7854730772480.0
Loss at iteration 1800 : 13047820189696.0
Loss at iteration 1810 : 3890081169408.0
Loss at iteration 1820 : 1078456221696.0
Loss at iteration 1830 : 2047113035776.0
Loss at iteration 1840 : 828151037952.0
Loss at iteration 1850 : 489532118007808.0
Loss at iteration 1860 : 2042088259584.0
Loss at iteration 1870 : 4099749183488.0
Loss at iteration 1880 : 2528135348224.0
Loss at iteration 1890 : 993155743744.0
Loss at iteration 1900 : 4030984617984.0
Loss at iteration 1910 : 1018577944576.0
Loss at iteration 1920 : 10775050584064.0
Loss at iteration 1930 : 3067310768128.0
Loss at iteration 1940 : 40614229966848.0
Loss at iteration 1950 : 72460738560.0
Loss at iteration 1960 : 5620415070208.0
Loss at iteration 1970 : 1610545758208.0
Loss at iteration 1980 : 944998842368.0
Loss at iteration 1990 : 258195030016.0
Loss at iteration 2000 : 96918585344.0
Loss at iteration 2010 : 569657458688.0
Loss at iteration 2020 : 14578226298880.0
Loss at iteration 2030 : 727174348800.0
Loss at iteration 2040 : 608620052480.0
Loss at iteration 2050 : 4447751634944.0
Loss at iteration 2060 : 901256511488.0
Loss at iteration 2070 : 7787422679040.0
Loss at iteration 2080 : 11973933662208.0
Loss at iteration 2090 : 1794021654528.0
Loss at iteration 2100 : 1787500429312.0
Loss at iteration 2110 : 1016762925056.0
Loss at iteration 2120 : 3102764433408.0
Loss at iteration 2130 : 24330847125504.0
Loss at iteration 2140 : 640220921856.0
Loss at iteration 2150 : 1401794854912.0
Loss at iteration 2160 : 450866118656.0
Loss at iteration 2170 : 958122229760.0
Loss at iteration 2180 : 3075240099840.0
Loss at iteration 2190 : 2929013555200.0
Loss at iteration 2200 : 4692554809344.0
Loss at iteration 2210 : 7411119685632.0
Loss at iteration 2220 : 7945469820928.0
Loss at iteration 2230 : 62036705280.0
Loss at iteration 2240 : 63679643648.0
Loss at iteration 2250 : 70149906432.0
Loss at iteration 2260 : 5231392325632.0
Loss at iteration 2270 : 2217540845568.0
Loss at iteration 2280 : 726569189376.0
Loss at iteration 2290 : 163077701632.0
Loss at iteration 2300 : 392185413632.0
Loss at iteration 2310 : 9136427237376.0
Loss at iteration 2320 : 3049844375552.0
Loss at iteration 2330 : 411303280640.0
Loss at iteration 2340 : 1945481641984.0
Loss at iteration 2350 : 46587069857792.0
Loss at iteration 2360 : 1001613164544.0
Loss at iteration 2370 : 770209742848.0
Loss at iteration 2380 : 45167990013952.0
Loss at iteration 2390 : 185352987869184.0
Loss at iteration 2400 : 13723399880704.0
Loss at iteration 2410 : 14754210906112.0
Loss at iteration 2420 : 3492972068864.0
The SSIM Value is: 1.361988292813976e-06
The PSNR Value is: -135.72295837402345
the epoch is: 169
Loss at iteration 10 : 3285417721856.0
Loss at iteration 20 : 11279390474240.0
Loss at iteration 30 : 7498321887232.0
Loss at iteration 40 : 20908003557376.0
Loss at iteration 50 : 516517199872.0
Loss at iteration 60 : 2987079237632.0
Loss at iteration 70 : 1728667451392.0
Loss at iteration 80 : 46365732241408.0
Loss at iteration 90 : 1336022794240.0
Loss at iteration 100 : 290670018560.0
Loss at iteration 110 : 1106188042240.0
Loss at iteration 120 : 21308066758656.0
Loss at iteration 130 : 46993674076160.0
Loss at iteration 140 : 23791616917504.0
Loss at iteration 150 : 1128349958144.0
Loss at iteration 160 : 14941328244736.0
Loss at iteration 170 : 4085101625344.0
Loss at iteration 180 : 442799259648.0
Loss at iteration 190 : 12281196838912.0
Loss at iteration 200 : 12060713811968.0
Loss at iteration 210 : 1567172067328.0
Loss at iteration 220 : 78787794436096.0
Loss at iteration 230 : 12384390348800.0
Loss at iteration 240 : 7052420186112.0
Loss at iteration 250 : 89853517627392.0
Loss at iteration 260 : 11623779532800.0
Loss at iteration 270 : 1643457937408.0
Loss at iteration 280 : 74976623329280.0
Loss at iteration 290 : 4125755179008.0
Loss at iteration 300 : 4065705852928.0
Loss at iteration 310 : 108757489025024.0
Loss at iteration 320 : 76990249959424.0
Loss at iteration 330 : 13423291138048.0
Loss at iteration 340 : 52454414614528.0
Loss at iteration 350 : 16752085827584.0
Loss at iteration 360 : 4713954672640.0
Loss at iteration 370 : 4637630922752.0
Loss at iteration 380 : 5762076639232.0
Loss at iteration 390 : 5157725143040.0
Loss at iteration 400 : 6070326525952.0
Loss at iteration 410 : 3331577348096.0
Loss at iteration 420 : 16530323537920.0
Loss at iteration 430 : 1752988647424.0
Loss at iteration 440 : 40956657139712.0
Loss at iteration 450 : 40337795973120.0
Loss at iteration 460 : 12393129181184.0
Loss at iteration 470 : 7070151081984.0
Loss at iteration 480 : 46537824534528.0
Loss at iteration 490 : 3299338616832.0
Loss at iteration 500 : 13342224678912.0
Loss at iteration 510 : 413956833280000.0
Loss at iteration 520 : 14581049065472.0
Loss at iteration 530 : 170678460350464.0
Loss at iteration 540 : 2781250846720.0
Loss at iteration 550 : 18040141905920.0
Loss at iteration 560 : 72064903938048.0
Loss at iteration 570 : 283082703765504.0
Loss at iteration 580 : 70011469168640.0
Loss at iteration 590 : 135287007084544.0
Loss at iteration 600 : 48438599221248.0
Loss at iteration 610 : 26501470748672.0
Loss at iteration 620 : 27154842648576.0
Loss at iteration 630 : 159617543831552.0
Loss at iteration 640 : 981397078016.0
Loss at iteration 650 : 9604311285760.0
Loss at iteration 660 : 53796419928064.0
Loss at iteration 670 : 34271783813120.0
Loss at iteration 680 : 6154008657920.0
Loss at iteration 690 : 9161094987776.0
Loss at iteration 700 : 5618485690368.0
Loss at iteration 710 : 8780871892992.0
Loss at iteration 720 : 43921853906944.0
Loss at iteration 730 : 16450150465536.0
Loss at iteration 740 : 9044222803968.0
Loss at iteration 750 : 39921851039744.0
Loss at iteration 760 : 7746842263552.0
Loss at iteration 770 : 5824784105472.0
Loss at iteration 780 : 1806054981632.0
Loss at iteration 790 : 10581820047360.0
Loss at iteration 800 : 8711327711232.0
Loss at iteration 810 : 3979990794240.0
Loss at iteration 820 : 30223122825216.0
Loss at iteration 830 : 7461612814336.0
Loss at iteration 840 : 33007662530560.0
Loss at iteration 850 : 162289008640.0
Loss at iteration 860 : 19523564470272.0
Loss at iteration 870 : 2507991123230720.0
Loss at iteration 880 : 2599975900938240.0
Loss at iteration 890 : 282611431768064.0
Loss at iteration 900 : 1004796190392320.0
Loss at iteration 910 : 253987337011200.0
Loss at iteration 920 : 18545740087296.0
Loss at iteration 930 : 37982207737856.0
Loss at iteration 940 : 4757441740800.0
Loss at iteration 950 : 6673743522824192.0
Loss at iteration 960 : 340569532399616.0
Loss at iteration 970 : 332658806620160.0
Loss at iteration 980 : 726563578445824.0
Loss at iteration 990 : 5254424335220736.0
Loss at iteration 1000 : 326267526184960.0
Loss at iteration 1010 : 156585347252224.0
Loss at iteration 1020 : 3235610624000.0
Loss at iteration 1030 : 319457855537152.0
Loss at iteration 1040 : 6943677087744.0
Loss at iteration 1050 : 5905539137536.0
Loss at iteration 1060 : 1642461003776.0
Loss at iteration 1070 : 3223426957312.0
Loss at iteration 1080 : 12317838278656.0
Loss at iteration 1090 : 11807689277440.0
Loss at iteration 1100 : 14198994108416.0
Loss at iteration 1110 : 776865316864.0
Loss at iteration 1120 : 4720026976256.0
Loss at iteration 1130 : 41531293564928.0
Loss at iteration 1140 : 245222621184.0
Loss at iteration 1150 : 262658539520.0
Loss at iteration 1160 : 1760426196992.0
Loss at iteration 1170 : 8649120415744.0
Loss at iteration 1180 : 24805201936384.0
Loss at iteration 1190 : 418112077824.0
Loss at iteration 1200 : 34275699195904.0
Loss at iteration 1210 : 981149286400.0
Loss at iteration 1220 : 1626941947904.0
Loss at iteration 1230 : 30976136708096.0
Loss at iteration 1240 : 49409249247232.0
Loss at iteration 1250 : 338121333932032.0
Loss at iteration 1260 : 12320187088896.0
Loss at iteration 1270 : 193357884162048.0
Loss at iteration 1280 : 365349614649344.0
Loss at iteration 1290 : 8082491441152.0
Loss at iteration 1300 : 3477143027712.0
Loss at iteration 1310 : 5933646741504.0
Loss at iteration 1320 : 18609646600192.0
Loss at iteration 1330 : 1018286571520.0
Loss at iteration 1340 : 7969318633472.0
Loss at iteration 1350 : 115656351744.0
Loss at iteration 1360 : 295573844393984.0
Loss at iteration 1370 : 5313917878272.0
Loss at iteration 1380 : 8185908822016.0
Loss at iteration 1390 : 371414108471296.0
Loss at iteration 1400 : 429453803520.0
Loss at iteration 1410 : 1619257589760.0
Loss at iteration 1420 : 21489038393344.0
Loss at iteration 1430 : 5148420603904.0
Loss at iteration 1440 : 2621983948800.0
Loss at iteration 1450 : 146698436608.0
Loss at iteration 1460 : 502053535744.0
Loss at iteration 1470 : 2870338387968.0
Loss at iteration 1480 : 1038263123968.0
Loss at iteration 1490 : 2412654100480.0
Loss at iteration 1500 : 6041917456384.0
Loss at iteration 1510 : 2042783465472.0
Loss at iteration 1520 : 383134007296.0
Loss at iteration 1530 : 53641752576.0
Loss at iteration 1540 : 713515073536.0
Loss at iteration 1550 : 77198786560.0
Loss at iteration 1560 : 94622638080.0
Loss at iteration 1570 : 243982024704.0
Loss at iteration 1580 : 507631337472.0
Loss at iteration 1590 : 43679582519296.0
Loss at iteration 1600 : 17558917873664.0
Loss at iteration 1610 : 71353704448.0
Loss at iteration 1620 : 1153287192576.0
Loss at iteration 1630 : 298436132864.0
Loss at iteration 1640 : 490555965440.0
Loss at iteration 1650 : 4293685936128.0
Loss at iteration 1660 : 581463179264.0
Loss at iteration 1670 : 242477105152.0
Loss at iteration 1680 : 543703334912.0
Loss at iteration 1690 : 10784717406208.0
Loss at iteration 1700 : 275697532928.0
Loss at iteration 1710 : 347087241216.0
Loss at iteration 1720 : 423792181248.0
Loss at iteration 1730 : 3677463773184.0
Loss at iteration 1740 : 397351550976.0
Loss at iteration 1750 : 1096379334656.0
Loss at iteration 1760 : 8519485489152.0
Loss at iteration 1770 : 2393767411712.0
Loss at iteration 1780 : 1721060370153472.0
Loss at iteration 1790 : 2669231980150784.0
Loss at iteration 1800 : 84680372125696.0
Loss at iteration 1810 : 225975862296576.0
Loss at iteration 1820 : 569482464460800.0
Loss at iteration 1830 : 495256772542464.0
Loss at iteration 1840 : 323236587896832.0
Loss at iteration 1850 : 4199410827264.0
Loss at iteration 1860 : 11818311352320.0
Loss at iteration 1870 : 208871238926336.0
Loss at iteration 1880 : 61824040960000.0
Loss at iteration 1890 : 134366399299584.0
Loss at iteration 1900 : 581866532896768.0
Loss at iteration 1910 : 6584510447616.0
Loss at iteration 1920 : 130690704211968.0
Loss at iteration 1930 : 16382263558144.0
Loss at iteration 1940 : 11087513649152.0
Loss at iteration 1950 : 252517971656704.0
Loss at iteration 1960 : 48012940279808.0
Loss at iteration 1970 : 97272385765376.0
Loss at iteration 1980 : 8229975228416.0
Loss at iteration 1990 : 23878508216320.0
Loss at iteration 2000 : 4770199240704.0
Loss at iteration 2010 : 25710647312384.0
Loss at iteration 2020 : 43389013721088.0
Loss at iteration 2030 : 27063436181504.0
Loss at iteration 2040 : 435080388411392.0
Loss at iteration 2050 : 265658273103872.0
Loss at iteration 2060 : 8230013501440.0
Loss at iteration 2070 : 2978572140544.0
Loss at iteration 2080 : 625882901250048.0
Loss at iteration 2090 : 2145319387136000.0
Loss at iteration 2100 : 191355238219776.0
Loss at iteration 2110 : 893552951296.0
Loss at iteration 2120 : 27053843808256.0
Loss at iteration 2130 : 10050845278208.0
Loss at iteration 2140 : 17189828558848.0
Loss at iteration 2150 : 11819360976896.0
Loss at iteration 2160 : 7256490377216.0
Loss at iteration 2170 : 4789119221760.0
Loss at iteration 2180 : 435270776258560.0
Loss at iteration 2190 : 161859114106880.0
Loss at iteration 2200 : 92070609944576.0
Loss at iteration 2210 : 16464403759104.0
Loss at iteration 2220 : 649127133184.0
Loss at iteration 2230 : 40765996662784.0
Loss at iteration 2240 : 204595625984.0
Loss at iteration 2250 : 26291979943936.0
Loss at iteration 2260 : 68019023773696.0
Loss at iteration 2270 : 43694661042176.0
Loss at iteration 2280 : 5387300959682560.0
Loss at iteration 2290 : 158166096543744.0
Loss at iteration 2300 : 63550487789568.0
Loss at iteration 2310 : 1185316208640.0
Loss at iteration 2320 : 830110206787584.0
Loss at iteration 2330 : 147175761772544.0
Loss at iteration 2340 : 3973642190848.0
Loss at iteration 2350 : 17005193199616.0
Loss at iteration 2360 : 40170267082752.0
Loss at iteration 2370 : 15082696212480.0
Loss at iteration 2380 : 56268899221504.0
Loss at iteration 2390 : 127827957514240.0
Loss at iteration 2400 : 215948657164288.0
Loss at iteration 2410 : 4526925938688.0
Loss at iteration 2420 : 311335199965184.0
The SSIM Value is: -1.2817207807103158e-06
The PSNR Value is: -142.3984858194987
the epoch is: 170
Loss at iteration 10 : 14154522951680.0
Loss at iteration 20 : 6014364024832.0
Loss at iteration 30 : 384300755189760.0
Loss at iteration 40 : 114488065916928.0
Loss at iteration 50 : 519585044365312.0
Loss at iteration 60 : 193290523639808.0
Loss at iteration 70 : 63832944803840.0
Loss at iteration 80 : 895757372620800.0
Loss at iteration 90 : 113790980980736.0
Loss at iteration 100 : 44479750864896.0
Loss at iteration 110 : 41142812934144.0
Loss at iteration 120 : 43668761214976.0
Loss at iteration 130 : 5052551397376.0
Loss at iteration 140 : 6404249747456.0
Loss at iteration 150 : 76352589922304.0
Loss at iteration 160 : 90255684272128.0
Loss at iteration 170 : 4198551257088.0
Loss at iteration 180 : 3419540815872.0
Loss at iteration 190 : 1239306469376.0
Loss at iteration 200 : 23790379597824.0
Loss at iteration 210 : 151867627667456.0
Loss at iteration 220 : 4884976893952.0
Loss at iteration 230 : 115667009536.0
Loss at iteration 240 : 12610577629184.0
Loss at iteration 250 : 4326385516544.0
Loss at iteration 260 : 12315447525376.0
Loss at iteration 270 : 1318200759287808.0
Loss at iteration 280 : 9.983385191579648e+16
Loss at iteration 290 : 549287293353984.0
Loss at iteration 300 : 2621332357382144.0
Loss at iteration 310 : 584950319415296.0
Loss at iteration 320 : 2987181966622720.0
Loss at iteration 330 : 1.8598030877917184e+16
Loss at iteration 340 : 87800732975104.0
Loss at iteration 350 : 5304538013630464.0
Loss at iteration 360 : 1871040091258880.0
Loss at iteration 370 : 64264924561408.0
Loss at iteration 380 : 105946021888000.0
Loss at iteration 390 : 187611134033920.0
Loss at iteration 400 : 205215835881472.0
Loss at iteration 410 : 462294844702720.0
Loss at iteration 420 : 163130357317632.0
Loss at iteration 430 : 969470889689088.0
Loss at iteration 440 : 133572971200512.0
Loss at iteration 450 : 706525811179520.0
Loss at iteration 460 : 1165393339088896.0
Loss at iteration 470 : 67962610384896.0
Loss at iteration 480 : 1.969387331513221e+17
Loss at iteration 490 : 41295821144064.0
Loss at iteration 500 : 9465175736320.0
Loss at iteration 510 : 8875839324160.0
Loss at iteration 520 : 6576267591680.0
Loss at iteration 530 : 120819116146688.0
Loss at iteration 540 : 11538658230272.0
Loss at iteration 550 : 14367237079040.0
Loss at iteration 560 : 105802132094976.0
Loss at iteration 570 : 18854017236992.0
Loss at iteration 580 : 1777758765056.0
Loss at iteration 590 : 45011127238656.0
Loss at iteration 600 : 12033207566336.0
Loss at iteration 610 : 100954363920384.0
Loss at iteration 620 : 1908905345024.0
Loss at iteration 630 : 9834321674240.0
Loss at iteration 640 : 611838853120.0
Loss at iteration 650 : 52953658425344.0
Loss at iteration 660 : 3493505531904.0
Loss at iteration 670 : 3023284994048.0
Loss at iteration 680 : 27616994131968.0
Loss at iteration 690 : 52296620703744.0
Loss at iteration 700 : 123204383277056.0
Loss at iteration 710 : 3084278824960.0
Loss at iteration 720 : 5901409320960.0
Loss at iteration 730 : 48586393911296.0
Loss at iteration 740 : 2590840717312.0
Loss at iteration 750 : 9147791704064.0
Loss at iteration 760 : 974432436224.0
Loss at iteration 770 : 23399101366272.0
Loss at iteration 780 : 3671598825472.0
Loss at iteration 790 : 98940015869952.0
Loss at iteration 800 : 1556411842560.0
Loss at iteration 810 : 17300521484288.0
Loss at iteration 820 : 9252037984256.0
Loss at iteration 830 : 36354461270016.0
Loss at iteration 840 : 29014274080768.0
Loss at iteration 850 : 625783144448.0
Loss at iteration 860 : 364042125312.0
Loss at iteration 870 : 16750832779264.0
Loss at iteration 880 : 19144495857664.0
Loss at iteration 890 : 77965719240704.0
Loss at iteration 900 : 12562948161536.0
Loss at iteration 910 : 5604306845696.0
Loss at iteration 920 : 6625037385728.0
Loss at iteration 930 : 448968130560.0
Loss at iteration 940 : 8752024518656.0
Loss at iteration 950 : 21414765658112.0
Loss at iteration 960 : 93206041591808.0
Loss at iteration 970 : 1442880684032.0
Loss at iteration 980 : 1726847254528.0
Loss at iteration 990 : 137181062496256.0
Loss at iteration 1000 : 378707247104.0
Loss at iteration 1010 : 11570891456512.0
Loss at iteration 1020 : 1263562129408.0
Loss at iteration 1030 : 77777571151872.0
Loss at iteration 1040 : 3762673156096.0
Loss at iteration 1050 : 2881242005504.0
Loss at iteration 1060 : 742541492224.0
Loss at iteration 1070 : 2718392909824.0
Loss at iteration 1080 : 1160644526080.0
Loss at iteration 1090 : 7336960720896.0
Loss at iteration 1100 : 58977169702912.0
Loss at iteration 1110 : 9924147937280.0
Loss at iteration 1120 : 26404278239232.0
Loss at iteration 1130 : 56715433213952.0
Loss at iteration 1140 : 1243828453376.0
Loss at iteration 1150 : 2937613975552.0
Loss at iteration 1160 : 14492484239360.0
Loss at iteration 1170 : 6847226970112.0
Loss at iteration 1180 : 5014859284480.0
Loss at iteration 1190 : 6208287670272.0
Loss at iteration 1200 : 191891177472.0
Loss at iteration 1210 : 6472409284608.0
Loss at iteration 1220 : 3785937911808.0
Loss at iteration 1230 : 35822329921536.0
Loss at iteration 1240 : 3253707997184.0
Loss at iteration 1250 : 568617467904.0
Loss at iteration 1260 : 65619609255936.0
Loss at iteration 1270 : 20419847389184.0
Loss at iteration 1280 : 9754935033856.0
Loss at iteration 1290 : 31703861035008.0
Loss at iteration 1300 : 108037679349760.0
Loss at iteration 1310 : 54343935983616.0
Loss at iteration 1320 : 843203936256.0
Loss at iteration 1330 : 2564454875136.0
Loss at iteration 1340 : 784166874513408.0
Loss at iteration 1350 : 100170515611648.0
Loss at iteration 1360 : 16328184299520.0
Loss at iteration 1370 : 23636666744832.0
Loss at iteration 1380 : 8336613834752.0
Loss at iteration 1390 : 25301669117952.0
Loss at iteration 1400 : 3651590684672.0
Loss at iteration 1410 : 766356029440.0
Loss at iteration 1420 : 8974748352512.0
Loss at iteration 1430 : 47051349950464.0
Loss at iteration 1440 : 256056856936448.0
Loss at iteration 1450 : 2023412377583616.0
Loss at iteration 1460 : 14540740755456.0
Loss at iteration 1470 : 4984045830144.0
Loss at iteration 1480 : 22750234148864.0
Loss at iteration 1490 : 34345756655616.0
Loss at iteration 1500 : 36369795645440.0
Loss at iteration 1510 : 37799340277760.0
Loss at iteration 1520 : 97982296883200.0
Loss at iteration 1530 : 469702377472.0
Loss at iteration 1540 : 9818058260480.0
Loss at iteration 1550 : 2044724641792.0
Loss at iteration 1560 : 12198747308032.0
Loss at iteration 1570 : 217398812606464.0
Loss at iteration 1580 : 92889858179072.0
Loss at iteration 1590 : 3524863721472.0
Loss at iteration 1600 : 133671889666048.0
Loss at iteration 1610 : 4232596160512.0
Loss at iteration 1620 : 14732283084800.0
Loss at iteration 1630 : 44461283344384.0
Loss at iteration 1640 : 5527226023936.0
Loss at iteration 1650 : 9613595377664.0
Loss at iteration 1660 : 1126641958912.0
Loss at iteration 1670 : 1985721663488.0
Loss at iteration 1680 : 6657745092608.0
Loss at iteration 1690 : 14684954558464.0
Loss at iteration 1700 : 3362805776384.0
Loss at iteration 1710 : 396200280064.0
Loss at iteration 1720 : 1684831076352.0
Loss at iteration 1730 : 45713608704.0
Loss at iteration 1740 : 700476293120.0
Loss at iteration 1750 : 9079580786688.0
Loss at iteration 1760 : 86273318453248.0
Loss at iteration 1770 : 27602033049600.0
Loss at iteration 1780 : 3257461374976.0
Loss at iteration 1790 : 74557830463488.0
Loss at iteration 1800 : 9497080758272.0
Loss at iteration 1810 : 23971940532224.0
Loss at iteration 1820 : 586228474839040.0
Loss at iteration 1830 : 1595308828000256.0
Loss at iteration 1840 : 7093051457536.0
Loss at iteration 1850 : 31272074215424.0
Loss at iteration 1860 : 15113804316672.0
Loss at iteration 1870 : 5608236908544.0
Loss at iteration 1880 : 9336129585152.0
Loss at iteration 1890 : 77084361752576.0
Loss at iteration 1900 : 9385366519808.0
Loss at iteration 1910 : 869557272576.0
Loss at iteration 1920 : 59874935308288.0
Loss at iteration 1930 : 1275749859328.0
Loss at iteration 1940 : 308501741568.0
Loss at iteration 1950 : 2414558576640.0
Loss at iteration 1960 : 9486928445440.0
Loss at iteration 1970 : 19248489431040.0
Loss at iteration 1980 : 5397441150976.0
Loss at iteration 1990 : 71469086277632.0
Loss at iteration 2000 : 2631549583360.0
Loss at iteration 2010 : 6973207085056.0
Loss at iteration 2020 : 76040307212288.0
Loss at iteration 2030 : 1823495340163072.0
Loss at iteration 2040 : 4503167303680.0
Loss at iteration 2050 : 609658863616.0
Loss at iteration 2060 : 4853352366080.0
Loss at iteration 2070 : 9403974549504.0
Loss at iteration 2080 : 2591239700480.0
Loss at iteration 2090 : 2225221402624.0
Loss at iteration 2100 : 3120710025216.0
Loss at iteration 2110 : 323633301946368.0
Loss at iteration 2120 : 2178383872000.0
Loss at iteration 2130 : 73709415038976.0
Loss at iteration 2140 : 6480267313152.0
Loss at iteration 2150 : 7392660553728.0
Loss at iteration 2160 : 5864346877952.0
Loss at iteration 2170 : 5530750287872.0
Loss at iteration 2180 : 8211581108224.0
Loss at iteration 2190 : 1176718934016.0
Loss at iteration 2200 : 18953155903488.0
Loss at iteration 2210 : 8681783033856.0
Loss at iteration 2220 : 31273191997440.0
Loss at iteration 2230 : 2307053846528.0
Loss at iteration 2240 : 62068359168000.0
Loss at iteration 2250 : 10967351033856.0
Loss at iteration 2260 : 953725681664.0
Loss at iteration 2270 : 3413259321344.0
Loss at iteration 2280 : 2472104689664.0
Loss at iteration 2290 : 1979607154688.0
Loss at iteration 2300 : 83840605356032.0
Loss at iteration 2310 : 12552908046336.0
Loss at iteration 2320 : 6469759008768.0
Loss at iteration 2330 : 7406641741824.0
Loss at iteration 2340 : 22174750474240.0
Loss at iteration 2350 : 936709586944.0
Loss at iteration 2360 : 19218007326720.0
Loss at iteration 2370 : 13065835773952.0
Loss at iteration 2380 : 53175092510720.0
Loss at iteration 2390 : 817714167808.0
Loss at iteration 2400 : 3605770272768.0
Loss at iteration 2410 : 930992291840.0
Loss at iteration 2420 : 2437796593664.0
The SSIM Value is: 7.868900543902177e-06
The PSNR Value is: -136.14653625488282
the epoch is: 171
Loss at iteration 10 : 26315581292544.0
Loss at iteration 20 : 223361597440.0
Loss at iteration 30 : 36282919026688.0
Loss at iteration 40 : 13607287914496.0
Loss at iteration 50 : 7723659296768.0
Loss at iteration 60 : 816203035574272.0
Loss at iteration 70 : 3132803776512.0
Loss at iteration 80 : 3944668463104.0
Loss at iteration 90 : 1707527634944.0
Loss at iteration 100 : 217718687006720.0
Loss at iteration 110 : 15400056127488.0
Loss at iteration 120 : 3675282735104.0
Loss at iteration 130 : 1983109922816.0
Loss at iteration 140 : 1639022592000.0
Loss at iteration 150 : 271089926144.0
Loss at iteration 160 : 649810804736.0
Loss at iteration 170 : 4939210817536.0
Loss at iteration 180 : 1919109038080.0
Loss at iteration 190 : 37156911316992.0
Loss at iteration 200 : 5797281005568.0
Loss at iteration 210 : 774237044342784.0
Loss at iteration 220 : 10213993218048.0
Loss at iteration 230 : 210641805639680.0
Loss at iteration 240 : 33701211668480.0
Loss at iteration 250 : 628071661568.0
Loss at iteration 260 : 1197804355584.0
Loss at iteration 270 : 3600796090368.0
Loss at iteration 280 : 4702568710144.0
Loss at iteration 290 : 78419341606912.0
Loss at iteration 300 : 15961758367744.0
Loss at iteration 310 : 5004113477632.0
Loss at iteration 320 : 601349095424.0
Loss at iteration 330 : 692712046592.0
Loss at iteration 340 : 741439438848.0
Loss at iteration 350 : 17757735223296.0
Loss at iteration 360 : 140297581363200.0
Loss at iteration 370 : 1696296730624.0
Loss at iteration 380 : 32297518628864.0
Loss at iteration 390 : 92568658378752.0
Loss at iteration 400 : 359495708442624.0
Loss at iteration 410 : 3402769891328.0
Loss at iteration 420 : 13503322652672.0
Loss at iteration 430 : 27877024202752.0
Loss at iteration 440 : 3032463179776.0
Loss at iteration 450 : 8194801795072.0
Loss at iteration 460 : 72602890534912.0
Loss at iteration 470 : 4249003753472.0
Loss at iteration 480 : 34827545870336.0
Loss at iteration 490 : 119702307209216.0
Loss at iteration 500 : 9947331952640.0
Loss at iteration 510 : 395823415296.0
Loss at iteration 520 : 23879122681856.0
Loss at iteration 530 : 45677606338560.0
Loss at iteration 540 : 5024157007872.0
Loss at iteration 550 : 3847364018176.0
Loss at iteration 560 : 23528761982976.0
Loss at iteration 570 : 5374753636352.0
Loss at iteration 580 : 6833786322944.0
Loss at iteration 590 : 7930114998272.0
Loss at iteration 600 : 953936969728.0
Loss at iteration 610 : 3081731047424.0
Loss at iteration 620 : 6010707640320.0
Loss at iteration 630 : 1769210380288.0
Loss at iteration 640 : 5747254493184.0
Loss at iteration 650 : 18767281127424.0
Loss at iteration 660 : 785133928448.0
Loss at iteration 670 : 802589442048.0
Loss at iteration 680 : 442412870664192.0
Loss at iteration 690 : 1727837896704.0
Loss at iteration 700 : 644413259776.0
Loss at iteration 710 : 34932374110208.0
Loss at iteration 720 : 40161626816512.0
Loss at iteration 730 : 472133271552.0
Loss at iteration 740 : 12915616776192.0
Loss at iteration 750 : 377639665664.0
Loss at iteration 760 : 20573939826688.0
Loss at iteration 770 : 1481708797952.0
Loss at iteration 780 : 1378810331136.0
Loss at iteration 790 : 9164210307072.0
Loss at iteration 800 : 1339518091264.0
Loss at iteration 810 : 2712898633728.0
Loss at iteration 820 : 402404704256.0
Loss at iteration 830 : 2387878084608.0
Loss at iteration 840 : 6334270930944.0
Loss at iteration 850 : 8489432252416.0
Loss at iteration 860 : 1195914428416.0
Loss at iteration 870 : 21844641972224.0
Loss at iteration 880 : 1212268544000.0
Loss at iteration 890 : 155000619008.0
Loss at iteration 900 : 2808761024512.0
Loss at iteration 910 : 38088048640.0
Loss at iteration 920 : 21076086095872.0
Loss at iteration 930 : 377237143552.0
Loss at iteration 940 : 3284061126656.0
Loss at iteration 950 : 4315178074112.0
Loss at iteration 960 : 126172594176.0
Loss at iteration 970 : 505757401088.0
Loss at iteration 980 : 688969809920.0
Loss at iteration 990 : 792209981440.0
Loss at iteration 1000 : 329816604672.0
Loss at iteration 1010 : 2105053937664.0
Loss at iteration 1020 : 219466579968.0
Loss at iteration 1030 : 859794112512.0
Loss at iteration 1040 : 1524842758144.0
Loss at iteration 1050 : 1302244098048.0
Loss at iteration 1060 : 1244046163968.0
Loss at iteration 1070 : 3367372849152.0
Loss at iteration 1080 : 4378199064576.0
Loss at iteration 1090 : 7394305245184.0
Loss at iteration 1100 : 396309757952.0
Loss at iteration 1110 : 2587102019584.0
Loss at iteration 1120 : 216213979136.0
Loss at iteration 1130 : 2689236467712.0
Loss at iteration 1140 : 187784331264.0
Loss at iteration 1150 : 514217508864.0
Loss at iteration 1160 : 1995260559360.0
Loss at iteration 1170 : 175748956160.0
Loss at iteration 1180 : 5459144605696.0
Loss at iteration 1190 : 63377367891968.0
Loss at iteration 1200 : 699100233728.0
Loss at iteration 1210 : 1183345410048.0
Loss at iteration 1220 : 35178283008.0
Loss at iteration 1230 : 751611215872.0
Loss at iteration 1240 : 12287628804096.0
Loss at iteration 1250 : 40583510884352.0
Loss at iteration 1260 : 2538606166016.0
Loss at iteration 1270 : 1497617793024.0
Loss at iteration 1280 : 1080985059328.0
Loss at iteration 1290 : 247431217152.0
Loss at iteration 1300 : 5991983218688.0
Loss at iteration 1310 : 1503640682496.0
Loss at iteration 1320 : 485271470080.0
Loss at iteration 1330 : 731036778496.0
Loss at iteration 1340 : 106880311296.0
Loss at iteration 1350 : 147351060480.0
Loss at iteration 1360 : 77403234304.0
Loss at iteration 1370 : 3869106503680.0
Loss at iteration 1380 : 1170135711744.0
Loss at iteration 1390 : 2028494127104.0
Loss at iteration 1400 : 236677414912.0
Loss at iteration 1410 : 10297768148992.0
Loss at iteration 1420 : 1106462638080.0
Loss at iteration 1430 : 1193504407552.0
Loss at iteration 1440 : 11582457249792.0
Loss at iteration 1450 : 2052623826944.0
Loss at iteration 1460 : 475495399424.0
Loss at iteration 1470 : 539187085312.0
Loss at iteration 1480 : 1632921976832.0
Loss at iteration 1490 : 14274873262080.0
Loss at iteration 1500 : 6870925836288.0
Loss at iteration 1510 : 1276151332864.0
Loss at iteration 1520 : 1586793545728.0
Loss at iteration 1530 : 2642850873344.0
Loss at iteration 1540 : 5685437792256.0
Loss at iteration 1550 : 7141048451072.0
Loss at iteration 1560 : 3470416674816.0
Loss at iteration 1570 : 22350123008.0
Loss at iteration 1580 : 205092454400.0
Loss at iteration 1590 : 14832489201664.0
Loss at iteration 1600 : 2038399762432.0
Loss at iteration 1610 : 648459059200.0
Loss at iteration 1620 : 1222160547840.0
Loss at iteration 1630 : 289015103488.0
Loss at iteration 1640 : 925579608064.0
Loss at iteration 1650 : 3946043932672.0
Loss at iteration 1660 : 2127768190976.0
Loss at iteration 1670 : 10300368617472.0
Loss at iteration 1680 : 46613305229312.0
Loss at iteration 1690 : 1700308713472.0
Loss at iteration 1700 : 61829778767872.0
Loss at iteration 1710 : 31654330499072.0
Loss at iteration 1720 : 813286490112.0
Loss at iteration 1730 : 971158650880.0
Loss at iteration 1740 : 11258543734784.0
Loss at iteration 1750 : 9166313750528.0
Loss at iteration 1760 : 431046843695104.0
Loss at iteration 1770 : 889109031682048.0
Loss at iteration 1780 : 2080493298253824.0
Loss at iteration 1790 : 26975349506048.0
Loss at iteration 1800 : 1200478224384.0
Loss at iteration 1810 : 1234888556544.0
Loss at iteration 1820 : 14776333762560.0
Loss at iteration 1830 : 625473290240.0
Loss at iteration 1840 : 1057615511552.0
Loss at iteration 1850 : 2117548769280.0
Loss at iteration 1860 : 124587572461568.0
Loss at iteration 1870 : 524955680768.0
Loss at iteration 1880 : 1981554229248.0
Loss at iteration 1890 : 416912637952.0
Loss at iteration 1900 : 3075221225472.0
Loss at iteration 1910 : 3884348080128.0
Loss at iteration 1920 : 1242183499776.0
Loss at iteration 1930 : 3930226425856.0
Loss at iteration 1940 : 752961650688.0
Loss at iteration 1950 : 3220187119616.0
Loss at iteration 1960 : 6115835248640.0
Loss at iteration 1970 : 136937734144.0
Loss at iteration 1980 : 12431453585408.0
Loss at iteration 1990 : 1572175216640.0
Loss at iteration 2000 : 3506760318976.0
Loss at iteration 2010 : 6977610055680.0
Loss at iteration 2020 : 80934808322048.0
Loss at iteration 2030 : 8313860784128.0
Loss at iteration 2040 : 209004450021376.0
Loss at iteration 2050 : 4813683163136.0
Loss at iteration 2060 : 14205905272832.0
Loss at iteration 2070 : 1856341409792.0
Loss at iteration 2080 : 3445648785408.0
Loss at iteration 2090 : 580594696192.0
Loss at iteration 2100 : 1593312149504.0
Loss at iteration 2110 : 474777976832.0
Loss at iteration 2120 : 9542385532928.0
Loss at iteration 2130 : 9268909572096.0
Loss at iteration 2140 : 1886238801920.0
Loss at iteration 2150 : 2254648115200.0
Loss at iteration 2160 : 5903255863296.0
Loss at iteration 2170 : 34153697378304.0
Loss at iteration 2180 : 7824072507392.0
Loss at iteration 2190 : 34329235292160.0
Loss at iteration 2200 : 30079782486016.0
Loss at iteration 2210 : 8.741763403900518e+16
Loss at iteration 2220 : 177594364329984.0
Loss at iteration 2230 : 58762094182400.0
Loss at iteration 2240 : 360490932895744.0
Loss at iteration 2250 : 70426910785536.0
Loss at iteration 2260 : 2988710706544640.0
Loss at iteration 2270 : 9834260856832.0
Loss at iteration 2280 : 4359875257696256.0
Loss at iteration 2290 : 228058451673088.0
Loss at iteration 2300 : 11593915039744.0
Loss at iteration 2310 : 51405696008192.0
Loss at iteration 2320 : 4514597306368.0
Loss at iteration 2330 : 6004236877824.0
Loss at iteration 2340 : 24669323264000.0
Loss at iteration 2350 : 7830034710528.0
Loss at iteration 2360 : 24040607580160.0
Loss at iteration 2370 : 116953846906880.0
Loss at iteration 2380 : 322380111020032.0
Loss at iteration 2390 : 117342868602880.0
Loss at iteration 2400 : 27910616383488.0
Loss at iteration 2410 : 68372381302784.0
Loss at iteration 2420 : 18562387279872.0
The SSIM Value is: 7.579084041253736e-06
The PSNR Value is: -146.49498901367187
the epoch is: 172
Loss at iteration 10 : 2.817823889948672e+16
Loss at iteration 20 : 91244768264192.0
Loss at iteration 30 : 15366648496128.0
Loss at iteration 40 : 550063636480.0
Loss at iteration 50 : 260180361216.0
Loss at iteration 60 : 13303324606464.0
Loss at iteration 70 : 727149445120.0
Loss at iteration 80 : 1799403077632.0
Loss at iteration 90 : 2308046323712.0
Loss at iteration 100 : 2927022309376.0
Loss at iteration 110 : 2452497629184.0
Loss at iteration 120 : 5378400059392.0
Loss at iteration 130 : 11701047001088.0
Loss at iteration 140 : 100132875927552.0
Loss at iteration 150 : 1159549157376.0
Loss at iteration 160 : 3955568511287296.0
Loss at iteration 170 : 2692566220800.0
Loss at iteration 180 : 120795695153152.0
Loss at iteration 190 : 10305854767104.0
Loss at iteration 200 : 3366530056192.0
Loss at iteration 210 : 33249267023872.0
Loss at iteration 220 : 2678311354368.0
Loss at iteration 230 : 61169935056896.0
Loss at iteration 240 : 85777207787520.0
Loss at iteration 250 : 9426963529728.0
Loss at iteration 260 : 144640959315968.0
Loss at iteration 270 : 4705388331008.0
Loss at iteration 280 : 102842916405248.0
Loss at iteration 290 : 27297587396608.0
Loss at iteration 300 : 88237393575936.0
Loss at iteration 310 : 986523172864.0
Loss at iteration 320 : 16906455089152.0
Loss at iteration 330 : 2660740104192.0
Loss at iteration 340 : 4189841260544.0
Loss at iteration 350 : 15172289691648.0
Loss at iteration 360 : 11080097071104.0
Loss at iteration 370 : 2695418085376.0
Loss at iteration 380 : 3963831975936.0
Loss at iteration 390 : 13176493047808.0
Loss at iteration 400 : 52726746578944.0
Loss at iteration 410 : 3464181579776.0
Loss at iteration 420 : 1060955572142080.0
Loss at iteration 430 : 1042692834328576.0
Loss at iteration 440 : 2.7221434002571264e+16
Loss at iteration 450 : 895109436538880.0
Loss at iteration 460 : 1799585928314880.0
Loss at iteration 470 : 65883691024384.0
Loss at iteration 480 : 122410510581760.0
Loss at iteration 490 : 60339982958592.0
Loss at iteration 500 : 137966949236736.0
Loss at iteration 510 : 597128900509696.0
Loss at iteration 520 : 7527300333568.0
Loss at iteration 530 : 254643611369472.0
Loss at iteration 540 : 4661702033408.0
Loss at iteration 550 : 25457594466304.0
Loss at iteration 560 : 28371266306048.0
Loss at iteration 570 : 1326172487024640.0
Loss at iteration 580 : 6250808475648.0
Loss at iteration 590 : 533522246795264.0
Loss at iteration 600 : 96332274466816.0
Loss at iteration 610 : 568979483525120.0
Loss at iteration 620 : 994549405057024.0
Loss at iteration 630 : 28873079128064.0
Loss at iteration 640 : 575861296201728.0
Loss at iteration 650 : 71539198263296.0
Loss at iteration 660 : 556773253578752.0
Loss at iteration 670 : 1368808895807488.0
Loss at iteration 680 : 110066388697088.0
Loss at iteration 690 : 53581906444288.0
Loss at iteration 700 : 930090871422976.0
Loss at iteration 710 : 219238736330752.0
Loss at iteration 720 : 4519828652032.0
Loss at iteration 730 : 59801803423744.0
Loss at iteration 740 : 23691897339904.0
Loss at iteration 750 : 198469482446848.0
Loss at iteration 760 : 1668061681680384.0
Loss at iteration 770 : 58839361650688.0
Loss at iteration 780 : 130576124215296.0
Loss at iteration 790 : 116119683727360.0
Loss at iteration 800 : 314006233415680.0
Loss at iteration 810 : 1035562987290624.0
Loss at iteration 820 : 200982994616320.0
Loss at iteration 830 : 81289654829056.0
Loss at iteration 840 : 102381006094336.0
Loss at iteration 850 : 115771229339648.0
Loss at iteration 860 : 198076962701312.0
Loss at iteration 870 : 24708984602624.0
Loss at iteration 880 : 97856929136640.0
Loss at iteration 890 : 76057268977664.0
Loss at iteration 900 : 791297795293184.0
Loss at iteration 910 : 5565250011136.0
Loss at iteration 920 : 62184319090688.0
Loss at iteration 930 : 11523150839808.0
Loss at iteration 940 : 9913882378240.0
Loss at iteration 950 : 11841395752960.0
Loss at iteration 960 : 3664948494336.0
Loss at iteration 970 : 46505201238016.0
Loss at iteration 980 : 397209849823232.0
Loss at iteration 990 : 28370240798720.0
Loss at iteration 1000 : 22222722826240.0
Loss at iteration 1010 : 5130122952704.0
Loss at iteration 1020 : 425018521550848.0
Loss at iteration 1030 : 28378979631104.0
Loss at iteration 1040 : 130238818287616.0
Loss at iteration 1050 : 7291691597824.0
Loss at iteration 1060 : 1427805569024.0
Loss at iteration 1070 : 5170411339776.0
Loss at iteration 1080 : 44753148182528.0
Loss at iteration 1090 : 22711738826752.0
Loss at iteration 1100 : 6455857512448.0
Loss at iteration 1110 : 38527374983168.0
Loss at iteration 1120 : 10344294514688.0
Loss at iteration 1130 : 13263665364992.0
Loss at iteration 1140 : 32285374021632.0
Loss at iteration 1150 : 42695116455936.0
Loss at iteration 1160 : 11933076946944.0
Loss at iteration 1170 : 59730932269056.0
Loss at iteration 1180 : 26009392906240.0
Loss at iteration 1190 : 4666412236800.0
Loss at iteration 1200 : 75039160401920.0
Loss at iteration 1210 : 29012797685760.0
Loss at iteration 1220 : 24910833385472.0
Loss at iteration 1230 : 34683616231424.0
Loss at iteration 1240 : 504292544872448.0
Loss at iteration 1250 : 82046449876992.0
Loss at iteration 1260 : 36784008331264.0
Loss at iteration 1270 : 18043281342464.0
Loss at iteration 1280 : 11726502232064.0
Loss at iteration 1290 : 2971192786944.0
Loss at iteration 1300 : 14382401585152.0
Loss at iteration 1310 : 90938844119040.0
Loss at iteration 1320 : 157355387912192.0
Loss at iteration 1330 : 25776552411136.0
Loss at iteration 1340 : 15920065937408.0
Loss at iteration 1350 : 3891604488192.0
Loss at iteration 1360 : 4317621256192.0
Loss at iteration 1370 : 1367491739648.0
Loss at iteration 1380 : 2782796709888.0
Loss at iteration 1390 : 17434192904192.0
Loss at iteration 1400 : 58394262110208.0
Loss at iteration 1410 : 19167451283456.0
Loss at iteration 1420 : 16290084290560.0
Loss at iteration 1430 : 1448936472576.0
Loss at iteration 1440 : 10881029111808.0
Loss at iteration 1450 : 22048655015936.0
Loss at iteration 1460 : 29124798185472.0
Loss at iteration 1470 : 3835422310400.0
Loss at iteration 1480 : 5478423724032.0
Loss at iteration 1490 : 87370816815104.0
Loss at iteration 1500 : 82330068713472.0
Loss at iteration 1510 : 5223147372544.0
Loss at iteration 1520 : 9925979799552.0
Loss at iteration 1530 : 5889356988416.0
Loss at iteration 1540 : 8219884257280.0
Loss at iteration 1550 : 82983407058944.0
Loss at iteration 1560 : 660711276544.0
Loss at iteration 1570 : 9971796279296.0
Loss at iteration 1580 : 13081926172672.0
Loss at iteration 1590 : 14158796947456.0
Loss at iteration 1600 : 2622449254400.0
Loss at iteration 1610 : 160571211120640.0
Loss at iteration 1620 : 3398944686080.0
Loss at iteration 1630 : 7221548679168.0
Loss at iteration 1640 : 5483868454912.0
Loss at iteration 1650 : 1561890521088.0
Loss at iteration 1660 : 30728247050240.0
Loss at iteration 1670 : 1152024313856.0
Loss at iteration 1680 : 24728020451328.0
Loss at iteration 1690 : 6392189026304.0
Loss at iteration 1700 : 7615392776192.0
Loss at iteration 1710 : 321309254877184.0
Loss at iteration 1720 : 27863357063168.0
Loss at iteration 1730 : 1860627202048.0
Loss at iteration 1740 : 3028723695616.0
Loss at iteration 1750 : 421313609728.0
Loss at iteration 1760 : 10294221864960.0
Loss at iteration 1770 : 10199966416896.0
Loss at iteration 1780 : 3402519019520.0
Loss at iteration 1790 : 4117996240896.0
Loss at iteration 1800 : 53362653396992.0
Loss at iteration 1810 : 127211680038912.0
Loss at iteration 1820 : 13628669427712.0
Loss at iteration 1830 : 16861715496960.0
Loss at iteration 1840 : 22855808974848.0
Loss at iteration 1850 : 7136034684928.0
Loss at iteration 1860 : 3943639285760.0
Loss at iteration 1870 : 58312502542336.0
Loss at iteration 1880 : 87450919632896.0
Loss at iteration 1890 : 5276768403456.0
Loss at iteration 1900 : 22611685801984.0
Loss at iteration 1910 : 3310503591936.0
Loss at iteration 1920 : 297060406394880.0
Loss at iteration 1930 : 31214048116736.0
Loss at iteration 1940 : 6799624765440.0
Loss at iteration 1950 : 12036644798464.0
Loss at iteration 1960 : 769769406464.0
Loss at iteration 1970 : 6078906499072.0
Loss at iteration 1980 : 14480192831488.0
Loss at iteration 1990 : 3996130476032.0
Loss at iteration 2000 : 5932572475392.0
Loss at iteration 2010 : 18688363200512.0
Loss at iteration 2020 : 5433234817024.0
Loss at iteration 2030 : 9956599267328.0
Loss at iteration 2040 : 17940772552704.0
Loss at iteration 2050 : 4341703901184.0
Loss at iteration 2060 : 560827662336.0
Loss at iteration 2070 : 4663566401536.0
Loss at iteration 2080 : 16210996494336.0
Loss at iteration 2090 : 1911550509056.0
Loss at iteration 2100 : 74052265836544.0
Loss at iteration 2110 : 3.704357409595064e+17
Loss at iteration 2120 : 1958528575078400.0
Loss at iteration 2130 : 569170810896384.0
Loss at iteration 2140 : 3916474376781824.0
Loss at iteration 2150 : 658760540356608.0
Loss at iteration 2160 : 223582525325312.0
Loss at iteration 2170 : 227999261655040.0
Loss at iteration 2180 : 46735296561152.0
Loss at iteration 2190 : 223049144074240.0
Loss at iteration 2200 : 98549425504256.0
Loss at iteration 2210 : 80637365059584.0
Loss at iteration 2220 : 139809783808000.0
Loss at iteration 2230 : 27913648865280.0
Loss at iteration 2240 : 279834970292224.0
Loss at iteration 2250 : 88522555916288.0
Loss at iteration 2260 : 81856263356416.0
Loss at iteration 2270 : 92312696782848.0
Loss at iteration 2280 : 26812547596288.0
Loss at iteration 2290 : 73975778508800.0
Loss at iteration 2300 : 7353484181504.0
Loss at iteration 2310 : 30656943882240.0
Loss at iteration 2320 : 63287425236992.0
Loss at iteration 2330 : 27345354227712.0
Loss at iteration 2340 : 28759403003904.0
Loss at iteration 2350 : 30059731615744.0
Loss at iteration 2360 : 32953996410880.0
Loss at iteration 2370 : 59170506145792.0
Loss at iteration 2380 : 66731800264704.0
Loss at iteration 2390 : 89412545282048.0
Loss at iteration 2400 : 43440721100800.0
Loss at iteration 2410 : 8579086024704.0
Loss at iteration 2420 : 36639036407808.0
The SSIM Value is: 5.266143974343625e-06
The PSNR Value is: -139.7377716064453
the epoch is: 173
Loss at iteration 10 : 38587600994304.0
Loss at iteration 20 : 8888541773824.0
Loss at iteration 30 : 81213066838016.0
Loss at iteration 40 : 130397010657280.0
Loss at iteration 50 : 1941514223616.0
Loss at iteration 60 : 12589103841280.0
Loss at iteration 70 : 21248725745664.0
Loss at iteration 80 : 13791437783040.0
Loss at iteration 90 : 19670874718208.0
Loss at iteration 100 : 28367944417280.0
Loss at iteration 110 : 10415913304064.0
Loss at iteration 120 : 509082809139200.0
Loss at iteration 130 : 121816404197376.0
Loss at iteration 140 : 4703116066816.0
Loss at iteration 150 : 26889280290816.0
Loss at iteration 160 : 6076771074048.0
Loss at iteration 170 : 17642423320576.0
Loss at iteration 180 : 3021235814400.0
Loss at iteration 190 : 27595160682496.0
Loss at iteration 200 : 3665851318272.0
Loss at iteration 210 : 844340789248.0
Loss at iteration 220 : 2570949492736.0
Loss at iteration 230 : 27586891612160.0
Loss at iteration 240 : 6137722699776.0
Loss at iteration 250 : 37954584051712.0
Loss at iteration 260 : 42263816175616.0
Loss at iteration 270 : 16015537733632.0
Loss at iteration 280 : 1353959079936.0
Loss at iteration 290 : 3286506405888.0
Loss at iteration 300 : 127315514228736.0
Loss at iteration 310 : 19621765709824.0
Loss at iteration 320 : 3141290164224.0
Loss at iteration 330 : 3969120206848.0
Loss at iteration 340 : 11867862859776.0
Loss at iteration 350 : 33915043577856.0
Loss at iteration 360 : 880594583552.0
Loss at iteration 370 : 10590987747328.0
Loss at iteration 380 : 28158040473600.0
Loss at iteration 390 : 1833799516160.0
Loss at iteration 400 : 2198845784064.0
Loss at iteration 410 : 21870034288640.0
Loss at iteration 420 : 5234346688512.0
Loss at iteration 430 : 20471181475840.0
Loss at iteration 440 : 6730638426112.0
Loss at iteration 450 : 1229223362560.0
Loss at iteration 460 : 12968885485568.0
Loss at iteration 470 : 2587479769088.0
Loss at iteration 480 : 21807134408704.0
Loss at iteration 490 : 12448703709184.0
Loss at iteration 500 : 4586542202880.0
Loss at iteration 510 : 1445030002688.0
Loss at iteration 520 : 472305008640.0
Loss at iteration 530 : 21431614177280.0
Loss at iteration 540 : 33476665409536.0
Loss at iteration 550 : 150181030920192.0
Loss at iteration 560 : 249395681427456.0
Loss at iteration 570 : 9772115951616.0
Loss at iteration 580 : 18879860441088.0
Loss at iteration 590 : 225730327740416.0
Loss at iteration 600 : 29821121855488.0
Loss at iteration 610 : 313677030883328.0
Loss at iteration 620 : 33286158024704.0
Loss at iteration 630 : 8477777854464.0
Loss at iteration 640 : 41520803610624.0
Loss at iteration 650 : 292474220183552.0
Loss at iteration 660 : 37545085763584.0
Loss at iteration 670 : 17572118396928.0
Loss at iteration 680 : 2465012383744.0
Loss at iteration 690 : 3346180341760.0
Loss at iteration 700 : 13015466377216.0
Loss at iteration 710 : 41071597846528.0
Loss at iteration 720 : 371954334826496.0
Loss at iteration 730 : 47801132122112.0
Loss at iteration 740 : 18961445945344.0
Loss at iteration 750 : 6774673375232.0
Loss at iteration 760 : 58211751165952.0
Loss at iteration 770 : 104114067341312.0
Loss at iteration 780 : 3618002698240.0
Loss at iteration 790 : 1956388405248.0
Loss at iteration 800 : 12315079475200.0
Loss at iteration 810 : 445130276864.0
Loss at iteration 820 : 428970770432.0
Loss at iteration 830 : 56463925968896.0
Loss at iteration 840 : 56633103220736.0
Loss at iteration 850 : 706345369600.0
Loss at iteration 860 : 3899645231104.0
Loss at iteration 870 : 8788177321984.0
Loss at iteration 880 : 3281967906816.0
Loss at iteration 890 : 3111723466752.0
Loss at iteration 900 : 26630028263424.0
Loss at iteration 910 : 7340132663296.0
Loss at iteration 920 : 8867719151616.0
Loss at iteration 930 : 11650638807040.0
Loss at iteration 940 : 4317806592000.0
Loss at iteration 950 : 3851278090240.0
Loss at iteration 960 : 762068992000.0
Loss at iteration 970 : 5309488693248.0
Loss at iteration 980 : 132393490972672.0
Loss at iteration 990 : 12760976982016.0
Loss at iteration 1000 : 81260873515008.0
Loss at iteration 1010 : 2901585166336.0
Loss at iteration 1020 : 172773095768064.0
Loss at iteration 1030 : 22327116955648.0
Loss at iteration 1040 : 6356006862848.0
Loss at iteration 1050 : 501403942912.0
Loss at iteration 1060 : 4201527115776.0
Loss at iteration 1070 : 4031728320512.0
Loss at iteration 1080 : 3550458150912.0
Loss at iteration 1090 : 1166230552576.0
Loss at iteration 1100 : 11470415855616.0
Loss at iteration 1110 : 34651806629888.0
Loss at iteration 1120 : 10379025448960.0
Loss at iteration 1130 : 25801433022464.0
Loss at iteration 1140 : 1765740249088.0
Loss at iteration 1150 : 93452691832832.0
Loss at iteration 1160 : 466723635200.0
Loss at iteration 1170 : 6604583337984.0
Loss at iteration 1180 : 750188429312.0
Loss at iteration 1190 : 5586012864512.0
Loss at iteration 1200 : 40361552510976.0
Loss at iteration 1210 : 4558685208576.0
Loss at iteration 1220 : 210843779072.0
Loss at iteration 1230 : 5720244224000.0
Loss at iteration 1240 : 12761153142784.0
Loss at iteration 1250 : 743253344256.0
Loss at iteration 1260 : 104983529783296.0
Loss at iteration 1270 : 1045651521536.0
Loss at iteration 1280 : 655415312384.0
Loss at iteration 1290 : 9297620631552.0
Loss at iteration 1300 : 1112665882624.0
Loss at iteration 1310 : 68651419959296.0
Loss at iteration 1320 : 3218312265728.0
Loss at iteration 1330 : 1119386468352.0
Loss at iteration 1340 : 1513099231232.0
Loss at iteration 1350 : 18435419406336.0
Loss at iteration 1360 : 5404163571712.0
Loss at iteration 1370 : 18473214279680.0
Loss at iteration 1380 : 4325334319104.0
Loss at iteration 1390 : 15951160410112.0
Loss at iteration 1400 : 654118354944.0
Loss at iteration 1410 : 2725854314496.0
Loss at iteration 1420 : 5737537863680.0
Loss at iteration 1430 : 1842780438528.0
Loss at iteration 1440 : 1179001683968.0
Loss at iteration 1450 : 3896379965440.0
Loss at iteration 1460 : 11406391902208.0
Loss at iteration 1470 : 7260665282560.0
Loss at iteration 1480 : 5195623301120.0
Loss at iteration 1490 : 17025315373056.0
Loss at iteration 1500 : 5905425367040.0
Loss at iteration 1510 : 2425090998272.0
Loss at iteration 1520 : 4598643818496.0
Loss at iteration 1530 : 5479494320128.0
Loss at iteration 1540 : 55158364962816.0
Loss at iteration 1550 : 531789999243264.0
Loss at iteration 1560 : 739486924800.0
Loss at iteration 1570 : 2176602472448.0
Loss at iteration 1580 : 2609983520768.0
Loss at iteration 1590 : 28028281290752.0
Loss at iteration 1600 : 8878160871424.0
Loss at iteration 1610 : 737427980288.0
Loss at iteration 1620 : 1445788254208.0
Loss at iteration 1630 : 150853142970368.0
Loss at iteration 1640 : 4689802821632.0
Loss at iteration 1650 : 1895600226304.0
Loss at iteration 1660 : 441157222400.0
Loss at iteration 1670 : 44693748449280.0
Loss at iteration 1680 : 762220380160.0
Loss at iteration 1690 : 6025274982400.0
Loss at iteration 1700 : 17958239731712.0
Loss at iteration 1710 : 8133616861184.0
Loss at iteration 1720 : 661376204800.0
Loss at iteration 1730 : 13132090048512.0
Loss at iteration 1740 : 237964017664.0
Loss at iteration 1750 : 3130638204928.0
Loss at iteration 1760 : 3427502653440.0
Loss at iteration 1770 : 551090323456.0
Loss at iteration 1780 : 1191827603456.0
Loss at iteration 1790 : 85953360166912.0
Loss at iteration 1800 : 7731504218112.0
Loss at iteration 1810 : 817223434240.0
Loss at iteration 1820 : 29553003069440.0
Loss at iteration 1830 : 180368261120.0
Loss at iteration 1840 : 7150416429056.0
Loss at iteration 1850 : 978112937984.0
Loss at iteration 1860 : 16328687616000.0
Loss at iteration 1870 : 15279088205824.0
Loss at iteration 1880 : 6871232544768.0
Loss at iteration 1890 : 4797638377472.0
Loss at iteration 1900 : 19390479204352.0
Loss at iteration 1910 : 595824738304.0
Loss at iteration 1920 : 4153126420480.0
Loss at iteration 1930 : 3509818490880.0
Loss at iteration 1940 : 2204782821376.0
Loss at iteration 1950 : 5065236545536.0
Loss at iteration 1960 : 2463965904896.0
Loss at iteration 1970 : 550918488064.0
Loss at iteration 1980 : 33670314328064.0
Loss at iteration 1990 : 941250314240.0
Loss at iteration 2000 : 17875144278016.0
Loss at iteration 2010 : 4834964013056.0
Loss at iteration 2020 : 4662692937728.0
Loss at iteration 2030 : 4352419299328.0
Loss at iteration 2040 : 293213274112.0
Loss at iteration 2050 : 694630154240.0
Loss at iteration 2060 : 6262632218624.0
Loss at iteration 2070 : 629298167808.0
Loss at iteration 2080 : 129277444096.0
Loss at iteration 2090 : 3282921324544.0
Loss at iteration 2100 : 727587422208.0
Loss at iteration 2110 : 477648093184.0
Loss at iteration 2120 : 704089489408.0
Loss at iteration 2130 : 1525670477824.0
Loss at iteration 2140 : 13602146746368.0
Loss at iteration 2150 : 9778779652096.0
Loss at iteration 2160 : 43484232810496.0
Loss at iteration 2170 : 3735107141632.0
Loss at iteration 2180 : 34205257957376.0
Loss at iteration 2190 : 5921325973504.0
Loss at iteration 2200 : 2583769645056.0
Loss at iteration 2210 : 3188953972736.0
Loss at iteration 2220 : 56432565157888.0
Loss at iteration 2230 : 1743200190464.0
Loss at iteration 2240 : 5250966618112.0
Loss at iteration 2250 : 2891677696000.0
Loss at iteration 2260 : 4313528664064.0
Loss at iteration 2270 : 3713043267584.0
Loss at iteration 2280 : 27752319156224.0
Loss at iteration 2290 : 6236115304448.0
Loss at iteration 2300 : 26619827716096.0
Loss at iteration 2310 : 12238892040192.0
Loss at iteration 2320 : 9509225365504.0
Loss at iteration 2330 : 84789323366400.0
Loss at iteration 2340 : 5936567549952.0
Loss at iteration 2350 : 11580107390976.0
Loss at iteration 2360 : 5212291465216.0
Loss at iteration 2370 : 76123782250496.0
Loss at iteration 2380 : 2684757213184.0
Loss at iteration 2390 : 4921431162880.0
Loss at iteration 2400 : 13644022677504.0
Loss at iteration 2410 : 15582705483776.0
Loss at iteration 2420 : 2668019318784.0
The SSIM Value is: 9.067654853437782e-06
The PSNR Value is: -137.74185943603516
the epoch is: 174
Loss at iteration 10 : 4541117366272.0
Loss at iteration 20 : 1292535201792.0
Loss at iteration 30 : 235157045248.0
Loss at iteration 40 : 2232995545088.0
Loss at iteration 50 : 20922629095424.0
Loss at iteration 60 : 2267838152704.0
Loss at iteration 70 : 5207394615296.0
Loss at iteration 80 : 47281927618560.0
Loss at iteration 90 : 1129214509056.0
Loss at iteration 100 : 1401975734272.0
Loss at iteration 110 : 1249283932160.0
Loss at iteration 120 : 1131320311808.0
Loss at iteration 130 : 68582969344.0
Loss at iteration 140 : 2494410522624.0
Loss at iteration 150 : 26005446066176.0
Loss at iteration 160 : 51764813824.0
Loss at iteration 170 : 60958285824.0
Loss at iteration 180 : 1706152034304.0
Loss at iteration 190 : 6933746548736.0
Loss at iteration 200 : 8917589426176.0
Loss at iteration 210 : 1476574707712.0
Loss at iteration 220 : 5542545719296.0
Loss at iteration 230 : 421526601728.0
Loss at iteration 240 : 4715454136320.0
Loss at iteration 250 : 82941220749312.0
Loss at iteration 260 : 3089184325632.0
Loss at iteration 270 : 8418232369152.0
Loss at iteration 280 : 3127212244992.0
Loss at iteration 290 : 3754572644352.0
Loss at iteration 300 : 677871419392.0
Loss at iteration 310 : 3976088256512.0
Loss at iteration 320 : 4743595294720.0
Loss at iteration 330 : 7954504351744.0
Loss at iteration 340 : 1157400363008.0
Loss at iteration 350 : 4349631660032.0
Loss at iteration 360 : 12640442122240.0
Loss at iteration 370 : 3374524661760.0
Loss at iteration 380 : 3743710183424.0
Loss at iteration 390 : 3287607934976.0
Loss at iteration 400 : 5178208026624.0
Loss at iteration 410 : 3426955296768.0
Loss at iteration 420 : 409236373504.0
Loss at iteration 430 : 12122137296896.0
Loss at iteration 440 : 984004689920.0
Loss at iteration 450 : 2877222813696.0
Loss at iteration 460 : 10558437851136.0
Loss at iteration 470 : 873435219623936.0
Loss at iteration 480 : 9562323156992.0
Loss at iteration 490 : 1055885557760.0
Loss at iteration 500 : 463742730240.0
Loss at iteration 510 : 528687497216.0
Loss at iteration 520 : 4512022003712.0
Loss at iteration 530 : 2487904108544.0
Loss at iteration 540 : 2438362300416.0
Loss at iteration 550 : 333050478592.0
Loss at iteration 560 : 63760500785152.0
Loss at iteration 570 : 492503662592.0
Loss at iteration 580 : 1157190254592.0
Loss at iteration 590 : 619808292864.0
Loss at iteration 600 : 528656236544.0
Loss at iteration 610 : 103186169856.0
Loss at iteration 620 : 15595564032.0
Loss at iteration 630 : 114519744512.0
Loss at iteration 640 : 964549935104.0
Loss at iteration 650 : 26328696881152.0
Loss at iteration 660 : 154064822206464.0
Loss at iteration 670 : 282037911552.0
Loss at iteration 680 : 360487190528.0
Loss at iteration 690 : 2449717592064.0
Loss at iteration 700 : 25486614855680.0
Loss at iteration 710 : 685369524224.0
Loss at iteration 720 : 1640015986688.0
Loss at iteration 730 : 3098336821248.0
Loss at iteration 740 : 2007816208384.0
Loss at iteration 750 : 4149295710208.0
Loss at iteration 760 : 2420739145728.0
Loss at iteration 770 : 321085276160.0
Loss at iteration 780 : 2462521229312.0
Loss at iteration 790 : 320119275520.0
Loss at iteration 800 : 4109460045824.0
Loss at iteration 810 : 85730697216.0
Loss at iteration 820 : 500113997824.0
Loss at iteration 830 : 942502117376.0
Loss at iteration 840 : 1211112620032.0
Loss at iteration 850 : 9526537355264.0
Loss at iteration 860 : 6872470388736.0
Loss at iteration 870 : 863456067584.0
Loss at iteration 880 : 187403862016.0
Loss at iteration 890 : 59789680640.0
Loss at iteration 900 : 40715956224.0
Loss at iteration 910 : 4019916111872.0
Loss at iteration 920 : 99066167296.0
Loss at iteration 930 : 2201727270912.0
Loss at iteration 940 : 2569725804544.0
Loss at iteration 950 : 579532685312.0
Loss at iteration 960 : 273235902464.0
Loss at iteration 970 : 283561951232.0
Loss at iteration 980 : 49558519808.0
Loss at iteration 990 : 7584428851200.0
Loss at iteration 1000 : 113598455808.0
Loss at iteration 1010 : 426984996864.0
Loss at iteration 1020 : 1960560427008.0
Loss at iteration 1030 : 3622300286976.0
Loss at iteration 1040 : 7474630885376.0
Loss at iteration 1050 : 1398339928064.0
Loss at iteration 1060 : 677412208640.0
Loss at iteration 1070 : 1898957111296.0
Loss at iteration 1080 : 147624116224.0
Loss at iteration 1090 : 61127569408.0
Loss at iteration 1100 : 607275581440.0
Loss at iteration 1110 : 12500817936384.0
Loss at iteration 1120 : 53864767488.0
Loss at iteration 1130 : 14308906893312.0
Loss at iteration 1140 : 34640711680.0
Loss at iteration 1150 : 818246320128.0
Loss at iteration 1160 : 137709830144.0
Loss at iteration 1170 : 2467681533952.0
Loss at iteration 1180 : 1045876375552.0
Loss at iteration 1190 : 111386230784.0
Loss at iteration 1200 : 1402309705728.0
Loss at iteration 1210 : 196467064832.0
Loss at iteration 1220 : 156537110528.0
Loss at iteration 1230 : 100520017920.0
Loss at iteration 1240 : 86722617344.0
Loss at iteration 1250 : 7195823439872.0
Loss at iteration 1260 : 251291631616.0
Loss at iteration 1270 : 3641896075264.0
Loss at iteration 1280 : 118209587970048.0
Loss at iteration 1290 : 33847714512896.0
Loss at iteration 1300 : 139569450188800.0
Loss at iteration 1310 : 1397281710407680.0
Loss at iteration 1320 : 2952269788086272.0
Loss at iteration 1330 : 366928786882560.0
Loss at iteration 1340 : 1945962842947584.0
Loss at iteration 1350 : 78594504130560.0
Loss at iteration 1360 : 81028676845568.0
Loss at iteration 1370 : 7481636945920.0
Loss at iteration 1380 : 6617515950080.0
Loss at iteration 1390 : 22022501433344.0
Loss at iteration 1400 : 1091225518080.0
Loss at iteration 1410 : 1441565638656.0
Loss at iteration 1420 : 21525367357440.0
Loss at iteration 1430 : 19788862586880.0
Loss at iteration 1440 : 55770192281600.0
Loss at iteration 1450 : 462325043691520.0
Loss at iteration 1460 : 24060601827328.0
Loss at iteration 1470 : 7419513536512.0
Loss at iteration 1480 : 51467490689024.0
Loss at iteration 1490 : 26897230594048.0
Loss at iteration 1500 : 5675673452544.0
Loss at iteration 1510 : 1952925614080.0
Loss at iteration 1520 : 78354799656960.0
Loss at iteration 1530 : 8511568740352.0
Loss at iteration 1540 : 9374310334464.0
Loss at iteration 1550 : 3823274819584.0
Loss at iteration 1560 : 32170118742016.0
Loss at iteration 1570 : 1699861889024.0
Loss at iteration 1580 : 203284862205952.0
Loss at iteration 1590 : 341829333549056.0
Loss at iteration 1600 : 19090718588928.0
Loss at iteration 1610 : 8094601445376.0
Loss at iteration 1620 : 6543273099264.0
Loss at iteration 1630 : 3746011545600.0
Loss at iteration 1640 : 3326261854208.0
Loss at iteration 1650 : 3021588398080.0
Loss at iteration 1660 : 4977639555072.0
Loss at iteration 1670 : 48976439017472.0
Loss at iteration 1680 : 53684947910656.0
Loss at iteration 1690 : 16037856673792.0
Loss at iteration 1700 : 24588037652480.0
Loss at iteration 1710 : 39855677505536.0
Loss at iteration 1720 : 66276319821824.0
Loss at iteration 1730 : 2609754669056.0
Loss at iteration 1740 : 46283716820992.0
Loss at iteration 1750 : 8113816076288.0
Loss at iteration 1760 : 19119271313408.0
Loss at iteration 1770 : 17684066467840.0
Loss at iteration 1780 : 15799484940288.0
Loss at iteration 1790 : 541405020160.0
Loss at iteration 1800 : 18396737437696.0
Loss at iteration 1810 : 8456201306112.0
Loss at iteration 1820 : 16676762419200.0
Loss at iteration 1830 : 3375401795584.0
Loss at iteration 1840 : 11590628802560.0
Loss at iteration 1850 : 5527431020544.0
Loss at iteration 1860 : 111209110044672.0
Loss at iteration 1870 : 4169565995008.0
Loss at iteration 1880 : 7031417208832.0
Loss at iteration 1890 : 38707528728576.0
Loss at iteration 1900 : 397224902656.0
Loss at iteration 1910 : 7044859953152.0
Loss at iteration 1920 : 31853247463424.0
Loss at iteration 1930 : 10809118818304.0
Loss at iteration 1940 : 3452215230464.0
Loss at iteration 1950 : 3021057818624.0
Loss at iteration 1960 : 50168123392.0
Loss at iteration 1970 : 41871514533888.0
Loss at iteration 1980 : 3624778858496.0
Loss at iteration 1990 : 9995145969664.0
Loss at iteration 2000 : 22961499144192.0
Loss at iteration 2010 : 4075149328384.0
Loss at iteration 2020 : 1131027234816.0
Loss at iteration 2030 : 6645964865536.0
Loss at iteration 2040 : 488033189888.0
Loss at iteration 2050 : 1166877523968.0
Loss at iteration 2060 : 2524911763456.0
Loss at iteration 2070 : 4041767649280.0
Loss at iteration 2080 : 287420284928.0
Loss at iteration 2090 : 24999261896704.0
Loss at iteration 2100 : 352639090688.0
Loss at iteration 2110 : 17356217647104.0
Loss at iteration 2120 : 5937869357056.0
Loss at iteration 2130 : 29585074814976.0
Loss at iteration 2140 : 464729997312.0
Loss at iteration 2150 : 10125237551104.0
Loss at iteration 2160 : 2709926707200.0
Loss at iteration 2170 : 42924972703744.0
Loss at iteration 2180 : 770861432832.0
Loss at iteration 2190 : 13130205757440.0
Loss at iteration 2200 : 1308086108160.0
Loss at iteration 2210 : 4968077066240.0
Loss at iteration 2220 : 52061282500608.0
Loss at iteration 2230 : 780888244224.0
Loss at iteration 2240 : 9446896959488.0
Loss at iteration 2250 : 16619283677184.0
Loss at iteration 2260 : 265124271095808.0
Loss at iteration 2270 : 9029172592640.0
Loss at iteration 2280 : 1061584240640.0
Loss at iteration 2290 : 16306586779648.0
Loss at iteration 2300 : 21913374031872.0
Loss at iteration 2310 : 1165971947520.0
Loss at iteration 2320 : 6168024449024.0
Loss at iteration 2330 : 19014715703296.0
Loss at iteration 2340 : 9033363750912.0
Loss at iteration 2350 : 1006633091072.0
Loss at iteration 2360 : 2269778542592.0
Loss at iteration 2370 : 38502095912960.0
Loss at iteration 2380 : 472615976960.0
Loss at iteration 2390 : 12391901298688.0
Loss at iteration 2400 : 2913336295424.0
Loss at iteration 2410 : 222672411688960.0
Loss at iteration 2420 : 13835310202880.0
The SSIM Value is: -2.9085105779813604e-06
The PSNR Value is: -148.23634541829426
the epoch is: 175
Loss at iteration 10 : 91766858448896.0
Loss at iteration 20 : 49053882646528.0
Loss at iteration 30 : 383851461345280.0
Loss at iteration 40 : 286154276470784.0
Loss at iteration 50 : 1239197117579264.0
Loss at iteration 60 : 35277372391424.0
Loss at iteration 70 : 28043093475328.0
Loss at iteration 80 : 89630808473600.0
Loss at iteration 90 : 19353802113024.0
Loss at iteration 100 : 28642021212160.0
Loss at iteration 110 : 36475328528384.0
Loss at iteration 120 : 50720652918784.0
Loss at iteration 130 : 8953133006848.0
Loss at iteration 140 : 2470568525824.0
Loss at iteration 150 : 17208717606912.0
Loss at iteration 160 : 1937641832448.0
Loss at iteration 170 : 322507210752.0
Loss at iteration 180 : 3197143613440.0
Loss at iteration 190 : 37780977614848.0
Loss at iteration 200 : 195341588627456.0
Loss at iteration 210 : 533699592192.0
Loss at iteration 220 : 823076929404928.0
Loss at iteration 230 : 162386984960.0
Loss at iteration 240 : 21152451788800.0
Loss at iteration 250 : 3608930418688.0
Loss at iteration 260 : 1000520482816.0
Loss at iteration 270 : 146948497604608.0
Loss at iteration 280 : 32675838558208.0
Loss at iteration 290 : 13934265368576.0
Loss at iteration 300 : 129587635814400.0
Loss at iteration 310 : 3085768589312.0
Loss at iteration 320 : 1618764890112.0
Loss at iteration 330 : 2677976858624.0
Loss at iteration 340 : 6039222091776.0
Loss at iteration 350 : 2267806433280.0
Loss at iteration 360 : 33345966702592.0
Loss at iteration 370 : 4526252752896.0
Loss at iteration 380 : 292158472192.0
Loss at iteration 390 : 1657392857088.0
Loss at iteration 400 : 139338416128.0
Loss at iteration 410 : 164495671296.0
Loss at iteration 420 : 130344699297792.0
Loss at iteration 430 : 3588049076224.0
Loss at iteration 440 : 8503520919552.0
Loss at iteration 450 : 394828283904.0
Loss at iteration 460 : 4076637519872.0
Loss at iteration 470 : 1312462995456.0
Loss at iteration 480 : 5218117877760.0
Loss at iteration 490 : 7349022490624.0
Loss at iteration 500 : 2292692811776.0
Loss at iteration 510 : 77709455654912.0
Loss at iteration 520 : 6113342259200.0
Loss at iteration 530 : 5166039302144.0
Loss at iteration 540 : 31801747701760.0
Loss at iteration 550 : 4363757551616.0
Loss at iteration 560 : 2007637164032.0
Loss at iteration 570 : 39849058893824.0
Loss at iteration 580 : 1544100511744.0
Loss at iteration 590 : 6626067611648.0
Loss at iteration 600 : 27671526375424.0
Loss at iteration 610 : 8181861842944.0
Loss at iteration 620 : 11106926985216.0
Loss at iteration 630 : 59957739257856.0
Loss at iteration 640 : 11881916923904.0
Loss at iteration 650 : 58236732440576.0
Loss at iteration 660 : 3672825397248.0
Loss at iteration 670 : 8325168627712.0
Loss at iteration 680 : 48967517732864.0
Loss at iteration 690 : 11374147141632.0
Loss at iteration 700 : 24821425504256.0
Loss at iteration 710 : 132618272112640.0
Loss at iteration 720 : 188750894202880.0
Loss at iteration 730 : 5675847516160.0
Loss at iteration 740 : 24733053616128.0
Loss at iteration 750 : 14407447871488.0
Loss at iteration 760 : 30868714291200.0
Loss at iteration 770 : 187400949071872.0
Loss at iteration 780 : 582924369920000.0
Loss at iteration 790 : 1067179852169216.0
Loss at iteration 800 : 46147620044800.0
Loss at iteration 810 : 868744108703744.0
Loss at iteration 820 : 3154820988928.0
Loss at iteration 830 : 13184664600576.0
Loss at iteration 840 : 7577907232768.0
Loss at iteration 850 : 20360695119872.0
Loss at iteration 860 : 28924910239744.0
Loss at iteration 870 : 7013171986432.0
Loss at iteration 880 : 12591653978112.0
Loss at iteration 890 : 42416329457664.0
Loss at iteration 900 : 5655168024576.0
Loss at iteration 910 : 10516850278400.0
Loss at iteration 920 : 126518453862400.0
Loss at iteration 930 : 20734103519232.0
Loss at iteration 940 : 19845437456384.0
Loss at iteration 950 : 6521207914496.0
Loss at iteration 960 : 4297031942144.0
Loss at iteration 970 : 5653821128704.0
Loss at iteration 980 : 3198984388608.0
Loss at iteration 990 : 13748682096640.0
Loss at iteration 1000 : 9588456816640.0
Loss at iteration 1010 : 4948431470592.0
Loss at iteration 1020 : 4121333596160.0
Loss at iteration 1030 : 11532002918400.0
Loss at iteration 1040 : 5253747441664.0
Loss at iteration 1050 : 2761787703296.0
Loss at iteration 1060 : 42139438284800.0
Loss at iteration 1070 : 19688060878848.0
Loss at iteration 1080 : 9591290068992.0
Loss at iteration 1090 : 14220162760704.0
Loss at iteration 1100 : 35306115956736.0
Loss at iteration 1110 : 14061536280576.0
Loss at iteration 1120 : 26617992708096.0
Loss at iteration 1130 : 19162835451904.0
Loss at iteration 1140 : 8397702299648.0
Loss at iteration 1150 : 34345605660672.0
Loss at iteration 1160 : 2031085551616.0
Loss at iteration 1170 : 18486162096128.0
Loss at iteration 1180 : 2711755423744.0
Loss at iteration 1190 : 2241420591104.0
Loss at iteration 1200 : 5912017764352.0
Loss at iteration 1210 : 11890800459776.0
Loss at iteration 1220 : 12967384973312.0
Loss at iteration 1230 : 719547465728.0
Loss at iteration 1240 : 3755788468224.0
Loss at iteration 1250 : 5528402526208.0
Loss at iteration 1260 : 2123414765568.0
Loss at iteration 1270 : 67900312387584.0
Loss at iteration 1280 : 39474994085888.0
Loss at iteration 1290 : 17246907793408.0
Loss at iteration 1300 : 1213069220904960.0
Loss at iteration 1310 : 124547617521664.0
Loss at iteration 1320 : 1007519727616.0
Loss at iteration 1330 : 13474151268352.0
Loss at iteration 1340 : 1365498396672.0
Loss at iteration 1350 : 155293515776.0
Loss at iteration 1360 : 1148471607296.0
Loss at iteration 1370 : 2187187847168.0
Loss at iteration 1380 : 89215236833280.0
Loss at iteration 1390 : 16796473098240.0
Loss at iteration 1400 : 1890529837056.0
Loss at iteration 1410 : 1540408676974592.0
Loss at iteration 1420 : 8649156591616.0
Loss at iteration 1430 : 1114119471104.0
Loss at iteration 1440 : 4472431443968.0
Loss at iteration 1450 : 2617339805696.0
Loss at iteration 1460 : 16102668107776.0
Loss at iteration 1470 : 5619083378688.0
Loss at iteration 1480 : 4500823736320.0
Loss at iteration 1490 : 143983275671552.0
Loss at iteration 1500 : 37085964664832.0
Loss at iteration 1510 : 2298344374272.0
Loss at iteration 1520 : 8481713160192.0
Loss at iteration 1530 : 84853412331520.0
Loss at iteration 1540 : 22880588922880.0
Loss at iteration 1550 : 15494885146624.0
Loss at iteration 1560 : 12165321850880.0
Loss at iteration 1570 : 85930006282240.0
Loss at iteration 1580 : 44835054551040.0
Loss at iteration 1590 : 956583437664256.0
Loss at iteration 1600 : 225948767092736.0
Loss at iteration 1610 : 20538495860736.0
Loss at iteration 1620 : 583562362880.0
Loss at iteration 1630 : 19380966522880.0
Loss at iteration 1640 : 6681162416128.0
Loss at iteration 1650 : 6844087009280.0
Loss at iteration 1660 : 12409839288320.0
Loss at iteration 1670 : 1086016706314240.0
Loss at iteration 1680 : 181710905933824.0
Loss at iteration 1690 : 4895930843136.0
Loss at iteration 1700 : 91302691602432.0
Loss at iteration 1710 : 343823205007360.0
Loss at iteration 1720 : 7261179084800.0
Loss at iteration 1730 : 12974533115904.0
Loss at iteration 1740 : 13196338397184.0
Loss at iteration 1750 : 5738101997568.0
Loss at iteration 1760 : 53850992017408.0
Loss at iteration 1770 : 20593864867840.0
Loss at iteration 1780 : 37322947035136.0
Loss at iteration 1790 : 877319290880.0
Loss at iteration 1800 : 23244205719552.0
Loss at iteration 1810 : 39263362088960.0
Loss at iteration 1820 : 12088820891648.0
Loss at iteration 1830 : 134103877812224.0
Loss at iteration 1840 : 21610608197632.0
Loss at iteration 1850 : 37489557372928.0
Loss at iteration 1860 : 12302443085824.0
Loss at iteration 1870 : 2533668945920.0
Loss at iteration 1880 : 109516850987008.0
Loss at iteration 1890 : 14846691115008.0
Loss at iteration 1900 : 17436623503360.0
Loss at iteration 1910 : 279892557824.0
Loss at iteration 1920 : 45835622547456.0
Loss at iteration 1930 : 54319831318528.0
Loss at iteration 1940 : 17336077647872.0
Loss at iteration 1950 : 30485805793280.0
Loss at iteration 1960 : 42142739202048.0
Loss at iteration 1970 : 733451649024.0
Loss at iteration 1980 : 7682406744064.0
Loss at iteration 1990 : 1494093135872.0
Loss at iteration 2000 : 1894241927168.0
Loss at iteration 2010 : 16927022907392.0
Loss at iteration 2020 : 2366630789120.0
Loss at iteration 2030 : 461658587136.0
Loss at iteration 2040 : 8719861547008.0
Loss at iteration 2050 : 1186170404864.0
Loss at iteration 2060 : 1470412750848.0
Loss at iteration 2070 : 885316059136.0
Loss at iteration 2080 : 19150747467776.0
Loss at iteration 2090 : 791552786432.0
Loss at iteration 2100 : 242089263104.0
Loss at iteration 2110 : 2638928674816.0
Loss at iteration 2120 : 2364806529024.0
Loss at iteration 2130 : 7739739209728.0
Loss at iteration 2140 : 487065649152.0
Loss at iteration 2150 : 423332872192.0
Loss at iteration 2160 : 180459192320.0
Loss at iteration 2170 : 215600578560.0
Loss at iteration 2180 : 334291795968.0
Loss at iteration 2190 : 1810604359680.0
Loss at iteration 2200 : 171615928320.0
Loss at iteration 2210 : 7497238708224.0
Loss at iteration 2220 : 1576962752512.0
Loss at iteration 2230 : 844912459776.0
Loss at iteration 2240 : 2595545153536.0
Loss at iteration 2250 : 417021132800.0
Loss at iteration 2260 : 633868779520.0
Loss at iteration 2270 : 2035860766720.0
Loss at iteration 2280 : 2121086009344.0
Loss at iteration 2290 : 736507199488.0
Loss at iteration 2300 : 57715904741376.0
Loss at iteration 2310 : 1598231805952.0
Loss at iteration 2320 : 5027115040768.0
Loss at iteration 2330 : 329065365504.0
Loss at iteration 2340 : 4732920266752.0
Loss at iteration 2350 : 3900243968000.0
Loss at iteration 2360 : 791072407552.0
Loss at iteration 2370 : 3265879605248.0
Loss at iteration 2380 : 2848796704768.0
Loss at iteration 2390 : 975910207488.0
Loss at iteration 2400 : 1057917108224.0
Loss at iteration 2410 : 798249713664.0
Loss at iteration 2420 : 434566430720.0
The SSIM Value is: 2.2674687253735706e-06
The PSNR Value is: -130.2925069173177
the epoch is: 176
Loss at iteration 10 : 817287266304.0
Loss at iteration 20 : 5172245299200.0
Loss at iteration 30 : 166042271744.0
Loss at iteration 40 : 223182569472.0
Loss at iteration 50 : 3180881248256.0
Loss at iteration 60 : 1241189580800.0
Loss at iteration 70 : 299390795776.0
Loss at iteration 80 : 7591387725824.0
Loss at iteration 90 : 4009817538560.0
Loss at iteration 100 : 219966832640.0
Loss at iteration 110 : 910137294848.0
Loss at iteration 120 : 1326493859840.0
Loss at iteration 130 : 3711166054400.0
Loss at iteration 140 : 1178594050048.0
Loss at iteration 150 : 13818590658560.0
Loss at iteration 160 : 4181367455744.0
Loss at iteration 170 : 6662165364736.0
Loss at iteration 180 : 405009858560.0
Loss at iteration 190 : 4365563985920.0
Loss at iteration 200 : 6105560776704.0
Loss at iteration 210 : 1290473308160.0
Loss at iteration 220 : 933959565312.0
Loss at iteration 230 : 9053570859008.0
Loss at iteration 240 : 66489734397952.0
Loss at iteration 250 : 714834903040.0
Loss at iteration 260 : 4998279725056.0
Loss at iteration 270 : 3611118272512.0
Loss at iteration 280 : 3395826745344.0
Loss at iteration 290 : 27050454810624.0
Loss at iteration 300 : 6625401765888.0
Loss at iteration 310 : 14981003214848.0
Loss at iteration 320 : 5036432687104.0
Loss at iteration 330 : 2421848801280.0
Loss at iteration 340 : 506315112448.0
Loss at iteration 350 : 907387928576.0
Loss at iteration 360 : 10359028056064.0
Loss at iteration 370 : 3647763382272.0
Loss at iteration 380 : 4992007143424.0
Loss at iteration 390 : 7356173254656.0
Loss at iteration 400 : 250388234240.0
Loss at iteration 410 : 33417871753216.0
Loss at iteration 420 : 6226146492416.0
Loss at iteration 430 : 10126195949568.0
Loss at iteration 440 : 1140605845504.0
Loss at iteration 450 : 3412297515008.0
Loss at iteration 460 : 1007285764096.0
Loss at iteration 470 : 46257619861504.0
Loss at iteration 480 : 956223389696.0
Loss at iteration 490 : 13395940081664.0
Loss at iteration 500 : 618320166912.0
Loss at iteration 510 : 3887893577728.0
Loss at iteration 520 : 247315005440.0
Loss at iteration 530 : 9832107081728.0
Loss at iteration 540 : 267923423232.0
Loss at iteration 550 : 3867913224192.0
Loss at iteration 560 : 846387675136.0
Loss at iteration 570 : 787825426432.0
Loss at iteration 580 : 391783022592.0
Loss at iteration 590 : 6345859268608.0
Loss at iteration 600 : 2833087725568.0
Loss at iteration 610 : 670356865024.0
Loss at iteration 620 : 11223193092096.0
Loss at iteration 630 : 979813859328.0
Loss at iteration 640 : 45374483988480.0
Loss at iteration 650 : 7466129031168.0
Loss at iteration 660 : 3475104595968.0
Loss at iteration 670 : 2566984040448.0
Loss at iteration 680 : 15554311094272.0
Loss at iteration 690 : 2162454167552.0
Loss at iteration 700 : 6002822348800.0
Loss at iteration 710 : 4424505753600.0
Loss at iteration 720 : 7406102249472.0
Loss at iteration 730 : 11418911899648.0
Loss at iteration 740 : 3332425908224.0
Loss at iteration 750 : 20859846656000.0
Loss at iteration 760 : 12412603334656.0
Loss at iteration 770 : 33201898651648.0
Loss at iteration 780 : 5689377816576.0
Loss at iteration 790 : 4588319014912.0
Loss at iteration 800 : 7056894984192.0
Loss at iteration 810 : 6663377518592.0
Loss at iteration 820 : 439853154304.0
Loss at iteration 830 : 3066657243136.0
Loss at iteration 840 : 27620437655552.0
Loss at iteration 850 : 13687090839552.0
Loss at iteration 860 : 1950439440384.0
Loss at iteration 870 : 511796674560.0
Loss at iteration 880 : 3089849384960.0
Loss at iteration 890 : 5986662744064.0
Loss at iteration 900 : 6358135996416.0
Loss at iteration 910 : 745443229696.0
Loss at iteration 920 : 2692624154624.0
Loss at iteration 930 : 5816856870912.0
Loss at iteration 940 : 481167147008.0
Loss at iteration 950 : 7979959058432.0
Loss at iteration 960 : 720118349824.0
Loss at iteration 970 : 12611300098048.0
Loss at iteration 980 : 5499558821888.0
Loss at iteration 990 : 2020052697088.0
Loss at iteration 1000 : 1561972572160.0
Loss at iteration 1010 : 382864326656.0
Loss at iteration 1020 : 3746871902208.0
Loss at iteration 1030 : 1383211204608.0
Loss at iteration 1040 : 3221481062400.0
Loss at iteration 1050 : 1065749643264.0
Loss at iteration 1060 : 24619541069824.0
Loss at iteration 1070 : 5048785960960.0
Loss at iteration 1080 : 9411461382144.0
Loss at iteration 1090 : 16336589684736.0
Loss at iteration 1100 : 1504191971328.0
Loss at iteration 1110 : 295553957888.0
Loss at iteration 1120 : 5685071314944.0
Loss at iteration 1130 : 352421445632.0
Loss at iteration 1140 : 2505170223104.0
Loss at iteration 1150 : 454052118528.0
Loss at iteration 1160 : 7074927345664.0
Loss at iteration 1170 : 2492533309440.0
Loss at iteration 1180 : 3282501107712.0
Loss at iteration 1190 : 2087005192192.0
Loss at iteration 1200 : 2106488782848.0
Loss at iteration 1210 : 821318057984.0
Loss at iteration 1220 : 1157101518848.0
Loss at iteration 1230 : 1485563625472.0
Loss at iteration 1240 : 192692649984.0
Loss at iteration 1250 : 19961030377472.0
Loss at iteration 1260 : 9457819975680.0
Loss at iteration 1270 : 4457275850752.0
Loss at iteration 1280 : 3851072831488.0
Loss at iteration 1290 : 4078436614144.0
Loss at iteration 1300 : 4055500587008.0
Loss at iteration 1310 : 38212667965440.0
Loss at iteration 1320 : 9379395928064.0
Loss at iteration 1330 : 10506524950528.0
Loss at iteration 1340 : 3486960844800.0
Loss at iteration 1350 : 11832474468352.0
Loss at iteration 1360 : 27155981402112.0
Loss at iteration 1370 : 1803089215488.0
Loss at iteration 1380 : 13378083880960.0
Loss at iteration 1390 : 4041704734720.0
Loss at iteration 1400 : 9807456108544.0
Loss at iteration 1410 : 20122374766592.0
Loss at iteration 1420 : 2983326646272.0
Loss at iteration 1430 : 7551295422464.0
Loss at iteration 1440 : 1281790705664.0
Loss at iteration 1450 : 5496216485888.0
Loss at iteration 1460 : 10469986271232.0
Loss at iteration 1470 : 818214469632.0
Loss at iteration 1480 : 15596723896320.0
Loss at iteration 1490 : 358099124224.0
Loss at iteration 1500 : 1361848041472.0
Loss at iteration 1510 : 28274071699456.0
Loss at iteration 1520 : 5517163364352.0
Loss at iteration 1530 : 5458221334528.0
Loss at iteration 1540 : 511929909248.0
Loss at iteration 1550 : 3285106556928.0
Loss at iteration 1560 : 79603452346368.0
Loss at iteration 1570 : 1512788852736.0
Loss at iteration 1580 : 2338656092160.0
Loss at iteration 1590 : 8536714117120.0
Loss at iteration 1600 : 14078746558464.0
Loss at iteration 1610 : 867966058496.0
Loss at iteration 1620 : 481661190144.0
Loss at iteration 1630 : 378394312704.0
Loss at iteration 1640 : 1389053345792.0
Loss at iteration 1650 : 1372220162048.0
Loss at iteration 1660 : 3846423969792.0
Loss at iteration 1670 : 197842632704.0
Loss at iteration 1680 : 181785411584.0
Loss at iteration 1690 : 1498274725888.0
Loss at iteration 1700 : 2233075499008.0
Loss at iteration 1710 : 115195879424.0
Loss at iteration 1720 : 1570422390784.0
Loss at iteration 1730 : 826819674112.0
Loss at iteration 1740 : 14478191099904.0
Loss at iteration 1750 : 303521660928.0
Loss at iteration 1760 : 8073613148160.0
Loss at iteration 1770 : 2166382395392.0
Loss at iteration 1780 : 1706003398656.0
Loss at iteration 1790 : 898106327040.0
Loss at iteration 1800 : 1425473798144.0
Loss at iteration 1810 : 304256548864.0
Loss at iteration 1820 : 2763829280768.0
Loss at iteration 1830 : 199636959232.0
Loss at iteration 1840 : 1757921411072.0
Loss at iteration 1850 : 98451267584.0
Loss at iteration 1860 : 133014282240.0
Loss at iteration 1870 : 2098248810496.0
Loss at iteration 1880 : 215444193280.0
Loss at iteration 1890 : 335007907840.0
Loss at iteration 1900 : 927769952256.0
Loss at iteration 1910 : 304590422016.0
Loss at iteration 1920 : 385504083968.0
Loss at iteration 1930 : 332134449152.0
Loss at iteration 1940 : 630691004416.0
Loss at iteration 1950 : 313814417408.0
Loss at iteration 1960 : 2502239715328.0
Loss at iteration 1970 : 901327683584.0
Loss at iteration 1980 : 6652984557568.0
Loss at iteration 1990 : 592938074112.0
Loss at iteration 2000 : 2794217275392.0
Loss at iteration 2010 : 10342193168384.0
Loss at iteration 2020 : 93501628416.0
Loss at iteration 2030 : 2082345189376.0
Loss at iteration 2040 : 1217393721344.0
Loss at iteration 2050 : 2629824151552.0
Loss at iteration 2060 : 4238909636608.0
Loss at iteration 2070 : 89474763587584.0
Loss at iteration 2080 : 1504511655936.0
Loss at iteration 2090 : 10188031524864.0
Loss at iteration 2100 : 79700114276352.0
Loss at iteration 2110 : 27392374472704.0
Loss at iteration 2120 : 33485469253632.0
Loss at iteration 2130 : 31723966431232.0
Loss at iteration 2140 : 24147107250176.0
Loss at iteration 2150 : 19000650104832.0
Loss at iteration 2160 : 19704422858752.0
Loss at iteration 2170 : 3878154928128.0
Loss at iteration 2180 : 6792275296256.0
Loss at iteration 2190 : 20579723771904.0
Loss at iteration 2200 : 23678779654144.0
Loss at iteration 2210 : 9077073641472.0
Loss at iteration 2220 : 9405249617920.0
Loss at iteration 2230 : 22020192468992.0
Loss at iteration 2240 : 4249589645312.0
Loss at iteration 2250 : 15782304022528.0
Loss at iteration 2260 : 26523719434240.0
Loss at iteration 2270 : 12592983572480.0
Loss at iteration 2280 : 11509085241344.0
Loss at iteration 2290 : 16974943879168.0
Loss at iteration 2300 : 6139618000896.0
Loss at iteration 2310 : 11068322611200.0
Loss at iteration 2320 : 9053126262784.0
Loss at iteration 2330 : 15549153148928.0
Loss at iteration 2340 : 37198942437376.0
Loss at iteration 2350 : 10777482231808.0
Loss at iteration 2360 : 78830056243200.0
Loss at iteration 2370 : 10225035771904.0
Loss at iteration 2380 : 1911410786304.0
Loss at iteration 2390 : 2426030260224.0
Loss at iteration 2400 : 1625609732096.0
Loss at iteration 2410 : 2501389844480.0
Loss at iteration 2420 : 224559316992.0
The SSIM Value is: 6.209370637103954e-06
The PSNR Value is: -137.71572570800782
the epoch is: 177
Loss at iteration 10 : 903399931904.0
Loss at iteration 20 : 2698428547072.0
Loss at iteration 30 : 94285781270528.0
Loss at iteration 40 : 15350397665280.0
Loss at iteration 50 : 3162010288128.0
Loss at iteration 60 : 33899891654656.0
Loss at iteration 70 : 12698964197376.0
Loss at iteration 80 : 4038639747072.0
Loss at iteration 90 : 6302198136832.0
Loss at iteration 100 : 3762809470976.0
Loss at iteration 110 : 4074543775744.0
Loss at iteration 120 : 1573959237632.0
Loss at iteration 130 : 7771858665472.0
Loss at iteration 140 : 7177680453632.0
Loss at iteration 150 : 9414910148608.0
Loss at iteration 160 : 3756937183232.0
Loss at iteration 170 : 934728171520.0
Loss at iteration 180 : 4576785727488.0
Loss at iteration 190 : 4785095835648.0
Loss at iteration 200 : 2363777089536.0
Loss at iteration 210 : 1644321439744.0
Loss at iteration 220 : 5841620566016.0
Loss at iteration 230 : 3370636017664.0
Loss at iteration 240 : 43838622138368.0
Loss at iteration 250 : 951796432896.0
Loss at iteration 260 : 10454154870784.0
Loss at iteration 270 : 3383327719424.0
Loss at iteration 280 : 3089244618752.0
Loss at iteration 290 : 4266767155200.0
Loss at iteration 300 : 1706800971776.0
Loss at iteration 310 : 4163754000384.0
Loss at iteration 320 : 5804342640640.0
Loss at iteration 330 : 3126980509696.0
Loss at iteration 340 : 2103932223488.0
Loss at iteration 350 : 12475751727104.0
Loss at iteration 360 : 1949481172992.0
Loss at iteration 370 : 3330833383424.0
Loss at iteration 380 : 936150827008.0
Loss at iteration 390 : 311997628416.0
Loss at iteration 400 : 714713661440.0
Loss at iteration 410 : 4028502638592.0
Loss at iteration 420 : 3447094771712.0
Loss at iteration 430 : 468775731200.0
Loss at iteration 440 : 522001809408.0
Loss at iteration 450 : 1505324433408.0
Loss at iteration 460 : 550833356800.0
Loss at iteration 470 : 2604738281472.0
Loss at iteration 480 : 11328638943232.0
Loss at iteration 490 : 913207787520.0
Loss at iteration 500 : 666674200576.0
Loss at iteration 510 : 7991875600384.0
Loss at iteration 520 : 20599170662400.0
Loss at iteration 530 : 1785977372672.0
Loss at iteration 540 : 3605956919296.0
Loss at iteration 550 : 7461094817792.0
Loss at iteration 560 : 620520275968.0
Loss at iteration 570 : 319417450496.0
Loss at iteration 580 : 734287560704.0
Loss at iteration 590 : 1553851744256.0
Loss at iteration 600 : 10040221106176.0
Loss at iteration 610 : 3775910903808.0
Loss at iteration 620 : 1151606849536.0
Loss at iteration 630 : 492455067648.0
Loss at iteration 640 : 687488106496.0
Loss at iteration 650 : 3912267726848.0
Loss at iteration 660 : 396578095104.0
Loss at iteration 670 : 2245265457152.0
Loss at iteration 680 : 7728464920576.0
Loss at iteration 690 : 2173677076480.0
Loss at iteration 700 : 507793997824.0
Loss at iteration 710 : 9909442707456.0
Loss at iteration 720 : 774800867328.0
Loss at iteration 730 : 731196489728.0
Loss at iteration 740 : 635984216064.0
Loss at iteration 750 : 696568053760.0
Loss at iteration 760 : 1945548881920.0
Loss at iteration 770 : 4024157339648.0
Loss at iteration 780 : 1630657708032.0
Loss at iteration 790 : 1214076289024.0
Loss at iteration 800 : 5989873483776.0
Loss at iteration 810 : 5595139670016.0
Loss at iteration 820 : 7659852922880.0
Loss at iteration 830 : 2046117543936.0
Loss at iteration 840 : 3100790489088.0
Loss at iteration 850 : 3504065216512.0
Loss at iteration 860 : 5653978415104.0
Loss at iteration 870 : 713634414592.0
Loss at iteration 880 : 1380258414592.0
Loss at iteration 890 : 361339355136.0
Loss at iteration 900 : 2332665577472.0
Loss at iteration 910 : 984794791936.0
Loss at iteration 920 : 719048015872.0
Loss at iteration 930 : 168186134528.0
Loss at iteration 940 : 18113187807232.0
Loss at iteration 950 : 709461147648.0
Loss at iteration 960 : 637886726144.0
Loss at iteration 970 : 262959071232.0
Loss at iteration 980 : 271259811840.0
Loss at iteration 990 : 1599646990336.0
Loss at iteration 1000 : 2641448140800.0
Loss at iteration 1010 : 1320969175040.0
Loss at iteration 1020 : 272559865856.0
Loss at iteration 1030 : 293888327680.0
Loss at iteration 1040 : 625245945856.0
Loss at iteration 1050 : 53209804800.0
Loss at iteration 1060 : 152085266432.0
Loss at iteration 1070 : 196192567296.0
Loss at iteration 1080 : 897204551680.0
Loss at iteration 1090 : 111035465728.0
Loss at iteration 1100 : 1319223296000.0
Loss at iteration 1110 : 816997990400.0
Loss at iteration 1120 : 51201925120.0
Loss at iteration 1130 : 2802530910208.0
Loss at iteration 1140 : 97744224256.0
Loss at iteration 1150 : 690370510848.0
Loss at iteration 1160 : 365203881984.0
Loss at iteration 1170 : 89512779776.0
Loss at iteration 1180 : 538563051520.0
Loss at iteration 1190 : 174465515520.0
Loss at iteration 1200 : 228860657664.0
Loss at iteration 1210 : 78073503744.0
Loss at iteration 1220 : 278686466048.0
Loss at iteration 1230 : 1409560346624.0
Loss at iteration 1240 : 1995794808832.0
Loss at iteration 1250 : 813903773696.0
Loss at iteration 1260 : 431199518720.0
Loss at iteration 1270 : 557624000512.0
Loss at iteration 1280 : 484277256192.0
Loss at iteration 1290 : 303140798464.0
Loss at iteration 1300 : 1272731009024.0
Loss at iteration 1310 : 229660442624.0
Loss at iteration 1320 : 886171172864.0
Loss at iteration 1330 : 285246717952.0
Loss at iteration 1340 : 253778345984.0
Loss at iteration 1350 : 228983095296.0
Loss at iteration 1360 : 162928574464.0
Loss at iteration 1370 : 1818503413760.0
Loss at iteration 1380 : 512537034752.0
Loss at iteration 1390 : 342331850752.0
Loss at iteration 1400 : 320555745280.0
Loss at iteration 1410 : 2016941572096.0
Loss at iteration 1420 : 346752385024.0
Loss at iteration 1430 : 1275519827968.0
Loss at iteration 1440 : 110258905088.0
Loss at iteration 1450 : 206469939200.0
Loss at iteration 1460 : 531156729856.0
Loss at iteration 1470 : 409000116224.0
Loss at iteration 1480 : 109262266368.0
Loss at iteration 1490 : 211720830976.0
Loss at iteration 1500 : 100157267968.0
Loss at iteration 1510 : 133663850496.0
Loss at iteration 1520 : 533979365376.0
Loss at iteration 1530 : 352741982208.0
Loss at iteration 1540 : 251941994496.0
Loss at iteration 1550 : 976546627584.0
Loss at iteration 1560 : 90913718272.0
Loss at iteration 1570 : 130306875392.0
Loss at iteration 1580 : 13797951488.0
Loss at iteration 1590 : 981335867392.0
Loss at iteration 1600 : 360080441344.0
Loss at iteration 1610 : 451332505600.0
Loss at iteration 1620 : 90309828608.0
Loss at iteration 1630 : 663928700928.0
Loss at iteration 1640 : 4740124508160.0
Loss at iteration 1650 : 830224662528.0
Loss at iteration 1660 : 1352128659456.0
Loss at iteration 1670 : 331640963072.0
Loss at iteration 1680 : 301553647616.0
Loss at iteration 1690 : 710591184896.0
Loss at iteration 1700 : 2677093171200.0
Loss at iteration 1710 : 1822932336640.0
Loss at iteration 1720 : 979451445248.0
Loss at iteration 1730 : 108507308032.0
Loss at iteration 1740 : 108531376128.0
Loss at iteration 1750 : 161961508864.0
Loss at iteration 1760 : 133978931200.0
Loss at iteration 1770 : 1138582618112.0
Loss at iteration 1780 : 117373894656.0
Loss at iteration 1790 : 141058654208.0
Loss at iteration 1800 : 986171244544.0
Loss at iteration 1810 : 195355344896.0
Loss at iteration 1820 : 731677720576.0
Loss at iteration 1830 : 733284663296.0
Loss at iteration 1840 : 523307253760.0
Loss at iteration 1850 : 300762169344.0
Loss at iteration 1860 : 135637925888.0
Loss at iteration 1870 : 224581599232.0
Loss at iteration 1880 : 457447538688.0
Loss at iteration 1890 : 138431447040.0
Loss at iteration 1900 : 445681991680.0
Loss at iteration 1910 : 282613940224.0
Loss at iteration 1920 : 68206342144.0
Loss at iteration 1930 : 381239328768.0
Loss at iteration 1940 : 509852385280.0
Loss at iteration 1950 : 1550778368000.0
Loss at iteration 1960 : 123622785024.0
Loss at iteration 1970 : 309750988800.0
Loss at iteration 1980 : 155170308096.0
Loss at iteration 1990 : 98683527168.0
Loss at iteration 2000 : 1764855644160.0
Loss at iteration 2010 : 286831804416.0
Loss at iteration 2020 : 583708377088.0
Loss at iteration 2030 : 341299593216.0
Loss at iteration 2040 : 325558206464.0
Loss at iteration 2050 : 350626316288.0
Loss at iteration 2060 : 579584786432.0
Loss at iteration 2070 : 142463549440.0
Loss at iteration 2080 : 304487006208.0
Loss at iteration 2090 : 406979444736.0
Loss at iteration 2100 : 671248416768.0
Loss at iteration 2110 : 179922894848.0
Loss at iteration 2120 : 93373480960.0
Loss at iteration 2130 : 108685631488.0
Loss at iteration 2140 : 198887555072.0
Loss at iteration 2150 : 629403090944.0
Loss at iteration 2160 : 574548541440.0
Loss at iteration 2170 : 1091642195968.0
Loss at iteration 2180 : 340190232576.0
Loss at iteration 2190 : 717309607936.0
Loss at iteration 2200 : 160070402048.0
Loss at iteration 2210 : 70622412800.0
Loss at iteration 2220 : 73287409664.0
Loss at iteration 2230 : 327634878464.0
Loss at iteration 2240 : 246723002368.0
Loss at iteration 2250 : 15662658560.0
Loss at iteration 2260 : 149996322816.0
Loss at iteration 2270 : 2205982916608.0
Loss at iteration 2280 : 115787980800.0
Loss at iteration 2290 : 67801616384.0
Loss at iteration 2300 : 258178433024.0
Loss at iteration 2310 : 783212740608.0
Loss at iteration 2320 : 190657429504.0
Loss at iteration 2330 : 227763453952.0
Loss at iteration 2340 : 241386438656.0
Loss at iteration 2350 : 1431889117184.0
Loss at iteration 2360 : 73991667712.0
Loss at iteration 2370 : 167524139008.0
Loss at iteration 2380 : 326723305472.0
Loss at iteration 2390 : 73764036608.0
Loss at iteration 2400 : 98001199104.0
Loss at iteration 2410 : 286981816320.0
Loss at iteration 2420 : 101627658240.0
The SSIM Value is: 4.737719979175381e-06
The PSNR Value is: -119.20080006917318
the epoch is: 178
Loss at iteration 10 : 786032427008.0
Loss at iteration 20 : 156690382848.0
Loss at iteration 30 : 405962883072.0
Loss at iteration 40 : 92009259008.0
Loss at iteration 50 : 942323990528.0
Loss at iteration 60 : 742619217920.0
Loss at iteration 70 : 583652802560.0
Loss at iteration 80 : 250322894848.0
Loss at iteration 90 : 989774544896.0
Loss at iteration 100 : 483233300480.0
Loss at iteration 110 : 2460663152640.0
Loss at iteration 120 : 175611920384.0
Loss at iteration 130 : 975143174144.0
Loss at iteration 140 : 1185177403392.0
Loss at iteration 150 : 1012010450944.0
Loss at iteration 160 : 65185693696.0
Loss at iteration 170 : 155228831744.0
Loss at iteration 180 : 206151024640.0
Loss at iteration 190 : 78571094016.0
Loss at iteration 200 : 1073597841408.0
Loss at iteration 210 : 1663367643136.0
Loss at iteration 220 : 680128348160.0
Loss at iteration 230 : 698852966400.0
Loss at iteration 240 : 1551961030656.0
Loss at iteration 250 : 643505979392.0
Loss at iteration 260 : 473528303616.0
Loss at iteration 270 : 87597285376.0
Loss at iteration 280 : 20839669760.0
Loss at iteration 290 : 168839249920.0
Loss at iteration 300 : 245837398016.0
Loss at iteration 310 : 556080758784.0
Loss at iteration 320 : 105026674688.0
Loss at iteration 330 : 854799941632.0
Loss at iteration 340 : 483600105472.0
Loss at iteration 350 : 196692148224.0
Loss at iteration 360 : 40781287424.0
Loss at iteration 370 : 212125073408.0
Loss at iteration 380 : 47724048384.0
Loss at iteration 390 : 361844801536.0
Loss at iteration 400 : 82403639296.0
Loss at iteration 410 : 347429175296.0
Loss at iteration 420 : 446106140672.0
Loss at iteration 430 : 227642458112.0
Loss at iteration 440 : 43173806080.0
Loss at iteration 450 : 444183052288.0
Loss at iteration 460 : 320559054848.0
Loss at iteration 470 : 68079980544.0
Loss at iteration 480 : 1538446065664.0
Loss at iteration 490 : 199486406656.0
Loss at iteration 500 : 120681250816.0
Loss at iteration 510 : 534891724800.0
Loss at iteration 520 : 39366062080.0
Loss at iteration 530 : 757586853888.0
Loss at iteration 540 : 330641244160.0
Loss at iteration 550 : 67239256064.0
Loss at iteration 560 : 135351394304.0
Loss at iteration 570 : 51908595712.0
Loss at iteration 580 : 115215867904.0
Loss at iteration 590 : 673777647616.0
Loss at iteration 600 : 245600354304.0
Loss at iteration 610 : 103433797632.0
Loss at iteration 620 : 186578583552.0
Loss at iteration 630 : 117665718272.0
Loss at iteration 640 : 27400642560.0
Loss at iteration 650 : 55584104448.0
Loss at iteration 660 : 42325651456.0
Loss at iteration 670 : 475332378624.0
Loss at iteration 680 : 74830405632.0
Loss at iteration 690 : 141769703424.0
Loss at iteration 700 : 91014569984.0
Loss at iteration 710 : 26196447232.0
Loss at iteration 720 : 241405870080.0
Loss at iteration 730 : 852785561600.0
Loss at iteration 740 : 6507963392.0
Loss at iteration 750 : 103257808896.0
Loss at iteration 760 : 59956461568.0
Loss at iteration 770 : 54542401536.0
Loss at iteration 780 : 1002710695936.0
Loss at iteration 790 : 1607789051904.0
Loss at iteration 800 : 13762468773888.0
Loss at iteration 810 : 2452207697920.0
Loss at iteration 820 : 504608980992.0
Loss at iteration 830 : 499507396608.0
Loss at iteration 840 : 62955593728.0
Loss at iteration 850 : 2759674036224.0
Loss at iteration 860 : 1040184115200.0
Loss at iteration 870 : 951788306432.0
Loss at iteration 880 : 11952061415424.0
Loss at iteration 890 : 1992498216960.0
Loss at iteration 900 : 3931213660160.0
Loss at iteration 910 : 8014575697920.0
Loss at iteration 920 : 23834038108160.0
Loss at iteration 930 : 760129716224.0
Loss at iteration 940 : 1051017019392.0
Loss at iteration 950 : 6366234148864.0
Loss at iteration 960 : 10866345902080.0
Loss at iteration 970 : 9311157747712.0
Loss at iteration 980 : 3193879920640.0
Loss at iteration 990 : 10601772351488.0
Loss at iteration 1000 : 857967820800.0
Loss at iteration 1010 : 1211981234176.0
Loss at iteration 1020 : 475978956800.0
Loss at iteration 1030 : 2618522599424.0
Loss at iteration 1040 : 3283808419840.0
Loss at iteration 1050 : 16802532818944.0
Loss at iteration 1060 : 190625103872.0
Loss at iteration 1070 : 502072082432.0
Loss at iteration 1080 : 1161759948800.0
Loss at iteration 1090 : 616492367872.0
Loss at iteration 1100 : 1618742214656.0
Loss at iteration 1110 : 1874222645248.0
Loss at iteration 1120 : 697200345088.0
Loss at iteration 1130 : 1883357184000.0
Loss at iteration 1140 : 177218699264.0
Loss at iteration 1150 : 903231242240.0
Loss at iteration 1160 : 634030063616.0
Loss at iteration 1170 : 363515576320.0
Loss at iteration 1180 : 888478367744.0
Loss at iteration 1190 : 427440209920.0
Loss at iteration 1200 : 214479421440.0
Loss at iteration 1210 : 134516727808.0
Loss at iteration 1220 : 57821458432.0
Loss at iteration 1230 : 102615883776.0
Loss at iteration 1240 : 708224679936.0
Loss at iteration 1250 : 973284311040.0
Loss at iteration 1260 : 207409954816.0
Loss at iteration 1270 : 186304053248.0
Loss at iteration 1280 : 238846607360.0
Loss at iteration 1290 : 1012550336512.0
Loss at iteration 1300 : 152508858368.0
Loss at iteration 1310 : 2038878044160.0
Loss at iteration 1320 : 101156552704.0
Loss at iteration 1330 : 118736764928.0
Loss at iteration 1340 : 1517345964032.0
Loss at iteration 1350 : 1619976650752.0
Loss at iteration 1360 : 41592930304.0
Loss at iteration 1370 : 107423973376.0
Loss at iteration 1380 : 1003266441216.0
Loss at iteration 1390 : 870358188032.0
Loss at iteration 1400 : 142692728832.0
Loss at iteration 1410 : 338499698688.0
Loss at iteration 1420 : 229442732032.0
Loss at iteration 1430 : 35571580928.0
Loss at iteration 1440 : 74241662976.0
Loss at iteration 1450 : 181960245248.0
Loss at iteration 1460 : 864099368960.0
Loss at iteration 1470 : 250288570368.0
Loss at iteration 1480 : 1660155068416.0
Loss at iteration 1490 : 217901809664.0
Loss at iteration 1500 : 931470704640.0
Loss at iteration 1510 : 127615631360.0
Loss at iteration 1520 : 655403581440.0
Loss at iteration 1530 : 203562172416.0
Loss at iteration 1540 : 308978515968.0
Loss at iteration 1550 : 189735190528.0
Loss at iteration 1560 : 37592526848.0
Loss at iteration 1570 : 1381527846912.0
Loss at iteration 1580 : 387789455360.0
Loss at iteration 1590 : 191600115712.0
Loss at iteration 1600 : 209142759424.0
Loss at iteration 1610 : 118965780480.0
Loss at iteration 1620 : 1779584991232.0
Loss at iteration 1630 : 192852705280.0
Loss at iteration 1640 : 1225803825152.0
Loss at iteration 1650 : 634246463488.0
Loss at iteration 1660 : 195837640704.0
Loss at iteration 1670 : 258850258944.0
Loss at iteration 1680 : 175601614848.0
Loss at iteration 1690 : 306406686720.0
Loss at iteration 1700 : 28580331520.0
Loss at iteration 1710 : 630438887424.0
Loss at iteration 1720 : 104217403392.0
Loss at iteration 1730 : 121798901760.0
Loss at iteration 1740 : 505286623232.0
Loss at iteration 1750 : 79875973120.0
Loss at iteration 1760 : 95931334656.0
Loss at iteration 1770 : 367618195456.0
Loss at iteration 1780 : 84300701696.0
Loss at iteration 1790 : 127543238656.0
Loss at iteration 1800 : 160730349568.0
Loss at iteration 1810 : 353243332608.0
Loss at iteration 1820 : 61869088768.0
Loss at iteration 1830 : 140473483264.0
Loss at iteration 1840 : 19174733824.0
Loss at iteration 1850 : 209366548480.0
Loss at iteration 1860 : 58556432384.0
Loss at iteration 1870 : 706158002176.0
Loss at iteration 1880 : 92376686592.0
Loss at iteration 1890 : 19784992768.0
Loss at iteration 1900 : 31815862272.0
Loss at iteration 1910 : 3870592073728.0
Loss at iteration 1920 : 35474223104.0
Loss at iteration 1930 : 255958859776.0
Loss at iteration 1940 : 77732413440.0
Loss at iteration 1950 : 518481149952.0
Loss at iteration 1960 : 72588713984.0
Loss at iteration 1970 : 188413952000.0
Loss at iteration 1980 : 50810707968.0
Loss at iteration 1990 : 223072616448.0
Loss at iteration 2000 : 154621788160.0
Loss at iteration 2010 : 40996134912.0
Loss at iteration 2020 : 161727135744.0
Loss at iteration 2030 : 294103842816.0
Loss at iteration 2040 : 92259721216.0
Loss at iteration 2050 : 232991752192.0
Loss at iteration 2060 : 33672816640.0
Loss at iteration 2070 : 230797197312.0
Loss at iteration 2080 : 31540830208.0
Loss at iteration 2090 : 82068496384.0
Loss at iteration 2100 : 20108584960.0
Loss at iteration 2110 : 244340391936.0
Loss at iteration 2120 : 95957032960.0
Loss at iteration 2130 : 107709939712.0
Loss at iteration 2140 : 102929842176.0
Loss at iteration 2150 : 42182647808.0
Loss at iteration 2160 : 110701584384.0
Loss at iteration 2170 : 193030815744.0
Loss at iteration 2180 : 161829617664.0
Loss at iteration 2190 : 109280346112.0
Loss at iteration 2200 : 702060429312.0
Loss at iteration 2210 : 295973453824.0
Loss at iteration 2220 : 38783528960.0
Loss at iteration 2230 : 49988300800.0
Loss at iteration 2240 : 37887868928.0
Loss at iteration 2250 : 262604750848.0
Loss at iteration 2260 : 39953629184.0
Loss at iteration 2270 : 233840656384.0
Loss at iteration 2280 : 91212955648.0
Loss at iteration 2290 : 229214748672.0
Loss at iteration 2300 : 66671878144.0
Loss at iteration 2310 : 1846422536192.0
Loss at iteration 2320 : 100159078400.0
Loss at iteration 2330 : 46083420160.0
Loss at iteration 2340 : 30954842112.0
Loss at iteration 2350 : 83606552576.0
Loss at iteration 2360 : 14545269760.0
Loss at iteration 2370 : 77566083072.0
Loss at iteration 2380 : 8010928640.0
Loss at iteration 2390 : 124365012992.0
Loss at iteration 2400 : 651483283456.0
Loss at iteration 2410 : 87952220160.0
Loss at iteration 2420 : 16073309184.0
The SSIM Value is: 1.1698464072651405e-05
The PSNR Value is: -117.95273234049479
the epoch is: 179
Loss at iteration 10 : 16339227648.0
Loss at iteration 20 : 155054866432.0
Loss at iteration 30 : 34301384704.0
Loss at iteration 40 : 18929938432.0
Loss at iteration 50 : 27755745280.0
Loss at iteration 60 : 44805754880.0
Loss at iteration 70 : 16267895808.0
Loss at iteration 80 : 80894050304.0
Loss at iteration 90 : 37964722176.0
Loss at iteration 100 : 55963414528.0
Loss at iteration 110 : 124611592192.0
Loss at iteration 120 : 71543234560.0
Loss at iteration 130 : 203237015552.0
Loss at iteration 140 : 70630588416.0
Loss at iteration 150 : 33996744704.0
Loss at iteration 160 : 20939112448.0
Loss at iteration 170 : 54962728960.0
Loss at iteration 180 : 92307668992.0
Loss at iteration 190 : 20323770368.0
Loss at iteration 200 : 445429809152.0
Loss at iteration 210 : 56842141696.0
Loss at iteration 220 : 235898716160.0
Loss at iteration 230 : 29027092480.0
Loss at iteration 240 : 34979303424.0
Loss at iteration 250 : 59506880512.0
Loss at iteration 260 : 20427763712.0
Loss at iteration 270 : 73341075456.0
Loss at iteration 280 : 24958048256.0
Loss at iteration 290 : 70370222080.0
Loss at iteration 300 : 68981334016.0
Loss at iteration 310 : 95714099200.0
Loss at iteration 320 : 11511930880.0
Loss at iteration 330 : 20049022976.0
Loss at iteration 340 : 74248642560.0
Loss at iteration 350 : 59950526464.0
Loss at iteration 360 : 251395964928.0
Loss at iteration 370 : 46805774336.0
Loss at iteration 380 : 56742047744.0
Loss at iteration 390 : 404647837696.0
Loss at iteration 400 : 30311544832.0
Loss at iteration 410 : 80237207552.0
Loss at iteration 420 : 9626802192384.0
Loss at iteration 430 : 1013660319744.0
Loss at iteration 440 : 542989582336.0
Loss at iteration 450 : 361143959552.0
Loss at iteration 460 : 3303341817856.0
Loss at iteration 470 : 209990729728.0
Loss at iteration 480 : 280888672256.0
Loss at iteration 490 : 32809123840.0
Loss at iteration 500 : 4611911450624.0
Loss at iteration 510 : 953175310336.0
Loss at iteration 520 : 1792843710464.0
Loss at iteration 530 : 614830702592.0
Loss at iteration 540 : 417070252032.0
Loss at iteration 550 : 1432904663040.0
Loss at iteration 560 : 1061335007232.0
Loss at iteration 570 : 2214523305984.0
Loss at iteration 580 : 4926268243968.0
Loss at iteration 590 : 5780689911808.0
Loss at iteration 600 : 551240728576.0
Loss at iteration 610 : 389773328384.0
Loss at iteration 620 : 1692282519552.0
Loss at iteration 630 : 1351876214784.0
Loss at iteration 640 : 940233195520.0
Loss at iteration 650 : 56029560832.0
Loss at iteration 660 : 629520465920.0
Loss at iteration 670 : 368977608704.0
Loss at iteration 680 : 1903646081024.0
Loss at iteration 690 : 163473326080.0
Loss at iteration 700 : 249910034432.0
Loss at iteration 710 : 207036137472.0
Loss at iteration 720 : 66687909888.0
Loss at iteration 730 : 51454218240.0
Loss at iteration 740 : 345742737408.0
Loss at iteration 750 : 45624008704.0
Loss at iteration 760 : 52713529344.0
Loss at iteration 770 : 68411584512.0
Loss at iteration 780 : 32254451712.0
Loss at iteration 790 : 467663486976.0
Loss at iteration 800 : 16456501248.0
Loss at iteration 810 : 55128518656.0
Loss at iteration 820 : 79261048832.0
Loss at iteration 830 : 72924504064.0
Loss at iteration 840 : 13228356608.0
Loss at iteration 850 : 105280831488.0
Loss at iteration 860 : 14871585792.0
Loss at iteration 870 : 78477508608.0
Loss at iteration 880 : 18494085120.0
Loss at iteration 890 : 6683713536.0
Loss at iteration 900 : 38421630976.0
Loss at iteration 910 : 124695937024.0
Loss at iteration 920 : 22206466048.0
Loss at iteration 930 : 62759821312.0
Loss at iteration 940 : 130977456128.0
Loss at iteration 950 : 15892238336.0
Loss at iteration 960 : 103628251136.0
Loss at iteration 970 : 311034740736.0
Loss at iteration 980 : 18950625280.0
Loss at iteration 990 : 159737151488.0
Loss at iteration 1000 : 21535422464.0
Loss at iteration 1010 : 12430516224.0
Loss at iteration 1020 : 54528487424.0
Loss at iteration 1030 : 113386307584.0
Loss at iteration 1040 : 67790610432.0
Loss at iteration 1050 : 70169321472.0
Loss at iteration 1060 : 5070181888.0
Loss at iteration 1070 : 69475049472.0
Loss at iteration 1080 : 26004602880.0
Loss at iteration 1090 : 61704880128.0
Loss at iteration 1100 : 292099227648.0
Loss at iteration 1110 : 6648939520.0
Loss at iteration 1120 : 26211543040.0
Loss at iteration 1130 : 58826792960.0
Loss at iteration 1140 : 63616655360.0
Loss at iteration 1150 : 9275489280.0
Loss at iteration 1160 : 22824050688.0
Loss at iteration 1170 : 7567145984.0
Loss at iteration 1180 : 35842859008.0
Loss at iteration 1190 : 13802220544.0
Loss at iteration 1200 : 23653410816.0
Loss at iteration 1210 : 7637104128.0
Loss at iteration 1220 : 176231120896.0
Loss at iteration 1230 : 42712293376.0
Loss at iteration 1240 : 17745336320.0
Loss at iteration 1250 : 14201440256.0
Loss at iteration 1260 : 27342970880.0
Loss at iteration 1270 : 9616908288.0
Loss at iteration 1280 : 19530962944.0
Loss at iteration 1290 : 31274428416.0
Loss at iteration 1300 : 20803899392.0
Loss at iteration 1310 : 29525403648.0
Loss at iteration 1320 : 9432786944.0
Loss at iteration 1330 : 32018092032.0
Loss at iteration 1340 : 4596359168.0
Loss at iteration 1350 : 10576264192.0
Loss at iteration 1360 : 83636117504.0
Loss at iteration 1370 : 31700168704.0
Loss at iteration 1380 : 95939788800.0
Loss at iteration 1390 : 3750572288.0
Loss at iteration 1400 : 16137766912.0
Loss at iteration 1410 : 13097474048.0
Loss at iteration 1420 : 176767156224.0
Loss at iteration 1430 : 75460280320.0
Loss at iteration 1440 : 1822227072.0
Loss at iteration 1450 : 132719353856.0
Loss at iteration 1460 : 10764483584.0
Loss at iteration 1470 : 69036408832.0
Loss at iteration 1480 : 23230253056.0
Loss at iteration 1490 : 6486732288.0
Loss at iteration 1500 : 20150599680.0
Loss at iteration 1510 : 24679145472.0
Loss at iteration 1520 : 54293434368.0
Loss at iteration 1530 : 65825103872.0
Loss at iteration 1540 : 367754313728.0
Loss at iteration 1550 : 52452888576.0
Loss at iteration 1560 : 113500372992.0
Loss at iteration 1570 : 31564859392.0
Loss at iteration 1580 : 40775585792.0
Loss at iteration 1590 : 13978216448.0
Loss at iteration 1600 : 156328984576.0
Loss at iteration 1610 : 132089749504.0
Loss at iteration 1620 : 16893864960.0
Loss at iteration 1630 : 12342300672.0
Loss at iteration 1640 : 52685565952.0
Loss at iteration 1650 : 89905586176.0
Loss at iteration 1660 : 56270811136.0
Loss at iteration 1670 : 21832220672.0
Loss at iteration 1680 : 5667460608.0
Loss at iteration 1690 : 33240397824.0
Loss at iteration 1700 : 123897061376.0
Loss at iteration 1710 : 21375617024.0
Loss at iteration 1720 : 26363109376.0
Loss at iteration 1730 : 71627120640.0
Loss at iteration 1740 : 103573921792.0
Loss at iteration 1750 : 41074294784.0
Loss at iteration 1760 : 43217100800.0
Loss at iteration 1770 : 24437192704.0
Loss at iteration 1780 : 15492206592.0
Loss at iteration 1790 : 93182967808.0
Loss at iteration 1800 : 12843880448.0
Loss at iteration 1810 : 12088336384.0
Loss at iteration 1820 : 13300068352.0
Loss at iteration 1830 : 17004006400.0
Loss at iteration 1840 : 61098536960.0
Loss at iteration 1850 : 24101070848.0
Loss at iteration 1860 : 76580274176.0
Loss at iteration 1870 : 63224643584.0
Loss at iteration 1880 : 161886126080.0
Loss at iteration 1890 : 34839863296.0
Loss at iteration 1900 : 706139193344.0
Loss at iteration 1910 : 36097093632.0
Loss at iteration 1920 : 229546622976.0
Loss at iteration 1930 : 27295686656.0
Loss at iteration 1940 : 7783418880.0
Loss at iteration 1950 : 121631522816.0
Loss at iteration 1960 : 2687541504.0
Loss at iteration 1970 : 29750253568.0
Loss at iteration 1980 : 38255955968.0
Loss at iteration 1990 : 84339056640.0
Loss at iteration 2000 : 27615975424.0
Loss at iteration 2010 : 77085818880.0
Loss at iteration 2020 : 13646570496.0
Loss at iteration 2030 : 52460224512.0
Loss at iteration 2040 : 3923556096.0
Loss at iteration 2050 : 9038586880.0
Loss at iteration 2060 : 19145803776.0
Loss at iteration 2070 : 7254296576.0
Loss at iteration 2080 : 6261026816.0
Loss at iteration 2090 : 34657304576.0
Loss at iteration 2100 : 31677540352.0
Loss at iteration 2110 : 25572220928.0
Loss at iteration 2120 : 17446014976.0
Loss at iteration 2130 : 23578712064.0
Loss at iteration 2140 : 80556400640.0
Loss at iteration 2150 : 22155569152.0
Loss at iteration 2160 : 31599409152.0
Loss at iteration 2170 : 41073147904.0
Loss at iteration 2180 : 6717111808.0
Loss at iteration 2190 : 64342945792.0
Loss at iteration 2200 : 13946594304.0
Loss at iteration 2210 : 35286155264.0
Loss at iteration 2220 : 5572548608.0
Loss at iteration 2230 : 32559108096.0
Loss at iteration 2240 : 30898411520.0
Loss at iteration 2250 : 45693394944.0
Loss at iteration 2260 : 1143411840.0
Loss at iteration 2270 : 23753539584.0
Loss at iteration 2280 : 50056273920.0
Loss at iteration 2290 : 10691171328.0
Loss at iteration 2300 : 129091321856.0
Loss at iteration 2310 : 1619850880.0
Loss at iteration 2320 : 2338873088.0
Loss at iteration 2330 : 15999499264.0
Loss at iteration 2340 : 67870437376.0
Loss at iteration 2350 : 200470544384.0
Loss at iteration 2360 : 204922011648.0
Loss at iteration 2370 : 781830062080.0
Loss at iteration 2380 : 47188410368.0
Loss at iteration 2390 : 411830779904.0
Loss at iteration 2400 : 304566763520.0
Loss at iteration 2410 : 418612936704.0
Loss at iteration 2420 : 198427492352.0
The SSIM Value is: 1.8930775877379346e-05
The PSNR Value is: -122.59233957926432
the epoch is: 180
Loss at iteration 10 : 162909372416.0
Loss at iteration 20 : 193331396608.0
Loss at iteration 30 : 11407011840.0
Loss at iteration 40 : 45025374208.0
Loss at iteration 50 : 91337547776.0
Loss at iteration 60 : 4313193381888.0
Loss at iteration 70 : 82890260480.0
Loss at iteration 80 : 23038595072.0
Loss at iteration 90 : 22756323328.0
Loss at iteration 100 : 9612782592.0
Loss at iteration 110 : 3546862336.0
Loss at iteration 120 : 697452658688.0
Loss at iteration 130 : 339817005056.0
Loss at iteration 140 : 304331751424.0
Loss at iteration 150 : 232882847744.0
Loss at iteration 160 : 67359014912.0
Loss at iteration 170 : 92097609728.0
Loss at iteration 180 : 42672111616.0
Loss at iteration 190 : 88320540672.0
Loss at iteration 200 : 40781598720.0
Loss at iteration 210 : 2467121920.0
Loss at iteration 220 : 196842307584.0
Loss at iteration 230 : 7229709312.0
Loss at iteration 240 : 54084149248.0
Loss at iteration 250 : 21167710208.0
Loss at iteration 260 : 1868720000.0
Loss at iteration 270 : 14156062720.0
Loss at iteration 280 : 4560516608.0
Loss at iteration 290 : 26004029440.0
Loss at iteration 300 : 32169953280.0
Loss at iteration 310 : 4400743424.0
Loss at iteration 320 : 16872644608.0
Loss at iteration 330 : 22429425664.0
Loss at iteration 340 : 69069455360.0
Loss at iteration 350 : 8339544576.0
Loss at iteration 360 : 4308418048.0
Loss at iteration 370 : 504394880.0
Loss at iteration 380 : 5731554304.0
Loss at iteration 390 : 42926981120.0
Loss at iteration 400 : 18194905088.0
Loss at iteration 410 : 16085049344.0
Loss at iteration 420 : 8720607232.0
Loss at iteration 430 : 15554609152.0
Loss at iteration 440 : 10663980032.0
Loss at iteration 450 : 1455213568.0
Loss at iteration 460 : 38140362752.0
Loss at iteration 470 : 2979263232.0
Loss at iteration 480 : 973252544.0
Loss at iteration 490 : 148725039104.0
Loss at iteration 500 : 7962217472.0
Loss at iteration 510 : 20002494464.0
Loss at iteration 520 : 19958870016.0
Loss at iteration 530 : 19496146944.0
Loss at iteration 540 : 113578647552.0
Loss at iteration 550 : 10504839168.0
Loss at iteration 560 : 14775116800.0
Loss at iteration 570 : 16368502784.0
Loss at iteration 580 : 6947347968.0
Loss at iteration 590 : 70939623424.0
Loss at iteration 600 : 4894061056.0
Loss at iteration 610 : 14921588736.0
Loss at iteration 620 : 5436997632.0
Loss at iteration 630 : 15567575040.0
Loss at iteration 640 : 7728457216.0
Loss at iteration 650 : 2484582912.0
Loss at iteration 660 : 91369652224.0
Loss at iteration 670 : 3256804608.0
Loss at iteration 680 : 5243516416.0
Loss at iteration 690 : 434769362944.0
Loss at iteration 700 : 39802576896.0
Loss at iteration 710 : 10864081920.0
Loss at iteration 720 : 3454007552.0
Loss at iteration 730 : 5275064832.0
Loss at iteration 740 : 41450299392.0
Loss at iteration 750 : 1493733120.0
Loss at iteration 760 : 4370077696.0
Loss at iteration 770 : 252941320192.0
Loss at iteration 780 : 3297414912.0
Loss at iteration 790 : 32826206208.0
Loss at iteration 800 : 5702379520.0
Loss at iteration 810 : 167868825600.0
Loss at iteration 820 : 6440302592.0
Loss at iteration 830 : 59460296704.0
Loss at iteration 840 : 6237362688.0
Loss at iteration 850 : 12492081152.0
Loss at iteration 860 : 2600377088.0
Loss at iteration 870 : 6505298944.0
Loss at iteration 880 : 35450753024.0
Loss at iteration 890 : 8460484096.0
Loss at iteration 900 : 68112187392.0
Loss at iteration 910 : 17721493504.0
Loss at iteration 920 : 5955798016.0
Loss at iteration 930 : 11278967808.0
Loss at iteration 940 : 23003549696.0
Loss at iteration 950 : 11187445760.0
Loss at iteration 960 : 16513526784.0
Loss at iteration 970 : 5793181696.0
Loss at iteration 980 : 2695976192.0
Loss at iteration 990 : 997118976.0
Loss at iteration 1000 : 4189645312.0
Loss at iteration 1010 : 7518064128.0
Loss at iteration 1020 : 1850564864.0
Loss at iteration 1030 : 8831184896.0
Loss at iteration 1040 : 3144542464.0
Loss at iteration 1050 : 5647582720.0
Loss at iteration 1060 : 6537231872.0
Loss at iteration 1070 : 5795299328.0
Loss at iteration 1080 : 3398177024.0
Loss at iteration 1090 : 3951509760.0
Loss at iteration 1100 : 793218112.0
Loss at iteration 1110 : 5541726208.0
Loss at iteration 1120 : 23062919168.0
Loss at iteration 1130 : 3422525952.0
Loss at iteration 1140 : 156339683328.0
Loss at iteration 1150 : 16075278336.0
Loss at iteration 1160 : 2223011584.0
Loss at iteration 1170 : 144552787968.0
Loss at iteration 1180 : 4521401344.0
Loss at iteration 1190 : 6781262848.0
Loss at iteration 1200 : 10725648384.0
Loss at iteration 1210 : 5236004864.0
Loss at iteration 1220 : 2842585088.0
Loss at iteration 1230 : 2630105856.0
Loss at iteration 1240 : 9767292928.0
Loss at iteration 1250 : 1569262848.0
Loss at iteration 1260 : 18797535232.0
Loss at iteration 1270 : 1478302208.0
Loss at iteration 1280 : 4951507456.0
Loss at iteration 1290 : 2081325440.0
Loss at iteration 1300 : 4058671616.0
Loss at iteration 1310 : 22833637376.0
Loss at iteration 1320 : 2131171200.0
Loss at iteration 1330 : 31421337600.0
Loss at iteration 1340 : 528740960.0
Loss at iteration 1350 : 4055288064.0
Loss at iteration 1360 : 1136233728.0
Loss at iteration 1370 : 509423840.0
Loss at iteration 1380 : 16453550080.0
Loss at iteration 1390 : 1571463552.0
Loss at iteration 1400 : 9234853888.0
Loss at iteration 1410 : 7676605440.0
Loss at iteration 1420 : 688246208.0
Loss at iteration 1430 : 8958205952.0
Loss at iteration 1440 : 26609080320.0
Loss at iteration 1450 : 14961645568.0
Loss at iteration 1460 : 10645915648.0
Loss at iteration 1470 : 225906704384.0
Loss at iteration 1480 : 33587103744.0
Loss at iteration 1490 : 581892440064.0
Loss at iteration 1500 : 195955572736.0
Loss at iteration 1510 : 39870042112.0
Loss at iteration 1520 : 23899348992.0
Loss at iteration 1530 : 13746794496.0
Loss at iteration 1540 : 7838701056.0
Loss at iteration 1550 : 4195650048.0
Loss at iteration 1560 : 7073873920.0
Loss at iteration 1570 : 33145044992.0
Loss at iteration 1580 : 42524950528.0
Loss at iteration 1590 : 9482346496.0
Loss at iteration 1600 : 21488988160.0
Loss at iteration 1610 : 81623416832.0
Loss at iteration 1620 : 29310625792.0
Loss at iteration 1630 : 10148262912.0
Loss at iteration 1640 : 7677696000.0
Loss at iteration 1650 : 71153410048.0
Loss at iteration 1660 : 20256851968.0
Loss at iteration 1670 : 7862062592.0
Loss at iteration 1680 : 4785942016.0
Loss at iteration 1690 : 3479365888.0
Loss at iteration 1700 : 12447685632.0
Loss at iteration 1710 : 41431224320.0
Loss at iteration 1720 : 66742394880.0
Loss at iteration 1730 : 7190356480.0
Loss at iteration 1740 : 9572099072.0
Loss at iteration 1750 : 6089046528.0
Loss at iteration 1760 : 6740131328.0
Loss at iteration 1770 : 52718678016.0
Loss at iteration 1780 : 16033608704.0
Loss at iteration 1790 : 17099564032.0
Loss at iteration 1800 : 4795169792.0
Loss at iteration 1810 : 36957306880.0
Loss at iteration 1820 : 104575361024.0
Loss at iteration 1830 : 56909553664.0
Loss at iteration 1840 : 10372851712.0
Loss at iteration 1850 : 134320799744.0
Loss at iteration 1860 : 5383925760.0
Loss at iteration 1870 : 7835300352.0
Loss at iteration 1880 : 34252161024.0
Loss at iteration 1890 : 332556664832.0
Loss at iteration 1900 : 14803884032.0
Loss at iteration 1910 : 2247306496.0
Loss at iteration 1920 : 26461237248.0
Loss at iteration 1930 : 1746455808.0
Loss at iteration 1940 : 15536741376.0
Loss at iteration 1950 : 8800563200.0
Loss at iteration 1960 : 5594296320.0
Loss at iteration 1970 : 22766422016.0
Loss at iteration 1980 : 24296118272.0
Loss at iteration 1990 : 16663453696.0
Loss at iteration 2000 : 19229274112.0
Loss at iteration 2010 : 6280764928.0
Loss at iteration 2020 : 7410428416.0
Loss at iteration 2030 : 10720280576.0
Loss at iteration 2040 : 24294387712.0
Loss at iteration 2050 : 127328329728.0
Loss at iteration 2060 : 2155921408.0
Loss at iteration 2070 : 5849671680.0
Loss at iteration 2080 : 20087842816.0
Loss at iteration 2090 : 5883058688.0
Loss at iteration 2100 : 5071441408.0
Loss at iteration 2110 : 6626428416.0
Loss at iteration 2120 : 3477125632.0
Loss at iteration 2130 : 15744595968.0
Loss at iteration 2140 : 7249007104.0
Loss at iteration 2150 : 7573250048.0
Loss at iteration 2160 : 5433317888.0
Loss at iteration 2170 : 1632816640.0
Loss at iteration 2180 : 6541029376.0
Loss at iteration 2190 : 6680139776.0
Loss at iteration 2200 : 4015889664.0
Loss at iteration 2210 : 21711831040.0
Loss at iteration 2220 : 28456411136.0
Loss at iteration 2230 : 1751800192.0
Loss at iteration 2240 : 5232007680.0
Loss at iteration 2250 : 26851950592.0
Loss at iteration 2260 : 2138167296.0
Loss at iteration 2270 : 3814452480.0
Loss at iteration 2280 : 95575605248.0
Loss at iteration 2290 : 436330627072.0
Loss at iteration 2300 : 170393911296.0
Loss at iteration 2310 : 261779161088.0
Loss at iteration 2320 : 2026341924864.0
Loss at iteration 2330 : 8728469831680.0
Loss at iteration 2340 : 43827003916288.0
Loss at iteration 2350 : 4570329120768.0
Loss at iteration 2360 : 11277072072704.0
Loss at iteration 2370 : 107440267264.0
Loss at iteration 2380 : 1238989537280.0
Loss at iteration 2390 : 3508893384704.0
Loss at iteration 2400 : 14100108148736.0
Loss at iteration 2410 : 206037778432.0
Loss at iteration 2420 : 46558302208.0
The SSIM Value is: -9.022403477961423e-07
The PSNR Value is: -126.1494155883789
the epoch is: 181
Loss at iteration 10 : 339237601280.0
Loss at iteration 20 : 3262237638656.0
Loss at iteration 30 : 621026476032.0
Loss at iteration 40 : 408836243456.0
Loss at iteration 50 : 741898387456.0
Loss at iteration 60 : 271531491328.0
Loss at iteration 70 : 697025953792.0
Loss at iteration 80 : 945989681152.0
Loss at iteration 90 : 2905158975488.0
Loss at iteration 100 : 403546537984.0
Loss at iteration 110 : 11352032673792.0
Loss at iteration 120 : 471014866944.0
Loss at iteration 130 : 2179146579968.0
Loss at iteration 140 : 1604795498496.0
Loss at iteration 150 : 1155282501632.0
Loss at iteration 160 : 12209147084800.0
Loss at iteration 170 : 563182043136.0
Loss at iteration 180 : 6636961792000.0
Loss at iteration 190 : 10100202496.0
Loss at iteration 200 : 72925200384.0
Loss at iteration 210 : 1495691821056.0
Loss at iteration 220 : 1233944707072.0
Loss at iteration 230 : 19784826880.0
Loss at iteration 240 : 20714486759424.0
Loss at iteration 250 : 8438504488960.0
Loss at iteration 260 : 3882135060480.0
Loss at iteration 270 : 869444681728.0
Loss at iteration 280 : 3284216840192.0
Loss at iteration 290 : 14144081231872.0
Loss at iteration 300 : 92417974272.0
Loss at iteration 310 : 3088202334208.0
Loss at iteration 320 : 3732269694976.0
Loss at iteration 330 : 5799072896122880.0
Loss at iteration 340 : 20812551684096.0
Loss at iteration 350 : 447118946861056.0
Loss at iteration 360 : 2064521101312.0
Loss at iteration 370 : 5065165766656.0
Loss at iteration 380 : 7970503524352.0
Loss at iteration 390 : 7420298395648.0
Loss at iteration 400 : 252205154304.0
Loss at iteration 410 : 28047113715712.0
Loss at iteration 420 : 11368054915072.0
Loss at iteration 430 : 6009737707520.0
Loss at iteration 440 : 1214710546432.0
Loss at iteration 450 : 3593111863296.0
Loss at iteration 460 : 23159516430336.0
Loss at iteration 470 : 9040879943680.0
Loss at iteration 480 : 3256686477312.0
Loss at iteration 490 : 3612992864256.0
Loss at iteration 500 : 6843032141824.0
Loss at iteration 510 : 21238468575232.0
Loss at iteration 520 : 3383910203392.0
Loss at iteration 530 : 1891241951232.0
Loss at iteration 540 : 516550361088.0
Loss at iteration 550 : 115138669576192.0
Loss at iteration 560 : 17438971265024.0
Loss at iteration 570 : 61441146880.0
Loss at iteration 580 : 251825242112.0
Loss at iteration 590 : 795659075584.0
Loss at iteration 600 : 257418739712.0
Loss at iteration 610 : 325722308608.0
Loss at iteration 620 : 3618812461056.0
Loss at iteration 630 : 442777862144.0
Loss at iteration 640 : 114058313728.0
Loss at iteration 650 : 172534644736.0
Loss at iteration 660 : 1779392315392.0
Loss at iteration 670 : 1545002942464.0
Loss at iteration 680 : 81949966336.0
Loss at iteration 690 : 39164919808.0
Loss at iteration 700 : 395193352192.0
Loss at iteration 710 : 26106771456.0
Loss at iteration 720 : 709556895744.0
Loss at iteration 730 : 164761927680.0
Loss at iteration 740 : 244034797568.0
Loss at iteration 750 : 172546359296.0
Loss at iteration 760 : 50605486080.0
Loss at iteration 770 : 37964156928.0
Loss at iteration 780 : 39809130496.0
Loss at iteration 790 : 1315648831488.0
Loss at iteration 800 : 117410693120.0
Loss at iteration 810 : 952906940416.0
Loss at iteration 820 : 136171241472.0
Loss at iteration 830 : 214279077888.0
Loss at iteration 840 : 1797495193600.0
Loss at iteration 850 : 4536689754112.0
Loss at iteration 860 : 481888763904.0
Loss at iteration 870 : 159282184192.0
Loss at iteration 880 : 76127461376.0
Loss at iteration 890 : 627125190656.0
Loss at iteration 900 : 198308233216.0
Loss at iteration 910 : 677471780864.0
Loss at iteration 920 : 286193156096.0
Loss at iteration 930 : 58513481728.0
Loss at iteration 940 : 649500164096.0
Loss at iteration 950 : 4567163904.0
Loss at iteration 960 : 697564004352.0
Loss at iteration 970 : 14948527767552.0
Loss at iteration 980 : 120949465088.0
Loss at iteration 990 : 330032807936.0
Loss at iteration 1000 : 128640352256.0
Loss at iteration 1010 : 21815439360.0
Loss at iteration 1020 : 280835096576.0
Loss at iteration 1030 : 84536156160.0
Loss at iteration 1040 : 27589328896.0
Loss at iteration 1050 : 29369759744.0
Loss at iteration 1060 : 212108165120.0
Loss at iteration 1070 : 69573550080.0
Loss at iteration 1080 : 18388244480.0
Loss at iteration 1090 : 1237872279552.0
Loss at iteration 1100 : 310735372288.0
Loss at iteration 1110 : 30283507712.0
Loss at iteration 1120 : 163119300608.0
Loss at iteration 1130 : 17409388544.0
Loss at iteration 1140 : 125248987136.0
Loss at iteration 1150 : 1615099904.0
Loss at iteration 1160 : 25162688512.0
Loss at iteration 1170 : 67840225280.0
Loss at iteration 1180 : 986991427584.0
Loss at iteration 1190 : 28064792576.0
Loss at iteration 1200 : 601063292928.0
Loss at iteration 1210 : 63140155392.0
Loss at iteration 1220 : 27283576832.0
Loss at iteration 1230 : 551706624000.0
Loss at iteration 1240 : 209247764480.0
Loss at iteration 1250 : 753733664768.0
Loss at iteration 1260 : 105887031296.0
Loss at iteration 1270 : 344808652800.0
Loss at iteration 1280 : 195517710336.0
Loss at iteration 1290 : 36467453952.0
Loss at iteration 1300 : 646034096128.0
Loss at iteration 1310 : 20345176064.0
Loss at iteration 1320 : 4796007841792.0
Loss at iteration 1330 : 117892243456.0
Loss at iteration 1340 : 279459201024.0
Loss at iteration 1350 : 209629298688.0
Loss at iteration 1360 : 1026798649344.0
Loss at iteration 1370 : 408022843392.0
Loss at iteration 1380 : 7284940288.0
Loss at iteration 1390 : 18799452160.0
Loss at iteration 1400 : 88789164032.0
Loss at iteration 1410 : 164515643392.0
Loss at iteration 1420 : 45297643520.0
Loss at iteration 1430 : 75838038016.0
Loss at iteration 1440 : 48352165888.0
Loss at iteration 1450 : 267081072640.0
Loss at iteration 1460 : 15315783680.0
Loss at iteration 1470 : 3316733968384.0
Loss at iteration 1480 : 24112281600.0
Loss at iteration 1490 : 1068725960704.0
Loss at iteration 1500 : 49746518016.0
Loss at iteration 1510 : 132434731008.0
Loss at iteration 1520 : 467711819776.0
Loss at iteration 1530 : 354678800384.0
Loss at iteration 1540 : 184228593664.0
Loss at iteration 1550 : 1198744403968.0
Loss at iteration 1560 : 581598969856.0
Loss at iteration 1570 : 954717962240.0
Loss at iteration 1580 : 521024798720.0
Loss at iteration 1590 : 3537378476032.0
Loss at iteration 1600 : 14748027904.0
Loss at iteration 1610 : 1242290061312.0
Loss at iteration 1620 : 2003165511680.0
Loss at iteration 1630 : 612548935680.0
Loss at iteration 1640 : 1973139931136.0
Loss at iteration 1650 : 72591826944.0
Loss at iteration 1660 : 943981395968.0
Loss at iteration 1670 : 2344606236672.0
Loss at iteration 1680 : 1510664044544.0
Loss at iteration 1690 : 7833614024704.0
Loss at iteration 1700 : 1254547259392.0
Loss at iteration 1710 : 871855423488.0
Loss at iteration 1720 : 1153946746880.0
Loss at iteration 1730 : 141184286720.0
Loss at iteration 1740 : 12569801728.0
Loss at iteration 1750 : 67464101888.0
Loss at iteration 1760 : 223289982976.0
Loss at iteration 1770 : 1176544215040.0
Loss at iteration 1780 : 41058844672.0
Loss at iteration 1790 : 1284524212224.0
Loss at iteration 1800 : 3057436327936.0
Loss at iteration 1810 : 184420892672.0
Loss at iteration 1820 : 16782894080.0
Loss at iteration 1830 : 285315727360.0
Loss at iteration 1840 : 59550797824.0
Loss at iteration 1850 : 504492457984.0
Loss at iteration 1860 : 35042910208.0
Loss at iteration 1870 : 2462561599488.0
Loss at iteration 1880 : 401716903936.0
Loss at iteration 1890 : 35200057344.0
Loss at iteration 1900 : 104515166208.0
Loss at iteration 1910 : 135076118528.0
Loss at iteration 1920 : 258851782656.0
Loss at iteration 1930 : 177985519616.0
Loss at iteration 1940 : 342954573824.0
Loss at iteration 1950 : 301012123648.0
Loss at iteration 1960 : 222905024512.0
Loss at iteration 1970 : 5524498944.0
Loss at iteration 1980 : 9105195008.0
Loss at iteration 1990 : 339577077760.0
Loss at iteration 2000 : 445642276864.0
Loss at iteration 2010 : 158956486656.0
Loss at iteration 2020 : 127874924544.0
Loss at iteration 2030 : 1174623617024.0
Loss at iteration 2040 : 3278841315328.0
Loss at iteration 2050 : 37478305792.0
Loss at iteration 2060 : 793248006144.0
Loss at iteration 2070 : 665731203072.0
Loss at iteration 2080 : 76175908864.0
Loss at iteration 2090 : 250376536064.0
Loss at iteration 2100 : 270939291648.0
Loss at iteration 2110 : 140438880256.0
Loss at iteration 2120 : 33200379904.0
Loss at iteration 2130 : 739673440256.0
Loss at iteration 2140 : 237423263744.0
Loss at iteration 2150 : 1173905211392.0
Loss at iteration 2160 : 5107676086272.0
Loss at iteration 2170 : 56279277568.0
Loss at iteration 2180 : 45069262848.0
Loss at iteration 2190 : 234998317056.0
Loss at iteration 2200 : 145150672896.0
Loss at iteration 2210 : 56213852160.0
Loss at iteration 2220 : 12010049536.0
Loss at iteration 2230 : 259546972160.0
Loss at iteration 2240 : 117746810880.0
Loss at iteration 2250 : 240309534720.0
Loss at iteration 2260 : 46116597760.0
Loss at iteration 2270 : 13792786432.0
Loss at iteration 2280 : 38986747904.0
Loss at iteration 2290 : 25963802624.0
Loss at iteration 2300 : 121019916288.0
Loss at iteration 2310 : 101654429696.0
Loss at iteration 2320 : 58289332224.0
Loss at iteration 2330 : 107552219136.0
Loss at iteration 2340 : 210230771712.0
Loss at iteration 2350 : 194294022144.0
Loss at iteration 2360 : 70951657472.0
Loss at iteration 2370 : 74962468864.0
Loss at iteration 2380 : 32498669568.0
Loss at iteration 2390 : 9364493312.0
Loss at iteration 2400 : 26467858432.0
Loss at iteration 2410 : 61027901440.0
Loss at iteration 2420 : 228310335488.0
The SSIM Value is: 1.9802972239801875e-06
The PSNR Value is: -112.65599365234375
the epoch is: 182
Loss at iteration 10 : 258192474112.0
Loss at iteration 20 : 59105255424.0
Loss at iteration 30 : 23026946048.0
Loss at iteration 40 : 227951755264.0
Loss at iteration 50 : 39395577856.0
Loss at iteration 60 : 38657261568.0
Loss at iteration 70 : 32225423360.0
Loss at iteration 80 : 68422324224.0
Loss at iteration 90 : 494381858816.0
Loss at iteration 100 : 36429987840.0
Loss at iteration 110 : 65669599232.0
Loss at iteration 120 : 82254643200.0
Loss at iteration 130 : 1072405544960.0
Loss at iteration 140 : 251278262272.0
Loss at iteration 150 : 280835457024.0
Loss at iteration 160 : 822177169408.0
Loss at iteration 170 : 1277696278528.0
Loss at iteration 180 : 1293146652672.0
Loss at iteration 190 : 928356302848.0
Loss at iteration 200 : 1075603308544.0
Loss at iteration 210 : 787569115136.0
Loss at iteration 220 : 1134426368.0
Loss at iteration 230 : 118449446912.0
Loss at iteration 240 : 94604574720.0
Loss at iteration 250 : 126383734784.0
Loss at iteration 260 : 31404480512.0
Loss at iteration 270 : 45779992576.0
Loss at iteration 280 : 116939087872.0
Loss at iteration 290 : 29890463744.0
Loss at iteration 300 : 211297042432.0
Loss at iteration 310 : 25743626240.0
Loss at iteration 320 : 7027207680.0
Loss at iteration 330 : 1865168256.0
Loss at iteration 340 : 98719252480.0
Loss at iteration 350 : 61351346176.0
Loss at iteration 360 : 5186688000.0
Loss at iteration 370 : 47571156992.0
Loss at iteration 380 : 253742809088.0
Loss at iteration 390 : 66899734528.0
Loss at iteration 400 : 876142657536.0
Loss at iteration 410 : 87581876224.0
Loss at iteration 420 : 180302577664.0
Loss at iteration 430 : 2842192384.0
Loss at iteration 440 : 107743469568.0
Loss at iteration 450 : 75549696000.0
Loss at iteration 460 : 44700876800.0
Loss at iteration 470 : 241896243200.0
Loss at iteration 480 : 45305864192.0
Loss at iteration 490 : 124936421376.0
Loss at iteration 500 : 470746660864.0
Loss at iteration 510 : 163581935616.0
Loss at iteration 520 : 212789051392.0
Loss at iteration 530 : 218191020032.0
Loss at iteration 540 : 178184798208.0
Loss at iteration 550 : 227088711680.0
Loss at iteration 560 : 171413618688.0
Loss at iteration 570 : 141399097344.0
Loss at iteration 580 : 22707558400.0
Loss at iteration 590 : 102064062464.0
Loss at iteration 600 : 49317380096.0
Loss at iteration 610 : 227260858368.0
Loss at iteration 620 : 183066017792.0
Loss at iteration 630 : 73779150848.0
Loss at iteration 640 : 480387661824.0
Loss at iteration 650 : 12168035328.0
Loss at iteration 660 : 3726606080.0
Loss at iteration 670 : 744085585920.0
Loss at iteration 680 : 1043350487040.0
Loss at iteration 690 : 34114154496.0
Loss at iteration 700 : 100613619712.0
Loss at iteration 710 : 45488521216.0
Loss at iteration 720 : 346302545920.0
Loss at iteration 730 : 52422410240.0
Loss at iteration 740 : 16644666368.0
Loss at iteration 750 : 27636611072.0
Loss at iteration 760 : 80158883840.0
Loss at iteration 770 : 15064189952.0
Loss at iteration 780 : 56267210752.0
Loss at iteration 790 : 94844674048.0
Loss at iteration 800 : 37702103040.0
Loss at iteration 810 : 72600633344.0
Loss at iteration 820 : 66473390080.0
Loss at iteration 830 : 109476552704.0
Loss at iteration 840 : 27729004544.0
Loss at iteration 850 : 489066037248.0
Loss at iteration 860 : 16982988800.0
Loss at iteration 870 : 13242720256.0
Loss at iteration 880 : 72594808832.0
Loss at iteration 890 : 39717052416.0
Loss at iteration 900 : 35840991232.0
Loss at iteration 910 : 28540166144.0
Loss at iteration 920 : 38573715456.0
Loss at iteration 930 : 128450125824.0
Loss at iteration 940 : 163041869824.0
Loss at iteration 950 : 300967624704.0
Loss at iteration 960 : 49405661184.0
Loss at iteration 970 : 131902095360.0
Loss at iteration 980 : 62061899776.0
Loss at iteration 990 : 498603327488.0
Loss at iteration 1000 : 362925621248.0
Loss at iteration 1010 : 76610306048.0
Loss at iteration 1020 : 75368579072.0
Loss at iteration 1030 : 9240075264.0
Loss at iteration 1040 : 103567679488.0
Loss at iteration 1050 : 75661320192.0
Loss at iteration 1060 : 127353593856.0
Loss at iteration 1070 : 15602316288.0
Loss at iteration 1080 : 75573501952.0
Loss at iteration 1090 : 8525729280.0
Loss at iteration 1100 : 3984126208.0
Loss at iteration 1110 : 153212518400.0
Loss at iteration 1120 : 11761920000.0
Loss at iteration 1130 : 1547963520.0
Loss at iteration 1140 : 3610471680.0
Loss at iteration 1150 : 71648051200.0
Loss at iteration 1160 : 33073799168.0
Loss at iteration 1170 : 144455974912.0
Loss at iteration 1180 : 133669068800.0
Loss at iteration 1190 : 136337645568.0
Loss at iteration 1200 : 88557723648.0
Loss at iteration 1210 : 765788553216.0
Loss at iteration 1220 : 4570489344.0
Loss at iteration 1230 : 18408896512.0
Loss at iteration 1240 : 28205719552.0
Loss at iteration 1250 : 796068544.0
Loss at iteration 1260 : 45807550464.0
Loss at iteration 1270 : 32015742976.0
Loss at iteration 1280 : 160455704576.0
Loss at iteration 1290 : 92948381696.0
Loss at iteration 1300 : 9209788416.0
Loss at iteration 1310 : 8744366080.0
Loss at iteration 1320 : 17422065664.0
Loss at iteration 1330 : 46296190976.0
Loss at iteration 1340 : 76690333696.0
Loss at iteration 1350 : 6669450240.0
Loss at iteration 1360 : 41849638912.0
Loss at iteration 1370 : 12715104256.0
Loss at iteration 1380 : 23751782400.0
Loss at iteration 1390 : 90809745408.0
Loss at iteration 1400 : 33896773632.0
Loss at iteration 1410 : 30303182848.0
Loss at iteration 1420 : 45558661120.0
Loss at iteration 1430 : 32610932736.0
Loss at iteration 1440 : 6675668480.0
Loss at iteration 1450 : 11304055808.0
Loss at iteration 1460 : 2016561280.0
Loss at iteration 1470 : 5302339584.0
Loss at iteration 1480 : 11032299520.0
Loss at iteration 1490 : 157492543488.0
Loss at iteration 1500 : 50495467520.0
Loss at iteration 1510 : 28569929728.0
Loss at iteration 1520 : 24012425216.0
Loss at iteration 1530 : 39270088704.0
Loss at iteration 1540 : 15225800704.0
Loss at iteration 1550 : 29755721728.0
Loss at iteration 1560 : 343094820864.0
Loss at iteration 1570 : 94017257472.0
Loss at iteration 1580 : 353265451008.0
Loss at iteration 1590 : 182761619456.0
Loss at iteration 1600 : 127605178368.0
Loss at iteration 1610 : 27707983872.0
Loss at iteration 1620 : 78588731392.0
Loss at iteration 1630 : 50334584832.0
Loss at iteration 1640 : 83750232064.0
Loss at iteration 1650 : 2732285440.0
Loss at iteration 1660 : 40322416640.0
Loss at iteration 1670 : 112102113280.0
Loss at iteration 1680 : 66282340352.0
Loss at iteration 1690 : 171608162304.0
Loss at iteration 1700 : 120918622208.0
Loss at iteration 1710 : 82274140160.0
Loss at iteration 1720 : 13635877888.0
Loss at iteration 1730 : 43217534976.0
Loss at iteration 1740 : 5680818176.0
Loss at iteration 1750 : 71495835648.0
Loss at iteration 1760 : 5980433920.0
Loss at iteration 1770 : 16546537472.0
Loss at iteration 1780 : 82748727296.0
Loss at iteration 1790 : 4630418432.0
Loss at iteration 1800 : 45353136128.0
Loss at iteration 1810 : 12258885632.0
Loss at iteration 1820 : 2867977216.0
Loss at iteration 1830 : 56113172480.0
Loss at iteration 1840 : 123817656320.0
Loss at iteration 1850 : 276064829440.0
Loss at iteration 1860 : 7855097856.0
Loss at iteration 1870 : 50024464384.0
Loss at iteration 1880 : 37143625728.0
Loss at iteration 1890 : 16976807936.0
Loss at iteration 1900 : 11241274368.0
Loss at iteration 1910 : 43524300800.0
Loss at iteration 1920 : 17914845184.0
Loss at iteration 1930 : 37401284608.0
Loss at iteration 1940 : 53028659200.0
Loss at iteration 1950 : 8740230144.0
Loss at iteration 1960 : 100896514048.0
Loss at iteration 1970 : 15300273152.0
Loss at iteration 1980 : 115632668672.0
Loss at iteration 1990 : 6563457024.0
Loss at iteration 2000 : 3080099840.0
Loss at iteration 2010 : 4448958976.0
Loss at iteration 2020 : 77307420672.0
Loss at iteration 2030 : 20824463360.0
Loss at iteration 2040 : 86608429056.0
Loss at iteration 2050 : 41622384640.0
Loss at iteration 2060 : 5423740416.0
Loss at iteration 2070 : 77239033856.0
Loss at iteration 2080 : 77178216448.0
Loss at iteration 2090 : 117487484928.0
Loss at iteration 2100 : 610222336.0
Loss at iteration 2110 : 22031585280.0
Loss at iteration 2120 : 12178155520.0
Loss at iteration 2130 : 11395292160.0
Loss at iteration 2140 : 79345082368.0
Loss at iteration 2150 : 48206745600.0
Loss at iteration 2160 : 43272871936.0
Loss at iteration 2170 : 1824275584.0
Loss at iteration 2180 : 40427102208.0
Loss at iteration 2190 : 20432105472.0
Loss at iteration 2200 : 11594086400.0
Loss at iteration 2210 : 17237415936.0
Loss at iteration 2220 : 10140672000.0
Loss at iteration 2230 : 8197359616.0
Loss at iteration 2240 : 60396425216.0
Loss at iteration 2250 : 278521249792.0
Loss at iteration 2260 : 454854836224.0
Loss at iteration 2270 : 59878641664.0
Loss at iteration 2280 : 37620461568.0
Loss at iteration 2290 : 120659189760.0
Loss at iteration 2300 : 194923102208.0
Loss at iteration 2310 : 95635660800.0
Loss at iteration 2320 : 147298254848.0
Loss at iteration 2330 : 1083291664384.0
Loss at iteration 2340 : 27127089152.0
Loss at iteration 2350 : 2051130916864.0
Loss at iteration 2360 : 39238574080.0
Loss at iteration 2370 : 80930791424.0
Loss at iteration 2380 : 29098627072.0
Loss at iteration 2390 : 109208903680.0
Loss at iteration 2400 : 50703577088.0
Loss at iteration 2410 : 75343962112.0
Loss at iteration 2420 : 143352872960.0
The SSIM Value is: 4.016374627250722e-06
The PSNR Value is: -120.69580891927083
the epoch is: 183
Loss at iteration 10 : 69833687040.0
Loss at iteration 20 : 89635225600.0
Loss at iteration 30 : 266759454720.0
Loss at iteration 40 : 1144384651264.0
Loss at iteration 50 : 38214307840.0
Loss at iteration 60 : 42730598400.0
Loss at iteration 70 : 4938377216.0
Loss at iteration 80 : 143378563072.0
Loss at iteration 90 : 129743011840.0
Loss at iteration 100 : 293988630528.0
Loss at iteration 110 : 641599275008.0
Loss at iteration 120 : 354247114752.0
Loss at iteration 130 : 109393887232.0
Loss at iteration 140 : 15052642304.0
Loss at iteration 150 : 271915974656.0
Loss at iteration 160 : 557285244928.0
Loss at iteration 170 : 348674162688.0
Loss at iteration 180 : 50532519936.0
Loss at iteration 190 : 9824759808.0
Loss at iteration 200 : 28086114304.0
Loss at iteration 210 : 96255533056.0
Loss at iteration 220 : 30442338304.0
Loss at iteration 230 : 28568690688.0
Loss at iteration 240 : 375061184512.0
Loss at iteration 250 : 16765332480.0
Loss at iteration 260 : 77193797632.0
Loss at iteration 270 : 45373853696.0
Loss at iteration 280 : 80657965056.0
Loss at iteration 290 : 61410643968.0
Loss at iteration 300 : 16351230976.0
Loss at iteration 310 : 61676220416.0
Loss at iteration 320 : 122206396416.0
Loss at iteration 330 : 1105738334208.0
Loss at iteration 340 : 44693200896.0
Loss at iteration 350 : 107103043584.0
Loss at iteration 360 : 36200476672.0
Loss at iteration 370 : 22852186112.0
Loss at iteration 380 : 137150136320.0
Loss at iteration 390 : 34283679744.0
Loss at iteration 400 : 159185059840.0
Loss at iteration 410 : 182127378432.0
Loss at iteration 420 : 221317365760.0
Loss at iteration 430 : 277952856064.0
Loss at iteration 440 : 79614574592.0
Loss at iteration 450 : 133946531840.0
Loss at iteration 460 : 734257217536.0
Loss at iteration 470 : 29000445952.0
Loss at iteration 480 : 22078926848.0
Loss at iteration 490 : 9558974464.0
Loss at iteration 500 : 105498198016.0
Loss at iteration 510 : 398551285760.0
Loss at iteration 520 : 151898013696.0
Loss at iteration 530 : 12373742592.0
Loss at iteration 540 : 32706928640.0
Loss at iteration 550 : 46708637696.0
Loss at iteration 560 : 11768680448.0
Loss at iteration 570 : 152770641920.0
Loss at iteration 580 : 84819034112.0
Loss at iteration 590 : 49510068224.0
Loss at iteration 600 : 11547055104.0
Loss at iteration 610 : 32735158272.0
Loss at iteration 620 : 150055665664.0
Loss at iteration 630 : 20932028416.0
Loss at iteration 640 : 247712694272.0
Loss at iteration 650 : 172902612992.0
Loss at iteration 660 : 43555598336.0
Loss at iteration 670 : 36227346432.0
Loss at iteration 680 : 170958749696.0
Loss at iteration 690 : 98887409664.0
Loss at iteration 700 : 8135023104.0
Loss at iteration 710 : 14150196224.0
Loss at iteration 720 : 11411509248.0
Loss at iteration 730 : 2503824113664.0
Loss at iteration 740 : 36476997632.0
Loss at iteration 750 : 145351180288.0
Loss at iteration 760 : 27154423808.0
Loss at iteration 770 : 3477708032.0
Loss at iteration 780 : 46201434112.0
Loss at iteration 790 : 37585670144.0
Loss at iteration 800 : 11375093760.0
Loss at iteration 810 : 10471839744.0
Loss at iteration 820 : 50558844928.0
Loss at iteration 830 : 65396162560.0
Loss at iteration 840 : 7555434496.0
Loss at iteration 850 : 7815691776.0
Loss at iteration 860 : 28127698944.0
Loss at iteration 870 : 13076291584.0
Loss at iteration 880 : 29255938048.0
Loss at iteration 890 : 9547351040.0
Loss at iteration 900 : 26159110144.0
Loss at iteration 910 : 164183048192.0
Loss at iteration 920 : 4895936512.0
Loss at iteration 930 : 22309623808.0
Loss at iteration 940 : 23237349376.0
Loss at iteration 950 : 20336392192.0
Loss at iteration 960 : 102052102144.0
Loss at iteration 970 : 28219072512.0
Loss at iteration 980 : 32512886784.0
Loss at iteration 990 : 120209817600.0
Loss at iteration 1000 : 24429266944.0
Loss at iteration 1010 : 3763962112.0
Loss at iteration 1020 : 5766075392.0
Loss at iteration 1030 : 35575758848.0
Loss at iteration 1040 : 34206763008.0
Loss at iteration 1050 : 26408738816.0
Loss at iteration 1060 : 993439232.0
Loss at iteration 1070 : 136428052480.0
Loss at iteration 1080 : 295271333888.0
Loss at iteration 1090 : 252365373440.0
Loss at iteration 1100 : 257012154368.0
Loss at iteration 1110 : 80831012864.0
Loss at iteration 1120 : 674706554880.0
Loss at iteration 1130 : 129086734336.0
Loss at iteration 1140 : 8419934720.0
Loss at iteration 1150 : 132251287552.0
Loss at iteration 1160 : 76097339392.0
Loss at iteration 1170 : 17545056256.0
Loss at iteration 1180 : 82292088832.0
Loss at iteration 1190 : 19757234176.0
Loss at iteration 1200 : 53908332544.0
Loss at iteration 1210 : 11652771840.0
Loss at iteration 1220 : 104679653376.0
Loss at iteration 1230 : 741950816256.0
Loss at iteration 1240 : 106641170432.0
Loss at iteration 1250 : 168326742016.0
Loss at iteration 1260 : 90419691520.0
Loss at iteration 1270 : 655509028864.0
Loss at iteration 1280 : 55180460032.0
Loss at iteration 1290 : 62427451392.0
Loss at iteration 1300 : 68673003520.0
Loss at iteration 1310 : 14515150848.0
Loss at iteration 1320 : 174305624064.0
Loss at iteration 1330 : 29412030464.0
Loss at iteration 1340 : 55019806720.0
Loss at iteration 1350 : 16188903424.0
Loss at iteration 1360 : 161497415680.0
Loss at iteration 1370 : 48046022656.0
Loss at iteration 1380 : 50698522624.0
Loss at iteration 1390 : 73623412736.0
Loss at iteration 1400 : 16396484608.0
Loss at iteration 1410 : 56248700928.0
Loss at iteration 1420 : 9236567040.0
Loss at iteration 1430 : 2831732992.0
Loss at iteration 1440 : 99913515008.0
Loss at iteration 1450 : 352804372480.0
Loss at iteration 1460 : 75472306176.0
Loss at iteration 1470 : 74440228864.0
Loss at iteration 1480 : 81346412544.0
Loss at iteration 1490 : 9599599616.0
Loss at iteration 1500 : 12843868160.0
Loss at iteration 1510 : 31526008832.0
Loss at iteration 1520 : 76622913536.0
Loss at iteration 1530 : 5656294912.0
Loss at iteration 1540 : 21648922624.0
Loss at iteration 1550 : 7404764160.0
Loss at iteration 1560 : 50611597312.0
Loss at iteration 1570 : 3275259136.0
Loss at iteration 1580 : 7121772032.0
Loss at iteration 1590 : 86711959552.0
Loss at iteration 1600 : 40276422656.0
Loss at iteration 1610 : 8263240192.0
Loss at iteration 1620 : 75063902208.0
Loss at iteration 1630 : 19658254336.0
Loss at iteration 1640 : 14835551232.0
Loss at iteration 1650 : 2748704256.0
Loss at iteration 1660 : 17024017408.0
Loss at iteration 1670 : 86977609728.0
Loss at iteration 1680 : 42240679936.0
Loss at iteration 1690 : 994735423488.0
Loss at iteration 1700 : 538515210240.0
Loss at iteration 1710 : 4921041092608.0
Loss at iteration 1720 : 1960046231552.0
Loss at iteration 1730 : 1423769731072.0
Loss at iteration 1740 : 407966187520.0
Loss at iteration 1750 : 89376858112.0
Loss at iteration 1760 : 163460169728.0
Loss at iteration 1770 : 409878691840.0
Loss at iteration 1780 : 48778936320.0
Loss at iteration 1790 : 108971958272.0
Loss at iteration 1800 : 101975203840.0
Loss at iteration 1810 : 2838765568.0
Loss at iteration 1820 : 28708980736.0
Loss at iteration 1830 : 12865623040.0
Loss at iteration 1840 : 9036395520.0
Loss at iteration 1850 : 41084510208.0
Loss at iteration 1860 : 51013242880.0
Loss at iteration 1870 : 8534944256.0
Loss at iteration 1880 : 94510989312.0
Loss at iteration 1890 : 46666100736.0
Loss at iteration 1900 : 117340848128.0
Loss at iteration 1910 : 24845383680.0
Loss at iteration 1920 : 8361300992.0
Loss at iteration 1930 : 12779236352.0
Loss at iteration 1940 : 68775354368.0
Loss at iteration 1950 : 23120734208.0
Loss at iteration 1960 : 63028355072.0
Loss at iteration 1970 : 221391355904.0
Loss at iteration 1980 : 2280093646848.0
Loss at iteration 1990 : 87496916992.0
Loss at iteration 2000 : 128432078848.0
Loss at iteration 2010 : 126360592384.0
Loss at iteration 2020 : 387514335232.0
Loss at iteration 2030 : 212754055168.0
Loss at iteration 2040 : 549140627456.0
Loss at iteration 2050 : 172626296832.0
Loss at iteration 2060 : 239589408768.0
Loss at iteration 2070 : 86585614336.0
Loss at iteration 2080 : 541843324928.0
Loss at iteration 2090 : 41885286400.0
Loss at iteration 2100 : 4702274560.0
Loss at iteration 2110 : 5084378112.0
Loss at iteration 2120 : 278920167424.0
Loss at iteration 2130 : 4730353152.0
Loss at iteration 2140 : 8516993024.0
Loss at iteration 2150 : 18092933120.0
Loss at iteration 2160 : 17759866880.0
Loss at iteration 2170 : 2425242368.0
Loss at iteration 2180 : 5626121216.0
Loss at iteration 2190 : 5628063744.0
Loss at iteration 2200 : 70032293888.0
Loss at iteration 2210 : 39298142208.0
Loss at iteration 2220 : 19140241408.0
Loss at iteration 2230 : 144399532032.0
Loss at iteration 2240 : 61047787520.0
Loss at iteration 2250 : 9992652800.0
Loss at iteration 2260 : 6883587584.0
Loss at iteration 2270 : 3709809408.0
Loss at iteration 2280 : 36317396992.0
Loss at iteration 2290 : 7182275072.0
Loss at iteration 2300 : 94527700992.0
Loss at iteration 2310 : 22752862208.0
Loss at iteration 2320 : 116233281536.0
Loss at iteration 2330 : 8407964672.0
Loss at iteration 2340 : 1042776128.0
Loss at iteration 2350 : 220397780992.0
Loss at iteration 2360 : 97044529152.0
Loss at iteration 2370 : 6332107776.0
Loss at iteration 2380 : 23753500672.0
Loss at iteration 2390 : 51555328000.0
Loss at iteration 2400 : 5881606144.0
Loss at iteration 2410 : 159889457152.0
Loss at iteration 2420 : 91011833856.0
The SSIM Value is: 8.848877604350491e-06
The PSNR Value is: -112.15462544759114
the epoch is: 184
Loss at iteration 10 : 14951454720.0
Loss at iteration 20 : 28131452928.0
Loss at iteration 30 : 25614362624.0
Loss at iteration 40 : 3622315264.0
Loss at iteration 50 : 8395273216.0
Loss at iteration 60 : 4955802624.0
Loss at iteration 70 : 6766006784.0
Loss at iteration 80 : 5038912000.0
Loss at iteration 90 : 11700642816.0
Loss at iteration 100 : 12107813888.0
Loss at iteration 110 : 24857272320.0
Loss at iteration 120 : 2221279488.0
Loss at iteration 130 : 41907216384.0
Loss at iteration 140 : 7279694336.0
Loss at iteration 150 : 23241549824.0
Loss at iteration 160 : 19108485120.0
Loss at iteration 170 : 10564451328.0
Loss at iteration 180 : 12153114624.0
Loss at iteration 190 : 17881694208.0
Loss at iteration 200 : 18837827584.0
Loss at iteration 210 : 253710581760.0
Loss at iteration 220 : 6785596928.0
Loss at iteration 230 : 2436686592.0
Loss at iteration 240 : 12701514752.0
Loss at iteration 250 : 73129369600.0
Loss at iteration 260 : 19296430080.0
Loss at iteration 270 : 2072143104.0
Loss at iteration 280 : 93045104640.0
Loss at iteration 290 : 3830213120.0
Loss at iteration 300 : 335651045376.0
Loss at iteration 310 : 7848596992.0
Loss at iteration 320 : 23255005184.0
Loss at iteration 330 : 36043128832.0
Loss at iteration 340 : 10283451392.0
Loss at iteration 350 : 1042593408.0
Loss at iteration 360 : 6449499648.0
Loss at iteration 370 : 10210582528.0
Loss at iteration 380 : 99859693568.0
Loss at iteration 390 : 55626412032.0
Loss at iteration 400 : 12826331136.0
Loss at iteration 410 : 13289493504.0
Loss at iteration 420 : 39841775616.0
Loss at iteration 430 : 8939096064.0
Loss at iteration 440 : 7997712896.0
Loss at iteration 450 : 8696121344.0
Loss at iteration 460 : 3584236544.0
Loss at iteration 470 : 13717581824.0
Loss at iteration 480 : 45196509184.0
Loss at iteration 490 : 4241442304.0
Loss at iteration 500 : 28309870592.0
Loss at iteration 510 : 17008529408.0
Loss at iteration 520 : 7541737984.0
Loss at iteration 530 : 137853337600.0
Loss at iteration 540 : 508606976.0
Loss at iteration 550 : 7919375360.0
Loss at iteration 560 : 33803548672.0
Loss at iteration 570 : 14596384768.0
Loss at iteration 580 : 2376449280.0
Loss at iteration 590 : 381818496.0
Loss at iteration 600 : 17874812928.0
Loss at iteration 610 : 94303387648.0
Loss at iteration 620 : 85559918592.0
Loss at iteration 630 : 145417666560.0
Loss at iteration 640 : 464869523456.0
Loss at iteration 650 : 1254682752.0
Loss at iteration 660 : 103399497728.0
Loss at iteration 670 : 12337075200.0
Loss at iteration 680 : 13440379904.0
Loss at iteration 690 : 40050167808.0
Loss at iteration 700 : 226673721344.0
Loss at iteration 710 : 6790582784.0
Loss at iteration 720 : 107893850112.0
Loss at iteration 730 : 276364394496.0
Loss at iteration 740 : 215970545664.0
Loss at iteration 750 : 50054356992.0
Loss at iteration 760 : 520611463168.0
Loss at iteration 770 : 42994274304.0
Loss at iteration 780 : 881022337024.0
Loss at iteration 790 : 111401222144.0
Loss at iteration 800 : 28864743424.0
Loss at iteration 810 : 10056843264.0
Loss at iteration 820 : 104845025280.0
Loss at iteration 830 : 31003449344.0
Loss at iteration 840 : 171994775552.0
Loss at iteration 850 : 15652943872.0
Loss at iteration 860 : 641178402816.0
Loss at iteration 870 : 130594299904.0
Loss at iteration 880 : 74656931840.0
Loss at iteration 890 : 136396464128.0
Loss at iteration 900 : 47626186752.0
Loss at iteration 910 : 10170355712.0
Loss at iteration 920 : 176039411712.0
Loss at iteration 930 : 180050329600.0
Loss at iteration 940 : 22128656384.0
Loss at iteration 950 : 88228921344.0
Loss at iteration 960 : 100694482944.0
Loss at iteration 970 : 273814831104.0
Loss at iteration 980 : 50462126080.0
Loss at iteration 990 : 5471490048.0
Loss at iteration 1000 : 190154719232.0
Loss at iteration 1010 : 12945057792.0
Loss at iteration 1020 : 25831374848.0
Loss at iteration 1030 : 30956593152.0
Loss at iteration 1040 : 21059076096.0
Loss at iteration 1050 : 96442417152.0
Loss at iteration 1060 : 7683920896.0
Loss at iteration 1070 : 7411260928.0
Loss at iteration 1080 : 8927085568.0
Loss at iteration 1090 : 12984615936.0
Loss at iteration 1100 : 13666035712.0
Loss at iteration 1110 : 3392334336.0
Loss at iteration 1120 : 7219528704.0
Loss at iteration 1130 : 1916226816.0
Loss at iteration 1140 : 2930792192.0
Loss at iteration 1150 : 21639352320.0
Loss at iteration 1160 : 21343184896.0
Loss at iteration 1170 : 7435521024.0
Loss at iteration 1180 : 38676430848.0
Loss at iteration 1190 : 40569651200.0
Loss at iteration 1200 : 15956222976.0
Loss at iteration 1210 : 74886963200.0
Loss at iteration 1220 : 26386147328.0
Loss at iteration 1230 : 39737851904.0
Loss at iteration 1240 : 31697143808.0
Loss at iteration 1250 : 4494479360.0
Loss at iteration 1260 : 5010017792.0
Loss at iteration 1270 : 26072760320.0
Loss at iteration 1280 : 22123558912.0
Loss at iteration 1290 : 15767194624.0
Loss at iteration 1300 : 38229553152.0
Loss at iteration 1310 : 2200132864.0
Loss at iteration 1320 : 5340125184.0
Loss at iteration 1330 : 12287751168.0
Loss at iteration 1340 : 16636269568.0
Loss at iteration 1350 : 2326836736.0
Loss at iteration 1360 : 1799810176.0
Loss at iteration 1370 : 9451754496.0
Loss at iteration 1380 : 4184639744.0
Loss at iteration 1390 : 4466577920.0
Loss at iteration 1400 : 6202519040.0
Loss at iteration 1410 : 3900164096.0
Loss at iteration 1420 : 27505178624.0
Loss at iteration 1430 : 22205083648.0
Loss at iteration 1440 : 3041329664.0
Loss at iteration 1450 : 46561427456.0
Loss at iteration 1460 : 11860305920.0
Loss at iteration 1470 : 4815386112.0
Loss at iteration 1480 : 2572974336.0
Loss at iteration 1490 : 18942621696.0
Loss at iteration 1500 : 37845819392.0
Loss at iteration 1510 : 3537827584.0
Loss at iteration 1520 : 6145705984.0
Loss at iteration 1530 : 23512051712.0
Loss at iteration 1540 : 26337112064.0
Loss at iteration 1550 : 4407004160.0
Loss at iteration 1560 : 3449415680.0
Loss at iteration 1570 : 33497186304.0
Loss at iteration 1580 : 4543619584.0
Loss at iteration 1590 : 8128525824.0
Loss at iteration 1600 : 12902096896.0
Loss at iteration 1610 : 13139017728.0
Loss at iteration 1620 : 6981116928.0
Loss at iteration 1630 : 5253180416.0
Loss at iteration 1640 : 5075485696.0
Loss at iteration 1650 : 8705832960.0
Loss at iteration 1660 : 1097375488.0
Loss at iteration 1670 : 7385585152.0
Loss at iteration 1680 : 16095717376.0
Loss at iteration 1690 : 8478800384.0
Loss at iteration 1700 : 8167767040.0
Loss at iteration 1710 : 2045990144.0
Loss at iteration 1720 : 3461658880.0
Loss at iteration 1730 : 20276895744.0
Loss at iteration 1740 : 45018882048.0
Loss at iteration 1750 : 1960205440.0
Loss at iteration 1760 : 19869636608.0
Loss at iteration 1770 : 5150849536.0
Loss at iteration 1780 : 2165253632.0
Loss at iteration 1790 : 12079187968.0
Loss at iteration 1800 : 9773875200.0
Loss at iteration 1810 : 3339611392.0
Loss at iteration 1820 : 1581759488.0
Loss at iteration 1830 : 2695306496.0
Loss at iteration 1840 : 5177798144.0
Loss at iteration 1850 : 7066731008.0
Loss at iteration 1860 : 4461851136.0
Loss at iteration 1870 : 71271325696.0
Loss at iteration 1880 : 1159075712.0
Loss at iteration 1890 : 112456597504.0
Loss at iteration 1900 : 7542896128.0
Loss at iteration 1910 : 10696921088.0
Loss at iteration 1920 : 38407360512.0
Loss at iteration 1930 : 2301947648.0
Loss at iteration 1940 : 35552915456.0
Loss at iteration 1950 : 14300913664.0
Loss at iteration 1960 : 30520092672.0
Loss at iteration 1970 : 43448332288.0
Loss at iteration 1980 : 6463392256.0
Loss at iteration 1990 : 2550021120.0
Loss at iteration 2000 : 11496658944.0
Loss at iteration 2010 : 8266790912.0
Loss at iteration 2020 : 8215315968.0
Loss at iteration 2030 : 5329081856.0
Loss at iteration 2040 : 5432470016.0
Loss at iteration 2050 : 29596594176.0
Loss at iteration 2060 : 13722220544.0
Loss at iteration 2070 : 24591742976.0
Loss at iteration 2080 : 6267896832.0
Loss at iteration 2090 : 23469660160.0
Loss at iteration 2100 : 2943761920.0
Loss at iteration 2110 : 16407406592.0
Loss at iteration 2120 : 20299085824.0
Loss at iteration 2130 : 17103889408.0
Loss at iteration 2140 : 19663685632.0
Loss at iteration 2150 : 3450851072.0
Loss at iteration 2160 : 28011186176.0
Loss at iteration 2170 : 8345269248.0
Loss at iteration 2180 : 47110193152.0
Loss at iteration 2190 : 216600379392.0
Loss at iteration 2200 : 4087915264.0
Loss at iteration 2210 : 16515503104.0
Loss at iteration 2220 : 9977751552.0
Loss at iteration 2230 : 17058920448.0
Loss at iteration 2240 : 8588382720.0
Loss at iteration 2250 : 30524825600.0
Loss at iteration 2260 : 38297731072.0
Loss at iteration 2270 : 2143908864.0
Loss at iteration 2280 : 78533836800.0
Loss at iteration 2290 : 31854383104.0
Loss at iteration 2300 : 119097614336.0
Loss at iteration 2310 : 31651696640.0
Loss at iteration 2320 : 17544083456.0
Loss at iteration 2330 : 88816902144.0
Loss at iteration 2340 : 5831748096.0
Loss at iteration 2350 : 3952678912.0
Loss at iteration 2360 : 16157753344.0
Loss at iteration 2370 : 230797344768.0
Loss at iteration 2380 : 8715269120.0
Loss at iteration 2390 : 5133504000.0
Loss at iteration 2400 : 3606665984.0
Loss at iteration 2410 : 97165795328.0
Loss at iteration 2420 : 126508916736.0
The SSIM Value is: 2.808730247731243e-06
The PSNR Value is: -109.09510040283203
the epoch is: 185
Loss at iteration 10 : 38199865344.0
Loss at iteration 20 : 117246312448.0
Loss at iteration 30 : 40412717056.0
Loss at iteration 40 : 284938600448.0
Loss at iteration 50 : 20149225472.0
Loss at iteration 60 : 175481077760.0
Loss at iteration 70 : 8570800640.0
Loss at iteration 80 : 23772047360.0
Loss at iteration 90 : 601988544.0
Loss at iteration 100 : 23898474496.0
Loss at iteration 110 : 62835564544.0
Loss at iteration 120 : 33731258368.0
Loss at iteration 130 : 16701259776.0
Loss at iteration 140 : 104243183616.0
Loss at iteration 150 : 1764126208.0
Loss at iteration 160 : 98706391040.0
Loss at iteration 170 : 2904299776.0
Loss at iteration 180 : 4346925568.0
Loss at iteration 190 : 35018522624.0
Loss at iteration 200 : 1284622592.0
Loss at iteration 210 : 114507496.0
Loss at iteration 220 : 5130827776.0
Loss at iteration 230 : 91424864.0
Loss at iteration 240 : 8933179392.0
Loss at iteration 250 : 9618693120.0
Loss at iteration 260 : 14974635008.0
Loss at iteration 270 : 6804174336.0
Loss at iteration 280 : 17169814528.0
Loss at iteration 290 : 2324765696.0
Loss at iteration 300 : 17120519168.0
Loss at iteration 310 : 2228161024.0
Loss at iteration 320 : 2290788608.0
Loss at iteration 330 : 260198384.0
Loss at iteration 340 : 2810796288.0
Loss at iteration 350 : 1384138880.0
Loss at iteration 360 : 1076188160.0
Loss at iteration 370 : 1695121920.0
Loss at iteration 380 : 11195635712.0
Loss at iteration 390 : 9664369664.0
Loss at iteration 400 : 434217920.0
Loss at iteration 410 : 212053744.0
Loss at iteration 420 : 2655985408.0
Loss at iteration 430 : 8138332672.0
Loss at iteration 440 : 594610112.0
Loss at iteration 450 : 8407360000.0
Loss at iteration 460 : 3867148544.0
Loss at iteration 470 : 840574272.0
Loss at iteration 480 : 8942751744.0
Loss at iteration 490 : 2745166080.0
Loss at iteration 500 : 6535326720.0
Loss at iteration 510 : 1013700992.0
Loss at iteration 520 : 2391586560.0
Loss at iteration 530 : 3558727936.0
Loss at iteration 540 : 616877504.0
Loss at iteration 550 : 1177944832.0
Loss at iteration 560 : 3140399104.0
Loss at iteration 570 : 912966208.0
Loss at iteration 580 : 20390373376.0
Loss at iteration 590 : 2718434816.0
Loss at iteration 600 : 26433708032.0
Loss at iteration 610 : 444141312.0
Loss at iteration 620 : 1925069568.0
Loss at iteration 630 : 7113429504.0
Loss at iteration 640 : 460646016.0
Loss at iteration 650 : 6809108480.0
Loss at iteration 660 : 960071104.0
Loss at iteration 670 : 255812992.0
Loss at iteration 680 : 162247424.0
Loss at iteration 690 : 3169817856.0
Loss at iteration 700 : 7397700096.0
Loss at iteration 710 : 11695416320.0
Loss at iteration 720 : 1568449280.0
Loss at iteration 730 : 286993536.0
Loss at iteration 740 : 1694158720.0
Loss at iteration 750 : 20069783552.0
Loss at iteration 760 : 5479668736.0
Loss at iteration 770 : 219190944.0
Loss at iteration 780 : 2008367104.0
Loss at iteration 790 : 714536128.0
Loss at iteration 800 : 1528221440.0
Loss at iteration 810 : 774682432.0
Loss at iteration 820 : 3661737728.0
Loss at iteration 830 : 6390656512.0
Loss at iteration 840 : 1572604032.0
Loss at iteration 850 : 737377344.0
Loss at iteration 860 : 3348561152.0
Loss at iteration 870 : 2693853696.0
Loss at iteration 880 : 1907434880.0
Loss at iteration 890 : 729461696.0
Loss at iteration 900 : 62878674944.0
Loss at iteration 910 : 5029203456.0
Loss at iteration 920 : 871333568.0
Loss at iteration 930 : 1712481280.0
Loss at iteration 940 : 1506521088.0
Loss at iteration 950 : 210326624.0
Loss at iteration 960 : 18512613376.0
Loss at iteration 970 : 15768414208.0
Loss at iteration 980 : 1324036352.0
Loss at iteration 990 : 2707874304.0
Loss at iteration 1000 : 6643991552.0
Loss at iteration 1010 : 3346891776.0
Loss at iteration 1020 : 211435700224.0
Loss at iteration 1030 : 5769197568.0
Loss at iteration 1040 : 2671621376.0
Loss at iteration 1050 : 115593969664.0
Loss at iteration 1060 : 1310339200.0
Loss at iteration 1070 : 7470968320.0
Loss at iteration 1080 : 11709359104.0
Loss at iteration 1090 : 24153053184.0
Loss at iteration 1100 : 6959228928.0
Loss at iteration 1110 : 16647103488.0
Loss at iteration 1120 : 549981248.0
Loss at iteration 1130 : 2125139840.0
Loss at iteration 1140 : 60748029952.0
Loss at iteration 1150 : 47677042688.0
Loss at iteration 1160 : 57088901120.0
Loss at iteration 1170 : 59267514368.0
Loss at iteration 1180 : 61781843968.0
Loss at iteration 1190 : 4549790208.0
Loss at iteration 1200 : 27483527168.0
Loss at iteration 1210 : 10306382848.0
Loss at iteration 1220 : 7520193536.0
Loss at iteration 1230 : 5923550720.0
Loss at iteration 1240 : 4623730688.0
Loss at iteration 1250 : 10908598272.0
Loss at iteration 1260 : 14702179328.0
Loss at iteration 1270 : 112470540288.0
Loss at iteration 1280 : 38600392704.0
Loss at iteration 1290 : 4900141056.0
Loss at iteration 1300 : 3788987648.0
Loss at iteration 1310 : 921673600.0
Loss at iteration 1320 : 4714337280.0
Loss at iteration 1330 : 27450103808.0
Loss at iteration 1340 : 21890258944.0
Loss at iteration 1350 : 12887254016.0
Loss at iteration 1360 : 24069115904.0
Loss at iteration 1370 : 205669792.0
Loss at iteration 1380 : 280873568.0
Loss at iteration 1390 : 24767676416.0
Loss at iteration 1400 : 2528334592.0
Loss at iteration 1410 : 1063759104.0
Loss at iteration 1420 : 3682310144.0
Loss at iteration 1430 : 5656279552.0
Loss at iteration 1440 : 10973963264.0
Loss at iteration 1450 : 39172272128.0
Loss at iteration 1460 : 23217002496.0
Loss at iteration 1470 : 12460691456.0
Loss at iteration 1480 : 2522939904.0
Loss at iteration 1490 : 14259940352.0
Loss at iteration 1500 : 4951738880.0
Loss at iteration 1510 : 9047288832.0
Loss at iteration 1520 : 7606811136.0
Loss at iteration 1530 : 10699066368.0
Loss at iteration 1540 : 1279003392.0
Loss at iteration 1550 : 158222106624.0
Loss at iteration 1560 : 4166847488.0
Loss at iteration 1570 : 2826318848.0
Loss at iteration 1580 : 10312660992.0
Loss at iteration 1590 : 8915585024.0
Loss at iteration 1600 : 1554383744.0
Loss at iteration 1610 : 1305697664.0
Loss at iteration 1620 : 8107430912.0
Loss at iteration 1630 : 10798368768.0
Loss at iteration 1640 : 5479577600.0
Loss at iteration 1650 : 3683039744.0
Loss at iteration 1660 : 2728622080.0
Loss at iteration 1670 : 1236508160.0
Loss at iteration 1680 : 64243343360.0
Loss at iteration 1690 : 828333555712.0
Loss at iteration 1700 : 2027995267072.0
Loss at iteration 1710 : 676095000576.0
Loss at iteration 1720 : 47428321280.0
Loss at iteration 1730 : 295645904896.0
Loss at iteration 1740 : 499638304768.0
Loss at iteration 1750 : 130824577024.0
Loss at iteration 1760 : 247602298880.0
Loss at iteration 1770 : 68661510144.0
Loss at iteration 1780 : 170447093760.0
Loss at iteration 1790 : 9797273387008.0
Loss at iteration 1800 : 652405833728.0
Loss at iteration 1810 : 10903235584.0
Loss at iteration 1820 : 232984412160.0
Loss at iteration 1830 : 3589261754368.0
Loss at iteration 1840 : 5168047849472.0
Loss at iteration 1850 : 116692180992.0
Loss at iteration 1860 : 431123660800.0
Loss at iteration 1870 : 1361739907072.0
Loss at iteration 1880 : 437080915968.0
Loss at iteration 1890 : 984335843328.0
Loss at iteration 1900 : 916741095424.0
Loss at iteration 1910 : 8362389405696.0
Loss at iteration 1920 : 339156434944.0
Loss at iteration 1930 : 144676536320.0
Loss at iteration 1940 : 82289451008.0
Loss at iteration 1950 : 887681974272.0
Loss at iteration 1960 : 44177821696.0
Loss at iteration 1970 : 566303588352.0
Loss at iteration 1980 : 121194790912.0
Loss at iteration 1990 : 298533748736.0
Loss at iteration 2000 : 21272903680.0
Loss at iteration 2010 : 129754406912.0
Loss at iteration 2020 : 163132784640.0
Loss at iteration 2030 : 428854837248.0
Loss at iteration 2040 : 70585909248.0
Loss at iteration 2050 : 1424713711616.0
Loss at iteration 2060 : 16010436608.0
Loss at iteration 2070 : 48743436288.0
Loss at iteration 2080 : 627693453312.0
Loss at iteration 2090 : 11292414976.0
Loss at iteration 2100 : 20457533440.0
Loss at iteration 2110 : 69919506432.0
Loss at iteration 2120 : 1698027012096.0
Loss at iteration 2130 : 19671068672.0
Loss at iteration 2140 : 19934844928.0
Loss at iteration 2150 : 220095807488.0
Loss at iteration 2160 : 51334643712.0
Loss at iteration 2170 : 46042849280.0
Loss at iteration 2180 : 39364481024.0
Loss at iteration 2190 : 9581417472.0
Loss at iteration 2200 : 5644059648.0
Loss at iteration 2210 : 1237943582720.0
Loss at iteration 2220 : 72169701376.0
Loss at iteration 2230 : 51318562816.0
Loss at iteration 2240 : 23268243456.0
Loss at iteration 2250 : 4472201728.0
Loss at iteration 2260 : 26103427072.0
Loss at iteration 2270 : 35968163840.0
Loss at iteration 2280 : 369978277888.0
Loss at iteration 2290 : 7670782230528.0
Loss at iteration 2300 : 5662591418368.0
Loss at iteration 2310 : 133682700288.0
Loss at iteration 2320 : 2430128357376.0
Loss at iteration 2330 : 171282219008.0
Loss at iteration 2340 : 10191307276288.0
Loss at iteration 2350 : 7050237050880.0
Loss at iteration 2360 : 778439491584.0
Loss at iteration 2370 : 2033670684672.0
Loss at iteration 2380 : 29291116544.0
Loss at iteration 2390 : 1019413856256.0
Loss at iteration 2400 : 345968050176.0
Loss at iteration 2410 : 6505516498944.0
Loss at iteration 2420 : 94873018368.0
The SSIM Value is: -9.279034989262413e-08
The PSNR Value is: -128.55782725016277
the epoch is: 186
Loss at iteration 10 : 2101020459008.0
Loss at iteration 20 : 4430522482688.0
Loss at iteration 30 : 154689585152.0
Loss at iteration 40 : 108603392000.0
Loss at iteration 50 : 469590638592.0
Loss at iteration 60 : 142960787456.0
Loss at iteration 70 : 127008710656.0
Loss at iteration 80 : 1873697570816.0
Loss at iteration 90 : 208896557056.0
Loss at iteration 100 : 537917030400.0
Loss at iteration 110 : 64385757184.0
Loss at iteration 120 : 538747404288.0
Loss at iteration 130 : 185390841856.0
Loss at iteration 140 : 70937706496.0
Loss at iteration 150 : 39077040128.0
Loss at iteration 160 : 36682702848.0
Loss at iteration 170 : 30119202816.0
Loss at iteration 180 : 173672431616.0
Loss at iteration 190 : 680625373184.0
Loss at iteration 200 : 76097208320.0
Loss at iteration 210 : 20768612352.0
Loss at iteration 220 : 56358043648.0
Loss at iteration 230 : 369997611008.0
Loss at iteration 240 : 50725355520.0
Loss at iteration 250 : 16264612864.0
Loss at iteration 260 : 34468782080.0
Loss at iteration 270 : 29048039424.0
Loss at iteration 280 : 283707244544.0
Loss at iteration 290 : 9540517888.0
Loss at iteration 300 : 91251007488.0
Loss at iteration 310 : 18602692608.0
Loss at iteration 320 : 78525784064.0
Loss at iteration 330 : 26167134208.0
Loss at iteration 340 : 321382318080.0
Loss at iteration 350 : 9993453568.0
Loss at iteration 360 : 87240065024.0
Loss at iteration 370 : 99860865024.0
Loss at iteration 380 : 9638658048.0
Loss at iteration 390 : 118133096448.0
Loss at iteration 400 : 130659868672.0
Loss at iteration 410 : 75016560640.0
Loss at iteration 420 : 1094743097344.0
Loss at iteration 430 : 1237711585280.0
Loss at iteration 440 : 392292761600.0
Loss at iteration 450 : 3854975893504.0
Loss at iteration 460 : 120277860352.0
Loss at iteration 470 : 662879862784.0
Loss at iteration 480 : 103810220032.0
Loss at iteration 490 : 2693877202944.0
Loss at iteration 500 : 1302107783168.0
Loss at iteration 510 : 59696422912.0
Loss at iteration 520 : 31292614656.0
Loss at iteration 530 : 140430868480.0
Loss at iteration 540 : 31917733888.0
Loss at iteration 550 : 30622744576.0
Loss at iteration 560 : 65348640768.0
Loss at iteration 570 : 4286859008.0
Loss at iteration 580 : 33155708928.0
Loss at iteration 590 : 2814000234496.0
Loss at iteration 600 : 539263729664.0
Loss at iteration 610 : 349033529344.0
Loss at iteration 620 : 21381150720.0
Loss at iteration 630 : 260145594368.0
Loss at iteration 640 : 72017354752.0
Loss at iteration 650 : 530450317312.0
Loss at iteration 660 : 249852575744.0
Loss at iteration 670 : 81508605952.0
Loss at iteration 680 : 446130651136.0
Loss at iteration 690 : 36094676992.0
Loss at iteration 700 : 753968349184.0
Loss at iteration 710 : 106964836352.0
Loss at iteration 720 : 138963107840.0
Loss at iteration 730 : 149299150848.0
Loss at iteration 740 : 389201231872.0
Loss at iteration 750 : 1220769742848.0
Loss at iteration 760 : 193765031936.0
Loss at iteration 770 : 3754333044736.0
Loss at iteration 780 : 416248299520.0
Loss at iteration 790 : 6233741852672.0
Loss at iteration 800 : 1682665111552.0
Loss at iteration 810 : 108992544768.0
Loss at iteration 820 : 129482596352.0
Loss at iteration 830 : 3857070424064.0
Loss at iteration 840 : 258300198912.0
Loss at iteration 850 : 171048927232.0
Loss at iteration 860 : 774251937792.0
Loss at iteration 870 : 77305331712.0
Loss at iteration 880 : 130940764160.0
Loss at iteration 890 : 116413743104.0
Loss at iteration 900 : 72279728128.0
Loss at iteration 910 : 52311515136.0
Loss at iteration 920 : 44003573760.0
Loss at iteration 930 : 12331189248.0
Loss at iteration 940 : 73476915200.0
Loss at iteration 950 : 18963683328.0
Loss at iteration 960 : 128425615360.0
Loss at iteration 970 : 8918195200.0
Loss at iteration 980 : 44433641472.0
Loss at iteration 990 : 61956575232.0
Loss at iteration 1000 : 20232615936.0
Loss at iteration 1010 : 37460230144.0
Loss at iteration 1020 : 79427747840.0
Loss at iteration 1030 : 49913810944.0
Loss at iteration 1040 : 23407613952.0
Loss at iteration 1050 : 24584914944.0
Loss at iteration 1060 : 3037253861376.0
Loss at iteration 1070 : 22846265344.0
Loss at iteration 1080 : 25271943168.0
Loss at iteration 1090 : 166543441920.0
Loss at iteration 1100 : 6522508800.0
Loss at iteration 1110 : 5894028800.0
Loss at iteration 1120 : 42287243264.0
Loss at iteration 1130 : 45744652288.0
Loss at iteration 1140 : 24944261120.0
Loss at iteration 1150 : 59652124672.0
Loss at iteration 1160 : 22514274304.0
Loss at iteration 1170 : 25181054976.0
Loss at iteration 1180 : 1705608320.0
Loss at iteration 1190 : 13980636160.0
Loss at iteration 1200 : 5343608832.0
Loss at iteration 1210 : 24665442304.0
Loss at iteration 1220 : 64432283648.0
Loss at iteration 1230 : 317721509888.0
Loss at iteration 1240 : 68640407552.0
Loss at iteration 1250 : 277946662912.0
Loss at iteration 1260 : 1640492800.0
Loss at iteration 1270 : 16585352192.0
Loss at iteration 1280 : 37243912192.0
Loss at iteration 1290 : 3650224384.0
Loss at iteration 1300 : 16629410816.0
Loss at iteration 1310 : 11435955200.0
Loss at iteration 1320 : 13484301312.0
Loss at iteration 1330 : 3437303552.0
Loss at iteration 1340 : 10276884480.0
Loss at iteration 1350 : 7154373632.0
Loss at iteration 1360 : 8572122112.0
Loss at iteration 1370 : 5574598144.0
Loss at iteration 1380 : 10282870784.0
Loss at iteration 1390 : 3554408448.0
Loss at iteration 1400 : 4365590016.0
Loss at iteration 1410 : 51252891648.0
Loss at iteration 1420 : 21449926656.0
Loss at iteration 1430 : 4136864256.0
Loss at iteration 1440 : 14407654400.0
Loss at iteration 1450 : 8729320448.0
Loss at iteration 1460 : 13376220160.0
Loss at iteration 1470 : 9065809920.0
Loss at iteration 1480 : 17603510272.0
Loss at iteration 1490 : 2723633664.0
Loss at iteration 1500 : 3506453504.0
Loss at iteration 1510 : 152790450176.0
Loss at iteration 1520 : 132533927936.0
Loss at iteration 1530 : 49790578688.0
Loss at iteration 1540 : 36500344832.0
Loss at iteration 1550 : 29700694016.0
Loss at iteration 1560 : 25711515648.0
Loss at iteration 1570 : 8762181632.0
Loss at iteration 1580 : 19775428608.0
Loss at iteration 1590 : 25193326592.0
Loss at iteration 1600 : 5552342016.0
Loss at iteration 1610 : 11162125312.0
Loss at iteration 1620 : 10806083584.0
Loss at iteration 1630 : 15079380992.0
Loss at iteration 1640 : 4707293696.0
Loss at iteration 1650 : 109415596032.0
Loss at iteration 1660 : 17613580288.0
Loss at iteration 1670 : 99477618688.0
Loss at iteration 1680 : 5724438016.0
Loss at iteration 1690 : 26786349056.0
Loss at iteration 1700 : 50475950080.0
Loss at iteration 1710 : 4244360704.0
Loss at iteration 1720 : 242401525760.0
Loss at iteration 1730 : 22322565120.0
Loss at iteration 1740 : 6453136384.0
Loss at iteration 1750 : 2864116736.0
Loss at iteration 1760 : 19489110016.0
Loss at iteration 1770 : 25872910336.0
Loss at iteration 1780 : 9454116864.0
Loss at iteration 1790 : 492141051904.0
Loss at iteration 1800 : 2114437382144.0
Loss at iteration 1810 : 150392504320.0
Loss at iteration 1820 : 77660028928.0
Loss at iteration 1830 : 556189614080.0
Loss at iteration 1840 : 29970448384.0
Loss at iteration 1850 : 1671106134016.0
Loss at iteration 1860 : 2117170495488.0
Loss at iteration 1870 : 311228792832.0
Loss at iteration 1880 : 174176026624.0
Loss at iteration 1890 : 89166053376.0
Loss at iteration 1900 : 1673755885568.0
Loss at iteration 1910 : 1220226711552.0
Loss at iteration 1920 : 130322079744.0
Loss at iteration 1930 : 583063502848.0
Loss at iteration 1940 : 560086450176.0
Loss at iteration 1950 : 59641462784.0
Loss at iteration 1960 : 449685225472.0
Loss at iteration 1970 : 2084164730880.0
Loss at iteration 1980 : 99328229376.0
Loss at iteration 1990 : 1937695309824.0
Loss at iteration 2000 : 1420253200384.0
Loss at iteration 2010 : 1389632421888.0
Loss at iteration 2020 : 247019470848.0
Loss at iteration 2030 : 31235571712.0
Loss at iteration 2040 : 1260815253504.0
Loss at iteration 2050 : 295915454464.0
Loss at iteration 2060 : 24445771776.0
Loss at iteration 2070 : 22043287552.0
Loss at iteration 2080 : 16350254080.0
Loss at iteration 2090 : 55113670656.0
Loss at iteration 2100 : 230367166464.0
Loss at iteration 2110 : 186790952960.0
Loss at iteration 2120 : 11263656960.0
Loss at iteration 2130 : 129761435648.0
Loss at iteration 2140 : 14209416192.0
Loss at iteration 2150 : 37143715840.0
Loss at iteration 2160 : 100541956096.0
Loss at iteration 2170 : 808773746688.0
Loss at iteration 2180 : 424369061888.0
Loss at iteration 2190 : 25331367936.0
Loss at iteration 2200 : 901608636416.0
Loss at iteration 2210 : 640211877888.0
Loss at iteration 2220 : 226259632128.0
Loss at iteration 2230 : 622143864832.0
Loss at iteration 2240 : 6098846744576.0
Loss at iteration 2250 : 1000886239232.0
Loss at iteration 2260 : 47647739904.0
Loss at iteration 2270 : 27577849856.0
Loss at iteration 2280 : 222179000320.0
Loss at iteration 2290 : 12219479040.0
Loss at iteration 2300 : 112576585728.0
Loss at iteration 2310 : 998637633536.0
Loss at iteration 2320 : 81584463872.0
Loss at iteration 2330 : 4614410731520.0
Loss at iteration 2340 : 361480224768.0
Loss at iteration 2350 : 35324325888.0
Loss at iteration 2360 : 111880265728.0
Loss at iteration 2370 : 4229368381440.0
Loss at iteration 2380 : 69234024448.0
Loss at iteration 2390 : 315849048064.0
Loss at iteration 2400 : 5240790712320.0
Loss at iteration 2410 : 304309927936.0
Loss at iteration 2420 : 45098573824.0
The SSIM Value is: -2.2968482849180146e-07
The PSNR Value is: -120.05973256429037
the epoch is: 187
Loss at iteration 10 : 52959346688.0
Loss at iteration 20 : 34512433152.0
Loss at iteration 30 : 119194419200.0
Loss at iteration 40 : 23667271680.0
Loss at iteration 50 : 195265740800.0
Loss at iteration 60 : 133606998016.0
Loss at iteration 70 : 5551542272.0
Loss at iteration 80 : 248480792576.0
Loss at iteration 90 : 12524919808.0
Loss at iteration 100 : 20662974464.0
Loss at iteration 110 : 123398070272.0
Loss at iteration 120 : 26594340864.0
Loss at iteration 130 : 79240962048.0
Loss at iteration 140 : 9862207488.0
Loss at iteration 150 : 141100662784.0
Loss at iteration 160 : 31113207808.0
Loss at iteration 170 : 249112199168.0
Loss at iteration 180 : 101523783680.0
Loss at iteration 190 : 164861018112.0
Loss at iteration 200 : 526584676352.0
Loss at iteration 210 : 112501219328.0
Loss at iteration 220 : 13341663232.0
Loss at iteration 230 : 160422100992.0
Loss at iteration 240 : 665798639616.0
Loss at iteration 250 : 340682801152.0
Loss at iteration 260 : 611216457728.0
Loss at iteration 270 : 29681053696.0
Loss at iteration 280 : 6220127744.0
Loss at iteration 290 : 22020550656.0
Loss at iteration 300 : 670400118784.0
Loss at iteration 310 : 59252129792.0
Loss at iteration 320 : 4235129856.0
Loss at iteration 330 : 176910385152.0
Loss at iteration 340 : 191141412864.0
Loss at iteration 350 : 516618289152.0
Loss at iteration 360 : 719647277056.0
Loss at iteration 370 : 44229955584.0
Loss at iteration 380 : 75671093248.0
Loss at iteration 390 : 55011987456.0
Loss at iteration 400 : 182935207936.0
Loss at iteration 410 : 54926307328.0
Loss at iteration 420 : 1596025344.0
Loss at iteration 430 : 64955863040.0
Loss at iteration 440 : 6148505600.0
Loss at iteration 450 : 7966752768.0
Loss at iteration 460 : 24266725376.0
Loss at iteration 470 : 2813249024.0
Loss at iteration 480 : 2313711104.0
Loss at iteration 490 : 54966132736.0
Loss at iteration 500 : 5834072576.0
Loss at iteration 510 : 4129009172480.0
Loss at iteration 520 : 466611339264.0
Loss at iteration 530 : 1861644058624.0
Loss at iteration 540 : 717726482432.0
Loss at iteration 550 : 379007008768.0
Loss at iteration 560 : 2714787381248.0
Loss at iteration 570 : 1010146672640.0
Loss at iteration 580 : 1326535147520.0
Loss at iteration 590 : 187993292800.0
Loss at iteration 600 : 66822475776.0
Loss at iteration 610 : 1141413380096.0
Loss at iteration 620 : 174768275456.0
Loss at iteration 630 : 63491858432.0
Loss at iteration 640 : 124938772480.0
Loss at iteration 650 : 70957826048.0
Loss at iteration 660 : 615977975808.0
Loss at iteration 670 : 15523155968.0
Loss at iteration 680 : 633761693696.0
Loss at iteration 690 : 1930795024384.0
Loss at iteration 700 : 101918654464.0
Loss at iteration 710 : 411248885760.0
Loss at iteration 720 : 44709015552.0
Loss at iteration 730 : 78124179456.0
Loss at iteration 740 : 32656461824.0
Loss at iteration 750 : 72277958656.0
Loss at iteration 760 : 39191662592.0
Loss at iteration 770 : 113790812160.0
Loss at iteration 780 : 1442245771264.0
Loss at iteration 790 : 491621285888.0
Loss at iteration 800 : 69155176448.0
Loss at iteration 810 : 123722022912.0
Loss at iteration 820 : 28538341376.0
Loss at iteration 830 : 53920845824.0
Loss at iteration 840 : 40892932096.0
Loss at iteration 850 : 202203889664.0
Loss at iteration 860 : 72859508736.0
Loss at iteration 870 : 9943984128.0
Loss at iteration 880 : 53726244864.0
Loss at iteration 890 : 25326446592.0
Loss at iteration 900 : 22585552896.0
Loss at iteration 910 : 207381446656.0
Loss at iteration 920 : 348761292800.0
Loss at iteration 930 : 266613260288.0
Loss at iteration 940 : 38218874880.0
Loss at iteration 950 : 871252688896.0
Loss at iteration 960 : 492674482176.0
Loss at iteration 970 : 58085912576.0
Loss at iteration 980 : 220822093824.0
Loss at iteration 990 : 64325197824.0
Loss at iteration 1000 : 25154850816.0
Loss at iteration 1010 : 25632567296.0
Loss at iteration 1020 : 141350797312.0
Loss at iteration 1030 : 7663665152.0
Loss at iteration 1040 : 1709122256896.0
Loss at iteration 1050 : 479324143616.0
Loss at iteration 1060 : 3385494016.0
Loss at iteration 1070 : 55881506816.0
Loss at iteration 1080 : 1608602112.0
Loss at iteration 1090 : 460005900288.0
Loss at iteration 1100 : 15126228992.0
Loss at iteration 1110 : 11190176768.0
Loss at iteration 1120 : 59987824640.0
Loss at iteration 1130 : 527602155520.0
Loss at iteration 1140 : 160571604992.0
Loss at iteration 1150 : 1807556280320.0
Loss at iteration 1160 : 558317633536.0
Loss at iteration 1170 : 84791803904.0
Loss at iteration 1180 : 33351960576.0
Loss at iteration 1190 : 51918172160.0
Loss at iteration 1200 : 89066233856.0
Loss at iteration 1210 : 75006885888.0
Loss at iteration 1220 : 3618994126848.0
Loss at iteration 1230 : 587788320768.0
Loss at iteration 1240 : 399158673408.0
Loss at iteration 1250 : 1160668512256.0
Loss at iteration 1260 : 3052297519104.0
Loss at iteration 1270 : 4948466176.0
Loss at iteration 1280 : 190353997824.0
Loss at iteration 1290 : 2614585720832.0
Loss at iteration 1300 : 111219570638848.0
Loss at iteration 1310 : 565586821120.0
Loss at iteration 1320 : 412217049088.0
Loss at iteration 1330 : 49588484440064.0
Loss at iteration 1340 : 2888706555904.0
Loss at iteration 1350 : 7884186320896.0
Loss at iteration 1360 : 12969319596032.0
Loss at iteration 1370 : 8193420296192.0
Loss at iteration 1380 : 3065728204800.0
Loss at iteration 1390 : 238863040512.0
Loss at iteration 1400 : 4603025817600.0
Loss at iteration 1410 : 53747417088.0
Loss at iteration 1420 : 142796226560.0
Loss at iteration 1430 : 3194244864.0
Loss at iteration 1440 : 141070024704.0
Loss at iteration 1450 : 45432131584.0
Loss at iteration 1460 : 4051176960.0
Loss at iteration 1470 : 2390340864.0
Loss at iteration 1480 : 5672456704.0
Loss at iteration 1490 : 94891278336.0
Loss at iteration 1500 : 353208926208.0
Loss at iteration 1510 : 530029150208.0
Loss at iteration 1520 : 203810635776.0
Loss at iteration 1530 : 7632806400.0
Loss at iteration 1540 : 2327260430336.0
Loss at iteration 1550 : 35971051520.0
Loss at iteration 1560 : 92986318848.0
Loss at iteration 1570 : 1178384728064.0
Loss at iteration 1580 : 155185463296.0
Loss at iteration 1590 : 207141339136.0
Loss at iteration 1600 : 37613230620672.0
Loss at iteration 1610 : 2050626682880.0
Loss at iteration 1620 : 10260669530112.0
Loss at iteration 1630 : 820201717235712.0
Loss at iteration 1640 : 1310622089216.0
Loss at iteration 1650 : 228614701056.0
Loss at iteration 1660 : 3533300826112.0
Loss at iteration 1670 : 1284235591680.0
Loss at iteration 1680 : 3539793608704.0
Loss at iteration 1690 : 109464985600.0
Loss at iteration 1700 : 208436559872.0
Loss at iteration 1710 : 280138481664.0
Loss at iteration 1720 : 650339024896.0
Loss at iteration 1730 : 514774748102656.0
Loss at iteration 1740 : 92685385859072.0
Loss at iteration 1750 : 18914605056.0
Loss at iteration 1760 : 57712222208.0
Loss at iteration 1770 : 197415845888.0
Loss at iteration 1780 : 116281720832.0
Loss at iteration 1790 : 1388588040192.0
Loss at iteration 1800 : 25342003200.0
Loss at iteration 1810 : 301552828416.0
Loss at iteration 1820 : 1482355376128.0
Loss at iteration 1830 : 12847760384.0
Loss at iteration 1840 : 353390034944.0
Loss at iteration 1850 : 205728301056.0
Loss at iteration 1860 : 1176146542592.0
Loss at iteration 1870 : 42819833856.0
Loss at iteration 1880 : 139382554624.0
Loss at iteration 1890 : 62241685504.0
Loss at iteration 1900 : 51792093184.0
Loss at iteration 1910 : 13891390464.0
Loss at iteration 1920 : 5809700339712.0
Loss at iteration 1930 : 7915761664.0
Loss at iteration 1940 : 145492525056.0
Loss at iteration 1950 : 32745359360.0
Loss at iteration 1960 : 349228498944.0
Loss at iteration 1970 : 1083674525696.0
Loss at iteration 1980 : 1283209560064.0
Loss at iteration 1990 : 183223975936.0
Loss at iteration 2000 : 415485919232.0
Loss at iteration 2010 : 69026947072.0
Loss at iteration 2020 : 1274578337792.0
Loss at iteration 2030 : 6850983938228224.0
Loss at iteration 2040 : 61624250368.0
Loss at iteration 2050 : 1143756816384.0
Loss at iteration 2060 : 655182790656.0
Loss at iteration 2070 : 16429534208.0
Loss at iteration 2080 : 1860936663040.0
Loss at iteration 2090 : 22079032262656.0
Loss at iteration 2100 : 368397975552.0
Loss at iteration 2110 : 454799261696.0
Loss at iteration 2120 : 210224388505600.0
Loss at iteration 2130 : 103698227200.0
Loss at iteration 2140 : 5330901139456.0
Loss at iteration 2150 : 19574796288.0
Loss at iteration 2160 : 114284699648.0
Loss at iteration 2170 : 115190058188800.0
Loss at iteration 2180 : 35929704103936.0
Loss at iteration 2190 : 375734403072.0
Loss at iteration 2200 : 1741762854912.0
Loss at iteration 2210 : 16905251840.0
Loss at iteration 2220 : 4779587141632.0
Loss at iteration 2230 : 46788435968.0
Loss at iteration 2240 : 19800270848.0
Loss at iteration 2250 : 250316128256.0
Loss at iteration 2260 : 6201575735296.0
Loss at iteration 2270 : 49806163968.0
Loss at iteration 2280 : 36879114240.0
Loss at iteration 2290 : 200181645312.0
Loss at iteration 2300 : 98707898368.0
Loss at iteration 2310 : 74407583744.0
Loss at iteration 2320 : 23589253120.0
Loss at iteration 2330 : 113547730944.0
Loss at iteration 2340 : 34342222954496.0
Loss at iteration 2350 : 17691758821376.0
Loss at iteration 2360 : 67354656768.0
Loss at iteration 2370 : 420259921920.0
Loss at iteration 2380 : 784282816.0
Loss at iteration 2390 : 50539339776.0
Loss at iteration 2400 : 5543361536.0
Loss at iteration 2410 : 697551028224.0
Loss at iteration 2420 : 757902934016.0
The SSIM Value is: -2.631960966207695e-06
The PSNR Value is: -120.72794138590494
the epoch is: 188
Loss at iteration 10 : 318803214336.0
Loss at iteration 20 : 216999231488.0
Loss at iteration 30 : 15627627520.0
Loss at iteration 40 : 417473953792.0
Loss at iteration 50 : 1278203658240.0
Loss at iteration 60 : 202825744384.0
Loss at iteration 70 : 109484376064.0
Loss at iteration 80 : 160103563264.0
Loss at iteration 90 : 473608028160.0
Loss at iteration 100 : 48490147840.0
Loss at iteration 110 : 211614056448.0
Loss at iteration 120 : 12052769792.0
Loss at iteration 130 : 452842160128.0
Loss at iteration 140 : 31134812160.0
Loss at iteration 150 : 3769800704.0
Loss at iteration 160 : 69000036352.0
Loss at iteration 170 : 326269370368.0
Loss at iteration 180 : 17681047552.0
Loss at iteration 190 : 74397753344.0
Loss at iteration 200 : 54464434176.0
Loss at iteration 210 : 79724118016.0
Loss at iteration 220 : 93394731008.0
Loss at iteration 230 : 95291105280.0
Loss at iteration 240 : 485591842816.0
Loss at iteration 250 : 15963598848.0
Loss at iteration 260 : 1629451904.0
Loss at iteration 270 : 55263191040.0
Loss at iteration 280 : 174375862272.0
Loss at iteration 290 : 48887615488.0
Loss at iteration 300 : 7088196096.0
Loss at iteration 310 : 17739927552.0
Loss at iteration 320 : 103654047744.0
Loss at iteration 330 : 505069535232.0
Loss at iteration 340 : 9223035904.0
Loss at iteration 350 : 144429727744.0
Loss at iteration 360 : 70444998656.0
Loss at iteration 370 : 259161079808.0
Loss at iteration 380 : 157632888832.0
Loss at iteration 390 : 1385888743424.0
Loss at iteration 400 : 400847667200.0
Loss at iteration 410 : 11655988224.0
Loss at iteration 420 : 195110715392.0
Loss at iteration 430 : 23300397056.0
Loss at iteration 440 : 5985956864.0
Loss at iteration 450 : 69913133056.0
Loss at iteration 460 : 21903904768.0
Loss at iteration 470 : 22264653824.0
Loss at iteration 480 : 87469318144.0
Loss at iteration 490 : 12206235648.0
Loss at iteration 500 : 1488851959808.0
Loss at iteration 510 : 46700425216.0
Loss at iteration 520 : 413081436160.0
Loss at iteration 530 : 221760405504.0
Loss at iteration 540 : 1071310438400.0
Loss at iteration 550 : 226632122368.0
Loss at iteration 560 : 1596189696.0
Loss at iteration 570 : 21268070400.0
Loss at iteration 580 : 527056371712.0
Loss at iteration 590 : 3249945600.0
Loss at iteration 600 : 600591680.0
Loss at iteration 610 : 1123314565120.0
Loss at iteration 620 : 423311278080.0
Loss at iteration 630 : 4966243106816.0
Loss at iteration 640 : 31957557248.0
Loss at iteration 650 : 932551655424.0
Loss at iteration 660 : 46875987968.0
Loss at iteration 670 : 52040650752.0
Loss at iteration 680 : 6270439936.0
Loss at iteration 690 : 2646831360.0
Loss at iteration 700 : 9611065344.0
Loss at iteration 710 : 26398392320.0
Loss at iteration 720 : 268225101824.0
Loss at iteration 730 : 15881416704.0
Loss at iteration 740 : 663934664704.0
Loss at iteration 750 : 580074012672.0
Loss at iteration 760 : 40552865792.0
Loss at iteration 770 : 32414433280.0
Loss at iteration 780 : 874283401216.0
Loss at iteration 790 : 528705683456.0
Loss at iteration 800 : 343514775552.0
Loss at iteration 810 : 87475068928.0
Loss at iteration 820 : 313437978624.0
Loss at iteration 830 : 69262196736.0
Loss at iteration 840 : 13866407936.0
Loss at iteration 850 : 11040452608.0
Loss at iteration 860 : 405924610048.0
Loss at iteration 870 : 566072115200.0
Loss at iteration 880 : 32938498457600.0
Loss at iteration 890 : 716313067520.0
Loss at iteration 900 : 1863517732864.0
Loss at iteration 910 : 1018401062912.0
Loss at iteration 920 : 546232631296.0
Loss at iteration 930 : 8077886095360.0
Loss at iteration 940 : 161155481600.0
Loss at iteration 950 : 1161940566016.0
Loss at iteration 960 : 484457381888.0
Loss at iteration 970 : 33000454144.0
Loss at iteration 980 : 142557593600.0
Loss at iteration 990 : 56363278336.0
Loss at iteration 1000 : 14113777664.0
Loss at iteration 1010 : 290659270656.0
Loss at iteration 1020 : 9620237312.0
Loss at iteration 1030 : 207718400000.0
Loss at iteration 1040 : 235198955520.0
Loss at iteration 1050 : 7552427520.0
Loss at iteration 1060 : 254679220224.0
Loss at iteration 1070 : 13203084288.0
Loss at iteration 1080 : 21663242240.0
Loss at iteration 1090 : 161443577856.0
Loss at iteration 1100 : 102999982080.0
Loss at iteration 1110 : 17273395200.0
Loss at iteration 1120 : 24852664320.0
Loss at iteration 1130 : 427376869376.0
Loss at iteration 1140 : 1023097344.0
Loss at iteration 1150 : 185824444416.0
Loss at iteration 1160 : 653100384256.0
Loss at iteration 1170 : 68646080512.0
Loss at iteration 1180 : 55595384832.0
Loss at iteration 1190 : 2746450176.0
Loss at iteration 1200 : 75804631040.0
Loss at iteration 1210 : 29931466752.0
Loss at iteration 1220 : 6694835712.0
Loss at iteration 1230 : 13131179008.0
Loss at iteration 1240 : 7479326720.0
Loss at iteration 1250 : 42422464512.0
Loss at iteration 1260 : 15104407552.0
Loss at iteration 1270 : 3988668928.0
Loss at iteration 1280 : 28065959936.0
Loss at iteration 1290 : 3521517824.0
Loss at iteration 1300 : 909530497024.0
Loss at iteration 1310 : 37529092882432.0
Loss at iteration 1320 : 140713820160.0
Loss at iteration 1330 : 119907721216.0
Loss at iteration 1340 : 123707170816.0
Loss at iteration 1350 : 1235644186624.0
Loss at iteration 1360 : 408127406080.0
Loss at iteration 1370 : 191119179776.0
Loss at iteration 1380 : 85630730240.0
Loss at iteration 1390 : 269874823168.0
Loss at iteration 1400 : 76455985152.0
Loss at iteration 1410 : 245639544832.0
Loss at iteration 1420 : 75774328832.0
Loss at iteration 1430 : 209971331072.0
Loss at iteration 1440 : 90497302528.0
Loss at iteration 1450 : 23083132928.0
Loss at iteration 1460 : 308155940864.0
Loss at iteration 1470 : 203501961216.0
Loss at iteration 1480 : 251769339904.0
Loss at iteration 1490 : 22120904704.0
Loss at iteration 1500 : 368554344448.0
Loss at iteration 1510 : 3350526427136.0
Loss at iteration 1520 : 583675412480.0
Loss at iteration 1530 : 18328460460032.0
Loss at iteration 1540 : 156628074496.0
Loss at iteration 1550 : 55521824768.0
Loss at iteration 1560 : 3603080675328.0
Loss at iteration 1570 : 62441730048.0
Loss at iteration 1580 : 1365512290304.0
Loss at iteration 1590 : 14444610560.0
Loss at iteration 1600 : 117872779264.0
Loss at iteration 1610 : 131076358144.0
Loss at iteration 1620 : 490441539584.0
Loss at iteration 1630 : 649500098560.0
Loss at iteration 1640 : 101976154112.0
Loss at iteration 1650 : 51853881344.0
Loss at iteration 1660 : 775097600.0
Loss at iteration 1670 : 34379501568.0
Loss at iteration 1680 : 32873582592.0
Loss at iteration 1690 : 624719616.0
Loss at iteration 1700 : 384441810944.0
Loss at iteration 1710 : 349488742400.0
Loss at iteration 1720 : 420169728.0
Loss at iteration 1730 : 10752636928.0
Loss at iteration 1740 : 859955527680.0
Loss at iteration 1750 : 19616835584.0
Loss at iteration 1760 : 12246293504.0
Loss at iteration 1770 : 7781929984.0
Loss at iteration 1780 : 1187072896.0
Loss at iteration 1790 : 50712354816.0
Loss at iteration 1800 : 1145080064.0
Loss at iteration 1810 : 1035386752.0
Loss at iteration 1820 : 10512924672.0
Loss at iteration 1830 : 13204676608.0
Loss at iteration 1840 : 7999091712.0
Loss at iteration 1850 : 7745019392.0
Loss at iteration 1860 : 6246543872.0
Loss at iteration 1870 : 28916267008.0
Loss at iteration 1880 : 358811664384.0
Loss at iteration 1890 : 9930542080.0
Loss at iteration 1900 : 67126517760.0
Loss at iteration 1910 : 14518466560.0
Loss at iteration 1920 : 3956119040.0
Loss at iteration 1930 : 138660036608.0
Loss at iteration 1940 : 583350592.0
Loss at iteration 1950 : 2210142720.0
Loss at iteration 1960 : 2145924096.0
Loss at iteration 1970 : 52105990144.0
Loss at iteration 1980 : 7877806592.0
Loss at iteration 1990 : 5101534720.0
Loss at iteration 2000 : 297754591232.0
Loss at iteration 2010 : 170949607424.0
Loss at iteration 2020 : 21747509248.0
Loss at iteration 2030 : 17051130880.0
Loss at iteration 2040 : 333453623296.0
Loss at iteration 2050 : 2781451911168.0
Loss at iteration 2060 : 1308974120960.0
Loss at iteration 2070 : 14228046848.0
Loss at iteration 2080 : 68967358464.0
Loss at iteration 2090 : 345671467008.0
Loss at iteration 2100 : 20198858752.0
Loss at iteration 2110 : 26427461632.0
Loss at iteration 2120 : 1582222592.0
Loss at iteration 2130 : 7487030784.0
Loss at iteration 2140 : 132622385152.0
Loss at iteration 2150 : 73556148224.0
Loss at iteration 2160 : 1453338880.0
Loss at iteration 2170 : 16280938496.0
Loss at iteration 2180 : 2277583872.0
Loss at iteration 2190 : 12996179968.0
Loss at iteration 2200 : 4668340736.0
Loss at iteration 2210 : 1767269888.0
Loss at iteration 2220 : 1383882240.0
Loss at iteration 2230 : 10181311488.0
Loss at iteration 2240 : 14539482112.0
Loss at iteration 2250 : 12860774400.0
Loss at iteration 2260 : 12008255488.0
Loss at iteration 2270 : 25510690816.0
Loss at iteration 2280 : 17322606592.0
Loss at iteration 2290 : 350010272.0
Loss at iteration 2300 : 8342775296.0
Loss at iteration 2310 : 119480213504.0
Loss at iteration 2320 : 58568667136.0
Loss at iteration 2330 : 140071763968.0
Loss at iteration 2340 : 3845072384.0
Loss at iteration 2350 : 3195009792.0
Loss at iteration 2360 : 1592629632.0
Loss at iteration 2370 : 20503799808.0
Loss at iteration 2380 : 4137827072.0
Loss at iteration 2390 : 12048396288.0
Loss at iteration 2400 : 10151110656.0
Loss at iteration 2410 : 752579575808.0
Loss at iteration 2420 : 45890528.0
The SSIM Value is: 3.118539216588149e-06
The PSNR Value is: -111.00831960042318
the epoch is: 189
Loss at iteration 10 : 6044392448.0
Loss at iteration 20 : 4858696704.0
Loss at iteration 30 : 1133599872.0
Loss at iteration 40 : 30817314816.0
Loss at iteration 50 : 38498594816.0
Loss at iteration 60 : 141710245888.0
Loss at iteration 70 : 60892766208.0
Loss at iteration 80 : 14802274304.0
Loss at iteration 90 : 13769404416.0
Loss at iteration 100 : 28993681408.0
Loss at iteration 110 : 2866829312.0
Loss at iteration 120 : 13724985344.0
Loss at iteration 130 : 747854592.0
Loss at iteration 140 : 62212395008.0
Loss at iteration 150 : 1382177792.0
Loss at iteration 160 : 259051732992.0
Loss at iteration 170 : 309940158464.0
Loss at iteration 180 : 19270977191936.0
Loss at iteration 190 : 277202272256.0
Loss at iteration 200 : 2805772582912.0
Loss at iteration 210 : 3719736852480.0
Loss at iteration 220 : 69792120832.0
Loss at iteration 230 : 2667375230976.0
Loss at iteration 240 : 2523272052736.0
Loss at iteration 250 : 224688340992.0
Loss at iteration 260 : 822678192128.0
Loss at iteration 270 : 151625498624.0
Loss at iteration 280 : 6982785826816.0
Loss at iteration 290 : 3786665623552.0
Loss at iteration 300 : 562645893120.0
Loss at iteration 310 : 11378242879488.0
Loss at iteration 320 : 1372268789760.0
Loss at iteration 330 : 23357818880.0
Loss at iteration 340 : 961424850944.0
Loss at iteration 350 : 397159137280.0
Loss at iteration 360 : 592034398208.0
Loss at iteration 370 : 369787961344.0
Loss at iteration 380 : 2822905266176.0
Loss at iteration 390 : 304117219328.0
Loss at iteration 400 : 74715455488.0
Loss at iteration 410 : 59434737664.0
Loss at iteration 420 : 16450128896.0
Loss at iteration 430 : 16668527616.0
Loss at iteration 440 : 29408661504.0
Loss at iteration 450 : 262010404864.0
Loss at iteration 460 : 394827530240.0
Loss at iteration 470 : 343242342400.0
Loss at iteration 480 : 260372528.0
Loss at iteration 490 : 24237029376.0
Loss at iteration 500 : 22345603072.0
Loss at iteration 510 : 422574915584.0
Loss at iteration 520 : 8807307264.0
Loss at iteration 530 : 58533466112.0
Loss at iteration 540 : 22247782400.0
Loss at iteration 550 : 147063078912.0
Loss at iteration 560 : 69369053184.0
Loss at iteration 570 : 28915275776.0
Loss at iteration 580 : 53417738240.0
Loss at iteration 590 : 1113523355648.0
Loss at iteration 600 : 24809060352.0
Loss at iteration 610 : 7028697088.0
Loss at iteration 620 : 200948858880.0
Loss at iteration 630 : 1152657784832.0
Loss at iteration 640 : 42266611712.0
Loss at iteration 650 : 22017667072.0
Loss at iteration 660 : 102933872640.0
Loss at iteration 670 : 326721404928.0
Loss at iteration 680 : 176548577280.0
Loss at iteration 690 : 18635210752.0
Loss at iteration 700 : 71664074752.0
Loss at iteration 710 : 192246544.0
Loss at iteration 720 : 52585463808.0
Loss at iteration 730 : 17088257024.0
Loss at iteration 740 : 16620267520.0
Loss at iteration 750 : 6443283456.0
Loss at iteration 760 : 1296315318272.0
Loss at iteration 770 : 417156384.0
Loss at iteration 780 : 4582986752.0
Loss at iteration 790 : 206433042432.0
Loss at iteration 800 : 131835207680.0
Loss at iteration 810 : 106767992.0
Loss at iteration 820 : 35782021120.0
Loss at iteration 830 : 6095907328.0
Loss at iteration 840 : 3677620992.0
Loss at iteration 850 : 230032752640.0
Loss at iteration 860 : 28807690240.0
Loss at iteration 870 : 138960768.0
Loss at iteration 880 : 906913316864.0
Loss at iteration 890 : 3788815466496.0
Loss at iteration 900 : 21759666176.0
Loss at iteration 910 : 1512657911808.0
Loss at iteration 920 : 152798887936.0
Loss at iteration 930 : 67584069632.0
Loss at iteration 940 : 24884989952.0
Loss at iteration 950 : 1763493543936.0
Loss at iteration 960 : 159252545536.0
Loss at iteration 970 : 508209332224.0
Loss at iteration 980 : 175437545472.0
Loss at iteration 990 : 63845416960.0
Loss at iteration 1000 : 40778506240.0
Loss at iteration 1010 : 163560308736.0
Loss at iteration 1020 : 121159213056.0
Loss at iteration 1030 : 2565908480.0
Loss at iteration 1040 : 345878134784.0
Loss at iteration 1050 : 62424342528.0
Loss at iteration 1060 : 148230651904.0
Loss at iteration 1070 : 107150196736.0
Loss at iteration 1080 : 62114136064.0
Loss at iteration 1090 : 261352259584.0
Loss at iteration 1100 : 295014531072.0
Loss at iteration 1110 : 179900055552.0
Loss at iteration 1120 : 2982128910336.0
Loss at iteration 1130 : 19042226176.0
Loss at iteration 1140 : 162800254976.0
Loss at iteration 1150 : 73163923456.0
Loss at iteration 1160 : 190046617600.0
Loss at iteration 1170 : 350278451200.0
Loss at iteration 1180 : 269630521344.0
Loss at iteration 1190 : 357277466624.0
Loss at iteration 1200 : 187181236224.0
Loss at iteration 1210 : 452229005312.0
Loss at iteration 1220 : 26493685760.0
Loss at iteration 1230 : 1540583981056.0
Loss at iteration 1240 : 554295492608.0
Loss at iteration 1250 : 2583936106496.0
Loss at iteration 1260 : 9956196614144.0
Loss at iteration 1270 : 424644214784.0
Loss at iteration 1280 : 13230353408.0
Loss at iteration 1290 : 35654287360.0
Loss at iteration 1300 : 115351560192.0
Loss at iteration 1310 : 25817970688.0
Loss at iteration 1320 : 10286114816.0
Loss at iteration 1330 : 606747951104.0
Loss at iteration 1340 : 218683359232.0
Loss at iteration 1350 : 1178786594816.0
Loss at iteration 1360 : 16883014656.0
Loss at iteration 1370 : 12125577216.0
Loss at iteration 1380 : 164798480384.0
Loss at iteration 1390 : 59529641984.0
Loss at iteration 1400 : 2638284544.0
Loss at iteration 1410 : 487567589376.0
Loss at iteration 1420 : 6409639936.0
Loss at iteration 1430 : 225356431360.0
Loss at iteration 1440 : 37324460032.0
Loss at iteration 1450 : 519017562112.0
Loss at iteration 1460 : 3715842048.0
Loss at iteration 1470 : 8336788480.0
Loss at iteration 1480 : 7855268352.0
Loss at iteration 1490 : 22886676480.0
Loss at iteration 1500 : 79721570304.0
Loss at iteration 1510 : 1658972800.0
Loss at iteration 1520 : 29423683584.0
Loss at iteration 1530 : 86619856896.0
Loss at iteration 1540 : 36773126144.0
Loss at iteration 1550 : 6182588416.0
Loss at iteration 1560 : 41591869440.0
Loss at iteration 1570 : 15705244672.0
Loss at iteration 1580 : 91889008640.0
Loss at iteration 1590 : 73086648320.0
Loss at iteration 1600 : 7187028992.0
Loss at iteration 1610 : 22500861952.0
Loss at iteration 1620 : 145074978816.0
Loss at iteration 1630 : 54267183104.0
Loss at iteration 1640 : 172125716480.0
Loss at iteration 1650 : 1427364992.0
Loss at iteration 1660 : 171028463616.0
Loss at iteration 1670 : 50334003200.0
Loss at iteration 1680 : 742429312.0
Loss at iteration 1690 : 252839198720.0
Loss at iteration 1700 : 37381160960.0
Loss at iteration 1710 : 18036199424.0
Loss at iteration 1720 : 45730156544.0
Loss at iteration 1730 : 119715995648.0
Loss at iteration 1740 : 62715973632.0
Loss at iteration 1750 : 239625895936.0
Loss at iteration 1760 : 103745044480.0
Loss at iteration 1770 : 26653323264.0
Loss at iteration 1780 : 23861522432.0
Loss at iteration 1790 : 10431599616.0
Loss at iteration 1800 : 2957938944.0
Loss at iteration 1810 : 168985149440.0
Loss at iteration 1820 : 15168918528.0
Loss at iteration 1830 : 31316428800.0
Loss at iteration 1840 : 154124435456.0
Loss at iteration 1850 : 214637314048.0
Loss at iteration 1860 : 10449178624.0
Loss at iteration 1870 : 638201344.0
Loss at iteration 1880 : 51663523840.0
Loss at iteration 1890 : 683448336384.0
Loss at iteration 1900 : 4529302528.0
Loss at iteration 1910 : 2960241152.0
Loss at iteration 1920 : 7361935360.0
Loss at iteration 1930 : 37967278080.0
Loss at iteration 1940 : 17553565696.0
Loss at iteration 1950 : 56846409728.0
Loss at iteration 1960 : 11494578176.0
Loss at iteration 1970 : 128493428736.0
Loss at iteration 1980 : 1851924224.0
Loss at iteration 1990 : 128777000.0
Loss at iteration 2000 : 12891896832.0
Loss at iteration 2010 : 9337578496.0
Loss at iteration 2020 : 13842825216.0
Loss at iteration 2030 : 4496573440.0
Loss at iteration 2040 : 1922166016.0
Loss at iteration 2050 : 47598870528.0
Loss at iteration 2060 : 101601787904.0
Loss at iteration 2070 : 49697204.0
Loss at iteration 2080 : 51264110592.0
Loss at iteration 2090 : 13076896768.0
Loss at iteration 2100 : 1699568896.0
Loss at iteration 2110 : 2494978304.0
Loss at iteration 2120 : 78765547520.0
Loss at iteration 2130 : 1571308160.0
Loss at iteration 2140 : 3895062272.0
Loss at iteration 2150 : 9736587264.0
Loss at iteration 2160 : 9412154368.0
Loss at iteration 2170 : 25071093760.0
Loss at iteration 2180 : 2563763968.0
Loss at iteration 2190 : 6971041280.0
Loss at iteration 2200 : 4027955456.0
Loss at iteration 2210 : 11440833536.0
Loss at iteration 2220 : 7744815104.0
Loss at iteration 2230 : 7801905152.0
Loss at iteration 2240 : 62178348.0
Loss at iteration 2250 : 43623907328.0
Loss at iteration 2260 : 357734144.0
Loss at iteration 2270 : 45893750784.0
Loss at iteration 2280 : 80322248.0
Loss at iteration 2290 : 31035916288.0
Loss at iteration 2300 : 2360947456.0
Loss at iteration 2310 : 615201856.0
Loss at iteration 2320 : 61107838976.0
Loss at iteration 2330 : 13324234752.0
Loss at iteration 2340 : 406722240.0
Loss at iteration 2350 : 571893632.0
Loss at iteration 2360 : 24326879232.0
Loss at iteration 2370 : 1926859392.0
Loss at iteration 2380 : 870370816.0
Loss at iteration 2390 : 19805921280.0
Loss at iteration 2400 : 28511192.0
Loss at iteration 2410 : 61414395904.0
Loss at iteration 2420 : 2627375872.0
The SSIM Value is: 1.6487087407313083e-06
The PSNR Value is: -110.46123708089193
the epoch is: 190
Loss at iteration 10 : 59784081408.0
Loss at iteration 20 : 57815040000.0
Loss at iteration 30 : 202134847488.0
Loss at iteration 40 : 16919842816.0
Loss at iteration 50 : 4713105408.0
Loss at iteration 60 : 683056000.0
Loss at iteration 70 : 5579385864192.0
Loss at iteration 80 : 171807375360.0
Loss at iteration 90 : 608209600512.0
Loss at iteration 100 : 269396262912.0
Loss at iteration 110 : 465089757184.0
Loss at iteration 120 : 14838187008.0
Loss at iteration 130 : 491018485760.0
Loss at iteration 140 : 36190052352.0
Loss at iteration 150 : 9414722560.0
Loss at iteration 160 : 114209202176.0
Loss at iteration 170 : 16206178304.0
Loss at iteration 180 : 559771877376.0
Loss at iteration 190 : 7385559040.0
Loss at iteration 200 : 1820533719040.0
Loss at iteration 210 : 117242093568.0
Loss at iteration 220 : 11938507776.0
Loss at iteration 230 : 226661367808.0
Loss at iteration 240 : 415755894784.0
Loss at iteration 250 : 17979140096.0
Loss at iteration 260 : 57342091264.0
Loss at iteration 270 : 15511112.0
Loss at iteration 280 : 122907624.0
Loss at iteration 290 : 35838578688.0
Loss at iteration 300 : 759269883904.0
Loss at iteration 310 : 6395694592.0
Loss at iteration 320 : 168083603456.0
Loss at iteration 330 : 7070839296.0
Loss at iteration 340 : 93326598144.0
Loss at iteration 350 : 1160331008.0
Loss at iteration 360 : 54340616192.0
Loss at iteration 370 : 327545192448.0
Loss at iteration 380 : 111791308800.0
Loss at iteration 390 : 6735032320.0
Loss at iteration 400 : 29309882368.0
Loss at iteration 410 : 1762657664.0
Loss at iteration 420 : 13892017.0
Loss at iteration 430 : 70587359232.0
Loss at iteration 440 : 14200648704.0
Loss at iteration 450 : 4198829056.0
Loss at iteration 460 : 48147360.0
Loss at iteration 470 : 162207940608.0
Loss at iteration 480 : 6668464128.0
Loss at iteration 490 : 2499064576.0
Loss at iteration 500 : 20293713920.0
Loss at iteration 510 : 10199638016.0
Loss at iteration 520 : 23510145024.0
Loss at iteration 530 : 78019076096.0
Loss at iteration 540 : 362524864.0
Loss at iteration 550 : 916360000.0
Loss at iteration 560 : 2584854016.0
Loss at iteration 570 : 7738682880.0
Loss at iteration 580 : 50181768.0
Loss at iteration 590 : 141633929216.0
Loss at iteration 600 : 60686995456.0
Loss at iteration 610 : 24948574.0
Loss at iteration 620 : 45777231872.0
Loss at iteration 630 : 1472892928.0
Loss at iteration 640 : 863688523776.0
Loss at iteration 650 : 54600437760.0
Loss at iteration 660 : 1244075904.0
Loss at iteration 670 : 275048235008.0
Loss at iteration 680 : 49833234432.0
Loss at iteration 690 : 1889606959104.0
Loss at iteration 700 : 348514144.0
Loss at iteration 710 : 1816123008.0
Loss at iteration 720 : 115342432.0
Loss at iteration 730 : 15561742336.0
Loss at iteration 740 : 41422118912.0
Loss at iteration 750 : 22141779968.0
Loss at iteration 760 : 163887824.0
Loss at iteration 770 : 13541183488.0
Loss at iteration 780 : 136313479168.0
Loss at iteration 790 : 8774941671424.0
Loss at iteration 800 : 81508507648.0
Loss at iteration 810 : 27295442944.0
Loss at iteration 820 : 10682058752.0
Loss at iteration 830 : 2616257.75
Loss at iteration 840 : 92194390016.0
Loss at iteration 850 : 5355021312.0
Loss at iteration 860 : 2794258432.0
Loss at iteration 870 : 7954322432.0
Loss at iteration 880 : 57993108.0
Loss at iteration 890 : 79815704576.0
Loss at iteration 900 : 8112417792.0
Loss at iteration 910 : 926372416.0
Loss at iteration 920 : 2252387328.0
Loss at iteration 930 : 100532740096.0
Loss at iteration 940 : 134332260352.0
Loss at iteration 950 : 44944703488.0
Loss at iteration 960 : 771556224.0
Loss at iteration 970 : 32824598528.0
Loss at iteration 980 : 256151440.0
Loss at iteration 990 : 176717648.0
Loss at iteration 1000 : 5764079104.0
Loss at iteration 1010 : 4639668736.0
Loss at iteration 1020 : 64100835328.0
Loss at iteration 1030 : 3084403456.0
Loss at iteration 1040 : 12453776384.0
Loss at iteration 1050 : 1808447872.0
Loss at iteration 1060 : 1735152896.0
Loss at iteration 1070 : 12934285312.0
Loss at iteration 1080 : 2065137920.0
Loss at iteration 1090 : 8763749376.0
Loss at iteration 1100 : 2240629248.0
Loss at iteration 1110 : 23636738048.0
Loss at iteration 1120 : 366006176.0
Loss at iteration 1130 : 7549524992.0
Loss at iteration 1140 : 123150655488.0
Loss at iteration 1150 : 13832698880.0
Loss at iteration 1160 : 37120232.0
Loss at iteration 1170 : 8200355840.0
Loss at iteration 1180 : 9669598208.0
Loss at iteration 1190 : 6013398016.0
Loss at iteration 1200 : 32744958.0
Loss at iteration 1210 : 15189262336.0
Loss at iteration 1220 : 1080636800.0
Loss at iteration 1230 : 4394662912.0
Loss at iteration 1240 : 1844429824.0
Loss at iteration 1250 : 52145188.0
Loss at iteration 1260 : 2859374080.0
Loss at iteration 1270 : 134274129920.0
Loss at iteration 1280 : 140214832.0
Loss at iteration 1290 : 8165968896.0
Loss at iteration 1300 : 6280474624.0
Loss at iteration 1310 : 1013078656.0
Loss at iteration 1320 : 162922840064.0
Loss at iteration 1330 : 309466752.0
Loss at iteration 1340 : 4957049856.0
Loss at iteration 1350 : 19886180.0
Loss at iteration 1360 : 252825632768.0
Loss at iteration 1370 : 122983336.0
Loss at iteration 1380 : 215947853824.0
Loss at iteration 1390 : 5348158976.0
Loss at iteration 1400 : 12923012096.0
Loss at iteration 1410 : 14214070272.0
Loss at iteration 1420 : 154575388672.0
Loss at iteration 1430 : 12022275072.0
Loss at iteration 1440 : 9364516864.0
Loss at iteration 1450 : 6329362944.0
Loss at iteration 1460 : 19069796352.0
Loss at iteration 1470 : 4969509888.0
Loss at iteration 1480 : 21372082176.0
Loss at iteration 1490 : 2166166016.0
Loss at iteration 1500 : 327445536.0
Loss at iteration 1510 : 84963123200.0
Loss at iteration 1520 : 1484627840.0
Loss at iteration 1530 : 12985873408.0
Loss at iteration 1540 : 879145152.0
Loss at iteration 1550 : 35797245952.0
Loss at iteration 1560 : 3076090112.0
Loss at iteration 1570 : 11919703040.0
Loss at iteration 1580 : 38832720.0
Loss at iteration 1590 : 25346070528.0
Loss at iteration 1600 : 15489760256.0
Loss at iteration 1610 : 3317326592.0
Loss at iteration 1620 : 2074215168.0
Loss at iteration 1630 : 4790860288.0
Loss at iteration 1640 : 173704336.0
Loss at iteration 1650 : 25648668672.0
Loss at iteration 1660 : 2535781376.0
Loss at iteration 1670 : 41695830016.0
Loss at iteration 1680 : 2234372096.0
Loss at iteration 1690 : 7354406400.0
Loss at iteration 1700 : 15441979392.0
Loss at iteration 1710 : 34531934208.0
Loss at iteration 1720 : 4165731328.0
Loss at iteration 1730 : 534030720.0
Loss at iteration 1740 : 1772276864.0
Loss at iteration 1750 : 5116957696.0
Loss at iteration 1760 : 1909457280.0
Loss at iteration 1770 : 10759044096.0
Loss at iteration 1780 : 1250347904.0
Loss at iteration 1790 : 3515563520.0
Loss at iteration 1800 : 1468792576.0
Loss at iteration 1810 : 4185919744.0
Loss at iteration 1820 : 2889012480.0
Loss at iteration 1830 : 2362811648.0
Loss at iteration 1840 : 860045504.0
Loss at iteration 1850 : 75221508096.0
Loss at iteration 1860 : 293674976.0
Loss at iteration 1870 : 302526944.0
Loss at iteration 1880 : 1925299328.0
Loss at iteration 1890 : 3266497280.0
Loss at iteration 1900 : 9519571968.0
Loss at iteration 1910 : 6304407040.0
Loss at iteration 1920 : 121721736.0
Loss at iteration 1930 : 10057927680.0
Loss at iteration 1940 : 763874688.0
Loss at iteration 1950 : 3596192256.0
Loss at iteration 1960 : 107028424.0
Loss at iteration 1970 : 92227056.0
Loss at iteration 1980 : 24594866176.0
Loss at iteration 1990 : 1758549248.0
Loss at iteration 2000 : 9441125376.0
Loss at iteration 2010 : 8269241344.0
Loss at iteration 2020 : 191701888.0
Loss at iteration 2030 : 252550848.0
Loss at iteration 2040 : 1854367616.0
Loss at iteration 2050 : 686567744.0
Loss at iteration 2060 : 1315449088.0
Loss at iteration 2070 : 3418448896.0
Loss at iteration 2080 : 4600944640.0
Loss at iteration 2090 : 108999072.0
Loss at iteration 2100 : 9926169600.0
Loss at iteration 2110 : 93128912.0
Loss at iteration 2120 : 2132568320.0
Loss at iteration 2130 : 1187570432.0
Loss at iteration 2140 : 308196608.0
Loss at iteration 2150 : 2266793472.0
Loss at iteration 2160 : 12625488896.0
Loss at iteration 2170 : 65191464.0
Loss at iteration 2180 : 75209272.0
Loss at iteration 2190 : 861642880.0
Loss at iteration 2200 : 13608216576.0
Loss at iteration 2210 : 197486256.0
Loss at iteration 2220 : 18669826048.0
Loss at iteration 2230 : 6367847936.0
Loss at iteration 2240 : 4508123648.0
Loss at iteration 2250 : 7425129.0
Loss at iteration 2260 : 2751612416.0
Loss at iteration 2270 : 338991840.0
Loss at iteration 2280 : 2444334336.0
Loss at iteration 2290 : 5184695296.0
Loss at iteration 2300 : 13789553664.0
Loss at iteration 2310 : 2156610304.0
Loss at iteration 2320 : 6636855808.0
Loss at iteration 2330 : 64578273280.0
Loss at iteration 2340 : 1853117824.0
Loss at iteration 2350 : 914711488.0
Loss at iteration 2360 : 9083757568.0
Loss at iteration 2370 : 9482333184.0
Loss at iteration 2380 : 355621952.0
Loss at iteration 2390 : 1448299264.0
Loss at iteration 2400 : 6214707712.0
Loss at iteration 2410 : 51851317248.0
Loss at iteration 2420 : 6356426240.0
The SSIM Value is: 3.6963960980074263e-06
The PSNR Value is: -99.43082173665364
the epoch is: 191
Loss at iteration 10 : 5695482368.0
Loss at iteration 20 : 1403258368.0
Loss at iteration 30 : 63672426496.0
Loss at iteration 40 : 17981513728.0
Loss at iteration 50 : 6934993408.0
Loss at iteration 60 : 18931128320.0
Loss at iteration 70 : 7273808896.0
Loss at iteration 80 : 125408952.0
Loss at iteration 90 : 37117748.0
Loss at iteration 100 : 1184019584.0
Loss at iteration 110 : 499851328.0
Loss at iteration 120 : 30886127616.0
Loss at iteration 130 : 62300049408.0
Loss at iteration 140 : 47614948.0
Loss at iteration 150 : 82255368.0
Loss at iteration 160 : 352915712.0
Loss at iteration 170 : 1330650752.0
Loss at iteration 180 : 49621671936.0
Loss at iteration 190 : 114636728.0
Loss at iteration 200 : 855784357888.0
Loss at iteration 210 : 1107143424.0
Loss at iteration 220 : 1751859584.0
Loss at iteration 230 : 441626592.0
Loss at iteration 240 : 15525855232.0
Loss at iteration 250 : 60820116.0
Loss at iteration 260 : 197159088.0
Loss at iteration 270 : 135573405696.0
Loss at iteration 280 : 1647820288.0
Loss at iteration 290 : 24534556672.0
Loss at iteration 300 : 3375967744.0
Loss at iteration 310 : 15540169728.0
Loss at iteration 320 : 910610560.0
Loss at iteration 330 : 11921572.0
Loss at iteration 340 : 2564495360.0
Loss at iteration 350 : 10045888.0
Loss at iteration 360 : 801792768.0
Loss at iteration 370 : 67756592.0
Loss at iteration 380 : 1601155584.0
Loss at iteration 390 : 1085768576.0
Loss at iteration 400 : 759975424.0
Loss at iteration 410 : 2810809.5
Loss at iteration 420 : 6248857600.0
Loss at iteration 430 : 1841773056.0
Loss at iteration 440 : 7568935936.0
Loss at iteration 450 : 233674368.0
Loss at iteration 460 : 15071563776.0
Loss at iteration 470 : 43925053440.0
Loss at iteration 480 : 1392988928.0
Loss at iteration 490 : 16337554432.0
Loss at iteration 500 : 19918988.0
Loss at iteration 510 : 244479024.0
Loss at iteration 520 : 160625280.0
Loss at iteration 530 : 503155584.0
Loss at iteration 540 : 14282323968.0
Loss at iteration 550 : 36190355456.0
Loss at iteration 560 : 72676592.0
Loss at iteration 570 : 917185344.0
Loss at iteration 580 : 19693864.0
Loss at iteration 590 : 430453280.0
Loss at iteration 600 : 35296948.0
Loss at iteration 610 : 1779118336.0
Loss at iteration 620 : 2837667840.0
Loss at iteration 630 : 71622880.0
Loss at iteration 640 : 1208256512.0
Loss at iteration 650 : 7110439936.0
Loss at iteration 660 : 5127394816.0
Loss at iteration 670 : 365159936.0
Loss at iteration 680 : 39305700.0
Loss at iteration 690 : 3858900736.0
Loss at iteration 700 : 568023936.0
Loss at iteration 710 : 856337664.0
Loss at iteration 720 : 9210058752.0
Loss at iteration 730 : 11162195968.0
Loss at iteration 740 : 4920498688.0
Loss at iteration 750 : 10660912.0
Loss at iteration 760 : 1339281664.0
Loss at iteration 770 : 143156384.0
Loss at iteration 780 : 7438094.0
Loss at iteration 790 : 18274678.0
Loss at iteration 800 : 147970256.0
Loss at iteration 810 : 1604938624.0
Loss at iteration 820 : 112736680.0
Loss at iteration 830 : 11978255.0
Loss at iteration 840 : 5989239.5
Loss at iteration 850 : 68666992.0
Loss at iteration 860 : 1196087680.0
Loss at iteration 870 : 7264359.5
Loss at iteration 880 : 631268800.0
Loss at iteration 890 : 1049055552.0
Loss at iteration 900 : 1409824896.0
Loss at iteration 910 : 162847104.0
Loss at iteration 920 : 2024531072.0
Loss at iteration 930 : 3271533312.0
Loss at iteration 940 : 74649152.0
Loss at iteration 950 : 1512713856.0
Loss at iteration 960 : 992522688.0
Loss at iteration 970 : 270982720.0
Loss at iteration 980 : 2976343040.0
Loss at iteration 990 : 6079006208.0
Loss at iteration 1000 : 84189976.0
Loss at iteration 1010 : 84694600.0
Loss at iteration 1020 : 2404308224.0
Loss at iteration 1030 : 350218464.0
Loss at iteration 1040 : 3873281536.0
Loss at iteration 1050 : 252325856.0
Loss at iteration 1060 : 3143040000.0
Loss at iteration 1070 : 72049840.0
Loss at iteration 1080 : 398737152.0
Loss at iteration 1090 : 150986032.0
Loss at iteration 1100 : 434750784.0
Loss at iteration 1110 : 2569799936.0
Loss at iteration 1120 : 16405197824.0
Loss at iteration 1130 : 1603626880.0
Loss at iteration 1140 : 318649280.0
Loss at iteration 1150 : 307528544.0
Loss at iteration 1160 : 525510176.0
Loss at iteration 1170 : 8191127040.0
Loss at iteration 1180 : 2115830.75
Loss at iteration 1190 : 71661272.0
Loss at iteration 1200 : 863020096.0
Loss at iteration 1210 : 4902982144.0
Loss at iteration 1220 : 2387345408.0
Loss at iteration 1230 : 223886416.0
Loss at iteration 1240 : 674604992.0
Loss at iteration 1250 : 240040000.0
Loss at iteration 1260 : 1833953536.0
Loss at iteration 1270 : 2176002048.0
Loss at iteration 1280 : 188629472.0
Loss at iteration 1290 : 5097911808.0
Loss at iteration 1300 : 5385079808.0
Loss at iteration 1310 : 93558744.0
Loss at iteration 1320 : 329507008.0
Loss at iteration 1330 : 169333152.0
Loss at iteration 1340 : 7222495.5
Loss at iteration 1350 : 80889816.0
Loss at iteration 1360 : 3423592.5
Loss at iteration 1370 : 119091416.0
Loss at iteration 1380 : 435974240.0
Loss at iteration 1390 : 69495192.0
Loss at iteration 1400 : 1557373568.0
Loss at iteration 1410 : 949941056.0
Loss at iteration 1420 : 174501504.0
Loss at iteration 1430 : 465330016.0
Loss at iteration 1440 : 98801664.0
Loss at iteration 1450 : 1762220160.0
Loss at iteration 1460 : 581236416.0
Loss at iteration 1470 : 3058114304.0
Loss at iteration 1480 : 3547423.25
Loss at iteration 1490 : 610774848.0
Loss at iteration 1500 : 47995452.0
Loss at iteration 1510 : 1865573248.0
Loss at iteration 1520 : 97194115072.0
Loss at iteration 1530 : 8350648320.0
Loss at iteration 1540 : 31774802.0
Loss at iteration 1550 : 23758480.0
Loss at iteration 1560 : 419281664.0
Loss at iteration 1570 : 1351224960.0
Loss at iteration 1580 : 1691442432.0
Loss at iteration 1590 : 4928480768.0
Loss at iteration 1600 : 25719804.0
Loss at iteration 1610 : 161228992.0
Loss at iteration 1620 : 1703533440.0
Loss at iteration 1630 : 2279731712.0
Loss at iteration 1640 : 641386496.0
Loss at iteration 1650 : 23950790.0
Loss at iteration 1660 : 57983136.0
Loss at iteration 1670 : 14898861056.0
Loss at iteration 1680 : 271570528.0
Loss at iteration 1690 : 650264832.0
Loss at iteration 1700 : 2000467456.0
Loss at iteration 1710 : 930923072.0
Loss at iteration 1720 : 244833152.0
Loss at iteration 1730 : 45716012.0
Loss at iteration 1740 : 2939504640.0
Loss at iteration 1750 : 738051456.0
Loss at iteration 1760 : 273239616.0
Loss at iteration 1770 : 33614588.0
Loss at iteration 1780 : 63867404.0
Loss at iteration 1790 : 262028880.0
Loss at iteration 1800 : 21711304.0
Loss at iteration 1810 : 134587888.0
Loss at iteration 1820 : 4053820928.0
Loss at iteration 1830 : 73719968.0
Loss at iteration 1840 : 13645950.0
Loss at iteration 1850 : 2566856.0
Loss at iteration 1860 : 3867231744.0
Loss at iteration 1870 : 932960576.0
Loss at iteration 1880 : 4718704128.0
Loss at iteration 1890 : 1564384768.0
Loss at iteration 1900 : 36691392.0
Loss at iteration 1910 : 29716628.0
Loss at iteration 1920 : 15184471.0
Loss at iteration 1930 : 46499272.0
Loss at iteration 1940 : 330700544.0
Loss at iteration 1950 : 3174560256.0
Loss at iteration 1960 : 1001191360.0
Loss at iteration 1970 : 954956352.0
Loss at iteration 1980 : 63391948.0
Loss at iteration 1990 : 8487315456.0
Loss at iteration 2000 : 332743840.0
Loss at iteration 2010 : 182565872.0
Loss at iteration 2020 : 102156328.0
Loss at iteration 2030 : 3294340.75
Loss at iteration 2040 : 194818128.0
Loss at iteration 2050 : 60039748.0
Loss at iteration 2060 : 7425926.5
Loss at iteration 2070 : 9615489024.0
Loss at iteration 2080 : 25704540160.0
Loss at iteration 2090 : 1056096000.0
Loss at iteration 2100 : 37922196.0
Loss at iteration 2110 : 98241776.0
Loss at iteration 2120 : 24802540.0
Loss at iteration 2130 : 6149985792.0
Loss at iteration 2140 : 46238784.0
Loss at iteration 2150 : 17793400832.0
Loss at iteration 2160 : 5194724352.0
Loss at iteration 2170 : 4707998720.0
Loss at iteration 2180 : 1355882240.0
Loss at iteration 2190 : 25404220.0
Loss at iteration 2200 : 284323520.0
Loss at iteration 2210 : 911544384.0
Loss at iteration 2220 : 3809022976.0
Loss at iteration 2230 : 5170557952.0
Loss at iteration 2240 : 1088309760.0
Loss at iteration 2250 : 1463230592.0
Loss at iteration 2260 : 9680764928.0
Loss at iteration 2270 : 126346720.0
Loss at iteration 2280 : 346177408.0
Loss at iteration 2290 : 121336736.0
Loss at iteration 2300 : 403815776.0
Loss at iteration 2310 : 9105556.0
Loss at iteration 2320 : 7491938.5
Loss at iteration 2330 : 911141120.0
Loss at iteration 2340 : 384908224.0
Loss at iteration 2350 : 40406128.0
Loss at iteration 2360 : 39813708.0
Loss at iteration 2370 : 47302492.0
Loss at iteration 2380 : 359020640.0
Loss at iteration 2390 : 5096771072.0
Loss at iteration 2400 : 15885539328.0
Loss at iteration 2410 : 1105752704.0
Loss at iteration 2420 : 1324173824.0
The SSIM Value is: 9.02759282629025e-06
The PSNR Value is: -103.41216888427735
the epoch is: 192
Loss at iteration 10 : 832128192.0
Loss at iteration 20 : 3420437248.0
Loss at iteration 30 : 5324966912.0
Loss at iteration 40 : 518678208.0
Loss at iteration 50 : 897101760.0
Loss at iteration 60 : 16294656.0
Loss at iteration 70 : 55738764.0
Loss at iteration 80 : 15234969.0
Loss at iteration 90 : 2210693120.0
Loss at iteration 100 : 3219111424.0
Loss at iteration 110 : 197791392.0
Loss at iteration 120 : 3028835584.0
Loss at iteration 130 : 406191136.0
Loss at iteration 140 : 93250808.0
Loss at iteration 150 : 52160760.0
Loss at iteration 160 : 4723729920.0
Loss at iteration 170 : 277748928.0
Loss at iteration 180 : 451269376.0
Loss at iteration 190 : 808090816.0
Loss at iteration 200 : 179960544.0
Loss at iteration 210 : 4706476544.0
Loss at iteration 220 : 2396045312.0
Loss at iteration 230 : 23546848.0
Loss at iteration 240 : 2434802432.0
Loss at iteration 250 : 6714595328.0
Loss at iteration 260 : 2099304064.0
Loss at iteration 270 : 6966283776.0
Loss at iteration 280 : 200565904.0
Loss at iteration 290 : 5647026176.0
Loss at iteration 300 : 4322913.5
Loss at iteration 310 : 5823699456.0
Loss at iteration 320 : 5420000256.0
Loss at iteration 330 : 852033984.0
Loss at iteration 340 : 1165026816.0
Loss at iteration 350 : 4248984832.0
Loss at iteration 360 : 331778432.0
Loss at iteration 370 : 1282537600.0
Loss at iteration 380 : 3730753280.0
Loss at iteration 390 : 86265168.0
Loss at iteration 400 : 74802208768.0
Loss at iteration 410 : 1122034432.0
Loss at iteration 420 : 117827182592.0
Loss at iteration 430 : 4340497776640.0
Loss at iteration 440 : 1606347259904.0
Loss at iteration 450 : 107348738048.0
Loss at iteration 460 : 962919792640.0
Loss at iteration 470 : 4652841566208.0
Loss at iteration 480 : 30974035968.0
Loss at iteration 490 : 77869400064.0
Loss at iteration 500 : 1181336862720.0
Loss at iteration 510 : 1155217620992.0
Loss at iteration 520 : 4014746107904.0
Loss at iteration 530 : 1935680339968.0
Loss at iteration 540 : 187190247424.0
Loss at iteration 550 : 2046773559296.0
Loss at iteration 560 : 545658109952.0
Loss at iteration 570 : 62946123776.0
Loss at iteration 580 : 38400602112.0
Loss at iteration 590 : 185890455552.0
Loss at iteration 600 : 6560948224.0
Loss at iteration 610 : 101577457664.0
Loss at iteration 620 : 18242144256.0
Loss at iteration 630 : 365987659776.0
Loss at iteration 640 : 589832781824.0
Loss at iteration 650 : 181048000512.0
Loss at iteration 660 : 149894119424.0
Loss at iteration 670 : 32799651840.0
Loss at iteration 680 : 273384734720.0
Loss at iteration 690 : 2050487484416.0
Loss at iteration 700 : 791328849920.0
Loss at iteration 710 : 27418744832.0
Loss at iteration 720 : 1305395593216.0
Loss at iteration 730 : 201209413632.0
Loss at iteration 740 : 33694257152.0
Loss at iteration 750 : 41087918080.0
Loss at iteration 760 : 306080219136.0
Loss at iteration 770 : 34241480704.0
Loss at iteration 780 : 3271938015232.0
Loss at iteration 790 : 3265969520640.0
Loss at iteration 800 : 81039269888.0
Loss at iteration 810 : 63104659456.0
Loss at iteration 820 : 1234482757632.0
Loss at iteration 830 : 796171632640.0
Loss at iteration 840 : 265623306240.0
Loss at iteration 850 : 9033101312.0
Loss at iteration 860 : 274803310592.0
Loss at iteration 870 : 7639290871808.0
Loss at iteration 880 : 78436810752.0
Loss at iteration 890 : 13369560064.0
Loss at iteration 900 : 110433558528.0
Loss at iteration 910 : 46147694592.0
Loss at iteration 920 : 17435746304.0
Loss at iteration 930 : 272238886912.0
Loss at iteration 940 : 9603136512.0
Loss at iteration 950 : 96933879808.0
Loss at iteration 960 : 72546885632.0
Loss at iteration 970 : 560936058880.0
Loss at iteration 980 : 4564641792.0
Loss at iteration 990 : 168872001536.0
Loss at iteration 1000 : 70733201408.0
Loss at iteration 1010 : 6883523584.0
Loss at iteration 1020 : 940814761984.0
Loss at iteration 1030 : 14910800896.0
Loss at iteration 1040 : 160169099264.0
Loss at iteration 1050 : 9712781312.0
Loss at iteration 1060 : 54496280576.0
Loss at iteration 1070 : 93871276032.0
Loss at iteration 1080 : 10088999936.0
Loss at iteration 1090 : 81588625408.0
Loss at iteration 1100 : 53821763584.0
Loss at iteration 1110 : 221831708672.0
Loss at iteration 1120 : 47334096896.0
Loss at iteration 1130 : 33805746176.0
Loss at iteration 1140 : 175907749888.0
Loss at iteration 1150 : 34596630528.0
Loss at iteration 1160 : 69415747584.0
Loss at iteration 1170 : 26475278336.0
Loss at iteration 1180 : 37136850944.0
Loss at iteration 1190 : 10996285440.0
Loss at iteration 1200 : 25271713792.0
Loss at iteration 1210 : 52978237440.0
Loss at iteration 1220 : 8199677952.0
Loss at iteration 1230 : 43841376256.0
Loss at iteration 1240 : 819982172160.0
Loss at iteration 1250 : 10375651328.0
Loss at iteration 1260 : 36383387648.0
Loss at iteration 1270 : 78404534272.0
Loss at iteration 1280 : 250851442688.0
Loss at iteration 1290 : 438878666752.0
Loss at iteration 1300 : 105140822016.0
Loss at iteration 1310 : 175851487232.0
Loss at iteration 1320 : 133106647040.0
Loss at iteration 1330 : 365592313856.0
Loss at iteration 1340 : 87026016256.0
Loss at iteration 1350 : 12722631680.0
Loss at iteration 1360 : 188971302912.0
Loss at iteration 1370 : 123777155072.0
Loss at iteration 1380 : 334776991744.0
Loss at iteration 1390 : 452569628672.0
Loss at iteration 1400 : 277613510656.0
Loss at iteration 1410 : 856379228160.0
Loss at iteration 1420 : 34202615808.0
Loss at iteration 1430 : 92720758784.0
Loss at iteration 1440 : 37805576192.0
Loss at iteration 1450 : 30270619648.0
Loss at iteration 1460 : 35225108480.0
Loss at iteration 1470 : 7452571992064.0
Loss at iteration 1480 : 669329391616.0
Loss at iteration 1490 : 211070287872.0
Loss at iteration 1500 : 314435862528.0
Loss at iteration 1510 : 67907809280.0
Loss at iteration 1520 : 296768405504.0
Loss at iteration 1530 : 6245104222208.0
Loss at iteration 1540 : 250496860160.0
Loss at iteration 1550 : 174252933120.0
Loss at iteration 1560 : 271705260032.0
Loss at iteration 1570 : 113154170880.0
Loss at iteration 1580 : 265646325760.0
Loss at iteration 1590 : 39042527232.0
Loss at iteration 1600 : 190066900992.0
Loss at iteration 1610 : 737350320128.0
Loss at iteration 1620 : 1885130457088.0
Loss at iteration 1630 : 8186158907392.0
Loss at iteration 1640 : 512776830976.0
Loss at iteration 1650 : 17583286272.0
Loss at iteration 1660 : 428092260352.0
Loss at iteration 1670 : 631669248.0
Loss at iteration 1680 : 95739551744.0
Loss at iteration 1690 : 22271246336.0
Loss at iteration 1700 : 3054303744.0
Loss at iteration 1710 : 138169581568.0
Loss at iteration 1720 : 66881466368.0
Loss at iteration 1730 : 50807103488.0
Loss at iteration 1740 : 134506127360.0
Loss at iteration 1750 : 606495244288.0
Loss at iteration 1760 : 27594240000.0
Loss at iteration 1770 : 971494976.0
Loss at iteration 1780 : 1070837120.0
Loss at iteration 1790 : 144109813760.0
Loss at iteration 1800 : 9883389952.0
Loss at iteration 1810 : 27294359552.0
Loss at iteration 1820 : 25231908864.0
Loss at iteration 1830 : 4660140032.0
Loss at iteration 1840 : 1358313856.0
Loss at iteration 1850 : 16988980224.0
Loss at iteration 1860 : 19233931264.0
Loss at iteration 1870 : 4493989376.0
Loss at iteration 1880 : 29641869312.0
Loss at iteration 1890 : 41663803392.0
Loss at iteration 1900 : 188849717248.0
Loss at iteration 1910 : 35825942528.0
Loss at iteration 1920 : 17918003200.0
Loss at iteration 1930 : 3858008899584.0
Loss at iteration 1940 : 408757403648.0
Loss at iteration 1950 : 139770085376.0
Loss at iteration 1960 : 557095387136.0
Loss at iteration 1970 : 17529032409088.0
Loss at iteration 1980 : 27574428237824.0
Loss at iteration 1990 : 110729863168.0
Loss at iteration 2000 : 2388197376000.0
Loss at iteration 2010 : 1400041897984.0
Loss at iteration 2020 : 447118175109120.0
Loss at iteration 2030 : 2713190137856.0
Loss at iteration 2040 : 22879378866176.0
Loss at iteration 2050 : 4011914428416.0
Loss at iteration 2060 : 9200881106944.0
Loss at iteration 2070 : 700443131904.0
Loss at iteration 2080 : 104488903901184.0
Loss at iteration 2090 : 99929536069632.0
Loss at iteration 2100 : 1642208690176.0
Loss at iteration 2110 : 1080589090816.0
Loss at iteration 2120 : 926759452672.0
Loss at iteration 2130 : 20348347088896.0
Loss at iteration 2140 : 612100145152.0
Loss at iteration 2150 : 17889121796096.0
Loss at iteration 2160 : 45246947786752.0
Loss at iteration 2170 : 3724356616192.0
Loss at iteration 2180 : 1412660985856.0
Loss at iteration 2190 : 5161571319808.0
Loss at iteration 2200 : 228270374912.0
Loss at iteration 2210 : 1373318283264.0
Loss at iteration 2220 : 1263435513856.0
Loss at iteration 2230 : 496687185920.0
Loss at iteration 2240 : 824837537792.0
Loss at iteration 2250 : 231995637760.0
Loss at iteration 2260 : 758262071296.0
Loss at iteration 2270 : 1341835968512.0
Loss at iteration 2280 : 90739834880.0
Loss at iteration 2290 : 196425646080.0
Loss at iteration 2300 : 743118143488.0
Loss at iteration 2310 : 1145329156096.0
Loss at iteration 2320 : 3295669649408.0
Loss at iteration 2330 : 15406335000576.0
Loss at iteration 2340 : 32177324556288.0
Loss at iteration 2350 : 1009783734272.0
Loss at iteration 2360 : 2535889567744.0
Loss at iteration 2370 : 144950427648.0
Loss at iteration 2380 : 28792032591872.0
Loss at iteration 2390 : 3399703068672.0
Loss at iteration 2400 : 147779305472.0
Loss at iteration 2410 : 14690725888.0
Loss at iteration 2420 : 370588909568.0
The SSIM Value is: 6.146883824461232e-07
The PSNR Value is: -122.25030314127604
the epoch is: 193
Loss at iteration 10 : 653988724736.0
Loss at iteration 20 : 195861217280.0
Loss at iteration 30 : 691632340992.0
Loss at iteration 40 : 123840724992.0
Loss at iteration 50 : 2124902694912.0
Loss at iteration 60 : 134143066112.0
Loss at iteration 70 : 137443901440.0
Loss at iteration 80 : 3944346288128.0
Loss at iteration 90 : 2553410486272.0
Loss at iteration 100 : 34002190729216.0
Loss at iteration 110 : 416776716288.0
Loss at iteration 120 : 7923049168896.0
Loss at iteration 130 : 2633112485888.0
Loss at iteration 140 : 676477599744.0
Loss at iteration 150 : 237939343360.0
Loss at iteration 160 : 1060591763456.0
Loss at iteration 170 : 62939729920.0
Loss at iteration 180 : 83638575104.0
Loss at iteration 190 : 8417233600512.0
Loss at iteration 200 : 7488875520.0
Loss at iteration 210 : 490065100800.0
Loss at iteration 220 : 18718969856.0
Loss at iteration 230 : 1531994832896.0
Loss at iteration 240 : 98709331968.0
Loss at iteration 250 : 296229765120.0
Loss at iteration 260 : 829705748480.0
Loss at iteration 270 : 1621579661312.0
Loss at iteration 280 : 719040937984.0
Loss at iteration 290 : 51544854528.0
Loss at iteration 300 : 253697687552.0
Loss at iteration 310 : 6852609310720.0
Loss at iteration 320 : 92248350720.0
Loss at iteration 330 : 223901843456.0
Loss at iteration 340 : 12974552064.0
Loss at iteration 350 : 59212967936.0
Loss at iteration 360 : 30012653568.0
Loss at iteration 370 : 662505455616.0
Loss at iteration 380 : 3099029667840.0
Loss at iteration 390 : 16083758088192.0
Loss at iteration 400 : 573718724608.0
Loss at iteration 410 : 217901416448.0
Loss at iteration 420 : 581200379904.0
Loss at iteration 430 : 276863909888.0
Loss at iteration 440 : 331917688832.0
Loss at iteration 450 : 1540609802240.0
Loss at iteration 460 : 571666006016.0
Loss at iteration 470 : 154732691456.0
Loss at iteration 480 : 310225666048.0
Loss at iteration 490 : 6965983232.0
Loss at iteration 500 : 249889177600.0
Loss at iteration 510 : 294040535040.0
Loss at iteration 520 : 108853198848.0
Loss at iteration 530 : 260527947776.0
Loss at iteration 540 : 633322405888.0
Loss at iteration 550 : 206566932480.0
Loss at iteration 560 : 693940453376.0
Loss at iteration 570 : 55421087744.0
Loss at iteration 580 : 259193815040.0
Loss at iteration 590 : 4608010747904.0
Loss at iteration 600 : 60531556352.0
Loss at iteration 610 : 231331168256.0
Loss at iteration 620 : 996785192960.0
Loss at iteration 630 : 811183570944.0
Loss at iteration 640 : 115928989696.0
Loss at iteration 650 : 710372360192.0
Loss at iteration 660 : 40815710208.0
Loss at iteration 670 : 9369649152.0
Loss at iteration 680 : 67568967680.0
Loss at iteration 690 : 65481093120.0
Loss at iteration 700 : 57047576576.0
Loss at iteration 710 : 32928264192.0
Loss at iteration 720 : 224246972416.0
Loss at iteration 730 : 647324237824.0
Loss at iteration 740 : 4476584853504.0
Loss at iteration 750 : 40573521920.0
Loss at iteration 760 : 4403689472.0
Loss at iteration 770 : 159711166464.0
Loss at iteration 780 : 101507457024.0
Loss at iteration 790 : 351474057216.0
Loss at iteration 800 : 33566730240.0
Loss at iteration 810 : 203194007552.0
Loss at iteration 820 : 64918818816.0
Loss at iteration 830 : 10421614592.0
Loss at iteration 840 : 650256777216.0
Loss at iteration 850 : 2439045709824.0
Loss at iteration 860 : 31032940544.0
Loss at iteration 870 : 96043892736.0
Loss at iteration 880 : 416535445504.0
Loss at iteration 890 : 243926827008.0
Loss at iteration 900 : 172627001344.0
Loss at iteration 910 : 462998470656.0
Loss at iteration 920 : 209618976768.0
Loss at iteration 930 : 132164231168.0
Loss at iteration 940 : 140843761664.0
Loss at iteration 950 : 270645919744.0
Loss at iteration 960 : 2885263360.0
Loss at iteration 970 : 1544039040.0
Loss at iteration 980 : 30102761472.0
Loss at iteration 990 : 5632033792.0
Loss at iteration 1000 : 761433292800.0
Loss at iteration 1010 : 775367819264.0
Loss at iteration 1020 : 7497220096.0
Loss at iteration 1030 : 358500630528.0
Loss at iteration 1040 : 292260642816.0
Loss at iteration 1050 : 6637775360.0
Loss at iteration 1060 : 94281572352.0
Loss at iteration 1070 : 347554578432.0
Loss at iteration 1080 : 92931440640.0
Loss at iteration 1090 : 13049151488.0
Loss at iteration 1100 : 350763384832.0
Loss at iteration 1110 : 6621339136.0
Loss at iteration 1120 : 480831209472.0
Loss at iteration 1130 : 2611702398976.0
Loss at iteration 1140 : 70410960896.0
Loss at iteration 1150 : 78096384000.0
Loss at iteration 1160 : 58070114304.0
Loss at iteration 1170 : 41120501760.0
Loss at iteration 1180 : 86428246016.0
Loss at iteration 1190 : 31969988608.0
Loss at iteration 1200 : 76908199936.0
Loss at iteration 1210 : 140756516864.0
Loss at iteration 1220 : 341352742912.0
Loss at iteration 1230 : 18562521088.0
Loss at iteration 1240 : 535719215104.0
Loss at iteration 1250 : 510509056000.0
Loss at iteration 1260 : 159439192064.0
Loss at iteration 1270 : 83325468672.0
Loss at iteration 1280 : 450285699072.0
Loss at iteration 1290 : 246249603072.0
Loss at iteration 1300 : 209617534976.0
Loss at iteration 1310 : 1168926179328.0
Loss at iteration 1320 : 311511777280.0
Loss at iteration 1330 : 505531138048.0
Loss at iteration 1340 : 30924253167616.0
Loss at iteration 1350 : 2076176678912.0
Loss at iteration 1360 : 561732190208.0
Loss at iteration 1370 : 1867326423040.0
Loss at iteration 1380 : 52809990144.0
Loss at iteration 1390 : 4630672048128.0
Loss at iteration 1400 : 673372176384.0
Loss at iteration 1410 : 42185838592.0
Loss at iteration 1420 : 4639328567296.0
Loss at iteration 1430 : 1625616416768.0
Loss at iteration 1440 : 14727503872.0
Loss at iteration 1450 : 80936501248.0
Loss at iteration 1460 : 29324879872.0
Loss at iteration 1470 : 2180056612864.0
Loss at iteration 1480 : 20634740736.0
Loss at iteration 1490 : 1310822656.0
Loss at iteration 1500 : 103738392576.0
Loss at iteration 1510 : 513633320960.0
Loss at iteration 1520 : 101593251840.0
Loss at iteration 1530 : 83649945600.0
Loss at iteration 1540 : 197314887680.0
Loss at iteration 1550 : 165848236032.0
Loss at iteration 1560 : 9058706432.0
Loss at iteration 1570 : 9657196544.0
Loss at iteration 1580 : 386994733056.0
Loss at iteration 1590 : 103642234880.0
Loss at iteration 1600 : 23450689536.0
Loss at iteration 1610 : 446110105600.0
Loss at iteration 1620 : 9304003584.0
Loss at iteration 1630 : 580036657152.0
Loss at iteration 1640 : 1122361540608.0
Loss at iteration 1650 : 9005173833728.0
Loss at iteration 1660 : 2171073331200.0
Loss at iteration 1670 : 1852489859072.0
Loss at iteration 1680 : 1861261328384.0
Loss at iteration 1690 : 360063729664.0
Loss at iteration 1700 : 25398746284032.0
Loss at iteration 1710 : 1345199669248.0
Loss at iteration 1720 : 6420134625280.0
Loss at iteration 1730 : 71841447936.0
Loss at iteration 1740 : 1787233042432.0
Loss at iteration 1750 : 815335276544.0
Loss at iteration 1760 : 314973323264.0
Loss at iteration 1770 : 7700553400320.0
Loss at iteration 1780 : 267566120960.0
Loss at iteration 1790 : 10321636352.0
Loss at iteration 1800 : 401616797696.0
Loss at iteration 1810 : 346198376448.0
Loss at iteration 1820 : 144709484544.0
Loss at iteration 1830 : 3193161646080.0
Loss at iteration 1840 : 41422864384.0
Loss at iteration 1850 : 2178655191040.0
Loss at iteration 1860 : 664490803200.0
Loss at iteration 1870 : 1096611201024.0
Loss at iteration 1880 : 118422495232.0
Loss at iteration 1890 : 1719762560.0
Loss at iteration 1900 : 54504259584.0
Loss at iteration 1910 : 120872034304.0
Loss at iteration 1920 : 20254066688.0
Loss at iteration 1930 : 60851212288.0
Loss at iteration 1940 : 2087261175808.0
Loss at iteration 1950 : 12960321536.0
Loss at iteration 1960 : 33860564992.0
Loss at iteration 1970 : 2144977536.0
Loss at iteration 1980 : 180292485120.0
Loss at iteration 1990 : 94496292864.0
Loss at iteration 2000 : 55954898944.0
Loss at iteration 2010 : 75164991488.0
Loss at iteration 2020 : 1385835134976.0
Loss at iteration 2030 : 83313827840.0
Loss at iteration 2040 : 407687987200.0
Loss at iteration 2050 : 86600204288.0
Loss at iteration 2060 : 32394205184.0
Loss at iteration 2070 : 2426388736.0
Loss at iteration 2080 : 272735207424.0
Loss at iteration 2090 : 66500759552.0
Loss at iteration 2100 : 369454317568.0
Loss at iteration 2110 : 244515979264.0
Loss at iteration 2120 : 38926462976.0
Loss at iteration 2130 : 77314138112.0
Loss at iteration 2140 : 353248378880.0
Loss at iteration 2150 : 8384380928.0
Loss at iteration 2160 : 25441796096.0
Loss at iteration 2170 : 423682473984.0
Loss at iteration 2180 : 715540594688.0
Loss at iteration 2190 : 38578937856.0
Loss at iteration 2200 : 28350484480.0
Loss at iteration 2210 : 8449572352.0
Loss at iteration 2220 : 13615606784.0
Loss at iteration 2230 : 25622503424.0
Loss at iteration 2240 : 68796907520.0
Loss at iteration 2250 : 473157271552.0
Loss at iteration 2260 : 619184390144.0
Loss at iteration 2270 : 26923644928.0
Loss at iteration 2280 : 245101133824.0
Loss at iteration 2290 : 2038924544.0
Loss at iteration 2300 : 4307290685440.0
Loss at iteration 2310 : 57841745920.0
Loss at iteration 2320 : 97442136064.0
Loss at iteration 2330 : 223983534080.0
Loss at iteration 2340 : 10726295552.0
Loss at iteration 2350 : 57966710784.0
Loss at iteration 2360 : 47413235712.0
Loss at iteration 2370 : 108030910464.0
Loss at iteration 2380 : 92365406208.0
Loss at iteration 2390 : 2610122457088.0
Loss at iteration 2400 : 249883459584.0
Loss at iteration 2410 : 129691926528.0
Loss at iteration 2420 : 15090727936.0
The SSIM Value is: -5.580079111192996e-06
The PSNR Value is: -120.04491933186848
the epoch is: 194
Loss at iteration 10 : 1052289204224.0
Loss at iteration 20 : 677176016896.0
Loss at iteration 30 : 40390389760.0
Loss at iteration 40 : 453257723904.0
Loss at iteration 50 : 105847234560.0
Loss at iteration 60 : 18701135872.0
Loss at iteration 70 : 90240180224.0
Loss at iteration 80 : 738441887744.0
Loss at iteration 90 : 4276431616.0
Loss at iteration 100 : 5521649664.0
Loss at iteration 110 : 83160752128.0
Loss at iteration 120 : 254937563136.0
Loss at iteration 130 : 12681795584.0
Loss at iteration 140 : 4857570304.0
Loss at iteration 150 : 17363961856.0
Loss at iteration 160 : 976601022464.0
Loss at iteration 170 : 110123360256.0
Loss at iteration 180 : 17975513088.0
Loss at iteration 190 : 24348104704.0
Loss at iteration 200 : 40362803200.0
Loss at iteration 210 : 190273421312.0
Loss at iteration 220 : 17898342400.0
Loss at iteration 230 : 723332825088.0
Loss at iteration 240 : 15250095104.0
Loss at iteration 250 : 128354926592.0
Loss at iteration 260 : 61820739584.0
Loss at iteration 270 : 98483994624.0
Loss at iteration 280 : 667872460800.0
Loss at iteration 290 : 59145113600.0
Loss at iteration 300 : 3559990528.0
Loss at iteration 310 : 219603501056.0
Loss at iteration 320 : 308717813760.0
Loss at iteration 330 : 44044660736.0
Loss at iteration 340 : 21838772224.0
Loss at iteration 350 : 7321686016.0
Loss at iteration 360 : 25277237248.0
Loss at iteration 370 : 4372725248.0
Loss at iteration 380 : 62859976704.0
Loss at iteration 390 : 159648317440.0
Loss at iteration 400 : 98581348352.0
Loss at iteration 410 : 32253048832.0
Loss at iteration 420 : 16746042368.0
Loss at iteration 430 : 40578805760.0
Loss at iteration 440 : 21352376320.0
Loss at iteration 450 : 28828735488.0
Loss at iteration 460 : 2175238930432.0
Loss at iteration 470 : 276429078528.0
Loss at iteration 480 : 15534262272.0
Loss at iteration 490 : 892557852672.0
Loss at iteration 500 : 168538210304.0
Loss at iteration 510 : 26457546752.0
Loss at iteration 520 : 51386630144.0
Loss at iteration 530 : 36288806912.0
Loss at iteration 540 : 7673720320.0
Loss at iteration 550 : 3514483867648.0
Loss at iteration 560 : 1143360716800.0
Loss at iteration 570 : 57654505472.0
Loss at iteration 580 : 58204913664.0
Loss at iteration 590 : 13663432704.0
Loss at iteration 600 : 31172861952.0
Loss at iteration 610 : 1620760068096.0
Loss at iteration 620 : 140403621888.0
Loss at iteration 630 : 173030883328.0
Loss at iteration 640 : 28743430144.0
Loss at iteration 650 : 188644671488.0
Loss at iteration 660 : 529969807360.0
Loss at iteration 670 : 1518688534528.0
Loss at iteration 680 : 65464406016.0
Loss at iteration 690 : 765897998336.0
Loss at iteration 700 : 364712165376.0
Loss at iteration 710 : 385390346240.0
Loss at iteration 720 : 71236235296768.0
Loss at iteration 730 : 19371520000.0
Loss at iteration 740 : 61661802496.0
Loss at iteration 750 : 90653114368.0
Loss at iteration 760 : 7541500416.0
Loss at iteration 770 : 7871397376.0
Loss at iteration 780 : 383631097856.0
Loss at iteration 790 : 11372841984.0
Loss at iteration 800 : 5572599296.0
Loss at iteration 810 : 57558573056.0
Loss at iteration 820 : 91569029120.0
Loss at iteration 830 : 6479153152.0
Loss at iteration 840 : 696690868224.0
Loss at iteration 850 : 88784044032.0
Loss at iteration 860 : 7650989056.0
Loss at iteration 870 : 7761227264.0
Loss at iteration 880 : 979989376.0
Loss at iteration 890 : 21341669376.0
Loss at iteration 900 : 4032912687104.0
Loss at iteration 910 : 74330832896.0
Loss at iteration 920 : 7091742720.0
Loss at iteration 930 : 145395597312.0
Loss at iteration 940 : 2607301632.0
Loss at iteration 950 : 3902726144.0
Loss at iteration 960 : 2402693376.0
Loss at iteration 970 : 2755693568.0
Loss at iteration 980 : 73826082816.0
Loss at iteration 990 : 57032351744.0
Loss at iteration 1000 : 418077736960.0
Loss at iteration 1010 : 2554709504.0
Loss at iteration 1020 : 2097027200.0
Loss at iteration 1030 : 10823856128.0
Loss at iteration 1040 : 12432917504.0
Loss at iteration 1050 : 117743403008.0
Loss at iteration 1060 : 23332347904.0
Loss at iteration 1070 : 63380307968.0
Loss at iteration 1080 : 8080407040.0
Loss at iteration 1090 : 73686695936.0
Loss at iteration 1100 : 21135781888.0
Loss at iteration 1110 : 18924101632.0
Loss at iteration 1120 : 41887109120.0
Loss at iteration 1130 : 8717815808.0
Loss at iteration 1140 : 5021261824.0
Loss at iteration 1150 : 55447130112.0
Loss at iteration 1160 : 7738207232.0
Loss at iteration 1170 : 7713209344.0
Loss at iteration 1180 : 4061455712256.0
Loss at iteration 1190 : 35734085632.0
Loss at iteration 1200 : 70640418816.0
Loss at iteration 1210 : 98824052736.0
Loss at iteration 1220 : 403221381120.0
Loss at iteration 1230 : 56736722944.0
Loss at iteration 1240 : 126897225728.0
Loss at iteration 1250 : 34299774976.0
Loss at iteration 1260 : 48340209664.0
Loss at iteration 1270 : 265170239488.0
Loss at iteration 1280 : 208337174528.0
Loss at iteration 1290 : 4274317426688.0
Loss at iteration 1300 : 30033055744.0
Loss at iteration 1310 : 125373603840.0
Loss at iteration 1320 : 298441670656.0
Loss at iteration 1330 : 144382148608.0
Loss at iteration 1340 : 269843054592.0
Loss at iteration 1350 : 2550039052288.0
Loss at iteration 1360 : 151372595200.0
Loss at iteration 1370 : 68489269248.0
Loss at iteration 1380 : 284316860416.0
Loss at iteration 1390 : 68191399936.0
Loss at iteration 1400 : 79835250688.0
Loss at iteration 1410 : 1662443716608.0
Loss at iteration 1420 : 14805895168.0
Loss at iteration 1430 : 125882941440.0
Loss at iteration 1440 : 1334750085120.0
Loss at iteration 1450 : 16859880448.0
Loss at iteration 1460 : 24084043776.0
Loss at iteration 1470 : 85052039168.0
Loss at iteration 1480 : 83706781696.0
Loss at iteration 1490 : 32585355264.0
Loss at iteration 1500 : 119798710272.0
Loss at iteration 1510 : 81673912320.0
Loss at iteration 1520 : 99366535168.0
Loss at iteration 1530 : 107349295104.0
Loss at iteration 1540 : 47064043520.0
Loss at iteration 1550 : 34102650880.0
Loss at iteration 1560 : 163056451584.0
Loss at iteration 1570 : 59605385216.0
Loss at iteration 1580 : 50684080128.0
Loss at iteration 1590 : 89641934848.0
Loss at iteration 1600 : 721060888576.0
Loss at iteration 1610 : 1730950725632.0
Loss at iteration 1620 : 14439026786304.0
Loss at iteration 1630 : 2254556364800.0
Loss at iteration 1640 : 399413018624.0
Loss at iteration 1650 : 283035303936.0
Loss at iteration 1660 : 284545679360.0
Loss at iteration 1670 : 83311583232.0
Loss at iteration 1680 : 767825674240.0
Loss at iteration 1690 : 1311142707200.0
Loss at iteration 1700 : 1304210964480.0
Loss at iteration 1710 : 48857866240.0
Loss at iteration 1720 : 23472959488.0
Loss at iteration 1730 : 81701830656.0
Loss at iteration 1740 : 315354611712.0
Loss at iteration 1750 : 13410643968.0
Loss at iteration 1760 : 158286757888.0
Loss at iteration 1770 : 102051135488.0
Loss at iteration 1780 : 44475293696.0
Loss at iteration 1790 : 317526016000.0
Loss at iteration 1800 : 746139025408.0
Loss at iteration 1810 : 85269405696.0
Loss at iteration 1820 : 10211619840.0
Loss at iteration 1830 : 32673347584.0
Loss at iteration 1840 : 63118684160.0
Loss at iteration 1850 : 480275103744.0
Loss at iteration 1860 : 28755529728.0
Loss at iteration 1870 : 119091716096.0
Loss at iteration 1880 : 313409044480.0
Loss at iteration 1890 : 4362481434624.0
Loss at iteration 1900 : 7378071715840.0
Loss at iteration 1910 : 698329989120.0
Loss at iteration 1920 : 22021111021568.0
Loss at iteration 1930 : 652097748992.0
Loss at iteration 1940 : 7758108164096.0
Loss at iteration 1950 : 1436755296256.0
Loss at iteration 1960 : 2387601260544.0
Loss at iteration 1970 : 5976817664000.0
Loss at iteration 1980 : 1266814943232.0
Loss at iteration 1990 : 350914871296.0
Loss at iteration 2000 : 385832910848.0
Loss at iteration 2010 : 6167365943296.0
Loss at iteration 2020 : 4439583752192.0
Loss at iteration 2030 : 278899195904.0
Loss at iteration 2040 : 61819764736.0
Loss at iteration 2050 : 43468795904.0
Loss at iteration 2060 : 1255524139008.0
Loss at iteration 2070 : 1065168535552.0
Loss at iteration 2080 : 23571642368.0
Loss at iteration 2090 : 825714016256.0
Loss at iteration 2100 : 171900076032.0
Loss at iteration 2110 : 495785115648.0
Loss at iteration 2120 : 686044676096.0
Loss at iteration 2130 : 132002660352.0
Loss at iteration 2140 : 262507675648.0
Loss at iteration 2150 : 189612457984.0
Loss at iteration 2160 : 154158956544.0
Loss at iteration 2170 : 323664838656.0
Loss at iteration 2180 : 80653475840.0
Loss at iteration 2190 : 481097154560.0
Loss at iteration 2200 : 25972015104.0
Loss at iteration 2210 : 378591117312.0
Loss at iteration 2220 : 100089389056.0
Loss at iteration 2230 : 284176449536.0
Loss at iteration 2240 : 1368522620928.0
Loss at iteration 2250 : 1601267302400.0
Loss at iteration 2260 : 108219834368.0
Loss at iteration 2270 : 112253468672.0
Loss at iteration 2280 : 129202708480.0
Loss at iteration 2290 : 1462910844928.0
Loss at iteration 2300 : 49342070784.0
Loss at iteration 2310 : 582313377792.0
Loss at iteration 2320 : 217490898944.0
Loss at iteration 2330 : 6769198592.0
Loss at iteration 2340 : 6186455552.0
Loss at iteration 2350 : 1624402821120.0
Loss at iteration 2360 : 84399603712.0
Loss at iteration 2370 : 85176705024.0
Loss at iteration 2380 : 52175458304.0
Loss at iteration 2390 : 133937995776.0
Loss at iteration 2400 : 287718113280.0
Loss at iteration 2410 : 106086047744.0
Loss at iteration 2420 : 86476488704.0
The SSIM Value is: 9.970619112209534e-06
The PSNR Value is: -114.10611623128256
the epoch is: 195
Loss at iteration 10 : 31617898496.0
Loss at iteration 20 : 11671813120.0
Loss at iteration 30 : 110248517632.0
Loss at iteration 40 : 9303941120.0
Loss at iteration 50 : 30918893568.0
Loss at iteration 60 : 7561764352.0
Loss at iteration 70 : 45200822272.0
Loss at iteration 80 : 36361158656.0
Loss at iteration 90 : 171441422336.0
Loss at iteration 100 : 51917131776.0
Loss at iteration 110 : 19406589952.0
Loss at iteration 120 : 23003990016.0
Loss at iteration 130 : 11632491520.0
Loss at iteration 140 : 21716987904.0
Loss at iteration 150 : 5824842240.0
Loss at iteration 160 : 91073544192.0
Loss at iteration 170 : 1088748453888.0
Loss at iteration 180 : 27018622976.0
Loss at iteration 190 : 13618031616.0
Loss at iteration 200 : 162690564096.0
Loss at iteration 210 : 106544259072.0
Loss at iteration 220 : 125759062016.0
Loss at iteration 230 : 6632200192.0
Loss at iteration 240 : 777067167744.0
Loss at iteration 250 : 2147123986432.0
Loss at iteration 260 : 784253452288.0
Loss at iteration 270 : 33602031616.0
Loss at iteration 280 : 143789047808.0
Loss at iteration 290 : 151916150784.0
Loss at iteration 300 : 40440836096.0
Loss at iteration 310 : 277823422464.0
Loss at iteration 320 : 21305001984.0
Loss at iteration 330 : 29553002496.0
Loss at iteration 340 : 178750275584.0
Loss at iteration 350 : 155832221696.0
Loss at iteration 360 : 75349942272.0
Loss at iteration 370 : 82677530624.0
Loss at iteration 380 : 10071476224.0
Loss at iteration 390 : 147770572800.0
Loss at iteration 400 : 300035866624.0
Loss at iteration 410 : 211179765760.0
Loss at iteration 420 : 60446494720.0
Loss at iteration 430 : 51976085504.0
Loss at iteration 440 : 239106359296.0
Loss at iteration 450 : 43290447872.0
Loss at iteration 460 : 87760142336.0
Loss at iteration 470 : 33885571072.0
Loss at iteration 480 : 3097837312.0
Loss at iteration 490 : 5097069568.0
Loss at iteration 500 : 9603119104.0
Loss at iteration 510 : 6059660288.0
Loss at iteration 520 : 797120593920.0
Loss at iteration 530 : 11335092224.0
Loss at iteration 540 : 10809111552.0
Loss at iteration 550 : 154357972992.0
Loss at iteration 560 : 20429508608.0
Loss at iteration 570 : 269275758592.0
Loss at iteration 580 : 35800580096.0
Loss at iteration 590 : 23896733696.0
Loss at iteration 600 : 15160397824.0
Loss at iteration 610 : 8444910080.0
Loss at iteration 620 : 8046208000.0
Loss at iteration 630 : 3745769728.0
Loss at iteration 640 : 20316362752.0
Loss at iteration 650 : 1114106626048.0
Loss at iteration 660 : 16499597312.0
Loss at iteration 670 : 396445679616.0
Loss at iteration 680 : 773662703616.0
Loss at iteration 690 : 7716377600.0
Loss at iteration 700 : 87906770944.0
Loss at iteration 710 : 100189036544.0
Loss at iteration 720 : 23877206016.0
Loss at iteration 730 : 407972511744.0
Loss at iteration 740 : 18006659072.0
Loss at iteration 750 : 21258776576.0
Loss at iteration 760 : 102588686336.0
Loss at iteration 770 : 137332342784.0
Loss at iteration 780 : 42191986688.0
Loss at iteration 790 : 472364646400.0
Loss at iteration 800 : 7188906496.0
Loss at iteration 810 : 13013649408.0
Loss at iteration 820 : 8920858624.0
Loss at iteration 830 : 7089218560.0
Loss at iteration 840 : 5582396928.0
Loss at iteration 850 : 9404893184.0
Loss at iteration 860 : 1440235520000.0
Loss at iteration 870 : 19801397248.0
Loss at iteration 880 : 26350643200.0
Loss at iteration 890 : 4906670592.0
Loss at iteration 900 : 14356881408.0
Loss at iteration 910 : 14848567296.0
Loss at iteration 920 : 1545373184.0
Loss at iteration 930 : 1306598144.0
Loss at iteration 940 : 26260819968.0
Loss at iteration 950 : 13950939136.0
Loss at iteration 960 : 25485250560.0
Loss at iteration 970 : 20485672960.0
Loss at iteration 980 : 17689645056.0
Loss at iteration 990 : 52092518400.0
Loss at iteration 1000 : 70276661248.0
Loss at iteration 1010 : 1131110912.0
Loss at iteration 1020 : 14838849536.0
Loss at iteration 1030 : 9875101696.0
Loss at iteration 1040 : 19398707200.0
Loss at iteration 1050 : 94026801152.0
Loss at iteration 1060 : 29300396032.0
Loss at iteration 1070 : 46593085440.0
Loss at iteration 1080 : 13863475200.0
Loss at iteration 1090 : 25520547840.0
Loss at iteration 1100 : 95117959168.0
Loss at iteration 1110 : 34029756416.0
Loss at iteration 1120 : 6134810624.0
Loss at iteration 1130 : 3125548288.0
Loss at iteration 1140 : 3636413440.0
Loss at iteration 1150 : 92949037056.0
Loss at iteration 1160 : 2993166080.0
Loss at iteration 1170 : 18366791680.0
Loss at iteration 1180 : 244807286784.0
Loss at iteration 1190 : 9193364480.0
Loss at iteration 1200 : 227437314048.0
Loss at iteration 1210 : 4439761920.0
Loss at iteration 1220 : 77701455872.0
Loss at iteration 1230 : 14474838016.0
Loss at iteration 1240 : 1420726912.0
Loss at iteration 1250 : 4541230592.0
Loss at iteration 1260 : 18742679552.0
Loss at iteration 1270 : 13264567296.0
Loss at iteration 1280 : 8540408320.0
Loss at iteration 1290 : 5399826432.0
Loss at iteration 1300 : 27262875648.0
Loss at iteration 1310 : 1348477440.0
Loss at iteration 1320 : 1547282176.0
Loss at iteration 1330 : 40630124544.0
Loss at iteration 1340 : 23348355072.0
Loss at iteration 1350 : 16581581824.0
Loss at iteration 1360 : 915058496.0
Loss at iteration 1370 : 17038088192.0
Loss at iteration 1380 : 9952562176.0
Loss at iteration 1390 : 19164303360.0
Loss at iteration 1400 : 11362697216.0
Loss at iteration 1410 : 9903050752.0
Loss at iteration 1420 : 34156226560.0
Loss at iteration 1430 : 25227399168.0
Loss at iteration 1440 : 8344287232.0
Loss at iteration 1450 : 81976582144.0
Loss at iteration 1460 : 145349558272.0
Loss at iteration 1470 : 152040275968.0
Loss at iteration 1480 : 10409843712.0
Loss at iteration 1490 : 21589479424.0
Loss at iteration 1500 : 18526623744.0
Loss at iteration 1510 : 17677707264.0
Loss at iteration 1520 : 30237937664.0
Loss at iteration 1530 : 34336634880.0
Loss at iteration 1540 : 17296766976.0
Loss at iteration 1550 : 253441867776.0
Loss at iteration 1560 : 4604630016.0
Loss at iteration 1570 : 7957160960.0
Loss at iteration 1580 : 6007280640.0
Loss at iteration 1590 : 46330187776.0
Loss at iteration 1600 : 14760856576.0
Loss at iteration 1610 : 868789760.0
Loss at iteration 1620 : 9947925504.0
Loss at iteration 1630 : 4128260352.0
Loss at iteration 1640 : 354079932416.0
Loss at iteration 1650 : 20756756480.0
Loss at iteration 1660 : 4618772480.0
Loss at iteration 1670 : 27694534656.0
Loss at iteration 1680 : 13516952576.0
Loss at iteration 1690 : 3100931328.0
Loss at iteration 1700 : 13635279872.0
Loss at iteration 1710 : 1952973184.0
Loss at iteration 1720 : 23955630080.0
Loss at iteration 1730 : 1260684032.0
Loss at iteration 1740 : 107360296960.0
Loss at iteration 1750 : 2794996480.0
Loss at iteration 1760 : 7125368320.0
Loss at iteration 1770 : 1103905280.0
Loss at iteration 1780 : 11402296320.0
Loss at iteration 1790 : 1793226240.0
Loss at iteration 1800 : 1476457728.0
Loss at iteration 1810 : 84669186048.0
Loss at iteration 1820 : 2135973248.0
Loss at iteration 1830 : 858193408.0
Loss at iteration 1840 : 1141779840.0
Loss at iteration 1850 : 7228426752.0
Loss at iteration 1860 : 10373245952.0
Loss at iteration 1870 : 2022651776.0
Loss at iteration 1880 : 1692065408.0
Loss at iteration 1890 : 37174755328.0
Loss at iteration 1900 : 24694259712.0
Loss at iteration 1910 : 3320085760.0
Loss at iteration 1920 : 22555441152.0
Loss at iteration 1930 : 3709264640.0
Loss at iteration 1940 : 3947864064.0
Loss at iteration 1950 : 4235613952.0
Loss at iteration 1960 : 545957632.0
Loss at iteration 1970 : 9125694464.0
Loss at iteration 1980 : 16575732736.0
Loss at iteration 1990 : 7376786432.0
Loss at iteration 2000 : 2427454464.0
Loss at iteration 2010 : 46682398720.0
Loss at iteration 2020 : 3489214720.0
Loss at iteration 2030 : 2107026688.0
Loss at iteration 2040 : 5170710528.0
Loss at iteration 2050 : 1837348736.0
Loss at iteration 2060 : 1346227840.0
Loss at iteration 2070 : 1729662336.0
Loss at iteration 2080 : 1712809472.0
Loss at iteration 2090 : 599593024.0
Loss at iteration 2100 : 1300994048.0
Loss at iteration 2110 : 3304528128.0
Loss at iteration 2120 : 49475477504.0
Loss at iteration 2130 : 2680659712.0
Loss at iteration 2140 : 4195632128.0
Loss at iteration 2150 : 10286531584.0
Loss at iteration 2160 : 1499516416.0
Loss at iteration 2170 : 44572221440.0
Loss at iteration 2180 : 5065622528.0
Loss at iteration 2190 : 2197844992.0
Loss at iteration 2200 : 2618295808.0
Loss at iteration 2210 : 510657920.0
Loss at iteration 2220 : 5333428224.0
Loss at iteration 2230 : 1806397440.0
Loss at iteration 2240 : 1601313152.0
Loss at iteration 2250 : 30140104704.0
Loss at iteration 2260 : 345669828608.0
Loss at iteration 2270 : 4930642944.0
Loss at iteration 2280 : 1098992512.0
Loss at iteration 2290 : 30351308800.0
Loss at iteration 2300 : 4853835264.0
Loss at iteration 2310 : 15436675072.0
Loss at iteration 2320 : 21203499008.0
Loss at iteration 2330 : 2202963200.0
Loss at iteration 2340 : 3223381760.0
Loss at iteration 2350 : 2613968640.0
Loss at iteration 2360 : 2543838464.0
Loss at iteration 2370 : 45469249536.0
Loss at iteration 2380 : 16769325056.0
Loss at iteration 2390 : 63912132608.0
Loss at iteration 2400 : 167773323264.0
Loss at iteration 2410 : 173783138304.0
Loss at iteration 2420 : 9131307008.0
The SSIM Value is: 3.025587981634696e-07
The PSNR Value is: -111.95984802246093
the epoch is: 196
Loss at iteration 10 : 42518872064.0
Loss at iteration 20 : 1310841896960.0
Loss at iteration 30 : 14551635968.0
Loss at iteration 40 : 58738343936.0
Loss at iteration 50 : 163543564288.0
Loss at iteration 60 : 10296838144.0
Loss at iteration 70 : 208552214528.0
Loss at iteration 80 : 13436134400.0
Loss at iteration 90 : 557004881920.0
Loss at iteration 100 : 23876691968.0
Loss at iteration 110 : 157817520128.0
Loss at iteration 120 : 25048645632.0
Loss at iteration 130 : 4784633344.0
Loss at iteration 140 : 174018134016.0
Loss at iteration 150 : 8895155200.0
Loss at iteration 160 : 20597553152.0
Loss at iteration 170 : 9480652800.0
Loss at iteration 180 : 38911049728.0
Loss at iteration 190 : 42341289984.0
Loss at iteration 200 : 6116690944.0
Loss at iteration 210 : 13960767488.0
Loss at iteration 220 : 31456407552.0
Loss at iteration 230 : 52082941952.0
Loss at iteration 240 : 4661966848.0
Loss at iteration 250 : 23434037248.0
Loss at iteration 260 : 38153068544.0
Loss at iteration 270 : 5295377920.0
Loss at iteration 280 : 5453964800.0
Loss at iteration 290 : 8322913792.0
Loss at iteration 300 : 2073643520.0
Loss at iteration 310 : 13946487808.0
Loss at iteration 320 : 17828659200.0
Loss at iteration 330 : 11583644672.0
Loss at iteration 340 : 9885991936.0
Loss at iteration 350 : 7192855552.0
Loss at iteration 360 : 3767036672.0
Loss at iteration 370 : 17114539008.0
Loss at iteration 380 : 43341869056.0
Loss at iteration 390 : 32616263680.0
Loss at iteration 400 : 1899591424.0
Loss at iteration 410 : 25348112384.0
Loss at iteration 420 : 12278801408.0
Loss at iteration 430 : 9243795456.0
Loss at iteration 440 : 10995891200.0
Loss at iteration 450 : 5028100096.0
Loss at iteration 460 : 15007956992.0
Loss at iteration 470 : 5888621568.0
Loss at iteration 480 : 37334568960.0
Loss at iteration 490 : 22072246272.0
Loss at iteration 500 : 1777223296.0
Loss at iteration 510 : 36874723328.0
Loss at iteration 520 : 8531778048.0
Loss at iteration 530 : 20687751168.0
Loss at iteration 540 : 3791346176.0
Loss at iteration 550 : 515881408.0
Loss at iteration 560 : 19736338432.0
Loss at iteration 570 : 3564058368.0
Loss at iteration 580 : 15840627712.0
Loss at iteration 590 : 16952654848.0
Loss at iteration 600 : 30681743360.0
Loss at iteration 610 : 1629145088.0
Loss at iteration 620 : 11542542336.0
Loss at iteration 630 : 26784698368.0
Loss at iteration 640 : 7668511744.0
Loss at iteration 650 : 4325784576.0
Loss at iteration 660 : 1788481408.0
Loss at iteration 670 : 33771069440.0
Loss at iteration 680 : 2678320384.0
Loss at iteration 690 : 8629664768.0
Loss at iteration 700 : 207262187520.0
Loss at iteration 710 : 5282840182784.0
Loss at iteration 720 : 1912551505920.0
Loss at iteration 730 : 24656042000384.0
Loss at iteration 740 : 319771901952.0
Loss at iteration 750 : 292861941645312.0
Loss at iteration 760 : 17325190283264.0
Loss at iteration 770 : 693028473798656.0
Loss at iteration 780 : 37222604800.0
Loss at iteration 790 : 2025769402368.0
Loss at iteration 800 : 60002366652416.0
Loss at iteration 810 : 1775322791936.0
Loss at iteration 820 : 2696870887424.0
Loss at iteration 830 : 4730145734656.0
Loss at iteration 840 : 4594695929856.0
Loss at iteration 850 : 162940583936.0
Loss at iteration 860 : 388612325376.0
Loss at iteration 870 : 10979736813568.0
Loss at iteration 880 : 420298752000.0
Loss at iteration 890 : 1539808952320.0
Loss at iteration 900 : 131875422208.0
Loss at iteration 910 : 8675660922880.0
Loss at iteration 920 : 37044004847616.0
Loss at iteration 930 : 898842820608.0
Loss at iteration 940 : 610178957312.0
Loss at iteration 950 : 338111528960.0
Loss at iteration 960 : 104633982976.0
Loss at iteration 970 : 1440828096512.0
Loss at iteration 980 : 1949505290240.0
Loss at iteration 990 : 4579507306496.0
Loss at iteration 1000 : 54655676416.0
Loss at iteration 1010 : 392120500224.0
Loss at iteration 1020 : 808328429568.0
Loss at iteration 1030 : 16188809674752.0
Loss at iteration 1040 : 1548762611712.0
Loss at iteration 1050 : 2863533654016.0
Loss at iteration 1060 : 18092769935360.0
Loss at iteration 1070 : 211926007808.0
Loss at iteration 1080 : 671285837824.0
Loss at iteration 1090 : 9004023545856.0
Loss at iteration 1100 : 53408648134656.0
Loss at iteration 1110 : 20603669053440.0
Loss at iteration 1120 : 9598972985344.0
Loss at iteration 1130 : 75790964228096.0
Loss at iteration 1140 : 566459236352.0
Loss at iteration 1150 : 12037785649152.0
Loss at iteration 1160 : 592179298304.0
Loss at iteration 1170 : 65546989076480.0
Loss at iteration 1180 : 1130530865152.0
Loss at iteration 1190 : 100875575296.0
Loss at iteration 1200 : 967704838144.0
Loss at iteration 1210 : 222217060352.0
Loss at iteration 1220 : 1390207172608.0
Loss at iteration 1230 : 867834920960.0
Loss at iteration 1240 : 69672200306688.0
Loss at iteration 1250 : 1634456043520.0
Loss at iteration 1260 : 14508310396928.0
Loss at iteration 1270 : 2790304514048.0
Loss at iteration 1280 : 127717228544.0
Loss at iteration 1290 : 3765194457088.0
Loss at iteration 1300 : 163522265088.0
Loss at iteration 1310 : 906518724608.0
Loss at iteration 1320 : 2093848461312.0
Loss at iteration 1330 : 10481454546944.0
Loss at iteration 1340 : 418310651904.0
Loss at iteration 1350 : 623863857152.0
Loss at iteration 1360 : 2437574033408.0
Loss at iteration 1370 : 1233263525888.0
Loss at iteration 1380 : 826690502656.0
Loss at iteration 1390 : 168421900288.0
Loss at iteration 1400 : 4208034578432.0
Loss at iteration 1410 : 608315768832.0
Loss at iteration 1420 : 843918016512.0
Loss at iteration 1430 : 247599513600.0
Loss at iteration 1440 : 4309516800.0
Loss at iteration 1450 : 19452643328.0
Loss at iteration 1460 : 135200817152.0
Loss at iteration 1470 : 220187525120.0
Loss at iteration 1480 : 30336704512.0
Loss at iteration 1490 : 76030001152.0
Loss at iteration 1500 : 342623879168.0
Loss at iteration 1510 : 1329914052608.0
Loss at iteration 1520 : 596766687232.0
Loss at iteration 1530 : 2602918739968.0
Loss at iteration 1540 : 64438403072.0
Loss at iteration 1550 : 151087218688.0
Loss at iteration 1560 : 442081574912.0
Loss at iteration 1570 : 448412123136.0
Loss at iteration 1580 : 311358652416.0
Loss at iteration 1590 : 326221135872.0
Loss at iteration 1600 : 90036543488.0
Loss at iteration 1610 : 62586138624.0
Loss at iteration 1620 : 33935568896.0
Loss at iteration 1630 : 37028626432.0
Loss at iteration 1640 : 77980082176.0
Loss at iteration 1650 : 203270275072.0
Loss at iteration 1660 : 145524883456.0
Loss at iteration 1670 : 36676464640.0
Loss at iteration 1680 : 1267743719424.0
Loss at iteration 1690 : 304815636480.0
Loss at iteration 1700 : 401771397120.0
Loss at iteration 1710 : 180601995264.0
Loss at iteration 1720 : 121596231680.0
Loss at iteration 1730 : 66743812096.0
Loss at iteration 1740 : 53992833024.0
Loss at iteration 1750 : 305929289728.0
Loss at iteration 1760 : 104876081152.0
Loss at iteration 1770 : 84934909952.0
Loss at iteration 1780 : 423817019392.0
Loss at iteration 1790 : 23014903808.0
Loss at iteration 1800 : 189844389888.0
Loss at iteration 1810 : 8308361527296.0
Loss at iteration 1820 : 22417311744.0
Loss at iteration 1830 : 40450748416.0
Loss at iteration 1840 : 3091456589824.0
Loss at iteration 1850 : 2645461827584.0
Loss at iteration 1860 : 15067509686272.0
Loss at iteration 1870 : 12671816564736.0
Loss at iteration 1880 : 107336819539968.0
Loss at iteration 1890 : 6702198423552.0
Loss at iteration 1900 : 798125326336.0
Loss at iteration 1910 : 2037395750912.0
Loss at iteration 1920 : 643116892160.0
Loss at iteration 1930 : 1198868922368.0
Loss at iteration 1940 : 1062102630400.0
Loss at iteration 1950 : 854369370112.0
Loss at iteration 1960 : 322947088384.0
Loss at iteration 1970 : 3728454713344.0
Loss at iteration 1980 : 2270615044096.0
Loss at iteration 1990 : 13657211904.0
Loss at iteration 2000 : 117624078336.0
Loss at iteration 2010 : 177688756224.0
Loss at iteration 2020 : 70534881280.0
Loss at iteration 2030 : 63145390080.0
Loss at iteration 2040 : 7779807395840.0
Loss at iteration 2050 : 6513909248.0
Loss at iteration 2060 : 122803642368.0
Loss at iteration 2070 : 80609452032.0
Loss at iteration 2080 : 27489552384.0
Loss at iteration 2090 : 3338217717760.0
Loss at iteration 2100 : 263186841600.0
Loss at iteration 2110 : 2920114552832.0
Loss at iteration 2120 : 5326338260992.0
Loss at iteration 2130 : 272473440256.0
Loss at iteration 2140 : 7268495523840.0
Loss at iteration 2150 : 177976786944.0
Loss at iteration 2160 : 61999144960.0
Loss at iteration 2170 : 978488590336.0
Loss at iteration 2180 : 3203298754560.0
Loss at iteration 2190 : 363661000704.0
Loss at iteration 2200 : 553535930368.0
Loss at iteration 2210 : 12057828130816.0
Loss at iteration 2220 : 117170552832.0
Loss at iteration 2230 : 422865731584.0
Loss at iteration 2240 : 220708323328.0
Loss at iteration 2250 : 24693342208.0
Loss at iteration 2260 : 51347542016.0
Loss at iteration 2270 : 24134041600.0
Loss at iteration 2280 : 35985162240.0
Loss at iteration 2290 : 1356060557312.0
Loss at iteration 2300 : 4521301377024.0
Loss at iteration 2310 : 15208045084672.0
Loss at iteration 2320 : 20172119212032.0
Loss at iteration 2330 : 627257901056.0
Loss at iteration 2340 : 2573434613661696.0
Loss at iteration 2350 : 8136182202368.0
Loss at iteration 2360 : 6027111500349440.0
Loss at iteration 2370 : 7505925111808000.0
Loss at iteration 2380 : 1630566617186304.0
Loss at iteration 2390 : 36235984764928.0
Loss at iteration 2400 : 8940895160238080.0
Loss at iteration 2410 : 6766708626817024.0
Loss at iteration 2420 : 32433317609472.0
The SSIM Value is: 3.817592395686612e-07
The PSNR Value is: -147.97797546386718
the epoch is: 197
Loss at iteration 10 : 7727969992704.0
Loss at iteration 20 : 1054909267968.0
Loss at iteration 30 : 28267400658944.0
Loss at iteration 40 : 3922404048896.0
Loss at iteration 50 : 6120571142144.0
Loss at iteration 60 : 119146721312768.0
Loss at iteration 70 : 1211681210368.0
Loss at iteration 80 : 47386890076160.0
Loss at iteration 90 : 12193385938944.0
Loss at iteration 100 : 29498783301632.0
Loss at iteration 110 : 5954056749056.0
Loss at iteration 120 : 14467715825664.0
Loss at iteration 130 : 13890405531648.0
Loss at iteration 140 : 11058778472448.0
Loss at iteration 150 : 3668337754112.0
Loss at iteration 160 : 2944933036032.0
Loss at iteration 170 : 1198868398080.0
Loss at iteration 180 : 15214645870592.0
Loss at iteration 190 : 4847807496192.0
Loss at iteration 200 : 29743625797632.0
Loss at iteration 210 : 20872180006912.0
Loss at iteration 220 : 11295425298432.0
Loss at iteration 230 : 129522095620096.0
Loss at iteration 240 : 17827280977920.0
Loss at iteration 250 : 987254816768.0
Loss at iteration 260 : 1415761756160.0
Loss at iteration 270 : 457951772672.0
Loss at iteration 280 : 15105939996672.0
Loss at iteration 290 : 1891830988800.0
Loss at iteration 300 : 6300668788736.0
Loss at iteration 310 : 798618091520.0
Loss at iteration 320 : 1276341649408.0
Loss at iteration 330 : 1238459351040.0
Loss at iteration 340 : 1615579185152.0
Loss at iteration 350 : 17681656840192.0
Loss at iteration 360 : 288082783895552.0
Loss at iteration 370 : 1955653353472.0
Loss at iteration 380 : 5835548786688.0
Loss at iteration 390 : 3126657024000.0
Loss at iteration 400 : 7381398323200.0
Loss at iteration 410 : 6187770707968.0
Loss at iteration 420 : 19348471152640.0
Loss at iteration 430 : 33649477025792.0
Loss at iteration 440 : 278335946752.0
Loss at iteration 450 : 249712836608.0
Loss at iteration 460 : 2601890349056.0
Loss at iteration 470 : 4397197688832.0
Loss at iteration 480 : 70748706177024.0
Loss at iteration 490 : 2071131979776.0
Loss at iteration 500 : 2487102996480.0
Loss at iteration 510 : 1108425048064.0
Loss at iteration 520 : 6580496498688.0
Loss at iteration 530 : 4290850062336.0
Loss at iteration 540 : 6194067931136.0
Loss at iteration 550 : 1133752745984.0
Loss at iteration 560 : 17640621867008.0
Loss at iteration 570 : 7122402148352.0
Loss at iteration 580 : 26740032274432.0
Loss at iteration 590 : 18607417327616.0
Loss at iteration 600 : 9099598102528.0
Loss at iteration 610 : 35443370360832.0
Loss at iteration 620 : 28416931790848.0
Loss at iteration 630 : 29085579345920.0
Loss at iteration 640 : 116190760402944.0
Loss at iteration 650 : 8718649917440.0
Loss at iteration 660 : 12179085459456.0
Loss at iteration 670 : 9718630187008.0
Loss at iteration 680 : 15868949954560.0
Loss at iteration 690 : 324465653186560.0
Loss at iteration 700 : 2129005379584.0
Loss at iteration 710 : 81265411751936.0
Loss at iteration 720 : 2787172679680.0
Loss at iteration 730 : 1170172018688.0
Loss at iteration 740 : 20429471219712.0
Loss at iteration 750 : 622976499712.0
Loss at iteration 760 : 184024317952.0
Loss at iteration 770 : 536549851136.0
Loss at iteration 780 : 15483495514112.0
Loss at iteration 790 : 1293788381184.0
Loss at iteration 800 : 1872279896064.0
Loss at iteration 810 : 4453542395904.0
Loss at iteration 820 : 3599110766592.0
Loss at iteration 830 : 7185089691648.0
Loss at iteration 840 : 1107912294400.0
Loss at iteration 850 : 3938957656064.0
Loss at iteration 860 : 27890357895168.0
Loss at iteration 870 : 13421417332736.0
Loss at iteration 880 : 24136839593984.0
Loss at iteration 890 : 81769911025664.0
Loss at iteration 900 : 4989579689984.0
Loss at iteration 910 : 9301583200256.0
Loss at iteration 920 : 1064177500160.0
Loss at iteration 930 : 22120084013056.0
Loss at iteration 940 : 3658469343232.0
Loss at iteration 950 : 4511099781120.0
Loss at iteration 960 : 1215846547456.0
Loss at iteration 970 : 2585938100224.0
Loss at iteration 980 : 36272865280000.0
Loss at iteration 990 : 2348742344704.0
Loss at iteration 1000 : 12271865561088.0
Loss at iteration 1010 : 18618272186368.0
Loss at iteration 1020 : 3245524123648.0
Loss at iteration 1030 : 6006260629504.0
Loss at iteration 1040 : 7916387565568.0
Loss at iteration 1050 : 1873401348096.0
Loss at iteration 1060 : 4317096443904.0
Loss at iteration 1070 : 26717066362880.0
Loss at iteration 1080 : 4639651004416.0
Loss at iteration 1090 : 18048606011392.0
Loss at iteration 1100 : 1222344835072.0
Loss at iteration 1110 : 2897737416704.0
Loss at iteration 1120 : 8198881280000.0
Loss at iteration 1130 : 6394526826496.0
Loss at iteration 1140 : 5130742136832.0
Loss at iteration 1150 : 10135810342912.0
Loss at iteration 1160 : 595779977216.0
Loss at iteration 1170 : 2814825463808.0
Loss at iteration 1180 : 70148907008.0
Loss at iteration 1190 : 1569879752704.0
Loss at iteration 1200 : 5001008119808.0
Loss at iteration 1210 : 5854224973824.0
Loss at iteration 1220 : 4047573090304.0
Loss at iteration 1230 : 1632155860992.0
Loss at iteration 1240 : 1461230632960.0
Loss at iteration 1250 : 1501360160768.0
Loss at iteration 1260 : 5121877999616.0
Loss at iteration 1270 : 2003097747456.0
Loss at iteration 1280 : 460445188096.0
Loss at iteration 1290 : 6714971127808.0
Loss at iteration 1300 : 2105315033088.0
Loss at iteration 1310 : 4747884494848.0
Loss at iteration 1320 : 5410373763072.0
Loss at iteration 1330 : 1921985150976.0
Loss at iteration 1340 : 383462801408.0
Loss at iteration 1350 : 36009551069184.0
Loss at iteration 1360 : 2963581173760.0
Loss at iteration 1370 : 1911331094528.0
Loss at iteration 1380 : 960198279168.0
Loss at iteration 1390 : 10418545229824.0
Loss at iteration 1400 : 4686982152192.0
Loss at iteration 1410 : 388314071040.0
Loss at iteration 1420 : 5658489913344.0
Loss at iteration 1430 : 278642294784.0
Loss at iteration 1440 : 1044265238528.0
Loss at iteration 1450 : 422114656256.0
Loss at iteration 1460 : 606788124672.0
Loss at iteration 1470 : 35498689036288.0
Loss at iteration 1480 : 9277237362688.0
Loss at iteration 1490 : 164461985792.0
Loss at iteration 1500 : 4067738255360.0
Loss at iteration 1510 : 683556339712.0
Loss at iteration 1520 : 576038502400.0
Loss at iteration 1530 : 329713975296.0
Loss at iteration 1540 : 2201142165504.0
Loss at iteration 1550 : 10737330159616.0
Loss at iteration 1560 : 54568901672960.0
Loss at iteration 1570 : 1811375194112.0
Loss at iteration 1580 : 20311026171904.0
Loss at iteration 1590 : 278600603402240.0
Loss at iteration 1600 : 7827290062848.0
Loss at iteration 1610 : 1857704296448.0
Loss at iteration 1620 : 15530003005440.0
Loss at iteration 1630 : 34722514206720.0
Loss at iteration 1640 : 38924785287168.0
Loss at iteration 1650 : 17639948681216.0
Loss at iteration 1660 : 23470255636480.0
Loss at iteration 1670 : 33513357180928.0
Loss at iteration 1680 : 148235360403456.0
Loss at iteration 1690 : 4621532659712.0
Loss at iteration 1700 : 23776148324352.0
Loss at iteration 1710 : 3236911906816.0
Loss at iteration 1720 : 19664327409664.0
Loss at iteration 1730 : 15124931805184.0
Loss at iteration 1740 : 50723643457536.0
Loss at iteration 1750 : 29975258333184.0
Loss at iteration 1760 : 108207640936448.0
Loss at iteration 1770 : 26014572871680.0
Loss at iteration 1780 : 12652054052864.0
Loss at iteration 1790 : 11640046092288.0
Loss at iteration 1800 : 58447726903296.0
Loss at iteration 1810 : 1170985713664.0
Loss at iteration 1820 : 6693257216000.0
Loss at iteration 1830 : 14869015298048.0
Loss at iteration 1840 : 11695400419328.0
Loss at iteration 1850 : 57474665152512.0
Loss at iteration 1860 : 61367230922752.0
Loss at iteration 1870 : 10352789028864.0
Loss at iteration 1880 : 5638982729728.0
Loss at iteration 1890 : 1431997775872.0
Loss at iteration 1900 : 70835696041984.0
Loss at iteration 1910 : 6643414728704.0
Loss at iteration 1920 : 3791758032896.0
Loss at iteration 1930 : 10324558217216.0
Loss at iteration 1940 : 28268650561536.0
Loss at iteration 1950 : 3943460503552.0
Loss at iteration 1960 : 5125661786112.0
Loss at iteration 1970 : 11956732821504.0
Loss at iteration 1980 : 2692715642880.0
Loss at iteration 1990 : 59683842818048.0
Loss at iteration 2000 : 9673906323456.0
Loss at iteration 2010 : 837398167552.0
Loss at iteration 2020 : 46622171987968.0
Loss at iteration 2030 : 4815054700544.0
Loss at iteration 2040 : 3015264174080.0
Loss at iteration 2050 : 568524603392.0
Loss at iteration 2060 : 514430468096.0
Loss at iteration 2070 : 4290102427648.0
Loss at iteration 2080 : 56638748753920.0
Loss at iteration 2090 : 470015508480.0
Loss at iteration 2100 : 16381624975360.0
Loss at iteration 2110 : 1050975666176.0
Loss at iteration 2120 : 2731142545408.0
Loss at iteration 2130 : 17988489052160.0
Loss at iteration 2140 : 8079573778432.0
Loss at iteration 2150 : 3808449265664.0
Loss at iteration 2160 : 9657098698752.0
Loss at iteration 2170 : 378416463872.0
Loss at iteration 2180 : 2241648656384.0
Loss at iteration 2190 : 1110562177024.0
Loss at iteration 2200 : 970800562176.0
Loss at iteration 2210 : 5057525317632.0
Loss at iteration 2220 : 1339496857600.0
Loss at iteration 2230 : 1250533703680.0
Loss at iteration 2240 : 1020374089728.0
Loss at iteration 2250 : 655445721088.0
Loss at iteration 2260 : 1612518522880.0
Loss at iteration 2270 : 2220689195008.0
Loss at iteration 2280 : 278755311616.0
Loss at iteration 2290 : 7704083955712.0
Loss at iteration 2300 : 806155714560.0
Loss at iteration 2310 : 5725494444032.0
Loss at iteration 2320 : 390412500992.0
Loss at iteration 2330 : 518702825472.0
Loss at iteration 2340 : 4537818021888.0
Loss at iteration 2350 : 1228997394432.0
Loss at iteration 2360 : 3669634842624.0
Loss at iteration 2370 : 2140510617600.0
Loss at iteration 2380 : 96773439488.0
Loss at iteration 2390 : 929755103232.0
Loss at iteration 2400 : 6159973482496.0
Loss at iteration 2410 : 177050550272.0
Loss at iteration 2420 : 33132778618880.0
The SSIM Value is: 3.733282170278092e-06
The PSNR Value is: -130.09028015136718
the epoch is: 198
Loss at iteration 10 : 306125307904.0
Loss at iteration 20 : 925988487168.0
Loss at iteration 30 : 3517692510208.0
Loss at iteration 40 : 5930521985024.0
Loss at iteration 50 : 287994773504.0
Loss at iteration 60 : 5621122859008.0
Loss at iteration 70 : 1491878412288.0
Loss at iteration 80 : 3335974813696.0
Loss at iteration 90 : 307122929664.0
Loss at iteration 100 : 63602114560.0
Loss at iteration 110 : 4087964237824.0
Loss at iteration 120 : 3834407550976.0
Loss at iteration 130 : 88388247552.0
Loss at iteration 140 : 7553274085376.0
Loss at iteration 150 : 847768780800.0
Loss at iteration 160 : 103209861120.0
Loss at iteration 170 : 271136014336.0
Loss at iteration 180 : 2812556869632.0
Loss at iteration 190 : 88388255744.0
Loss at iteration 200 : 1256180547584.0
Loss at iteration 210 : 519865171968.0
Loss at iteration 220 : 768367198208.0
Loss at iteration 230 : 29197407879168.0
Loss at iteration 240 : 50557796352.0
Loss at iteration 250 : 1398840229888.0
Loss at iteration 260 : 689069948928.0
Loss at iteration 270 : 1106005983232.0
Loss at iteration 280 : 81639451394048.0
Loss at iteration 290 : 1290297671680.0
Loss at iteration 300 : 4017799561216.0
Loss at iteration 310 : 667053326336.0
Loss at iteration 320 : 7319213572096.0
Loss at iteration 330 : 10164727971840.0
Loss at iteration 340 : 7670973071360.0
Loss at iteration 350 : 3500531777536.0
Loss at iteration 360 : 4230957236224.0
Loss at iteration 370 : 14932267499520.0
Loss at iteration 380 : 1117585670144.0
Loss at iteration 390 : 3008543850496.0
Loss at iteration 400 : 5074175655936.0
Loss at iteration 410 : 3728022437888.0
Loss at iteration 420 : 378470105088.0
Loss at iteration 430 : 1813321613312.0
Loss at iteration 440 : 14914920906752.0
Loss at iteration 450 : 6505925967872.0
Loss at iteration 460 : 1716930609152.0
Loss at iteration 470 : 2314863378432.0
Loss at iteration 480 : 5472427442176.0
Loss at iteration 490 : 4170806722560.0
Loss at iteration 500 : 13228464668672.0
Loss at iteration 510 : 6570449567744.0
Loss at iteration 520 : 18981467455488.0
Loss at iteration 530 : 4166425772032.0
Loss at iteration 540 : 13091957899264.0
Loss at iteration 550 : 16606188011520.0
Loss at iteration 560 : 9945650036736.0
Loss at iteration 570 : 10469832130560.0
Loss at iteration 580 : 3313326358528.0
Loss at iteration 590 : 45606424805376.0
Loss at iteration 600 : 15829208924160.0
Loss at iteration 610 : 9869422755840.0
Loss at iteration 620 : 1200761602048.0
Loss at iteration 630 : 3002830159872.0
Loss at iteration 640 : 205800931328.0
Loss at iteration 650 : 1103321235456.0
Loss at iteration 660 : 127709069312.0
Loss at iteration 670 : 39896260608.0
Loss at iteration 680 : 37022474240.0
Loss at iteration 690 : 3782056345600.0
Loss at iteration 700 : 488934949781504.0
Loss at iteration 710 : 4296173913374720.0
Loss at iteration 720 : 5086320787456.0
Loss at iteration 730 : 124410086293504.0
Loss at iteration 740 : 495801327419392.0
Loss at iteration 750 : 8149381677056.0
Loss at iteration 760 : 561429400780800.0
Loss at iteration 770 : 14931962363904.0
Loss at iteration 780 : 31269486329856.0
Loss at iteration 790 : 2793350889472.0
Loss at iteration 800 : 125510671663104.0
Loss at iteration 810 : 29518318272512.0
Loss at iteration 820 : 3196199108608.0
Loss at iteration 830 : 1192163672064.0
Loss at iteration 840 : 581542608896.0
Loss at iteration 850 : 8146967855104.0
Loss at iteration 860 : 22256799449088.0
Loss at iteration 870 : 51060076969984.0
Loss at iteration 880 : 367063172382720.0
Loss at iteration 890 : 4400181936128.0
Loss at iteration 900 : 41156679303168.0
Loss at iteration 910 : 2109210755072.0
Loss at iteration 920 : 44535816126464.0
Loss at iteration 930 : 27026861850624.0
Loss at iteration 940 : 17959177158656.0
Loss at iteration 950 : 26247908294656.0
Loss at iteration 960 : 1193348300800.0
Loss at iteration 970 : 3933238722560.0
Loss at iteration 980 : 7463258030080.0
Loss at iteration 990 : 4340281769984.0
Loss at iteration 1000 : 11071443173376.0
Loss at iteration 1010 : 60955329298432.0
Loss at iteration 1020 : 4958791401472.0
Loss at iteration 1030 : 1330104500224.0
Loss at iteration 1040 : 473104203644928.0
Loss at iteration 1050 : 7868091727872.0
Loss at iteration 1060 : 154383761408.0
Loss at iteration 1070 : 3796500742144.0
Loss at iteration 1080 : 3806012381331456.0
Loss at iteration 1090 : 1.4838086369489715e+17
Loss at iteration 1100 : 1429040577642496.0
Loss at iteration 1110 : 41333301444608.0
Loss at iteration 1120 : 104342514302976.0
Loss at iteration 1130 : 189991636434944.0
Loss at iteration 1140 : 63299517415424.0
Loss at iteration 1150 : 4436979613696.0
Loss at iteration 1160 : 5755804057600.0
Loss at iteration 1170 : 1868598214656.0
Loss at iteration 1180 : 21506792882176.0
Loss at iteration 1190 : 923629227343872.0
Loss at iteration 1200 : 15144215117824.0
Loss at iteration 1210 : 117354604265472.0
Loss at iteration 1220 : 4896179879936.0
Loss at iteration 1230 : 3696651141120.0
Loss at iteration 1240 : 21662139416576.0
Loss at iteration 1250 : 104929423261696.0
Loss at iteration 1260 : 3086804844544.0
Loss at iteration 1270 : 11681998569472.0
Loss at iteration 1280 : 1052698279936.0
Loss at iteration 1290 : 1867320393728.0
Loss at iteration 1300 : 546255011840.0
Loss at iteration 1310 : 22663969898496.0
Loss at iteration 1320 : 10227422330880.0
Loss at iteration 1330 : 8660981907456.0
Loss at iteration 1340 : 8691314065408.0
Loss at iteration 1350 : 2660873011200.0
Loss at iteration 1360 : 11317275525120.0
Loss at iteration 1370 : 209059663839232.0
Loss at iteration 1380 : 609461403648.0
Loss at iteration 1390 : 1458231181312.0
Loss at iteration 1400 : 404029284810752.0
Loss at iteration 1410 : 7837783162880.0
Loss at iteration 1420 : 3412129480704.0
Loss at iteration 1430 : 241618519064576.0
Loss at iteration 1440 : 1957577097216.0
Loss at iteration 1450 : 15444171816960.0
Loss at iteration 1460 : 4725023440896.0
Loss at iteration 1470 : 9388903366656.0
Loss at iteration 1480 : 8879015460864.0
Loss at iteration 1490 : 4833502298112.0
Loss at iteration 1500 : 933036749225984.0
Loss at iteration 1510 : 2773307097088.0
Loss at iteration 1520 : 1922210201600.0
Loss at iteration 1530 : 5243425259520.0
Loss at iteration 1540 : 794736185049088.0
Loss at iteration 1550 : 4784166273024.0
Loss at iteration 1560 : 12423085948928.0
Loss at iteration 1570 : 1813987852288.0
Loss at iteration 1580 : 4763235123200.0
Loss at iteration 1590 : 53000840151040.0
Loss at iteration 1600 : 16428655706112.0
Loss at iteration 1610 : 2701305839616.0
Loss at iteration 1620 : 107244609536.0
Loss at iteration 1630 : 211095764992.0
Loss at iteration 1640 : 7077237358592.0
Loss at iteration 1650 : 4118569811968.0
Loss at iteration 1660 : 52483612672.0
Loss at iteration 1670 : 1421646626816.0
Loss at iteration 1680 : 13428282359808.0
Loss at iteration 1690 : 2382612660224.0
Loss at iteration 1700 : 7947311644672.0
Loss at iteration 1710 : 245407891456.0
Loss at iteration 1720 : 588849020928.0
Loss at iteration 1730 : 538927169536.0
Loss at iteration 1740 : 709736792064.0
Loss at iteration 1750 : 1215957434368.0
Loss at iteration 1760 : 4891553562624.0
Loss at iteration 1770 : 965590908928.0
Loss at iteration 1780 : 6704255729664.0
Loss at iteration 1790 : 387227025408.0
Loss at iteration 1800 : 11117194641408.0
Loss at iteration 1810 : 2066026332160.0
Loss at iteration 1820 : 6221356597248.0
Loss at iteration 1830 : 2375688912896.0
Loss at iteration 1840 : 44354446032896.0
Loss at iteration 1850 : 1562339966976.0
Loss at iteration 1860 : 37225207169024.0
Loss at iteration 1870 : 351793446912.0
Loss at iteration 1880 : 1755401814016.0
Loss at iteration 1890 : 31362354511872.0
Loss at iteration 1900 : 13474956574720.0
Loss at iteration 1910 : 37598760271872.0
Loss at iteration 1920 : 10261419261952.0
Loss at iteration 1930 : 2375913046016.0
Loss at iteration 1940 : 455901675520.0
Loss at iteration 1950 : 1496672763904.0
Loss at iteration 1960 : 1864559230976.0
Loss at iteration 1970 : 7808406781952.0
Loss at iteration 1980 : 213596536832.0
Loss at iteration 1990 : 8097731969024.0
Loss at iteration 2000 : 3404819595264.0
Loss at iteration 2010 : 45818262323200.0
Loss at iteration 2020 : 1039737427066880.0
Loss at iteration 2030 : 260851751714816.0
Loss at iteration 2040 : 135461053923328.0
Loss at iteration 2050 : 178738671124480.0
Loss at iteration 2060 : 1181470031872.0
Loss at iteration 2070 : 37913052053504.0
Loss at iteration 2080 : 5849784778752.0
Loss at iteration 2090 : 13551034957824.0
Loss at iteration 2100 : 39649175142400.0
Loss at iteration 2110 : 448027656192.0
Loss at iteration 2120 : 6458300694528.0
Loss at iteration 2130 : 73051580399616.0
Loss at iteration 2140 : 2086052298752.0
Loss at iteration 2150 : 969901015040.0
Loss at iteration 2160 : 2082555035648.0
Loss at iteration 2170 : 4124003008512.0
Loss at iteration 2180 : 12803324772352.0
Loss at iteration 2190 : 278766977024.0
Loss at iteration 2200 : 5235297222656.0
Loss at iteration 2210 : 854324740096.0
Loss at iteration 2220 : 4751962406912.0
Loss at iteration 2230 : 5795255156736.0
Loss at iteration 2240 : 78204428288.0
Loss at iteration 2250 : 365021102080.0
Loss at iteration 2260 : 264438726656.0
Loss at iteration 2270 : 1366361112576.0
Loss at iteration 2280 : 2258560352256.0
Loss at iteration 2290 : 1986898165760.0
Loss at iteration 2300 : 2842315456512.0
Loss at iteration 2310 : 3545444909056.0
Loss at iteration 2320 : 432073173106688.0
Loss at iteration 2330 : 7971051929600.0
Loss at iteration 2340 : 8640233734144.0
Loss at iteration 2350 : 32147209453568.0
Loss at iteration 2360 : 890749517824.0
Loss at iteration 2370 : 1253700665344.0
Loss at iteration 2380 : 3025348853760.0
Loss at iteration 2390 : 2956220956672.0
Loss at iteration 2400 : 280347508736.0
Loss at iteration 2410 : 565132394496.0
Loss at iteration 2420 : 328724905984.0
The SSIM Value is: 5.8249149484860634e-06
The PSNR Value is: -134.26939341227214
the epoch is: 199
Loss at iteration 10 : 740152901632.0
Loss at iteration 20 : 748684136415232.0
Loss at iteration 30 : 357334417408.0
Loss at iteration 40 : 1593336922112.0
Loss at iteration 50 : 4865931083776.0
Loss at iteration 60 : 6275734700032.0
Loss at iteration 70 : 937800892416.0
Loss at iteration 80 : 920098832384.0
Loss at iteration 90 : 132823121920000.0
Loss at iteration 100 : 6493383426048.0
Loss at iteration 110 : 5184688750592.0
Loss at iteration 120 : 2341711118336.0
Loss at iteration 130 : 702688794771456.0
Loss at iteration 140 : 224464175104.0
Loss at iteration 150 : 210054807552.0
Loss at iteration 160 : 1497308856320.0
Loss at iteration 170 : 1418125508608.0
Loss at iteration 180 : 1826744303616.0
Loss at iteration 190 : 692108132352.0
Loss at iteration 200 : 968629747712.0
Loss at iteration 210 : 5370719764480.0
Loss at iteration 220 : 5795833446400.0
Loss at iteration 230 : 220906274816.0
Loss at iteration 240 : 1928407285760.0
Loss at iteration 250 : 611191488512.0
Loss at iteration 260 : 1267881213952.0
Loss at iteration 270 : 1098066690048.0
Loss at iteration 280 : 57820070281216.0
Loss at iteration 290 : 4204986892288.0
Loss at iteration 300 : 663148494848.0
Loss at iteration 310 : 14841521635328.0
Loss at iteration 320 : 7191396352000.0
Loss at iteration 330 : 3098349666304.0
Loss at iteration 340 : 4354353135616.0
Loss at iteration 350 : 10217276309504.0
Loss at iteration 360 : 1654719774720.0
Loss at iteration 370 : 2689655373824.0
Loss at iteration 380 : 211803406336.0
Loss at iteration 390 : 965373263872.0
Loss at iteration 400 : 529309728768.0
Loss at iteration 410 : 655911550976.0
Loss at iteration 420 : 1998882865152.0
Loss at iteration 430 : 10665666281472.0
Loss at iteration 440 : 268695535616.0
Loss at iteration 450 : 1036207063040.0
Loss at iteration 460 : 554217832448.0
Loss at iteration 470 : 2301519986688.0
Loss at iteration 480 : 10268128051200.0
Loss at iteration 490 : 1096630337536.0
Loss at iteration 500 : 3194548649984.0
Loss at iteration 510 : 2659854581760.0
Loss at iteration 520 : 896869924864.0
Loss at iteration 530 : 4566843654144.0
Loss at iteration 540 : 841427910656.0
Loss at iteration 550 : 3678198824960.0
Loss at iteration 560 : 24329356050432.0
Loss at iteration 570 : 8570459389952.0
Loss at iteration 580 : 1400125381410816.0
Loss at iteration 590 : 857948104425472.0
Loss at iteration 600 : 6733379928064.0
Loss at iteration 610 : 1617124130816.0
Loss at iteration 620 : 16847920431104.0
Loss at iteration 630 : 10887397113856.0
Loss at iteration 640 : 3543448944640.0
Loss at iteration 650 : 322101542912.0
Loss at iteration 660 : 1563486584832.0
Loss at iteration 670 : 287257886720.0
Loss at iteration 680 : 958639636480.0
Loss at iteration 690 : 15962632880128.0
Loss at iteration 700 : 127481860325376.0
Loss at iteration 710 : 3825851695104.0
Loss at iteration 720 : 4759658954752.0
Loss at iteration 730 : 8584181579776.0
Loss at iteration 740 : 1119145558016.0
Loss at iteration 750 : 1113020694528.0
Loss at iteration 760 : 746974674944.0
Loss at iteration 770 : 1172797784064.0
Loss at iteration 780 : 11193973473280.0
Loss at iteration 790 : 3845457444864.0
Loss at iteration 800 : 195750985728.0
Loss at iteration 810 : 972593364992.0
Loss at iteration 820 : 7590503776256.0
Loss at iteration 830 : 205577879552.0
Loss at iteration 840 : 283214086144.0
Loss at iteration 850 : 736707936256.0
Loss at iteration 860 : 1243721891840.0
Loss at iteration 870 : 710198231040.0
Loss at iteration 880 : 6569193897984.0
Loss at iteration 890 : 831343362048.0
Loss at iteration 900 : 560804003840.0
Loss at iteration 910 : 1922447966208.0
Loss at iteration 920 : 2731641143296.0
Loss at iteration 930 : 6061984579584.0
Loss at iteration 940 : 1812059914240.0
Loss at iteration 950 : 7133478780928.0
Loss at iteration 960 : 4404376240128.0
Loss at iteration 970 : 573344907264.0
Loss at iteration 980 : 14195049365504.0
Loss at iteration 990 : 884245921792.0
Loss at iteration 1000 : 22102495199232.0
Loss at iteration 1010 : 1642369646592.0
Loss at iteration 1020 : 479663128576.0
Loss at iteration 1030 : 1655507648512.0
Loss at iteration 1040 : 534318481408.0
Loss at iteration 1050 : 4143545057280.0
Loss at iteration 1060 : 102090137600.0
Loss at iteration 1070 : 183820550144.0
Loss at iteration 1080 : 1150870749184.0
Loss at iteration 1090 : 24717004111872.0
Loss at iteration 1100 : 5542080151552.0
Loss at iteration 1110 : 3142161006592.0
Loss at iteration 1120 : 3509435236352.0
Loss at iteration 1130 : 939678498816.0
Loss at iteration 1140 : 79545163776.0
Loss at iteration 1150 : 732571041792.0
Loss at iteration 1160 : 42641156734976.0
Loss at iteration 1170 : 3047862304768.0
Loss at iteration 1180 : 1022588289024.0
Loss at iteration 1190 : 1365132705792.0
Loss at iteration 1200 : 1457623531520.0
Loss at iteration 1210 : 3592526233600.0
Loss at iteration 1220 : 1390257111040.0
Loss at iteration 1230 : 1182236803072.0
Loss at iteration 1240 : 2525995991040.0
Loss at iteration 1250 : 1171683672064.0
Loss at iteration 1260 : 11302878576640.0
Loss at iteration 1270 : 3704422137856.0
Loss at iteration 1280 : 2699396120576.0
Loss at iteration 1290 : 840518664192.0
Loss at iteration 1300 : 1605919703040.0
Loss at iteration 1310 : 5937760829440.0
Loss at iteration 1320 : 1556260847616.0
Loss at iteration 1330 : 911601696768.0
Loss at iteration 1340 : 3407641051136.0
Loss at iteration 1350 : 690649497600.0
Loss at iteration 1360 : 1200828710912.0
Loss at iteration 1370 : 312467456000.0
Loss at iteration 1380 : 926593253376.0
Loss at iteration 1390 : 1760407715840.0
Loss at iteration 1400 : 575816925184.0
Loss at iteration 1410 : 803261186048.0
Loss at iteration 1420 : 1309539827712.0
Loss at iteration 1430 : 7583682789376.0
Loss at iteration 1440 : 431062319104.0
Loss at iteration 1450 : 4373573795840.0
Loss at iteration 1460 : 1378896052224.0
Loss at iteration 1470 : 585938501632.0
Loss at iteration 1480 : 2550050324480.0
Loss at iteration 1490 : 4395301339136.0
Loss at iteration 1500 : 742153191424.0
Loss at iteration 1510 : 1320945188864.0
Loss at iteration 1520 : 738879733760.0
Loss at iteration 1530 : 6562458370048.0
Loss at iteration 1540 : 868420616192.0
Loss at iteration 1550 : 1283285712896.0
Loss at iteration 1560 : 10934302015488.0
Loss at iteration 1570 : 625119395840.0
Loss at iteration 1580 : 10821821267968.0
Loss at iteration 1590 : 58614214656.0
Loss at iteration 1600 : 1256019591168.0
Loss at iteration 1610 : 395794055168.0
Loss at iteration 1620 : 1123788259328.0
Loss at iteration 1630 : 1741794836480.0
Loss at iteration 1640 : 2989040599040.0
Loss at iteration 1650 : 6113259945984.0
Loss at iteration 1660 : 1339315847168.0
Loss at iteration 1670 : 117609743777792.0
Loss at iteration 1680 : 8538421198848.0
Loss at iteration 1690 : 340802437120.0
Loss at iteration 1700 : 3085781958656.0
Loss at iteration 1710 : 837081300992.0
Loss at iteration 1720 : 398448754688.0
Loss at iteration 1730 : 289654865920.0
Loss at iteration 1740 : 1713763516416.0
Loss at iteration 1750 : 488267317248.0
Loss at iteration 1760 : 154100219904.0
Loss at iteration 1770 : 130472263680.0
Loss at iteration 1780 : 121167855616.0
Loss at iteration 1790 : 2480688070656.0
Loss at iteration 1800 : 695504338944.0
Loss at iteration 1810 : 811007279104.0
Loss at iteration 1820 : 8740904370176.0
Loss at iteration 1830 : 29893500862464.0
Loss at iteration 1840 : 13671493271552.0
Loss at iteration 1850 : 1562878410752.0
Loss at iteration 1860 : 1860764958720.0
Loss at iteration 1870 : 2027043422208.0
Loss at iteration 1880 : 2726813761536.0
Loss at iteration 1890 : 194444902400.0
Loss at iteration 1900 : 472699404288.0
Loss at iteration 1910 : 1304393678848.0
Loss at iteration 1920 : 89902620672.0
Loss at iteration 1930 : 207815966720.0
Loss at iteration 1940 : 371199541248.0
Loss at iteration 1950 : 894852988928.0
Loss at iteration 1960 : 5812603322368.0
Loss at iteration 1970 : 65262088192.0
Loss at iteration 1980 : 646318325760.0
Loss at iteration 1990 : 46107500544.0
Loss at iteration 2000 : 719089238016.0
Loss at iteration 2010 : 810916642816.0
Loss at iteration 2020 : 3269506891776.0
Loss at iteration 2030 : 2026604462080.0
Loss at iteration 2040 : 640489750528.0
Loss at iteration 2050 : 162699788288.0
Loss at iteration 2060 : 148926955520.0
Loss at iteration 2070 : 1455246802944.0
Loss at iteration 2080 : 4257199947776.0
Loss at iteration 2090 : 130111881216.0
Loss at iteration 2100 : 1134254882816.0
Loss at iteration 2110 : 3595248336896.0
Loss at iteration 2120 : 216811012096.0
Loss at iteration 2130 : 560229908480.0
Loss at iteration 2140 : 937772974080.0
Loss at iteration 2150 : 1385718218752.0
Loss at iteration 2160 : 714990223360.0
Loss at iteration 2170 : 475305246720.0
Loss at iteration 2180 : 1463809474560.0
Loss at iteration 2190 : 855937253376.0
Loss at iteration 2200 : 177208098816.0
Loss at iteration 2210 : 393740812288.0
Loss at iteration 2220 : 1713352343552.0
Loss at iteration 2230 : 1225835282432.0
Loss at iteration 2240 : 2370752741376.0
Loss at iteration 2250 : 21697715503104.0
Loss at iteration 2260 : 723921338368.0
Loss at iteration 2270 : 2156956876800.0
Loss at iteration 2280 : 300318425088.0
Loss at iteration 2290 : 198383140864.0
Loss at iteration 2300 : 2305412825088.0
Loss at iteration 2310 : 1469205184512.0
Loss at iteration 2320 : 468100775936.0
Loss at iteration 2330 : 1606995279872.0
Loss at iteration 2340 : 567310286848.0
Loss at iteration 2350 : 2547781206016.0
Loss at iteration 2360 : 28958382882816.0
Loss at iteration 2370 : 270284029952.0
Loss at iteration 2380 : 1180702867456.0
Loss at iteration 2390 : 2601671196672.0
Loss at iteration 2400 : 1631796461568.0
Loss at iteration 2410 : 54382256128.0
Loss at iteration 2420 : 1735614398464.0
The SSIM Value is: 2.244685618772261e-06
The PSNR Value is: -126.37978566487631
