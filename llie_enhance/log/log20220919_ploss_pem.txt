Namespace(gpu_id=0, img_path='/home/wsz/workspace/Data/LOLdataset/our485_patch/low/', img_val_path='/home/wsz/workspace/Data/LOLdataset/eval15/low/', batch_size=4, lr=0.0002, weight_decay=0.0004, pretrain_dir=None, num_epochs=200, display_iter=10, snapshots_folder='workdirs/snapshots_folder_lol_v1_patch_u2net_ploss_pem_220919')
Total examples: 4850
Total examples: 15
the device is: cuda:0
######## Start IAT Training #########
the epoch is: 0
/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/functional.py:3509: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.
  warnings.warn("nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.")
/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
/home/wsz/miniconda3/envs/kang/lib/python3.9/site-packages/torch/nn/functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.
  warnings.warn("nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.")
Loss at iteration 10 : 0.0706949383020401
Loss at iteration 20 : 0.05494117736816406
Loss at iteration 30 : 0.07197824120521545
Loss at iteration 40 : 0.054428134113550186
Loss at iteration 50 : 0.07168253511190414
Loss at iteration 60 : 0.06994781643152237
Loss at iteration 70 : 0.06865614652633667
Loss at iteration 80 : 0.06097131595015526
Loss at iteration 90 : 0.0786128118634224
Loss at iteration 100 : 0.06123889982700348
Loss at iteration 110 : 0.06400492042303085
Loss at iteration 120 : 0.07581474632024765
Loss at iteration 130 : 0.08667346835136414
Loss at iteration 140 : 0.0573759600520134
Loss at iteration 150 : 0.08659599721431732
Loss at iteration 160 : 0.05123702064156532
Loss at iteration 170 : 0.04593214765191078
Loss at iteration 180 : 0.054352015256881714
Loss at iteration 190 : 0.08475400507450104
Loss at iteration 200 : 0.07196725904941559
Loss at iteration 210 : 0.06592443585395813
Loss at iteration 220 : 0.07142012566328049
Loss at iteration 230 : 0.09200311452150345
Loss at iteration 240 : 0.07332330197095871
Loss at iteration 250 : 0.061585552990436554
Loss at iteration 260 : 0.06614729762077332
Loss at iteration 270 : 0.0828605368733406
Loss at iteration 280 : 0.06986016035079956
Loss at iteration 290 : 0.0808950811624527
Loss at iteration 300 : 0.0625317320227623
Loss at iteration 310 : 0.08120265603065491
Loss at iteration 320 : 0.040459662675857544
Loss at iteration 330 : 0.07706931233406067
Loss at iteration 340 : 0.06474356353282928
Loss at iteration 350 : 0.07059377431869507
Loss at iteration 360 : 0.06716564297676086
Loss at iteration 370 : 0.050708942115306854
Loss at iteration 380 : 0.07846193760633469
Loss at iteration 390 : 0.07340505719184875
Loss at iteration 400 : 0.0845557302236557
Loss at iteration 410 : 0.059265054762363434
Loss at iteration 420 : 0.06712055206298828
Loss at iteration 430 : 0.07253462821245193
Loss at iteration 440 : 0.09330074489116669
Loss at iteration 450 : 0.06450396031141281
Loss at iteration 460 : 0.06751362979412079
Loss at iteration 470 : 0.07751807570457458
Loss at iteration 480 : 0.07321427017450333
Loss at iteration 490 : 0.06907841563224792
Loss at iteration 500 : 0.057272784411907196
Loss at iteration 510 : 0.07048079371452332
Loss at iteration 520 : 0.06774091720581055
Loss at iteration 530 : 0.05650443583726883
Loss at iteration 540 : 0.05855812504887581
Loss at iteration 550 : 0.06506191194057465
Loss at iteration 560 : 0.05133721977472305
Loss at iteration 570 : 0.08751183748245239
Loss at iteration 580 : 0.05618515610694885
Loss at iteration 590 : 0.0407925583422184
Loss at iteration 600 : 0.0655176192522049
Loss at iteration 610 : 0.08530069887638092
Loss at iteration 620 : 0.05237635225057602
Loss at iteration 630 : 0.060121722519397736
Loss at iteration 640 : 0.03939470276236534
Loss at iteration 650 : 0.090785451233387
Loss at iteration 660 : 0.042039573192596436
Loss at iteration 670 : 0.04649117588996887
Loss at iteration 680 : 0.07182411104440689
Loss at iteration 690 : 0.0515531450510025
Loss at iteration 700 : 0.03513951227068901
Loss at iteration 710 : 0.055811114609241486
Loss at iteration 720 : 0.04469563812017441
Loss at iteration 730 : 0.033169325441122055
Loss at iteration 740 : 0.05474746972322464
Loss at iteration 750 : 0.08085010200738907
Loss at iteration 760 : 0.07821953296661377
Loss at iteration 770 : 0.0735643282532692
Loss at iteration 780 : 0.04250355437397957
Loss at iteration 790 : 0.0423213429749012
Loss at iteration 800 : 0.05108107253909111
Loss at iteration 810 : 0.047642454504966736
Loss at iteration 820 : 0.03909142687916756
Loss at iteration 830 : 0.05552984029054642
Loss at iteration 840 : 0.060799770057201385
Loss at iteration 850 : 0.03752290457487106
Loss at iteration 860 : 0.04421229660511017
Loss at iteration 870 : 0.06711070984601974
Loss at iteration 880 : 0.037971388548612595
Loss at iteration 890 : 0.042584799230098724
Loss at iteration 900 : 0.06318406015634537
Loss at iteration 910 : 0.04593431204557419
Loss at iteration 920 : 0.064167819917202
Loss at iteration 930 : 0.05982409417629242
Loss at iteration 940 : 0.04171428829431534
Loss at iteration 950 : 0.06526044756174088
Loss at iteration 960 : 0.040853776037693024
Loss at iteration 970 : 0.05424455553293228
Loss at iteration 980 : 0.08347000181674957
Loss at iteration 990 : 0.06724496185779572
Loss at iteration 1000 : 0.08088846504688263
Loss at iteration 1010 : 0.032609596848487854
Loss at iteration 1020 : 0.044143639504909515
Loss at iteration 1030 : 0.06360521167516708
Loss at iteration 1040 : 0.06663721799850464
Loss at iteration 1050 : 0.0368850938975811
Loss at iteration 1060 : 0.07604553550481796
Loss at iteration 1070 : 0.054002244025468826
Loss at iteration 1080 : 0.04678028076887131
Loss at iteration 1090 : 0.05351913720369339
Loss at iteration 1100 : 0.050159648060798645
Loss at iteration 1110 : 0.047647807747125626
Loss at iteration 1120 : 0.07355524599552155
Loss at iteration 1130 : 0.047917671501636505
Loss at iteration 1140 : 0.08347991108894348
Loss at iteration 1150 : 0.04834720492362976
Loss at iteration 1160 : 0.03330241143703461
Loss at iteration 1170 : 0.06142948940396309
Loss at iteration 1180 : 0.05274435132741928
Loss at iteration 1190 : 0.04983500391244888
Loss at iteration 1200 : 0.06650906801223755
Loss at iteration 1210 : 0.05619358643889427
The SSIM Value is: 0.6848367134730021
The PSNR Value is: 16.700029436747233
the highest SSIM value is: 16.700029436747233
the epoch is: 1
Loss at iteration 10 : 0.05018509924411774
Loss at iteration 20 : 0.06558451801538467
Loss at iteration 30 : 0.043213505297899246
Loss at iteration 40 : 0.04154777526855469
Loss at iteration 50 : 0.05722349137067795
Loss at iteration 60 : 0.0478721484541893
Loss at iteration 70 : 0.044250935316085815
Loss at iteration 80 : 0.04187912493944168
Loss at iteration 90 : 0.06059664487838745
Loss at iteration 100 : 0.039100900292396545
Loss at iteration 110 : 0.04797077924013138
Loss at iteration 120 : 0.04144039750099182
Loss at iteration 130 : 0.05266755446791649
Loss at iteration 140 : 0.053024787455797195
Loss at iteration 150 : 0.039700429886579514
Loss at iteration 160 : 0.051862865686416626
Loss at iteration 170 : 0.04619734361767769
Loss at iteration 180 : 0.041178423911333084
Loss at iteration 190 : 0.05926937982439995
Loss at iteration 200 : 0.04719950258731842
Loss at iteration 210 : 0.05093328654766083
Loss at iteration 220 : 0.06512285768985748
Loss at iteration 230 : 0.03793593868613243
Loss at iteration 240 : 0.06830649077892303
Loss at iteration 250 : 0.057506151497364044
Loss at iteration 260 : 0.030011000111699104
Loss at iteration 270 : 0.051908694207668304
Loss at iteration 280 : 0.04321994259953499
Loss at iteration 290 : 0.04605594277381897
Loss at iteration 300 : 0.052942052483558655
Loss at iteration 310 : 0.048601552844047546
Loss at iteration 320 : 0.05331782251596451
Loss at iteration 330 : 0.06072262302041054
Loss at iteration 340 : 0.049630746245384216
Loss at iteration 350 : 0.04238871484994888
Loss at iteration 360 : 0.04500710964202881
Loss at iteration 370 : 0.028462274000048637
Loss at iteration 380 : 0.03975921869277954
Loss at iteration 390 : 0.041372209787368774
Loss at iteration 400 : 0.04304807633161545
Loss at iteration 410 : 0.05644122511148453
Loss at iteration 420 : 0.056698307394981384
Loss at iteration 430 : 0.04829034209251404
Loss at iteration 440 : 0.04924117773771286
Loss at iteration 450 : 0.03857290744781494
Loss at iteration 460 : 0.03541228175163269
Loss at iteration 470 : 0.04119190201163292
Loss at iteration 480 : 0.04987926781177521
Loss at iteration 490 : 0.05877168849110603
Loss at iteration 500 : 0.0666528269648552
Loss at iteration 510 : 0.04494747519493103
Loss at iteration 520 : 0.03452366590499878
Loss at iteration 530 : 0.04692615568637848
Loss at iteration 540 : 0.02751222252845764
Loss at iteration 550 : 0.04135550558567047
Loss at iteration 560 : 0.04923908784985542
Loss at iteration 570 : 0.03692425787448883
Loss at iteration 580 : 0.04156880080699921
Loss at iteration 590 : 0.04720628261566162
Loss at iteration 600 : 0.04903550446033478
Loss at iteration 610 : 0.04322861507534981
Loss at iteration 620 : 0.042448729276657104
Loss at iteration 630 : 0.03921280801296234
Loss at iteration 640 : 0.04360620677471161
Loss at iteration 650 : 0.03415815532207489
Loss at iteration 660 : 0.04290257394313812
Loss at iteration 670 : 0.02939658984541893
Loss at iteration 680 : 0.03166140243411064
Loss at iteration 690 : 0.03684183210134506
Loss at iteration 700 : 0.04124161973595619
Loss at iteration 710 : 0.03250005096197128
Loss at iteration 720 : 0.032597433775663376
Loss at iteration 730 : 0.042847976088523865
Loss at iteration 740 : 0.03756626322865486
Loss at iteration 750 : 0.05846714973449707
Loss at iteration 760 : 0.03667148947715759
Loss at iteration 770 : 0.0553300641477108
Loss at iteration 780 : 0.03666984289884567
Loss at iteration 790 : 0.03927578032016754
Loss at iteration 800 : 0.03663073107600212
Loss at iteration 810 : 0.030762508511543274
Loss at iteration 820 : 0.03605569526553154
Loss at iteration 830 : 0.024606840685009956
Loss at iteration 840 : 0.0341799259185791
Loss at iteration 850 : 0.04107127711176872
Loss at iteration 860 : 0.03969719260931015
Loss at iteration 870 : 0.040602654218673706
Loss at iteration 880 : 0.03841207176446915
Loss at iteration 890 : 0.04495774954557419
Loss at iteration 900 : 0.03097228705883026
Loss at iteration 910 : 0.0318780243396759
Loss at iteration 920 : 0.04504677653312683
Loss at iteration 930 : 0.04867209494113922
Loss at iteration 940 : 0.06777819246053696
Loss at iteration 950 : 0.032921645790338516
Loss at iteration 960 : 0.049023039638996124
Loss at iteration 970 : 0.04505613446235657
Loss at iteration 980 : 0.04584607109427452
Loss at iteration 990 : 0.03138483315706253
Loss at iteration 1000 : 0.03249026834964752
Loss at iteration 1010 : 0.033965907990932465
Loss at iteration 1020 : 0.024979915469884872
Loss at iteration 1030 : 0.02299449034035206
Loss at iteration 1040 : 0.03292146697640419
Loss at iteration 1050 : 0.03353923559188843
Loss at iteration 1060 : 0.038037363439798355
Loss at iteration 1070 : 0.044630736112594604
Loss at iteration 1080 : 0.03701949864625931
Loss at iteration 1090 : 0.016317417845129967
Loss at iteration 1100 : 0.028069771826267242
Loss at iteration 1110 : 0.021840590983629227
Loss at iteration 1120 : 0.03862198442220688
Loss at iteration 1130 : 0.036157961934804916
Loss at iteration 1140 : 0.048805106431245804
Loss at iteration 1150 : 0.037378884851932526
Loss at iteration 1160 : 0.06241534650325775
Loss at iteration 1170 : 0.03779282420873642
Loss at iteration 1180 : 0.026107244193553925
Loss at iteration 1190 : 0.041279759258031845
Loss at iteration 1200 : 0.05248236656188965
Loss at iteration 1210 : 0.04050585627555847
The SSIM Value is: 0.7389619429906209
The PSNR Value is: 17.629054005940755
the highest SSIM value is: 17.629054005940755
the epoch is: 2
Loss at iteration 10 : 0.02761014923453331
Loss at iteration 20 : 0.03716619312763214
Loss at iteration 30 : 0.030067041516304016
Loss at iteration 40 : 0.029964059591293335
Loss at iteration 50 : 0.03972724825143814
Loss at iteration 60 : 0.032212112098932266
Loss at iteration 70 : 0.0742962658405304
Loss at iteration 80 : 0.05136343464255333
Loss at iteration 90 : 0.03258911892771721
Loss at iteration 100 : 0.061108533293008804
Loss at iteration 110 : 0.034725360572338104
Loss at iteration 120 : 0.028585754334926605
Loss at iteration 130 : 0.0449308305978775
Loss at iteration 140 : 0.039936065673828125
Loss at iteration 150 : 0.06205660477280617
Loss at iteration 160 : 0.04399159178137779
Loss at iteration 170 : 0.02957252785563469
Loss at iteration 180 : 0.03161890059709549
Loss at iteration 190 : 0.038944851607084274
Loss at iteration 200 : 0.024862026795744896
Loss at iteration 210 : 0.03903037682175636
Loss at iteration 220 : 0.022899974137544632
Loss at iteration 230 : 0.031091829761862755
Loss at iteration 240 : 0.028235115110874176
Loss at iteration 250 : 0.032634951174259186
Loss at iteration 260 : 0.03889913856983185
Loss at iteration 270 : 0.03288514167070389
Loss at iteration 280 : 0.020846743136644363
Loss at iteration 290 : 0.03161577880382538
Loss at iteration 300 : 0.035092804580926895
Loss at iteration 310 : 0.034123603254556656
Loss at iteration 320 : 0.030829288065433502
Loss at iteration 330 : 0.03876039385795593
Loss at iteration 340 : 0.028822503983974457
Loss at iteration 350 : 0.03778576850891113
Loss at iteration 360 : 0.05909125879406929
Loss at iteration 370 : 0.03838988393545151
Loss at iteration 380 : 0.028195353224873543
Loss at iteration 390 : 0.030453570187091827
Loss at iteration 400 : 0.022951096296310425
Loss at iteration 410 : 0.03337879478931427
Loss at iteration 420 : 0.022354640066623688
Loss at iteration 430 : 0.03588247671723366
Loss at iteration 440 : 0.025560975074768066
Loss at iteration 450 : 0.027947135269641876
Loss at iteration 460 : 0.03431197628378868
Loss at iteration 470 : 0.040145039558410645
Loss at iteration 480 : 0.04369480162858963
Loss at iteration 490 : 0.03029220551252365
Loss at iteration 500 : 0.027583958581089973
Loss at iteration 510 : 0.031534478068351746
Loss at iteration 520 : 0.02798348292708397
Loss at iteration 530 : 0.043505895882844925
Loss at iteration 540 : 0.037699226289987564
Loss at iteration 550 : 0.03727618604898453
Loss at iteration 560 : 0.037069156765937805
Loss at iteration 570 : 0.028823159635066986
Loss at iteration 580 : 0.027903474867343903
Loss at iteration 590 : 0.02051467075943947
Loss at iteration 600 : 0.023217637091875076
Loss at iteration 610 : 0.034548189491033554
Loss at iteration 620 : 0.04238565266132355
Loss at iteration 630 : 0.029389996081590652
Loss at iteration 640 : 0.027340859174728394
Loss at iteration 650 : 0.027966806665062904
Loss at iteration 660 : 0.025404317304491997
Loss at iteration 670 : 0.030868977308273315
Loss at iteration 680 : 0.04075442627072334
Loss at iteration 690 : 0.02011362835764885
Loss at iteration 700 : 0.03885415568947792
Loss at iteration 710 : 0.03392213582992554
Loss at iteration 720 : 0.035730838775634766
Loss at iteration 730 : 0.04667622596025467
Loss at iteration 740 : 0.05232961103320122
Loss at iteration 750 : 0.043813664466142654
Loss at iteration 760 : 0.027721460908651352
Loss at iteration 770 : 0.028050538152456284
Loss at iteration 780 : 0.024139873683452606
Loss at iteration 790 : 0.02332109585404396
Loss at iteration 800 : 0.03084493800997734
Loss at iteration 810 : 0.029064469039440155
Loss at iteration 820 : 0.03994647040963173
Loss at iteration 830 : 0.03177831694483757
Loss at iteration 840 : 0.024020301178097725
Loss at iteration 850 : 0.04472759738564491
Loss at iteration 860 : 0.0372004434466362
Loss at iteration 870 : 0.035582639276981354
Loss at iteration 880 : 0.026354629546403885
Loss at iteration 890 : 0.040624406188726425
Loss at iteration 900 : 0.029866816475987434
Loss at iteration 910 : 0.028380315750837326
Loss at iteration 920 : 0.029056938365101814
Loss at iteration 930 : 0.031780414283275604
Loss at iteration 940 : 0.0275669414550066
Loss at iteration 950 : 0.031545527279376984
Loss at iteration 960 : 0.018552206456661224
Loss at iteration 970 : 0.03317614644765854
Loss at iteration 980 : 0.022119048982858658
Loss at iteration 990 : 0.028125477954745293
Loss at iteration 1000 : 0.04310925304889679
Loss at iteration 1010 : 0.027906320989131927
Loss at iteration 1020 : 0.024915795773267746
Loss at iteration 1030 : 0.04346608370542526
Loss at iteration 1040 : 0.03946366906166077
Loss at iteration 1050 : 0.03447730094194412
Loss at iteration 1060 : 0.030045364052057266
Loss at iteration 1070 : 0.046569544821977615
Loss at iteration 1080 : 0.04872007295489311
Loss at iteration 1090 : 0.026357755064964294
Loss at iteration 1100 : 0.036545462906360626
Loss at iteration 1110 : 0.03310331702232361
Loss at iteration 1120 : 0.0324801467359066
Loss at iteration 1130 : 0.03164088726043701
Loss at iteration 1140 : 0.017400894314050674
Loss at iteration 1150 : 0.04011239856481552
Loss at iteration 1160 : 0.025754224509000778
Loss at iteration 1170 : 0.029327532276511192
Loss at iteration 1180 : 0.042942725121974945
Loss at iteration 1190 : 0.01740526594221592
Loss at iteration 1200 : 0.026444870978593826
Loss at iteration 1210 : 0.022396810352802277
The SSIM Value is: 0.7459495643774668
The PSNR Value is: 17.853819211324055
the highest SSIM value is: 17.853819211324055
the epoch is: 3
Loss at iteration 10 : 0.027789616957306862
Loss at iteration 20 : 0.02976890467107296
Loss at iteration 30 : 0.03979015722870827
Loss at iteration 40 : 0.02435176447033882
Loss at iteration 50 : 0.022822175174951553
Loss at iteration 60 : 0.019185416400432587
Loss at iteration 70 : 0.037108637392520905
Loss at iteration 80 : 0.02744569629430771
Loss at iteration 90 : 0.02202485501766205
Loss at iteration 100 : 0.02789030596613884
Loss at iteration 110 : 0.05358375608921051
Loss at iteration 120 : 0.026686184108257294
Loss at iteration 130 : 0.02931186743080616
Loss at iteration 140 : 0.02938396856188774
Loss at iteration 150 : 0.021401219069957733
Loss at iteration 160 : 0.02335410937666893
Loss at iteration 170 : 0.027695011347532272
Loss at iteration 180 : 0.06681116670370102
Loss at iteration 190 : 0.029441915452480316
Loss at iteration 200 : 0.03836334869265556
Loss at iteration 210 : 0.018348651006817818
Loss at iteration 220 : 0.022682620212435722
Loss at iteration 230 : 0.032402120530605316
Loss at iteration 240 : 0.028743073344230652
Loss at iteration 250 : 0.02214851975440979
Loss at iteration 260 : 0.031120698899030685
Loss at iteration 270 : 0.03171778470277786
Loss at iteration 280 : 0.045817844569683075
Loss at iteration 290 : 0.02702445164322853
Loss at iteration 300 : 0.034103214740753174
Loss at iteration 310 : 0.03251286596059799
Loss at iteration 320 : 0.03309350088238716
Loss at iteration 330 : 0.03385176137089729
Loss at iteration 340 : 0.022470436990261078
Loss at iteration 350 : 0.026892302557826042
Loss at iteration 360 : 0.02771342545747757
Loss at iteration 370 : 0.030080510303378105
Loss at iteration 380 : 0.04484569653868675
Loss at iteration 390 : 0.027220062911510468
Loss at iteration 400 : 0.04093996062874794
Loss at iteration 410 : 0.027294516563415527
Loss at iteration 420 : 0.01805834285914898
Loss at iteration 430 : 0.028263989835977554
Loss at iteration 440 : 0.031105319038033485
Loss at iteration 450 : 0.03598652780056
Loss at iteration 460 : 0.02534090355038643
Loss at iteration 470 : 0.03709331154823303
Loss at iteration 480 : 0.0338544063270092
Loss at iteration 490 : 0.022396136075258255
Loss at iteration 500 : 0.033344611525535583
Loss at iteration 510 : 0.04166146367788315
Loss at iteration 520 : 0.01798219420015812
Loss at iteration 530 : 0.03309734910726547
Loss at iteration 540 : 0.029144268482923508
Loss at iteration 550 : 0.026698511093854904
Loss at iteration 560 : 0.026002854108810425
Loss at iteration 570 : 0.016287632286548615
Loss at iteration 580 : 0.03683317452669144
Loss at iteration 590 : 0.0351562425494194
Loss at iteration 600 : 0.03075173869729042
Loss at iteration 610 : 0.027448542416095734
Loss at iteration 620 : 0.024366075173020363
Loss at iteration 630 : 0.03777670860290527
Loss at iteration 640 : 0.03713459521532059
Loss at iteration 650 : 0.025462592020630836
Loss at iteration 660 : 0.03787591680884361
Loss at iteration 670 : 0.02245413139462471
Loss at iteration 680 : 0.01969095692038536
Loss at iteration 690 : 0.02531791850924492
Loss at iteration 700 : 0.036301836371421814
Loss at iteration 710 : 0.04391488432884216
Loss at iteration 720 : 0.02726544253528118
Loss at iteration 730 : 0.022050492465496063
Loss at iteration 740 : 0.05164402723312378
Loss at iteration 750 : 0.04024988412857056
Loss at iteration 760 : 0.022748170420527458
Loss at iteration 770 : 0.01478792168200016
Loss at iteration 780 : 0.04480869323015213
Loss at iteration 790 : 0.041324786841869354
Loss at iteration 800 : 0.03291475772857666
Loss at iteration 810 : 0.039210185408592224
Loss at iteration 820 : 0.035274703055620193
Loss at iteration 830 : 0.017582451924681664
Loss at iteration 840 : 0.03809906542301178
Loss at iteration 850 : 0.04119779169559479
Loss at iteration 860 : 0.038023676723241806
Loss at iteration 870 : 0.024680089205503464
Loss at iteration 880 : 0.029384102672338486
Loss at iteration 890 : 0.038471050560474396
Loss at iteration 900 : 0.025144435465335846
Loss at iteration 910 : 0.05273888260126114
Loss at iteration 920 : 0.03952089697122574
Loss at iteration 930 : 0.02109477110207081
Loss at iteration 940 : 0.0226434338837862
Loss at iteration 950 : 0.021589674055576324
Loss at iteration 960 : 0.030658597126603127
Loss at iteration 970 : 0.03115476295351982
Loss at iteration 980 : 0.030961070209741592
Loss at iteration 990 : 0.02458210103213787
Loss at iteration 1000 : 0.04287825524806976
Loss at iteration 1010 : 0.030579864978790283
Loss at iteration 1020 : 0.034526243805885315
Loss at iteration 1030 : 0.038844186812639236
Loss at iteration 1040 : 0.030188102275133133
Loss at iteration 1050 : 0.016923129558563232
Loss at iteration 1060 : 0.03628631308674812
Loss at iteration 1070 : 0.03141459822654724
Loss at iteration 1080 : 0.034542642533779144
Loss at iteration 1090 : 0.014190982095897198
Loss at iteration 1100 : 0.032616518437862396
Loss at iteration 1110 : 0.013897096738219261
Loss at iteration 1120 : 0.030672386288642883
Loss at iteration 1130 : 0.029592284932732582
Loss at iteration 1140 : 0.02532249316573143
Loss at iteration 1150 : 0.02201857790350914
Loss at iteration 1160 : 0.038506440818309784
Loss at iteration 1170 : 0.04677153751254082
Loss at iteration 1180 : 0.024537215009331703
Loss at iteration 1190 : 0.030057761818170547
Loss at iteration 1200 : 0.030796818435192108
Loss at iteration 1210 : 0.03486037254333496
The SSIM Value is: 0.7508520424365998
The PSNR Value is: 17.98624216715495
the highest SSIM value is: 17.98624216715495
the epoch is: 4
Loss at iteration 10 : 0.03434216231107712
Loss at iteration 20 : 0.03604729473590851
Loss at iteration 30 : 0.019744813442230225
Loss at iteration 40 : 0.023122556507587433
Loss at iteration 50 : 0.036747343838214874
Loss at iteration 60 : 0.02864798717200756
Loss at iteration 70 : 0.03244251385331154
Loss at iteration 80 : 0.02232590690255165
Loss at iteration 90 : 0.018349599093198776
Loss at iteration 100 : 0.041824426501989365
Loss at iteration 110 : 0.04551219940185547
Loss at iteration 120 : 0.03361662104725838
Loss at iteration 130 : 0.032098352909088135
Loss at iteration 140 : 0.026643693447113037
Loss at iteration 150 : 0.023706112056970596
Loss at iteration 160 : 0.01759582757949829
Loss at iteration 170 : 0.02983824536204338
Loss at iteration 180 : 0.030607717111706734
Loss at iteration 190 : 0.03147807717323303
Loss at iteration 200 : 0.04035501182079315
Loss at iteration 210 : 0.017520219087600708
Loss at iteration 220 : 0.02756590023636818
Loss at iteration 230 : 0.033833980560302734
Loss at iteration 240 : 0.026521185413002968
Loss at iteration 250 : 0.030395440757274628
Loss at iteration 260 : 0.024853095412254333
Loss at iteration 270 : 0.03373267501592636
Loss at iteration 280 : 0.027853595092892647
Loss at iteration 290 : 0.04017753154039383
Loss at iteration 300 : 0.024455580860376358
Loss at iteration 310 : 0.026902057230472565
Loss at iteration 320 : 0.02287326380610466
Loss at iteration 330 : 0.037321291863918304
Loss at iteration 340 : 0.03471097722649574
Loss at iteration 350 : 0.019631564617156982
Loss at iteration 360 : 0.027334902435541153
Loss at iteration 370 : 0.03503376618027687
Loss at iteration 380 : 0.03753834590315819
Loss at iteration 390 : 0.038815658539533615
Loss at iteration 400 : 0.027268294245004654
Loss at iteration 410 : 0.02271241322159767
Loss at iteration 420 : 0.015283291228115559
Loss at iteration 430 : 0.030796784907579422
Loss at iteration 440 : 0.02820640429854393
Loss at iteration 450 : 0.04322320222854614
Loss at iteration 460 : 0.03568010777235031
Loss at iteration 470 : 0.029466211795806885
Loss at iteration 480 : 0.03470481187105179
Loss at iteration 490 : 0.02593623474240303
Loss at iteration 500 : 0.02964726649224758
Loss at iteration 510 : 0.0450022853910923
Loss at iteration 520 : 0.04710189253091812
Loss at iteration 530 : 0.03398691117763519
Loss at iteration 540 : 0.0332515612244606
Loss at iteration 550 : 0.025887183845043182
Loss at iteration 560 : 0.019781816750764847
Loss at iteration 570 : 0.026964426040649414
Loss at iteration 580 : 0.026407556608319283
Loss at iteration 590 : 0.016054756939411163
Loss at iteration 600 : 0.0467342846095562
Loss at iteration 610 : 0.0334283672273159
Loss at iteration 620 : 0.027486726641654968
Loss at iteration 630 : 0.03303617984056473
Loss at iteration 640 : 0.014057694934308529
Loss at iteration 650 : 0.02748776413500309
Loss at iteration 660 : 0.023284833878278732
Loss at iteration 670 : 0.02650962583720684
Loss at iteration 680 : 0.02187359519302845
Loss at iteration 690 : 0.04597194492816925
Loss at iteration 700 : 0.027685031294822693
Loss at iteration 710 : 0.02341804839670658
Loss at iteration 720 : 0.039080411195755005
Loss at iteration 730 : 0.019595928490161896
Loss at iteration 740 : 0.027156449854373932
Loss at iteration 750 : 0.022480007261037827
Loss at iteration 760 : 0.030333736911416054
Loss at iteration 770 : 0.02124892547726631
Loss at iteration 780 : 0.022284477949142456
Loss at iteration 790 : 0.04770173877477646
Loss at iteration 800 : 0.028147418051958084
Loss at iteration 810 : 0.0254391860216856
Loss at iteration 820 : 0.025627795606851578
Loss at iteration 830 : 0.02554221637547016
Loss at iteration 840 : 0.025473041459918022
Loss at iteration 850 : 0.024809617549180984
Loss at iteration 860 : 0.04085954651236534
Loss at iteration 870 : 0.03238212317228317
Loss at iteration 880 : 0.02603522688150406
Loss at iteration 890 : 0.035993754863739014
Loss at iteration 900 : 0.02399187535047531
Loss at iteration 910 : 0.041311316192150116
Loss at iteration 920 : 0.04014755040407181
Loss at iteration 930 : 0.029786596074700356
Loss at iteration 940 : 0.029487870633602142
Loss at iteration 950 : 0.021685201674699783
Loss at iteration 960 : 0.03088623285293579
Loss at iteration 970 : 0.017970874905586243
Loss at iteration 980 : 0.02555389329791069
Loss at iteration 990 : 0.033144451677799225
Loss at iteration 1000 : 0.027521943673491478
Loss at iteration 1010 : 0.03314526006579399
Loss at iteration 1020 : 0.019028380513191223
Loss at iteration 1030 : 0.025388676673173904
Loss at iteration 1040 : 0.026730870828032494
Loss at iteration 1050 : 0.022965580224990845
Loss at iteration 1060 : 0.022860612720251083
Loss at iteration 1070 : 0.028839334845542908
Loss at iteration 1080 : 0.031083881855010986
Loss at iteration 1090 : 0.03698287159204483
Loss at iteration 1100 : 0.03796707093715668
Loss at iteration 1110 : 0.021659523248672485
Loss at iteration 1120 : 0.02973794750869274
Loss at iteration 1130 : 0.04776518791913986
Loss at iteration 1140 : 0.03414534777402878
Loss at iteration 1150 : 0.02815154939889908
Loss at iteration 1160 : 0.034900519996881485
Loss at iteration 1170 : 0.021636180579662323
Loss at iteration 1180 : 0.03984968364238739
Loss at iteration 1190 : 0.03222029283642769
Loss at iteration 1200 : 0.013780886307358742
Loss at iteration 1210 : 0.01937999576330185
The SSIM Value is: 0.7515256365140279
The PSNR Value is: 17.870843823750814
the epoch is: 5
Loss at iteration 10 : 0.033796198666095734
Loss at iteration 20 : 0.02324506640434265
Loss at iteration 30 : 0.029069218784570694
Loss at iteration 40 : 0.035920482128858566
Loss at iteration 50 : 0.024514760822057724
Loss at iteration 60 : 0.027222342789173126
Loss at iteration 70 : 0.02066575549542904
Loss at iteration 80 : 0.0318710058927536
Loss at iteration 90 : 0.026830090209841728
Loss at iteration 100 : 0.012598357163369656
Loss at iteration 110 : 0.02043924666941166
Loss at iteration 120 : 0.03185253217816353
Loss at iteration 130 : 0.025550179183483124
Loss at iteration 140 : 0.025958426296710968
Loss at iteration 150 : 0.01310994103550911
Loss at iteration 160 : 0.015116509981453419
Loss at iteration 170 : 0.026066403836011887
Loss at iteration 180 : 0.03700755536556244
Loss at iteration 190 : 0.02098017930984497
Loss at iteration 200 : 0.020483117550611496
Loss at iteration 210 : 0.028631310909986496
Loss at iteration 220 : 0.021705780178308487
Loss at iteration 230 : 0.020876388996839523
Loss at iteration 240 : 0.03177390620112419
Loss at iteration 250 : 0.031466178596019745
Loss at iteration 260 : 0.03779356926679611
Loss at iteration 270 : 0.030993539839982986
Loss at iteration 280 : 0.03455878794193268
Loss at iteration 290 : 0.024888204410672188
Loss at iteration 300 : 0.030606281012296677
Loss at iteration 310 : 0.025496214628219604
Loss at iteration 320 : 0.02065642550587654
Loss at iteration 330 : 0.025067731738090515
Loss at iteration 340 : 0.029746094718575478
Loss at iteration 350 : 0.03292476385831833
Loss at iteration 360 : 0.026249561458826065
Loss at iteration 370 : 0.0289150457829237
Loss at iteration 380 : 0.01904364302754402
Loss at iteration 390 : 0.041618429124355316
Loss at iteration 400 : 0.029260385781526566
Loss at iteration 410 : 0.025100624188780785
Loss at iteration 420 : 0.032298509031534195
Loss at iteration 430 : 0.02641802839934826
Loss at iteration 440 : 0.029275987297296524
Loss at iteration 450 : 0.034120671451091766
Loss at iteration 460 : 0.024549096822738647
Loss at iteration 470 : 0.03270381689071655
Loss at iteration 480 : 0.02123648300766945
Loss at iteration 490 : 0.028113417327404022
Loss at iteration 500 : 0.024277757853269577
Loss at iteration 510 : 0.021544719114899635
Loss at iteration 520 : 0.027838844805955887
Loss at iteration 530 : 0.029692737385630608
Loss at iteration 540 : 0.03367766737937927
Loss at iteration 550 : 0.02743346244096756
Loss at iteration 560 : 0.02573462575674057
Loss at iteration 570 : 0.015656884759664536
Loss at iteration 580 : 0.03305526077747345
Loss at iteration 590 : 0.04573708400130272
Loss at iteration 600 : 0.034039802849292755
Loss at iteration 610 : 0.027640685439109802
Loss at iteration 620 : 0.03409324586391449
Loss at iteration 630 : 0.024412792176008224
Loss at iteration 640 : 0.026676049456000328
Loss at iteration 650 : 0.022856930270791054
Loss at iteration 660 : 0.027595466002821922
Loss at iteration 670 : 0.031556226313114166
Loss at iteration 680 : 0.0272088460624218
Loss at iteration 690 : 0.012950820848345757
Loss at iteration 700 : 0.030680976808071136
Loss at iteration 710 : 0.02150546945631504
Loss at iteration 720 : 0.03725818544626236
Loss at iteration 730 : 0.044142961502075195
Loss at iteration 740 : 0.04056510701775551
Loss at iteration 750 : 0.03942972049117088
Loss at iteration 760 : 0.05368020385503769
Loss at iteration 770 : 0.030799809843301773
Loss at iteration 780 : 0.03225167095661163
Loss at iteration 790 : 0.02900341898202896
Loss at iteration 800 : 0.04117654263973236
Loss at iteration 810 : 0.026200218126177788
Loss at iteration 820 : 0.03064088523387909
Loss at iteration 830 : 0.044119954109191895
Loss at iteration 840 : 0.04010869190096855
Loss at iteration 850 : 0.015928206965327263
Loss at iteration 860 : 0.01966586522758007
Loss at iteration 870 : 0.02020362764596939
Loss at iteration 880 : 0.041404686868190765
Loss at iteration 890 : 0.04399409145116806
Loss at iteration 900 : 0.02738148160278797
Loss at iteration 910 : 0.02550959214568138
Loss at iteration 920 : 0.02837897278368473
Loss at iteration 930 : 0.01794448122382164
Loss at iteration 940 : 0.02879561111330986
Loss at iteration 950 : 0.036399926990270615
Loss at iteration 960 : 0.02744905836880207
Loss at iteration 970 : 0.032420627772808075
Loss at iteration 980 : 0.028318749740719795
Loss at iteration 990 : 0.021704958751797676
Loss at iteration 1000 : 0.02685895748436451
Loss at iteration 1010 : 0.04208334535360336
Loss at iteration 1020 : 0.033755555748939514
Loss at iteration 1030 : 0.029757967218756676
Loss at iteration 1040 : 0.04158809036016464
Loss at iteration 1050 : 0.0392119437456131
Loss at iteration 1060 : 0.025821760296821594
Loss at iteration 1070 : 0.027382897213101387
Loss at iteration 1080 : 0.033357471227645874
Loss at iteration 1090 : 0.018384482711553574
Loss at iteration 1100 : 0.03567802160978317
Loss at iteration 1110 : 0.01677946373820305
Loss at iteration 1120 : 0.02182544395327568
Loss at iteration 1130 : 0.028007004410028458
Loss at iteration 1140 : 0.03295890614390373
Loss at iteration 1150 : 0.03873405233025551
Loss at iteration 1160 : 0.02214905247092247
Loss at iteration 1170 : 0.026042450219392776
Loss at iteration 1180 : 0.024981286376714706
Loss at iteration 1190 : 0.03634095564484596
Loss at iteration 1200 : 0.03095388039946556
Loss at iteration 1210 : 0.0203845351934433
The SSIM Value is: 0.7619573473930359
The PSNR Value is: 17.948191134134927
the epoch is: 6
Loss at iteration 10 : 0.03588784486055374
Loss at iteration 20 : 0.02409256063401699
Loss at iteration 30 : 0.02611018717288971
Loss at iteration 40 : 0.02726801112294197
Loss at iteration 50 : 0.03272520750761032
Loss at iteration 60 : 0.018799612298607826
Loss at iteration 70 : 0.02688966691493988
Loss at iteration 80 : 0.02720269188284874
Loss at iteration 90 : 0.02359650656580925
Loss at iteration 100 : 0.024029672145843506
Loss at iteration 110 : 0.025812290608882904
Loss at iteration 120 : 0.03902950510382652
Loss at iteration 130 : 0.03684788942337036
Loss at iteration 140 : 0.027350839227437973
Loss at iteration 150 : 0.01419307291507721
Loss at iteration 160 : 0.0348680354654789
Loss at iteration 170 : 0.03710075467824936
Loss at iteration 180 : 0.04017651081085205
Loss at iteration 190 : 0.034151170402765274
Loss at iteration 200 : 0.026741044595837593
Loss at iteration 210 : 0.023963136598467827
Loss at iteration 220 : 0.03134406358003616
Loss at iteration 230 : 0.02756796032190323
Loss at iteration 240 : 0.023358767852187157
Loss at iteration 250 : 0.027505092322826385
Loss at iteration 260 : 0.025500940158963203
Loss at iteration 270 : 0.020788997411727905
Loss at iteration 280 : 0.03927453234791756
Loss at iteration 290 : 0.03338034451007843
Loss at iteration 300 : 0.037663236260414124
Loss at iteration 310 : 0.02493169717490673
Loss at iteration 320 : 0.02143268473446369
Loss at iteration 330 : 0.0170886367559433
Loss at iteration 340 : 0.024189762771129608
Loss at iteration 350 : 0.03402701020240784
Loss at iteration 360 : 0.03113379515707493
Loss at iteration 370 : 0.028975630179047585
Loss at iteration 380 : 0.020578324794769287
Loss at iteration 390 : 0.027087222784757614
Loss at iteration 400 : 0.03793393820524216
Loss at iteration 410 : 0.03877096623182297
Loss at iteration 420 : 0.038490623235702515
Loss at iteration 430 : 0.031129419803619385
Loss at iteration 440 : 0.021708423271775246
Loss at iteration 450 : 0.03018733486533165
Loss at iteration 460 : 0.02968854270875454
Loss at iteration 470 : 0.029945598915219307
Loss at iteration 480 : 0.021756790578365326
Loss at iteration 490 : 0.02737114019691944
Loss at iteration 500 : 0.021712850779294968
Loss at iteration 510 : 0.01619967445731163
Loss at iteration 520 : 0.047693461179733276
Loss at iteration 530 : 0.02854975499212742
Loss at iteration 540 : 0.03903481364250183
Loss at iteration 550 : 0.032837554812431335
Loss at iteration 560 : 0.020441533997654915
Loss at iteration 570 : 0.027309121564030647
Loss at iteration 580 : 0.013385357335209846
Loss at iteration 590 : 0.03292666748166084
Loss at iteration 600 : 0.02888309583067894
Loss at iteration 610 : 0.03068215772509575
Loss at iteration 620 : 0.042622730135917664
Loss at iteration 630 : 0.02565436065196991
Loss at iteration 640 : 0.032134950160980225
Loss at iteration 650 : 0.02115245908498764
Loss at iteration 660 : 0.022642511874437332
Loss at iteration 670 : 0.020661357790231705
Loss at iteration 680 : 0.030913840979337692
Loss at iteration 690 : 0.04742132127285004
Loss at iteration 700 : 0.028598986566066742
Loss at iteration 710 : 0.027750708162784576
Loss at iteration 720 : 0.025462180376052856
Loss at iteration 730 : 0.03727813437581062
Loss at iteration 740 : 0.02705225721001625
Loss at iteration 750 : 0.033621884882450104
Loss at iteration 760 : 0.02140718139708042
Loss at iteration 770 : 0.03930017352104187
Loss at iteration 780 : 0.03970074653625488
Loss at iteration 790 : 0.025663301348686218
Loss at iteration 800 : 0.030109835788607597
Loss at iteration 810 : 0.019497988745570183
Loss at iteration 820 : 0.024597179144620895
Loss at iteration 830 : 0.03755766153335571
Loss at iteration 840 : 0.03179711848497391
Loss at iteration 850 : 0.022125788033008575
Loss at iteration 860 : 0.015606909990310669
Loss at iteration 870 : 0.028635382652282715
Loss at iteration 880 : 0.02432769164443016
Loss at iteration 890 : 0.01611175201833248
Loss at iteration 900 : 0.020117836073040962
Loss at iteration 910 : 0.030959105119109154
Loss at iteration 920 : 0.03249066323041916
Loss at iteration 930 : 0.0224747397005558
Loss at iteration 940 : 0.028383854776620865
Loss at iteration 950 : 0.026486776769161224
Loss at iteration 960 : 0.022823646664619446
Loss at iteration 970 : 0.02030165307223797
Loss at iteration 980 : 0.031911302357912064
Loss at iteration 990 : 0.02016431838274002
Loss at iteration 1000 : 0.018714845180511475
Loss at iteration 1010 : 0.05000940337777138
Loss at iteration 1020 : 0.02375701442360878
Loss at iteration 1030 : 0.030339200049638748
Loss at iteration 1040 : 0.026591453701257706
Loss at iteration 1050 : 0.03576037660241127
Loss at iteration 1060 : 0.039663515985012054
Loss at iteration 1070 : 0.03999725729227066
Loss at iteration 1080 : 0.028846466913819313
Loss at iteration 1090 : 0.038348667323589325
Loss at iteration 1100 : 0.03805909305810928
Loss at iteration 1110 : 0.041985124349594116
Loss at iteration 1120 : 0.028682908043265343
Loss at iteration 1130 : 0.020061442628502846
Loss at iteration 1140 : 0.018489383161067963
Loss at iteration 1150 : 0.02366362139582634
Loss at iteration 1160 : 0.035336658358573914
Loss at iteration 1170 : 0.02278623729944229
Loss at iteration 1180 : 0.04098096489906311
Loss at iteration 1190 : 0.03674396127462387
Loss at iteration 1200 : 0.02175520360469818
Loss at iteration 1210 : 0.021508442237973213
The SSIM Value is: 0.7608556707700094
The PSNR Value is: 18.035440254211426
the highest SSIM value is: 18.035440254211426
the epoch is: 7
Loss at iteration 10 : 0.016200926154851913
Loss at iteration 20 : 0.028007399290800095
Loss at iteration 30 : 0.034559912979602814
Loss at iteration 40 : 0.03052244894206524
Loss at iteration 50 : 0.02076619490981102
Loss at iteration 60 : 0.030278077349066734
Loss at iteration 70 : 0.02502022683620453
Loss at iteration 80 : 0.04754999652504921
Loss at iteration 90 : 0.022757895290851593
Loss at iteration 100 : 0.0353567898273468
Loss at iteration 110 : 0.026102716103196144
Loss at iteration 120 : 0.034154411405324936
Loss at iteration 130 : 0.031882256269454956
Loss at iteration 140 : 0.027081677690148354
Loss at iteration 150 : 0.030009083449840546
Loss at iteration 160 : 0.02712927758693695
Loss at iteration 170 : 0.03354538232088089
Loss at iteration 180 : 0.03492891788482666
Loss at iteration 190 : 0.03263331204652786
Loss at iteration 200 : 0.02973349764943123
Loss at iteration 210 : 0.025572875514626503
Loss at iteration 220 : 0.024736495688557625
Loss at iteration 230 : 0.031314022839069366
Loss at iteration 240 : 0.03143857792019844
Loss at iteration 250 : 0.04033564031124115
Loss at iteration 260 : 0.03314308449625969
Loss at iteration 270 : 0.030178839340806007
Loss at iteration 280 : 0.025437863543629646
Loss at iteration 290 : 0.035755742341279984
Loss at iteration 300 : 0.02913440763950348
Loss at iteration 310 : 0.021975908428430557
Loss at iteration 320 : 0.025155048817396164
Loss at iteration 330 : 0.02512814849615097
Loss at iteration 340 : 0.04378480464220047
Loss at iteration 350 : 0.03555051237344742
Loss at iteration 360 : 0.027578076347708702
Loss at iteration 370 : 0.018744757398962975
Loss at iteration 380 : 0.02928636223077774
Loss at iteration 390 : 0.03166515380144119
Loss at iteration 400 : 0.026846420019865036
Loss at iteration 410 : 0.019925253465771675
Loss at iteration 420 : 0.02322765626013279
Loss at iteration 430 : 0.0330270379781723
Loss at iteration 440 : 0.03923601284623146
Loss at iteration 450 : 0.03274267166852951
Loss at iteration 460 : 0.018585842102766037
Loss at iteration 470 : 0.018435200676321983
Loss at iteration 480 : 0.034013450145721436
Loss at iteration 490 : 0.030524782836437225
Loss at iteration 500 : 0.025781996548175812
Loss at iteration 510 : 0.03719650208950043
Loss at iteration 520 : 0.03607577830553055
Loss at iteration 530 : 0.02600136399269104
Loss at iteration 540 : 0.03305146098136902
Loss at iteration 550 : 0.035945288836956024
Loss at iteration 560 : 0.031599074602127075
Loss at iteration 570 : 0.018288185819983482
Loss at iteration 580 : 0.03966715931892395
Loss at iteration 590 : 0.026938963681459427
Loss at iteration 600 : 0.022725965827703476
Loss at iteration 610 : 0.036421969532966614
Loss at iteration 620 : 0.021048512309789658
Loss at iteration 630 : 0.026540398597717285
Loss at iteration 640 : 0.03356313332915306
Loss at iteration 650 : 0.02613002248108387
Loss at iteration 660 : 0.033050380647182465
Loss at iteration 670 : 0.020845267921686172
Loss at iteration 680 : 0.023191101849079132
Loss at iteration 690 : 0.0351003035902977
Loss at iteration 700 : 0.029251933097839355
Loss at iteration 710 : 0.038048699498176575
Loss at iteration 720 : 0.02161891758441925
Loss at iteration 730 : 0.03325929492712021
Loss at iteration 740 : 0.03288388252258301
Loss at iteration 750 : 0.03032691404223442
Loss at iteration 760 : 0.03133821487426758
Loss at iteration 770 : 0.025525113567709923
Loss at iteration 780 : 0.01764688268303871
Loss at iteration 790 : 0.030700815841555595
Loss at iteration 800 : 0.03655778616666794
Loss at iteration 810 : 0.04871870204806328
Loss at iteration 820 : 0.03241579607129097
Loss at iteration 830 : 0.024693667888641357
Loss at iteration 840 : 0.03859851136803627
Loss at iteration 850 : 0.034765128046274185
Loss at iteration 860 : 0.023247823119163513
Loss at iteration 870 : 0.0290447399020195
Loss at iteration 880 : 0.03011384978890419
Loss at iteration 890 : 0.03069119341671467
Loss at iteration 900 : 0.018868040293455124
Loss at iteration 910 : 0.03195960074663162
Loss at iteration 920 : 0.033066991716623306
Loss at iteration 930 : 0.015523158013820648
Loss at iteration 940 : 0.03168434649705887
Loss at iteration 950 : 0.023933392018079758
Loss at iteration 960 : 0.04054124653339386
Loss at iteration 970 : 0.019123408943414688
Loss at iteration 980 : 0.03309488296508789
Loss at iteration 990 : 0.026469964534044266
Loss at iteration 1000 : 0.029439054429531097
Loss at iteration 1010 : 0.03788407891988754
Loss at iteration 1020 : 0.03490570932626724
Loss at iteration 1030 : 0.04382834583520889
Loss at iteration 1040 : 0.043979838490486145
Loss at iteration 1050 : 0.02674388512969017
Loss at iteration 1060 : 0.027432426810264587
Loss at iteration 1070 : 0.026712341234087944
Loss at iteration 1080 : 0.024595707654953003
Loss at iteration 1090 : 0.025362249463796616
Loss at iteration 1100 : 0.011243235319852829
Loss at iteration 1110 : 0.026005879044532776
Loss at iteration 1120 : 0.017795264720916748
Loss at iteration 1130 : 0.02415759488940239
Loss at iteration 1140 : 0.038354936987161636
Loss at iteration 1150 : 0.029061077162623405
Loss at iteration 1160 : 0.029822248965501785
Loss at iteration 1170 : 0.02558954246342182
Loss at iteration 1180 : 0.02852529287338257
Loss at iteration 1190 : 0.03169373422861099
Loss at iteration 1200 : 0.013460989110171795
Loss at iteration 1210 : 0.023071210831403732
The SSIM Value is: 0.7564881483713786
The PSNR Value is: 18.267851956685384
the highest SSIM value is: 18.267851956685384
the epoch is: 8
Loss at iteration 10 : 0.03273370489478111
Loss at iteration 20 : 0.029655056074261665
Loss at iteration 30 : 0.023253239691257477
Loss at iteration 40 : 0.027363773435354233
Loss at iteration 50 : 0.02223394438624382
Loss at iteration 60 : 0.025854431092739105
Loss at iteration 70 : 0.03472384437918663
Loss at iteration 80 : 0.025148514658212662
Loss at iteration 90 : 0.02471233159303665
Loss at iteration 100 : 0.03707434982061386
Loss at iteration 110 : 0.02995489537715912
Loss at iteration 120 : 0.04076644033193588
Loss at iteration 130 : 0.02299502119421959
Loss at iteration 140 : 0.024706494063138962
Loss at iteration 150 : 0.01498502679169178
Loss at iteration 160 : 0.02359323762357235
Loss at iteration 170 : 0.0289340540766716
Loss at iteration 180 : 0.024456363171339035
Loss at iteration 190 : 0.03850816935300827
Loss at iteration 200 : 0.0346498116850853
Loss at iteration 210 : 0.052420176565647125
Loss at iteration 220 : 0.024490967392921448
Loss at iteration 230 : 0.016689304262399673
Loss at iteration 240 : 0.041929394006729126
Loss at iteration 250 : 0.033177778124809265
Loss at iteration 260 : 0.02131546102464199
Loss at iteration 270 : 0.021191060543060303
Loss at iteration 280 : 0.051939405500888824
Loss at iteration 290 : 0.029000909999012947
Loss at iteration 300 : 0.04213280975818634
Loss at iteration 310 : 0.01800098642706871
Loss at iteration 320 : 0.02837083302438259
Loss at iteration 330 : 0.022449582815170288
Loss at iteration 340 : 0.03286786004900932
Loss at iteration 350 : 0.032176677137613297
Loss at iteration 360 : 0.032290685921907425
Loss at iteration 370 : 0.030900876969099045
Loss at iteration 380 : 0.040618281811475754
Loss at iteration 390 : 0.021216439083218575
Loss at iteration 400 : 0.021788660436868668
Loss at iteration 410 : 0.04402013123035431
Loss at iteration 420 : 0.019125500693917274
Loss at iteration 430 : 0.0366925373673439
Loss at iteration 440 : 0.03697451949119568
Loss at iteration 450 : 0.025620754808187485
Loss at iteration 460 : 0.024065285921096802
Loss at iteration 470 : 0.03920717164874077
Loss at iteration 480 : 0.028736429288983345
Loss at iteration 490 : 0.02634717896580696
Loss at iteration 500 : 0.02376660332083702
Loss at iteration 510 : 0.018993832170963287
Loss at iteration 520 : 0.020142316818237305
Loss at iteration 530 : 0.027286235243082047
Loss at iteration 540 : 0.02173120714724064
Loss at iteration 550 : 0.038870397955179214
Loss at iteration 560 : 0.025456596165895462
Loss at iteration 570 : 0.022163329645991325
Loss at iteration 580 : 0.03213411942124367
Loss at iteration 590 : 0.037092503160238266
Loss at iteration 600 : 0.035095810890197754
Loss at iteration 610 : 0.0521550178527832
Loss at iteration 620 : 0.03127964586019516
Loss at iteration 630 : 0.017457827925682068
Loss at iteration 640 : 0.024257197976112366
Loss at iteration 650 : 0.025589054450392723
Loss at iteration 660 : 0.034238316118717194
Loss at iteration 670 : 0.04071091488003731
Loss at iteration 680 : 0.033184655010700226
Loss at iteration 690 : 0.024795658886432648
Loss at iteration 700 : 0.031520307064056396
Loss at iteration 710 : 0.03009634092450142
Loss at iteration 720 : 0.021840132772922516
Loss at iteration 730 : 0.02585076354444027
Loss at iteration 740 : 0.027019303292036057
Loss at iteration 750 : 0.027738524600863457
Loss at iteration 760 : 0.017976833507418633
Loss at iteration 770 : 0.034529443830251694
Loss at iteration 780 : 0.0267792958766222
Loss at iteration 790 : 0.03084293007850647
Loss at iteration 800 : 0.01850200444459915
Loss at iteration 810 : 0.025641361251473427
Loss at iteration 820 : 0.035638101398944855
Loss at iteration 830 : 0.019973112270236015
Loss at iteration 840 : 0.025780946016311646
Loss at iteration 850 : 0.01700674369931221
Loss at iteration 860 : 0.011443677358329296
Loss at iteration 870 : 0.03938327729701996
Loss at iteration 880 : 0.02424158714711666
Loss at iteration 890 : 0.0259721539914608
Loss at iteration 900 : 0.01210595853626728
Loss at iteration 910 : 0.03535914421081543
Loss at iteration 920 : 0.032136667519807816
Loss at iteration 930 : 0.02895241603255272
Loss at iteration 940 : 0.023381253704428673
Loss at iteration 950 : 0.029706686735153198
Loss at iteration 960 : 0.035478055477142334
Loss at iteration 970 : 0.03218146413564682
Loss at iteration 980 : 0.02152533456683159
Loss at iteration 990 : 0.028138581663370132
Loss at iteration 1000 : 0.026876285672187805
Loss at iteration 1010 : 0.01843823492527008
Loss at iteration 1020 : 0.045890942215919495
Loss at iteration 1030 : 0.024383818730711937
Loss at iteration 1040 : 0.033374689519405365
Loss at iteration 1050 : 0.01687811315059662
Loss at iteration 1060 : 0.020362380892038345
Loss at iteration 1070 : 0.023465029895305634
Loss at iteration 1080 : 0.026507040485739708
Loss at iteration 1090 : 0.015984434634447098
Loss at iteration 1100 : 0.025159582495689392
Loss at iteration 1110 : 0.02450709231197834
Loss at iteration 1120 : 0.03438001871109009
Loss at iteration 1130 : 0.03417127579450607
Loss at iteration 1140 : 0.022321393713355064
Loss at iteration 1150 : 0.02337101846933365
Loss at iteration 1160 : 0.037484098225831985
Loss at iteration 1170 : 0.03658324480056763
Loss at iteration 1180 : 0.04230283945798874
Loss at iteration 1190 : 0.029101338237524033
Loss at iteration 1200 : 0.02477634884417057
Loss at iteration 1210 : 0.03391874581575394
The SSIM Value is: 0.7627438584963481
The PSNR Value is: 17.957327715555827
the epoch is: 9
Loss at iteration 10 : 0.021203013136982918
Loss at iteration 20 : 0.0380328968167305
Loss at iteration 30 : 0.026737889274954796
Loss at iteration 40 : 0.029751047492027283
Loss at iteration 50 : 0.02599884569644928
Loss at iteration 60 : 0.03287496417760849
Loss at iteration 70 : 0.02936609461903572
Loss at iteration 80 : 0.032675597816705704
Loss at iteration 90 : 0.028131214901804924
Loss at iteration 100 : 0.03057391755282879
Loss at iteration 110 : 0.026674367487430573
Loss at iteration 120 : 0.026948023587465286
Loss at iteration 130 : 0.02473229169845581
Loss at iteration 140 : 0.029701344668865204
Loss at iteration 150 : 0.03783143311738968
Loss at iteration 160 : 0.019125962629914284
Loss at iteration 170 : 0.05570088326931
Loss at iteration 180 : 0.041543491184711456
Loss at iteration 190 : 0.02284727245569229
Loss at iteration 200 : 0.03163442760705948
Loss at iteration 210 : 0.01789800636470318
Loss at iteration 220 : 0.027868688106536865
Loss at iteration 230 : 0.029074961319565773
Loss at iteration 240 : 0.0395369715988636
Loss at iteration 250 : 0.02678946778178215
Loss at iteration 260 : 0.03129001334309578
Loss at iteration 270 : 0.019837908446788788
Loss at iteration 280 : 0.015642231330275536
Loss at iteration 290 : 0.021426118910312653
Loss at iteration 300 : 0.021906768903136253
Loss at iteration 310 : 0.028158672153949738
Loss at iteration 320 : 0.028659552335739136
Loss at iteration 330 : 0.033756449818611145
Loss at iteration 340 : 0.022304106503725052
Loss at iteration 350 : 0.029433155432343483
Loss at iteration 360 : 0.024510901421308517
Loss at iteration 370 : 0.0336463525891304
Loss at iteration 380 : 0.025369323790073395
Loss at iteration 390 : 0.03800754249095917
Loss at iteration 400 : 0.02942538820207119
Loss at iteration 410 : 0.038745101541280746
Loss at iteration 420 : 0.02045278809964657
Loss at iteration 430 : 0.03196614235639572
Loss at iteration 440 : 0.027742693200707436
Loss at iteration 450 : 0.03753962367773056
Loss at iteration 460 : 0.02237587235867977
Loss at iteration 470 : 0.01941431313753128
Loss at iteration 480 : 0.03137095272541046
Loss at iteration 490 : 0.03269834816455841
Loss at iteration 500 : 0.029094096273183823
Loss at iteration 510 : 0.028194939717650414
Loss at iteration 520 : 0.03614283725619316
Loss at iteration 530 : 0.0362752228975296
Loss at iteration 540 : 0.03392646461725235
Loss at iteration 550 : 0.03604981303215027
Loss at iteration 560 : 0.037449244409799576
Loss at iteration 570 : 0.030476588755846024
Loss at iteration 580 : 0.02548067457973957
Loss at iteration 590 : 0.030977848917245865
Loss at iteration 600 : 0.0234423466026783
Loss at iteration 610 : 0.019455349072813988
Loss at iteration 620 : 0.028624605387449265
Loss at iteration 630 : 0.025086484849452972
Loss at iteration 640 : 0.02417638897895813
Loss at iteration 650 : 0.025349903851747513
Loss at iteration 660 : 0.022542160004377365
Loss at iteration 670 : 0.017855629324913025
Loss at iteration 680 : 0.022352274507284164
Loss at iteration 690 : 0.017260942608118057
Loss at iteration 700 : 0.01918976567685604
Loss at iteration 710 : 0.027587851509451866
Loss at iteration 720 : 0.02757474221289158
Loss at iteration 730 : 0.02576637826859951
Loss at iteration 740 : 0.01746010035276413
Loss at iteration 750 : 0.03218579664826393
Loss at iteration 760 : 0.03136972337961197
Loss at iteration 770 : 0.0351782888174057
Loss at iteration 780 : 0.018133200705051422
Loss at iteration 790 : 0.02159903384745121
Loss at iteration 800 : 0.038714997470378876
Loss at iteration 810 : 0.034777551889419556
Loss at iteration 820 : 0.01894979551434517
Loss at iteration 830 : 0.023691389709711075
Loss at iteration 840 : 0.04188928008079529
Loss at iteration 850 : 0.034537505358457565
Loss at iteration 860 : 0.024135805666446686
Loss at iteration 870 : 0.03292910009622574
Loss at iteration 880 : 0.023604372516274452
Loss at iteration 890 : 0.028239134699106216
Loss at iteration 900 : 0.026823583990335464
Loss at iteration 910 : 0.02815196104347706
Loss at iteration 920 : 0.03389978036284447
Loss at iteration 930 : 0.02693825401365757
Loss at iteration 940 : 0.02658357098698616
Loss at iteration 950 : 0.02982594259083271
Loss at iteration 960 : 0.021498199552297592
Loss at iteration 970 : 0.03924836218357086
Loss at iteration 980 : 0.04539985954761505
Loss at iteration 990 : 0.02625429816544056
Loss at iteration 1000 : 0.01553699467331171
Loss at iteration 1010 : 0.03729897737503052
Loss at iteration 1020 : 0.03392637521028519
Loss at iteration 1030 : 0.019204415380954742
Loss at iteration 1040 : 0.023337244987487793
Loss at iteration 1050 : 0.02915850654244423
Loss at iteration 1060 : 0.027891622856259346
Loss at iteration 1070 : 0.027732213959097862
Loss at iteration 1080 : 0.03212086856365204
Loss at iteration 1090 : 0.02783331274986267
Loss at iteration 1100 : 0.024013184010982513
Loss at iteration 1110 : 0.030368473380804062
Loss at iteration 1120 : 0.028627697378396988
Loss at iteration 1130 : 0.04062564671039581
Loss at iteration 1140 : 0.025474047288298607
Loss at iteration 1150 : 0.02172250486910343
Loss at iteration 1160 : 0.016865544021129608
Loss at iteration 1170 : 0.0200762078166008
Loss at iteration 1180 : 0.04957876354455948
Loss at iteration 1190 : 0.025387708097696304
Loss at iteration 1200 : 0.020021479576826096
Loss at iteration 1210 : 0.027066202834248543
The SSIM Value is: 0.7591063857078553
The PSNR Value is: 17.82957585652669
the epoch is: 10
Loss at iteration 10 : 0.020540080964565277
Loss at iteration 20 : 0.0322282537817955
Loss at iteration 30 : 0.025498870760202408
Loss at iteration 40 : 0.021290626376867294
Loss at iteration 50 : 0.01978492923080921
Loss at iteration 60 : 0.03504307568073273
Loss at iteration 70 : 0.0329873263835907
Loss at iteration 80 : 0.026400655508041382
Loss at iteration 90 : 0.027733229100704193
Loss at iteration 100 : 0.029418999329209328
Loss at iteration 110 : 0.02463950589299202
Loss at iteration 120 : 0.026474924758076668
Loss at iteration 130 : 0.027670614421367645
Loss at iteration 140 : 0.01872275397181511
Loss at iteration 150 : 0.029217274859547615
Loss at iteration 160 : 0.02657533623278141
Loss at iteration 170 : 0.032078687101602554
Loss at iteration 180 : 0.025554519146680832
Loss at iteration 190 : 0.01969059184193611
Loss at iteration 200 : 0.02664327248930931
Loss at iteration 210 : 0.03974858671426773
Loss at iteration 220 : 0.025992590934038162
Loss at iteration 230 : 0.0395849384367466
Loss at iteration 240 : 0.026880063116550446
Loss at iteration 250 : 0.02375875599682331
Loss at iteration 260 : 0.016003195196390152
Loss at iteration 270 : 0.023245323449373245
Loss at iteration 280 : 0.043833617120981216
Loss at iteration 290 : 0.030558455735445023
Loss at iteration 300 : 0.026228055357933044
Loss at iteration 310 : 0.02940688282251358
Loss at iteration 320 : 0.018382348120212555
Loss at iteration 330 : 0.02003348432481289
Loss at iteration 340 : 0.03839663043618202
Loss at iteration 350 : 0.02926991879940033
Loss at iteration 360 : 0.024441398680210114
Loss at iteration 370 : 0.02233682945370674
Loss at iteration 380 : 0.025212787091732025
Loss at iteration 390 : 0.024645566940307617
Loss at iteration 400 : 0.027650274336338043
Loss at iteration 410 : 0.018652882426977158
Loss at iteration 420 : 0.022388989105820656
Loss at iteration 430 : 0.030654150992631912
Loss at iteration 440 : 0.03201769292354584
Loss at iteration 450 : 0.03702265024185181
Loss at iteration 460 : 0.02379559725522995
Loss at iteration 470 : 0.022823236882686615
Loss at iteration 480 : 0.029129276052117348
Loss at iteration 490 : 0.023335451260209084
Loss at iteration 500 : 0.034681402146816254
Loss at iteration 510 : 0.03134763240814209
Loss at iteration 520 : 0.026066113263368607
Loss at iteration 530 : 0.028554901480674744
Loss at iteration 540 : 0.025471564382314682
Loss at iteration 550 : 0.026850931346416473
Loss at iteration 560 : 0.030884651467204094
Loss at iteration 570 : 0.030600136145949364
Loss at iteration 580 : 0.023810317739844322
Loss at iteration 590 : 0.029584499076008797
Loss at iteration 600 : 0.037104129791259766
Loss at iteration 610 : 0.023088615387678146
Loss at iteration 620 : 0.02424323558807373
Loss at iteration 630 : 0.03349689394235611
Loss at iteration 640 : 0.024454236030578613
Loss at iteration 650 : 0.0359744131565094
Loss at iteration 660 : 0.05200963094830513
Loss at iteration 670 : 0.028804879635572433
Loss at iteration 680 : 0.027131181210279465
Loss at iteration 690 : 0.037440165877342224
Loss at iteration 700 : 0.030025020241737366
Loss at iteration 710 : 0.03008154407143593
Loss at iteration 720 : 0.025540657341480255
Loss at iteration 730 : 0.02524084970355034
Loss at iteration 740 : 0.029508909210562706
Loss at iteration 750 : 0.02812368795275688
Loss at iteration 760 : 0.03305738419294357
Loss at iteration 770 : 0.03331737220287323
Loss at iteration 780 : 0.034211818128824234
Loss at iteration 790 : 0.04368751868605614
Loss at iteration 800 : 0.02530677244067192
Loss at iteration 810 : 0.03216568008065224
Loss at iteration 820 : 0.030103225260972977
Loss at iteration 830 : 0.031082630157470703
Loss at iteration 840 : 0.039272136986255646
Loss at iteration 850 : 0.02844124101102352
Loss at iteration 860 : 0.023907862603664398
Loss at iteration 870 : 0.02817554958164692
Loss at iteration 880 : 0.026394065469503403
Loss at iteration 890 : 0.026128951460123062
Loss at iteration 900 : 0.016705326735973358
Loss at iteration 910 : 0.0361347496509552
Loss at iteration 920 : 0.04289233312010765
Loss at iteration 930 : 0.031131654977798462
Loss at iteration 940 : 0.03956981003284454
Loss at iteration 950 : 0.030887490138411522
Loss at iteration 960 : 0.026960544288158417
Loss at iteration 970 : 0.01457594707608223
Loss at iteration 980 : 0.02165943570435047
Loss at iteration 990 : 0.02984275296330452
Loss at iteration 1000 : 0.02586178295314312
Loss at iteration 1010 : 0.02747936174273491
Loss at iteration 1020 : 0.03088814951479435
Loss at iteration 1030 : 0.0282882172614336
Loss at iteration 1040 : 0.03538186848163605
Loss at iteration 1050 : 0.021467290818691254
Loss at iteration 1060 : 0.020092325285077095
Loss at iteration 1070 : 0.026480091735720634
Loss at iteration 1080 : 0.027165230363607407
Loss at iteration 1090 : 0.03668771684169769
Loss at iteration 1100 : 0.02208578959107399
Loss at iteration 1110 : 0.016311340034008026
Loss at iteration 1120 : 0.024833474308252335
Loss at iteration 1130 : 0.021506911143660545
Loss at iteration 1140 : 0.03130655363202095
Loss at iteration 1150 : 0.026552582159638405
Loss at iteration 1160 : 0.03321249037981033
Loss at iteration 1170 : 0.024829290807247162
Loss at iteration 1180 : 0.019973916932940483
Loss at iteration 1190 : 0.026795335114002228
Loss at iteration 1200 : 0.02872365713119507
Loss at iteration 1210 : 0.02866610698401928
The SSIM Value is: 0.7613408366839091
The PSNR Value is: 17.94159024556478
the epoch is: 11
Loss at iteration 10 : 0.031252793967723846
Loss at iteration 20 : 0.024654319509863853
Loss at iteration 30 : 0.027307704091072083
Loss at iteration 40 : 0.025679931044578552
Loss at iteration 50 : 0.02369319647550583
Loss at iteration 60 : 0.022135693579912186
Loss at iteration 70 : 0.029838621616363525
Loss at iteration 80 : 0.024040495976805687
Loss at iteration 90 : 0.02223522774875164
Loss at iteration 100 : 0.024143505841493607
Loss at iteration 110 : 0.03556463122367859
Loss at iteration 120 : 0.019249875098466873
Loss at iteration 130 : 0.034552473574876785
Loss at iteration 140 : 0.02763643115758896
Loss at iteration 150 : 0.02620593085885048
Loss at iteration 160 : 0.031080545857548714
Loss at iteration 170 : 0.03741394355893135
Loss at iteration 180 : 0.048697248101234436
Loss at iteration 190 : 0.018045973032712936
Loss at iteration 200 : 0.016167139634490013
Loss at iteration 210 : 0.025933459401130676
Loss at iteration 220 : 0.02236188016831875
Loss at iteration 230 : 0.023469939827919006
Loss at iteration 240 : 0.02065047062933445
Loss at iteration 250 : 0.024587787687778473
Loss at iteration 260 : 0.02386230230331421
Loss at iteration 270 : 0.047961294651031494
Loss at iteration 280 : 0.037570491433143616
Loss at iteration 290 : 0.03151950240135193
Loss at iteration 300 : 0.01734611764550209
Loss at iteration 310 : 0.023883236572146416
Loss at iteration 320 : 0.033152174204587936
Loss at iteration 330 : 0.030749380588531494
Loss at iteration 340 : 0.029275083914399147
Loss at iteration 350 : 0.03040948696434498
Loss at iteration 360 : 0.031734541058540344
Loss at iteration 370 : 0.021816283464431763
Loss at iteration 380 : 0.02602328360080719
Loss at iteration 390 : 0.01832178235054016
Loss at iteration 400 : 0.028022926300764084
Loss at iteration 410 : 0.030063755810260773
Loss at iteration 420 : 0.028839007019996643
Loss at iteration 430 : 0.04655275493860245
Loss at iteration 440 : 0.025719301775097847
Loss at iteration 450 : 0.01946345716714859
Loss at iteration 460 : 0.023535974323749542
Loss at iteration 470 : 0.020627837628126144
Loss at iteration 480 : 0.031811706721782684
Loss at iteration 490 : 0.020961087197065353
Loss at iteration 500 : 0.018612604588270187
Loss at iteration 510 : 0.04138129949569702
Loss at iteration 520 : 0.02391722798347473
Loss at iteration 530 : 0.024005960673093796
Loss at iteration 540 : 0.03834270313382149
Loss at iteration 550 : 0.029355701059103012
Loss at iteration 560 : 0.018550848588347435
Loss at iteration 570 : 0.018867963925004005
Loss at iteration 580 : 0.02355155535042286
Loss at iteration 590 : 0.018764130771160126
Loss at iteration 600 : 0.026878029108047485
Loss at iteration 610 : 0.024846365675330162
Loss at iteration 620 : 0.02306363731622696
Loss at iteration 630 : 0.0236318688839674
Loss at iteration 640 : 0.022979365661740303
Loss at iteration 650 : 0.027164440602064133
Loss at iteration 660 : 0.027229011058807373
Loss at iteration 670 : 0.018932141363620758
Loss at iteration 680 : 0.014271019026637077
Loss at iteration 690 : 0.02407114952802658
Loss at iteration 700 : 0.018147116526961327
Loss at iteration 710 : 0.03303733468055725
Loss at iteration 720 : 0.037967387586832047
Loss at iteration 730 : 0.0308365598320961
Loss at iteration 740 : 0.04270384460687637
Loss at iteration 750 : 0.033377207815647125
Loss at iteration 760 : 0.030137712135910988
Loss at iteration 770 : 0.02892715111374855
Loss at iteration 780 : 0.025234345346689224
Loss at iteration 790 : 0.01928982511162758
Loss at iteration 800 : 0.020101454108953476
Loss at iteration 810 : 0.02095617726445198
Loss at iteration 820 : 0.030171111226081848
Loss at iteration 830 : 0.034366730600595474
Loss at iteration 840 : 0.03255914896726608
Loss at iteration 850 : 0.020434919744729996
Loss at iteration 860 : 0.01914079114794731
Loss at iteration 870 : 0.02506541647017002
Loss at iteration 880 : 0.03753060847520828
Loss at iteration 890 : 0.023885507136583328
Loss at iteration 900 : 0.028727702796459198
Loss at iteration 910 : 0.029279863461852074
Loss at iteration 920 : 0.022303324192762375
Loss at iteration 930 : 0.022443201392889023
Loss at iteration 940 : 0.012920325621962547
Loss at iteration 950 : 0.031246749684214592
Loss at iteration 960 : 0.02266116812825203
Loss at iteration 970 : 0.029402945190668106
Loss at iteration 980 : 0.026513703167438507
Loss at iteration 990 : 0.040262870490550995
Loss at iteration 1000 : 0.028472555801272392
Loss at iteration 1010 : 0.022917622700333595
Loss at iteration 1020 : 0.038040466606616974
Loss at iteration 1030 : 0.029243197292089462
Loss at iteration 1040 : 0.03272887319326401
Loss at iteration 1050 : 0.024111097678542137
Loss at iteration 1060 : 0.01902730017900467
Loss at iteration 1070 : 0.03886894881725311
Loss at iteration 1080 : 0.03391002491116524
Loss at iteration 1090 : 0.02541508339345455
Loss at iteration 1100 : 0.028909672051668167
Loss at iteration 1110 : 0.035832781344652176
Loss at iteration 1120 : 0.020776722580194473
Loss at iteration 1130 : 0.021940728649497032
Loss at iteration 1140 : 0.020621413365006447
Loss at iteration 1150 : 0.02567385882139206
Loss at iteration 1160 : 0.02105490118265152
Loss at iteration 1170 : 0.028516048565506935
Loss at iteration 1180 : 0.027147825807332993
Loss at iteration 1190 : 0.037901245057582855
Loss at iteration 1200 : 0.025871314108371735
Loss at iteration 1210 : 0.035024695098400116
The SSIM Value is: 0.7632416288057963
The PSNR Value is: 18.357334264119466
the highest SSIM value is: 18.357334264119466
the epoch is: 12
Loss at iteration 10 : 0.03651250898838043
Loss at iteration 20 : 0.027590766549110413
Loss at iteration 30 : 0.02774115651845932
Loss at iteration 40 : 0.02103647030889988
Loss at iteration 50 : 0.017612367868423462
Loss at iteration 60 : 0.01789879985153675
Loss at iteration 70 : 0.031581174582242966
Loss at iteration 80 : 0.02350405976176262
Loss at iteration 90 : 0.03981402516365051
Loss at iteration 100 : 0.024601474404335022
Loss at iteration 110 : 0.01923649199306965
Loss at iteration 120 : 0.023144053295254707
Loss at iteration 130 : 0.03209979832172394
Loss at iteration 140 : 0.03290203586220741
Loss at iteration 150 : 0.025561515241861343
Loss at iteration 160 : 0.025158239528536797
Loss at iteration 170 : 0.02082415297627449
Loss at iteration 180 : 0.027154570445418358
Loss at iteration 190 : 0.040546715259552
Loss at iteration 200 : 0.020113954320549965
Loss at iteration 210 : 0.02211621031165123
Loss at iteration 220 : 0.03135278820991516
Loss at iteration 230 : 0.026491455733776093
Loss at iteration 240 : 0.03617475926876068
Loss at iteration 250 : 0.022035304456949234
Loss at iteration 260 : 0.03108787350356579
Loss at iteration 270 : 0.03543870896100998
Loss at iteration 280 : 0.021366160362958908
Loss at iteration 290 : 0.03273609280586243
Loss at iteration 300 : 0.018995510414242744
Loss at iteration 310 : 0.028965525329113007
Loss at iteration 320 : 0.022460319101810455
Loss at iteration 330 : 0.01874292455613613
Loss at iteration 340 : 0.042669035494327545
Loss at iteration 350 : 0.02208077162504196
Loss at iteration 360 : 0.019495202228426933
Loss at iteration 370 : 0.02268783189356327
Loss at iteration 380 : 0.026051722466945648
Loss at iteration 390 : 0.02421269379556179
Loss at iteration 400 : 0.027924012392759323
Loss at iteration 410 : 0.01853071339428425
Loss at iteration 420 : 0.022160865366458893
Loss at iteration 430 : 0.031865984201431274
Loss at iteration 440 : 0.03250508010387421
Loss at iteration 450 : 0.022399095818400383
Loss at iteration 460 : 0.02533945068717003
Loss at iteration 470 : 0.02555430494248867
Loss at iteration 480 : 0.021373704075813293
Loss at iteration 490 : 0.027725279331207275
Loss at iteration 500 : 0.03051067888736725
Loss at iteration 510 : 0.019530102610588074
Loss at iteration 520 : 0.027385536581277847
Loss at iteration 530 : 0.06255605816841125
Loss at iteration 540 : 0.0211908258497715
Loss at iteration 550 : 0.035120829939842224
Loss at iteration 560 : 0.036770015954971313
Loss at iteration 570 : 0.026744592934846878
Loss at iteration 580 : 0.05215120688080788
Loss at iteration 590 : 0.03793390095233917
Loss at iteration 600 : 0.027204018086194992
Loss at iteration 610 : 0.03303494304418564
Loss at iteration 620 : 0.02008185163140297
Loss at iteration 630 : 0.03323235362768173
Loss at iteration 640 : 0.028620000928640366
Loss at iteration 650 : 0.03265481814742088
Loss at iteration 660 : 0.03685693442821503
Loss at iteration 670 : 0.031838029623031616
Loss at iteration 680 : 0.05347496643662453
Loss at iteration 690 : 0.02392067015171051
Loss at iteration 700 : 0.033582903444767
Loss at iteration 710 : 0.020221268758177757
Loss at iteration 720 : 0.01526845432817936
Loss at iteration 730 : 0.035817354917526245
Loss at iteration 740 : 0.030265074223279953
Loss at iteration 750 : 0.017821267247200012
Loss at iteration 760 : 0.030495434999465942
Loss at iteration 770 : 0.020359709858894348
Loss at iteration 780 : 0.027188889682292938
Loss at iteration 790 : 0.02726890705525875
Loss at iteration 800 : 0.028594322502613068
Loss at iteration 810 : 0.018789254128932953
Loss at iteration 820 : 0.028632551431655884
Loss at iteration 830 : 0.022409554570913315
Loss at iteration 840 : 0.023117223754525185
Loss at iteration 850 : 0.033488184213638306
Loss at iteration 860 : 0.03800481557846069
Loss at iteration 870 : 0.022473860532045364
Loss at iteration 880 : 0.0220903679728508
Loss at iteration 890 : 0.026569368317723274
Loss at iteration 900 : 0.03643257915973663
Loss at iteration 910 : 0.025090062990784645
Loss at iteration 920 : 0.030907005071640015
Loss at iteration 930 : 0.03156463801860809
Loss at iteration 940 : 0.018601655960083008
Loss at iteration 950 : 0.034374356269836426
Loss at iteration 960 : 0.02680605836212635
Loss at iteration 970 : 0.03659220039844513
Loss at iteration 980 : 0.024887405335903168
Loss at iteration 990 : 0.03654256835579872
Loss at iteration 1000 : 0.023383334279060364
Loss at iteration 1010 : 0.026402991265058517
Loss at iteration 1020 : 0.034295760095119476
Loss at iteration 1030 : 0.04771118611097336
Loss at iteration 1040 : 0.0394786074757576
Loss at iteration 1050 : 0.021730326116085052
Loss at iteration 1060 : 0.028878994286060333
Loss at iteration 1070 : 0.031672924757003784
Loss at iteration 1080 : 0.029158087447285652
Loss at iteration 1090 : 0.036444567143917084
Loss at iteration 1100 : 0.02737250179052353
Loss at iteration 1110 : 0.026587728410959244
Loss at iteration 1120 : 0.03725442290306091
Loss at iteration 1130 : 0.03504638746380806
Loss at iteration 1140 : 0.023481719195842743
Loss at iteration 1150 : 0.02118486724793911
Loss at iteration 1160 : 0.023454129695892334
Loss at iteration 1170 : 0.031094981357455254
Loss at iteration 1180 : 0.030000314116477966
Loss at iteration 1190 : 0.03138776868581772
Loss at iteration 1200 : 0.01715935580432415
Loss at iteration 1210 : 0.02952207624912262
The SSIM Value is: 0.7600637674331665
The PSNR Value is: 18.03920529683431
the epoch is: 13
Loss at iteration 10 : 0.028295621275901794
Loss at iteration 20 : 0.025854863226413727
Loss at iteration 30 : 0.02834789827466011
Loss at iteration 40 : 0.026851333677768707
Loss at iteration 50 : 0.03057650476694107
Loss at iteration 60 : 0.04599856585264206
Loss at iteration 70 : 0.035103701055049896
Loss at iteration 80 : 0.02498195692896843
Loss at iteration 90 : 0.022371113300323486
Loss at iteration 100 : 0.036325011402368546
Loss at iteration 110 : 0.028342753648757935
Loss at iteration 120 : 0.027284225448966026
Loss at iteration 130 : 0.0277651809155941
Loss at iteration 140 : 0.024561427533626556
Loss at iteration 150 : 0.027444932609796524
Loss at iteration 160 : 0.036381274461746216
Loss at iteration 170 : 0.014608027413487434
Loss at iteration 180 : 0.05206313356757164
Loss at iteration 190 : 0.02098480612039566
Loss at iteration 200 : 0.03455553576350212
Loss at iteration 210 : 0.027119647711515427
Loss at iteration 220 : 0.027904687449336052
Loss at iteration 230 : 0.049952905625104904
Loss at iteration 240 : 0.036031052470207214
Loss at iteration 250 : 0.02880573831498623
Loss at iteration 260 : 0.027094682678580284
Loss at iteration 270 : 0.029042376205325127
Loss at iteration 280 : 0.02824004366993904
Loss at iteration 290 : 0.024184785783290863
Loss at iteration 300 : 0.014788789674639702
Loss at iteration 310 : 0.033283933997154236
Loss at iteration 320 : 0.04160822182893753
Loss at iteration 330 : 0.021194301545619965
Loss at iteration 340 : 0.04556269943714142
Loss at iteration 350 : 0.01692933589220047
Loss at iteration 360 : 0.025939349085092545
Loss at iteration 370 : 0.038362037390470505
Loss at iteration 380 : 0.020657870918512344
Loss at iteration 390 : 0.013787792064249516
Loss at iteration 400 : 0.029589738696813583
Loss at iteration 410 : 0.03217402845621109
Loss at iteration 420 : 0.012534817680716515
Loss at iteration 430 : 0.02321738749742508
Loss at iteration 440 : 0.023924212902784348
Loss at iteration 450 : 0.021746095269918442
Loss at iteration 460 : 0.035352639853954315
Loss at iteration 470 : 0.017798088490962982
Loss at iteration 480 : 0.027422741055488586
Loss at iteration 490 : 0.02056712843477726
Loss at iteration 500 : 0.03269053250551224
Loss at iteration 510 : 0.013952691107988358
Loss at iteration 520 : 0.03433447331190109
Loss at iteration 530 : 0.019177574664354324
Loss at iteration 540 : 0.034620363265275955
Loss at iteration 550 : 0.01806194707751274
Loss at iteration 560 : 0.03924761712551117
Loss at iteration 570 : 0.02933141402900219
Loss at iteration 580 : 0.019818656146526337
Loss at iteration 590 : 0.02603153884410858
Loss at iteration 600 : 0.02863895334303379
Loss at iteration 610 : 0.032183937728405
Loss at iteration 620 : 0.021754080429673195
Loss at iteration 630 : 0.03740667179226875
Loss at iteration 640 : 0.030119016766548157
Loss at iteration 650 : 0.018571317195892334
Loss at iteration 660 : 0.02546410635113716
Loss at iteration 670 : 0.0264749638736248
Loss at iteration 680 : 0.027657920494675636
Loss at iteration 690 : 0.02237129956483841
Loss at iteration 700 : 0.021715199574828148
Loss at iteration 710 : 0.02206144481897354
Loss at iteration 720 : 0.024075644090771675
Loss at iteration 730 : 0.028749234974384308
Loss at iteration 740 : 0.017719723284244537
Loss at iteration 750 : 0.03918345645070076
Loss at iteration 760 : 0.019523125141859055
Loss at iteration 770 : 0.022479459643363953
Loss at iteration 780 : 0.016031499952077866
Loss at iteration 790 : 0.03037940338253975
Loss at iteration 800 : 0.023161258548498154
Loss at iteration 810 : 0.021858731284737587
Loss at iteration 820 : 0.020453311502933502
Loss at iteration 830 : 0.018178004771471024
Loss at iteration 840 : 0.0294125284999609
Loss at iteration 850 : 0.04051453620195389
Loss at iteration 860 : 0.022139258682727814
Loss at iteration 870 : 0.028560159727931023
Loss at iteration 880 : 0.03506074473261833
Loss at iteration 890 : 0.020159006118774414
Loss at iteration 900 : 0.021383136510849
Loss at iteration 910 : 0.022540315985679626
Loss at iteration 920 : 0.03350897133350372
Loss at iteration 930 : 0.03629040718078613
Loss at iteration 940 : 0.022071341052651405
Loss at iteration 950 : 0.027095451951026917
Loss at iteration 960 : 0.03616442531347275
Loss at iteration 970 : 0.02505442500114441
Loss at iteration 980 : 0.01982513815164566
Loss at iteration 990 : 0.02595611847937107
Loss at iteration 1000 : 0.03641406446695328
Loss at iteration 1010 : 0.02384268492460251
Loss at iteration 1020 : 0.024365246295928955
Loss at iteration 1030 : 0.03415463864803314
Loss at iteration 1040 : 0.024803753942251205
Loss at iteration 1050 : 0.02878955751657486
Loss at iteration 1060 : 0.041942745447158813
Loss at iteration 1070 : 0.02152850478887558
Loss at iteration 1080 : 0.018279999494552612
Loss at iteration 1090 : 0.023458629846572876
Loss at iteration 1100 : 0.024398915469646454
Loss at iteration 1110 : 0.028343094512820244
Loss at iteration 1120 : 0.021081672981381416
Loss at iteration 1130 : 0.019483398646116257
Loss at iteration 1140 : 0.022842414677143097
Loss at iteration 1150 : 0.03569326549768448
Loss at iteration 1160 : 0.022850919514894485
Loss at iteration 1170 : 0.03665350377559662
Loss at iteration 1180 : 0.02717394009232521
Loss at iteration 1190 : 0.02061118371784687
Loss at iteration 1200 : 0.025388171896338463
Loss at iteration 1210 : 0.02954035811126232
The SSIM Value is: 0.7641341924667359
The PSNR Value is: 18.258424441019695
the epoch is: 14
Loss at iteration 10 : 0.021667437627911568
Loss at iteration 20 : 0.02466215379536152
Loss at iteration 30 : 0.025447817519307137
Loss at iteration 40 : 0.023852091282606125
Loss at iteration 50 : 0.013557510450482368
Loss at iteration 60 : 0.02506284974515438
Loss at iteration 70 : 0.03078475408256054
Loss at iteration 80 : 0.028489362448453903
Loss at iteration 90 : 0.024456966668367386
Loss at iteration 100 : 0.020373983308672905
Loss at iteration 110 : 0.032490797340869904
Loss at iteration 120 : 0.02627425268292427
Loss at iteration 130 : 0.028917919844388962
Loss at iteration 140 : 0.022186582908034325
Loss at iteration 150 : 0.034892402589321136
Loss at iteration 160 : 0.02462434209883213
Loss at iteration 170 : 0.01860986463725567
Loss at iteration 180 : 0.01869865506887436
Loss at iteration 190 : 0.029654093086719513
Loss at iteration 200 : 0.034379102289676666
Loss at iteration 210 : 0.02658943645656109
Loss at iteration 220 : 0.02792162448167801
Loss at iteration 230 : 0.015064562670886517
Loss at iteration 240 : 0.025110051035881042
Loss at iteration 250 : 0.03856738656759262
Loss at iteration 260 : 0.03188568353652954
Loss at iteration 270 : 0.02085067145526409
Loss at iteration 280 : 0.023738935589790344
Loss at iteration 290 : 0.025429993867874146
Loss at iteration 300 : 0.029534243047237396
Loss at iteration 310 : 0.05106963962316513
Loss at iteration 320 : 0.01144794188439846
Loss at iteration 330 : 0.02708282321691513
Loss at iteration 340 : 0.02092861756682396
Loss at iteration 350 : 0.029454953968524933
Loss at iteration 360 : 0.021477429196238518
Loss at iteration 370 : 0.0222760159522295
Loss at iteration 380 : 0.045108430087566376
Loss at iteration 390 : 0.02106306329369545
Loss at iteration 400 : 0.04522227495908737
Loss at iteration 410 : 0.036557238548994064
Loss at iteration 420 : 0.03934282809495926
Loss at iteration 430 : 0.018564052879810333
Loss at iteration 440 : 0.013521549291908741
Loss at iteration 450 : 0.030133811756968498
Loss at iteration 460 : 0.042939066886901855
Loss at iteration 470 : 0.025631725788116455
Loss at iteration 480 : 0.030609089881181717
Loss at iteration 490 : 0.042190052568912506
Loss at iteration 500 : 0.020457811653614044
Loss at iteration 510 : 0.0279878880828619
Loss at iteration 520 : 0.03196483105421066
Loss at iteration 530 : 0.03331883251667023
Loss at iteration 540 : 0.026240898296236992
Loss at iteration 550 : 0.03879764303565025
Loss at iteration 560 : 0.03190619498491287
Loss at iteration 570 : 0.027951782569289207
Loss at iteration 580 : 0.034330014139413834
Loss at iteration 590 : 0.034805793315172195
Loss at iteration 600 : 0.030004508793354034
Loss at iteration 610 : 0.03135376423597336
Loss at iteration 620 : 0.036638859659433365
Loss at iteration 630 : 0.05223865807056427
Loss at iteration 640 : 0.02646312117576599
Loss at iteration 650 : 0.02147575281560421
Loss at iteration 660 : 0.024297762662172318
Loss at iteration 670 : 0.03447922319173813
Loss at iteration 680 : 0.02035883069038391
Loss at iteration 690 : 0.028774136677384377
Loss at iteration 700 : 0.01836276613175869
Loss at iteration 710 : 0.018344663083553314
Loss at iteration 720 : 0.02990531548857689
Loss at iteration 730 : 0.02867555245757103
Loss at iteration 740 : 0.02982998825609684
Loss at iteration 750 : 0.03881362825632095
Loss at iteration 760 : 0.031389884650707245
Loss at iteration 770 : 0.03565245121717453
Loss at iteration 780 : 0.027841251343488693
Loss at iteration 790 : 0.01867455244064331
Loss at iteration 800 : 0.0200963094830513
Loss at iteration 810 : 0.02967870607972145
Loss at iteration 820 : 0.03353763744235039
Loss at iteration 830 : 0.022372659295797348
Loss at iteration 840 : 0.042583730071783066
Loss at iteration 850 : 0.04100625962018967
Loss at iteration 860 : 0.028584685176610947
Loss at iteration 870 : 0.02374279499053955
Loss at iteration 880 : 0.031199689954519272
Loss at iteration 890 : 0.030769987031817436
Loss at iteration 900 : 0.020772553980350494
Loss at iteration 910 : 0.02517922781407833
Loss at iteration 920 : 0.026209574192762375
Loss at iteration 930 : 0.02343149110674858
Loss at iteration 940 : 0.028581757098436356
Loss at iteration 950 : 0.023294689133763313
Loss at iteration 960 : 0.031826287508010864
Loss at iteration 970 : 0.031171981245279312
Loss at iteration 980 : 0.020943449810147285
Loss at iteration 990 : 0.03515612334012985
Loss at iteration 1000 : 0.03534357622265816
Loss at iteration 1010 : 0.035549014806747437
Loss at iteration 1020 : 0.035053275525569916
Loss at iteration 1030 : 0.031008867546916008
Loss at iteration 1040 : 0.019522525370121002
Loss at iteration 1050 : 0.02293216809630394
Loss at iteration 1060 : 0.025682678446173668
Loss at iteration 1070 : 0.026474323123693466
Loss at iteration 1080 : 0.019590303301811218
Loss at iteration 1090 : 0.026090919971466064
Loss at iteration 1100 : 0.032994594424963
Loss at iteration 1110 : 0.026809684932231903
Loss at iteration 1120 : 0.039714667946100235
Loss at iteration 1130 : 0.021151388064026833
Loss at iteration 1140 : 0.0160762220621109
Loss at iteration 1150 : 0.0261372122913599
Loss at iteration 1160 : 0.026680005714297295
Loss at iteration 1170 : 0.036504749208688736
Loss at iteration 1180 : 0.030050765722990036
Loss at iteration 1190 : 0.02296360582113266
Loss at iteration 1200 : 0.023174067959189415
Loss at iteration 1210 : 0.024852732196450233
The SSIM Value is: 0.7653737386067708
The PSNR Value is: 18.210398610432943
the epoch is: 15
Loss at iteration 10 : 0.03341830149292946
Loss at iteration 20 : 0.030348964035511017
Loss at iteration 30 : 0.030239945277571678
Loss at iteration 40 : 0.02750565856695175
Loss at iteration 50 : 0.04578770697116852
Loss at iteration 60 : 0.022924546152353287
Loss at iteration 70 : 0.022679511457681656
Loss at iteration 80 : 0.022086629644036293
Loss at iteration 90 : 0.023311825469136238
Loss at iteration 100 : 0.029892463237047195
Loss at iteration 110 : 0.019398026168346405
Loss at iteration 120 : 0.024196241050958633
Loss at iteration 130 : 0.020495600998401642
Loss at iteration 140 : 0.03178977966308594
Loss at iteration 150 : 0.020557040348649025
Loss at iteration 160 : 0.03961506858468056
Loss at iteration 170 : 0.02891445904970169
Loss at iteration 180 : 0.029050961136817932
Loss at iteration 190 : 0.01661275513470173
Loss at iteration 200 : 0.024841628968715668
Loss at iteration 210 : 0.028713803738355637
Loss at iteration 220 : 0.01721220090985298
Loss at iteration 230 : 0.023483561351895332
Loss at iteration 240 : 0.025521403178572655
Loss at iteration 250 : 0.04249843582510948
Loss at iteration 260 : 0.03552919253706932
Loss at iteration 270 : 0.029207123443484306
Loss at iteration 280 : 0.031530532985925674
Loss at iteration 290 : 0.02562011033296585
Loss at iteration 300 : 0.03721038997173309
Loss at iteration 310 : 0.024858281016349792
Loss at iteration 320 : 0.026261422783136368
Loss at iteration 330 : 0.030791569501161575
Loss at iteration 340 : 0.03041369654238224
Loss at iteration 350 : 0.040632545948028564
Loss at iteration 360 : 0.023861201480031013
Loss at iteration 370 : 0.02354753017425537
Loss at iteration 380 : 0.03128700703382492
Loss at iteration 390 : 0.02217707596719265
Loss at iteration 400 : 0.03137725591659546
Loss at iteration 410 : 0.018314490094780922
Loss at iteration 420 : 0.03376094624400139
Loss at iteration 430 : 0.025369565933942795
Loss at iteration 440 : 0.032795339822769165
Loss at iteration 450 : 0.035330772399902344
Loss at iteration 460 : 0.03170119598507881
Loss at iteration 470 : 0.017591945827007294
Loss at iteration 480 : 0.020732158794999123
Loss at iteration 490 : 0.018336493521928787
Loss at iteration 500 : 0.031223569065332413
Loss at iteration 510 : 0.02222527749836445
Loss at iteration 520 : 0.018636006861925125
Loss at iteration 530 : 0.016416005790233612
Loss at iteration 540 : 0.03801839053630829
Loss at iteration 550 : 0.02970668114721775
Loss at iteration 560 : 0.026295332238078117
Loss at iteration 570 : 0.028094910085201263
Loss at iteration 580 : 0.022806307300925255
Loss at iteration 590 : 0.023311171680688858
Loss at iteration 600 : 0.022346138954162598
Loss at iteration 610 : 0.02133176662027836
Loss at iteration 620 : 0.024266082793474197
Loss at iteration 630 : 0.026383932679891586
Loss at iteration 640 : 0.021652471274137497
Loss at iteration 650 : 0.02415449731051922
Loss at iteration 660 : 0.045913200825452805
Loss at iteration 670 : 0.041906874626874924
Loss at iteration 680 : 0.02321544662117958
Loss at iteration 690 : 0.028603218495845795
Loss at iteration 700 : 0.036167170852422714
Loss at iteration 710 : 0.026019789278507233
Loss at iteration 720 : 0.019688047468662262
Loss at iteration 730 : 0.039717454463243484
Loss at iteration 740 : 0.030144603922963142
Loss at iteration 750 : 0.022631343454122543
Loss at iteration 760 : 0.02957109361886978
Loss at iteration 770 : 0.024648549035191536
Loss at iteration 780 : 0.04019365459680557
Loss at iteration 790 : 0.02082638069987297
Loss at iteration 800 : 0.022687118500471115
Loss at iteration 810 : 0.02015274204313755
Loss at iteration 820 : 0.023158766329288483
Loss at iteration 830 : 0.021228937432169914
Loss at iteration 840 : 0.02934340015053749
Loss at iteration 850 : 0.029179349541664124
Loss at iteration 860 : 0.023704402148723602
Loss at iteration 870 : 0.031326934695243835
Loss at iteration 880 : 0.03148379176855087
Loss at iteration 890 : 0.03230573236942291
Loss at iteration 900 : 0.02450532652437687
Loss at iteration 910 : 0.023118730634450912
Loss at iteration 920 : 0.03562022000551224
Loss at iteration 930 : 0.019924219697713852
Loss at iteration 940 : 0.030960407108068466
Loss at iteration 950 : 0.026387840509414673
Loss at iteration 960 : 0.026493282988667488
Loss at iteration 970 : 0.028344791382551193
Loss at iteration 980 : 0.019178535789251328
Loss at iteration 990 : 0.04014253616333008
Loss at iteration 1000 : 0.03162664920091629
Loss at iteration 1010 : 0.01595231145620346
Loss at iteration 1020 : 0.03597982972860336
Loss at iteration 1030 : 0.028788365423679352
Loss at iteration 1040 : 0.014057988300919533
Loss at iteration 1050 : 0.02156318537890911
Loss at iteration 1060 : 0.04366222023963928
Loss at iteration 1070 : 0.02422296814620495
Loss at iteration 1080 : 0.0306643508374691
Loss at iteration 1090 : 0.02704991027712822
Loss at iteration 1100 : 0.025838032364845276
Loss at iteration 1110 : 0.03752463310956955
Loss at iteration 1120 : 0.023862075060606003
Loss at iteration 1130 : 0.025940636172890663
Loss at iteration 1140 : 0.030318792909383774
Loss at iteration 1150 : 0.025164540857076645
Loss at iteration 1160 : 0.024544965475797653
Loss at iteration 1170 : 0.014976541511714458
Loss at iteration 1180 : 0.03178342059254646
Loss at iteration 1190 : 0.0174554530531168
Loss at iteration 1200 : 0.024901846423745155
Loss at iteration 1210 : 0.02028997801244259
The SSIM Value is: 0.764438803990682
The PSNR Value is: 18.06744950612386
the epoch is: 16
Loss at iteration 10 : 0.025965113192796707
Loss at iteration 20 : 0.038737714290618896
Loss at iteration 30 : 0.036162782460451126
Loss at iteration 40 : 0.02329222671687603
Loss at iteration 50 : 0.024892929941415787
Loss at iteration 60 : 0.01896524801850319
Loss at iteration 70 : 0.026781726628541946
Loss at iteration 80 : 0.02073056250810623
Loss at iteration 90 : 0.012161226011812687
Loss at iteration 100 : 0.028772421181201935
Loss at iteration 110 : 0.016491064801812172
Loss at iteration 120 : 0.02299485355615616
Loss at iteration 130 : 0.028696460649371147
Loss at iteration 140 : 0.044121429324150085
Loss at iteration 150 : 0.03026469796895981
Loss at iteration 160 : 0.035109467804431915
Loss at iteration 170 : 0.044001080095767975
Loss at iteration 180 : 0.018908314406871796
Loss at iteration 190 : 0.027769427746534348
Loss at iteration 200 : 0.027231987565755844
Loss at iteration 210 : 0.06139232590794563
Loss at iteration 220 : 0.021155105903744698
Loss at iteration 230 : 0.03346233069896698
Loss at iteration 240 : 0.035844266414642334
Loss at iteration 250 : 0.027876172214746475
Loss at iteration 260 : 0.023175545036792755
Loss at iteration 270 : 0.022520918399095535
Loss at iteration 280 : 0.032191284000873566
Loss at iteration 290 : 0.03836166858673096
Loss at iteration 300 : 0.03402363881468773
Loss at iteration 310 : 0.027804702520370483
Loss at iteration 320 : 0.01816674694418907
Loss at iteration 330 : 0.04404497891664505
Loss at iteration 340 : 0.0228164941072464
Loss at iteration 350 : 0.019528239965438843
Loss at iteration 360 : 0.018007518723607063
Loss at iteration 370 : 0.028533000499010086
Loss at iteration 380 : 0.017859822139143944
Loss at iteration 390 : 0.022643782198429108
Loss at iteration 400 : 0.01964099332690239
Loss at iteration 410 : 0.02786720171570778
Loss at iteration 420 : 0.0369858555495739
Loss at iteration 430 : 0.028382467105984688
Loss at iteration 440 : 0.02647968754172325
Loss at iteration 450 : 0.024822242558002472
Loss at iteration 460 : 0.029523378238081932
Loss at iteration 470 : 0.03143996000289917
Loss at iteration 480 : 0.02073749341070652
Loss at iteration 490 : 0.03137046843767166
Loss at iteration 500 : 0.03320198878645897
Loss at iteration 510 : 0.01977291703224182
Loss at iteration 520 : 0.022025343030691147
Loss at iteration 530 : 0.01960136368870735
Loss at iteration 540 : 0.026936642825603485
Loss at iteration 550 : 0.024266298860311508
Loss at iteration 560 : 0.020568858832120895
Loss at iteration 570 : 0.02236262895166874
Loss at iteration 580 : 0.02215605601668358
Loss at iteration 590 : 0.025450319051742554
Loss at iteration 600 : 0.025302132591605186
Loss at iteration 610 : 0.024481642991304398
Loss at iteration 620 : 0.03259668126702309
Loss at iteration 630 : 0.019601380452513695
Loss at iteration 640 : 0.02956290915608406
Loss at iteration 650 : 0.031317103654146194
Loss at iteration 660 : 0.017865614965558052
Loss at iteration 670 : 0.024661898612976074
Loss at iteration 680 : 0.03612939268350601
Loss at iteration 690 : 0.01957094296813011
Loss at iteration 700 : 0.03060450591146946
Loss at iteration 710 : 0.031705740839242935
Loss at iteration 720 : 0.021177908405661583
Loss at iteration 730 : 0.029337316751480103
Loss at iteration 740 : 0.024508927017450333
Loss at iteration 750 : 0.012762238271534443
Loss at iteration 760 : 0.02291227877140045
Loss at iteration 770 : 0.03527228534221649
Loss at iteration 780 : 0.019196482375264168
Loss at iteration 790 : 0.04027374088764191
Loss at iteration 800 : 0.018819283694028854
Loss at iteration 810 : 0.02411177195608616
Loss at iteration 820 : 0.021727433428168297
Loss at iteration 830 : 0.03438147157430649
Loss at iteration 840 : 0.02266741171479225
Loss at iteration 850 : 0.033291518688201904
Loss at iteration 860 : 0.03698645532131195
Loss at iteration 870 : 0.02022409997880459
Loss at iteration 880 : 0.02027728408575058
Loss at iteration 890 : 0.02888365462422371
Loss at iteration 900 : 0.016512757167220116
Loss at iteration 910 : 0.01986735872924328
Loss at iteration 920 : 0.030620556324720383
Loss at iteration 930 : 0.03003951534628868
Loss at iteration 940 : 0.029580315575003624
Loss at iteration 950 : 0.026580316945910454
Loss at iteration 960 : 0.023108385503292084
Loss at iteration 970 : 0.020761631429195404
Loss at iteration 980 : 0.014272989705204964
Loss at iteration 990 : 0.020556200295686722
Loss at iteration 1000 : 0.038161344826221466
Loss at iteration 1010 : 0.03609269857406616
Loss at iteration 1020 : 0.026733562350273132
Loss at iteration 1030 : 0.027546534314751625
Loss at iteration 1040 : 0.015064319595694542
Loss at iteration 1050 : 0.023427903652191162
Loss at iteration 1060 : 0.016956724226474762
Loss at iteration 1070 : 0.023149535059928894
Loss at iteration 1080 : 0.025864573195576668
Loss at iteration 1090 : 0.029066216200590134
Loss at iteration 1100 : 0.034807316958904266
Loss at iteration 1110 : 0.018452534452080727
Loss at iteration 1120 : 0.02642938867211342
Loss at iteration 1130 : 0.030255571007728577
Loss at iteration 1140 : 0.03812962770462036
Loss at iteration 1150 : 0.02064310386776924
Loss at iteration 1160 : 0.030127502977848053
Loss at iteration 1170 : 0.025120599195361137
Loss at iteration 1180 : 0.020952336490154266
Loss at iteration 1190 : 0.02535349689424038
Loss at iteration 1200 : 0.018962174654006958
Loss at iteration 1210 : 0.023311210796236992
The SSIM Value is: 0.7650441884994507
The PSNR Value is: 18.04967352549235
the epoch is: 17
Loss at iteration 10 : 0.017981762066483498
Loss at iteration 20 : 0.025540873408317566
Loss at iteration 30 : 0.01735527813434601
Loss at iteration 40 : 0.015162216499447823
Loss at iteration 50 : 0.03090851753950119
Loss at iteration 60 : 0.0407867357134819
Loss at iteration 70 : 0.0205717571079731
Loss at iteration 80 : 0.01608610711991787
Loss at iteration 90 : 0.05685887485742569
Loss at iteration 100 : 0.046052396297454834
Loss at iteration 110 : 0.02502266876399517
Loss at iteration 120 : 0.028050431981682777
Loss at iteration 130 : 0.022376105189323425
Loss at iteration 140 : 0.024206405505537987
Loss at iteration 150 : 0.02604076638817787
Loss at iteration 160 : 0.011805917136371136
Loss at iteration 170 : 0.04126373678445816
Loss at iteration 180 : 0.022769877687096596
Loss at iteration 190 : 0.024098340421915054
Loss at iteration 200 : 0.031685031950473785
Loss at iteration 210 : 0.022532954812049866
Loss at iteration 220 : 0.027667827904224396
Loss at iteration 230 : 0.03467932343482971
Loss at iteration 240 : 0.0231691412627697
Loss at iteration 250 : 0.03282232582569122
Loss at iteration 260 : 0.031141702085733414
Loss at iteration 270 : 0.02640957199037075
Loss at iteration 280 : 0.025425583124160767
Loss at iteration 290 : 0.026248827576637268
Loss at iteration 300 : 0.0346207395195961
Loss at iteration 310 : 0.03837200626730919
Loss at iteration 320 : 0.03161638602614403
Loss at iteration 330 : 0.023429039865732193
Loss at iteration 340 : 0.018006853759288788
Loss at iteration 350 : 0.033417146652936935
Loss at iteration 360 : 0.03193513676524162
Loss at iteration 370 : 0.03555624932050705
Loss at iteration 380 : 0.01938701793551445
Loss at iteration 390 : 0.03392047435045242
Loss at iteration 400 : 0.028015214949846268
Loss at iteration 410 : 0.018689926713705063
Loss at iteration 420 : 0.03421878069639206
Loss at iteration 430 : 0.031867481768131256
Loss at iteration 440 : 0.02288157306611538
Loss at iteration 450 : 0.019464703276753426
Loss at iteration 460 : 0.02463250607252121
Loss at iteration 470 : 0.03405021131038666
Loss at iteration 480 : 0.02204803004860878
Loss at iteration 490 : 0.013455611653625965
Loss at iteration 500 : 0.03824932128190994
Loss at iteration 510 : 0.03204311430454254
Loss at iteration 520 : 0.031829774379730225
Loss at iteration 530 : 0.0349399670958519
Loss at iteration 540 : 0.030001992359757423
Loss at iteration 550 : 0.031225310638546944
Loss at iteration 560 : 0.0215282179415226
Loss at iteration 570 : 0.02486518956720829
Loss at iteration 580 : 0.024583155289292336
Loss at iteration 590 : 0.02525792084634304
Loss at iteration 600 : 0.040725164115428925
Loss at iteration 610 : 0.0277304295450449
Loss at iteration 620 : 0.029829418286681175
Loss at iteration 630 : 0.02300190180540085
Loss at iteration 640 : 0.03133440762758255
Loss at iteration 650 : 0.034139905124902725
Loss at iteration 660 : 0.028506701812148094
Loss at iteration 670 : 0.01739950105547905
Loss at iteration 680 : 0.048159159719944
Loss at iteration 690 : 0.04139455407857895
Loss at iteration 700 : 0.04617280513048172
Loss at iteration 710 : 0.01811153069138527
Loss at iteration 720 : 0.02970344014465809
Loss at iteration 730 : 0.024485155940055847
Loss at iteration 740 : 0.01887350343167782
Loss at iteration 750 : 0.020223889499902725
Loss at iteration 760 : 0.04139034450054169
Loss at iteration 770 : 0.034235697239637375
Loss at iteration 780 : 0.03504956513643265
Loss at iteration 790 : 0.019476691260933876
Loss at iteration 800 : 0.01818438060581684
Loss at iteration 810 : 0.02158309519290924
Loss at iteration 820 : 0.02440890483558178
Loss at iteration 830 : 0.02488304302096367
Loss at iteration 840 : 0.02445649914443493
Loss at iteration 850 : 0.019725607708096504
Loss at iteration 860 : 0.023597627878189087
Loss at iteration 870 : 0.038067255169153214
Loss at iteration 880 : 0.03465375304222107
Loss at iteration 890 : 0.025916961953043938
Loss at iteration 900 : 0.018177693709731102
Loss at iteration 910 : 0.02673214301466942
Loss at iteration 920 : 0.020555369555950165
Loss at iteration 930 : 0.022962862625718117
Loss at iteration 940 : 0.011583711951971054
Loss at iteration 950 : 0.039193037897348404
Loss at iteration 960 : 0.023615002632141113
Loss at iteration 970 : 0.029867926612496376
Loss at iteration 980 : 0.018296334892511368
Loss at iteration 990 : 0.028707487508654594
Loss at iteration 1000 : 0.017637670040130615
Loss at iteration 1010 : 0.026660777628421783
Loss at iteration 1020 : 0.03220434486865997
Loss at iteration 1030 : 0.041447825729846954
Loss at iteration 1040 : 0.028202708810567856
Loss at iteration 1050 : 0.03336550295352936
Loss at iteration 1060 : 0.02375764772295952
Loss at iteration 1070 : 0.0276531670242548
Loss at iteration 1080 : 0.031391046941280365
Loss at iteration 1090 : 0.04575309157371521
Loss at iteration 1100 : 0.031135033816099167
Loss at iteration 1110 : 0.02258250117301941
Loss at iteration 1120 : 0.01928500272333622
Loss at iteration 1130 : 0.022807808592915535
Loss at iteration 1140 : 0.026097383350133896
Loss at iteration 1150 : 0.02936115488409996
Loss at iteration 1160 : 0.02482270449399948
Loss at iteration 1170 : 0.040132321417331696
Loss at iteration 1180 : 0.025505583733320236
Loss at iteration 1190 : 0.026917066425085068
Loss at iteration 1200 : 0.01761571876704693
Loss at iteration 1210 : 0.01790769025683403
The SSIM Value is: 0.765891683101654
The PSNR Value is: 18.132152430216472
the epoch is: 18
Loss at iteration 10 : 0.02915840409696102
Loss at iteration 20 : 0.03229308873414993
Loss at iteration 30 : 0.037094976752996445
Loss at iteration 40 : 0.03999907523393631
Loss at iteration 50 : 0.028008919209241867
Loss at iteration 60 : 0.026662804186344147
Loss at iteration 70 : 0.021718740463256836
Loss at iteration 80 : 0.030076317489147186
Loss at iteration 90 : 0.03607691451907158
Loss at iteration 100 : 0.02988615073263645
Loss at iteration 110 : 0.015482466667890549
Loss at iteration 120 : 0.02562810108065605
Loss at iteration 130 : 0.025409694761037827
Loss at iteration 140 : 0.027658335864543915
Loss at iteration 150 : 0.016678832471370697
Loss at iteration 160 : 0.02398395538330078
Loss at iteration 170 : 0.035504329949617386
Loss at iteration 180 : 0.0331818163394928
Loss at iteration 190 : 0.03515176475048065
Loss at iteration 200 : 0.02155052125453949
Loss at iteration 210 : 0.02583274617791176
Loss at iteration 220 : 0.02742171660065651
Loss at iteration 230 : 0.01866389811038971
Loss at iteration 240 : 0.016140740364789963
Loss at iteration 250 : 0.017489299178123474
Loss at iteration 260 : 0.030349908396601677
Loss at iteration 270 : 0.03879286348819733
Loss at iteration 280 : 0.024687808007001877
Loss at iteration 290 : 0.02717285230755806
Loss at iteration 300 : 0.025194520130753517
Loss at iteration 310 : 0.012928486801683903
Loss at iteration 320 : 0.0380886010825634
Loss at iteration 330 : 0.02606618031859398
Loss at iteration 340 : 0.03406620770692825
Loss at iteration 350 : 0.043535251170396805
Loss at iteration 360 : 0.0216053519397974
Loss at iteration 370 : 0.03349284455180168
Loss at iteration 380 : 0.03208811953663826
Loss at iteration 390 : 0.026433264836668968
Loss at iteration 400 : 0.03271157294511795
Loss at iteration 410 : 0.026209140196442604
Loss at iteration 420 : 0.03367815166711807
Loss at iteration 430 : 0.03332293778657913
Loss at iteration 440 : 0.0337756872177124
Loss at iteration 450 : 0.03311946615576744
Loss at iteration 460 : 0.026263417676091194
Loss at iteration 470 : 0.03306432068347931
Loss at iteration 480 : 0.0350712388753891
Loss at iteration 490 : 0.030078981071710587
Loss at iteration 500 : 0.030670350417494774
Loss at iteration 510 : 0.04313679784536362
Loss at iteration 520 : 0.024775702506303787
Loss at iteration 530 : 0.024397332221269608
Loss at iteration 540 : 0.03639819100499153
Loss at iteration 550 : 0.018835105001926422
Loss at iteration 560 : 0.019760683178901672
Loss at iteration 570 : 0.010320044122636318
Loss at iteration 580 : 0.03339196741580963
Loss at iteration 590 : 0.027957089245319366
Loss at iteration 600 : 0.03351325914263725
Loss at iteration 610 : 0.03940560668706894
Loss at iteration 620 : 0.03488682955503464
Loss at iteration 630 : 0.019316265359520912
Loss at iteration 640 : 0.024039382115006447
Loss at iteration 650 : 0.028626583516597748
Loss at iteration 660 : 0.03257123753428459
Loss at iteration 670 : 0.018099743872880936
Loss at iteration 680 : 0.025383800268173218
Loss at iteration 690 : 0.023892994970083237
Loss at iteration 700 : 0.03058590739965439
Loss at iteration 710 : 0.02164841815829277
Loss at iteration 720 : 0.029550351202487946
Loss at iteration 730 : 0.020199347287416458
Loss at iteration 740 : 0.016314959153532982
Loss at iteration 750 : 0.03127983212471008
Loss at iteration 760 : 0.032142218202352524
Loss at iteration 770 : 0.0318288579583168
Loss at iteration 780 : 0.02540629915893078
Loss at iteration 790 : 0.022462742403149605
Loss at iteration 800 : 0.027868054807186127
Loss at iteration 810 : 0.01673843339085579
Loss at iteration 820 : 0.033931419253349304
Loss at iteration 830 : 0.04321357607841492
Loss at iteration 840 : 0.022488661110401154
Loss at iteration 850 : 0.023610979318618774
Loss at iteration 860 : 0.019283588975667953
Loss at iteration 870 : 0.021913649514317513
Loss at iteration 880 : 0.03622354939579964
Loss at iteration 890 : 0.0183181744068861
Loss at iteration 900 : 0.025290345773100853
Loss at iteration 910 : 0.02207772806286812
Loss at iteration 920 : 0.035898782312870026
Loss at iteration 930 : 0.025440450757741928
Loss at iteration 940 : 0.022714834660291672
Loss at iteration 950 : 0.025879940018057823
Loss at iteration 960 : 0.024916639551520348
Loss at iteration 970 : 0.028059348464012146
Loss at iteration 980 : 0.04189396649599075
Loss at iteration 990 : 0.029726542532444
Loss at iteration 1000 : 0.016209853813052177
Loss at iteration 1010 : 0.027297554537653923
Loss at iteration 1020 : 0.03026973456144333
Loss at iteration 1030 : 0.02616402506828308
Loss at iteration 1040 : 0.018896806985139847
Loss at iteration 1050 : 0.03388932719826698
Loss at iteration 1060 : 0.03686077892780304
Loss at iteration 1070 : 0.031036164611577988
Loss at iteration 1080 : 0.03328089416027069
Loss at iteration 1090 : 0.027251671999692917
Loss at iteration 1100 : 0.020781435072422028
Loss at iteration 1110 : 0.02104269154369831
Loss at iteration 1120 : 0.028038937598466873
Loss at iteration 1130 : 0.024829179048538208
Loss at iteration 1140 : 0.021710272878408432
Loss at iteration 1150 : 0.04335174709558487
Loss at iteration 1160 : 0.022373013198375702
Loss at iteration 1170 : 0.04103432223200798
Loss at iteration 1180 : 0.01949569582939148
Loss at iteration 1190 : 0.05172760784626007
Loss at iteration 1200 : 0.02759299799799919
Loss at iteration 1210 : 0.028167221695184708
The SSIM Value is: 0.7639290928840637
The PSNR Value is: 17.978406397501626
the epoch is: 19
Loss at iteration 10 : 0.029695168137550354
Loss at iteration 20 : 0.01442599855363369
Loss at iteration 30 : 0.0353650227189064
Loss at iteration 40 : 0.02183494158089161
Loss at iteration 50 : 0.028006989508867264
Loss at iteration 60 : 0.03651374578475952
Loss at iteration 70 : 0.013563266023993492
Loss at iteration 80 : 0.03743626922369003
Loss at iteration 90 : 0.029634717851877213
Loss at iteration 100 : 0.03382699936628342
Loss at iteration 110 : 0.031390443444252014
Loss at iteration 120 : 0.03276195004582405
Loss at iteration 130 : 0.028859008103609085
Loss at iteration 140 : 0.02433566004037857
Loss at iteration 150 : 0.024003710597753525
Loss at iteration 160 : 0.027175884693861008
Loss at iteration 170 : 0.030256256461143494
Loss at iteration 180 : 0.030998092144727707
Loss at iteration 190 : 0.021377447992563248
Loss at iteration 200 : 0.026925155892968178
Loss at iteration 210 : 0.02250061184167862
Loss at iteration 220 : 0.026937492191791534
Loss at iteration 230 : 0.027275439351797104
Loss at iteration 240 : 0.019535131752490997
Loss at iteration 250 : 0.017281020060181618
Loss at iteration 260 : 0.026463884860277176
Loss at iteration 270 : 0.033706627786159515
Loss at iteration 280 : 0.028520721942186356
Loss at iteration 290 : 0.02738683670759201
Loss at iteration 300 : 0.042461082339286804
Loss at iteration 310 : 0.023568326607346535
Loss at iteration 320 : 0.028925685212016106
Loss at iteration 330 : 0.036002155393362045
Loss at iteration 340 : 0.02038513869047165
Loss at iteration 350 : 0.026477979496121407
Loss at iteration 360 : 0.037804920226335526
Loss at iteration 370 : 0.027198901399970055
Loss at iteration 380 : 0.03212258964776993
Loss at iteration 390 : 0.03628985956311226
Loss at iteration 400 : 0.025291338562965393
Loss at iteration 410 : 0.029040556401014328
Loss at iteration 420 : 0.02610689587891102
Loss at iteration 430 : 0.03022768348455429
Loss at iteration 440 : 0.021350402384996414
Loss at iteration 450 : 0.020075418055057526
Loss at iteration 460 : 0.032700251787900925
Loss at iteration 470 : 0.027500972151756287
Loss at iteration 480 : 0.02800995483994484
Loss at iteration 490 : 0.035507284104824066
Loss at iteration 500 : 0.025765251368284225
Loss at iteration 510 : 0.037390001118183136
Loss at iteration 520 : 0.022974664345383644
Loss at iteration 530 : 0.03164498880505562
Loss at iteration 540 : 0.021896764636039734
Loss at iteration 550 : 0.02880742959678173
Loss at iteration 560 : 0.02259618043899536
Loss at iteration 570 : 0.04073578491806984
Loss at iteration 580 : 0.04493553191423416
Loss at iteration 590 : 0.02597198635339737
Loss at iteration 600 : 0.027060091495513916
Loss at iteration 610 : 0.025207871571183205
Loss at iteration 620 : 0.03908425569534302
Loss at iteration 630 : 0.04814416915178299
Loss at iteration 640 : 0.027390319854021072
Loss at iteration 650 : 0.020966023206710815
Loss at iteration 660 : 0.025001753121614456
Loss at iteration 670 : 0.025815758854150772
Loss at iteration 680 : 0.03126268833875656
Loss at iteration 690 : 0.027793142944574356
Loss at iteration 700 : 0.03149912506341934
Loss at iteration 710 : 0.02995484136044979
Loss at iteration 720 : 0.01944243162870407
Loss at iteration 730 : 0.02835141308605671
Loss at iteration 740 : 0.016693387180566788
Loss at iteration 750 : 0.025169380009174347
Loss at iteration 760 : 0.02134835533797741
Loss at iteration 770 : 0.019053276628255844
Loss at iteration 780 : 0.03425388038158417
Loss at iteration 790 : 0.012677598744630814
Loss at iteration 800 : 0.019833259284496307
Loss at iteration 810 : 0.014464879408478737
Loss at iteration 820 : 0.040748290717601776
Loss at iteration 830 : 0.02951507829129696
Loss at iteration 840 : 0.022209571674466133
Loss at iteration 850 : 0.03326784819364548
Loss at iteration 860 : 0.032225318253040314
Loss at iteration 870 : 0.026029201224446297
Loss at iteration 880 : 0.025472089648246765
Loss at iteration 890 : 0.036900877952575684
Loss at iteration 900 : 0.02571885660290718
Loss at iteration 910 : 0.014982319436967373
Loss at iteration 920 : 0.02769339643418789
Loss at iteration 930 : 0.037748463451862335
Loss at iteration 940 : 0.04140038415789604
Loss at iteration 950 : 0.019567696377635002
Loss at iteration 960 : 0.02216324210166931
Loss at iteration 970 : 0.034325011074543
Loss at iteration 980 : 0.039180442690849304
Loss at iteration 990 : 0.015630628913640976
Loss at iteration 1000 : 0.020371081307530403
Loss at iteration 1010 : 0.02218722179532051
Loss at iteration 1020 : 0.02560940571129322
Loss at iteration 1030 : 0.016257263720035553
Loss at iteration 1040 : 0.017819277942180634
Loss at iteration 1050 : 0.017851337790489197
Loss at iteration 1060 : 0.023275110870599747
Loss at iteration 1070 : 0.022852661088109016
Loss at iteration 1080 : 0.018534429371356964
Loss at iteration 1090 : 0.020137488842010498
Loss at iteration 1100 : 0.02328651025891304
Loss at iteration 1110 : 0.03353505581617355
Loss at iteration 1120 : 0.027683556079864502
Loss at iteration 1130 : 0.03158248960971832
Loss at iteration 1140 : 0.02308190055191517
Loss at iteration 1150 : 0.027451537549495697
Loss at iteration 1160 : 0.022328035905957222
Loss at iteration 1170 : 0.021303340792655945
Loss at iteration 1180 : 0.03063184767961502
Loss at iteration 1190 : 0.03666236251592636
Loss at iteration 1200 : 0.02746902033686638
Loss at iteration 1210 : 0.026872608810663223
The SSIM Value is: 0.7662256161371866
The PSNR Value is: 18.298416519165038
the epoch is: 20
Loss at iteration 10 : 0.02616262063384056
Loss at iteration 20 : 0.027542218565940857
Loss at iteration 30 : 0.025739993900060654
Loss at iteration 40 : 0.029910920187830925
Loss at iteration 50 : 0.026412012055516243
Loss at iteration 60 : 0.02492276206612587
Loss at iteration 70 : 0.024975992739200592
Loss at iteration 80 : 0.019084982573986053
Loss at iteration 90 : 0.02903767116367817
Loss at iteration 100 : 0.03508848696947098
Loss at iteration 110 : 0.016709689050912857
Loss at iteration 120 : 0.03295658156275749
Loss at iteration 130 : 0.02632806822657585
Loss at iteration 140 : 0.015777233988046646
Loss at iteration 150 : 0.025033706799149513
Loss at iteration 160 : 0.021466262638568878
Loss at iteration 170 : 0.02603982761502266
Loss at iteration 180 : 0.04333336651325226
Loss at iteration 190 : 0.037045784294605255
Loss at iteration 200 : 0.026580391451716423
Loss at iteration 210 : 0.029939768835902214
Loss at iteration 220 : 0.027257196605205536
Loss at iteration 230 : 0.026811957359313965
Loss at iteration 240 : 0.02981201373040676
Loss at iteration 250 : 0.03507715091109276
Loss at iteration 260 : 0.034556884318590164
Loss at iteration 270 : 0.029656996950507164
Loss at iteration 280 : 0.030075768008828163
Loss at iteration 290 : 0.03036370873451233
Loss at iteration 300 : 0.022902604192495346
Loss at iteration 310 : 0.02027268335223198
Loss at iteration 320 : 0.034389518201351166
Loss at iteration 330 : 0.020044535398483276
Loss at iteration 340 : 0.01957893930375576
Loss at iteration 350 : 0.026925992220640182
Loss at iteration 360 : 0.02371039427816868
Loss at iteration 370 : 0.021673880517482758
Loss at iteration 380 : 0.017083490267395973
Loss at iteration 390 : 0.02499549277126789
Loss at iteration 400 : 0.02765721082687378
Loss at iteration 410 : 0.02472447231411934
Loss at iteration 420 : 0.024844052270054817
Loss at iteration 430 : 0.021763145923614502
Loss at iteration 440 : 0.019638409838080406
Loss at iteration 450 : 0.038777563720941544
Loss at iteration 460 : 0.01733652502298355
Loss at iteration 470 : 0.022999275475740433
Loss at iteration 480 : 0.015678072348237038
Loss at iteration 490 : 0.018792327493429184
Loss at iteration 500 : 0.025604426860809326
Loss at iteration 510 : 0.02642831951379776
Loss at iteration 520 : 0.023675017058849335
Loss at iteration 530 : 0.054009053856134415
Loss at iteration 540 : 0.020008929073810577
Loss at iteration 550 : 0.0286484993994236
Loss at iteration 560 : 0.022202076390385628
Loss at iteration 570 : 0.023146305233240128
Loss at iteration 580 : 0.02340048737823963
Loss at iteration 590 : 0.032505374401807785
Loss at iteration 600 : 0.018726777285337448
Loss at iteration 610 : 0.0283817145973444
Loss at iteration 620 : 0.016789909452199936
Loss at iteration 630 : 0.014799943193793297
Loss at iteration 640 : 0.024670211598277092
Loss at iteration 650 : 0.029029730707406998
Loss at iteration 660 : 0.028833722695708275
Loss at iteration 670 : 0.02470148541033268
Loss at iteration 680 : 0.02155938372015953
Loss at iteration 690 : 0.020295968279242516
Loss at iteration 700 : 0.021564465016126633
Loss at iteration 710 : 0.025578105822205544
Loss at iteration 720 : 0.03614947944879532
Loss at iteration 730 : 0.01955706812441349
Loss at iteration 740 : 0.03207574039697647
Loss at iteration 750 : 0.025836464017629623
Loss at iteration 760 : 0.039177484810352325
Loss at iteration 770 : 0.02986309863626957
Loss at iteration 780 : 0.02872675657272339
Loss at iteration 790 : 0.014608773402869701
Loss at iteration 800 : 0.010683588683605194
Loss at iteration 810 : 0.01953807845711708
Loss at iteration 820 : 0.035253092646598816
Loss at iteration 830 : 0.03485491871833801
Loss at iteration 840 : 0.034369535744190216
Loss at iteration 850 : 0.02795829065144062
Loss at iteration 860 : 0.023253444582223892
Loss at iteration 870 : 0.04356364905834198
Loss at iteration 880 : 0.019750235602259636
Loss at iteration 890 : 0.01953718438744545
Loss at iteration 900 : 0.021688254550099373
Loss at iteration 910 : 0.0258957389742136
Loss at iteration 920 : 0.027520883828401566
Loss at iteration 930 : 0.030427588149905205
Loss at iteration 940 : 0.0360216423869133
Loss at iteration 950 : 0.018855268135666847
Loss at iteration 960 : 0.01601559668779373
Loss at iteration 970 : 0.03724712133407593
Loss at iteration 980 : 0.039129115641117096
Loss at iteration 990 : 0.0557277649641037
Loss at iteration 1000 : 0.015313482843339443
Loss at iteration 1010 : 0.02970215119421482
Loss at iteration 1020 : 0.017602287232875824
Loss at iteration 1030 : 0.029234815388917923
Loss at iteration 1040 : 0.02467305213212967
Loss at iteration 1050 : 0.02929670736193657
Loss at iteration 1060 : 0.02999899908900261
Loss at iteration 1070 : 0.049694597721099854
Loss at iteration 1080 : 0.021400390192866325
Loss at iteration 1090 : 0.03578813746571541
Loss at iteration 1100 : 0.02314525470137596
Loss at iteration 1110 : 0.028208771720528603
Loss at iteration 1120 : 0.033510126173496246
Loss at iteration 1130 : 0.02474835142493248
Loss at iteration 1140 : 0.029683701694011688
Loss at iteration 1150 : 0.019716788083314896
Loss at iteration 1160 : 0.029747897759079933
Loss at iteration 1170 : 0.0342523418366909
Loss at iteration 1180 : 0.03545186668634415
Loss at iteration 1190 : 0.02284357324242592
Loss at iteration 1200 : 0.02587348036468029
Loss at iteration 1210 : 0.021255601197481155
The SSIM Value is: 0.7690169095993042
The PSNR Value is: 18.229723103841145
the epoch is: 21
Loss at iteration 10 : 0.025652289390563965
Loss at iteration 20 : 0.034159786999225616
Loss at iteration 30 : 0.029694586992263794
Loss at iteration 40 : 0.024098586291074753
Loss at iteration 50 : 0.017620902508497238
Loss at iteration 60 : 0.03189629316329956
Loss at iteration 70 : 0.028094638139009476
Loss at iteration 80 : 0.03482580557465553
Loss at iteration 90 : 0.019185109063982964
Loss at iteration 100 : 0.0354943573474884
Loss at iteration 110 : 0.025439511984586716
Loss at iteration 120 : 0.020357206463813782
Loss at iteration 130 : 0.017614061012864113
Loss at iteration 140 : 0.027374615892767906
Loss at iteration 150 : 0.02581109292805195
Loss at iteration 160 : 0.02778773568570614
Loss at iteration 170 : 0.019368380308151245
Loss at iteration 180 : 0.038039498031139374
Loss at iteration 190 : 0.034693393856287
Loss at iteration 200 : 0.03816435486078262
Loss at iteration 210 : 0.030835073441267014
Loss at iteration 220 : 0.018009494990110397
Loss at iteration 230 : 0.029355721548199654
Loss at iteration 240 : 0.015938641503453255
Loss at iteration 250 : 0.03335343673825264
Loss at iteration 260 : 0.013592580333352089
Loss at iteration 270 : 0.04231216013431549
Loss at iteration 280 : 0.037603482604026794
Loss at iteration 290 : 0.025291919708251953
Loss at iteration 300 : 0.03784250468015671
Loss at iteration 310 : 0.03036770224571228
Loss at iteration 320 : 0.023540588095784187
Loss at iteration 330 : 0.0462505966424942
Loss at iteration 340 : 0.027880031615495682
Loss at iteration 350 : 0.01772453635931015
Loss at iteration 360 : 0.03374597057700157
Loss at iteration 370 : 0.019381843507289886
Loss at iteration 380 : 0.03794988989830017
Loss at iteration 390 : 0.02113775722682476
Loss at iteration 400 : 0.023928776383399963
Loss at iteration 410 : 0.03174758702516556
Loss at iteration 420 : 0.03346438333392143
Loss at iteration 430 : 0.032512638717889786
Loss at iteration 440 : 0.03501870483160019
Loss at iteration 450 : 0.025922201573848724
Loss at iteration 460 : 0.027988318353891373
Loss at iteration 470 : 0.02146947756409645
Loss at iteration 480 : 0.02546180598437786
Loss at iteration 490 : 0.02912089228630066
Loss at iteration 500 : 0.02403760328888893
Loss at iteration 510 : 0.02892453409731388
Loss at iteration 520 : 0.032611697912216187
Loss at iteration 530 : 0.01956847496330738
Loss at iteration 540 : 0.025314245373010635
Loss at iteration 550 : 0.016428574919700623
Loss at iteration 560 : 0.023941416293382645
Loss at iteration 570 : 0.02328953519463539
Loss at iteration 580 : 0.04251757264137268
Loss at iteration 590 : 0.02456851676106453
Loss at iteration 600 : 0.024961840361356735
Loss at iteration 610 : 0.031109709292650223
Loss at iteration 620 : 0.02609862945973873
Loss at iteration 630 : 0.018377654254436493
Loss at iteration 640 : 0.05054224282503128
Loss at iteration 650 : 0.019563989713788033
Loss at iteration 660 : 0.03501616418361664
Loss at iteration 670 : 0.021815940737724304
Loss at iteration 680 : 0.027097055688500404
Loss at iteration 690 : 0.025753404945135117
Loss at iteration 700 : 0.030403073877096176
Loss at iteration 710 : 0.023098085075616837
Loss at iteration 720 : 0.033161766827106476
Loss at iteration 730 : 0.02178913541138172
Loss at iteration 740 : 0.02646460384130478
Loss at iteration 750 : 0.01891317404806614
Loss at iteration 760 : 0.02517160028219223
Loss at iteration 770 : 0.022031890228390694
Loss at iteration 780 : 0.039347536861896515
Loss at iteration 790 : 0.020474517717957497
Loss at iteration 800 : 0.0203806534409523
Loss at iteration 810 : 0.034337930381298065
Loss at iteration 820 : 0.0416165366768837
Loss at iteration 830 : 0.019738763570785522
Loss at iteration 840 : 0.03396163135766983
Loss at iteration 850 : 0.02659360133111477
Loss at iteration 860 : 0.02524297684431076
Loss at iteration 870 : 0.018500370904803276
Loss at iteration 880 : 0.02781309187412262
Loss at iteration 890 : 0.0354698970913887
Loss at iteration 900 : 0.02443513460457325
Loss at iteration 910 : 0.015812622383236885
Loss at iteration 920 : 0.014516698196530342
Loss at iteration 930 : 0.01975938491523266
Loss at iteration 940 : 0.025489378720521927
Loss at iteration 950 : 0.019941337406635284
Loss at iteration 960 : 0.01488773338496685
Loss at iteration 970 : 0.042986683547496796
Loss at iteration 980 : 0.027511311694979668
Loss at iteration 990 : 0.023019352927803993
Loss at iteration 1000 : 0.024513626471161842
Loss at iteration 1010 : 0.03401670604944229
Loss at iteration 1020 : 0.017729710787534714
Loss at iteration 1030 : 0.01816553995013237
Loss at iteration 1040 : 0.028144830837845802
Loss at iteration 1050 : 0.02986474707722664
Loss at iteration 1060 : 0.01293653342872858
Loss at iteration 1070 : 0.019139600917696953
Loss at iteration 1080 : 0.031233787536621094
Loss at iteration 1090 : 0.025042088702321053
Loss at iteration 1100 : 0.028426580131053925
Loss at iteration 1110 : 0.04068921506404877
Loss at iteration 1120 : 0.022619429975748062
Loss at iteration 1130 : 0.026937559247016907
Loss at iteration 1140 : 0.024276845157146454
Loss at iteration 1150 : 0.021596457809209824
Loss at iteration 1160 : 0.02675975114107132
Loss at iteration 1170 : 0.03352348133921623
Loss at iteration 1180 : 0.03363081067800522
Loss at iteration 1190 : 0.018405262380838394
Loss at iteration 1200 : 0.03195968270301819
Loss at iteration 1210 : 0.04118745028972626
The SSIM Value is: 0.7656571825345357
The PSNR Value is: 18.32678616841634
the epoch is: 22
Loss at iteration 10 : 0.04131511598825455
Loss at iteration 20 : 0.03220245987176895
Loss at iteration 30 : 0.02512526698410511
Loss at iteration 40 : 0.03627163544297218
Loss at iteration 50 : 0.035128429532051086
Loss at iteration 60 : 0.0363946333527565
Loss at iteration 70 : 0.020196599885821342
Loss at iteration 80 : 0.016508445143699646
Loss at iteration 90 : 0.03766550123691559
Loss at iteration 100 : 0.04012324661016464
Loss at iteration 110 : 0.03600458800792694
Loss at iteration 120 : 0.0254166591912508
Loss at iteration 130 : 0.02645837888121605
Loss at iteration 140 : 0.03128381073474884
Loss at iteration 150 : 0.016835059970617294
Loss at iteration 160 : 0.020765814930200577
Loss at iteration 170 : 0.02813676930963993
Loss at iteration 180 : 0.02940702810883522
Loss at iteration 190 : 0.03106064535677433
Loss at iteration 200 : 0.017755748704075813
Loss at iteration 210 : 0.03091585636138916
Loss at iteration 220 : 0.028568215668201447
Loss at iteration 230 : 0.018842902034521103
Loss at iteration 240 : 0.01638306863605976
Loss at iteration 250 : 0.022358443588018417
Loss at iteration 260 : 0.02671903558075428
Loss at iteration 270 : 0.024588510394096375
Loss at iteration 280 : 0.019444454461336136
Loss at iteration 290 : 0.02532661147415638
Loss at iteration 300 : 0.02179693803191185
Loss at iteration 310 : 0.012652646750211716
Loss at iteration 320 : 0.01836770586669445
Loss at iteration 330 : 0.0474945493042469
Loss at iteration 340 : 0.02022353932261467
Loss at iteration 350 : 0.02219158224761486
Loss at iteration 360 : 0.019391320645809174
Loss at iteration 370 : 0.029304292052984238
Loss at iteration 380 : 0.03193354234099388
Loss at iteration 390 : 0.027779847383499146
Loss at iteration 400 : 0.03796413913369179
Loss at iteration 410 : 0.030820967629551888
Loss at iteration 420 : 0.021134845912456512
Loss at iteration 430 : 0.023464351892471313
Loss at iteration 440 : 0.036246899515390396
Loss at iteration 450 : 0.03645535558462143
Loss at iteration 460 : 0.04370452091097832
Loss at iteration 470 : 0.02787858247756958
Loss at iteration 480 : 0.03375682234764099
Loss at iteration 490 : 0.015316860750317574
Loss at iteration 500 : 0.025410085916519165
Loss at iteration 510 : 0.04411610960960388
Loss at iteration 520 : 0.03529869765043259
Loss at iteration 530 : 0.030001288279891014
Loss at iteration 540 : 0.02204321324825287
Loss at iteration 550 : 0.026286540552973747
Loss at iteration 560 : 0.026691284030675888
Loss at iteration 570 : 0.02742800861597061
Loss at iteration 580 : 0.03871103376150131
Loss at iteration 590 : 0.03409276157617569
Loss at iteration 600 : 0.03436398133635521
Loss at iteration 610 : 0.026263071224093437
Loss at iteration 620 : 0.021360084414482117
Loss at iteration 630 : 0.022521667182445526
Loss at iteration 640 : 0.021985577419400215
Loss at iteration 650 : 0.03941439092159271
Loss at iteration 660 : 0.031466513872146606
Loss at iteration 670 : 0.03832050412893295
Loss at iteration 680 : 0.029403485357761383
Loss at iteration 690 : 0.038041502237319946
Loss at iteration 700 : 0.022565171122550964
Loss at iteration 710 : 0.029545916244387627
Loss at iteration 720 : 0.03554130345582962
Loss at iteration 730 : 0.02158920094370842
Loss at iteration 740 : 0.03471079468727112
Loss at iteration 750 : 0.029743921011686325
Loss at iteration 760 : 0.03222327679395676
Loss at iteration 770 : 0.029307276010513306
Loss at iteration 780 : 0.030809815973043442
Loss at iteration 790 : 0.02541584149003029
Loss at iteration 800 : 0.022214964032173157
Loss at iteration 810 : 0.024105696007609367
Loss at iteration 820 : 0.02562573179602623
Loss at iteration 830 : 0.017792291939258575
Loss at iteration 840 : 0.019095808267593384
Loss at iteration 850 : 0.026653315871953964
Loss at iteration 860 : 0.0273173488676548
Loss at iteration 870 : 0.034879036247730255
Loss at iteration 880 : 0.025663817301392555
Loss at iteration 890 : 0.0392950065433979
Loss at iteration 900 : 0.04142071306705475
Loss at iteration 910 : 0.03517661243677139
Loss at iteration 920 : 0.04238724336028099
Loss at iteration 930 : 0.036894652992486954
Loss at iteration 940 : 0.02773580513894558
Loss at iteration 950 : 0.025259260088205338
Loss at iteration 960 : 0.03779379650950432
Loss at iteration 970 : 0.029193319380283356
Loss at iteration 980 : 0.023515580222010612
Loss at iteration 990 : 0.03738120198249817
Loss at iteration 1000 : 0.029899735003709793
Loss at iteration 1010 : 0.032619599252939224
Loss at iteration 1020 : 0.032307468354701996
Loss at iteration 1030 : 0.01923927664756775
Loss at iteration 1040 : 0.021069742739200592
Loss at iteration 1050 : 0.03263077884912491
Loss at iteration 1060 : 0.031467147171497345
Loss at iteration 1070 : 0.035222675651311874
Loss at iteration 1080 : 0.046187810599803925
Loss at iteration 1090 : 0.013693598099052906
Loss at iteration 1100 : 0.03988359123468399
Loss at iteration 1110 : 0.025358250364661217
Loss at iteration 1120 : 0.02887308970093727
Loss at iteration 1130 : 0.02945541962981224
Loss at iteration 1140 : 0.026581499725580215
Loss at iteration 1150 : 0.02665077894926071
Loss at iteration 1160 : 0.025886613875627518
Loss at iteration 1170 : 0.042710237205028534
Loss at iteration 1180 : 0.02615625411272049
Loss at iteration 1190 : 0.029713153839111328
Loss at iteration 1200 : 0.019309191033244133
Loss at iteration 1210 : 0.020408477634191513
The SSIM Value is: 0.7626885811487834
The PSNR Value is: 18.116199493408203
the epoch is: 23
Loss at iteration 10 : 0.021367210894823074
Loss at iteration 20 : 0.01975223794579506
Loss at iteration 30 : 0.03139756619930267
Loss at iteration 40 : 0.022100500762462616
Loss at iteration 50 : 0.032183222472667694
Loss at iteration 60 : 0.02388187311589718
Loss at iteration 70 : 0.02501038834452629
Loss at iteration 80 : 0.041136324405670166
Loss at iteration 90 : 0.0298457108438015
Loss at iteration 100 : 0.024519886821508408
Loss at iteration 110 : 0.016229890286922455
Loss at iteration 120 : 0.035493530333042145
Loss at iteration 130 : 0.03650066629052162
Loss at iteration 140 : 0.018298691138625145
Loss at iteration 150 : 0.02000197023153305
Loss at iteration 160 : 0.03674072027206421
Loss at iteration 170 : 0.03107769414782524
Loss at iteration 180 : 0.022985275834798813
Loss at iteration 190 : 0.019159715622663498
Loss at iteration 200 : 0.030742555856704712
Loss at iteration 210 : 0.024313462898135185
Loss at iteration 220 : 0.024677470326423645
Loss at iteration 230 : 0.02769213169813156
Loss at iteration 240 : 0.022930607199668884
Loss at iteration 250 : 0.02826898731291294
Loss at iteration 260 : 0.03759019076824188
Loss at iteration 270 : 0.03204815089702606
Loss at iteration 280 : 0.029752599075436592
Loss at iteration 290 : 0.02158462256193161
Loss at iteration 300 : 0.034334056079387665
Loss at iteration 310 : 0.012165531516075134
Loss at iteration 320 : 0.02067149244248867
Loss at iteration 330 : 0.027593005448579788
Loss at iteration 340 : 0.018217409029603004
Loss at iteration 350 : 0.03857945650815964
Loss at iteration 360 : 0.02929117903113365
Loss at iteration 370 : 0.023748882114887238
Loss at iteration 380 : 0.0248661320656538
Loss at iteration 390 : 0.01900257170200348
Loss at iteration 400 : 0.02754821814596653
Loss at iteration 410 : 0.028901681303977966
Loss at iteration 420 : 0.05224192515015602
Loss at iteration 430 : 0.02163710817694664
Loss at iteration 440 : 0.019227126613259315
Loss at iteration 450 : 0.020957089960575104
Loss at iteration 460 : 0.02115483209490776
Loss at iteration 470 : 0.02573050744831562
Loss at iteration 480 : 0.026090478524565697
Loss at iteration 490 : 0.031603194773197174
Loss at iteration 500 : 0.028200644999742508
Loss at iteration 510 : 0.028698332607746124
Loss at iteration 520 : 0.03714221715927124
Loss at iteration 530 : 0.026126820594072342
Loss at iteration 540 : 0.03019874170422554
Loss at iteration 550 : 0.03383581340312958
Loss at iteration 560 : 0.027132973074913025
Loss at iteration 570 : 0.025644153356552124
Loss at iteration 580 : 0.03445887565612793
Loss at iteration 590 : 0.030849890783429146
Loss at iteration 600 : 0.02663935348391533
Loss at iteration 610 : 0.03755667805671692
Loss at iteration 620 : 0.030683254823088646
Loss at iteration 630 : 0.014830254018306732
Loss at iteration 640 : 0.03678029775619507
Loss at iteration 650 : 0.027920125052332878
Loss at iteration 660 : 0.025408733636140823
Loss at iteration 670 : 0.02176412008702755
Loss at iteration 680 : 0.01682429574429989
Loss at iteration 690 : 0.042023397982120514
Loss at iteration 700 : 0.029468638822436333
Loss at iteration 710 : 0.027868028730154037
Loss at iteration 720 : 0.027494601905345917
Loss at iteration 730 : 0.027033012360334396
Loss at iteration 740 : 0.019849034026265144
Loss at iteration 750 : 0.035233981907367706
Loss at iteration 760 : 0.032530441880226135
Loss at iteration 770 : 0.03214685618877411
Loss at iteration 780 : 0.020357169210910797
Loss at iteration 790 : 0.026375414803624153
Loss at iteration 800 : 0.02794060856103897
Loss at iteration 810 : 0.018956854939460754
Loss at iteration 820 : 0.026982419192790985
Loss at iteration 830 : 0.02616405487060547
Loss at iteration 840 : 0.03218598663806915
Loss at iteration 850 : 0.0191875658929348
Loss at iteration 860 : 0.026327908039093018
Loss at iteration 870 : 0.029120050370693207
Loss at iteration 880 : 0.05970478057861328
Loss at iteration 890 : 0.020401740446686745
Loss at iteration 900 : 0.024479448795318604
Loss at iteration 910 : 0.018637731671333313
Loss at iteration 920 : 0.029385728761553764
Loss at iteration 930 : 0.028502419590950012
Loss at iteration 940 : 0.012872708961367607
Loss at iteration 950 : 0.021603204309940338
Loss at iteration 960 : 0.01882675290107727
Loss at iteration 970 : 0.017900852486491203
Loss at iteration 980 : 0.024393118917942047
Loss at iteration 990 : 0.02641511708498001
Loss at iteration 1000 : 0.04104126989841461
Loss at iteration 1010 : 0.009679103270173073
Loss at iteration 1020 : 0.017078761011362076
Loss at iteration 1030 : 0.0142870107665658
Loss at iteration 1040 : 0.032891806215047836
Loss at iteration 1050 : 0.02120840735733509
Loss at iteration 1060 : 0.0155428946018219
Loss at iteration 1070 : 0.04088180139660835
Loss at iteration 1080 : 0.022336892783641815
Loss at iteration 1090 : 0.027839167043566704
Loss at iteration 1100 : 0.03555899113416672
Loss at iteration 1110 : 0.04064382612705231
Loss at iteration 1120 : 0.028376441448926926
Loss at iteration 1130 : 0.030754366889595985
Loss at iteration 1140 : 0.02718210220336914
Loss at iteration 1150 : 0.02372932992875576
Loss at iteration 1160 : 0.013005750253796577
Loss at iteration 1170 : 0.017642054706811905
Loss at iteration 1180 : 0.027296416461467743
Loss at iteration 1190 : 0.018599331378936768
Loss at iteration 1200 : 0.022578030824661255
Loss at iteration 1210 : 0.026719622313976288
The SSIM Value is: 0.7706308205922444
The PSNR Value is: 18.178839619954427
the epoch is: 24
Loss at iteration 10 : 0.03328465670347214
Loss at iteration 20 : 0.04123200103640556
Loss at iteration 30 : 0.035418763756752014
Loss at iteration 40 : 0.02555100992321968
Loss at iteration 50 : 0.018208816647529602
Loss at iteration 60 : 0.03407511115074158
Loss at iteration 70 : 0.0187410619109869
Loss at iteration 80 : 0.01997598446905613
Loss at iteration 90 : 0.03176632151007652
Loss at iteration 100 : 0.028161831200122833
Loss at iteration 110 : 0.027115240693092346
Loss at iteration 120 : 0.018200542777776718
Loss at iteration 130 : 0.01874629780650139
Loss at iteration 140 : 0.019328337162733078
Loss at iteration 150 : 0.02170879766345024
Loss at iteration 160 : 0.025864675641059875
Loss at iteration 170 : 0.035353854298591614
Loss at iteration 180 : 0.020355146378278732
Loss at iteration 190 : 0.03172408789396286
Loss at iteration 200 : 0.03764226660132408
Loss at iteration 210 : 0.029822295531630516
Loss at iteration 220 : 0.033967047929763794
Loss at iteration 230 : 0.04112910479307175
Loss at iteration 240 : 0.03215235099196434
Loss at iteration 250 : 0.02346661500632763
Loss at iteration 260 : 0.025391124188899994
Loss at iteration 270 : 0.02700878120958805
Loss at iteration 280 : 0.018007459118962288
Loss at iteration 290 : 0.03410717099905014
Loss at iteration 300 : 0.027940819039940834
Loss at iteration 310 : 0.02657496929168701
Loss at iteration 320 : 0.03143996000289917
Loss at iteration 330 : 0.02260361611843109
Loss at iteration 340 : 0.019443688914179802
Loss at iteration 350 : 0.015068471431732178
Loss at iteration 360 : 0.02912503108382225
Loss at iteration 370 : 0.030508073046803474
Loss at iteration 380 : 0.02642497420310974
Loss at iteration 390 : 0.020913325250148773
Loss at iteration 400 : 0.03214723616838455
Loss at iteration 410 : 0.02318737655878067
Loss at iteration 420 : 0.027588188648223877
Loss at iteration 430 : 0.0222709272056818
Loss at iteration 440 : 0.022959522902965546
Loss at iteration 450 : 0.03636341542005539
Loss at iteration 460 : 0.017143698409199715
Loss at iteration 470 : 0.03470887616276741
Loss at iteration 480 : 0.023328401148319244
Loss at iteration 490 : 0.03946799039840698
Loss at iteration 500 : 0.021200375631451607
Loss at iteration 510 : 0.022269461303949356
Loss at iteration 520 : 0.02133861556649208
Loss at iteration 530 : 0.02789236232638359
Loss at iteration 540 : 0.05062996596097946
Loss at iteration 550 : 0.018741410225629807
Loss at iteration 560 : 0.013948362320661545
Loss at iteration 570 : 0.025703325867652893
Loss at iteration 580 : 0.02474047988653183
Loss at iteration 590 : 0.032060250639915466
Loss at iteration 600 : 0.03502586856484413
Loss at iteration 610 : 0.03388887643814087
Loss at iteration 620 : 0.022885393351316452
Loss at iteration 630 : 0.017107034102082253
Loss at iteration 640 : 0.0298488587141037
Loss at iteration 650 : 0.03581846505403519
Loss at iteration 660 : 0.014671487733721733
Loss at iteration 670 : 0.031213589012622833
Loss at iteration 680 : 0.04558037593960762
Loss at iteration 690 : 0.019943270832300186
Loss at iteration 700 : 0.030457867309451103
Loss at iteration 710 : 0.024519022554159164
Loss at iteration 720 : 0.024603649973869324
Loss at iteration 730 : 0.03554002195596695
Loss at iteration 740 : 0.023248862475156784
Loss at iteration 750 : 0.027523266151547432
Loss at iteration 760 : 0.023317476734519005
Loss at iteration 770 : 0.0317055806517601
Loss at iteration 780 : 0.025660647079348564
Loss at iteration 790 : 0.04090521112084389
Loss at iteration 800 : 0.021536245942115784
Loss at iteration 810 : 0.026693083345890045
Loss at iteration 820 : 0.031939778476953506
Loss at iteration 830 : 0.0315348356962204
Loss at iteration 840 : 0.02303776890039444
Loss at iteration 850 : 0.04227307811379433
Loss at iteration 860 : 0.020180420950055122
Loss at iteration 870 : 0.032231613993644714
Loss at iteration 880 : 0.021709997206926346
Loss at iteration 890 : 0.016326136887073517
Loss at iteration 900 : 0.022813571617007256
Loss at iteration 910 : 0.04553116112947464
Loss at iteration 920 : 0.025976311415433884
Loss at iteration 930 : 0.03846174478530884
Loss at iteration 940 : 0.024936728179454803
Loss at iteration 950 : 0.030008379369974136
Loss at iteration 960 : 0.013871774077415466
Loss at iteration 970 : 0.031241342425346375
Loss at iteration 980 : 0.027047503739595413
Loss at iteration 990 : 0.02062222547829151
Loss at iteration 1000 : 0.03719540312886238
Loss at iteration 1010 : 0.032904647290706635
Loss at iteration 1020 : 0.03669840842485428
Loss at iteration 1030 : 0.030968384817242622
Loss at iteration 1040 : 0.021865755319595337
Loss at iteration 1050 : 0.02364731952548027
Loss at iteration 1060 : 0.029480215162038803
Loss at iteration 1070 : 0.02617519721388817
Loss at iteration 1080 : 0.02905477024614811
Loss at iteration 1090 : 0.018532104790210724
Loss at iteration 1100 : 0.032692644745111465
Loss at iteration 1110 : 0.020219944417476654
Loss at iteration 1120 : 0.032201461493968964
Loss at iteration 1130 : 0.029106467962265015
Loss at iteration 1140 : 0.023647772148251534
Loss at iteration 1150 : 0.028191683813929558
Loss at iteration 1160 : 0.016170505434274673
Loss at iteration 1170 : 0.027004653587937355
Loss at iteration 1180 : 0.02298721671104431
Loss at iteration 1190 : 0.021614138036966324
Loss at iteration 1200 : 0.03213413059711456
Loss at iteration 1210 : 0.022108953446149826
The SSIM Value is: 0.7697248299916585
The PSNR Value is: 17.90903466542562
the epoch is: 25
Loss at iteration 10 : 0.020366590470075607
Loss at iteration 20 : 0.021136058494448662
Loss at iteration 30 : 0.027843819931149483
Loss at iteration 40 : 0.02939056046307087
Loss at iteration 50 : 0.02666063979268074
Loss at iteration 60 : 0.03157429024577141
Loss at iteration 70 : 0.02090969681739807
Loss at iteration 80 : 0.017955254763364792
Loss at iteration 90 : 0.02374340407550335
Loss at iteration 100 : 0.028039850294589996
Loss at iteration 110 : 0.05671617388725281
Loss at iteration 120 : 0.023242665454745293
Loss at iteration 130 : 0.030074402689933777
Loss at iteration 140 : 0.016605593264102936
Loss at iteration 150 : 0.023402035236358643
Loss at iteration 160 : 0.029771581292152405
Loss at iteration 170 : 0.028687763959169388
Loss at iteration 180 : 0.015901248902082443
Loss at iteration 190 : 0.01428663358092308
Loss at iteration 200 : 0.030654875561594963
Loss at iteration 210 : 0.025282226502895355
Loss at iteration 220 : 0.022669270634651184
Loss at iteration 230 : 0.01524184737354517
Loss at iteration 240 : 0.031081590801477432
Loss at iteration 250 : 0.028787918388843536
Loss at iteration 260 : 0.03355015069246292
Loss at iteration 270 : 0.01676340214908123
Loss at iteration 280 : 0.030419722199440002
Loss at iteration 290 : 0.018566256389021873
Loss at iteration 300 : 0.017490383237600327
Loss at iteration 310 : 0.012723475694656372
Loss at iteration 320 : 0.03221183270215988
Loss at iteration 330 : 0.029586145654320717
Loss at iteration 340 : 0.01860092207789421
Loss at iteration 350 : 0.02095855586230755
Loss at iteration 360 : 0.02892041578888893
Loss at iteration 370 : 0.025161083787679672
Loss at iteration 380 : 0.0229690782725811
Loss at iteration 390 : 0.016532443463802338
Loss at iteration 400 : 0.022978000342845917
Loss at iteration 410 : 0.029962360858917236
Loss at iteration 420 : 0.031648218631744385
Loss at iteration 430 : 0.032473374158144
Loss at iteration 440 : 0.030286721885204315
Loss at iteration 450 : 0.017332948744297028
Loss at iteration 460 : 0.02625853940844536
Loss at iteration 470 : 0.022513151168823242
Loss at iteration 480 : 0.021526698023080826
Loss at iteration 490 : 0.031972430646419525
Loss at iteration 500 : 0.02286885492503643
Loss at iteration 510 : 0.02958708256483078
Loss at iteration 520 : 0.023798290640115738
Loss at iteration 530 : 0.019455406814813614
Loss at iteration 540 : 0.022610759362578392
Loss at iteration 550 : 0.02127738483250141
Loss at iteration 560 : 0.027591349557042122
Loss at iteration 570 : 0.018818188458681107
Loss at iteration 580 : 0.01550027821213007
Loss at iteration 590 : 0.02425842173397541
Loss at iteration 600 : 0.035888802260160446
Loss at iteration 610 : 0.024179719388484955
Loss at iteration 620 : 0.029818613082170486
Loss at iteration 630 : 0.021063517779111862
Loss at iteration 640 : 0.03689752146601677
Loss at iteration 650 : 0.018096458166837692
Loss at iteration 660 : 0.02665778435766697
Loss at iteration 670 : 0.03338026627898216
Loss at iteration 680 : 0.02631155401468277
Loss at iteration 690 : 0.01865367218852043
Loss at iteration 700 : 0.031617697328329086
Loss at iteration 710 : 0.023765647783875465
Loss at iteration 720 : 0.032607369124889374
Loss at iteration 730 : 0.0209686066955328
Loss at iteration 740 : 0.018997754901647568
Loss at iteration 750 : 0.023140951991081238
Loss at iteration 760 : 0.02633829414844513
Loss at iteration 770 : 0.01913362368941307
Loss at iteration 780 : 0.024091511964797974
Loss at iteration 790 : 0.014160248450934887
Loss at iteration 800 : 0.02001108042895794
Loss at iteration 810 : 0.027036180719733238
Loss at iteration 820 : 0.02780449204146862
Loss at iteration 830 : 0.03011968918144703
Loss at iteration 840 : 0.027723021805286407
Loss at iteration 850 : 0.04817730933427811
Loss at iteration 860 : 0.039246395230293274
Loss at iteration 870 : 0.030236393213272095
Loss at iteration 880 : 0.06261260062456131
Loss at iteration 890 : 0.030662868171930313
Loss at iteration 900 : 0.021124767139554024
Loss at iteration 910 : 0.02740570157766342
Loss at iteration 920 : 0.027357332408428192
Loss at iteration 930 : 0.02690763957798481
Loss at iteration 940 : 0.03485614061355591
Loss at iteration 950 : 0.03188057243824005
Loss at iteration 960 : 0.024976558983325958
Loss at iteration 970 : 0.01612757332623005
Loss at iteration 980 : 0.023506764322519302
Loss at iteration 990 : 0.023144159466028214
Loss at iteration 1000 : 0.03067152202129364
Loss at iteration 1010 : 0.02252212166786194
Loss at iteration 1020 : 0.022655757144093513
Loss at iteration 1030 : 0.026994995772838593
Loss at iteration 1040 : 0.02507317252457142
Loss at iteration 1050 : 0.029568426311016083
Loss at iteration 1060 : 0.024362636730074883
Loss at iteration 1070 : 0.03310403972864151
Loss at iteration 1080 : 0.023296590894460678
Loss at iteration 1090 : 0.014983774162828922
Loss at iteration 1100 : 0.023309864103794098
Loss at iteration 1110 : 0.023865822702646255
Loss at iteration 1120 : 0.023418009281158447
Loss at iteration 1130 : 0.04355984181165695
Loss at iteration 1140 : 0.023507528007030487
Loss at iteration 1150 : 0.03059849515557289
Loss at iteration 1160 : 0.01404481753706932
Loss at iteration 1170 : 0.017235949635505676
Loss at iteration 1180 : 0.026813937351107597
Loss at iteration 1190 : 0.026097601279616356
Loss at iteration 1200 : 0.011643385514616966
Loss at iteration 1210 : 0.027350125834345818
The SSIM Value is: 0.7665416320164998
The PSNR Value is: 18.07293961842855
the epoch is: 26
Loss at iteration 10 : 0.026738330721855164
Loss at iteration 20 : 0.04843135178089142
Loss at iteration 30 : 0.03736124187707901
Loss at iteration 40 : 0.020830556750297546
Loss at iteration 50 : 0.023774288594722748
Loss at iteration 60 : 0.031782835721969604
Loss at iteration 70 : 0.026814211159944534
Loss at iteration 80 : 0.04084816947579384
Loss at iteration 90 : 0.01770791783928871
Loss at iteration 100 : 0.038748644292354584
Loss at iteration 110 : 0.026559600606560707
Loss at iteration 120 : 0.026617733761668205
Loss at iteration 130 : 0.029234619811177254
Loss at iteration 140 : 0.022474080324172974
Loss at iteration 150 : 0.02530786767601967
Loss at iteration 160 : 0.037391845136880875
Loss at iteration 170 : 0.024173486977815628
Loss at iteration 180 : 0.03427528589963913
Loss at iteration 190 : 0.025128833949565887
Loss at iteration 200 : 0.034752458333969116
Loss at iteration 210 : 0.020881760865449905
Loss at iteration 220 : 0.024876471608877182
Loss at iteration 230 : 0.0330449603497982
Loss at iteration 240 : 0.02150610461831093
Loss at iteration 250 : 0.03391053155064583
Loss at iteration 260 : 0.02604285255074501
Loss at iteration 270 : 0.020588543266057968
Loss at iteration 280 : 0.03195680305361748
Loss at iteration 290 : 0.027515407651662827
Loss at iteration 300 : 0.01972360722720623
Loss at iteration 310 : 0.01756424829363823
Loss at iteration 320 : 0.03329933434724808
Loss at iteration 330 : 0.02008243463933468
Loss at iteration 340 : 0.024381747469305992
Loss at iteration 350 : 0.017217764630913734
Loss at iteration 360 : 0.017181159928441048
Loss at iteration 370 : 0.02639969065785408
Loss at iteration 380 : 0.01869550719857216
Loss at iteration 390 : 0.02820519730448723
Loss at iteration 400 : 0.018365100026130676
Loss at iteration 410 : 0.02509417198598385
Loss at iteration 420 : 0.03532402962446213
Loss at iteration 430 : 0.030062923207879066
Loss at iteration 440 : 0.02812604233622551
Loss at iteration 450 : 0.03932199254631996
Loss at iteration 460 : 0.019578829407691956
Loss at iteration 470 : 0.028533935546875
Loss at iteration 480 : 0.026271646842360497
Loss at iteration 490 : 0.047598861157894135
Loss at iteration 500 : 0.031864456832408905
Loss at iteration 510 : 0.02444034442305565
Loss at iteration 520 : 0.0323299914598465
Loss at iteration 530 : 0.022297052666544914
Loss at iteration 540 : 0.029929853975772858
Loss at iteration 550 : 0.03370904177427292
Loss at iteration 560 : 0.021832667291164398
Loss at iteration 570 : 0.03053775057196617
Loss at iteration 580 : 0.031767360866069794
Loss at iteration 590 : 0.032481420785188675
Loss at iteration 600 : 0.04141046106815338
Loss at iteration 610 : 0.017566869035363197
Loss at iteration 620 : 0.03098805621266365
Loss at iteration 630 : 0.0348646380007267
Loss at iteration 640 : 0.023613017052412033
Loss at iteration 650 : 0.029201410710811615
Loss at iteration 660 : 0.025506600737571716
Loss at iteration 670 : 0.0254349522292614
Loss at iteration 680 : 0.020377669483423233
Loss at iteration 690 : 0.03454277664422989
Loss at iteration 700 : 0.02271066978573799
Loss at iteration 710 : 0.012029081583023071
Loss at iteration 720 : 0.032954975962638855
Loss at iteration 730 : 0.02428009919822216
Loss at iteration 740 : 0.03297979384660721
Loss at iteration 750 : 0.025216177105903625
Loss at iteration 760 : 0.03296022489666939
Loss at iteration 770 : 0.03601554408669472
Loss at iteration 780 : 0.0370364636182785
Loss at iteration 790 : 0.03356502577662468
Loss at iteration 800 : 0.03125150501728058
Loss at iteration 810 : 0.025256628170609474
Loss at iteration 820 : 0.030383940786123276
Loss at iteration 830 : 0.01619662716984749
Loss at iteration 840 : 0.022992590442299843
Loss at iteration 850 : 0.04091258719563484
Loss at iteration 860 : 0.01850045472383499
Loss at iteration 870 : 0.01810479909181595
Loss at iteration 880 : 0.029293926432728767
Loss at iteration 890 : 0.025338945910334587
Loss at iteration 900 : 0.028332354500889778
Loss at iteration 910 : 0.020528187975287437
Loss at iteration 920 : 0.0374319925904274
Loss at iteration 930 : 0.0357205905020237
Loss at iteration 940 : 0.030283071100711823
Loss at iteration 950 : 0.02780359797179699
Loss at iteration 960 : 0.029198501259088516
Loss at iteration 970 : 0.026937682181596756
Loss at iteration 980 : 0.01918751373887062
Loss at iteration 990 : 0.023754026740789413
Loss at iteration 1000 : 0.019503384828567505
Loss at iteration 1010 : 0.02701054885983467
Loss at iteration 1020 : 0.022082824259996414
Loss at iteration 1030 : 0.023157551884651184
Loss at iteration 1040 : 0.01994149014353752
Loss at iteration 1050 : 0.02412322536110878
Loss at iteration 1060 : 0.03651001304388046
Loss at iteration 1070 : 0.024657806381583214
Loss at iteration 1080 : 0.012849564664065838
Loss at iteration 1090 : 0.0241016186773777
Loss at iteration 1100 : 0.03443940356373787
Loss at iteration 1110 : 0.027703266590833664
Loss at iteration 1120 : 0.02229449152946472
Loss at iteration 1130 : 0.017558259889483452
Loss at iteration 1140 : 0.017748259007930756
Loss at iteration 1150 : 0.027058955281972885
Loss at iteration 1160 : 0.012012917548418045
Loss at iteration 1170 : 0.04122734069824219
Loss at iteration 1180 : 0.03477366268634796
Loss at iteration 1190 : 0.022749125957489014
Loss at iteration 1200 : 0.017184535041451454
Loss at iteration 1210 : 0.03237606957554817
The SSIM Value is: 0.7743115822474161
The PSNR Value is: 17.979016558329263
the epoch is: 27
Loss at iteration 10 : 0.022837314754724503
Loss at iteration 20 : 0.03658730164170265
Loss at iteration 30 : 0.040811166167259216
Loss at iteration 40 : 0.02583199180662632
Loss at iteration 50 : 0.01689448021352291
Loss at iteration 60 : 0.020364370197057724
Loss at iteration 70 : 0.021694570779800415
Loss at iteration 80 : 0.01806693896651268
Loss at iteration 90 : 0.018153008073568344
Loss at iteration 100 : 0.01985662616789341
Loss at iteration 110 : 0.01613733172416687
Loss at iteration 120 : 0.029313916340470314
Loss at iteration 130 : 0.017502788454294205
Loss at iteration 140 : 0.030575810000300407
Loss at iteration 150 : 0.01797894574701786
Loss at iteration 160 : 0.027531133964657784
Loss at iteration 170 : 0.02632119134068489
Loss at iteration 180 : 0.022745296359062195
Loss at iteration 190 : 0.02428513951599598
Loss at iteration 200 : 0.02391396090388298
Loss at iteration 210 : 0.012662834487855434
Loss at iteration 220 : 0.019953638315200806
Loss at iteration 230 : 0.0428302064538002
Loss at iteration 240 : 0.04886167496442795
Loss at iteration 250 : 0.01857703924179077
Loss at iteration 260 : 0.022346001118421555
Loss at iteration 270 : 0.024434614926576614
Loss at iteration 280 : 0.0284675695002079
Loss at iteration 290 : 0.033176176249980927
Loss at iteration 300 : 0.02799094468355179
Loss at iteration 310 : 0.03595370799303055
Loss at iteration 320 : 0.021739412099123
Loss at iteration 330 : 0.019736237823963165
Loss at iteration 340 : 0.045242682099342346
Loss at iteration 350 : 0.02290661260485649
Loss at iteration 360 : 0.028738057240843773
Loss at iteration 370 : 0.03471001982688904
Loss at iteration 380 : 0.016809910535812378
Loss at iteration 390 : 0.02214631624519825
Loss at iteration 400 : 0.014718284830451012
Loss at iteration 410 : 0.023908119648694992
Loss at iteration 420 : 0.025400161743164062
Loss at iteration 430 : 0.02047393098473549
Loss at iteration 440 : 0.019373459741473198
Loss at iteration 450 : 0.02811187505722046
Loss at iteration 460 : 0.028048086911439896
Loss at iteration 470 : 0.02566266804933548
Loss at iteration 480 : 0.02254369854927063
Loss at iteration 490 : 0.024892233312129974
Loss at iteration 500 : 0.021284539252519608
Loss at iteration 510 : 0.033150725066661835
Loss at iteration 520 : 0.053811222314834595
Loss at iteration 530 : 0.02358090505003929
Loss at iteration 540 : 0.03162047639489174
Loss at iteration 550 : 0.027364123612642288
Loss at iteration 560 : 0.02141420543193817
Loss at iteration 570 : 0.0385572612285614
Loss at iteration 580 : 0.024463269859552383
Loss at iteration 590 : 0.011773189529776573
Loss at iteration 600 : 0.035418421030044556
Loss at iteration 610 : 0.025884704664349556
Loss at iteration 620 : 0.025294305756688118
Loss at iteration 630 : 0.01863805577158928
Loss at iteration 640 : 0.02428635023534298
Loss at iteration 650 : 0.029348500072956085
Loss at iteration 660 : 0.027295319363474846
Loss at iteration 670 : 0.016339600086212158
Loss at iteration 680 : 0.03364093601703644
Loss at iteration 690 : 0.02663145400583744
Loss at iteration 700 : 0.03086368925869465
Loss at iteration 710 : 0.02710941806435585
Loss at iteration 720 : 0.027889471501111984
Loss at iteration 730 : 0.026911545544862747
Loss at iteration 740 : 0.015127962455153465
Loss at iteration 750 : 0.024486519396305084
Loss at iteration 760 : 0.029804613441228867
Loss at iteration 770 : 0.03950996696949005
Loss at iteration 780 : 0.02689901366829872
Loss at iteration 790 : 0.027276303619146347
Loss at iteration 800 : 0.021454187110066414
Loss at iteration 810 : 0.03930940851569176
Loss at iteration 820 : 0.036701466888189316
Loss at iteration 830 : 0.022669751197099686
Loss at iteration 840 : 0.026857448741793633
Loss at iteration 850 : 0.022386256605386734
Loss at iteration 860 : 0.026719719171524048
Loss at iteration 870 : 0.021924110129475594
Loss at iteration 880 : 0.032971519976854324
Loss at iteration 890 : 0.029835805296897888
Loss at iteration 900 : 0.031230052933096886
Loss at iteration 910 : 0.017328057438135147
Loss at iteration 920 : 0.02559875324368477
Loss at iteration 930 : 0.046896860003471375
Loss at iteration 940 : 0.02309693768620491
Loss at iteration 950 : 0.028000347316265106
Loss at iteration 960 : 0.02603808604180813
Loss at iteration 970 : 0.030458901077508926
Loss at iteration 980 : 0.018317844718694687
Loss at iteration 990 : 0.027912579476833344
Loss at iteration 1000 : 0.026786968111991882
Loss at iteration 1010 : 0.03642721474170685
Loss at iteration 1020 : 0.021537374705076218
Loss at iteration 1030 : 0.017869310453534126
Loss at iteration 1040 : 0.024876801297068596
Loss at iteration 1050 : 0.02198585495352745
Loss at iteration 1060 : 0.018500367179512978
Loss at iteration 1070 : 0.02520410344004631
Loss at iteration 1080 : 0.025191323831677437
Loss at iteration 1090 : 0.0253691878169775
Loss at iteration 1100 : 0.026901785284280777
Loss at iteration 1110 : 0.03101934678852558
Loss at iteration 1120 : 0.013869699090719223
Loss at iteration 1130 : 0.031227240338921547
Loss at iteration 1140 : 0.025997426360845566
Loss at iteration 1150 : 0.017913365736603737
Loss at iteration 1160 : 0.021705262362957
Loss at iteration 1170 : 0.02149915136396885
Loss at iteration 1180 : 0.02505551278591156
Loss at iteration 1190 : 0.02089284174144268
Loss at iteration 1200 : 0.03337853401899338
Loss at iteration 1210 : 0.02145363949239254
The SSIM Value is: 0.7726091623306275
The PSNR Value is: 17.867621612548827
the epoch is: 28
Loss at iteration 10 : 0.0274761151522398
Loss at iteration 20 : 0.026012646034359932
Loss at iteration 30 : 0.024875672534108162
Loss at iteration 40 : 0.022986147552728653
Loss at iteration 50 : 0.0308554507791996
Loss at iteration 60 : 0.022224683314561844
Loss at iteration 70 : 0.02536085620522499
Loss at iteration 80 : 0.03329500928521156
Loss at iteration 90 : 0.02164730429649353
Loss at iteration 100 : 0.018860526382923126
Loss at iteration 110 : 0.016963856294751167
Loss at iteration 120 : 0.0282551608979702
Loss at iteration 130 : 0.019561516121029854
Loss at iteration 140 : 0.016497740522027016
Loss at iteration 150 : 0.020732255652546883
Loss at iteration 160 : 0.025892237201333046
Loss at iteration 170 : 0.019111769273877144
Loss at iteration 180 : 0.022046750411391258
Loss at iteration 190 : 0.022558771073818207
Loss at iteration 200 : 0.02642858400940895
Loss at iteration 210 : 0.023780081421136856
Loss at iteration 220 : 0.027820920571684837
Loss at iteration 230 : 0.027805935591459274
Loss at iteration 240 : 0.02694985829293728
Loss at iteration 250 : 0.03286983072757721
Loss at iteration 260 : 0.042906396090984344
Loss at iteration 270 : 0.029221098870038986
Loss at iteration 280 : 0.03405075892806053
Loss at iteration 290 : 0.025810670107603073
Loss at iteration 300 : 0.029403721913695335
Loss at iteration 310 : 0.026693588122725487
Loss at iteration 320 : 0.021363647654652596
Loss at iteration 330 : 0.04301322251558304
Loss at iteration 340 : 0.023584507405757904
Loss at iteration 350 : 0.020116275176405907
Loss at iteration 360 : 0.01655447855591774
Loss at iteration 370 : 0.042308736592531204
Loss at iteration 380 : 0.0331314355134964
Loss at iteration 390 : 0.02705508843064308
Loss at iteration 400 : 0.02154478058218956
Loss at iteration 410 : 0.02168305590748787
Loss at iteration 420 : 0.02298595756292343
Loss at iteration 430 : 0.027393244206905365
Loss at iteration 440 : 0.013221612200140953
Loss at iteration 450 : 0.03282390534877777
Loss at iteration 460 : 0.023365389555692673
Loss at iteration 470 : 0.032446764409542084
Loss at iteration 480 : 0.021566279232501984
Loss at iteration 490 : 0.024400707334280014
Loss at iteration 500 : 0.02553529664874077
Loss at iteration 510 : 0.042340755462646484
Loss at iteration 520 : 0.01945967972278595
Loss at iteration 530 : 0.030626563355326653
Loss at iteration 540 : 0.021289195865392685
Loss at iteration 550 : 0.030578427016735077
Loss at iteration 560 : 0.024034179747104645
Loss at iteration 570 : 0.02281203679740429
Loss at iteration 580 : 0.022142581641674042
Loss at iteration 590 : 0.017235444858670235
Loss at iteration 600 : 0.029393259435892105
Loss at iteration 610 : 0.028881749138236046
Loss at iteration 620 : 0.029372485354542732
Loss at iteration 630 : 0.03889736533164978
Loss at iteration 640 : 0.033146265894174576
Loss at iteration 650 : 0.027672596275806427
Loss at iteration 660 : 0.024750590324401855
Loss at iteration 670 : 0.016673311591148376
Loss at iteration 680 : 0.021278155967593193
Loss at iteration 690 : 0.024761198088526726
Loss at iteration 700 : 0.022725004702806473
Loss at iteration 710 : 0.02233286201953888
Loss at iteration 720 : 0.016501519829034805
Loss at iteration 730 : 0.01642071083188057
Loss at iteration 740 : 0.021492376923561096
Loss at iteration 750 : 0.024630405008792877
Loss at iteration 760 : 0.029249828308820724
Loss at iteration 770 : 0.03243696689605713
Loss at iteration 780 : 0.03048545867204666
Loss at iteration 790 : 0.020425602793693542
Loss at iteration 800 : 0.03991027921438217
Loss at iteration 810 : 0.02496776357293129
Loss at iteration 820 : 0.026806479319930077
Loss at iteration 830 : 0.03206530958414078
Loss at iteration 840 : 0.04021339491009712
Loss at iteration 850 : 0.02784430794417858
Loss at iteration 860 : 0.02893991954624653
Loss at iteration 870 : 0.018040809780359268
Loss at iteration 880 : 0.038935571908950806
Loss at iteration 890 : 0.026625022292137146
Loss at iteration 900 : 0.029129598289728165
Loss at iteration 910 : 0.023657701909542084
Loss at iteration 920 : 0.037091583013534546
Loss at iteration 930 : 0.013855675235390663
Loss at iteration 940 : 0.023107878863811493
Loss at iteration 950 : 0.03743559867143631
Loss at iteration 960 : 0.026925677433609962
Loss at iteration 970 : 0.036511730402708054
Loss at iteration 980 : 0.034591272473335266
Loss at iteration 990 : 0.032443609088659286
Loss at iteration 1000 : 0.02291165664792061
Loss at iteration 1010 : 0.025444118306040764
Loss at iteration 1020 : 0.026493022218346596
Loss at iteration 1030 : 0.028603974729776382
Loss at iteration 1040 : 0.03326261043548584
Loss at iteration 1050 : 0.05174601823091507
Loss at iteration 1060 : 0.027616441249847412
Loss at iteration 1070 : 0.03634404391050339
Loss at iteration 1080 : 0.02249501459300518
Loss at iteration 1090 : 0.024299561977386475
Loss at iteration 1100 : 0.02620222046971321
Loss at iteration 1110 : 0.03940895199775696
Loss at iteration 1120 : 0.028343478217720985
Loss at iteration 1130 : 0.022137390449643135
Loss at iteration 1140 : 0.019417844712734222
Loss at iteration 1150 : 0.024623099714517593
Loss at iteration 1160 : 0.02006647363305092
Loss at iteration 1170 : 0.024906937032938004
Loss at iteration 1180 : 0.018920734524726868
Loss at iteration 1190 : 0.0237039215862751
Loss at iteration 1200 : 0.03640344738960266
Loss at iteration 1210 : 0.020182322710752487
The SSIM Value is: 0.7666091720263163
The PSNR Value is: 17.10709374745687
the epoch is: 29
Loss at iteration 10 : 0.01933875121176243
Loss at iteration 20 : 0.026759985834360123
Loss at iteration 30 : 0.0399320088326931
Loss at iteration 40 : 0.037171877920627594
Loss at iteration 50 : 0.030690211802721024
Loss at iteration 60 : 0.021489597856998444
Loss at iteration 70 : 0.044087834656238556
Loss at iteration 80 : 0.023765642195940018
Loss at iteration 90 : 0.02385769411921501
Loss at iteration 100 : 0.021638277918100357
Loss at iteration 110 : 0.017727017402648926
Loss at iteration 120 : 0.022264651954174042
Loss at iteration 130 : 0.01945595070719719
Loss at iteration 140 : 0.016253069043159485
Loss at iteration 150 : 0.020799782127141953
Loss at iteration 160 : 0.02065127342939377
Loss at iteration 170 : 0.035559214651584625
Loss at iteration 180 : 0.016806671395897865
Loss at iteration 190 : 0.042120080441236496
Loss at iteration 200 : 0.032916609197854996
Loss at iteration 210 : 0.013866759836673737
Loss at iteration 220 : 0.01448250375688076
Loss at iteration 230 : 0.01965920627117157
Loss at iteration 240 : 0.019245119765400887
Loss at iteration 250 : 0.02302098646759987
Loss at iteration 260 : 0.05361286923289299
Loss at iteration 270 : 0.02025604620575905
Loss at iteration 280 : 0.025382831692695618
Loss at iteration 290 : 0.02272767946124077
Loss at iteration 300 : 0.014719381928443909
Loss at iteration 310 : 0.025517486035823822
Loss at iteration 320 : 0.02305392548441887
Loss at iteration 330 : 0.018437707796692848
Loss at iteration 340 : 0.025851234793663025
Loss at iteration 350 : 0.032186515629291534
Loss at iteration 360 : 0.03371952101588249
Loss at iteration 370 : 0.021606983616948128
Loss at iteration 380 : 0.03103705123066902
Loss at iteration 390 : 0.025517061352729797
Loss at iteration 400 : 0.03895241767168045
Loss at iteration 410 : 0.02351461537182331
Loss at iteration 420 : 0.023614486679434776
Loss at iteration 430 : 0.027656549587845802
Loss at iteration 440 : 0.03969678282737732
Loss at iteration 450 : 0.018312392756342888
Loss at iteration 460 : 0.025057103484869003
Loss at iteration 470 : 0.024738024920225143
Loss at iteration 480 : 0.01835683360695839
Loss at iteration 490 : 0.022564083337783813
Loss at iteration 500 : 0.030071184039115906
Loss at iteration 510 : 0.02861778810620308
Loss at iteration 520 : 0.02783902920782566
Loss at iteration 530 : 0.023728415369987488
Loss at iteration 540 : 0.02568550407886505
Loss at iteration 550 : 0.021748656406998634
Loss at iteration 560 : 0.035055793821811676
Loss at iteration 570 : 0.02554963529109955
Loss at iteration 580 : 0.023557238280773163
Loss at iteration 590 : 0.022890781983733177
Loss at iteration 600 : 0.023346947506070137
Loss at iteration 610 : 0.034504689276218414
Loss at iteration 620 : 0.03500797972083092
Loss at iteration 630 : 0.022548794746398926
Loss at iteration 640 : 0.03411059454083443
Loss at iteration 650 : 0.037547092884778976
Loss at iteration 660 : 0.018738102167844772
Loss at iteration 670 : 0.023731574416160583
Loss at iteration 680 : 0.02540265955030918
Loss at iteration 690 : 0.013442674651741982
Loss at iteration 700 : 0.04344737529754639
Loss at iteration 710 : 0.03129164129495621
Loss at iteration 720 : 0.034941159188747406
Loss at iteration 730 : 0.03618248552083969
Loss at iteration 740 : 0.020125562325119972
Loss at iteration 750 : 0.027113012969493866
Loss at iteration 760 : 0.027791563421487808
Loss at iteration 770 : 0.019399523735046387
Loss at iteration 780 : 0.017336972057819366
Loss at iteration 790 : 0.05740712955594063
Loss at iteration 800 : 0.035080164670944214
Loss at iteration 810 : 0.06574676930904388
Loss at iteration 820 : 0.03031584434211254
Loss at iteration 830 : 0.024375304579734802
Loss at iteration 840 : 0.031347621232271194
Loss at iteration 850 : 0.025879165157675743
Loss at iteration 860 : 0.01661945879459381
Loss at iteration 870 : 0.039262913167476654
Loss at iteration 880 : 0.04419570788741112
Loss at iteration 890 : 0.043715618550777435
Loss at iteration 900 : 0.023349465802311897
Loss at iteration 910 : 0.027240611612796783
Loss at iteration 920 : 0.04148898646235466
Loss at iteration 930 : 0.019033389165997505
Loss at iteration 940 : 0.030942097306251526
Loss at iteration 950 : 0.02213873341679573
Loss at iteration 960 : 0.018342547118663788
Loss at iteration 970 : 0.017302654683589935
Loss at iteration 980 : 0.02111556939780712
Loss at iteration 990 : 0.044488728046417236
Loss at iteration 1000 : 0.022249307483434677
Loss at iteration 1010 : 0.015914497897028923
Loss at iteration 1020 : 0.014107681810855865
Loss at iteration 1030 : 0.03024326264858246
Loss at iteration 1040 : 0.03625117987394333
Loss at iteration 1050 : 0.02662724256515503
Loss at iteration 1060 : 0.025546099990606308
Loss at iteration 1070 : 0.030214598402380943
Loss at iteration 1080 : 0.018289227038621902
Loss at iteration 1090 : 0.021087702363729477
Loss at iteration 1100 : 0.030405016615986824
Loss at iteration 1110 : 0.01955500803887844
Loss at iteration 1120 : 0.02955331839621067
Loss at iteration 1130 : 0.02480914443731308
Loss at iteration 1140 : 0.03255504369735718
Loss at iteration 1150 : 0.03086283802986145
Loss at iteration 1160 : 0.040180131793022156
Loss at iteration 1170 : 0.02494056709110737
Loss at iteration 1180 : 0.02449336275458336
Loss at iteration 1190 : 0.02323833853006363
Loss at iteration 1200 : 0.03118625283241272
Loss at iteration 1210 : 0.054056745022535324
The SSIM Value is: 0.7708847880363464
The PSNR Value is: 17.939824612935386
the epoch is: 30
Loss at iteration 10 : 0.028195751830935478
Loss at iteration 20 : 0.019643263891339302
Loss at iteration 30 : 0.022747477516531944
Loss at iteration 40 : 0.03245937079191208
Loss at iteration 50 : 0.032460931688547134
Loss at iteration 60 : 0.025525547564029694
Loss at iteration 70 : 0.015272821299731731
Loss at iteration 80 : 0.024252675473690033
Loss at iteration 90 : 0.026774942874908447
Loss at iteration 100 : 0.03667965158820152
Loss at iteration 110 : 0.02611187845468521
Loss at iteration 120 : 0.027894560247659683
Loss at iteration 130 : 0.018504673615098
Loss at iteration 140 : 0.03046521358191967
Loss at iteration 150 : 0.016897082328796387
Loss at iteration 160 : 0.021538984030485153
Loss at iteration 170 : 0.03152237460017204
Loss at iteration 180 : 0.02436784654855728
Loss at iteration 190 : 0.02321005053818226
Loss at iteration 200 : 0.03560243546962738
Loss at iteration 210 : 0.030213341116905212
Loss at iteration 220 : 0.01457413099706173
Loss at iteration 230 : 0.031644634902477264
Loss at iteration 240 : 0.019102348014712334
Loss at iteration 250 : 0.026579599827528
Loss at iteration 260 : 0.028117718175053596
Loss at iteration 270 : 0.040223054587841034
Loss at iteration 280 : 0.024336762726306915
Loss at iteration 290 : 0.026336094364523888
Loss at iteration 300 : 0.0301847942173481
Loss at iteration 310 : 0.02423100173473358
Loss at iteration 320 : 0.017581121996045113
Loss at iteration 330 : 0.023424843326210976
Loss at iteration 340 : 0.03036208637058735
Loss at iteration 350 : 0.029585663229227066
Loss at iteration 360 : 0.023937039077281952
Loss at iteration 370 : 0.014651047065854073
Loss at iteration 380 : 0.012517464347183704
Loss at iteration 390 : 0.03419548273086548
Loss at iteration 400 : 0.027626710012555122
Loss at iteration 410 : 0.03813567012548447
Loss at iteration 420 : 0.030820010229945183
Loss at iteration 430 : 0.018069453537464142
Loss at iteration 440 : 0.025837082415819168
Loss at iteration 450 : 0.01889253407716751
Loss at iteration 460 : 0.02599603682756424
Loss at iteration 470 : 0.025013459846377373
Loss at iteration 480 : 0.01565331220626831
Loss at iteration 490 : 0.025473477318882942
Loss at iteration 500 : 0.02003929764032364
Loss at iteration 510 : 0.03382180258631706
Loss at iteration 520 : 0.036972783505916595
Loss at iteration 530 : 0.02658274583518505
Loss at iteration 540 : 0.02222171239554882
Loss at iteration 550 : 0.01858450099825859
Loss at iteration 560 : 0.018449721857905388
Loss at iteration 570 : 0.03261271119117737
Loss at iteration 580 : 0.0289151594042778
Loss at iteration 590 : 0.011651722714304924
Loss at iteration 600 : 0.022612297907471657
Loss at iteration 610 : 0.015501407906413078
Loss at iteration 620 : 0.022820889949798584
Loss at iteration 630 : 0.018716007471084595
Loss at iteration 640 : 0.011066704988479614
Loss at iteration 650 : 0.026603195816278458
Loss at iteration 660 : 0.018508095294237137
Loss at iteration 670 : 0.04299348592758179
Loss at iteration 680 : 0.014484474435448647
Loss at iteration 690 : 0.027360066771507263
Loss at iteration 700 : 0.024910837411880493
Loss at iteration 710 : 0.03036963939666748
Loss at iteration 720 : 0.032295145094394684
Loss at iteration 730 : 0.015310498885810375
Loss at iteration 740 : 0.0272829569876194
Loss at iteration 750 : 0.027026943862438202
Loss at iteration 760 : 0.028801940381526947
Loss at iteration 770 : 0.03639364242553711
Loss at iteration 780 : 0.02529469132423401
Loss at iteration 790 : 0.033840667456388474
Loss at iteration 800 : 0.022232405841350555
Loss at iteration 810 : 0.02737906202673912
Loss at iteration 820 : 0.034190792590379715
Loss at iteration 830 : 0.0201142318546772
Loss at iteration 840 : 0.028060924261808395
Loss at iteration 850 : 0.024388989433646202
Loss at iteration 860 : 0.026143047958612442
Loss at iteration 870 : 0.02887704037129879
Loss at iteration 880 : 0.029942113906145096
Loss at iteration 890 : 0.019843047484755516
Loss at iteration 900 : 0.024561284109950066
Loss at iteration 910 : 0.02181384339928627
Loss at iteration 920 : 0.016439855098724365
Loss at iteration 930 : 0.039592236280441284
Loss at iteration 940 : 0.028643397614359856
Loss at iteration 950 : 0.021129019558429718
Loss at iteration 960 : 0.013882385566830635
Loss at iteration 970 : 0.022197075188159943
Loss at iteration 980 : 0.01946839690208435
Loss at iteration 990 : 0.02401665598154068
Loss at iteration 1000 : 0.039141058921813965
Loss at iteration 1010 : 0.03395972400903702
Loss at iteration 1020 : 0.027921341359615326
Loss at iteration 1030 : 0.02861030399799347
Loss at iteration 1040 : 0.026526786386966705
Loss at iteration 1050 : 0.02652142383158207
Loss at iteration 1060 : 0.027122382074594498
Loss at iteration 1070 : 0.024129053577780724
Loss at iteration 1080 : 0.04307006672024727
Loss at iteration 1090 : 0.011673598550260067
Loss at iteration 1100 : 0.023282352834939957
Loss at iteration 1110 : 0.02827012911438942
Loss at iteration 1120 : 0.021417003124952316
Loss at iteration 1130 : 0.0394754558801651
Loss at iteration 1140 : 0.027257351204752922
Loss at iteration 1150 : 0.023090481758117676
Loss at iteration 1160 : 0.035111404955387115
Loss at iteration 1170 : 0.023187611252069473
Loss at iteration 1180 : 0.02217535674571991
Loss at iteration 1190 : 0.027688043192029
Loss at iteration 1200 : 0.024185340851545334
Loss at iteration 1210 : 0.019691601395606995
The SSIM Value is: 0.7628489712874095
The PSNR Value is: 17.803464508056642
the epoch is: 31
Loss at iteration 10 : 0.028625931590795517
Loss at iteration 20 : 0.02447553537786007
Loss at iteration 30 : 0.014926642179489136
Loss at iteration 40 : 0.03424829989671707
Loss at iteration 50 : 0.03633300960063934
Loss at iteration 60 : 0.02364274114370346
Loss at iteration 70 : 0.028785785660147667
Loss at iteration 80 : 0.03338393568992615
Loss at iteration 90 : 0.04565506801009178
Loss at iteration 100 : 0.03683280944824219
Loss at iteration 110 : 0.023311438038945198
Loss at iteration 120 : 0.029505377635359764
Loss at iteration 130 : 0.024246778339147568
Loss at iteration 140 : 0.028044406324625015
Loss at iteration 150 : 0.016077272593975067
Loss at iteration 160 : 0.016677550971508026
Loss at iteration 170 : 0.030218202620744705
Loss at iteration 180 : 0.01783393695950508
Loss at iteration 190 : 0.018395921215415
Loss at iteration 200 : 0.024795806035399437
Loss at iteration 210 : 0.01961582526564598
Loss at iteration 220 : 0.01790890283882618
Loss at iteration 230 : 0.015484675765037537
Loss at iteration 240 : 0.02017049491405487
Loss at iteration 250 : 0.021398216485977173
Loss at iteration 260 : 0.02676929160952568
Loss at iteration 270 : 0.029077861458063126
Loss at iteration 280 : 0.01557155791670084
Loss at iteration 290 : 0.02952854335308075
Loss at iteration 300 : 0.02246834710240364
Loss at iteration 310 : 0.011902699247002602
Loss at iteration 320 : 0.04370635747909546
Loss at iteration 330 : 0.03249869868159294
Loss at iteration 340 : 0.029749296605587006
Loss at iteration 350 : 0.024623820558190346
Loss at iteration 360 : 0.0331096425652504
Loss at iteration 370 : 0.023608408868312836
Loss at iteration 380 : 0.02432943508028984
Loss at iteration 390 : 0.024256279692053795
Loss at iteration 400 : 0.013313503935933113
Loss at iteration 410 : 0.01921382173895836
Loss at iteration 420 : 0.01700093224644661
Loss at iteration 430 : 0.03502615913748741
Loss at iteration 440 : 0.018659446388483047
Loss at iteration 450 : 0.027474477887153625
Loss at iteration 460 : 0.022594034671783447
Loss at iteration 470 : 0.03627238795161247
Loss at iteration 480 : 0.036563124507665634
Loss at iteration 490 : 0.014180777594447136
Loss at iteration 500 : 0.026301652193069458
Loss at iteration 510 : 0.016806554049253464
Loss at iteration 520 : 0.021358676254749298
Loss at iteration 530 : 0.023677896708250046
Loss at iteration 540 : 0.026302417740225792
Loss at iteration 550 : 0.021477140486240387
Loss at iteration 560 : 0.027110032737255096
Loss at iteration 570 : 0.02618403360247612
Loss at iteration 580 : 0.02285139262676239
Loss at iteration 590 : 0.019278552383184433
Loss at iteration 600 : 0.020508546382188797
Loss at iteration 610 : 0.024534467607736588
Loss at iteration 620 : 0.026373915374279022
Loss at iteration 630 : 0.027538558468222618
Loss at iteration 640 : 0.027520952746272087
Loss at iteration 650 : 0.02114693447947502
Loss at iteration 660 : 0.03156907856464386
Loss at iteration 670 : 0.03413640707731247
Loss at iteration 680 : 0.011834070086479187
Loss at iteration 690 : 0.046143777668476105
Loss at iteration 700 : 0.04432273283600807
Loss at iteration 710 : 0.026668278500437737
Loss at iteration 720 : 0.024768879637122154
Loss at iteration 730 : 0.0459713377058506
Loss at iteration 740 : 0.030654141679406166
Loss at iteration 750 : 0.01596350409090519
Loss at iteration 760 : 0.023424625396728516
Loss at iteration 770 : 0.02282358705997467
Loss at iteration 780 : 0.026437507942318916
Loss at iteration 790 : 0.020304713398218155
Loss at iteration 800 : 0.018185516819357872
Loss at iteration 810 : 0.025425812229514122
Loss at iteration 820 : 0.0364769883453846
Loss at iteration 830 : 0.019101347774267197
Loss at iteration 840 : 0.018522584810853004
Loss at iteration 850 : 0.020045652985572815
Loss at iteration 860 : 0.03891723230481148
Loss at iteration 870 : 0.024837199598550797
Loss at iteration 880 : 0.03092612512409687
Loss at iteration 890 : 0.030739374458789825
Loss at iteration 900 : 0.025673167780041695
Loss at iteration 910 : 0.022590968757867813
Loss at iteration 920 : 0.03376155346632004
Loss at iteration 930 : 0.027192622423171997
Loss at iteration 940 : 0.0632152408361435
Loss at iteration 950 : 0.013305745087563992
Loss at iteration 960 : 0.03629288822412491
Loss at iteration 970 : 0.019391700625419617
Loss at iteration 980 : 0.0242031067609787
Loss at iteration 990 : 0.02453097514808178
Loss at iteration 1000 : 0.018864210695028305
Loss at iteration 1010 : 0.020646650344133377
Loss at iteration 1020 : 0.025545859709382057
Loss at iteration 1030 : 0.01695447787642479
Loss at iteration 1040 : 0.019769586622714996
Loss at iteration 1050 : 0.03402698040008545
Loss at iteration 1060 : 0.03162609785795212
Loss at iteration 1070 : 0.030604880303144455
Loss at iteration 1080 : 0.025186534970998764
Loss at iteration 1090 : 0.0233879666775465
Loss at iteration 1100 : 0.020061805844306946
Loss at iteration 1110 : 0.02283298969268799
Loss at iteration 1120 : 0.01867683045566082
Loss at iteration 1130 : 0.02887367270886898
Loss at iteration 1140 : 0.020261377096176147
Loss at iteration 1150 : 0.028837399557232857
Loss at iteration 1160 : 0.010414187796413898
Loss at iteration 1170 : 0.024068744853138924
Loss at iteration 1180 : 0.021775858476758003
Loss at iteration 1190 : 0.022534189745783806
Loss at iteration 1200 : 0.028073515743017197
Loss at iteration 1210 : 0.026664085686206818
The SSIM Value is: 0.7747962951660157
The PSNR Value is: 18.113511848449708
the epoch is: 32
Loss at iteration 10 : 0.024434197694063187
Loss at iteration 20 : 0.02719511091709137
Loss at iteration 30 : 0.020559493452310562
Loss at iteration 40 : 0.019884075969457626
Loss at iteration 50 : 0.022200169041752815
Loss at iteration 60 : 0.019622227177023888
Loss at iteration 70 : 0.01927867904305458
Loss at iteration 80 : 0.025199778378009796
Loss at iteration 90 : 0.016226641833782196
Loss at iteration 100 : 0.013632770627737045
Loss at iteration 110 : 0.016591211780905724
Loss at iteration 120 : 0.02807081677019596
Loss at iteration 130 : 0.02771933190524578
Loss at iteration 140 : 0.020144503563642502
Loss at iteration 150 : 0.02513844519853592
Loss at iteration 160 : 0.02875317446887493
Loss at iteration 170 : 0.024185068905353546
Loss at iteration 180 : 0.030306247994303703
Loss at iteration 190 : 0.022413451224565506
Loss at iteration 200 : 0.03468923643231392
Loss at iteration 210 : 0.03310367092490196
Loss at iteration 220 : 0.04980019852519035
Loss at iteration 230 : 0.040676552802324295
Loss at iteration 240 : 0.04156707599759102
Loss at iteration 250 : 0.028400756418704987
Loss at iteration 260 : 0.029867246747016907
Loss at iteration 270 : 0.028325337916612625
Loss at iteration 280 : 0.019307048991322517
Loss at iteration 290 : 0.027449995279312134
Loss at iteration 300 : 0.024387620389461517
Loss at iteration 310 : 0.03889835253357887
Loss at iteration 320 : 0.03279585391283035
Loss at iteration 330 : 0.014654083177447319
Loss at iteration 340 : 0.01754051074385643
Loss at iteration 350 : 0.023564346134662628
Loss at iteration 360 : 0.029287997633218765
Loss at iteration 370 : 0.02937963791191578
Loss at iteration 380 : 0.02033131942152977
Loss at iteration 390 : 0.03070114739239216
Loss at iteration 400 : 0.018113337457180023
Loss at iteration 410 : 0.032139286398887634
Loss at iteration 420 : 0.03884508088231087
Loss at iteration 430 : 0.041181229054927826
Loss at iteration 440 : 0.021118979901075363
Loss at iteration 450 : 0.020675139501690865
Loss at iteration 460 : 0.02890065498650074
Loss at iteration 470 : 0.026523824781179428
Loss at iteration 480 : 0.022122446447610855
Loss at iteration 490 : 0.02122313342988491
Loss at iteration 500 : 0.033173818141222
Loss at iteration 510 : 0.0251009538769722
Loss at iteration 520 : 0.026324398815631866
Loss at iteration 530 : 0.03578871488571167
Loss at iteration 540 : 0.03450891748070717
Loss at iteration 550 : 0.02485688403248787
Loss at iteration 560 : 0.024277012795209885
Loss at iteration 570 : 0.03273780643939972
Loss at iteration 580 : 0.028961237519979477
Loss at iteration 590 : 0.018957016989588737
Loss at iteration 600 : 0.017189472913742065
Loss at iteration 610 : 0.029484912753105164
Loss at iteration 620 : 0.03839939087629318
Loss at iteration 630 : 0.03101586177945137
Loss at iteration 640 : 0.01949116215109825
Loss at iteration 650 : 0.027079185470938683
Loss at iteration 660 : 0.013788961805403233
Loss at iteration 670 : 0.02097216062247753
Loss at iteration 680 : 0.02368699386715889
Loss at iteration 690 : 0.015312924981117249
Loss at iteration 700 : 0.02501208335161209
Loss at iteration 710 : 0.03060462325811386
Loss at iteration 720 : 0.02331175096333027
Loss at iteration 730 : 0.01776600256562233
Loss at iteration 740 : 0.02325558103621006
Loss at iteration 750 : 0.03574758768081665
Loss at iteration 760 : 0.021883167326450348
Loss at iteration 770 : 0.017484480515122414
Loss at iteration 780 : 0.03256648778915405
Loss at iteration 790 : 0.035213664174079895
Loss at iteration 800 : 0.02053392119705677
Loss at iteration 810 : 0.027377523481845856
Loss at iteration 820 : 0.02271231636404991
Loss at iteration 830 : 0.04185844212770462
Loss at iteration 840 : 0.04276713728904724
Loss at iteration 850 : 0.03613629937171936
Loss at iteration 860 : 0.036047741770744324
Loss at iteration 870 : 0.05494844168424606
Loss at iteration 880 : 0.017278917133808136
Loss at iteration 890 : 0.019215259701013565
Loss at iteration 900 : 0.03178563714027405
Loss at iteration 910 : 0.02670511230826378
Loss at iteration 920 : 0.02984597533941269
Loss at iteration 930 : 0.017724141478538513
Loss at iteration 940 : 0.026870235800743103
Loss at iteration 950 : 0.022912124171853065
Loss at iteration 960 : 0.039932042360305786
Loss at iteration 970 : 0.03208006173372269
Loss at iteration 980 : 0.03341694548726082
Loss at iteration 990 : 0.025624947622418404
Loss at iteration 1000 : 0.020285239443182945
Loss at iteration 1010 : 0.021035274490714073
Loss at iteration 1020 : 0.025313563644886017
Loss at iteration 1030 : 0.023874431848526
Loss at iteration 1040 : 0.04105488210916519
Loss at iteration 1050 : 0.026083583012223244
Loss at iteration 1060 : 0.02261320874094963
Loss at iteration 1070 : 0.022784322500228882
Loss at iteration 1080 : 0.020862290635704994
Loss at iteration 1090 : 0.03194357454776764
Loss at iteration 1100 : 0.027961410582065582
Loss at iteration 1110 : 0.014067195355892181
Loss at iteration 1120 : 0.03905286639928818
Loss at iteration 1130 : 0.049198079854249954
Loss at iteration 1140 : 0.022405561059713364
Loss at iteration 1150 : 0.026787836104631424
Loss at iteration 1160 : 0.025794997811317444
Loss at iteration 1170 : 0.020382672548294067
Loss at iteration 1180 : 0.03002799302339554
Loss at iteration 1190 : 0.028181616216897964
Loss at iteration 1200 : 0.022260550409555435
Loss at iteration 1210 : 0.029044706374406815
The SSIM Value is: 0.767672618230184
The PSNR Value is: 17.897919146219888
the epoch is: 33
Loss at iteration 10 : 0.016604505479335785
Loss at iteration 20 : 0.02617669850587845
Loss at iteration 30 : 0.03143902122974396
Loss at iteration 40 : 0.04607126861810684
Loss at iteration 50 : 0.02946563810110092
Loss at iteration 60 : 0.028201770037412643
Loss at iteration 70 : 0.021833665668964386
Loss at iteration 80 : 0.018015926703810692
Loss at iteration 90 : 0.02763490378856659
Loss at iteration 100 : 0.01706179603934288
Loss at iteration 110 : 0.028801949694752693
Loss at iteration 120 : 0.031168565154075623
Loss at iteration 130 : 0.040223900228738785
Loss at iteration 140 : 0.0321756936609745
Loss at iteration 150 : 0.026009730994701385
Loss at iteration 160 : 0.02998138964176178
Loss at iteration 170 : 0.043984346091747284
Loss at iteration 180 : 0.024396346881985664
Loss at iteration 190 : 0.03211595118045807
Loss at iteration 200 : 0.02276565507054329
Loss at iteration 210 : 0.018861524760723114
Loss at iteration 220 : 0.020888082683086395
Loss at iteration 230 : 0.009338390082120895
Loss at iteration 240 : 0.022091366350650787
Loss at iteration 250 : 0.03461490944027901
Loss at iteration 260 : 0.03959745168685913
Loss at iteration 270 : 0.0202836561948061
Loss at iteration 280 : 0.011492711491882801
Loss at iteration 290 : 0.026468005031347275
Loss at iteration 300 : 0.031234223395586014
Loss at iteration 310 : 0.02704232931137085
Loss at iteration 320 : 0.04004645347595215
Loss at iteration 330 : 0.024114660918712616
Loss at iteration 340 : 0.03874194249510765
Loss at iteration 350 : 0.02427736110985279
Loss at iteration 360 : 0.022736378014087677
Loss at iteration 370 : 0.026902958750724792
Loss at iteration 380 : 0.029031172394752502
Loss at iteration 390 : 0.020061705261468887
Loss at iteration 400 : 0.028438955545425415
Loss at iteration 410 : 0.02212788164615631
Loss at iteration 420 : 0.05173598229885101
Loss at iteration 430 : 0.024727817624807358
Loss at iteration 440 : 0.03329608216881752
Loss at iteration 450 : 0.02676159329712391
Loss at iteration 460 : 0.01754434034228325
Loss at iteration 470 : 0.05327746272087097
Loss at iteration 480 : 0.04152262955904007
Loss at iteration 490 : 0.025531746447086334
Loss at iteration 500 : 0.02176944725215435
Loss at iteration 510 : 0.031505368649959564
Loss at iteration 520 : 0.03809310495853424
Loss at iteration 530 : 0.041480306535959244
Loss at iteration 540 : 0.03185168653726578
Loss at iteration 550 : 0.02877546101808548
Loss at iteration 560 : 0.0223793163895607
Loss at iteration 570 : 0.031741730868816376
Loss at iteration 580 : 0.020091144368052483
Loss at iteration 590 : 0.0312199667096138
Loss at iteration 600 : 0.016465794295072556
Loss at iteration 610 : 0.031717926263809204
Loss at iteration 620 : 0.023010816425085068
Loss at iteration 630 : 0.022080689668655396
Loss at iteration 640 : 0.023136865347623825
Loss at iteration 650 : 0.02947079762816429
Loss at iteration 660 : 0.023798743262887
Loss at iteration 670 : 0.02557525783777237
Loss at iteration 680 : 0.022984331473708153
Loss at iteration 690 : 0.03052550181746483
Loss at iteration 700 : 0.02811330184340477
Loss at iteration 710 : 0.02358786016702652
Loss at iteration 720 : 0.038865476846694946
Loss at iteration 730 : 0.03248472884297371
Loss at iteration 740 : 0.03537119925022125
Loss at iteration 750 : 0.02566364035010338
Loss at iteration 760 : 0.015078438445925713
Loss at iteration 770 : 0.02210300974547863
Loss at iteration 780 : 0.026112694293260574
Loss at iteration 790 : 0.023294642567634583
Loss at iteration 800 : 0.016942650079727173
Loss at iteration 810 : 0.02751636505126953
Loss at iteration 820 : 0.02604508213698864
Loss at iteration 830 : 0.029936205595731735
Loss at iteration 840 : 0.02777768298983574
Loss at iteration 850 : 0.033253252506256104
Loss at iteration 860 : 0.018561292439699173
Loss at iteration 870 : 0.021597642451524734
Loss at iteration 880 : 0.04329022765159607
Loss at iteration 890 : 0.02604081481695175
Loss at iteration 900 : 0.020611446350812912
Loss at iteration 910 : 0.02428511530160904
Loss at iteration 920 : 0.033503949642181396
Loss at iteration 930 : 0.012097091414034367
Loss at iteration 940 : 0.03605976328253746
Loss at iteration 950 : 0.02713344618678093
Loss at iteration 960 : 0.02453000470995903
Loss at iteration 970 : 0.024452146142721176
Loss at iteration 980 : 0.019451137632131577
Loss at iteration 990 : 0.02055632323026657
Loss at iteration 1000 : 0.023369451984763145
Loss at iteration 1010 : 0.03153564780950546
Loss at iteration 1020 : 0.015282029286026955
Loss at iteration 1030 : 0.02448979765176773
Loss at iteration 1040 : 0.0113915354013443
Loss at iteration 1050 : 0.028601448982954025
Loss at iteration 1060 : 0.029444318264722824
Loss at iteration 1070 : 0.035995963960886
Loss at iteration 1080 : 0.020467154681682587
Loss at iteration 1090 : 0.02505255863070488
Loss at iteration 1100 : 0.0217556431889534
Loss at iteration 1110 : 0.027104942128062248
Loss at iteration 1120 : 0.015509132295846939
Loss at iteration 1130 : 0.025278624147176743
Loss at iteration 1140 : 0.026111971586942673
Loss at iteration 1150 : 0.02710353583097458
Loss at iteration 1160 : 0.027083195745944977
Loss at iteration 1170 : 0.021228915080428123
Loss at iteration 1180 : 0.03820483386516571
Loss at iteration 1190 : 0.02622806653380394
Loss at iteration 1200 : 0.023329205811023712
Loss at iteration 1210 : 0.01816919445991516
The SSIM Value is: 0.7657280842463176
The PSNR Value is: 18.003260803222656
the epoch is: 34
Loss at iteration 10 : 0.024582717567682266
Loss at iteration 20 : 0.020186563953757286
Loss at iteration 30 : 0.019923772662878036
Loss at iteration 40 : 0.03283095359802246
Loss at iteration 50 : 0.018900420516729355
Loss at iteration 60 : 0.021279940381646156
Loss at iteration 70 : 0.03394649922847748
Loss at iteration 80 : 0.032682210206985474
Loss at iteration 90 : 0.018505875021219254
Loss at iteration 100 : 0.010367458686232567
Loss at iteration 110 : 0.028008636087179184
Loss at iteration 120 : 0.03380430489778519
Loss at iteration 130 : 0.027119971811771393
Loss at iteration 140 : 0.02535073086619377
Loss at iteration 150 : 0.02319325879216194
Loss at iteration 160 : 0.03143821656703949
Loss at iteration 170 : 0.029689572751522064
Loss at iteration 180 : 0.024562247097492218
Loss at iteration 190 : 0.033022645860910416
Loss at iteration 200 : 0.02315111830830574
Loss at iteration 210 : 0.020018652081489563
Loss at iteration 220 : 0.025265440344810486
Loss at iteration 230 : 0.030001863837242126
Loss at iteration 240 : 0.01741635799407959
Loss at iteration 250 : 0.01871606335043907
Loss at iteration 260 : 0.01918436586856842
Loss at iteration 270 : 0.021919578313827515
Loss at iteration 280 : 0.030177490785717964
Loss at iteration 290 : 0.014943724498152733
Loss at iteration 300 : 0.03518214821815491
Loss at iteration 310 : 0.026179924607276917
Loss at iteration 320 : 0.02349427342414856
Loss at iteration 330 : 0.03099365159869194
Loss at iteration 340 : 0.024920102208852768
Loss at iteration 350 : 0.035859860479831696
Loss at iteration 360 : 0.02735101990401745
Loss at iteration 370 : 0.0343957394361496
Loss at iteration 380 : 0.03017653152346611
Loss at iteration 390 : 0.031241973862051964
Loss at iteration 400 : 0.026130735874176025
Loss at iteration 410 : 0.03052354045212269
Loss at iteration 420 : 0.04483023285865784
Loss at iteration 430 : 0.03046916238963604
Loss at iteration 440 : 0.016609547659754753
Loss at iteration 450 : 0.016897406429052353
Loss at iteration 460 : 0.03190082684159279
Loss at iteration 470 : 0.025717012584209442
Loss at iteration 480 : 0.02168172597885132
Loss at iteration 490 : 0.025022869929671288
Loss at iteration 500 : 0.03009631671011448
Loss at iteration 510 : 0.029712824150919914
Loss at iteration 520 : 0.027522364631295204
Loss at iteration 530 : 0.026265759021043777
Loss at iteration 540 : 0.023475509136915207
Loss at iteration 550 : 0.01368800364434719
Loss at iteration 560 : 0.021636944264173508
Loss at iteration 570 : 0.027678733691573143
Loss at iteration 580 : 0.01866164617240429
Loss at iteration 590 : 0.017848718911409378
Loss at iteration 600 : 0.05508942902088165
Loss at iteration 610 : 0.02490026131272316
Loss at iteration 620 : 0.02505342848598957
Loss at iteration 630 : 0.015839630737900734
Loss at iteration 640 : 0.02564856968820095
Loss at iteration 650 : 0.029626507312059402
Loss at iteration 660 : 0.02529861219227314
Loss at iteration 670 : 0.03745876997709274
Loss at iteration 680 : 0.04040230065584183
Loss at iteration 690 : 0.028991542756557465
Loss at iteration 700 : 0.01724531501531601
Loss at iteration 710 : 0.022023048251867294
Loss at iteration 720 : 0.025545112788677216
Loss at iteration 730 : 0.031110979616642
Loss at iteration 740 : 0.02598295360803604
Loss at iteration 750 : 0.03440406545996666
Loss at iteration 760 : 0.03617670014500618
Loss at iteration 770 : 0.027983825653791428
Loss at iteration 780 : 0.03533050790429115
Loss at iteration 790 : 0.02633320912718773
Loss at iteration 800 : 0.017404168844223022
Loss at iteration 810 : 0.024831395596265793
Loss at iteration 820 : 0.02845163457095623
Loss at iteration 830 : 0.016517654061317444
Loss at iteration 840 : 0.02923080511391163
Loss at iteration 850 : 0.01730945147573948
Loss at iteration 860 : 0.030215993523597717
Loss at iteration 870 : 0.029921408742666245
Loss at iteration 880 : 0.02591087482869625
Loss at iteration 890 : 0.024110063910484314
Loss at iteration 900 : 0.032537370920181274
Loss at iteration 910 : 0.022832773625850677
Loss at iteration 920 : 0.019757375121116638
Loss at iteration 930 : 0.02657954767346382
Loss at iteration 940 : 0.024388983845710754
Loss at iteration 950 : 0.022458018735051155
Loss at iteration 960 : 0.027705799788236618
Loss at iteration 970 : 0.020235270261764526
Loss at iteration 980 : 0.02319388836622238
Loss at iteration 990 : 0.02567247301340103
Loss at iteration 1000 : 0.02888406626880169
Loss at iteration 1010 : 0.01697545312345028
Loss at iteration 1020 : 0.030407153069972992
Loss at iteration 1030 : 0.026743555441498756
Loss at iteration 1040 : 0.01924142986536026
Loss at iteration 1050 : 0.022238541394472122
Loss at iteration 1060 : 0.022425290197134018
Loss at iteration 1070 : 0.018061455339193344
Loss at iteration 1080 : 0.02815316431224346
Loss at iteration 1090 : 0.015371479094028473
Loss at iteration 1100 : 0.013532556593418121
Loss at iteration 1110 : 0.020846499130129814
Loss at iteration 1120 : 0.0365757942199707
Loss at iteration 1130 : 0.02366284653544426
Loss at iteration 1140 : 0.020798753947019577
Loss at iteration 1150 : 0.026940304785966873
Loss at iteration 1160 : 0.018896743655204773
Loss at iteration 1170 : 0.029969610273838043
Loss at iteration 1180 : 0.03569241613149643
Loss at iteration 1190 : 0.02712862752377987
Loss at iteration 1200 : 0.020744038745760918
Loss at iteration 1210 : 0.019292373210191727
The SSIM Value is: 0.7740284204483032
The PSNR Value is: 18.35167185465495
the epoch is: 35
Loss at iteration 10 : 0.02654929645359516
Loss at iteration 20 : 0.02022598311305046
Loss at iteration 30 : 0.03544549643993378
Loss at iteration 40 : 0.01905249059200287
Loss at iteration 50 : 0.029023729264736176
Loss at iteration 60 : 0.02721022441983223
Loss at iteration 70 : 0.029312817379832268
Loss at iteration 80 : 0.04257024824619293
Loss at iteration 90 : 0.04121416062116623
Loss at iteration 100 : 0.017513543367385864
Loss at iteration 110 : 0.03218000382184982
Loss at iteration 120 : 0.02838212437927723
Loss at iteration 130 : 0.032330095767974854
Loss at iteration 140 : 0.026288822293281555
Loss at iteration 150 : 0.02190690115094185
Loss at iteration 160 : 0.01919049397110939
Loss at iteration 170 : 0.020542223006486893
Loss at iteration 180 : 0.023102842271327972
Loss at iteration 190 : 0.03153764456510544
Loss at iteration 200 : 0.03244072198867798
Loss at iteration 210 : 0.020837415009737015
Loss at iteration 220 : 0.03181745857000351
Loss at iteration 230 : 0.0165425855666399
Loss at iteration 240 : 0.022359509021043777
Loss at iteration 250 : 0.016493380069732666
Loss at iteration 260 : 0.03354179114103317
Loss at iteration 270 : 0.036586157977581024
Loss at iteration 280 : 0.023777328431606293
Loss at iteration 290 : 0.012991586700081825
Loss at iteration 300 : 0.017726415768265724
Loss at iteration 310 : 0.024075418710708618
Loss at iteration 320 : 0.02545831725001335
Loss at iteration 330 : 0.029636021703481674
Loss at iteration 340 : 0.02141355164349079
Loss at iteration 350 : 0.022010184824466705
Loss at iteration 360 : 0.026991982012987137
Loss at iteration 370 : 0.024833042174577713
Loss at iteration 380 : 0.03995020315051079
Loss at iteration 390 : 0.02882371097803116
Loss at iteration 400 : 0.022857239469885826
Loss at iteration 410 : 0.02044571191072464
Loss at iteration 420 : 0.019447043538093567
Loss at iteration 430 : 0.017490770667791367
Loss at iteration 440 : 0.026423931121826172
Loss at iteration 450 : 0.041711434721946716
Loss at iteration 460 : 0.04129183292388916
Loss at iteration 470 : 0.02327786013484001
Loss at iteration 480 : 0.017734888941049576
Loss at iteration 490 : 0.016951385885477066
Loss at iteration 500 : 0.039179056882858276
Loss at iteration 510 : 0.042580049484968185
Loss at iteration 520 : 0.025053851306438446
Loss at iteration 530 : 0.022021226584911346
Loss at iteration 540 : 0.02632061019539833
Loss at iteration 550 : 0.02532282844185829
Loss at iteration 560 : 0.031241748481988907
Loss at iteration 570 : 0.02112160250544548
Loss at iteration 580 : 0.028325051069259644
Loss at iteration 590 : 0.02856397069990635
Loss at iteration 600 : 0.03394137695431709
Loss at iteration 610 : 0.02656428888440132
Loss at iteration 620 : 0.01846900023519993
Loss at iteration 630 : 0.026838157325983047
Loss at iteration 640 : 0.013438437134027481
Loss at iteration 650 : 0.01693027839064598
Loss at iteration 660 : 0.03346128761768341
Loss at iteration 670 : 0.019838638603687286
Loss at iteration 680 : 0.016682486981153488
Loss at iteration 690 : 0.03557044640183449
Loss at iteration 700 : 0.016396421939134598
Loss at iteration 710 : 0.025515660643577576
Loss at iteration 720 : 0.02545967325568199
Loss at iteration 730 : 0.016240403056144714
Loss at iteration 740 : 0.02969178929924965
Loss at iteration 750 : 0.026199718937277794
Loss at iteration 760 : 0.02576007880270481
Loss at iteration 770 : 0.024749312549829483
Loss at iteration 780 : 0.03608296439051628
Loss at iteration 790 : 0.03255345672369003
Loss at iteration 800 : 0.017209503799676895
Loss at iteration 810 : 0.03541754558682442
Loss at iteration 820 : 0.02952301874756813
Loss at iteration 830 : 0.01848495751619339
Loss at iteration 840 : 0.023430347442626953
Loss at iteration 850 : 0.02852536365389824
Loss at iteration 860 : 0.03148748725652695
Loss at iteration 870 : 0.022301185876131058
Loss at iteration 880 : 0.027015645056962967
Loss at iteration 890 : 0.013628949411213398
Loss at iteration 900 : 0.02102251723408699
Loss at iteration 910 : 0.026529483497142792
Loss at iteration 920 : 0.023500651121139526
Loss at iteration 930 : 0.019294098019599915
Loss at iteration 940 : 0.02591756358742714
Loss at iteration 950 : 0.022898800671100616
Loss at iteration 960 : 0.014846233651041985
Loss at iteration 970 : 0.0417880155146122
Loss at iteration 980 : 0.0382254384458065
Loss at iteration 990 : 0.019298691302537918
Loss at iteration 1000 : 0.027655985206365585
Loss at iteration 1010 : 0.03569146990776062
Loss at iteration 1020 : 0.018075503408908844
Loss at iteration 1030 : 0.02038848213851452
Loss at iteration 1040 : 0.03529945760965347
Loss at iteration 1050 : 0.03201443701982498
Loss at iteration 1060 : 0.031444989144802094
Loss at iteration 1070 : 0.03957439959049225
Loss at iteration 1080 : 0.013814380392432213
Loss at iteration 1090 : 0.04782611131668091
Loss at iteration 1100 : 0.023658450692892075
Loss at iteration 1110 : 0.027678703889250755
Loss at iteration 1120 : 0.019574176520109177
Loss at iteration 1130 : 0.0181889608502388
Loss at iteration 1140 : 0.019243868067860603
Loss at iteration 1150 : 0.02795451506972313
Loss at iteration 1160 : 0.032875508069992065
Loss at iteration 1170 : 0.025694340467453003
Loss at iteration 1180 : 0.025346433743834496
Loss at iteration 1190 : 0.029831327497959137
Loss at iteration 1200 : 0.02187763713300228
Loss at iteration 1210 : 0.04035528004169464
The SSIM Value is: 0.7734126845995585
The PSNR Value is: 18.284162203470867
the epoch is: 36
Loss at iteration 10 : 0.02623746171593666
Loss at iteration 20 : 0.035926662385463715
Loss at iteration 30 : 0.024450266733765602
Loss at iteration 40 : 0.026854133233428
Loss at iteration 50 : 0.024122823029756546
Loss at iteration 60 : 0.0202232263982296
Loss at iteration 70 : 0.020435910671949387
Loss at iteration 80 : 0.019663114100694656
Loss at iteration 90 : 0.02786935865879059
Loss at iteration 100 : 0.016566544771194458
Loss at iteration 110 : 0.017739035189151764
Loss at iteration 120 : 0.03209327161312103
Loss at iteration 130 : 0.02240380272269249
Loss at iteration 140 : 0.027084164321422577
Loss at iteration 150 : 0.013731194660067558
Loss at iteration 160 : 0.01547788456082344
Loss at iteration 170 : 0.028673995286226273
Loss at iteration 180 : 0.02137431502342224
Loss at iteration 190 : 0.04970937222242355
Loss at iteration 200 : 0.021528681740164757
Loss at iteration 210 : 0.021495342254638672
Loss at iteration 220 : 0.017709793522953987
Loss at iteration 230 : 0.019400672987103462
Loss at iteration 240 : 0.02626347355544567
Loss at iteration 250 : 0.03560027480125427
Loss at iteration 260 : 0.034394342452287674
Loss at iteration 270 : 0.026064883917570114
Loss at iteration 280 : 0.0231923945248127
Loss at iteration 290 : 0.023648176342248917
Loss at iteration 300 : 0.026369377970695496
Loss at iteration 310 : 0.02470732480287552
Loss at iteration 320 : 0.025819025933742523
Loss at iteration 330 : 0.04691530764102936
Loss at iteration 340 : 0.027231767773628235
Loss at iteration 350 : 0.04483925551176071
Loss at iteration 360 : 0.020760035142302513
Loss at iteration 370 : 0.01341051422059536
Loss at iteration 380 : 0.03100503794848919
Loss at iteration 390 : 0.039653144776821136
Loss at iteration 400 : 0.01894870214164257
Loss at iteration 410 : 0.016428623348474503
Loss at iteration 420 : 0.017410404980182648
Loss at iteration 430 : 0.03169352933764458
Loss at iteration 440 : 0.013586575165390968
Loss at iteration 450 : 0.03146238625049591
Loss at iteration 460 : 0.028131408616900444
Loss at iteration 470 : 0.029697062447667122
Loss at iteration 480 : 0.03809972107410431
Loss at iteration 490 : 0.022287126630544662
Loss at iteration 500 : 0.024558598175644875
Loss at iteration 510 : 0.03461836278438568
Loss at iteration 520 : 0.01811099238693714
Loss at iteration 530 : 0.016557013615965843
Loss at iteration 540 : 0.026359986513853073
Loss at iteration 550 : 0.01513721328228712
Loss at iteration 560 : 0.030326731503009796
Loss at iteration 570 : 0.025961939245462418
Loss at iteration 580 : 0.015304370783269405
Loss at iteration 590 : 0.022691840305924416
Loss at iteration 600 : 0.02930387482047081
Loss at iteration 610 : 0.032551366835832596
Loss at iteration 620 : 0.018860064446926117
Loss at iteration 630 : 0.03479618579149246
Loss at iteration 640 : 0.022762272506952286
Loss at iteration 650 : 0.029521964490413666
Loss at iteration 660 : 0.033463869243860245
Loss at iteration 670 : 0.0152046587318182
Loss at iteration 680 : 0.026485387235879898
Loss at iteration 690 : 0.030310550704598427
Loss at iteration 700 : 0.027433311566710472
Loss at iteration 710 : 0.03437114506959915
Loss at iteration 720 : 0.036419693380594254
Loss at iteration 730 : 0.022643759846687317
Loss at iteration 740 : 0.015957538038492203
Loss at iteration 750 : 0.020418602973222733
Loss at iteration 760 : 0.025958042591810226
Loss at iteration 770 : 0.01743566058576107
Loss at iteration 780 : 0.014014072716236115
Loss at iteration 790 : 0.025494851171970367
Loss at iteration 800 : 0.025112049654126167
Loss at iteration 810 : 0.037235889583826065
Loss at iteration 820 : 0.0298917256295681
Loss at iteration 830 : 0.04185391962528229
Loss at iteration 840 : 0.014712534844875336
Loss at iteration 850 : 0.040282685309648514
Loss at iteration 860 : 0.015769295394420624
Loss at iteration 870 : 0.01946607604622841
Loss at iteration 880 : 0.0179237499833107
Loss at iteration 890 : 0.020935900509357452
Loss at iteration 900 : 0.023831559345126152
Loss at iteration 910 : 0.025658655911684036
Loss at iteration 920 : 0.028691142797470093
Loss at iteration 930 : 0.03635704517364502
Loss at iteration 940 : 0.023194383829832077
Loss at iteration 950 : 0.036267247051000595
Loss at iteration 960 : 0.012474353425204754
Loss at iteration 970 : 0.030863795429468155
Loss at iteration 980 : 0.02873712033033371
Loss at iteration 990 : 0.03582572937011719
Loss at iteration 1000 : 0.033802878111600876
Loss at iteration 1010 : 0.031027479097247124
Loss at iteration 1020 : 0.021280787885189056
Loss at iteration 1030 : 0.01993555761873722
Loss at iteration 1040 : 0.046481385827064514
Loss at iteration 1050 : 0.02829345129430294
Loss at iteration 1060 : 0.027015134692192078
Loss at iteration 1070 : 0.030489062890410423
Loss at iteration 1080 : 0.03827454149723053
Loss at iteration 1090 : 0.02198990061879158
Loss at iteration 1100 : 0.023775678128004074
Loss at iteration 1110 : 0.02790055423974991
Loss at iteration 1120 : 0.04772189259529114
Loss at iteration 1130 : 0.027827885001897812
Loss at iteration 1140 : 0.02659025974571705
Loss at iteration 1150 : 0.024421874433755875
Loss at iteration 1160 : 0.041560277342796326
Loss at iteration 1170 : 0.03134539723396301
Loss at iteration 1180 : 0.017106708139181137
Loss at iteration 1190 : 0.031807057559490204
Loss at iteration 1200 : 0.022567782551050186
Loss at iteration 1210 : 0.011465886607766151
The SSIM Value is: 0.7638325929641724
The PSNR Value is: 17.665839767456056
the epoch is: 37
Loss at iteration 10 : 0.02239033579826355
Loss at iteration 20 : 0.018268615007400513
Loss at iteration 30 : 0.01594814658164978
Loss at iteration 40 : 0.020363830029964447
Loss at iteration 50 : 0.01625906489789486
Loss at iteration 60 : 0.02161627635359764
Loss at iteration 70 : 0.027477780357003212
Loss at iteration 80 : 0.021776901558041573
Loss at iteration 90 : 0.017951324582099915
Loss at iteration 100 : 0.028480123728513718
Loss at iteration 110 : 0.024068843573331833
Loss at iteration 120 : 0.023063935339450836
Loss at iteration 130 : 0.02206943929195404
Loss at iteration 140 : 0.018768463283777237
Loss at iteration 150 : 0.02438424341380596
Loss at iteration 160 : 0.03196810930967331
Loss at iteration 170 : 0.02338084764778614
Loss at iteration 180 : 0.020312022417783737
Loss at iteration 190 : 0.017363857477903366
Loss at iteration 200 : 0.03393113613128662
Loss at iteration 210 : 0.02296500839293003
Loss at iteration 220 : 0.02517877146601677
Loss at iteration 230 : 0.02013831026852131
Loss at iteration 240 : 0.02018841728568077
Loss at iteration 250 : 0.030958008021116257
Loss at iteration 260 : 0.01656639762222767
Loss at iteration 270 : 0.01800728775560856
Loss at iteration 280 : 0.023855382576584816
Loss at iteration 290 : 0.020126203075051308
Loss at iteration 300 : 0.02020459994673729
Loss at iteration 310 : 0.025421757251024246
Loss at iteration 320 : 0.022298283874988556
Loss at iteration 330 : 0.02572803944349289
Loss at iteration 340 : 0.02217210829257965
Loss at iteration 350 : 0.02700921893119812
Loss at iteration 360 : 0.03282224386930466
Loss at iteration 370 : 0.0423448383808136
Loss at iteration 380 : 0.026219800114631653
Loss at iteration 390 : 0.03083227574825287
Loss at iteration 400 : 0.030519235879182816
Loss at iteration 410 : 0.031191792339086533
Loss at iteration 420 : 0.037219420075416565
Loss at iteration 430 : 0.030282294377684593
Loss at iteration 440 : 0.029598621651530266
Loss at iteration 450 : 0.024145394563674927
Loss at iteration 460 : 0.027233794331550598
Loss at iteration 470 : 0.015923751518130302
Loss at iteration 480 : 0.019632812589406967
Loss at iteration 490 : 0.02298019453883171
Loss at iteration 500 : 0.017741184681653976
Loss at iteration 510 : 0.02186417765915394
Loss at iteration 520 : 0.037156373262405396
Loss at iteration 530 : 0.012138120830059052
Loss at iteration 540 : 0.04545384645462036
Loss at iteration 550 : 0.015744028612971306
Loss at iteration 560 : 0.025466188788414
Loss at iteration 570 : 0.02133261412382126
Loss at iteration 580 : 0.024799741804599762
Loss at iteration 590 : 0.03116842731833458
Loss at iteration 600 : 0.028986811637878418
Loss at iteration 610 : 0.026434578001499176
Loss at iteration 620 : 0.02715178206562996
Loss at iteration 630 : 0.019939884543418884
Loss at iteration 640 : 0.02635790780186653
Loss at iteration 650 : 0.04011092707514763
Loss at iteration 660 : 0.03458771854639053
Loss at iteration 670 : 0.02232765033841133
Loss at iteration 680 : 0.0180555060505867
Loss at iteration 690 : 0.023277638480067253
Loss at iteration 700 : 0.02129967510700226
Loss at iteration 710 : 0.03274967521429062
Loss at iteration 720 : 0.022211013361811638
Loss at iteration 730 : 0.014206490479409695
Loss at iteration 740 : 0.014077618718147278
Loss at iteration 750 : 0.02585216984152794
Loss at iteration 760 : 0.02180534228682518
Loss at iteration 770 : 0.023671451956033707
Loss at iteration 780 : 0.027438875287771225
Loss at iteration 790 : 0.031512968242168427
Loss at iteration 800 : 0.031230663880705833
Loss at iteration 810 : 0.024164076894521713
Loss at iteration 820 : 0.02030959539115429
Loss at iteration 830 : 0.036833953112363815
Loss at iteration 840 : 0.032798610627651215
Loss at iteration 850 : 0.031176144257187843
Loss at iteration 860 : 0.019800463691353798
Loss at iteration 870 : 0.030150381848216057
Loss at iteration 880 : 0.024630680680274963
Loss at iteration 890 : 0.018151577562093735
Loss at iteration 900 : 0.022995060309767723
Loss at iteration 910 : 0.030851587653160095
Loss at iteration 920 : 0.02950058877468109
Loss at iteration 930 : 0.024478718638420105
Loss at iteration 940 : 0.02926044538617134
Loss at iteration 950 : 0.023592429235577583
Loss at iteration 960 : 0.034087441861629486
Loss at iteration 970 : 0.020534738898277283
Loss at iteration 980 : 0.02965938113629818
Loss at iteration 990 : 0.02138163149356842
Loss at iteration 1000 : 0.03340199589729309
Loss at iteration 1010 : 0.02871517464518547
Loss at iteration 1020 : 0.027834253385663033
Loss at iteration 1030 : 0.022777274250984192
Loss at iteration 1040 : 0.02818075753748417
Loss at iteration 1050 : 0.021706288680434227
Loss at iteration 1060 : 0.02511719986796379
Loss at iteration 1070 : 0.025936752557754517
Loss at iteration 1080 : 0.027957160025835037
Loss at iteration 1090 : 0.016619980335235596
Loss at iteration 1100 : 0.018524879589676857
Loss at iteration 1110 : 0.018694130703806877
Loss at iteration 1120 : 0.027831215411424637
Loss at iteration 1130 : 0.017253011465072632
Loss at iteration 1140 : 0.03155338391661644
Loss at iteration 1150 : 0.018492314964532852
Loss at iteration 1160 : 0.04818016290664673
Loss at iteration 1170 : 0.0330190472304821
Loss at iteration 1180 : 0.02643643505871296
Loss at iteration 1190 : 0.031788989901542664
Loss at iteration 1200 : 0.014322581700980663
Loss at iteration 1210 : 0.017559368163347244
The SSIM Value is: 0.7744374354680379
The PSNR Value is: 18.328143501281737
the epoch is: 38
Loss at iteration 10 : 0.023008614778518677
Loss at iteration 20 : 0.03340642899274826
Loss at iteration 30 : 0.029843037948012352
Loss at iteration 40 : 0.018178272992372513
Loss at iteration 50 : 0.014420812949538231
Loss at iteration 60 : 0.03383805602788925
Loss at iteration 70 : 0.02252691239118576
Loss at iteration 80 : 0.017324084416031837
Loss at iteration 90 : 0.010928742587566376
Loss at iteration 100 : 0.017697907984256744
Loss at iteration 110 : 0.021439271047711372
Loss at iteration 120 : 0.02094138041138649
Loss at iteration 130 : 0.016770869493484497
Loss at iteration 140 : 0.025153841823339462
Loss at iteration 150 : 0.02524256706237793
Loss at iteration 160 : 0.022048447281122208
Loss at iteration 170 : 0.02776998095214367
Loss at iteration 180 : 0.02716509997844696
Loss at iteration 190 : 0.03314407914876938
Loss at iteration 200 : 0.02183370105922222
Loss at iteration 210 : 0.028561890125274658
Loss at iteration 220 : 0.026107411831617355
Loss at iteration 230 : 0.024878397583961487
Loss at iteration 240 : 0.021927176043391228
Loss at iteration 250 : 0.01513775996863842
Loss at iteration 260 : 0.031684499233961105
Loss at iteration 270 : 0.025601007044315338
Loss at iteration 280 : 0.03704600781202316
Loss at iteration 290 : 0.02381070703268051
Loss at iteration 300 : 0.035469360649585724
Loss at iteration 310 : 0.023032357916235924
Loss at iteration 320 : 0.03212098032236099
Loss at iteration 330 : 0.024678586050868034
Loss at iteration 340 : 0.015785569325089455
Loss at iteration 350 : 0.014190164394676685
Loss at iteration 360 : 0.0187938641756773
Loss at iteration 370 : 0.01746717281639576
Loss at iteration 380 : 0.017770037055015564
Loss at iteration 390 : 0.030998824164271355
Loss at iteration 400 : 0.025864990428090096
Loss at iteration 410 : 0.025060007348656654
Loss at iteration 420 : 0.02081034891307354
Loss at iteration 430 : 0.020985417068004608
Loss at iteration 440 : 0.026483219116926193
Loss at iteration 450 : 0.026539722457528114
Loss at iteration 460 : 0.028892165049910545
Loss at iteration 470 : 0.02349400892853737
Loss at iteration 480 : 0.02254796400666237
Loss at iteration 490 : 0.016242502257227898
Loss at iteration 500 : 0.02861478552222252
Loss at iteration 510 : 0.027147922664880753
Loss at iteration 520 : 0.03443846106529236
Loss at iteration 530 : 0.02694392018020153
Loss at iteration 540 : 0.03132081404328346
Loss at iteration 550 : 0.033965423703193665
Loss at iteration 560 : 0.021484391763806343
Loss at iteration 570 : 0.02214815467596054
Loss at iteration 580 : 0.026157110929489136
Loss at iteration 590 : 0.014494126662611961
Loss at iteration 600 : 0.019904281944036484
Loss at iteration 610 : 0.03882650285959244
Loss at iteration 620 : 0.018084267154335976
Loss at iteration 630 : 0.01993492618203163
Loss at iteration 640 : 0.030184626579284668
Loss at iteration 650 : 0.020420555025339127
Loss at iteration 660 : 0.02888745628297329
Loss at iteration 670 : 0.02238238975405693
Loss at iteration 680 : 0.03892064094543457
Loss at iteration 690 : 0.03411678969860077
Loss at iteration 700 : 0.036303356289863586
Loss at iteration 710 : 0.01279741246253252
Loss at iteration 720 : 0.04730818420648575
Loss at iteration 730 : 0.019115282222628593
Loss at iteration 740 : 0.021018385887145996
Loss at iteration 750 : 0.015801189467310905
Loss at iteration 760 : 0.02972858026623726
Loss at iteration 770 : 0.016241956502199173
Loss at iteration 780 : 0.03129274398088455
Loss at iteration 790 : 0.025109410285949707
Loss at iteration 800 : 0.035143665969371796
Loss at iteration 810 : 0.019565973430871964
Loss at iteration 820 : 0.028263479471206665
Loss at iteration 830 : 0.02651556394994259
Loss at iteration 840 : 0.031324729323387146
Loss at iteration 850 : 0.01840437576174736
Loss at iteration 860 : 0.022470498457551003
Loss at iteration 870 : 0.016040490940213203
Loss at iteration 880 : 0.022496508434414864
Loss at iteration 890 : 0.02443070337176323
Loss at iteration 900 : 0.04289574176073074
Loss at iteration 910 : 0.04309897497296333
Loss at iteration 920 : 0.021441800519824028
Loss at iteration 930 : 0.02416815422475338
Loss at iteration 940 : 0.0485612228512764
Loss at iteration 950 : 0.022666282951831818
Loss at iteration 960 : 0.024482499808073044
Loss at iteration 970 : 0.02188877761363983
Loss at iteration 980 : 0.024420328438282013
Loss at iteration 990 : 0.015271998010575771
Loss at iteration 1000 : 0.030945133417844772
Loss at iteration 1010 : 0.023674137890338898
Loss at iteration 1020 : 0.03699009492993355
Loss at iteration 1030 : 0.021145496517419815
Loss at iteration 1040 : 0.020373206585645676
Loss at iteration 1050 : 0.019912801682949066
Loss at iteration 1060 : 0.022756878286600113
Loss at iteration 1070 : 0.02922096848487854
Loss at iteration 1080 : 0.018420159816741943
Loss at iteration 1090 : 0.027243830263614655
Loss at iteration 1100 : 0.028784535825252533
Loss at iteration 1110 : 0.029307350516319275
Loss at iteration 1120 : 0.04141292721033096
Loss at iteration 1130 : 0.03548916056752205
Loss at iteration 1140 : 0.020259562879800797
Loss at iteration 1150 : 0.041928067803382874
Loss at iteration 1160 : 0.03115229308605194
Loss at iteration 1170 : 0.021619362756609917
Loss at iteration 1180 : 0.02557700127363205
Loss at iteration 1190 : 0.02104492485523224
Loss at iteration 1200 : 0.03945103660225868
Loss at iteration 1210 : 0.03375859558582306
The SSIM Value is: 0.7683017969131469
The PSNR Value is: 17.617661221822104
the epoch is: 39
Loss at iteration 10 : 0.023915208876132965
Loss at iteration 20 : 0.03723187744617462
Loss at iteration 30 : 0.022197674959897995
Loss at iteration 40 : 0.03059055097401142
Loss at iteration 50 : 0.03245919570326805
Loss at iteration 60 : 0.03437458723783493
Loss at iteration 70 : 0.030066654086112976
Loss at iteration 80 : 0.05084320157766342
Loss at iteration 90 : 0.020864378660917282
Loss at iteration 100 : 0.02639331854879856
Loss at iteration 110 : 0.018673084676265717
Loss at iteration 120 : 0.02889382094144821
Loss at iteration 130 : 0.026569746434688568
Loss at iteration 140 : 0.03957289084792137
Loss at iteration 150 : 0.020573701709508896
Loss at iteration 160 : 0.02289552055299282
Loss at iteration 170 : 0.02309885434806347
Loss at iteration 180 : 0.05909480154514313
Loss at iteration 190 : 0.015344039537012577
Loss at iteration 200 : 0.02491680160164833
Loss at iteration 210 : 0.0215641800314188
Loss at iteration 220 : 0.018493037670850754
Loss at iteration 230 : 0.017993977293372154
Loss at iteration 240 : 0.018770944327116013
Loss at iteration 250 : 0.014680120162665844
Loss at iteration 260 : 0.02052166685461998
Loss at iteration 270 : 0.029506050050258636
Loss at iteration 280 : 0.023646701127290726
Loss at iteration 290 : 0.01254700031131506
Loss at iteration 300 : 0.020936407148838043
Loss at iteration 310 : 0.028046267107129097
Loss at iteration 320 : 0.03145352005958557
Loss at iteration 330 : 0.026670878753066063
Loss at iteration 340 : 0.024228692054748535
Loss at iteration 350 : 0.031964175403118134
Loss at iteration 360 : 0.02885386347770691
Loss at iteration 370 : 0.027893276885151863
Loss at iteration 380 : 0.0233853030949831
Loss at iteration 390 : 0.028953494504094124
Loss at iteration 400 : 0.026957599446177483
Loss at iteration 410 : 0.042802050709724426
Loss at iteration 420 : 0.022714024409651756
Loss at iteration 430 : 0.01732478477060795
Loss at iteration 440 : 0.03431880101561546
Loss at iteration 450 : 0.031202219426631927
Loss at iteration 460 : 0.02686472237110138
Loss at iteration 470 : 0.03051273338496685
Loss at iteration 480 : 0.02675163373351097
Loss at iteration 490 : 0.028400558978319168
Loss at iteration 500 : 0.0313141793012619
Loss at iteration 510 : 0.02749079465866089
Loss at iteration 520 : 0.015278817154467106
Loss at iteration 530 : 0.026021001860499382
Loss at iteration 540 : 0.022744586691260338
Loss at iteration 550 : 0.022974226623773575
Loss at iteration 560 : 0.027754059061408043
Loss at iteration 570 : 0.02439660020172596
Loss at iteration 580 : 0.012348667718470097
Loss at iteration 590 : 0.031031500548124313
Loss at iteration 600 : 0.018703948706388474
Loss at iteration 610 : 0.04126701131463051
Loss at iteration 620 : 0.018148332834243774
Loss at iteration 630 : 0.02865944430232048
Loss at iteration 640 : 0.029277075082063675
Loss at iteration 650 : 0.024200938642024994
Loss at iteration 660 : 0.016413837671279907
Loss at iteration 670 : 0.02558024227619171
Loss at iteration 680 : 0.028913084417581558
Loss at iteration 690 : 0.028526900336146355
Loss at iteration 700 : 0.023062147200107574
Loss at iteration 710 : 0.047619014978408813
Loss at iteration 720 : 0.021108213812112808
Loss at iteration 730 : 0.034689731895923615
Loss at iteration 740 : 0.0282448623329401
Loss at iteration 750 : 0.024159245193004608
Loss at iteration 760 : 0.01711421273648739
Loss at iteration 770 : 0.02392641454935074
Loss at iteration 780 : 0.01403711549937725
Loss at iteration 790 : 0.020658325403928757
Loss at iteration 800 : 0.027958864346146584
Loss at iteration 810 : 0.028303811326622963
Loss at iteration 820 : 0.03738563880324364
Loss at iteration 830 : 0.023111557587981224
Loss at iteration 840 : 0.02437117137014866
Loss at iteration 850 : 0.019775865599513054
Loss at iteration 860 : 0.030332285910844803
Loss at iteration 870 : 0.02177409641444683
Loss at iteration 880 : 0.017603280022740364
Loss at iteration 890 : 0.02937745302915573
Loss at iteration 900 : 0.029573600739240646
Loss at iteration 910 : 0.024234961718320847
Loss at iteration 920 : 0.020497053861618042
Loss at iteration 930 : 0.03014734759926796
Loss at iteration 940 : 0.019558528438210487
Loss at iteration 950 : 0.03367304801940918
Loss at iteration 960 : 0.019693471491336823
Loss at iteration 970 : 0.025236479938030243
Loss at iteration 980 : 0.02005743607878685
Loss at iteration 990 : 0.031413450837135315
Loss at iteration 1000 : 0.02666987106204033
Loss at iteration 1010 : 0.021787475794553757
Loss at iteration 1020 : 0.025955215096473694
Loss at iteration 1030 : 0.023577813059091568
Loss at iteration 1040 : 0.035535119473934174
Loss at iteration 1050 : 0.02561483532190323
Loss at iteration 1060 : 0.02300400286912918
Loss at iteration 1070 : 0.037426285445690155
Loss at iteration 1080 : 0.03811672329902649
Loss at iteration 1090 : 0.025068432092666626
Loss at iteration 1100 : 0.030512504279613495
Loss at iteration 1110 : 0.020385220646858215
Loss at iteration 1120 : 0.022810406982898712
Loss at iteration 1130 : 0.02268175221979618
Loss at iteration 1140 : 0.023814644664525986
Loss at iteration 1150 : 0.023646580055356026
Loss at iteration 1160 : 0.0202868040651083
Loss at iteration 1170 : 0.021361971274018288
Loss at iteration 1180 : 0.03038083016872406
Loss at iteration 1190 : 0.022836579009890556
Loss at iteration 1200 : 0.029492484405636787
Loss at iteration 1210 : 0.04149657487869263
The SSIM Value is: 0.7674245119094849
The PSNR Value is: 18.042469851175944
the epoch is: 40
Loss at iteration 10 : 0.020066119730472565
Loss at iteration 20 : 0.0243217796087265
Loss at iteration 30 : 0.03152744099497795
Loss at iteration 40 : 0.021357551217079163
Loss at iteration 50 : 0.03191645070910454
Loss at iteration 60 : 0.010089622810482979
Loss at iteration 70 : 0.0199178084731102
Loss at iteration 80 : 0.010528698563575745
Loss at iteration 90 : 0.02938690222799778
Loss at iteration 100 : 0.032866913825273514
Loss at iteration 110 : 0.023165615275502205
Loss at iteration 120 : 0.028081491589546204
Loss at iteration 130 : 0.03259958326816559
Loss at iteration 140 : 0.028163578361272812
Loss at iteration 150 : 0.02586708590388298
Loss at iteration 160 : 0.02783830836415291
Loss at iteration 170 : 0.03919026255607605
Loss at iteration 180 : 0.020372916013002396
Loss at iteration 190 : 0.028785763308405876
Loss at iteration 200 : 0.04942603409290314
Loss at iteration 210 : 0.032783783972263336
Loss at iteration 220 : 0.04344883933663368
Loss at iteration 230 : 0.02020363323390484
Loss at iteration 240 : 0.02531086653470993
Loss at iteration 250 : 0.019200094044208527
Loss at iteration 260 : 0.029246091842651367
Loss at iteration 270 : 0.033648859709501266
Loss at iteration 280 : 0.016536036506295204
Loss at iteration 290 : 0.023728277534246445
Loss at iteration 300 : 0.028804641216993332
Loss at iteration 310 : 0.04032852128148079
Loss at iteration 320 : 0.02486305683851242
Loss at iteration 330 : 0.027107369154691696
Loss at iteration 340 : 0.02349945716559887
Loss at iteration 350 : 0.022696059197187424
Loss at iteration 360 : 0.01988905295729637
Loss at iteration 370 : 0.028722550719976425
Loss at iteration 380 : 0.029787417501211166
Loss at iteration 390 : 0.02107398957014084
Loss at iteration 400 : 0.027943136170506477
Loss at iteration 410 : 0.02736016921699047
Loss at iteration 420 : 0.032268643379211426
Loss at iteration 430 : 0.01835029385983944
Loss at iteration 440 : 0.03531214967370033
Loss at iteration 450 : 0.03153690695762634
Loss at iteration 460 : 0.031814031302928925
Loss at iteration 470 : 0.042922280728816986
Loss at iteration 480 : 0.015204181894659996
Loss at iteration 490 : 0.029180757701396942
Loss at iteration 500 : 0.022731002420186996
Loss at iteration 510 : 0.042895495891571045
Loss at iteration 520 : 0.02583158016204834
Loss at iteration 530 : 0.018392125144600868
Loss at iteration 540 : 0.024964045733213425
Loss at iteration 550 : 0.038898974657058716
Loss at iteration 560 : 0.02507721073925495
Loss at iteration 570 : 0.015937216579914093
Loss at iteration 580 : 0.03129778057336807
Loss at iteration 590 : 0.02231207862496376
Loss at iteration 600 : 0.026715893298387527
Loss at iteration 610 : 0.026499025523662567
Loss at iteration 620 : 0.030549034476280212
Loss at iteration 630 : 0.032525233924388885
Loss at iteration 640 : 0.04283543676137924
Loss at iteration 650 : 0.019412416964769363
Loss at iteration 660 : 0.025771349668502808
Loss at iteration 670 : 0.03011913225054741
Loss at iteration 680 : 0.020313289016485214
Loss at iteration 690 : 0.01978074386715889
Loss at iteration 700 : 0.020020458847284317
Loss at iteration 710 : 0.02384253963828087
Loss at iteration 720 : 0.03364335000514984
Loss at iteration 730 : 0.01595282554626465
Loss at iteration 740 : 0.02856946736574173
Loss at iteration 750 : 0.019249357283115387
Loss at iteration 760 : 0.020320463925600052
Loss at iteration 770 : 0.02098253183066845
Loss at iteration 780 : 0.02201269194483757
Loss at iteration 790 : 0.035291314125061035
Loss at iteration 800 : 0.03681657463312149
Loss at iteration 810 : 0.0280624870210886
Loss at iteration 820 : 0.024629492312669754
Loss at iteration 830 : 0.009653845801949501
Loss at iteration 840 : 0.027820169925689697
Loss at iteration 850 : 0.0185022484511137
Loss at iteration 860 : 0.033800896257162094
Loss at iteration 870 : 0.030912023037672043
Loss at iteration 880 : 0.03181646764278412
Loss at iteration 890 : 0.033214449882507324
Loss at iteration 900 : 0.024184679612517357
Loss at iteration 910 : 0.02509596198797226
Loss at iteration 920 : 0.027928249910473824
Loss at iteration 930 : 0.03404537960886955
Loss at iteration 940 : 0.028284385800361633
Loss at iteration 950 : 0.01712050661444664
Loss at iteration 960 : 0.028135007247328758
Loss at iteration 970 : 0.04587186500430107
Loss at iteration 980 : 0.02697914093732834
Loss at iteration 990 : 0.03519409894943237
Loss at iteration 1000 : 0.020959582179784775
Loss at iteration 1010 : 0.020922552794218063
Loss at iteration 1020 : 0.017997220158576965
Loss at iteration 1030 : 0.02757401019334793
Loss at iteration 1040 : 0.014655351638793945
Loss at iteration 1050 : 0.018404517322778702
Loss at iteration 1060 : 0.018538279458880424
Loss at iteration 1070 : 0.037945207208395004
Loss at iteration 1080 : 0.03092227876186371
Loss at iteration 1090 : 0.02817610278725624
Loss at iteration 1100 : 0.015700437128543854
Loss at iteration 1110 : 0.019176123663783073
Loss at iteration 1120 : 0.021052904427051544
Loss at iteration 1130 : 0.0170824583619833
Loss at iteration 1140 : 0.030267275869846344
Loss at iteration 1150 : 0.03763195499777794
Loss at iteration 1160 : 0.02689341828227043
Loss at iteration 1170 : 0.03953846916556358
Loss at iteration 1180 : 0.03012099117040634
Loss at iteration 1190 : 0.02934591844677925
Loss at iteration 1200 : 0.025861361995339394
Loss at iteration 1210 : 0.030757363885641098
The SSIM Value is: 0.7698592642943064
The PSNR Value is: 18.131925964355467
the epoch is: 41
Loss at iteration 10 : 0.019730012863874435
Loss at iteration 20 : 0.02100834622979164
Loss at iteration 30 : 0.02155829593539238
Loss at iteration 40 : 0.026924554258584976
Loss at iteration 50 : 0.024981269612908363
Loss at iteration 60 : 0.02706521563231945
Loss at iteration 70 : 0.030044760555028915
Loss at iteration 80 : 0.019129134714603424
Loss at iteration 90 : 0.033156268298625946
Loss at iteration 100 : 0.018229786306619644
Loss at iteration 110 : 0.016956765204668045
Loss at iteration 120 : 0.016305197030305862
Loss at iteration 130 : 0.029045015573501587
Loss at iteration 140 : 0.016040299087762833
Loss at iteration 150 : 0.03339833766222
Loss at iteration 160 : 0.01818731240928173
Loss at iteration 170 : 0.033849943429231644
Loss at iteration 180 : 0.021208858117461205
Loss at iteration 190 : 0.018790353089571
Loss at iteration 200 : 0.02166435495018959
Loss at iteration 210 : 0.03548011928796768
Loss at iteration 220 : 0.025007298216223717
Loss at iteration 230 : 0.0353870764374733
Loss at iteration 240 : 0.035169631242752075
Loss at iteration 250 : 0.02379351109266281
Loss at iteration 260 : 0.026882942765951157
Loss at iteration 270 : 0.02142895758152008
Loss at iteration 280 : 0.016105692833662033
Loss at iteration 290 : 0.02971784770488739
Loss at iteration 300 : 0.017116939648985863
Loss at iteration 310 : 0.01505251694470644
Loss at iteration 320 : 0.018474917858839035
Loss at iteration 330 : 0.022146888077259064
Loss at iteration 340 : 0.03458055853843689
Loss at iteration 350 : 0.019588883966207504
Loss at iteration 360 : 0.016619568690657616
Loss at iteration 370 : 0.03436974436044693
Loss at iteration 380 : 0.0187608003616333
Loss at iteration 390 : 0.03225990757346153
Loss at iteration 400 : 0.021070338785648346
Loss at iteration 410 : 0.03446584194898605
Loss at iteration 420 : 0.03809564188122749
Loss at iteration 430 : 0.018038323149085045
Loss at iteration 440 : 0.025694333016872406
Loss at iteration 450 : 0.01622941717505455
Loss at iteration 460 : 0.016357699409127235
Loss at iteration 470 : 0.0425976999104023
Loss at iteration 480 : 0.03374381363391876
Loss at iteration 490 : 0.030659625306725502
Loss at iteration 500 : 0.03291744738817215
Loss at iteration 510 : 0.028814630582928658
Loss at iteration 520 : 0.03589748591184616
Loss at iteration 530 : 0.0330037921667099
Loss at iteration 540 : 0.03871474042534828
Loss at iteration 550 : 0.020437462255358696
Loss at iteration 560 : 0.027599815279245377
Loss at iteration 570 : 0.026698533445596695
Loss at iteration 580 : 0.02777896448969841
Loss at iteration 590 : 0.026444943621754646
Loss at iteration 600 : 0.022357411682605743
Loss at iteration 610 : 0.03587999939918518
Loss at iteration 620 : 0.021739808842539787
Loss at iteration 630 : 0.01961829885840416
Loss at iteration 640 : 0.015529111959040165
Loss at iteration 650 : 0.018857795745134354
Loss at iteration 660 : 0.017014414072036743
Loss at iteration 670 : 0.02782556414604187
Loss at iteration 680 : 0.027755824849009514
Loss at iteration 690 : 0.01484488695859909
Loss at iteration 700 : 0.02261390909552574
Loss at iteration 710 : 0.01760074682533741
Loss at iteration 720 : 0.023182280361652374
Loss at iteration 730 : 0.017467381432652473
Loss at iteration 740 : 0.029309356585144997
Loss at iteration 750 : 0.03084743209183216
Loss at iteration 760 : 0.018855534493923187
Loss at iteration 770 : 0.028183547779917717
Loss at iteration 780 : 0.024662543088197708
Loss at iteration 790 : 0.019100602716207504
Loss at iteration 800 : 0.032044827938079834
Loss at iteration 810 : 0.023626074194908142
Loss at iteration 820 : 0.036070745438337326
Loss at iteration 830 : 0.022410569712519646
Loss at iteration 840 : 0.03085268661379814
Loss at iteration 850 : 0.020057782530784607
Loss at iteration 860 : 0.0231292936950922
Loss at iteration 870 : 0.01951625570654869
Loss at iteration 880 : 0.021946564316749573
Loss at iteration 890 : 0.022546224296092987
Loss at iteration 900 : 0.028952373191714287
Loss at iteration 910 : 0.0377572625875473
Loss at iteration 920 : 0.029672376811504364
Loss at iteration 930 : 0.033804066479206085
Loss at iteration 940 : 0.018919631838798523
Loss at iteration 950 : 0.015515072271227837
Loss at iteration 960 : 0.01872876286506653
Loss at iteration 970 : 0.020163290202617645
Loss at iteration 980 : 0.02867497131228447
Loss at iteration 990 : 0.029250651597976685
Loss at iteration 1000 : 0.030555134639143944
Loss at iteration 1010 : 0.015897613018751144
Loss at iteration 1020 : 0.028784815222024918
Loss at iteration 1030 : 0.026940839365124702
Loss at iteration 1040 : 0.022038061171770096
Loss at iteration 1050 : 0.03965269774198532
Loss at iteration 1060 : 0.02543899603188038
Loss at iteration 1070 : 0.02308078110218048
Loss at iteration 1080 : 0.02902228944003582
Loss at iteration 1090 : 0.02950887195765972
Loss at iteration 1100 : 0.028691548854112625
Loss at iteration 1110 : 0.027070213109254837
Loss at iteration 1120 : 0.015714678913354874
Loss at iteration 1130 : 0.05800781026482582
Loss at iteration 1140 : 0.017473755404353142
Loss at iteration 1150 : 0.020798787474632263
Loss at iteration 1160 : 0.02758653834462166
Loss at iteration 1170 : 0.01985747180879116
Loss at iteration 1180 : 0.040728479623794556
Loss at iteration 1190 : 0.03144078701734543
Loss at iteration 1200 : 0.01876288652420044
Loss at iteration 1210 : 0.02813640609383583
The SSIM Value is: 0.7721365829308827
The PSNR Value is: 18.036006228129068
the epoch is: 42
Loss at iteration 10 : 0.02268797717988491
Loss at iteration 20 : 0.03386414051055908
Loss at iteration 30 : 0.024822013452649117
Loss at iteration 40 : 0.025757744908332825
Loss at iteration 50 : 0.02112731896340847
Loss at iteration 60 : 0.025104982778429985
Loss at iteration 70 : 0.02669808268547058
Loss at iteration 80 : 0.03355482965707779
Loss at iteration 90 : 0.02340211533010006
Loss at iteration 100 : 0.016602465882897377
Loss at iteration 110 : 0.034716375172138214
Loss at iteration 120 : 0.01735205203294754
Loss at iteration 130 : 0.042509887367486954
Loss at iteration 140 : 0.014210917986929417
Loss at iteration 150 : 0.023300450295209885
Loss at iteration 160 : 0.014967868104577065
Loss at iteration 170 : 0.016923142597079277
Loss at iteration 180 : 0.01730954460799694
Loss at iteration 190 : 0.016811523586511612
Loss at iteration 200 : 0.048876404762268066
Loss at iteration 210 : 0.020592262968420982
Loss at iteration 220 : 0.02978477068245411
Loss at iteration 230 : 0.014740288257598877
Loss at iteration 240 : 0.012321450747549534
Loss at iteration 250 : 0.0223906971514225
Loss at iteration 260 : 0.020632706582546234
Loss at iteration 270 : 0.029976792633533478
Loss at iteration 280 : 0.024995002895593643
Loss at iteration 290 : 0.042037688195705414
Loss at iteration 300 : 0.01430802047252655
Loss at iteration 310 : 0.016766579821705818
Loss at iteration 320 : 0.0342266745865345
Loss at iteration 330 : 0.016522984951734543
Loss at iteration 340 : 0.018472205847501755
Loss at iteration 350 : 0.03187211975455284
Loss at iteration 360 : 0.019543126225471497
Loss at iteration 370 : 0.015374711714684963
Loss at iteration 380 : 0.02103561721742153
Loss at iteration 390 : 0.019369080662727356
Loss at iteration 400 : 0.017359575256705284
Loss at iteration 410 : 0.028364116325974464
Loss at iteration 420 : 0.027007196098566055
Loss at iteration 430 : 0.022377217188477516
Loss at iteration 440 : 0.020241593942046165
Loss at iteration 450 : 0.03045276552438736
Loss at iteration 460 : 0.02827593684196472
Loss at iteration 470 : 0.018670953810214996
Loss at iteration 480 : 0.035024285316467285
Loss at iteration 490 : 0.022172214463353157
Loss at iteration 500 : 0.02233419008553028
Loss at iteration 510 : 0.02362828701734543
Loss at iteration 520 : 0.01747293770313263
Loss at iteration 530 : 0.03263118863105774
Loss at iteration 540 : 0.04268303140997887
Loss at iteration 550 : 0.03274223580956459
Loss at iteration 560 : 0.02332085371017456
Loss at iteration 570 : 0.041855037212371826
Loss at iteration 580 : 0.03066297620534897
Loss at iteration 590 : 0.02476689964532852
Loss at iteration 600 : 0.02901517227292061
Loss at iteration 610 : 0.023905416950583458
Loss at iteration 620 : 0.031230216845870018
Loss at iteration 630 : 0.01240873709321022
Loss at iteration 640 : 0.026608731597661972
Loss at iteration 650 : 0.02246040478348732
Loss at iteration 660 : 0.024221938103437424
Loss at iteration 670 : 0.021596884354948997
Loss at iteration 680 : 0.034436821937561035
Loss at iteration 690 : 0.03245145082473755
Loss at iteration 700 : 0.051797620952129364
Loss at iteration 710 : 0.033259086310863495
Loss at iteration 720 : 0.03392678126692772
Loss at iteration 730 : 0.027237340807914734
Loss at iteration 740 : 0.02354203537106514
Loss at iteration 750 : 0.03175412863492966
Loss at iteration 760 : 0.023527726531028748
Loss at iteration 770 : 0.041967228055000305
Loss at iteration 780 : 0.024974985048174858
Loss at iteration 790 : 0.021000046283006668
Loss at iteration 800 : 0.02953353524208069
Loss at iteration 810 : 0.0315425880253315
Loss at iteration 820 : 0.023503949865698814
Loss at iteration 830 : 0.014934193342924118
Loss at iteration 840 : 0.028390321880578995
Loss at iteration 850 : 0.031738992780447006
Loss at iteration 860 : 0.02788941003382206
Loss at iteration 870 : 0.03266069293022156
Loss at iteration 880 : 0.029972292482852936
Loss at iteration 890 : 0.03395793214440346
Loss at iteration 900 : 0.034016940742731094
Loss at iteration 910 : 0.0166456438601017
Loss at iteration 920 : 0.023185480386018753
Loss at iteration 930 : 0.043266747146844864
Loss at iteration 940 : 0.02560155652463436
Loss at iteration 950 : 0.018556850031018257
Loss at iteration 960 : 0.011427613906562328
Loss at iteration 970 : 0.02718742936849594
Loss at iteration 980 : 0.02351800911128521
Loss at iteration 990 : 0.016596604138612747
Loss at iteration 1000 : 0.01138470321893692
Loss at iteration 1010 : 0.01700757071375847
Loss at iteration 1020 : 0.025214452296495438
Loss at iteration 1030 : 0.018993157893419266
Loss at iteration 1040 : 0.017137937247753143
Loss at iteration 1050 : 0.016889385879039764
Loss at iteration 1060 : 0.03263911232352257
Loss at iteration 1070 : 0.024849385023117065
Loss at iteration 1080 : 0.03013504110276699
Loss at iteration 1090 : 0.025491785258054733
Loss at iteration 1100 : 0.035110972821712494
Loss at iteration 1110 : 0.026966586709022522
Loss at iteration 1120 : 0.025872237980365753
Loss at iteration 1130 : 0.014467747882008553
Loss at iteration 1140 : 0.022753100842237473
Loss at iteration 1150 : 0.02950928546488285
Loss at iteration 1160 : 0.019344953820109367
Loss at iteration 1170 : 0.02605212666094303
Loss at iteration 1180 : 0.04860350489616394
Loss at iteration 1190 : 0.02515907771885395
Loss at iteration 1200 : 0.02017604559659958
Loss at iteration 1210 : 0.02336883544921875
The SSIM Value is: 0.7751488208770752
The PSNR Value is: 18.115479469299316
the epoch is: 43
Loss at iteration 10 : 0.03222590312361717
Loss at iteration 20 : 0.015605174005031586
Loss at iteration 30 : 0.019359350204467773
Loss at iteration 40 : 0.029296046122908592
Loss at iteration 50 : 0.019016187638044357
Loss at iteration 60 : 0.014565533958375454
Loss at iteration 70 : 0.04094674810767174
Loss at iteration 80 : 0.022837232798337936
Loss at iteration 90 : 0.027406606823205948
Loss at iteration 100 : 0.021729500964283943
Loss at iteration 110 : 0.01988973841071129
Loss at iteration 120 : 0.032726578414440155
Loss at iteration 130 : 0.0320131778717041
Loss at iteration 140 : 0.019892478361725807
Loss at iteration 150 : 0.027952037751674652
Loss at iteration 160 : 0.026937518268823624
Loss at iteration 170 : 0.0225625392049551
Loss at iteration 180 : 0.02077474072575569
Loss at iteration 190 : 0.03260686621069908
Loss at iteration 200 : 0.016247328370809555
Loss at iteration 210 : 0.016317475587129593
Loss at iteration 220 : 0.01941462978720665
Loss at iteration 230 : 0.018693849444389343
Loss at iteration 240 : 0.01997743360698223
Loss at iteration 250 : 0.022435002028942108
Loss at iteration 260 : 0.029733948409557343
Loss at iteration 270 : 0.03033595159649849
Loss at iteration 280 : 0.02589600905776024
Loss at iteration 290 : 0.02400241792201996
Loss at iteration 300 : 0.04505833610892296
Loss at iteration 310 : 0.01686224713921547
Loss at iteration 320 : 0.0183463953435421
Loss at iteration 330 : 0.02035212516784668
Loss at iteration 340 : 0.03102813847362995
Loss at iteration 350 : 0.0267518050968647
Loss at iteration 360 : 0.021252278238534927
Loss at iteration 370 : 0.020554687827825546
Loss at iteration 380 : 0.04263848438858986
Loss at iteration 390 : 0.0165853351354599
Loss at iteration 400 : 0.023920249193906784
Loss at iteration 410 : 0.02786816656589508
Loss at iteration 420 : 0.023660076782107353
Loss at iteration 430 : 0.026600927114486694
Loss at iteration 440 : 0.028372708708047867
Loss at iteration 450 : 0.03146931529045105
Loss at iteration 460 : 0.022757340222597122
Loss at iteration 470 : 0.01707274094223976
Loss at iteration 480 : 0.02493075281381607
Loss at iteration 490 : 0.021844293922185898
Loss at iteration 500 : 0.038462888449430466
Loss at iteration 510 : 0.019855452701449394
Loss at iteration 520 : 0.023005332797765732
Loss at iteration 530 : 0.030416838824748993
Loss at iteration 540 : 0.017462100833654404
Loss at iteration 550 : 0.023854896426200867
Loss at iteration 560 : 0.02043800614774227
Loss at iteration 570 : 0.028164241462945938
Loss at iteration 580 : 0.021997038275003433
Loss at iteration 590 : 0.03315874934196472
Loss at iteration 600 : 0.014066306874155998
Loss at iteration 610 : 0.025889327749609947
Loss at iteration 620 : 0.023093316704034805
Loss at iteration 630 : 0.048150815069675446
Loss at iteration 640 : 0.02046528086066246
Loss at iteration 650 : 0.02959633432328701
Loss at iteration 660 : 0.05169600993394852
Loss at iteration 670 : 0.022679317742586136
Loss at iteration 680 : 0.021059099584817886
Loss at iteration 690 : 0.019464043900370598
Loss at iteration 700 : 0.03368126228451729
Loss at iteration 710 : 0.02733936533331871
Loss at iteration 720 : 0.018489645794034004
Loss at iteration 730 : 0.0182628333568573
Loss at iteration 740 : 0.05772078037261963
Loss at iteration 750 : 0.022243397310376167
Loss at iteration 760 : 0.0240950807929039
Loss at iteration 770 : 0.016198929399251938
Loss at iteration 780 : 0.0428709052503109
Loss at iteration 790 : 0.039529167115688324
Loss at iteration 800 : 0.03610081970691681
Loss at iteration 810 : 0.031632859259843826
Loss at iteration 820 : 0.014428412541747093
Loss at iteration 830 : 0.023778531700372696
Loss at iteration 840 : 0.02134762518107891
Loss at iteration 850 : 0.026660138741135597
Loss at iteration 860 : 0.013677400536835194
Loss at iteration 870 : 0.018350180238485336
Loss at iteration 880 : 0.027225736528635025
Loss at iteration 890 : 0.023957950994372368
Loss at iteration 900 : 0.026160046458244324
Loss at iteration 910 : 0.019911784678697586
Loss at iteration 920 : 0.02178827114403248
Loss at iteration 930 : 0.024600427597761154
Loss at iteration 940 : 0.024489540606737137
Loss at iteration 950 : 0.022316712886095047
Loss at iteration 960 : 0.037314292043447495
Loss at iteration 970 : 0.02551295794546604
Loss at iteration 980 : 0.028247343376278877
Loss at iteration 990 : 0.02360118180513382
Loss at iteration 1000 : 0.015834497287869453
Loss at iteration 1010 : 0.02675735205411911
Loss at iteration 1020 : 0.03912609815597534
Loss at iteration 1030 : 0.023741543292999268
Loss at iteration 1040 : 0.025966638699173927
Loss at iteration 1050 : 0.022190023213624954
Loss at iteration 1060 : 0.020815987139940262
Loss at iteration 1070 : 0.034674178808927536
Loss at iteration 1080 : 0.02788461372256279
Loss at iteration 1090 : 0.023902960121631622
Loss at iteration 1100 : 0.02446332387626171
Loss at iteration 1110 : 0.029925543814897537
Loss at iteration 1120 : 0.037195123732089996
Loss at iteration 1130 : 0.038923364132642746
Loss at iteration 1140 : 0.02536815032362938
Loss at iteration 1150 : 0.014295113272964954
Loss at iteration 1160 : 0.03338147699832916
Loss at iteration 1170 : 0.019239451736211777
Loss at iteration 1180 : 0.03708460181951523
Loss at iteration 1190 : 0.02874007821083069
Loss at iteration 1200 : 0.014255493879318237
Loss at iteration 1210 : 0.027575379237532616
The SSIM Value is: 0.7757480104764303
The PSNR Value is: 17.946420351664226
the epoch is: 44
Loss at iteration 10 : 0.027182459831237793
Loss at iteration 20 : 0.026866182684898376
Loss at iteration 30 : 0.01921284943819046
Loss at iteration 40 : 0.04160464555025101
Loss at iteration 50 : 0.06260375678539276
Loss at iteration 60 : 0.03380072861909866
Loss at iteration 70 : 0.020669987425208092
Loss at iteration 80 : 0.019435850903391838
Loss at iteration 90 : 0.03488205373287201
Loss at iteration 100 : 0.013765064999461174
Loss at iteration 110 : 0.027479976415634155
Loss at iteration 120 : 0.02142966352403164
Loss at iteration 130 : 0.017361003905534744
Loss at iteration 140 : 0.026991624385118484
Loss at iteration 150 : 0.026748118922114372
Loss at iteration 160 : 0.03027694672346115
Loss at iteration 170 : 0.01604483090341091
Loss at iteration 180 : 0.015914082527160645
Loss at iteration 190 : 0.027416333556175232
Loss at iteration 200 : 0.013453268446028233
Loss at iteration 210 : 0.022826526314020157
Loss at iteration 220 : 0.015404986217617989
Loss at iteration 230 : 0.01710277982056141
Loss at iteration 240 : 0.027821466326713562
Loss at iteration 250 : 0.02299671061336994
Loss at iteration 260 : 0.024327851831912994
Loss at iteration 270 : 0.028036363422870636
Loss at iteration 280 : 0.03311982750892639
Loss at iteration 290 : 0.020994700491428375
Loss at iteration 300 : 0.025460943579673767
Loss at iteration 310 : 0.022552402690052986
Loss at iteration 320 : 0.0260426364839077
Loss at iteration 330 : 0.021957214921712875
Loss at iteration 340 : 0.02223932556807995
Loss at iteration 350 : 0.012925323098897934
Loss at iteration 360 : 0.023865561932325363
Loss at iteration 370 : 0.021851934492588043
Loss at iteration 380 : 0.027487244457006454
Loss at iteration 390 : 0.03462796285748482
Loss at iteration 400 : 0.03434217721223831
Loss at iteration 410 : 0.019314367324113846
Loss at iteration 420 : 0.025761932134628296
Loss at iteration 430 : 0.014427161775529385
Loss at iteration 440 : 0.0228681992739439
Loss at iteration 450 : 0.024156365543603897
Loss at iteration 460 : 0.01728595793247223
Loss at iteration 470 : 0.023069247603416443
Loss at iteration 480 : 0.02439546212553978
Loss at iteration 490 : 0.02665426954627037
Loss at iteration 500 : 0.021944543346762657
Loss at iteration 510 : 0.022863145917654037
Loss at iteration 520 : 0.050203949213027954
Loss at iteration 530 : 0.011392325162887573
Loss at iteration 540 : 0.0310934167355299
Loss at iteration 550 : 0.02710009552538395
Loss at iteration 560 : 0.02411355823278427
Loss at iteration 570 : 0.020242970436811447
Loss at iteration 580 : 0.020474238321185112
Loss at iteration 590 : 0.021466735750436783
Loss at iteration 600 : 0.030041448771953583
Loss at iteration 610 : 0.04152090102434158
Loss at iteration 620 : 0.026008524000644684
Loss at iteration 630 : 0.037504054605960846
Loss at iteration 640 : 0.023455962538719177
Loss at iteration 650 : 0.03222312778234482
Loss at iteration 660 : 0.018704809248447418
Loss at iteration 670 : 0.025796599686145782
Loss at iteration 680 : 0.024231135845184326
Loss at iteration 690 : 0.02286112681031227
Loss at iteration 700 : 0.02497982606291771
Loss at iteration 710 : 0.023429375141859055
Loss at iteration 720 : 0.018936073407530785
Loss at iteration 730 : 0.015712561085820198
Loss at iteration 740 : 0.009974893182516098
Loss at iteration 750 : 0.0241632629185915
Loss at iteration 760 : 0.025336746126413345
Loss at iteration 770 : 0.013628941960632801
Loss at iteration 780 : 0.020702943205833435
Loss at iteration 790 : 0.024019315838813782
Loss at iteration 800 : 0.022883038967847824
Loss at iteration 810 : 0.034721292555332184
Loss at iteration 820 : 0.019755396991968155
Loss at iteration 830 : 0.02049317955970764
Loss at iteration 840 : 0.02081499621272087
Loss at iteration 850 : 0.02279544435441494
Loss at iteration 860 : 0.02916187047958374
Loss at iteration 870 : 0.033623576164245605
Loss at iteration 880 : 0.022354884073138237
Loss at iteration 890 : 0.020825643092393875
Loss at iteration 900 : 0.012490099295973778
Loss at iteration 910 : 0.02026933804154396
Loss at iteration 920 : 0.018277516588568687
Loss at iteration 930 : 0.026993609964847565
Loss at iteration 940 : 0.025778042152523994
Loss at iteration 950 : 0.03222513198852539
Loss at iteration 960 : 0.026277925819158554
Loss at iteration 970 : 0.02458951435983181
Loss at iteration 980 : 0.055447839200496674
Loss at iteration 990 : 0.011686349287629128
Loss at iteration 1000 : 0.0212860070168972
Loss at iteration 1010 : 0.019238941371440887
Loss at iteration 1020 : 0.025387972593307495
Loss at iteration 1030 : 0.03313117474317551
Loss at iteration 1040 : 0.025839723646640778
Loss at iteration 1050 : 0.0176678579300642
Loss at iteration 1060 : 0.020869821310043335
Loss at iteration 1070 : 0.035982728004455566
Loss at iteration 1080 : 0.014157924801111221
Loss at iteration 1090 : 0.03178739547729492
Loss at iteration 1100 : 0.029543787240982056
Loss at iteration 1110 : 0.022585783153772354
Loss at iteration 1120 : 0.02152540162205696
Loss at iteration 1130 : 0.01925409585237503
Loss at iteration 1140 : 0.020193248987197876
Loss at iteration 1150 : 0.05422590672969818
Loss at iteration 1160 : 0.012736531905829906
Loss at iteration 1170 : 0.02754627913236618
Loss at iteration 1180 : 0.021579476073384285
Loss at iteration 1190 : 0.021370597183704376
Loss at iteration 1200 : 0.023820500820875168
Loss at iteration 1210 : 0.01674271933734417
The SSIM Value is: 0.7761452078819275
The PSNR Value is: 17.87052370707194
the epoch is: 45
Loss at iteration 10 : 0.030746174976229668
Loss at iteration 20 : 0.022707711905241013
Loss at iteration 30 : 0.03039909526705742
Loss at iteration 40 : 0.024965733289718628
Loss at iteration 50 : 0.018044620752334595
Loss at iteration 60 : 0.02326131798326969
Loss at iteration 70 : 0.02198011800646782
Loss at iteration 80 : 0.019242146983742714
Loss at iteration 90 : 0.021788356825709343
Loss at iteration 100 : 0.0211537666618824
Loss at iteration 110 : 0.023798804730176926
Loss at iteration 120 : 0.0232109185308218
Loss at iteration 130 : 0.0174734927713871
Loss at iteration 140 : 0.03311095014214516
Loss at iteration 150 : 0.027133630588650703
Loss at iteration 160 : 0.02535267174243927
Loss at iteration 170 : 0.024765629321336746
Loss at iteration 180 : 0.03407781571149826
Loss at iteration 190 : 0.03079027310013771
Loss at iteration 200 : 0.042175278067588806
Loss at iteration 210 : 0.029056429862976074
Loss at iteration 220 : 0.03789929300546646
Loss at iteration 230 : 0.0344080850481987
Loss at iteration 240 : 0.02216723933815956
Loss at iteration 250 : 0.032477252185344696
Loss at iteration 260 : 0.03033870831131935
Loss at iteration 270 : 0.018694836646318436
Loss at iteration 280 : 0.040530379861593246
Loss at iteration 290 : 0.026873953640460968
Loss at iteration 300 : 0.02396710403263569
Loss at iteration 310 : 0.025423463433980942
Loss at iteration 320 : 0.022979609668254852
Loss at iteration 330 : 0.02212773635983467
Loss at iteration 340 : 0.022702272981405258
Loss at iteration 350 : 0.023224929347634315
Loss at iteration 360 : 0.02317812666296959
Loss at iteration 370 : 0.025591155514121056
Loss at iteration 380 : 0.020796680822968483
Loss at iteration 390 : 0.0232780110090971
Loss at iteration 400 : 0.02315157651901245
Loss at iteration 410 : 0.026339314877986908
Loss at iteration 420 : 0.04304865747690201
Loss at iteration 430 : 0.02425507828593254
Loss at iteration 440 : 0.03690232336521149
Loss at iteration 450 : 0.01845386065542698
Loss at iteration 460 : 0.02604486793279648
Loss at iteration 470 : 0.024361616000533104
Loss at iteration 480 : 0.018113255500793457
Loss at iteration 490 : 0.03019479289650917
Loss at iteration 500 : 0.03113739565014839
Loss at iteration 510 : 0.018671302124857903
Loss at iteration 520 : 0.0167505145072937
Loss at iteration 530 : 0.01758498325943947
Loss at iteration 540 : 0.026045525446534157
Loss at iteration 550 : 0.020378701388835907
Loss at iteration 560 : 0.0389491431415081
Loss at iteration 570 : 0.030660852789878845
Loss at iteration 580 : 0.031033795326948166
Loss at iteration 590 : 0.03160415217280388
Loss at iteration 600 : 0.02750549279153347
Loss at iteration 610 : 0.02906329557299614
Loss at iteration 620 : 0.02134443260729313
Loss at iteration 630 : 0.04180057346820831
Loss at iteration 640 : 0.026123568415641785
Loss at iteration 650 : 0.03379984200000763
Loss at iteration 660 : 0.020838983356952667
Loss at iteration 670 : 0.019463511183857918
Loss at iteration 680 : 0.024395987391471863
Loss at iteration 690 : 0.026818519458174706
Loss at iteration 700 : 0.02321893721818924
Loss at iteration 710 : 0.02506331540644169
Loss at iteration 720 : 0.018842950463294983
Loss at iteration 730 : 0.03024164028465748
Loss at iteration 740 : 0.034839097410440445
Loss at iteration 750 : 0.02399906888604164
Loss at iteration 760 : 0.02307126484811306
Loss at iteration 770 : 0.017041437327861786
Loss at iteration 780 : 0.01823415420949459
Loss at iteration 790 : 0.02183094248175621
Loss at iteration 800 : 0.017107835039496422
Loss at iteration 810 : 0.03087076172232628
Loss at iteration 820 : 0.02838471159338951
Loss at iteration 830 : 0.03296844661235809
Loss at iteration 840 : 0.019891325384378433
Loss at iteration 850 : 0.027091627940535545
Loss at iteration 860 : 0.02505401335656643
Loss at iteration 870 : 0.02445448935031891
Loss at iteration 880 : 0.02457064390182495
Loss at iteration 890 : 0.015334031544625759
Loss at iteration 900 : 0.031114015728235245
Loss at iteration 910 : 0.021287105977535248
Loss at iteration 920 : 0.02433634363114834
Loss at iteration 930 : 0.030743468552827835
Loss at iteration 940 : 0.027747053653001785
Loss at iteration 950 : 0.036471787840127945
Loss at iteration 960 : 0.019576050341129303
Loss at iteration 970 : 0.012851804494857788
Loss at iteration 980 : 0.051827289164066315
Loss at iteration 990 : 0.020015273243188858
Loss at iteration 1000 : 0.02251901477575302
Loss at iteration 1010 : 0.023591507226228714
Loss at iteration 1020 : 0.019504249095916748
Loss at iteration 1030 : 0.011845558881759644
Loss at iteration 1040 : 0.030120238661766052
Loss at iteration 1050 : 0.014130670577287674
Loss at iteration 1060 : 0.0416230633854866
Loss at iteration 1070 : 0.017604557797312737
Loss at iteration 1080 : 0.029109403491020203
Loss at iteration 1090 : 0.02585996501147747
Loss at iteration 1100 : 0.019835179671645164
Loss at iteration 1110 : 0.02236589603126049
Loss at iteration 1120 : 0.03258224576711655
Loss at iteration 1130 : 0.016959449276328087
Loss at iteration 1140 : 0.020471161231398582
Loss at iteration 1150 : 0.018029922619462013
Loss at iteration 1160 : 0.02851678617298603
Loss at iteration 1170 : 0.030937615782022476
Loss at iteration 1180 : 0.024607820436358452
Loss at iteration 1190 : 0.029551751911640167
Loss at iteration 1200 : 0.019832223653793335
Loss at iteration 1210 : 0.023758988827466965
The SSIM Value is: 0.7690650920073191
The PSNR Value is: 17.824346033732095
the epoch is: 46
Loss at iteration 10 : 0.027033574879169464
Loss at iteration 20 : 0.01957213133573532
Loss at iteration 30 : 0.01628275215625763
Loss at iteration 40 : 0.033052343875169754
Loss at iteration 50 : 0.01989256963133812
Loss at iteration 60 : 0.03395339101552963
Loss at iteration 70 : 0.023992033675312996
Loss at iteration 80 : 0.033017776906490326
Loss at iteration 90 : 0.037470266222953796
Loss at iteration 100 : 0.0388510599732399
Loss at iteration 110 : 0.01918189600110054
Loss at iteration 120 : 0.03203366696834564
Loss at iteration 130 : 0.02402213215827942
Loss at iteration 140 : 0.01678106002509594
Loss at iteration 150 : 0.019004154950380325
Loss at iteration 160 : 0.02075756900012493
Loss at iteration 170 : 0.02355475164949894
Loss at iteration 180 : 0.018449800089001656
Loss at iteration 190 : 0.02170640602707863
Loss at iteration 200 : 0.030156591907143593
Loss at iteration 210 : 0.03240743651986122
Loss at iteration 220 : 0.035761572420597076
Loss at iteration 230 : 0.02441963367164135
Loss at iteration 240 : 0.02079850062727928
Loss at iteration 250 : 0.01832190901041031
Loss at iteration 260 : 0.013533908873796463
Loss at iteration 270 : 0.0338861346244812
Loss at iteration 280 : 0.028934534639120102
Loss at iteration 290 : 0.0412248894572258
Loss at iteration 300 : 0.027128204703330994
Loss at iteration 310 : 0.03636125847697258
Loss at iteration 320 : 0.026113752275705338
Loss at iteration 330 : 0.019343577325344086
Loss at iteration 340 : 0.027568425983190536
Loss at iteration 350 : 0.03766116127371788
Loss at iteration 360 : 0.022292163223028183
Loss at iteration 370 : 0.020292039960622787
Loss at iteration 380 : 0.02285497821867466
Loss at iteration 390 : 0.017150072380900383
Loss at iteration 400 : 0.020571764558553696
Loss at iteration 410 : 0.038771457970142365
Loss at iteration 420 : 0.031220413744449615
Loss at iteration 430 : 0.023714344948530197
Loss at iteration 440 : 0.01884264498949051
Loss at iteration 450 : 0.02433336153626442
Loss at iteration 460 : 0.02921893447637558
Loss at iteration 470 : 0.023989805951714516
Loss at iteration 480 : 0.02051069587469101
Loss at iteration 490 : 0.015366239473223686
Loss at iteration 500 : 0.02452603355050087
Loss at iteration 510 : 0.024404698982834816
Loss at iteration 520 : 0.05373123288154602
Loss at iteration 530 : 0.025066830217838287
Loss at iteration 540 : 0.025997620075941086
Loss at iteration 550 : 0.020893309265375137
Loss at iteration 560 : 0.028018534183502197
Loss at iteration 570 : 0.01979386806488037
Loss at iteration 580 : 0.025259383022785187
Loss at iteration 590 : 0.03731583058834076
Loss at iteration 600 : 0.02144758030772209
Loss at iteration 610 : 0.024486051872372627
Loss at iteration 620 : 0.025715533643960953
Loss at iteration 630 : 0.03022981435060501
Loss at iteration 640 : 0.02190900221467018
Loss at iteration 650 : 0.02022627741098404
Loss at iteration 660 : 0.05139874666929245
Loss at iteration 670 : 0.02220878377556801
Loss at iteration 680 : 0.025108810514211655
Loss at iteration 690 : 0.02176600694656372
Loss at iteration 700 : 0.0201001837849617
Loss at iteration 710 : 0.017551831901073456
Loss at iteration 720 : 0.026521235704421997
Loss at iteration 730 : 0.020845938473939896
Loss at iteration 740 : 0.02114339917898178
Loss at iteration 750 : 0.020020466297864914
Loss at iteration 760 : 0.01940496638417244
Loss at iteration 770 : 0.029655467718839645
Loss at iteration 780 : 0.036806970834732056
Loss at iteration 790 : 0.027353797107934952
Loss at iteration 800 : 0.02579997293651104
Loss at iteration 810 : 0.0199640654027462
Loss at iteration 820 : 0.019155869260430336
Loss at iteration 830 : 0.03306525573134422
Loss at iteration 840 : 0.042182859033346176
Loss at iteration 850 : 0.023099105805158615
Loss at iteration 860 : 0.02473827637732029
Loss at iteration 870 : 0.014678940176963806
Loss at iteration 880 : 0.01698901504278183
Loss at iteration 890 : 0.03005821257829666
Loss at iteration 900 : 0.015021074563264847
Loss at iteration 910 : 0.017000533640384674
Loss at iteration 920 : 0.020265918225049973
Loss at iteration 930 : 0.018821246922016144
Loss at iteration 940 : 0.03633745759725571
Loss at iteration 950 : 0.021367717534303665
Loss at iteration 960 : 0.022119829431176186
Loss at iteration 970 : 0.02888530306518078
Loss at iteration 980 : 0.02054835483431816
Loss at iteration 990 : 0.034180648624897
Loss at iteration 1000 : 0.01824849471449852
Loss at iteration 1010 : 0.0351337268948555
Loss at iteration 1020 : 0.022313091903924942
Loss at iteration 1030 : 0.02049466222524643
Loss at iteration 1040 : 0.03881695121526718
Loss at iteration 1050 : 0.02523946948349476
Loss at iteration 1060 : 0.02316632680594921
Loss at iteration 1070 : 0.026608511805534363
Loss at iteration 1080 : 0.02464468963444233
Loss at iteration 1090 : 0.02149754762649536
Loss at iteration 1100 : 0.01917199231684208
Loss at iteration 1110 : 0.01793854869902134
Loss at iteration 1120 : 0.024218350648880005
Loss at iteration 1130 : 0.02857343666255474
Loss at iteration 1140 : 0.025042418390512466
Loss at iteration 1150 : 0.028600286692380905
Loss at iteration 1160 : 0.025597896426916122
Loss at iteration 1170 : 0.020812535658478737
Loss at iteration 1180 : 0.015404663048684597
Loss at iteration 1190 : 0.021923206746578217
Loss at iteration 1200 : 0.02870044857263565
Loss at iteration 1210 : 0.02560589835047722
The SSIM Value is: 0.7704803486665089
The PSNR Value is: 18.105311139424643
the epoch is: 47
Loss at iteration 10 : 0.018326731398701668
Loss at iteration 20 : 0.027978738769888878
Loss at iteration 30 : 0.02199292927980423
Loss at iteration 40 : 0.029756173491477966
Loss at iteration 50 : 0.030535683035850525
Loss at iteration 60 : 0.05783424153923988
Loss at iteration 70 : 0.036749567836523056
Loss at iteration 80 : 0.02251533791422844
Loss at iteration 90 : 0.02365865558385849
Loss at iteration 100 : 0.0229591466486454
Loss at iteration 110 : 0.030914850533008575
Loss at iteration 120 : 0.03011181950569153
Loss at iteration 130 : 0.018763432279229164
Loss at iteration 140 : 0.021400049328804016
Loss at iteration 150 : 0.029146991670131683
Loss at iteration 160 : 0.024721316993236542
Loss at iteration 170 : 0.02975672110915184
Loss at iteration 180 : 0.021807920187711716
Loss at iteration 190 : 0.025945620611310005
Loss at iteration 200 : 0.027689341455698013
Loss at iteration 210 : 0.02839437499642372
Loss at iteration 220 : 0.026916608214378357
Loss at iteration 230 : 0.030501998960971832
Loss at iteration 240 : 0.023736000061035156
Loss at iteration 250 : 0.03425392135977745
Loss at iteration 260 : 0.025184515863656998
Loss at iteration 270 : 0.025329984724521637
Loss at iteration 280 : 0.033684514462947845
Loss at iteration 290 : 0.026913337409496307
Loss at iteration 300 : 0.02440737746655941
Loss at iteration 310 : 0.026650618761777878
Loss at iteration 320 : 0.01566743291914463
Loss at iteration 330 : 0.01846039667725563
Loss at iteration 340 : 0.027407851070165634
Loss at iteration 350 : 0.014388661831617355
Loss at iteration 360 : 0.0338931605219841
Loss at iteration 370 : 0.018484003841876984
Loss at iteration 380 : 0.03908717632293701
Loss at iteration 390 : 0.034418269991874695
Loss at iteration 400 : 0.014367236755788326
Loss at iteration 410 : 0.02025187388062477
Loss at iteration 420 : 0.017948973923921585
Loss at iteration 430 : 0.027333125472068787
Loss at iteration 440 : 0.026614461094141006
Loss at iteration 450 : 0.023493565618991852
Loss at iteration 460 : 0.01895296573638916
Loss at iteration 470 : 0.01290369313210249
Loss at iteration 480 : 0.039151497185230255
Loss at iteration 490 : 0.01881902851164341
Loss at iteration 500 : 0.024629220366477966
Loss at iteration 510 : 0.024532008916139603
Loss at iteration 520 : 0.01841661147773266
Loss at iteration 530 : 0.026583563536405563
Loss at iteration 540 : 0.03783179447054863
Loss at iteration 550 : 0.021474208682775497
Loss at iteration 560 : 0.016894863918423653
Loss at iteration 570 : 0.016967110335826874
Loss at iteration 580 : 0.019702140241861343
Loss at iteration 590 : 0.02603556588292122
Loss at iteration 600 : 0.022465281188488007
Loss at iteration 610 : 0.01377106923609972
Loss at iteration 620 : 0.030543964356184006
Loss at iteration 630 : 0.033117447048425674
Loss at iteration 640 : 0.02254509925842285
Loss at iteration 650 : 0.027428172528743744
Loss at iteration 660 : 0.02228935807943344
Loss at iteration 670 : 0.02957373484969139
Loss at iteration 680 : 0.013832665979862213
Loss at iteration 690 : 0.026343584060668945
Loss at iteration 700 : 0.03211943060159683
Loss at iteration 710 : 0.03753012418746948
Loss at iteration 720 : 0.016453811898827553
Loss at iteration 730 : 0.027217300608754158
Loss at iteration 740 : 0.01895640604197979
Loss at iteration 750 : 0.022567905485630035
Loss at iteration 760 : 0.020235292613506317
Loss at iteration 770 : 0.024041440337896347
Loss at iteration 780 : 0.023633841425180435
Loss at iteration 790 : 0.02217745967209339
Loss at iteration 800 : 0.024579869583249092
Loss at iteration 810 : 0.023564599454402924
Loss at iteration 820 : 0.04064846783876419
Loss at iteration 830 : 0.018263399600982666
Loss at iteration 840 : 0.0280170738697052
Loss at iteration 850 : 0.02815682254731655
Loss at iteration 860 : 0.022203922271728516
Loss at iteration 870 : 0.01961652562022209
Loss at iteration 880 : 0.021729424595832825
Loss at iteration 890 : 0.015841001644730568
Loss at iteration 900 : 0.02497965842485428
Loss at iteration 910 : 0.01246310118585825
Loss at iteration 920 : 0.03371758013963699
Loss at iteration 930 : 0.016047939658164978
Loss at iteration 940 : 0.0388917438685894
Loss at iteration 950 : 0.03562386333942413
Loss at iteration 960 : 0.018328476697206497
Loss at iteration 970 : 0.022813886404037476
Loss at iteration 980 : 0.033723462373018265
Loss at iteration 990 : 0.034735508263111115
Loss at iteration 1000 : 0.017257671803236008
Loss at iteration 1010 : 0.025724753737449646
Loss at iteration 1020 : 0.025912635028362274
Loss at iteration 1030 : 0.03476458042860031
Loss at iteration 1040 : 0.024882907047867775
Loss at iteration 1050 : 0.009449508972465992
Loss at iteration 1060 : 0.024278175085783005
Loss at iteration 1070 : 0.01547696627676487
Loss at iteration 1080 : 0.026300732046365738
Loss at iteration 1090 : 0.04244174435734749
Loss at iteration 1100 : 0.02217099815607071
Loss at iteration 1110 : 0.025621799752116203
Loss at iteration 1120 : 0.02392685040831566
Loss at iteration 1130 : 0.02972748875617981
Loss at iteration 1140 : 0.019283127039670944
Loss at iteration 1150 : 0.026986312121152878
Loss at iteration 1160 : 0.025576192885637283
Loss at iteration 1170 : 0.0463523343205452
Loss at iteration 1180 : 0.028804441913962364
Loss at iteration 1190 : 0.03133349120616913
Loss at iteration 1200 : 0.02748609334230423
Loss at iteration 1210 : 0.030375540256500244
The SSIM Value is: 0.7764369169871013
The PSNR Value is: 18.119282658894857
the epoch is: 48
Loss at iteration 10 : 0.017865121364593506
Loss at iteration 20 : 0.028980959206819534
Loss at iteration 30 : 0.028274428099393845
Loss at iteration 40 : 0.021145937964320183
Loss at iteration 50 : 0.025652332231402397
Loss at iteration 60 : 0.019488560035824776
Loss at iteration 70 : 0.022977879270911217
Loss at iteration 80 : 0.011903181672096252
Loss at iteration 90 : 0.025509465485811234
Loss at iteration 100 : 0.024884089827537537
Loss at iteration 110 : 0.01494224090129137
Loss at iteration 120 : 0.04060722142457962
Loss at iteration 130 : 0.02353016659617424
Loss at iteration 140 : 0.03276725113391876
Loss at iteration 150 : 0.01570439152419567
Loss at iteration 160 : 0.025261573493480682
Loss at iteration 170 : 0.03215448558330536
Loss at iteration 180 : 0.016957547515630722
Loss at iteration 190 : 0.023702774196863174
Loss at iteration 200 : 0.017597638070583344
Loss at iteration 210 : 0.018664536997675896
Loss at iteration 220 : 0.03151068836450577
Loss at iteration 230 : 0.02427707239985466
Loss at iteration 240 : 0.01886908710002899
Loss at iteration 250 : 0.0213728379458189
Loss at iteration 260 : 0.01598445698618889
Loss at iteration 270 : 0.023461386561393738
Loss at iteration 280 : 0.030176712200045586
Loss at iteration 290 : 0.024685002863407135
Loss at iteration 300 : 0.025628991425037384
Loss at iteration 310 : 0.02512299083173275
Loss at iteration 320 : 0.026401296257972717
Loss at iteration 330 : 0.025236614048480988
Loss at iteration 340 : 0.03234875202178955
Loss at iteration 350 : 0.035958293825387955
Loss at iteration 360 : 0.018183909356594086
Loss at iteration 370 : 0.02350199781358242
Loss at iteration 380 : 0.024064933881163597
Loss at iteration 390 : 0.048153698444366455
Loss at iteration 400 : 0.022106263786554337
Loss at iteration 410 : 0.041234903037548065
Loss at iteration 420 : 0.03595469146966934
Loss at iteration 430 : 0.0361153669655323
Loss at iteration 440 : 0.028586778789758682
Loss at iteration 450 : 0.038457661867141724
Loss at iteration 460 : 0.019511930644512177
Loss at iteration 470 : 0.01606207713484764
Loss at iteration 480 : 0.023156534880399704
Loss at iteration 490 : 0.017319370061159134
Loss at iteration 500 : 0.02570100873708725
Loss at iteration 510 : 0.02734098583459854
Loss at iteration 520 : 0.012871770188212395
Loss at iteration 530 : 0.023523032665252686
Loss at iteration 540 : 0.027699273079633713
Loss at iteration 550 : 0.03545794636011124
Loss at iteration 560 : 0.01512746512889862
Loss at iteration 570 : 0.022119246423244476
Loss at iteration 580 : 0.02048090100288391
Loss at iteration 590 : 0.03139728307723999
Loss at iteration 600 : 0.03589341789484024
Loss at iteration 610 : 0.0301194004714489
Loss at iteration 620 : 0.02042992413043976
Loss at iteration 630 : 0.013056334108114243
Loss at iteration 640 : 0.041254252195358276
Loss at iteration 650 : 0.027433335781097412
Loss at iteration 660 : 0.024814099073410034
Loss at iteration 670 : 0.024086739867925644
Loss at iteration 680 : 0.02108118310570717
Loss at iteration 690 : 0.018173236399888992
Loss at iteration 700 : 0.038189440965652466
Loss at iteration 710 : 0.024078601971268654
Loss at iteration 720 : 0.027840236201882362
Loss at iteration 730 : 0.025343935936689377
Loss at iteration 740 : 0.02026992104947567
Loss at iteration 750 : 0.016919095069169998
Loss at iteration 760 : 0.029192131012678146
Loss at iteration 770 : 0.024055887013673782
Loss at iteration 780 : 0.016992906108498573
Loss at iteration 790 : 0.025488348677754402
Loss at iteration 800 : 0.023709045723080635
Loss at iteration 810 : 0.019465046003460884
Loss at iteration 820 : 0.02047504484653473
Loss at iteration 830 : 0.014823954552412033
Loss at iteration 840 : 0.02892765775322914
Loss at iteration 850 : 0.030935116112232208
Loss at iteration 860 : 0.017993982881307602
Loss at iteration 870 : 0.028771771118044853
Loss at iteration 880 : 0.019517019391059875
Loss at iteration 890 : 0.021703965961933136
Loss at iteration 900 : 0.02242942340672016
Loss at iteration 910 : 0.02169864997267723
Loss at iteration 920 : 0.01720602810382843
Loss at iteration 930 : 0.02396334335207939
Loss at iteration 940 : 0.021155957132577896
Loss at iteration 950 : 0.01644703559577465
Loss at iteration 960 : 0.033408306539058685
Loss at iteration 970 : 0.02232557162642479
Loss at iteration 980 : 0.01124630868434906
Loss at iteration 990 : 0.02471107244491577
Loss at iteration 1000 : 0.02047628164291382
Loss at iteration 1010 : 0.015743056312203407
Loss at iteration 1020 : 0.0312725231051445
Loss at iteration 1030 : 0.020979978144168854
Loss at iteration 1040 : 0.022536298260092735
Loss at iteration 1050 : 0.02661614865064621
Loss at iteration 1060 : 0.032132476568222046
Loss at iteration 1070 : 0.026520561426877975
Loss at iteration 1080 : 0.04050981625914574
Loss at iteration 1090 : 0.027244847267866135
Loss at iteration 1100 : 0.02790256217122078
Loss at iteration 1110 : 0.02659781277179718
Loss at iteration 1120 : 0.02409677952528
Loss at iteration 1130 : 0.02224985510110855
Loss at iteration 1140 : 0.022814108058810234
Loss at iteration 1150 : 0.01613890938460827
Loss at iteration 1160 : 0.026168690994381905
Loss at iteration 1170 : 0.02173289656639099
Loss at iteration 1180 : 0.02027614787220955
Loss at iteration 1190 : 0.021210409700870514
Loss at iteration 1200 : 0.03246362507343292
Loss at iteration 1210 : 0.021208755671977997
The SSIM Value is: 0.7778163909912109
The PSNR Value is: 18.23318640391032
the epoch is: 49
Loss at iteration 10 : 0.027645498514175415
Loss at iteration 20 : 0.01999707520008087
Loss at iteration 30 : 0.01697840541601181
Loss at iteration 40 : 0.03292667865753174
Loss at iteration 50 : 0.024552062153816223
Loss at iteration 60 : 0.023276545107364655
Loss at iteration 70 : 0.017511440441012383
Loss at iteration 80 : 0.04385104030370712
Loss at iteration 90 : 0.03611721843481064
Loss at iteration 100 : 0.014114925637841225
Loss at iteration 110 : 0.024711940437555313
Loss at iteration 120 : 0.0221709031611681
Loss at iteration 130 : 0.019504308700561523
Loss at iteration 140 : 0.024496830999851227
Loss at iteration 150 : 0.02537558227777481
Loss at iteration 160 : 0.019841637462377548
Loss at iteration 170 : 0.013568471185863018
Loss at iteration 180 : 0.030179450288414955
Loss at iteration 190 : 0.022404298186302185
Loss at iteration 200 : 0.0279522854834795
Loss at iteration 210 : 0.04252488538622856
Loss at iteration 220 : 0.02798052877187729
Loss at iteration 230 : 0.02603643760085106
Loss at iteration 240 : 0.028783610090613365
Loss at iteration 250 : 0.02213120646774769
Loss at iteration 260 : 0.03404058888554573
Loss at iteration 270 : 0.03209918737411499
Loss at iteration 280 : 0.015979373827576637
Loss at iteration 290 : 0.028793983161449432
Loss at iteration 300 : 0.026441901922225952
Loss at iteration 310 : 0.019525373354554176
Loss at iteration 320 : 0.024709228426218033
Loss at iteration 330 : 0.03366474434733391
Loss at iteration 340 : 0.024633601307868958
Loss at iteration 350 : 0.04018094390630722
Loss at iteration 360 : 0.019328530877828598
Loss at iteration 370 : 0.023389674723148346
Loss at iteration 380 : 0.030125075951218605
Loss at iteration 390 : 0.018513664603233337
Loss at iteration 400 : 0.02014586143195629
Loss at iteration 410 : 0.026423335075378418
Loss at iteration 420 : 0.02393517829477787
Loss at iteration 430 : 0.03735799342393875
Loss at iteration 440 : 0.029978403821587563
Loss at iteration 450 : 0.022189268842339516
Loss at iteration 460 : 0.026889927685260773
Loss at iteration 470 : 0.022168194875121117
Loss at iteration 480 : 0.03515802323818207
Loss at iteration 490 : 0.026938416063785553
Loss at iteration 500 : 0.03728362172842026
Loss at iteration 510 : 0.04104171693325043
Loss at iteration 520 : 0.02665114589035511
Loss at iteration 530 : 0.024822698906064034
Loss at iteration 540 : 0.019649650901556015
Loss at iteration 550 : 0.026361679658293724
Loss at iteration 560 : 0.03343039005994797
Loss at iteration 570 : 0.022480368614196777
Loss at iteration 580 : 0.035231754183769226
Loss at iteration 590 : 0.020624028518795967
Loss at iteration 600 : 0.02349291741847992
Loss at iteration 610 : 0.03724975883960724
Loss at iteration 620 : 0.03863122686743736
Loss at iteration 630 : 0.04024053364992142
Loss at iteration 640 : 0.016655519604682922
Loss at iteration 650 : 0.02542983926832676
Loss at iteration 660 : 0.02905421517789364
Loss at iteration 670 : 0.020011266693472862
Loss at iteration 680 : 0.04262581467628479
Loss at iteration 690 : 0.020595010370016098
Loss at iteration 700 : 0.02781461551785469
Loss at iteration 710 : 0.021058600395917892
Loss at iteration 720 : 0.024399496614933014
Loss at iteration 730 : 0.021620048210024834
Loss at iteration 740 : 0.03060893341898918
Loss at iteration 750 : 0.013071512803435326
Loss at iteration 760 : 0.018743321299552917
Loss at iteration 770 : 0.015410535968840122
Loss at iteration 780 : 0.020948074758052826
Loss at iteration 790 : 0.023167788982391357
Loss at iteration 800 : 0.04268304258584976
Loss at iteration 810 : 0.02387741208076477
Loss at iteration 820 : 0.03215208277106285
Loss at iteration 830 : 0.027640875428915024
Loss at iteration 840 : 0.029255827888846397
Loss at iteration 850 : 0.026665398851037025
Loss at iteration 860 : 0.019631344825029373
Loss at iteration 870 : 0.011003123596310616
Loss at iteration 880 : 0.01881570741534233
Loss at iteration 890 : 0.024856187403202057
Loss at iteration 900 : 0.02891608700156212
Loss at iteration 910 : 0.017294570803642273
Loss at iteration 920 : 0.020782092586159706
Loss at iteration 930 : 0.027375465258955956
Loss at iteration 940 : 0.05113792046904564
Loss at iteration 950 : 0.025114282965660095
Loss at iteration 960 : 0.05110708624124527
Loss at iteration 970 : 0.031267039477825165
Loss at iteration 980 : 0.029680367559194565
Loss at iteration 990 : 0.02835044637322426
Loss at iteration 1000 : 0.04367782920598984
Loss at iteration 1010 : 0.021039549261331558
Loss at iteration 1020 : 0.021278806030750275
Loss at iteration 1030 : 0.02405112236738205
Loss at iteration 1040 : 0.047922223806381226
Loss at iteration 1050 : 0.025332730263471603
Loss at iteration 1060 : 0.013335391879081726
Loss at iteration 1070 : 0.023426547646522522
Loss at iteration 1080 : 0.022080132737755775
Loss at iteration 1090 : 0.0344504676759243
Loss at iteration 1100 : 0.023625755682587624
Loss at iteration 1110 : 0.029634181410074234
Loss at iteration 1120 : 0.016718633472919464
Loss at iteration 1130 : 0.016141146421432495
Loss at iteration 1140 : 0.02278413623571396
Loss at iteration 1150 : 0.023967623710632324
Loss at iteration 1160 : 0.01820249855518341
Loss at iteration 1170 : 0.024679072201251984
Loss at iteration 1180 : 0.025889670476317406
Loss at iteration 1190 : 0.021944541484117508
Loss at iteration 1200 : 0.021204303950071335
Loss at iteration 1210 : 0.026097729802131653
The SSIM Value is: 0.7753176887830099
The PSNR Value is: 18.213797760009765
the epoch is: 50
Loss at iteration 10 : 0.02767292410135269
Loss at iteration 20 : 0.014178595505654812
Loss at iteration 30 : 0.02279793843626976
Loss at iteration 40 : 0.02497759833931923
Loss at iteration 50 : 0.017595939338207245
Loss at iteration 60 : 0.02583187445998192
Loss at iteration 70 : 0.02715170755982399
Loss at iteration 80 : 0.02850106731057167
Loss at iteration 90 : 0.02799479104578495
Loss at iteration 100 : 0.0302567258477211
Loss at iteration 110 : 0.020551901310682297
Loss at iteration 120 : 0.01603749953210354
Loss at iteration 130 : 0.013472025282680988
Loss at iteration 140 : 0.03431594371795654
Loss at iteration 150 : 0.026485387235879898
Loss at iteration 160 : 0.012128341943025589
Loss at iteration 170 : 0.04347746819257736
Loss at iteration 180 : 0.024369824677705765
Loss at iteration 190 : 0.03201102837920189
Loss at iteration 200 : 0.033726781606674194
Loss at iteration 210 : 0.021564245223999023
Loss at iteration 220 : 0.035209186375141144
Loss at iteration 230 : 0.015952598303556442
Loss at iteration 240 : 0.016723021864891052
Loss at iteration 250 : 0.023251021280884743
Loss at iteration 260 : 0.040806420147418976
Loss at iteration 270 : 0.018268005922436714
Loss at iteration 280 : 0.02435564063489437
Loss at iteration 290 : 0.0298039261251688
Loss at iteration 300 : 0.015351009555161
Loss at iteration 310 : 0.02593953162431717
Loss at iteration 320 : 0.018358925357460976
Loss at iteration 330 : 0.03193594887852669
Loss at iteration 340 : 0.025388384237885475
Loss at iteration 350 : 0.022478120401501656
Loss at iteration 360 : 0.05699002742767334
Loss at iteration 370 : 0.03141602501273155
Loss at iteration 380 : 0.018046947196125984
Loss at iteration 390 : 0.0172820296138525
Loss at iteration 400 : 0.030980922281742096
Loss at iteration 410 : 0.033999230712652206
Loss at iteration 420 : 0.017508387565612793
Loss at iteration 430 : 0.036078907549381256
Loss at iteration 440 : 0.020965375006198883
Loss at iteration 450 : 0.02988767810165882
Loss at iteration 460 : 0.03910326212644577
Loss at iteration 470 : 0.01909242570400238
Loss at iteration 480 : 0.01774659752845764
Loss at iteration 490 : 0.020307855680584908
Loss at iteration 500 : 0.02120276540517807
Loss at iteration 510 : 0.016302423551678658
Loss at iteration 520 : 0.02524489164352417
Loss at iteration 530 : 0.030475115403532982
Loss at iteration 540 : 0.01906268671154976
Loss at iteration 550 : 0.02000587433576584
Loss at iteration 560 : 0.03480955958366394
Loss at iteration 570 : 0.02319767139852047
Loss at iteration 580 : 0.0262836255133152
Loss at iteration 590 : 0.03783552721142769
Loss at iteration 600 : 0.026837708428502083
Loss at iteration 610 : 0.025734495371580124
Loss at iteration 620 : 0.027771322056651115
Loss at iteration 630 : 0.023651285097002983
Loss at iteration 640 : 0.03252548724412918
Loss at iteration 650 : 0.029911424964666367
Loss at iteration 660 : 0.011786224320530891
Loss at iteration 670 : 0.012234177440404892
Loss at iteration 680 : 0.02022099494934082
Loss at iteration 690 : 0.016118910163640976
Loss at iteration 700 : 0.01561967097222805
Loss at iteration 710 : 0.016108345240354538
Loss at iteration 720 : 0.035361431539058685
Loss at iteration 730 : 0.02666613645851612
Loss at iteration 740 : 0.030219994485378265
Loss at iteration 750 : 0.020852627232670784
Loss at iteration 760 : 0.023602217435836792
Loss at iteration 770 : 0.028150193393230438
Loss at iteration 780 : 0.020853638648986816
Loss at iteration 790 : 0.018402956426143646
Loss at iteration 800 : 0.02334938384592533
Loss at iteration 810 : 0.01758531481027603
Loss at iteration 820 : 0.02854202128946781
Loss at iteration 830 : 0.019427578896284103
Loss at iteration 840 : 0.012840338051319122
Loss at iteration 850 : 0.02513197995722294
Loss at iteration 860 : 0.027216285467147827
Loss at iteration 870 : 0.023509403690695763
Loss at iteration 880 : 0.014546826481819153
Loss at iteration 890 : 0.022954363375902176
Loss at iteration 900 : 0.025169847533106804
Loss at iteration 910 : 0.024227045476436615
Loss at iteration 920 : 0.03865991532802582
Loss at iteration 930 : 0.029603276401758194
Loss at iteration 940 : 0.0247369185090065
Loss at iteration 950 : 0.023884471505880356
Loss at iteration 960 : 0.01883471943438053
Loss at iteration 970 : 0.015826627612113953
Loss at iteration 980 : 0.029741603881120682
Loss at iteration 990 : 0.02294660173356533
Loss at iteration 1000 : 0.02565077319741249
Loss at iteration 1010 : 0.014631257392466068
Loss at iteration 1020 : 0.016566475853323936
Loss at iteration 1030 : 0.03164459392428398
Loss at iteration 1040 : 0.03411264345049858
Loss at iteration 1050 : 0.025101497769355774
Loss at iteration 1060 : 0.023491568863391876
Loss at iteration 1070 : 0.014365620911121368
Loss at iteration 1080 : 0.026920374482870102
Loss at iteration 1090 : 0.021968699991703033
Loss at iteration 1100 : 0.03318130597472191
Loss at iteration 1110 : 0.02024053782224655
Loss at iteration 1120 : 0.057513609528541565
Loss at iteration 1130 : 0.023288894444704056
Loss at iteration 1140 : 0.02044571563601494
Loss at iteration 1150 : 0.02367660403251648
Loss at iteration 1160 : 0.021882133558392525
Loss at iteration 1170 : 0.02964705415070057
Loss at iteration 1180 : 0.023900242522358894
Loss at iteration 1190 : 0.017122477293014526
Loss at iteration 1200 : 0.012904379516839981
Loss at iteration 1210 : 0.022701764479279518
The SSIM Value is: 0.7721776286760966
The PSNR Value is: 18.235541979471844
the epoch is: 51
Loss at iteration 10 : 0.023422420024871826
Loss at iteration 20 : 0.016911078244447708
Loss at iteration 30 : 0.015942879021167755
Loss at iteration 40 : 0.03300128132104874
Loss at iteration 50 : 0.01622619852423668
Loss at iteration 60 : 0.026596691459417343
Loss at iteration 70 : 0.030134499073028564
Loss at iteration 80 : 0.02045205608010292
Loss at iteration 90 : 0.025621403008699417
Loss at iteration 100 : 0.028805898502469063
Loss at iteration 110 : 0.021444056183099747
Loss at iteration 120 : 0.017343588173389435
Loss at iteration 130 : 0.026098135858774185
Loss at iteration 140 : 0.02571815624833107
Loss at iteration 150 : 0.04718367010354996
Loss at iteration 160 : 0.021924659609794617
Loss at iteration 170 : 0.01624460518360138
Loss at iteration 180 : 0.01901168003678322
Loss at iteration 190 : 0.02436049096286297
Loss at iteration 200 : 0.053557805716991425
Loss at iteration 210 : 0.019055835902690887
Loss at iteration 220 : 0.02054090052843094
Loss at iteration 230 : 0.009081415832042694
Loss at iteration 240 : 0.0160656850785017
Loss at iteration 250 : 0.023457614704966545
Loss at iteration 260 : 0.014936001040041447
Loss at iteration 270 : 0.012170201167464256
Loss at iteration 280 : 0.018368255347013474
Loss at iteration 290 : 0.024568721652030945
Loss at iteration 300 : 0.01741407811641693
Loss at iteration 310 : 0.02720000222325325
Loss at iteration 320 : 0.029666583985090256
Loss at iteration 330 : 0.026036132127046585
Loss at iteration 340 : 0.016239475458860397
Loss at iteration 350 : 0.026527078822255135
Loss at iteration 360 : 0.024455662816762924
Loss at iteration 370 : 0.010260376147925854
Loss at iteration 380 : 0.024432916194200516
Loss at iteration 390 : 0.026777930557727814
Loss at iteration 400 : 0.016991324722766876
Loss at iteration 410 : 0.01890750043094158
Loss at iteration 420 : 0.032276853919029236
Loss at iteration 430 : 0.01576399616897106
Loss at iteration 440 : 0.014517860487103462
Loss at iteration 450 : 0.03048507124185562
Loss at iteration 460 : 0.02268906682729721
Loss at iteration 470 : 0.02245904877781868
Loss at iteration 480 : 0.017640788108110428
Loss at iteration 490 : 0.012762401252985
Loss at iteration 500 : 0.0186256505548954
Loss at iteration 510 : 0.02637428604066372
Loss at iteration 520 : 0.03505446016788483
Loss at iteration 530 : 0.028022777289152145
Loss at iteration 540 : 0.029201682657003403
Loss at iteration 550 : 0.0363331213593483
Loss at iteration 560 : 0.019297700375318527
Loss at iteration 570 : 0.03787390515208244
Loss at iteration 580 : 0.034037478268146515
Loss at iteration 590 : 0.019969575107097626
Loss at iteration 600 : 0.033179737627506256
Loss at iteration 610 : 0.02074984833598137
Loss at iteration 620 : 0.023324061185121536
Loss at iteration 630 : 0.02689848095178604
Loss at iteration 640 : 0.010984452441334724
Loss at iteration 650 : 0.015323509462177753
Loss at iteration 660 : 0.01327035017311573
Loss at iteration 670 : 0.02358384057879448
Loss at iteration 680 : 0.023694247007369995
Loss at iteration 690 : 0.019998012110590935
Loss at iteration 700 : 0.02308368682861328
Loss at iteration 710 : 0.02112456038594246
Loss at iteration 720 : 0.027200419455766678
Loss at iteration 730 : 0.020906373858451843
Loss at iteration 740 : 0.026491273194551468
Loss at iteration 750 : 0.013012507930397987
Loss at iteration 760 : 0.019057869911193848
Loss at iteration 770 : 0.028507325798273087
Loss at iteration 780 : 0.026397857815027237
Loss at iteration 790 : 0.022367721423506737
Loss at iteration 800 : 0.021461933851242065
Loss at iteration 810 : 0.023736469447612762
Loss at iteration 820 : 0.038544148206710815
Loss at iteration 830 : 0.03588345646858215
Loss at iteration 840 : 0.035711657255887985
Loss at iteration 850 : 0.021437808871269226
Loss at iteration 860 : 0.040864668786525726
Loss at iteration 870 : 0.026628896594047546
Loss at iteration 880 : 0.0158054381608963
Loss at iteration 890 : 0.039250969886779785
Loss at iteration 900 : 0.02278325892984867
Loss at iteration 910 : 0.021072544157505035
Loss at iteration 920 : 0.023971203714609146
Loss at iteration 930 : 0.02726719155907631
Loss at iteration 940 : 0.026257086545228958
Loss at iteration 950 : 0.020865190774202347
Loss at iteration 960 : 0.03175138682126999
Loss at iteration 970 : 0.025034788995981216
Loss at iteration 980 : 0.04850554093718529
Loss at iteration 990 : 0.02277928590774536
Loss at iteration 1000 : 0.018049733713269234
Loss at iteration 1010 : 0.02637014165520668
Loss at iteration 1020 : 0.03346676379442215
Loss at iteration 1030 : 0.017403315752744675
Loss at iteration 1040 : 0.02723946049809456
Loss at iteration 1050 : 0.023192431777715683
Loss at iteration 1060 : 0.018572645261883736
Loss at iteration 1070 : 0.028610248118638992
Loss at iteration 1080 : 0.013427818194031715
Loss at iteration 1090 : 0.02612103521823883
Loss at iteration 1100 : 0.03751612454652786
Loss at iteration 1110 : 0.047797322273254395
Loss at iteration 1120 : 0.01981283910572529
Loss at iteration 1130 : 0.036302074790000916
Loss at iteration 1140 : 0.023125585168600082
Loss at iteration 1150 : 0.020573614165186882
Loss at iteration 1160 : 0.01859542354941368
Loss at iteration 1170 : 0.019511789083480835
Loss at iteration 1180 : 0.025337450206279755
Loss at iteration 1190 : 0.018145430833101273
Loss at iteration 1200 : 0.024055495858192444
Loss at iteration 1210 : 0.020768417045474052
The SSIM Value is: 0.7752859115600585
The PSNR Value is: 18.19393850962321
the epoch is: 52
Loss at iteration 10 : 0.018170442432165146
Loss at iteration 20 : 0.025951974093914032
Loss at iteration 30 : 0.025442173704504967
Loss at iteration 40 : 0.015969403088092804
Loss at iteration 50 : 0.019845567643642426
Loss at iteration 60 : 0.02445775829255581
Loss at iteration 70 : 0.03444775193929672
Loss at iteration 80 : 0.023877084255218506
Loss at iteration 90 : 0.023452403023838997
Loss at iteration 100 : 0.023523829877376556
Loss at iteration 110 : 0.025924894958734512
Loss at iteration 120 : 0.027628663927316666
Loss at iteration 130 : 0.027770351618528366
Loss at iteration 140 : 0.020426006987690926
Loss at iteration 150 : 0.016548477113246918
Loss at iteration 160 : 0.019259635359048843
Loss at iteration 170 : 0.026457374915480614
Loss at iteration 180 : 0.03130157291889191
Loss at iteration 190 : 0.05767237767577171
Loss at iteration 200 : 0.012177681550383568
Loss at iteration 210 : 0.029790164902806282
Loss at iteration 220 : 0.01559910923242569
Loss at iteration 230 : 0.03763134777545929
Loss at iteration 240 : 0.01208120584487915
Loss at iteration 250 : 0.02198890596628189
Loss at iteration 260 : 0.030295055359601974
Loss at iteration 270 : 0.04126301780343056
Loss at iteration 280 : 0.014240494929254055
Loss at iteration 290 : 0.018775558099150658
Loss at iteration 300 : 0.035547927021980286
Loss at iteration 310 : 0.0193642545491457
Loss at iteration 320 : 0.022445060312747955
Loss at iteration 330 : 0.023428380489349365
Loss at iteration 340 : 0.025286825373768806
Loss at iteration 350 : 0.01946590095758438
Loss at iteration 360 : 0.024733776226639748
Loss at iteration 370 : 0.023660289123654366
Loss at iteration 380 : 0.019007433205842972
Loss at iteration 390 : 0.021932346746325493
Loss at iteration 400 : 0.021450866013765335
Loss at iteration 410 : 0.025212151929736137
Loss at iteration 420 : 0.036727167665958405
Loss at iteration 430 : 0.0244998037815094
Loss at iteration 440 : 0.018351156264543533
Loss at iteration 450 : 0.023353461176156998
Loss at iteration 460 : 0.02232181280851364
Loss at iteration 470 : 0.017745139077305794
Loss at iteration 480 : 0.026715584099292755
Loss at iteration 490 : 0.03491344302892685
Loss at iteration 500 : 0.025750044733285904
Loss at iteration 510 : 0.015127061866223812
Loss at iteration 520 : 0.02805759757757187
Loss at iteration 530 : 0.028422901406884193
Loss at iteration 540 : 0.028550053015351295
Loss at iteration 550 : 0.01617502048611641
Loss at iteration 560 : 0.02687714993953705
Loss at iteration 570 : 0.029526572674512863
Loss at iteration 580 : 0.033785223960876465
Loss at iteration 590 : 0.021705642342567444
Loss at iteration 600 : 0.017338622361421585
Loss at iteration 610 : 0.012678258121013641
Loss at iteration 620 : 0.02290479838848114
Loss at iteration 630 : 0.02387850359082222
Loss at iteration 640 : 0.031388502568006516
Loss at iteration 650 : 0.02339724823832512
Loss at iteration 660 : 0.030508246272802353
Loss at iteration 670 : 0.013647216372191906
Loss at iteration 680 : 0.01551212277263403
Loss at iteration 690 : 0.017254456877708435
Loss at iteration 700 : 0.021258115768432617
Loss at iteration 710 : 0.019577648490667343
Loss at iteration 720 : 0.03516083210706711
Loss at iteration 730 : 0.021279212087392807
Loss at iteration 740 : 0.014729618094861507
Loss at iteration 750 : 0.02510174550116062
Loss at iteration 760 : 0.03260480612516403
Loss at iteration 770 : 0.026227621361613274
Loss at iteration 780 : 0.02649160660803318
Loss at iteration 790 : 0.03525213897228241
Loss at iteration 800 : 0.026926176622509956
Loss at iteration 810 : 0.028545351698994637
Loss at iteration 820 : 0.01860688626766205
Loss at iteration 830 : 0.020934240892529488
Loss at iteration 840 : 0.01860184222459793
Loss at iteration 850 : 0.022559620440006256
Loss at iteration 860 : 0.02659972570836544
Loss at iteration 870 : 0.022212807089090347
Loss at iteration 880 : 0.015585407614707947
Loss at iteration 890 : 0.02825586497783661
Loss at iteration 900 : 0.019638221710920334
Loss at iteration 910 : 0.026814550161361694
Loss at iteration 920 : 0.024273589253425598
Loss at iteration 930 : 0.021983224898576736
Loss at iteration 940 : 0.024075159803032875
Loss at iteration 950 : 0.014714485965669155
Loss at iteration 960 : 0.037527114152908325
Loss at iteration 970 : 0.018481498584151268
Loss at iteration 980 : 0.029706310480833054
Loss at iteration 990 : 0.016057481989264488
Loss at iteration 1000 : 0.023155586794018745
Loss at iteration 1010 : 0.03084847331047058
Loss at iteration 1020 : 0.02476802095770836
Loss at iteration 1030 : 0.039183564484119415
Loss at iteration 1040 : 0.030702175572514534
Loss at iteration 1050 : 0.014566030353307724
Loss at iteration 1060 : 0.03945620357990265
Loss at iteration 1070 : 0.023241154849529266
Loss at iteration 1080 : 0.0203063003718853
Loss at iteration 1090 : 0.022486267611384392
Loss at iteration 1100 : 0.021938683465123177
Loss at iteration 1110 : 0.029474357143044472
Loss at iteration 1120 : 0.03229412063956261
Loss at iteration 1130 : 0.013102658092975616
Loss at iteration 1140 : 0.021489154547452927
Loss at iteration 1150 : 0.02530265599489212
Loss at iteration 1160 : 0.02301255613565445
Loss at iteration 1170 : 0.02503249980509281
Loss at iteration 1180 : 0.02762582339346409
Loss at iteration 1190 : 0.024030614644289017
Loss at iteration 1200 : 0.027746733278036118
Loss at iteration 1210 : 0.015855703502893448
The SSIM Value is: 0.7732501069704691
The PSNR Value is: 18.060487683614095
the epoch is: 53
Loss at iteration 10 : 0.022452834993600845
Loss at iteration 20 : 0.020819850265979767
Loss at iteration 30 : 0.038305722177028656
Loss at iteration 40 : 0.022468455135822296
Loss at iteration 50 : 0.023053057491779327
Loss at iteration 60 : 0.025044122710824013
Loss at iteration 70 : 0.017655959352850914
Loss at iteration 80 : 0.01994246244430542
Loss at iteration 90 : 0.029141027480363846
Loss at iteration 100 : 0.03040975145995617
Loss at iteration 110 : 0.014995609410107136
Loss at iteration 120 : 0.03213890641927719
Loss at iteration 130 : 0.016853954643011093
Loss at iteration 140 : 0.02172888070344925
Loss at iteration 150 : 0.02210085466504097
Loss at iteration 160 : 0.019689612090587616
Loss at iteration 170 : 0.029388640075922012
Loss at iteration 180 : 0.027455048635601997
Loss at iteration 190 : 0.02516339160501957
Loss at iteration 200 : 0.01820092275738716
Loss at iteration 210 : 0.01929486356675625
Loss at iteration 220 : 0.020081685855984688
Loss at iteration 230 : 0.0255443025380373
Loss at iteration 240 : 0.029048003256320953
Loss at iteration 250 : 0.03817133605480194
Loss at iteration 260 : 0.02819833904504776
Loss at iteration 270 : 0.015673942863941193
Loss at iteration 280 : 0.022930897772312164
Loss at iteration 290 : 0.01856151781976223
Loss at iteration 300 : 0.030793264508247375
Loss at iteration 310 : 0.020255722105503082
Loss at iteration 320 : 0.014495950192213058
Loss at iteration 330 : 0.03076496347784996
Loss at iteration 340 : 0.03219136595726013
Loss at iteration 350 : 0.02340761385858059
Loss at iteration 360 : 0.016862649470567703
Loss at iteration 370 : 0.025111135095357895
Loss at iteration 380 : 0.016213927417993546
Loss at iteration 390 : 0.023753803223371506
Loss at iteration 400 : 0.032207801938056946
Loss at iteration 410 : 0.021561281755566597
Loss at iteration 420 : 0.03591712564229965
Loss at iteration 430 : 0.04007802903652191
Loss at iteration 440 : 0.02595316618680954
Loss at iteration 450 : 0.029606934636831284
Loss at iteration 460 : 0.020010903477668762
Loss at iteration 470 : 0.023076776415109634
Loss at iteration 480 : 0.03363047540187836
Loss at iteration 490 : 0.03779976814985275
Loss at iteration 500 : 0.022336194291710854
Loss at iteration 510 : 0.03023923560976982
Loss at iteration 520 : 0.020322386175394058
Loss at iteration 530 : 0.028250934556126595
Loss at iteration 540 : 0.01423775963485241
Loss at iteration 550 : 0.038360439240932465
Loss at iteration 560 : 0.01911022886633873
Loss at iteration 570 : 0.021786954253911972
Loss at iteration 580 : 0.020702045410871506
Loss at iteration 590 : 0.024380236864089966
Loss at iteration 600 : 0.021868687123060226
Loss at iteration 610 : 0.020684750750660896
Loss at iteration 620 : 0.030247077345848083
Loss at iteration 630 : 0.02541366219520569
Loss at iteration 640 : 0.02836674451828003
Loss at iteration 650 : 0.03001224435865879
Loss at iteration 660 : 0.018979931250214577
Loss at iteration 670 : 0.029234880581498146
Loss at iteration 680 : 0.019302012398838997
Loss at iteration 690 : 0.02919420599937439
Loss at iteration 700 : 0.020741894841194153
Loss at iteration 710 : 0.022260475903749466
Loss at iteration 720 : 0.017705803737044334
Loss at iteration 730 : 0.029173623770475388
Loss at iteration 740 : 0.013922433368861675
Loss at iteration 750 : 0.021886559203267097
Loss at iteration 760 : 0.023450979962944984
Loss at iteration 770 : 0.0164379570633173
Loss at iteration 780 : 0.02504722774028778
Loss at iteration 790 : 0.023372003808617592
Loss at iteration 800 : 0.019096899777650833
Loss at iteration 810 : 0.014597920700907707
Loss at iteration 820 : 0.017168795689940453
Loss at iteration 830 : 0.0294206403195858
Loss at iteration 840 : 0.02185698226094246
Loss at iteration 850 : 0.019207293167710304
Loss at iteration 860 : 0.029002204537391663
Loss at iteration 870 : 0.017635703086853027
Loss at iteration 880 : 0.015410717576742172
Loss at iteration 890 : 0.04244791716337204
Loss at iteration 900 : 0.02715473622083664
Loss at iteration 910 : 0.03349647298455238
Loss at iteration 920 : 0.03615114092826843
Loss at iteration 930 : 0.02287377417087555
Loss at iteration 940 : 0.022758757695555687
Loss at iteration 950 : 0.020537611097097397
Loss at iteration 960 : 0.028056414797902107
Loss at iteration 970 : 0.026723982766270638
Loss at iteration 980 : 0.018417391926050186
Loss at iteration 990 : 0.023298367857933044
Loss at iteration 1000 : 0.018521592020988464
Loss at iteration 1010 : 0.02657170221209526
Loss at iteration 1020 : 0.026770297437906265
Loss at iteration 1030 : 0.029934003949165344
Loss at iteration 1040 : 0.015974974259734154
Loss at iteration 1050 : 0.027374207973480225
Loss at iteration 1060 : 0.021056972444057465
Loss at iteration 1070 : 0.03522736206650734
Loss at iteration 1080 : 0.019800391048192978
Loss at iteration 1090 : 0.011140666902065277
Loss at iteration 1100 : 0.012966752983629704
Loss at iteration 1110 : 0.043777309358119965
Loss at iteration 1120 : 0.021159760653972626
Loss at iteration 1130 : 0.0217231847345829
Loss at iteration 1140 : 0.03359818086028099
Loss at iteration 1150 : 0.02601679600775242
Loss at iteration 1160 : 0.016875050961971283
Loss at iteration 1170 : 0.032602593302726746
Loss at iteration 1180 : 0.02914150059223175
Loss at iteration 1190 : 0.011730358004570007
Loss at iteration 1200 : 0.011793093755841255
Loss at iteration 1210 : 0.019465815275907516
The SSIM Value is: 0.7776374022165934
The PSNR Value is: 18.418375396728514
the highest SSIM value is: 18.418375396728514
the epoch is: 54
Loss at iteration 10 : 0.032249778509140015
Loss at iteration 20 : 0.044993408024311066
Loss at iteration 30 : 0.018557222560048103
Loss at iteration 40 : 0.021427715197205544
Loss at iteration 50 : 0.017981626093387604
Loss at iteration 60 : 0.01703338325023651
Loss at iteration 70 : 0.024289529770612717
Loss at iteration 80 : 0.023566363379359245
Loss at iteration 90 : 0.03899715840816498
Loss at iteration 100 : 0.02588101476430893
Loss at iteration 110 : 0.026760585606098175
Loss at iteration 120 : 0.018221162259578705
Loss at iteration 130 : 0.02372886799275875
Loss at iteration 140 : 0.01925645023584366
Loss at iteration 150 : 0.026208695024251938
Loss at iteration 160 : 0.019713539630174637
Loss at iteration 170 : 0.021254008635878563
Loss at iteration 180 : 0.020183537155389786
Loss at iteration 190 : 0.018263254314661026
Loss at iteration 200 : 0.020056534558534622
Loss at iteration 210 : 0.024077963083982468
Loss at iteration 220 : 0.028347203508019447
Loss at iteration 230 : 0.03710535168647766
Loss at iteration 240 : 0.030836211517453194
Loss at iteration 250 : 0.026937134563922882
Loss at iteration 260 : 0.023034438490867615
Loss at iteration 270 : 0.026074063032865524
Loss at iteration 280 : 0.021477295085787773
Loss at iteration 290 : 0.02347288653254509
Loss at iteration 300 : 0.01747133582830429
Loss at iteration 310 : 0.021346885710954666
Loss at iteration 320 : 0.02078227698802948
Loss at iteration 330 : 0.021293342113494873
Loss at iteration 340 : 0.03469758853316307
Loss at iteration 350 : 0.0271503496915102
Loss at iteration 360 : 0.033726826310157776
Loss at iteration 370 : 0.022170627489686012
Loss at iteration 380 : 0.03113529458642006
Loss at iteration 390 : 0.0245194174349308
Loss at iteration 400 : 0.03174690902233124
Loss at iteration 410 : 0.015148616395890713
Loss at iteration 420 : 0.026716070249676704
Loss at iteration 430 : 0.024896256625652313
Loss at iteration 440 : 0.02127409167587757
Loss at iteration 450 : 0.028104372322559357
Loss at iteration 460 : 0.02868538163602352
Loss at iteration 470 : 0.02446979284286499
Loss at iteration 480 : 0.023303501307964325
Loss at iteration 490 : 0.04260282218456268
Loss at iteration 500 : 0.01898300088942051
Loss at iteration 510 : 0.04582963138818741
Loss at iteration 520 : 0.02127612754702568
Loss at iteration 530 : 0.03848188742995262
Loss at iteration 540 : 0.024120479822158813
Loss at iteration 550 : 0.022122127935290337
Loss at iteration 560 : 0.018299072980880737
Loss at iteration 570 : 0.026423795148730278
Loss at iteration 580 : 0.03301995247602463
Loss at iteration 590 : 0.022626705467700958
Loss at iteration 600 : 0.024467259645462036
Loss at iteration 610 : 0.021735522896051407
Loss at iteration 620 : 0.03845977783203125
Loss at iteration 630 : 0.013540777377784252
Loss at iteration 640 : 0.02405620366334915
Loss at iteration 650 : 0.025366012006998062
Loss at iteration 660 : 0.026124857366085052
Loss at iteration 670 : 0.014405504800379276
Loss at iteration 680 : 0.027515623718500137
Loss at iteration 690 : 0.022371334955096245
Loss at iteration 700 : 0.01966431736946106
Loss at iteration 710 : 0.019015558063983917
Loss at iteration 720 : 0.02396966516971588
Loss at iteration 730 : 0.015258897095918655
Loss at iteration 740 : 0.018362127244472504
Loss at iteration 750 : 0.017939850687980652
Loss at iteration 760 : 0.021913306787610054
Loss at iteration 770 : 0.026819691061973572
Loss at iteration 780 : 0.02794087678194046
Loss at iteration 790 : 0.02946186251938343
Loss at iteration 800 : 0.015554702840745449
Loss at iteration 810 : 0.02059255540370941
Loss at iteration 820 : 0.02766682393848896
Loss at iteration 830 : 0.02325531654059887
Loss at iteration 840 : 0.014159610494971275
Loss at iteration 850 : 0.026383107528090477
Loss at iteration 860 : 0.021445877850055695
Loss at iteration 870 : 0.015171967446804047
Loss at iteration 880 : 0.018815219402313232
Loss at iteration 890 : 0.01887081004679203
Loss at iteration 900 : 0.039734091609716415
Loss at iteration 910 : 0.017983321100473404
Loss at iteration 920 : 0.015907803550362587
Loss at iteration 930 : 0.01556503213942051
Loss at iteration 940 : 0.020507819950580597
Loss at iteration 950 : 0.017335394397377968
Loss at iteration 960 : 0.017544979229569435
Loss at iteration 970 : 0.018239710479974747
Loss at iteration 980 : 0.03355875611305237
Loss at iteration 990 : 0.022814223542809486
Loss at iteration 1000 : 0.032655954360961914
Loss at iteration 1010 : 0.025157256051898003
Loss at iteration 1020 : 0.023584311828017235
Loss at iteration 1030 : 0.023018531501293182
Loss at iteration 1040 : 0.022968005388975143
Loss at iteration 1050 : 0.02960742451250553
Loss at iteration 1060 : 0.01934192143380642
Loss at iteration 1070 : 0.01566460356116295
Loss at iteration 1080 : 0.02849508821964264
Loss at iteration 1090 : 0.022028032690286636
Loss at iteration 1100 : 0.012493044137954712
Loss at iteration 1110 : 0.018408356234431267
Loss at iteration 1120 : 0.031353943049907684
Loss at iteration 1130 : 0.033597201108932495
Loss at iteration 1140 : 0.024389224126935005
Loss at iteration 1150 : 0.022760974243283272
Loss at iteration 1160 : 0.016849907115101814
Loss at iteration 1170 : 0.01931779459118843
Loss at iteration 1180 : 0.02552212029695511
Loss at iteration 1190 : 0.022788140922784805
Loss at iteration 1200 : 0.04665499925613403
Loss at iteration 1210 : 0.027013393118977547
The SSIM Value is: 0.7750001788139343
The PSNR Value is: 18.132154528299967
the epoch is: 55
Loss at iteration 10 : 0.025784065946936607
Loss at iteration 20 : 0.009813939221203327
Loss at iteration 30 : 0.015818681567907333
Loss at iteration 40 : 0.021200446411967278
Loss at iteration 50 : 0.02859414741396904
Loss at iteration 60 : 0.02848447486758232
Loss at iteration 70 : 0.013333072885870934
Loss at iteration 80 : 0.02201937884092331
Loss at iteration 90 : 0.04390083625912666
Loss at iteration 100 : 0.014877982437610626
Loss at iteration 110 : 0.027388734742999077
Loss at iteration 120 : 0.025824079290032387
Loss at iteration 130 : 0.01701544225215912
Loss at iteration 140 : 0.016579721122980118
Loss at iteration 150 : 0.016184208914637566
Loss at iteration 160 : 0.016338109970092773
Loss at iteration 170 : 0.0246923565864563
Loss at iteration 180 : 0.017852354794740677
Loss at iteration 190 : 0.02422616071999073
Loss at iteration 200 : 0.024569286033511162
Loss at iteration 210 : 0.025349710136651993
Loss at iteration 220 : 0.024740681052207947
Loss at iteration 230 : 0.02098264917731285
Loss at iteration 240 : 0.024177968502044678
Loss at iteration 250 : 0.021699927747249603
Loss at iteration 260 : 0.03335059434175491
Loss at iteration 270 : 0.018756773322820663
Loss at iteration 280 : 0.022544551640748978
Loss at iteration 290 : 0.033206965774297714
Loss at iteration 300 : 0.01938522607088089
Loss at iteration 310 : 0.015720156952738762
Loss at iteration 320 : 0.019372059032320976
Loss at iteration 330 : 0.018748270347714424
Loss at iteration 340 : 0.014157388359308243
Loss at iteration 350 : 0.02193751372396946
Loss at iteration 360 : 0.02351618930697441
Loss at iteration 370 : 0.018429763615131378
Loss at iteration 380 : 0.028686216101050377
Loss at iteration 390 : 0.023184604942798615
Loss at iteration 400 : 0.029640227556228638
Loss at iteration 410 : 0.019625719636678696
Loss at iteration 420 : 0.026198623701930046
Loss at iteration 430 : 0.03441110625863075
Loss at iteration 440 : 0.021920066326856613
Loss at iteration 450 : 0.02520175278186798
Loss at iteration 460 : 0.028070978820323944
Loss at iteration 470 : 0.0129665806889534
Loss at iteration 480 : 0.042180415242910385
Loss at iteration 490 : 0.01514756865799427
Loss at iteration 500 : 0.02307078428566456
Loss at iteration 510 : 0.013072313740849495
Loss at iteration 520 : 0.02410232275724411
Loss at iteration 530 : 0.02253533899784088
Loss at iteration 540 : 0.024468977004289627
Loss at iteration 550 : 0.01667340099811554
Loss at iteration 560 : 0.03142755851149559
Loss at iteration 570 : 0.02232947200536728
Loss at iteration 580 : 0.025567304342985153
Loss at iteration 590 : 0.030575113371014595
Loss at iteration 600 : 0.03169065713882446
Loss at iteration 610 : 0.03916185349225998
Loss at iteration 620 : 0.03784163296222687
Loss at iteration 630 : 0.03603503108024597
Loss at iteration 640 : 0.019887682050466537
Loss at iteration 650 : 0.018238402903079987
Loss at iteration 660 : 0.022567104548215866
Loss at iteration 670 : 0.021971002221107483
Loss at iteration 680 : 0.026474110782146454
Loss at iteration 690 : 0.019820561632514
Loss at iteration 700 : 0.02250230684876442
Loss at iteration 710 : 0.025073280557990074
Loss at iteration 720 : 0.019336696714162827
Loss at iteration 730 : 0.024216970428824425
Loss at iteration 740 : 0.028338175266981125
Loss at iteration 750 : 0.01594068482518196
Loss at iteration 760 : 0.02515927329659462
Loss at iteration 770 : 0.03492894768714905
Loss at iteration 780 : 0.019708560779690742
Loss at iteration 790 : 0.02491089329123497
Loss at iteration 800 : 0.011222216300666332
Loss at iteration 810 : 0.016369260847568512
Loss at iteration 820 : 0.02630569413304329
Loss at iteration 830 : 0.01972344145178795
Loss at iteration 840 : 0.036684636026620865
Loss at iteration 850 : 0.026887934654951096
Loss at iteration 860 : 0.03014807403087616
Loss at iteration 870 : 0.026809394359588623
Loss at iteration 880 : 0.0345374159514904
Loss at iteration 890 : 0.030721118673682213
Loss at iteration 900 : 0.0391521230340004
Loss at iteration 910 : 0.026066891849040985
Loss at iteration 920 : 0.012449630536139011
Loss at iteration 930 : 0.026204008609056473
Loss at iteration 940 : 0.02643776684999466
Loss at iteration 950 : 0.024798279628157616
Loss at iteration 960 : 0.02046401984989643
Loss at iteration 970 : 0.02296178974211216
Loss at iteration 980 : 0.021124884486198425
Loss at iteration 990 : 0.025260502472519875
Loss at iteration 1000 : 0.030480850487947464
Loss at iteration 1010 : 0.02678130939602852
Loss at iteration 1020 : 0.013201955705881119
Loss at iteration 1030 : 0.027069130912423134
Loss at iteration 1040 : 0.02783972956240177
Loss at iteration 1050 : 0.02614816278219223
Loss at iteration 1060 : 0.031366016715765
Loss at iteration 1070 : 0.022509071975946426
Loss at iteration 1080 : 0.026336152106523514
Loss at iteration 1090 : 0.029127731919288635
Loss at iteration 1100 : 0.022301672026515007
Loss at iteration 1110 : 0.02363617904484272
Loss at iteration 1120 : 0.027561552822589874
Loss at iteration 1130 : 0.02408771775662899
Loss at iteration 1140 : 0.021638521924614906
Loss at iteration 1150 : 0.022397128865122795
Loss at iteration 1160 : 0.02036154270172119
Loss at iteration 1170 : 0.026732930913567543
Loss at iteration 1180 : 0.026902202516794205
Loss at iteration 1190 : 0.023780107498168945
Loss at iteration 1200 : 0.017719637602567673
Loss at iteration 1210 : 0.019960880279541016
The SSIM Value is: 0.7771871387958527
The PSNR Value is: 18.130422655741373
the epoch is: 56
Loss at iteration 10 : 0.02771732583642006
Loss at iteration 20 : 0.01867295801639557
Loss at iteration 30 : 0.02287130057811737
Loss at iteration 40 : 0.021528519690036774
Loss at iteration 50 : 0.023768389597535133
Loss at iteration 60 : 0.025616638362407684
Loss at iteration 70 : 0.039026156067848206
Loss at iteration 80 : 0.020926477387547493
Loss at iteration 90 : 0.036369167268276215
Loss at iteration 100 : 0.021113425493240356
Loss at iteration 110 : 0.02363530918955803
Loss at iteration 120 : 0.02238343097269535
Loss at iteration 130 : 0.025161050260066986
Loss at iteration 140 : 0.01180207822471857
Loss at iteration 150 : 0.027590712532401085
Loss at iteration 160 : 0.030539551749825478
Loss at iteration 170 : 0.03713566064834595
Loss at iteration 180 : 0.030348634347319603
Loss at iteration 190 : 0.027438301593065262
Loss at iteration 200 : 0.020417872816324234
Loss at iteration 210 : 0.020971348509192467
Loss at iteration 220 : 0.021560588851571083
Loss at iteration 230 : 0.019896380603313446
Loss at iteration 240 : 0.01538090966641903
Loss at iteration 250 : 0.031234242022037506
Loss at iteration 260 : 0.020780391991138458
Loss at iteration 270 : 0.016688993200659752
Loss at iteration 280 : 0.030217938125133514
Loss at iteration 290 : 0.027745474129915237
Loss at iteration 300 : 0.03415786474943161
Loss at iteration 310 : 0.020787851884961128
Loss at iteration 320 : 0.01855640858411789
Loss at iteration 330 : 0.024380382150411606
Loss at iteration 340 : 0.0158885158598423
Loss at iteration 350 : 0.02504025772213936
Loss at iteration 360 : 0.01573801599442959
Loss at iteration 370 : 0.025784451514482498
Loss at iteration 380 : 0.020949162542819977
Loss at iteration 390 : 0.02158968336880207
Loss at iteration 400 : 0.030650192871689796
Loss at iteration 410 : 0.02855224348604679
Loss at iteration 420 : 0.030796092003583908
Loss at iteration 430 : 0.011804521083831787
Loss at iteration 440 : 0.01754835993051529
Loss at iteration 450 : 0.016847247257828712
Loss at iteration 460 : 0.026894275099039078
Loss at iteration 470 : 0.018924126401543617
Loss at iteration 480 : 0.017106082290410995
Loss at iteration 490 : 0.02476552687585354
Loss at iteration 500 : 0.022347670048475266
Loss at iteration 510 : 0.03060094639658928
Loss at iteration 520 : 0.02900572121143341
Loss at iteration 530 : 0.021540269255638123
Loss at iteration 540 : 0.022136013954877853
Loss at iteration 550 : 0.030682623386383057
Loss at iteration 560 : 0.018921108916401863
Loss at iteration 570 : 0.017649179324507713
Loss at iteration 580 : 0.025865286588668823
Loss at iteration 590 : 0.025236641988158226
Loss at iteration 600 : 0.019162755459547043
Loss at iteration 610 : 0.03162876144051552
Loss at iteration 620 : 0.027142565697431564
Loss at iteration 630 : 0.016897719353437424
Loss at iteration 640 : 0.01667177490890026
Loss at iteration 650 : 0.02483832836151123
Loss at iteration 660 : 0.03043418377637863
Loss at iteration 670 : 0.01935160718858242
Loss at iteration 680 : 0.025436922907829285
Loss at iteration 690 : 0.028621453791856766
Loss at iteration 700 : 0.01824720948934555
Loss at iteration 710 : 0.018883660435676575
Loss at iteration 720 : 0.03795062005519867
Loss at iteration 730 : 0.025207137688994408
Loss at iteration 740 : 0.02573060244321823
Loss at iteration 750 : 0.03043026477098465
Loss at iteration 760 : 0.028334859758615494
Loss at iteration 770 : 0.03360402584075928
Loss at iteration 780 : 0.020569536834955215
Loss at iteration 790 : 0.023472104221582413
Loss at iteration 800 : 0.03107910230755806
Loss at iteration 810 : 0.01830291375517845
Loss at iteration 820 : 0.035740926861763
Loss at iteration 830 : 0.02153557352721691
Loss at iteration 840 : 0.03579690307378769
Loss at iteration 850 : 0.014854034408926964
Loss at iteration 860 : 0.033094294369220734
Loss at iteration 870 : 0.023527566343545914
Loss at iteration 880 : 0.017839370295405388
Loss at iteration 890 : 0.024734698235988617
Loss at iteration 900 : 0.01851074770092964
Loss at iteration 910 : 0.02343078702688217
Loss at iteration 920 : 0.01061374880373478
Loss at iteration 930 : 0.041101567447185516
Loss at iteration 940 : 0.027802754193544388
Loss at iteration 950 : 0.026827408000826836
Loss at iteration 960 : 0.04117079824209213
Loss at iteration 970 : 0.033025022596120834
Loss at iteration 980 : 0.025183022022247314
Loss at iteration 990 : 0.014592776075005531
Loss at iteration 1000 : 0.02464599721133709
Loss at iteration 1010 : 0.026456089690327644
Loss at iteration 1020 : 0.02127024531364441
Loss at iteration 1030 : 0.02784905582666397
Loss at iteration 1040 : 0.015836860984563828
Loss at iteration 1050 : 0.025600414723157883
Loss at iteration 1060 : 0.023365914821624756
Loss at iteration 1070 : 0.018079662695527077
Loss at iteration 1080 : 0.02318422496318817
Loss at iteration 1090 : 0.02158421277999878
Loss at iteration 1100 : 0.030782954767346382
Loss at iteration 1110 : 0.025228533893823624
Loss at iteration 1120 : 0.03129391372203827
Loss at iteration 1130 : 0.042865462601184845
Loss at iteration 1140 : 0.0327424630522728
Loss at iteration 1150 : 0.03011402301490307
Loss at iteration 1160 : 0.028701916337013245
Loss at iteration 1170 : 0.025203827768564224
Loss at iteration 1180 : 0.02635633572936058
Loss at iteration 1190 : 0.02091408707201481
Loss at iteration 1200 : 0.03153393417596817
Loss at iteration 1210 : 0.018539464101195335
The SSIM Value is: 0.7738816459973653
The PSNR Value is: 17.86337687174479
the epoch is: 57
Loss at iteration 10 : 0.0315474197268486
Loss at iteration 20 : 0.033793698996305466
Loss at iteration 30 : 0.033284395933151245
Loss at iteration 40 : 0.028185972943902016
Loss at iteration 50 : 0.026367424055933952
Loss at iteration 60 : 0.025086354464292526
Loss at iteration 70 : 0.031477246433496475
Loss at iteration 80 : 0.022777264937758446
Loss at iteration 90 : 0.022760670632123947
Loss at iteration 100 : 0.017474308609962463
Loss at iteration 110 : 0.017090074717998505
Loss at iteration 120 : 0.02854492887854576
Loss at iteration 130 : 0.023292092606425285
Loss at iteration 140 : 0.025083336979150772
Loss at iteration 150 : 0.027043571695685387
Loss at iteration 160 : 0.015080777928233147
Loss at iteration 170 : 0.030005313456058502
Loss at iteration 180 : 0.028625771403312683
Loss at iteration 190 : 0.026441819965839386
Loss at iteration 200 : 0.025465689599514008
Loss at iteration 210 : 0.02196720615029335
Loss at iteration 220 : 0.019637396559119225
Loss at iteration 230 : 0.015265400521457195
Loss at iteration 240 : 0.019504673779010773
Loss at iteration 250 : 0.022641660645604134
Loss at iteration 260 : 0.01356281153857708
Loss at iteration 270 : 0.03217567875981331
Loss at iteration 280 : 0.0325162336230278
Loss at iteration 290 : 0.0210960004478693
Loss at iteration 300 : 0.02259199321269989
Loss at iteration 310 : 0.0395284965634346
Loss at iteration 320 : 0.017830263823270798
Loss at iteration 330 : 0.031924109905958176
Loss at iteration 340 : 0.03397814929485321
Loss at iteration 350 : 0.02838660031557083
Loss at iteration 360 : 0.032776638865470886
Loss at iteration 370 : 0.03898666054010391
Loss at iteration 380 : 0.02580515667796135
Loss at iteration 390 : 0.013722233474254608
Loss at iteration 400 : 0.020321602001786232
Loss at iteration 410 : 0.01859758421778679
Loss at iteration 420 : 0.0257114190608263
Loss at iteration 430 : 0.017937492579221725
Loss at iteration 440 : 0.021280944347381592
Loss at iteration 450 : 0.04332296922802925
Loss at iteration 460 : 0.030029870569705963
Loss at iteration 470 : 0.033033981919288635
Loss at iteration 480 : 0.016118712723255157
Loss at iteration 490 : 0.028188563883304596
Loss at iteration 500 : 0.03903639689087868
Loss at iteration 510 : 0.02058694139122963
Loss at iteration 520 : 0.01843976601958275
Loss at iteration 530 : 0.03156644105911255
Loss at iteration 540 : 0.022934768348932266
Loss at iteration 550 : 0.023554373532533646
Loss at iteration 560 : 0.028569607064127922
Loss at iteration 570 : 0.01940390095114708
Loss at iteration 580 : 0.01596325822174549
Loss at iteration 590 : 0.032439347356557846
Loss at iteration 600 : 0.02196408249437809
Loss at iteration 610 : 0.019766686484217644
Loss at iteration 620 : 0.03804578632116318
Loss at iteration 630 : 0.017890112474560738
Loss at iteration 640 : 0.031172696501016617
Loss at iteration 650 : 0.017326876521110535
Loss at iteration 660 : 0.03762362152338028
Loss at iteration 670 : 0.021213483065366745
Loss at iteration 680 : 0.016185585409402847
Loss at iteration 690 : 0.026691997423768044
Loss at iteration 700 : 0.03231017664074898
Loss at iteration 710 : 0.03240519016981125
Loss at iteration 720 : 0.014317778870463371
Loss at iteration 730 : 0.020840827375650406
Loss at iteration 740 : 0.013180195353925228
Loss at iteration 750 : 0.027685755863785744
Loss at iteration 760 : 0.03231513500213623
Loss at iteration 770 : 0.02335766889154911
Loss at iteration 780 : 0.020086660981178284
Loss at iteration 790 : 0.017891038209199905
Loss at iteration 800 : 0.02223404124379158
Loss at iteration 810 : 0.019153043627738953
Loss at iteration 820 : 0.023092254996299744
Loss at iteration 830 : 0.025128144770860672
Loss at iteration 840 : 0.04616418108344078
Loss at iteration 850 : 0.017628882080316544
Loss at iteration 860 : 0.042982347309589386
Loss at iteration 870 : 0.022486871108412743
Loss at iteration 880 : 0.017294593155384064
Loss at iteration 890 : 0.02167348563671112
Loss at iteration 900 : 0.026022132486104965
Loss at iteration 910 : 0.017214253544807434
Loss at iteration 920 : 0.02993699535727501
Loss at iteration 930 : 0.028003228828310966
Loss at iteration 940 : 0.02413245663046837
Loss at iteration 950 : 0.013391713611781597
Loss at iteration 960 : 0.03302353248000145
Loss at iteration 970 : 0.015311961993575096
Loss at iteration 980 : 0.02591286599636078
Loss at iteration 990 : 0.029797643423080444
Loss at iteration 1000 : 0.02541131153702736
Loss at iteration 1010 : 0.02283678576350212
Loss at iteration 1020 : 0.027034660801291466
Loss at iteration 1030 : 0.03446017950773239
Loss at iteration 1040 : 0.016974983736872673
Loss at iteration 1050 : 0.0247048232704401
Loss at iteration 1060 : 0.017902854830026627
Loss at iteration 1070 : 0.02130519598722458
Loss at iteration 1080 : 0.01533520594239235
Loss at iteration 1090 : 0.013961181044578552
Loss at iteration 1100 : 0.030666232109069824
Loss at iteration 1110 : 0.04366973787546158
Loss at iteration 1120 : 0.02668556571006775
Loss at iteration 1130 : 0.016263330355286598
Loss at iteration 1140 : 0.013357790187001228
Loss at iteration 1150 : 0.034713320434093475
Loss at iteration 1160 : 0.01758810132741928
Loss at iteration 1170 : 0.023980669677257538
Loss at iteration 1180 : 0.04434951767325401
Loss at iteration 1190 : 0.02623606100678444
Loss at iteration 1200 : 0.03750056400895119
Loss at iteration 1210 : 0.029539112001657486
The SSIM Value is: 0.7747853934764862
The PSNR Value is: 17.735017204284667
the epoch is: 58
Loss at iteration 10 : 0.010285209864377975
Loss at iteration 20 : 0.04572983458638191
Loss at iteration 30 : 0.029677560552954674
Loss at iteration 40 : 0.028625138103961945
Loss at iteration 50 : 0.01972983218729496
Loss at iteration 60 : 0.023404046893119812
Loss at iteration 70 : 0.020970245823264122
Loss at iteration 80 : 0.02926090732216835
Loss at iteration 90 : 0.0282164067029953
Loss at iteration 100 : 0.0138936098664999
Loss at iteration 110 : 0.024066146463155746
Loss at iteration 120 : 0.018496448174118996
Loss at iteration 130 : 0.03259125351905823
Loss at iteration 140 : 0.022868938744068146
Loss at iteration 150 : 0.01758635975420475
Loss at iteration 160 : 0.033447567373514175
Loss at iteration 170 : 0.03364928811788559
Loss at iteration 180 : 0.022001191973686218
Loss at iteration 190 : 0.01892390474677086
Loss at iteration 200 : 0.014058250002563
Loss at iteration 210 : 0.018871983513236046
Loss at iteration 220 : 0.029904941096901894
Loss at iteration 230 : 0.01655113697052002
Loss at iteration 240 : 0.02781176194548607
Loss at iteration 250 : 0.013816251419484615
Loss at iteration 260 : 0.019677065312862396
Loss at iteration 270 : 0.03482923284173012
Loss at iteration 280 : 0.017923804000020027
Loss at iteration 290 : 0.02326679416000843
Loss at iteration 300 : 0.011333580128848553
Loss at iteration 310 : 0.020306840538978577
Loss at iteration 320 : 0.016816742718219757
Loss at iteration 330 : 0.02818838134407997
Loss at iteration 340 : 0.029094547033309937
Loss at iteration 350 : 0.017832497134804726
Loss at iteration 360 : 0.022999610751867294
Loss at iteration 370 : 0.026119006797671318
Loss at iteration 380 : 0.020564954727888107
Loss at iteration 390 : 0.014205865561962128
Loss at iteration 400 : 0.023800060153007507
Loss at iteration 410 : 0.01739436388015747
Loss at iteration 420 : 0.02215021848678589
Loss at iteration 430 : 0.014182894490659237
Loss at iteration 440 : 0.017390217632055283
Loss at iteration 450 : 0.013538702391088009
Loss at iteration 460 : 0.03311698138713837
Loss at iteration 470 : 0.0248065497726202
Loss at iteration 480 : 0.015682443976402283
Loss at iteration 490 : 0.02262483909726143
Loss at iteration 500 : 0.01660984382033348
Loss at iteration 510 : 0.027920998632907867
Loss at iteration 520 : 0.0210830420255661
Loss at iteration 530 : 0.03120715171098709
Loss at iteration 540 : 0.030554428696632385
Loss at iteration 550 : 0.017161622643470764
Loss at iteration 560 : 0.033724941313266754
Loss at iteration 570 : 0.02234388142824173
Loss at iteration 580 : 0.025984443724155426
Loss at iteration 590 : 0.02943483367562294
Loss at iteration 600 : 0.0306566022336483
Loss at iteration 610 : 0.020145278424024582
Loss at iteration 620 : 0.02113448642194271
Loss at iteration 630 : 0.02132815681397915
Loss at iteration 640 : 0.040252476930618286
Loss at iteration 650 : 0.022417347878217697
Loss at iteration 660 : 0.01591198891401291
Loss at iteration 670 : 0.0479327067732811
Loss at iteration 680 : 0.024306170642375946
Loss at iteration 690 : 0.02061903104186058
Loss at iteration 700 : 0.02887978032231331
Loss at iteration 710 : 0.02442576363682747
Loss at iteration 720 : 0.029772639274597168
Loss at iteration 730 : 0.023585602641105652
Loss at iteration 740 : 0.02151460200548172
Loss at iteration 750 : 0.026769626885652542
Loss at iteration 760 : 0.03807833045721054
Loss at iteration 770 : 0.023558543995022774
Loss at iteration 780 : 0.026985792443156242
Loss at iteration 790 : 0.02669001743197441
Loss at iteration 800 : 0.01922297105193138
Loss at iteration 810 : 0.012535701505839825
Loss at iteration 820 : 0.025045502930879593
Loss at iteration 830 : 0.02397167682647705
Loss at iteration 840 : 0.025713391602039337
Loss at iteration 850 : 0.016181020066142082
Loss at iteration 860 : 0.028221026062965393
Loss at iteration 870 : 0.020058855414390564
Loss at iteration 880 : 0.01739128679037094
Loss at iteration 890 : 0.023821569979190826
Loss at iteration 900 : 0.03445865586400032
Loss at iteration 910 : 0.03275669366121292
Loss at iteration 920 : 0.03106875903904438
Loss at iteration 930 : 0.022651076316833496
Loss at iteration 940 : 0.023902416229248047
Loss at iteration 950 : 0.022410377860069275
Loss at iteration 960 : 0.026251357048749924
Loss at iteration 970 : 0.023037342354655266
Loss at iteration 980 : 0.017708271741867065
Loss at iteration 990 : 0.029009662568569183
Loss at iteration 1000 : 0.017336180433630943
Loss at iteration 1010 : 0.03885322064161301
Loss at iteration 1020 : 0.01796172931790352
Loss at iteration 1030 : 0.026978299021720886
Loss at iteration 1040 : 0.019386744126677513
Loss at iteration 1050 : 0.017152730375528336
Loss at iteration 1060 : 0.023865453898906708
Loss at iteration 1070 : 0.017384465783834457
Loss at iteration 1080 : 0.02579117938876152
Loss at iteration 1090 : 0.03460372984409332
Loss at iteration 1100 : 0.01780351996421814
Loss at iteration 1110 : 0.02317260205745697
Loss at iteration 1120 : 0.01925395056605339
Loss at iteration 1130 : 0.03430764749646187
Loss at iteration 1140 : 0.013733459636569023
Loss at iteration 1150 : 0.03261575102806091
Loss at iteration 1160 : 0.03425874561071396
Loss at iteration 1170 : 0.02617499604821205
Loss at iteration 1180 : 0.030234042555093765
Loss at iteration 1190 : 0.023503653705120087
Loss at iteration 1200 : 0.016052568331360817
Loss at iteration 1210 : 0.033696867525577545
The SSIM Value is: 0.7682897408803304
The PSNR Value is: 17.026262474060058
the epoch is: 59
Loss at iteration 10 : 0.04823458939790726
Loss at iteration 20 : 0.016738038510084152
Loss at iteration 30 : 0.01869482547044754
Loss at iteration 40 : 0.029562950134277344
Loss at iteration 50 : 0.03712879866361618
Loss at iteration 60 : 0.026246093213558197
Loss at iteration 70 : 0.01961960271000862
Loss at iteration 80 : 0.025446971878409386
Loss at iteration 90 : 0.027831558138132095
Loss at iteration 100 : 0.021815191954374313
Loss at iteration 110 : 0.03411180153489113
Loss at iteration 120 : 0.038964349776506424
Loss at iteration 130 : 0.027001962065696716
Loss at iteration 140 : 0.02800069749355316
Loss at iteration 150 : 0.02196136675775051
Loss at iteration 160 : 0.02195768803358078
Loss at iteration 170 : 0.0171164870262146
Loss at iteration 180 : 0.03477214276790619
Loss at iteration 190 : 0.018746841698884964
Loss at iteration 200 : 0.03406877815723419
Loss at iteration 210 : 0.013922581449151039
Loss at iteration 220 : 0.01957307755947113
Loss at iteration 230 : 0.016128141433000565
Loss at iteration 240 : 0.03180341795086861
Loss at iteration 250 : 0.021786633878946304
Loss at iteration 260 : 0.03219068795442581
Loss at iteration 270 : 0.02848222479224205
Loss at iteration 280 : 0.0164639875292778
Loss at iteration 290 : 0.03168714419007301
Loss at iteration 300 : 0.02459646388888359
Loss at iteration 310 : 0.012625141069293022
Loss at iteration 320 : 0.0220678448677063
Loss at iteration 330 : 0.017211779952049255
Loss at iteration 340 : 0.02555352821946144
Loss at iteration 350 : 0.027967292815446854
Loss at iteration 360 : 0.020737186074256897
Loss at iteration 370 : 0.025993693619966507
Loss at iteration 380 : 0.025765620172023773
Loss at iteration 390 : 0.021776419132947922
Loss at iteration 400 : 0.04453442990779877
Loss at iteration 410 : 0.019481755793094635
Loss at iteration 420 : 0.020762749016284943
Loss at iteration 430 : 0.0137461693957448
Loss at iteration 440 : 0.012035568244755268
Loss at iteration 450 : 0.016842585057020187
Loss at iteration 460 : 0.021143991500139236
Loss at iteration 470 : 0.038661736994981766
Loss at iteration 480 : 0.029841333627700806
Loss at iteration 490 : 0.01717330887913704
Loss at iteration 500 : 0.027464119717478752
Loss at iteration 510 : 0.02947232313454151
Loss at iteration 520 : 0.03221544623374939
Loss at iteration 530 : 0.02719246782362461
Loss at iteration 540 : 0.02785682864487171
Loss at iteration 550 : 0.03057318925857544
Loss at iteration 560 : 0.01971193589270115
Loss at iteration 570 : 0.03707064688205719
Loss at iteration 580 : 0.032625712454319
Loss at iteration 590 : 0.020186880603432655
Loss at iteration 600 : 0.02899145893752575
Loss at iteration 610 : 0.02366221882402897
Loss at iteration 620 : 0.02450769580900669
Loss at iteration 630 : 0.02638278156518936
Loss at iteration 640 : 0.01959281414747238
Loss at iteration 650 : 0.03202594071626663
Loss at iteration 660 : 0.030546054244041443
Loss at iteration 670 : 0.025423385202884674
Loss at iteration 680 : 0.024526316672563553
Loss at iteration 690 : 0.028850331902503967
Loss at iteration 700 : 0.03283055126667023
Loss at iteration 710 : 0.04548439756035805
Loss at iteration 720 : 0.022045670077204704
Loss at iteration 730 : 0.03484911471605301
Loss at iteration 740 : 0.02165452018380165
Loss at iteration 750 : 0.02603168413043022
Loss at iteration 760 : 0.01919165626168251
Loss at iteration 770 : 0.018124833703041077
Loss at iteration 780 : 0.027569880709052086
Loss at iteration 790 : 0.013812253251671791
Loss at iteration 800 : 0.031314652413129807
Loss at iteration 810 : 0.024615313857793808
Loss at iteration 820 : 0.025392305105924606
Loss at iteration 830 : 0.029367243871092796
Loss at iteration 840 : 0.019067177549004555
Loss at iteration 850 : 0.018654925748705864
Loss at iteration 860 : 0.03463566303253174
Loss at iteration 870 : 0.023317014798521996
Loss at iteration 880 : 0.0367707759141922
Loss at iteration 890 : 0.02577686309814453
Loss at iteration 900 : 0.02302877977490425
Loss at iteration 910 : 0.030062086880207062
Loss at iteration 920 : 0.027933375909924507
Loss at iteration 930 : 0.019066667184233665
Loss at iteration 940 : 0.019350802525877953
Loss at iteration 950 : 0.033103328198194504
Loss at iteration 960 : 0.02526545338332653
Loss at iteration 970 : 0.02462437003850937
Loss at iteration 980 : 0.027702931314706802
Loss at iteration 990 : 0.025114407762885094
Loss at iteration 1000 : 0.019102849066257477
Loss at iteration 1010 : 0.03025810420513153
Loss at iteration 1020 : 0.023406770080327988
Loss at iteration 1030 : 0.0307049248367548
Loss at iteration 1040 : 0.016162414103746414
Loss at iteration 1050 : 0.03662148490548134
Loss at iteration 1060 : 0.015537899918854237
Loss at iteration 1070 : 0.025210142135620117
Loss at iteration 1080 : 0.02527695894241333
Loss at iteration 1090 : 0.017130374908447266
Loss at iteration 1100 : 0.025133401155471802
Loss at iteration 1110 : 0.028625639155507088
Loss at iteration 1120 : 0.0156481321901083
Loss at iteration 1130 : 0.030445672571659088
Loss at iteration 1140 : 0.028192618861794472
Loss at iteration 1150 : 0.02184063196182251
Loss at iteration 1160 : 0.01511242613196373
Loss at iteration 1170 : 0.03360353037714958
Loss at iteration 1180 : 0.022398265078663826
Loss at iteration 1190 : 0.016692543402314186
Loss at iteration 1200 : 0.025181863456964493
Loss at iteration 1210 : 0.033072859048843384
The SSIM Value is: 0.7793866554896037
The PSNR Value is: 18.32956746419271
the epoch is: 60
Loss at iteration 10 : 0.012167280539870262
Loss at iteration 20 : 0.019136492162942886
Loss at iteration 30 : 0.02795121818780899
Loss at iteration 40 : 0.022852538153529167
Loss at iteration 50 : 0.022598154842853546
Loss at iteration 60 : 0.02829272300004959
Loss at iteration 70 : 0.018831603229045868
Loss at iteration 80 : 0.024182243272662163
Loss at iteration 90 : 0.01815275475382805
Loss at iteration 100 : 0.027073320001363754
Loss at iteration 110 : 0.016057996079325676
Loss at iteration 120 : 0.012505284510552883
Loss at iteration 130 : 0.02669690176844597
Loss at iteration 140 : 0.01074204221367836
Loss at iteration 150 : 0.04034731537103653
Loss at iteration 160 : 0.025597337633371353
Loss at iteration 170 : 0.022967752069234848
Loss at iteration 180 : 0.016880085691809654
Loss at iteration 190 : 0.020299550145864487
Loss at iteration 200 : 0.021248552948236465
Loss at iteration 210 : 0.02345532551407814
Loss at iteration 220 : 0.026439156383275986
Loss at iteration 230 : 0.021430207416415215
Loss at iteration 240 : 0.01950501836836338
Loss at iteration 250 : 0.021395880728960037
Loss at iteration 260 : 0.02319410629570484
Loss at iteration 270 : 0.023712145164608955
Loss at iteration 280 : 0.013050336390733719
Loss at iteration 290 : 0.020427269861102104
Loss at iteration 300 : 0.022445522248744965
Loss at iteration 310 : 0.01864766888320446
Loss at iteration 320 : 0.02317204885184765
Loss at iteration 330 : 0.018139701336622238
Loss at iteration 340 : 0.03441145271062851
Loss at iteration 350 : 0.024840209633111954
Loss at iteration 360 : 0.025238461792469025
Loss at iteration 370 : 0.025400325655937195
Loss at iteration 380 : 0.023426957428455353
Loss at iteration 390 : 0.03662813454866409
Loss at iteration 400 : 0.023631252348423004
Loss at iteration 410 : 0.024223342537879944
Loss at iteration 420 : 0.029947441071271896
Loss at iteration 430 : 0.02680618315935135
Loss at iteration 440 : 0.02997879683971405
Loss at iteration 450 : 0.02254696562886238
Loss at iteration 460 : 0.021981164813041687
Loss at iteration 470 : 0.022440742701292038
Loss at iteration 480 : 0.041333265602588654
Loss at iteration 490 : 0.023285649716854095
Loss at iteration 500 : 0.041572555899620056
Loss at iteration 510 : 0.022052699699997902
Loss at iteration 520 : 0.030766118317842484
Loss at iteration 530 : 0.039376065135002136
Loss at iteration 540 : 0.024220801889896393
Loss at iteration 550 : 0.02936936542391777
Loss at iteration 560 : 0.01809958554804325
Loss at iteration 570 : 0.025011342018842697
Loss at iteration 580 : 0.015467491000890732
Loss at iteration 590 : 0.014542201533913612
Loss at iteration 600 : 0.01586342789232731
Loss at iteration 610 : 0.01784169301390648
Loss at iteration 620 : 0.027322830632328987
Loss at iteration 630 : 0.026070216670632362
Loss at iteration 640 : 0.025363674387335777
Loss at iteration 650 : 0.02946084924042225
Loss at iteration 660 : 0.02891448885202408
Loss at iteration 670 : 0.02568140998482704
Loss at iteration 680 : 0.02152240090072155
Loss at iteration 690 : 0.039820119738578796
Loss at iteration 700 : 0.03637855127453804
Loss at iteration 710 : 0.02915201522409916
Loss at iteration 720 : 0.03487483784556389
Loss at iteration 730 : 0.028043562546372414
Loss at iteration 740 : 0.014848555438220501
Loss at iteration 750 : 0.020603179931640625
Loss at iteration 760 : 0.02044488675892353
Loss at iteration 770 : 0.03410785272717476
Loss at iteration 780 : 0.03361322730779648
Loss at iteration 790 : 0.01423359289765358
Loss at iteration 800 : 0.0191325880587101
Loss at iteration 810 : 0.028084369376301765
Loss at iteration 820 : 0.03080887533724308
Loss at iteration 830 : 0.019796594977378845
Loss at iteration 840 : 0.019784417003393173
Loss at iteration 850 : 0.024228349328041077
Loss at iteration 860 : 0.04915759712457657
Loss at iteration 870 : 0.025243137031793594
Loss at iteration 880 : 0.029104946181178093
Loss at iteration 890 : 0.018538132309913635
Loss at iteration 900 : 0.030136089771986008
Loss at iteration 910 : 0.022698847576975822
Loss at iteration 920 : 0.019238024950027466
Loss at iteration 930 : 0.022639598697423935
Loss at iteration 940 : 0.03044055961072445
Loss at iteration 950 : 0.028668906539678574
Loss at iteration 960 : 0.023760836571455002
Loss at iteration 970 : 0.021718181669712067
Loss at iteration 980 : 0.04048273712396622
Loss at iteration 990 : 0.028351008892059326
Loss at iteration 1000 : 0.03091302700340748
Loss at iteration 1010 : 0.0195615217089653
Loss at iteration 1020 : 0.026139680296182632
Loss at iteration 1030 : 0.014455044642090797
Loss at iteration 1040 : 0.02167014591395855
Loss at iteration 1050 : 0.013999754562973976
Loss at iteration 1060 : 0.02742728590965271
Loss at iteration 1070 : 0.020989080891013145
Loss at iteration 1080 : 0.01901114359498024
Loss at iteration 1090 : 0.019898638129234314
Loss at iteration 1100 : 0.022057494148612022
Loss at iteration 1110 : 0.024506591260433197
Loss at iteration 1120 : 0.02268468588590622
Loss at iteration 1130 : 0.034689001739025116
Loss at iteration 1140 : 0.015412071719765663
Loss at iteration 1150 : 0.0228567011654377
Loss at iteration 1160 : 0.014123475179076195
Loss at iteration 1170 : 0.02103210985660553
Loss at iteration 1180 : 0.02855604514479637
Loss at iteration 1190 : 0.02823200449347496
Loss at iteration 1200 : 0.029274476692080498
Loss at iteration 1210 : 0.01569349505007267
The SSIM Value is: 0.7344289382298788
The PSNR Value is: 15.277501360575359
the epoch is: 61
Loss at iteration 10 : 0.02610762044787407
Loss at iteration 20 : 0.018139181658625603
Loss at iteration 30 : 0.015259664505720139
Loss at iteration 40 : 0.02034473419189453
Loss at iteration 50 : 0.013709839433431625
Loss at iteration 60 : 0.019051294773817062
Loss at iteration 70 : 0.02058931067585945
Loss at iteration 80 : 0.023432806134223938
Loss at iteration 90 : 0.030220840126276016
Loss at iteration 100 : 0.0301115233451128
Loss at iteration 110 : 0.018554024398326874
Loss at iteration 120 : 0.028005018830299377
Loss at iteration 130 : 0.030627546831965446
Loss at iteration 140 : 0.04327027499675751
Loss at iteration 150 : 0.024147674441337585
Loss at iteration 160 : 0.022991223260760307
Loss at iteration 170 : 0.02327618934214115
Loss at iteration 180 : 0.05309596657752991
Loss at iteration 190 : 0.045282118022441864
Loss at iteration 200 : 0.015469733625650406
Loss at iteration 210 : 0.014486280269920826
Loss at iteration 220 : 0.02473471686244011
Loss at iteration 230 : 0.0166238471865654
Loss at iteration 240 : 0.01623387634754181
Loss at iteration 250 : 0.020622193813323975
Loss at iteration 260 : 0.026968367397785187
Loss at iteration 270 : 0.027790328487753868
Loss at iteration 280 : 0.01811784878373146
Loss at iteration 290 : 0.029020586982369423
Loss at iteration 300 : 0.022709492594003677
Loss at iteration 310 : 0.01656031236052513
Loss at iteration 320 : 0.03091585263609886
Loss at iteration 330 : 0.027123086154460907
Loss at iteration 340 : 0.022015700116753578
Loss at iteration 350 : 0.01905588060617447
Loss at iteration 360 : 0.021466189995408058
Loss at iteration 370 : 0.029919814318418503
Loss at iteration 380 : 0.027317214757204056
Loss at iteration 390 : 0.01973036304116249
Loss at iteration 400 : 0.024250268936157227
Loss at iteration 410 : 0.018018970265984535
Loss at iteration 420 : 0.04331193119287491
Loss at iteration 430 : 0.020782770588994026
Loss at iteration 440 : 0.03158323094248772
Loss at iteration 450 : 0.032075315713882446
Loss at iteration 460 : 0.027012526988983154
Loss at iteration 470 : 0.013516206294298172
Loss at iteration 480 : 0.012051928788423538
Loss at iteration 490 : 0.02364915981888771
Loss at iteration 500 : 0.02718130499124527
Loss at iteration 510 : 0.03550710529088974
Loss at iteration 520 : 0.01869923435151577
Loss at iteration 530 : 0.02729106694459915
Loss at iteration 540 : 0.022214466705918312
Loss at iteration 550 : 0.03880242630839348
Loss at iteration 560 : 0.029482049867510796
Loss at iteration 570 : 0.02892129123210907
Loss at iteration 580 : 0.024639956653118134
Loss at iteration 590 : 0.02587491273880005
Loss at iteration 600 : 0.054673872888088226
Loss at iteration 610 : 0.025397513061761856
Loss at iteration 620 : 0.017502591013908386
Loss at iteration 630 : 0.03384292870759964
Loss at iteration 640 : 0.02196020632982254
Loss at iteration 650 : 0.02053341269493103
Loss at iteration 660 : 0.024827249348163605
Loss at iteration 670 : 0.021548818796873093
Loss at iteration 680 : 0.029775038361549377
Loss at iteration 690 : 0.02358471043407917
Loss at iteration 700 : 0.02412412129342556
Loss at iteration 710 : 0.02481095679104328
Loss at iteration 720 : 0.030163224786520004
Loss at iteration 730 : 0.034628596156835556
Loss at iteration 740 : 0.020447198301553726
Loss at iteration 750 : 0.03215140104293823
Loss at iteration 760 : 0.03959670662879944
Loss at iteration 770 : 0.03382737189531326
Loss at iteration 780 : 0.029367469251155853
Loss at iteration 790 : 0.02666362375020981
Loss at iteration 800 : 0.029357992112636566
Loss at iteration 810 : 0.022894959896802902
Loss at iteration 820 : 0.023079976439476013
Loss at iteration 830 : 0.022976789623498917
Loss at iteration 840 : 0.02557903528213501
Loss at iteration 850 : 0.03897194191813469
Loss at iteration 860 : 0.025571592152118683
Loss at iteration 870 : 0.0218794122338295
Loss at iteration 880 : 0.03174615651369095
Loss at iteration 890 : 0.027878643944859505
Loss at iteration 900 : 0.01898418739438057
Loss at iteration 910 : 0.029194973409175873
Loss at iteration 920 : 0.014282731339335442
Loss at iteration 930 : 0.018791794776916504
Loss at iteration 940 : 0.020369593054056168
Loss at iteration 950 : 0.028099294751882553
Loss at iteration 960 : 0.04809662327170372
Loss at iteration 970 : 0.02713841013610363
Loss at iteration 980 : 0.014479625970125198
Loss at iteration 990 : 0.02412569709122181
Loss at iteration 1000 : 0.03960830718278885
Loss at iteration 1010 : 0.01764880120754242
Loss at iteration 1020 : 0.01694253832101822
Loss at iteration 1030 : 0.0216470155864954
Loss at iteration 1040 : 0.019216831773519516
Loss at iteration 1050 : 0.027191907167434692
Loss at iteration 1060 : 0.02896878309547901
Loss at iteration 1070 : 0.030880501493811607
Loss at iteration 1080 : 0.024524182081222534
Loss at iteration 1090 : 0.02891010232269764
Loss at iteration 1100 : 0.018700720742344856
Loss at iteration 1110 : 0.01903989538550377
Loss at iteration 1120 : 0.026462364941835403
Loss at iteration 1130 : 0.033736422657966614
Loss at iteration 1140 : 0.027172071859240532
Loss at iteration 1150 : 0.017822911962866783
Loss at iteration 1160 : 0.020269352942705154
Loss at iteration 1170 : 0.02214767411351204
Loss at iteration 1180 : 0.029332680627703667
Loss at iteration 1190 : 0.025105275213718414
Loss at iteration 1200 : 0.020109765231609344
Loss at iteration 1210 : 0.02891024574637413
The SSIM Value is: 0.7615160385767619
The PSNR Value is: 16.45639572143555
the epoch is: 62
Loss at iteration 10 : 0.04415665939450264
Loss at iteration 20 : 0.018672792240977287
Loss at iteration 30 : 0.052400536835193634
Loss at iteration 40 : 0.027401626110076904
Loss at iteration 50 : 0.022311188280582428
Loss at iteration 60 : 0.018807481974363327
Loss at iteration 70 : 0.022770896553993225
Loss at iteration 80 : 0.02294190227985382
Loss at iteration 90 : 0.029348257929086685
Loss at iteration 100 : 0.04044870659708977
Loss at iteration 110 : 0.02386646345257759
Loss at iteration 120 : 0.03316136822104454
Loss at iteration 130 : 0.03043566271662712
Loss at iteration 140 : 0.02286122739315033
Loss at iteration 150 : 0.022075414657592773
Loss at iteration 160 : 0.03919164836406708
Loss at iteration 170 : 0.021281348541378975
Loss at iteration 180 : 0.023771408945322037
Loss at iteration 190 : 0.014873621985316277
Loss at iteration 200 : 0.016045231372117996
Loss at iteration 210 : 0.01754225231707096
Loss at iteration 220 : 0.025656305253505707
Loss at iteration 230 : 0.01932891085743904
Loss at iteration 240 : 0.01972103677690029
Loss at iteration 250 : 0.02233678475022316
Loss at iteration 260 : 0.02703683078289032
Loss at iteration 270 : 0.03976397588849068
Loss at iteration 280 : 0.03197309747338295
Loss at iteration 290 : 0.01452197227627039
Loss at iteration 300 : 0.016506385058164597
Loss at iteration 310 : 0.017224615439772606
Loss at iteration 320 : 0.0137015450745821
Loss at iteration 330 : 0.026616295799613
Loss at iteration 340 : 0.026124900206923485
Loss at iteration 350 : 0.026744339615106583
Loss at iteration 360 : 0.027798166498541832
Loss at iteration 370 : 0.017952339723706245
Loss at iteration 380 : 0.040602415800094604
Loss at iteration 390 : 0.020520519465208054
Loss at iteration 400 : 0.02914484031498432
Loss at iteration 410 : 0.023206792771816254
Loss at iteration 420 : 0.02455342747271061
Loss at iteration 430 : 0.018501514568924904
Loss at iteration 440 : 0.028027692809700966
Loss at iteration 450 : 0.06605589389801025
Loss at iteration 460 : 0.021293703466653824
Loss at iteration 470 : 0.01926804520189762
Loss at iteration 480 : 0.02308402583003044
Loss at iteration 490 : 0.03691625967621803
Loss at iteration 500 : 0.0216403566300869
Loss at iteration 510 : 0.016341280192136765
Loss at iteration 520 : 0.025421051308512688
Loss at iteration 530 : 0.021604925394058228
Loss at iteration 540 : 0.029516398906707764
Loss at iteration 550 : 0.016985677182674408
Loss at iteration 560 : 0.025082439184188843
Loss at iteration 570 : 0.026137106120586395
Loss at iteration 580 : 0.018091095611453056
Loss at iteration 590 : 0.03713691979646683
Loss at iteration 600 : 0.03258347138762474
Loss at iteration 610 : 0.018064498901367188
Loss at iteration 620 : 0.016140807420015335
Loss at iteration 630 : 0.02536340244114399
Loss at iteration 640 : 0.02800149843096733
Loss at iteration 650 : 0.021215982735157013
Loss at iteration 660 : 0.02609831839799881
Loss at iteration 670 : 0.014959941618144512
Loss at iteration 680 : 0.025927260518074036
Loss at iteration 690 : 0.02031400427222252
Loss at iteration 700 : 0.027117963880300522
Loss at iteration 710 : 0.017461420968174934
Loss at iteration 720 : 0.020054342225193977
Loss at iteration 730 : 0.02144021913409233
Loss at iteration 740 : 0.015097635798156261
Loss at iteration 750 : 0.021257853135466576
Loss at iteration 760 : 0.0324765183031559
Loss at iteration 770 : 0.016593167558312416
Loss at iteration 780 : 0.022768843919038773
Loss at iteration 790 : 0.01757931336760521
Loss at iteration 800 : 0.023186327889561653
Loss at iteration 810 : 0.03212941065430641
Loss at iteration 820 : 0.025285905227065086
Loss at iteration 830 : 0.02684873342514038
Loss at iteration 840 : 0.01917136088013649
Loss at iteration 850 : 0.017958827316761017
Loss at iteration 860 : 0.01895102486014366
Loss at iteration 870 : 0.02517658844590187
Loss at iteration 880 : 0.024925291538238525
Loss at iteration 890 : 0.024806959554553032
Loss at iteration 900 : 0.03196288272738457
Loss at iteration 910 : 0.027644434943795204
Loss at iteration 920 : 0.016456879675388336
Loss at iteration 930 : 0.029720287770032883
Loss at iteration 940 : 0.0271572545170784
Loss at iteration 950 : 0.03602498397231102
Loss at iteration 960 : 0.02117149904370308
Loss at iteration 970 : 0.026062654331326485
Loss at iteration 980 : 0.03187115862965584
Loss at iteration 990 : 0.034913722425699234
Loss at iteration 1000 : 0.02462947554886341
Loss at iteration 1010 : 0.03593418002128601
Loss at iteration 1020 : 0.03408380225300789
Loss at iteration 1030 : 0.018642082810401917
Loss at iteration 1040 : 0.025314923375844955
Loss at iteration 1050 : 0.024680055677890778
Loss at iteration 1060 : 0.01750747486948967
Loss at iteration 1070 : 0.022879812866449356
Loss at iteration 1080 : 0.022807156667113304
Loss at iteration 1090 : 0.014474744908511639
Loss at iteration 1100 : 0.025625500828027725
Loss at iteration 1110 : 0.019792407751083374
Loss at iteration 1120 : 0.01823153719305992
Loss at iteration 1130 : 0.020402124151587486
Loss at iteration 1140 : 0.023056602105498314
Loss at iteration 1150 : 0.015579108148813248
Loss at iteration 1160 : 0.0280317272990942
Loss at iteration 1170 : 0.02725551649928093
Loss at iteration 1180 : 0.03118964284658432
Loss at iteration 1190 : 0.025088828057050705
Loss at iteration 1200 : 0.019395845010876656
Loss at iteration 1210 : 0.01933995634317398
The SSIM Value is: 0.7825313448905945
The PSNR Value is: 18.349458249409995
the epoch is: 63
Loss at iteration 10 : 0.06049283593893051
Loss at iteration 20 : 0.019285161048173904
Loss at iteration 30 : 0.024911893531680107
Loss at iteration 40 : 0.03802571818232536
Loss at iteration 50 : 0.020777104422450066
Loss at iteration 60 : 0.014127274975180626
Loss at iteration 70 : 0.021922048181295395
Loss at iteration 80 : 0.022979537025094032
Loss at iteration 90 : 0.012802007608115673
Loss at iteration 100 : 0.03163843974471092
Loss at iteration 110 : 0.021527715027332306
Loss at iteration 120 : 0.013014046475291252
Loss at iteration 130 : 0.019259698688983917
Loss at iteration 140 : 0.022314388304948807
Loss at iteration 150 : 0.024350889027118683
Loss at iteration 160 : 0.023109186440706253
Loss at iteration 170 : 0.017309706658124924
Loss at iteration 180 : 0.02970801293849945
Loss at iteration 190 : 0.01720903441309929
Loss at iteration 200 : 0.04840216040611267
Loss at iteration 210 : 0.023544788360595703
Loss at iteration 220 : 0.021903596818447113
Loss at iteration 230 : 0.02960975095629692
Loss at iteration 240 : 0.017992403358221054
Loss at iteration 250 : 0.015940964221954346
Loss at iteration 260 : 0.019458474591374397
Loss at iteration 270 : 0.022377369925379753
Loss at iteration 280 : 0.037167053669691086
Loss at iteration 290 : 0.01335972547531128
Loss at iteration 300 : 0.037418924272060394
Loss at iteration 310 : 0.04332149773836136
Loss at iteration 320 : 0.01591518707573414
Loss at iteration 330 : 0.02525223046541214
Loss at iteration 340 : 0.03056042641401291
Loss at iteration 350 : 0.01891276054084301
Loss at iteration 360 : 0.022341344505548477
Loss at iteration 370 : 0.01936355233192444
Loss at iteration 380 : 0.030341699719429016
Loss at iteration 390 : 0.023966696113348007
Loss at iteration 400 : 0.023812245577573776
Loss at iteration 410 : 0.02887522242963314
Loss at iteration 420 : 0.02335265278816223
Loss at iteration 430 : 0.030245710164308548
Loss at iteration 440 : 0.02370813488960266
Loss at iteration 450 : 0.024530751630663872
Loss at iteration 460 : 0.026096682995557785
Loss at iteration 470 : 0.023000678047537804
Loss at iteration 480 : 0.025706518441438675
Loss at iteration 490 : 0.019047178328037262
Loss at iteration 500 : 0.02615104243159294
Loss at iteration 510 : 0.021151447668671608
Loss at iteration 520 : 0.038960859179496765
Loss at iteration 530 : 0.04857586324214935
Loss at iteration 540 : 0.011824177578091621
Loss at iteration 550 : 0.02173422835767269
Loss at iteration 560 : 0.02876272238790989
Loss at iteration 570 : 0.02254202961921692
Loss at iteration 580 : 0.048824310302734375
Loss at iteration 590 : 0.025921132415533066
Loss at iteration 600 : 0.03624725341796875
Loss at iteration 610 : 0.022687748074531555
Loss at iteration 620 : 0.032328855246305466
Loss at iteration 630 : 0.022328756749629974
Loss at iteration 640 : 0.020248807966709137
Loss at iteration 650 : 0.028909964486956596
Loss at iteration 660 : 0.04025925695896149
Loss at iteration 670 : 0.022793833166360855
Loss at iteration 680 : 0.04608859121799469
Loss at iteration 690 : 0.015352535992860794
Loss at iteration 700 : 0.027623146772384644
Loss at iteration 710 : 0.02015184797346592
Loss at iteration 720 : 0.027025708928704262
Loss at iteration 730 : 0.028078526258468628
Loss at iteration 740 : 0.01989809051156044
Loss at iteration 750 : 0.027838483452796936
Loss at iteration 760 : 0.02835727110505104
Loss at iteration 770 : 0.01612281985580921
Loss at iteration 780 : 0.027329096570611
Loss at iteration 790 : 0.020651187747716904
Loss at iteration 800 : 0.019625836983323097
Loss at iteration 810 : 0.025677524507045746
Loss at iteration 820 : 0.030789032578468323
Loss at iteration 830 : 0.024859856814146042
Loss at iteration 840 : 0.03764921799302101
Loss at iteration 850 : 0.017726043239235878
Loss at iteration 860 : 0.02999458834528923
Loss at iteration 870 : 0.017466288059949875
Loss at iteration 880 : 0.02325567975640297
Loss at iteration 890 : 0.025987954810261726
Loss at iteration 900 : 0.0173044390976429
Loss at iteration 910 : 0.021760551258921623
Loss at iteration 920 : 0.02436661161482334
Loss at iteration 930 : 0.02357660047709942
Loss at iteration 940 : 0.015996232628822327
Loss at iteration 950 : 0.02251807227730751
Loss at iteration 960 : 0.015769612044095993
Loss at iteration 970 : 0.020894881337881088
Loss at iteration 980 : 0.040520079433918
Loss at iteration 990 : 0.02652902528643608
Loss at iteration 1000 : 0.01607975736260414
Loss at iteration 1010 : 0.0185927152633667
Loss at iteration 1020 : 0.017178382724523544
Loss at iteration 1030 : 0.031016230583190918
Loss at iteration 1040 : 0.029662838205695152
Loss at iteration 1050 : 0.015391318127512932
Loss at iteration 1060 : 0.030040163546800613
Loss at iteration 1070 : 0.02879505790770054
Loss at iteration 1080 : 0.021898362785577774
Loss at iteration 1090 : 0.02151552401483059
Loss at iteration 1100 : 0.015881478786468506
Loss at iteration 1110 : 0.02946612425148487
Loss at iteration 1120 : 0.017161550000309944
Loss at iteration 1130 : 0.029323086142539978
Loss at iteration 1140 : 0.01888374611735344
Loss at iteration 1150 : 0.017786744982004166
Loss at iteration 1160 : 0.02646855264902115
Loss at iteration 1170 : 0.024949461221694946
Loss at iteration 1180 : 0.03335309028625488
Loss at iteration 1190 : 0.023213451728224754
Loss at iteration 1200 : 0.03222287446260452
Loss at iteration 1210 : 0.02876194566488266
The SSIM Value is: 0.7676510135332744
The PSNR Value is: 16.879839769999187
the epoch is: 64
Loss at iteration 10 : 0.018828436732292175
Loss at iteration 20 : 0.019790783524513245
Loss at iteration 30 : 0.02909053862094879
Loss at iteration 40 : 0.02458646148443222
Loss at iteration 50 : 0.029581133276224136
Loss at iteration 60 : 0.04192265868186951
Loss at iteration 70 : 0.0445430614054203
Loss at iteration 80 : 0.02379508875310421
Loss at iteration 90 : 0.03642205893993378
Loss at iteration 100 : 0.024487588554620743
Loss at iteration 110 : 0.015389621257781982
Loss at iteration 120 : 0.0353088341653347
Loss at iteration 130 : 0.022123653441667557
Loss at iteration 140 : 0.037050943821668625
Loss at iteration 150 : 0.03168094903230667
Loss at iteration 160 : 0.03662458807229996
Loss at iteration 170 : 0.017169423401355743
Loss at iteration 180 : 0.022943001240491867
Loss at iteration 190 : 0.028009658679366112
Loss at iteration 200 : 0.009973473846912384
Loss at iteration 210 : 0.02081412635743618
Loss at iteration 220 : 0.02299799956381321
Loss at iteration 230 : 0.021589120849967003
Loss at iteration 240 : 0.02519364282488823
Loss at iteration 250 : 0.03421786054968834
Loss at iteration 260 : 0.02977113239467144
Loss at iteration 270 : 0.03604310005903244
Loss at iteration 280 : 0.016801252961158752
Loss at iteration 290 : 0.026752889156341553
Loss at iteration 300 : 0.023583419620990753
Loss at iteration 310 : 0.0159999318420887
Loss at iteration 320 : 0.016772879287600517
Loss at iteration 330 : 0.028908301144838333
Loss at iteration 340 : 0.035757653415203094
Loss at iteration 350 : 0.018364109098911285
Loss at iteration 360 : 0.03424409031867981
Loss at iteration 370 : 0.02983793057501316
Loss at iteration 380 : 0.032078616321086884
Loss at iteration 390 : 0.020264996215701103
Loss at iteration 400 : 0.01878708228468895
Loss at iteration 410 : 0.019582251086831093
Loss at iteration 420 : 0.018915079534053802
Loss at iteration 430 : 0.02061591111123562
Loss at iteration 440 : 0.028340278193354607
Loss at iteration 450 : 0.03284814953804016
Loss at iteration 460 : 0.02199741080403328
Loss at iteration 470 : 0.029948443174362183
Loss at iteration 480 : 0.02705644629895687
Loss at iteration 490 : 0.02275800332427025
Loss at iteration 500 : 0.021674541756510735
Loss at iteration 510 : 0.0190675500780344
Loss at iteration 520 : 0.01337505504488945
Loss at iteration 530 : 0.014600228518247604
Loss at iteration 540 : 0.019677292555570602
Loss at iteration 550 : 0.023765746504068375
Loss at iteration 560 : 0.019788522273302078
Loss at iteration 570 : 0.022702116519212723
Loss at iteration 580 : 0.02431139163672924
Loss at iteration 590 : 0.02483418397605419
Loss at iteration 600 : 0.02734093740582466
Loss at iteration 610 : 0.029215622693300247
Loss at iteration 620 : 0.02447466179728508
Loss at iteration 630 : 0.019191810861229897
Loss at iteration 640 : 0.013230355456471443
Loss at iteration 650 : 0.014346852898597717
Loss at iteration 660 : 0.021653907373547554
Loss at iteration 670 : 0.03051644191145897
Loss at iteration 680 : 0.024342115968465805
Loss at iteration 690 : 0.01966189034283161
Loss at iteration 700 : 0.02317013218998909
Loss at iteration 710 : 0.03523088991641998
Loss at iteration 720 : 0.026572007685899734
Loss at iteration 730 : 0.024481579661369324
Loss at iteration 740 : 0.015660345554351807
Loss at iteration 750 : 0.024217694997787476
Loss at iteration 760 : 0.01778881996870041
Loss at iteration 770 : 0.043537117540836334
Loss at iteration 780 : 0.022915290668606758
Loss at iteration 790 : 0.024282995611429214
Loss at iteration 800 : 0.022119665518403053
Loss at iteration 810 : 0.027088696137070656
Loss at iteration 820 : 0.035098202526569366
Loss at iteration 830 : 0.025218628346920013
Loss at iteration 840 : 0.033326782286167145
Loss at iteration 850 : 0.022888001054525375
Loss at iteration 860 : 0.020456062629818916
Loss at iteration 870 : 0.03185785934329033
Loss at iteration 880 : 0.02188817970454693
Loss at iteration 890 : 0.024955246597528458
Loss at iteration 900 : 0.026823490858078003
Loss at iteration 910 : 0.037177249789237976
Loss at iteration 920 : 0.018767040222883224
Loss at iteration 930 : 0.039395175874233246
Loss at iteration 940 : 0.019380511716008186
Loss at iteration 950 : 0.02370538003742695
Loss at iteration 960 : 0.04307926446199417
Loss at iteration 970 : 0.030879873782396317
Loss at iteration 980 : 0.018193792551755905
Loss at iteration 990 : 0.03205183893442154
Loss at iteration 1000 : 0.028496883809566498
Loss at iteration 1010 : 0.028083229437470436
Loss at iteration 1020 : 0.018458779901266098
Loss at iteration 1030 : 0.03391081839799881
Loss at iteration 1040 : 0.014654984697699547
Loss at iteration 1050 : 0.03255980461835861
Loss at iteration 1060 : 0.01550079882144928
Loss at iteration 1070 : 0.025741685181856155
Loss at iteration 1080 : 0.02184097096323967
Loss at iteration 1090 : 0.02081182226538658
Loss at iteration 1100 : 0.018649835139513016
Loss at iteration 1110 : 0.028316983953118324
Loss at iteration 1120 : 0.023870553821325302
Loss at iteration 1130 : 0.029681794345378876
Loss at iteration 1140 : 0.028344478458166122
Loss at iteration 1150 : 0.011829334311187267
Loss at iteration 1160 : 0.015006192028522491
Loss at iteration 1170 : 0.021857772022485733
Loss at iteration 1180 : 0.028444791212677956
Loss at iteration 1190 : 0.03236661106348038
Loss at iteration 1200 : 0.018255185335874557
Loss at iteration 1210 : 0.024836519733071327
The SSIM Value is: 0.7765250523885091
The PSNR Value is: 18.068160438537596
the epoch is: 65
Loss at iteration 10 : 0.027226824313402176
Loss at iteration 20 : 0.03344891965389252
Loss at iteration 30 : 0.028609344735741615
Loss at iteration 40 : 0.019338347017765045
Loss at iteration 50 : 0.018422938883304596
Loss at iteration 60 : 0.018693162128329277
Loss at iteration 70 : 0.012824040837585926
Loss at iteration 80 : 0.028051987290382385
Loss at iteration 90 : 0.021298730745911598
Loss at iteration 100 : 0.022846728563308716
Loss at iteration 110 : 0.02439681813120842
Loss at iteration 120 : 0.02199520170688629
Loss at iteration 130 : 0.018591778352856636
Loss at iteration 140 : 0.01802126318216324
Loss at iteration 150 : 0.01745382323861122
Loss at iteration 160 : 0.021442368626594543
Loss at iteration 170 : 0.018830668181180954
Loss at iteration 180 : 0.027636688202619553
Loss at iteration 190 : 0.03112877532839775
Loss at iteration 200 : 0.02824573591351509
Loss at iteration 210 : 0.020244931802153587
Loss at iteration 220 : 0.0276142880320549
Loss at iteration 230 : 0.036502234637737274
Loss at iteration 240 : 0.0211025420576334
Loss at iteration 250 : 0.031339239329099655
Loss at iteration 260 : 0.028599653393030167
Loss at iteration 270 : 0.019847527146339417
Loss at iteration 280 : 0.026021085679531097
Loss at iteration 290 : 0.01714402064681053
Loss at iteration 300 : 0.02053024247288704
Loss at iteration 310 : 0.02251686528325081
Loss at iteration 320 : 0.01888098567724228
Loss at iteration 330 : 0.027319733053445816
Loss at iteration 340 : 0.02585042640566826
Loss at iteration 350 : 0.04053458571434021
Loss at iteration 360 : 0.018259260803461075
Loss at iteration 370 : 0.023909389972686768
Loss at iteration 380 : 0.021129511296749115
Loss at iteration 390 : 0.029100023210048676
Loss at iteration 400 : 0.015075678005814552
Loss at iteration 410 : 0.030746841803193092
Loss at iteration 420 : 0.018518131226301193
Loss at iteration 430 : 0.02137378230690956
Loss at iteration 440 : 0.0193893164396286
Loss at iteration 450 : 0.02615070901811123
Loss at iteration 460 : 0.020602835342288017
Loss at iteration 470 : 0.021912433207035065
Loss at iteration 480 : 0.025656063109636307
Loss at iteration 490 : 0.01857089437544346
Loss at iteration 500 : 0.0317024290561676
Loss at iteration 510 : 0.033409249037504196
Loss at iteration 520 : 0.026097506284713745
Loss at iteration 530 : 0.03176891803741455
Loss at iteration 540 : 0.015046107582747936
Loss at iteration 550 : 0.03880317136645317
Loss at iteration 560 : 0.037735261023044586
Loss at iteration 570 : 0.02584902197122574
Loss at iteration 580 : 0.0225127711892128
Loss at iteration 590 : 0.015144397504627705
Loss at iteration 600 : 0.015270302072167397
Loss at iteration 610 : 0.023802034556865692
Loss at iteration 620 : 0.016095222905278206
Loss at iteration 630 : 0.027930336073040962
Loss at iteration 640 : 0.02525959350168705
Loss at iteration 650 : 0.029193703085184097
Loss at iteration 660 : 0.01322398241609335
Loss at iteration 670 : 0.02264474518597126
Loss at iteration 680 : 0.02007332444190979
Loss at iteration 690 : 0.03264054283499718
Loss at iteration 700 : 0.0131519865244627
Loss at iteration 710 : 0.02758893370628357
Loss at iteration 720 : 0.044349782168865204
Loss at iteration 730 : 0.013362139463424683
Loss at iteration 740 : 0.02383439429104328
Loss at iteration 750 : 0.033567000180482864
Loss at iteration 760 : 0.02963675558567047
Loss at iteration 770 : 0.03578139841556549
Loss at iteration 780 : 0.03873343765735626
Loss at iteration 790 : 0.018597984686493874
Loss at iteration 800 : 0.02520531415939331
Loss at iteration 810 : 0.02143503911793232
Loss at iteration 820 : 0.020167749375104904
Loss at iteration 830 : 0.033168449997901917
Loss at iteration 840 : 0.02812277525663376
Loss at iteration 850 : 0.0357968807220459
Loss at iteration 860 : 0.026601921766996384
Loss at iteration 870 : 0.02039986662566662
Loss at iteration 880 : 0.017847934737801552
Loss at iteration 890 : 0.024020617827773094
Loss at iteration 900 : 0.028513524681329727
Loss at iteration 910 : 0.020160671323537827
Loss at iteration 920 : 0.01773270219564438
Loss at iteration 930 : 0.024647368118166924
Loss at iteration 940 : 0.028015688061714172
Loss at iteration 950 : 0.02313658595085144
Loss at iteration 960 : 0.042447470128536224
Loss at iteration 970 : 0.01784776896238327
Loss at iteration 980 : 0.02267780900001526
Loss at iteration 990 : 0.03510928153991699
Loss at iteration 1000 : 0.04255248233675957
Loss at iteration 1010 : 0.025525987148284912
Loss at iteration 1020 : 0.02402081899344921
Loss at iteration 1030 : 0.0267996434122324
Loss at iteration 1040 : 0.01492187101393938
Loss at iteration 1050 : 0.015987472608685493
Loss at iteration 1060 : 0.03029421530663967
Loss at iteration 1070 : 0.028859080746769905
Loss at iteration 1080 : 0.020890694111585617
Loss at iteration 1090 : 0.012948748655617237
Loss at iteration 1100 : 0.019869061186909676
Loss at iteration 1110 : 0.034258559346199036
Loss at iteration 1120 : 0.043654512614011765
Loss at iteration 1130 : 0.016661733388900757
Loss at iteration 1140 : 0.036694467067718506
Loss at iteration 1150 : 0.025627024471759796
Loss at iteration 1160 : 0.01987246610224247
Loss at iteration 1170 : 0.021114937961101532
Loss at iteration 1180 : 0.022998614236712456
Loss at iteration 1190 : 0.015198701992630959
Loss at iteration 1200 : 0.01996241696178913
Loss at iteration 1210 : 0.024221934378147125
The SSIM Value is: 0.7805909832318624
The PSNR Value is: 18.472122701009116
the highest SSIM value is: 18.472122701009116
the epoch is: 66
Loss at iteration 10 : 0.01366705633699894
Loss at iteration 20 : 0.022076301276683807
Loss at iteration 30 : 0.015685610473155975
Loss at iteration 40 : 0.017453212291002274
Loss at iteration 50 : 0.01920585334300995
Loss at iteration 60 : 0.02740887925028801
Loss at iteration 70 : 0.0183959249407053
Loss at iteration 80 : 0.017367949709296227
Loss at iteration 90 : 0.03352145105600357
Loss at iteration 100 : 0.02492205798625946
Loss at iteration 110 : 0.024518655613064766
Loss at iteration 120 : 0.03042185679078102
Loss at iteration 130 : 0.016126541420817375
Loss at iteration 140 : 0.02937934175133705
Loss at iteration 150 : 0.024091776460409164
Loss at iteration 160 : 0.022284554317593575
Loss at iteration 170 : 0.014429150149226189
Loss at iteration 180 : 0.01997525803744793
Loss at iteration 190 : 0.01867407001554966
Loss at iteration 200 : 0.024590061977505684
Loss at iteration 210 : 0.012831112369894981
Loss at iteration 220 : 0.030878398567438126
Loss at iteration 230 : 0.036432407796382904
Loss at iteration 240 : 0.034220125526189804
Loss at iteration 250 : 0.01861448958516121
Loss at iteration 260 : 0.017036225646734238
Loss at iteration 270 : 0.026808761060237885
Loss at iteration 280 : 0.02298034355044365
Loss at iteration 290 : 0.026095492765307426
Loss at iteration 300 : 0.023875124752521515
Loss at iteration 310 : 0.038900621235370636
Loss at iteration 320 : 0.032131824642419815
Loss at iteration 330 : 0.024385955184698105
Loss at iteration 340 : 0.028955016285181046
Loss at iteration 350 : 0.015261730179190636
Loss at iteration 360 : 0.023971065878868103
Loss at iteration 370 : 0.035768087953329086
Loss at iteration 380 : 0.019692374393343925
Loss at iteration 390 : 0.028627488762140274
Loss at iteration 400 : 0.018643194809556007
Loss at iteration 410 : 0.02900782786309719
Loss at iteration 420 : 0.021223049610853195
Loss at iteration 430 : 0.02554992213845253
Loss at iteration 440 : 0.026721786707639694
Loss at iteration 450 : 0.017106276005506516
Loss at iteration 460 : 0.022150825709104538
Loss at iteration 470 : 0.02028430998325348
Loss at iteration 480 : 0.028722254559397697
Loss at iteration 490 : 0.019659338518977165
Loss at iteration 500 : 0.019412092864513397
Loss at iteration 510 : 0.019161544740200043
Loss at iteration 520 : 0.025338053703308105
Loss at iteration 530 : 0.017989501357078552
Loss at iteration 540 : 0.019773973152041435
Loss at iteration 550 : 0.017184311524033546
Loss at iteration 560 : 0.030313191935420036
Loss at iteration 570 : 0.019358495250344276
Loss at iteration 580 : 0.018870661035180092
Loss at iteration 590 : 0.02280653640627861
Loss at iteration 600 : 0.023206129670143127
Loss at iteration 610 : 0.01969636045396328
Loss at iteration 620 : 0.05375754088163376
Loss at iteration 630 : 0.032848719507455826
Loss at iteration 640 : 0.027722176164388657
Loss at iteration 650 : 0.02390853315591812
Loss at iteration 660 : 0.02976122498512268
Loss at iteration 670 : 0.027171902358531952
Loss at iteration 680 : 0.03682098910212517
Loss at iteration 690 : 0.02727659046649933
Loss at iteration 700 : 0.017900856211781502
Loss at iteration 710 : 0.02915605902671814
Loss at iteration 720 : 0.02700597420334816
Loss at iteration 730 : 0.0341508686542511
Loss at iteration 740 : 0.027599994093179703
Loss at iteration 750 : 0.023826628923416138
Loss at iteration 760 : 0.02709309570491314
Loss at iteration 770 : 0.01422499306499958
Loss at iteration 780 : 0.031914133578538895
Loss at iteration 790 : 0.03530915081501007
Loss at iteration 800 : 0.032210420817136765
Loss at iteration 810 : 0.02728734165430069
Loss at iteration 820 : 0.04569677636027336
Loss at iteration 830 : 0.026991229504346848
Loss at iteration 840 : 0.020570486783981323
Loss at iteration 850 : 0.02068581059575081
Loss at iteration 860 : 0.032170794904232025
Loss at iteration 870 : 0.022363798692822456
Loss at iteration 880 : 0.02741881273686886
Loss at iteration 890 : 0.02307305671274662
Loss at iteration 900 : 0.01904452219605446
Loss at iteration 910 : 0.020706593990325928
Loss at iteration 920 : 0.022339334711432457
Loss at iteration 930 : 0.017299838364124298
Loss at iteration 940 : 0.02372714877128601
Loss at iteration 950 : 0.03359191119670868
Loss at iteration 960 : 0.04391179978847504
Loss at iteration 970 : 0.023166142404079437
Loss at iteration 980 : 0.025061991065740585
Loss at iteration 990 : 0.028034616261720657
Loss at iteration 1000 : 0.016357161104679108
Loss at iteration 1010 : 0.01195184700191021
Loss at iteration 1020 : 0.023620832711458206
Loss at iteration 1030 : 0.028710635378956795
Loss at iteration 1040 : 0.028565330430865288
Loss at iteration 1050 : 0.022022992372512817
Loss at iteration 1060 : 0.031723544001579285
Loss at iteration 1070 : 0.032134272158145905
Loss at iteration 1080 : 0.019528701901435852
Loss at iteration 1090 : 0.0287226103246212
Loss at iteration 1100 : 0.03279396891593933
Loss at iteration 1110 : 0.04005665332078934
Loss at iteration 1120 : 0.02052345499396324
Loss at iteration 1130 : 0.024174561724066734
Loss at iteration 1140 : 0.02514394000172615
Loss at iteration 1150 : 0.02688390016555786
Loss at iteration 1160 : 0.037287481129169464
Loss at iteration 1170 : 0.022721733897924423
Loss at iteration 1180 : 0.03218623250722885
Loss at iteration 1190 : 0.023530270904302597
Loss at iteration 1200 : 0.016239264979958534
Loss at iteration 1210 : 0.026892758905887604
The SSIM Value is: 0.7717807233333588
The PSNR Value is: 17.910407511393228
the epoch is: 67
Loss at iteration 10 : 0.0159114021807909
Loss at iteration 20 : 0.01552494429051876
Loss at iteration 30 : 0.014817043207585812
Loss at iteration 40 : 0.024208592250943184
Loss at iteration 50 : 0.018259579315781593
Loss at iteration 60 : 0.02116963267326355
Loss at iteration 70 : 0.025662364438176155
Loss at iteration 80 : 0.016413047909736633
Loss at iteration 90 : 0.029807191342115402
Loss at iteration 100 : 0.02073444239795208
Loss at iteration 110 : 0.021387487649917603
Loss at iteration 120 : 0.03202744200825691
Loss at iteration 130 : 0.019954055547714233
Loss at iteration 140 : 0.02171173319220543
Loss at iteration 150 : 0.026782652363181114
Loss at iteration 160 : 0.02789531648159027
Loss at iteration 170 : 0.019011937081813812
Loss at iteration 180 : 0.02288275957107544
Loss at iteration 190 : 0.03510270640254021
Loss at iteration 200 : 0.033577851951122284
Loss at iteration 210 : 0.01577308028936386
Loss at iteration 220 : 0.023784976452589035
Loss at iteration 230 : 0.026685329154133797
Loss at iteration 240 : 0.019721409305930138
Loss at iteration 250 : 0.020687252283096313
Loss at iteration 260 : 0.026151645928621292
Loss at iteration 270 : 0.015925351530313492
Loss at iteration 280 : 0.03257221728563309
Loss at iteration 290 : 0.01715632528066635
Loss at iteration 300 : 0.011589828878641129
Loss at iteration 310 : 0.022332079708576202
Loss at iteration 320 : 0.027374550700187683
Loss at iteration 330 : 0.029341699555516243
Loss at iteration 340 : 0.01886022835969925
Loss at iteration 350 : 0.02565312199294567
Loss at iteration 360 : 0.030993223190307617
Loss at iteration 370 : 0.024379558861255646
Loss at iteration 380 : 0.020400941371917725
Loss at iteration 390 : 0.021705005317926407
Loss at iteration 400 : 0.021578557789325714
Loss at iteration 410 : 0.029526032507419586
Loss at iteration 420 : 0.02589251846075058
Loss at iteration 430 : 0.0258583202958107
Loss at iteration 440 : 0.016634473577141762
Loss at iteration 450 : 0.016528859734535217
Loss at iteration 460 : 0.019600383937358856
Loss at iteration 470 : 0.031727030873298645
Loss at iteration 480 : 0.04006844386458397
Loss at iteration 490 : 0.012464627623558044
Loss at iteration 500 : 0.029020121321082115
Loss at iteration 510 : 0.027501806616783142
Loss at iteration 520 : 0.023433368653059006
Loss at iteration 530 : 0.0195658877491951
Loss at iteration 540 : 0.021252142265439034
Loss at iteration 550 : 0.038237180560827255
Loss at iteration 560 : 0.018306763842701912
Loss at iteration 570 : 0.02841908298432827
Loss at iteration 580 : 0.018606379628181458
Loss at iteration 590 : 0.02919500321149826
Loss at iteration 600 : 0.01921214535832405
Loss at iteration 610 : 0.02015058323740959
Loss at iteration 620 : 0.032829947769641876
Loss at iteration 630 : 0.02503855526447296
Loss at iteration 640 : 0.02021360956132412
Loss at iteration 650 : 0.029237274080514908
Loss at iteration 660 : 0.023184165358543396
Loss at iteration 670 : 0.03782738000154495
Loss at iteration 680 : 0.02336595579981804
Loss at iteration 690 : 0.020721495151519775
Loss at iteration 700 : 0.021231666207313538
Loss at iteration 710 : 0.020791184157133102
Loss at iteration 720 : 0.024553332477808
Loss at iteration 730 : 0.012263910844922066
Loss at iteration 740 : 0.020992405712604523
Loss at iteration 750 : 0.018326982855796814
Loss at iteration 760 : 0.028722744435071945
Loss at iteration 770 : 0.042445484548807144
Loss at iteration 780 : 0.02185991406440735
Loss at iteration 790 : 0.038738004863262177
Loss at iteration 800 : 0.03073214367032051
Loss at iteration 810 : 0.012804609723389149
Loss at iteration 820 : 0.030688166618347168
Loss at iteration 830 : 0.039719149470329285
Loss at iteration 840 : 0.02267500013113022
Loss at iteration 850 : 0.015683438628911972
Loss at iteration 860 : 0.03914215788245201
Loss at iteration 870 : 0.015726758167147636
Loss at iteration 880 : 0.024866418913006783
Loss at iteration 890 : 0.03620859235525131
Loss at iteration 900 : 0.026616796851158142
Loss at iteration 910 : 0.03670189902186394
Loss at iteration 920 : 0.020897649228572845
Loss at iteration 930 : 0.030492635443806648
Loss at iteration 940 : 0.014710022136569023
Loss at iteration 950 : 0.019712109118700027
Loss at iteration 960 : 0.03134885057806969
Loss at iteration 970 : 0.03042559325695038
Loss at iteration 980 : 0.02128085121512413
Loss at iteration 990 : 0.034450821578502655
Loss at iteration 1000 : 0.023259567096829414
Loss at iteration 1010 : 0.01604682393372059
Loss at iteration 1020 : 0.02576451189815998
Loss at iteration 1030 : 0.01509866863489151
Loss at iteration 1040 : 0.01988830417394638
Loss at iteration 1050 : 0.024773074313998222
Loss at iteration 1060 : 0.026379968971014023
Loss at iteration 1070 : 0.024107851088047028
Loss at iteration 1080 : 0.01914171688258648
Loss at iteration 1090 : 0.021335259079933167
Loss at iteration 1100 : 0.026037197560071945
Loss at iteration 1110 : 0.024472102522850037
Loss at iteration 1120 : 0.017023921012878418
Loss at iteration 1130 : 0.013739785179495811
Loss at iteration 1140 : 0.024755362421274185
Loss at iteration 1150 : 0.014440963044762611
Loss at iteration 1160 : 0.02830306440591812
Loss at iteration 1170 : 0.03350413218140602
Loss at iteration 1180 : 0.03259636089205742
Loss at iteration 1190 : 0.02340296097099781
Loss at iteration 1200 : 0.021209578961133957
Loss at iteration 1210 : 0.022470828145742416
The SSIM Value is: 0.7780333280563354
The PSNR Value is: 18.356323941548666
the epoch is: 68
Loss at iteration 10 : 0.026518724858760834
Loss at iteration 20 : 0.015004925429821014
Loss at iteration 30 : 0.025640878826379776
Loss at iteration 40 : 0.026977524161338806
Loss at iteration 50 : 0.022321827709674835
Loss at iteration 60 : 0.02855144813656807
Loss at iteration 70 : 0.022035449743270874
Loss at iteration 80 : 0.02772003784775734
Loss at iteration 90 : 0.025333013385534286
Loss at iteration 100 : 0.02635767310857773
Loss at iteration 110 : 0.027901310473680496
Loss at iteration 120 : 0.03136390820145607
Loss at iteration 130 : 0.023870129138231277
Loss at iteration 140 : 0.016181547194719315
Loss at iteration 150 : 0.017497554421424866
Loss at iteration 160 : 0.0180702842772007
Loss at iteration 170 : 0.038453761488199234
Loss at iteration 180 : 0.023948166519403458
Loss at iteration 190 : 0.026104209944605827
Loss at iteration 200 : 0.01829824224114418
Loss at iteration 210 : 0.028355922549962997
Loss at iteration 220 : 0.021519795060157776
Loss at iteration 230 : 0.016753368079662323
Loss at iteration 240 : 0.016242846846580505
Loss at iteration 250 : 0.019429311156272888
Loss at iteration 260 : 0.017451364547014236
Loss at iteration 270 : 0.026714246720075607
Loss at iteration 280 : 0.030161384493112564
Loss at iteration 290 : 0.0198930986225605
Loss at iteration 300 : 0.019162617623806
Loss at iteration 310 : 0.02374417334794998
Loss at iteration 320 : 0.01724115200340748
Loss at iteration 330 : 0.03742002695798874
Loss at iteration 340 : 0.027500342577695847
Loss at iteration 350 : 0.014534523710608482
Loss at iteration 360 : 0.03190837800502777
Loss at iteration 370 : 0.012450553476810455
Loss at iteration 380 : 0.03173419088125229
Loss at iteration 390 : 0.02957400120794773
Loss at iteration 400 : 0.01623343490064144
Loss at iteration 410 : 0.013198914006352425
Loss at iteration 420 : 0.024336986243724823
Loss at iteration 430 : 0.02921149507164955
Loss at iteration 440 : 0.031667642295360565
Loss at iteration 450 : 0.035766564309597015
Loss at iteration 460 : 0.02876807563006878
Loss at iteration 470 : 0.028588857501745224
Loss at iteration 480 : 0.03468022495508194
Loss at iteration 490 : 0.04174456745386124
Loss at iteration 500 : 0.015554461628198624
Loss at iteration 510 : 0.022222429513931274
Loss at iteration 520 : 0.03381052613258362
Loss at iteration 530 : 0.02475523203611374
Loss at iteration 540 : 0.026360129937529564
Loss at iteration 550 : 0.029158495366573334
Loss at iteration 560 : 0.020755145698785782
Loss at iteration 570 : 0.023835880681872368
Loss at iteration 580 : 0.027223531156778336
Loss at iteration 590 : 0.02348928712308407
Loss at iteration 600 : 0.012608757242560387
Loss at iteration 610 : 0.021357495337724686
Loss at iteration 620 : 0.01861131563782692
Loss at iteration 630 : 0.015458404086530209
Loss at iteration 640 : 0.014883636496961117
Loss at iteration 650 : 0.020240064710378647
Loss at iteration 660 : 0.022568367421627045
Loss at iteration 670 : 0.034123510122299194
Loss at iteration 680 : 0.024071751162409782
Loss at iteration 690 : 0.02819056808948517
Loss at iteration 700 : 0.02063237875699997
Loss at iteration 710 : 0.013966290280222893
Loss at iteration 720 : 0.03585873916745186
Loss at iteration 730 : 0.018865425139665604
Loss at iteration 740 : 0.018943361937999725
Loss at iteration 750 : 0.02109718695282936
Loss at iteration 760 : 0.01725047454237938
Loss at iteration 770 : 0.020530715584754944
Loss at iteration 780 : 0.0244891494512558
Loss at iteration 790 : 0.025313537567853928
Loss at iteration 800 : 0.024790283292531967
Loss at iteration 810 : 0.02037927508354187
Loss at iteration 820 : 0.023708660155534744
Loss at iteration 830 : 0.011290667578577995
Loss at iteration 840 : 0.011758819222450256
Loss at iteration 850 : 0.024397149682044983
Loss at iteration 860 : 0.023807372897863388
Loss at iteration 870 : 0.02413618192076683
Loss at iteration 880 : 0.023577792569994926
Loss at iteration 890 : 0.017845019698143005
Loss at iteration 900 : 0.035844624042510986
Loss at iteration 910 : 0.019157471135258675
Loss at iteration 920 : 0.02065613679587841
Loss at iteration 930 : 0.025329064577817917
Loss at iteration 940 : 0.02729346975684166
Loss at iteration 950 : 0.025946229696273804
Loss at iteration 960 : 0.019720396026968956
Loss at iteration 970 : 0.02457098849117756
Loss at iteration 980 : 0.039402179419994354
Loss at iteration 990 : 0.031362682580947876
Loss at iteration 1000 : 0.01881112903356552
Loss at iteration 1010 : 0.030386097729206085
Loss at iteration 1020 : 0.016653597354888916
Loss at iteration 1030 : 0.01912076026201248
Loss at iteration 1040 : 0.024594835937023163
Loss at iteration 1050 : 0.02089613676071167
Loss at iteration 1060 : 0.021289143711328506
Loss at iteration 1070 : 0.022698843851685524
Loss at iteration 1080 : 0.018965862691402435
Loss at iteration 1090 : 0.022734560072422028
Loss at iteration 1100 : 0.024850325658917427
Loss at iteration 1110 : 0.025470735505223274
Loss at iteration 1120 : 0.038705892860889435
Loss at iteration 1130 : 0.01884143240749836
Loss at iteration 1140 : 0.012913729064166546
Loss at iteration 1150 : 0.028093736618757248
Loss at iteration 1160 : 0.02749583125114441
Loss at iteration 1170 : 0.018678179010748863
Loss at iteration 1180 : 0.03379081189632416
Loss at iteration 1190 : 0.02428913488984108
Loss at iteration 1200 : 0.018037324771285057
Loss at iteration 1210 : 0.009934869594871998
The SSIM Value is: 0.780388613541921
The PSNR Value is: 18.012146759033204
the epoch is: 69
Loss at iteration 10 : 0.018342338502407074
Loss at iteration 20 : 0.017938632518053055
Loss at iteration 30 : 0.03005683422088623
Loss at iteration 40 : 0.02450735494494438
Loss at iteration 50 : 0.022463593631982803
Loss at iteration 60 : 0.03478003293275833
Loss at iteration 70 : 0.03174984082579613
Loss at iteration 80 : 0.022845730185508728
Loss at iteration 90 : 0.03655432164669037
Loss at iteration 100 : 0.016730941832065582
Loss at iteration 110 : 0.02355995774269104
Loss at iteration 120 : 0.025549383834004402
Loss at iteration 130 : 0.015922095626592636
Loss at iteration 140 : 0.020300786942243576
Loss at iteration 150 : 0.01909453794360161
Loss at iteration 160 : 0.022898035123944283
Loss at iteration 170 : 0.02760874666273594
Loss at iteration 180 : 0.01581445336341858
Loss at iteration 190 : 0.012475387193262577
Loss at iteration 200 : 0.015035385265946388
Loss at iteration 210 : 0.02129044383764267
Loss at iteration 220 : 0.014062978327274323
Loss at iteration 230 : 0.024899108335375786
Loss at iteration 240 : 0.01730159856379032
Loss at iteration 250 : 0.0139186792075634
Loss at iteration 260 : 0.03247756138443947
Loss at iteration 270 : 0.031852856278419495
Loss at iteration 280 : 0.045851632952690125
Loss at iteration 290 : 0.03345891833305359
Loss at iteration 300 : 0.030810877680778503
Loss at iteration 310 : 0.020530100911855698
Loss at iteration 320 : 0.01629571244120598
Loss at iteration 330 : 0.022517211735248566
Loss at iteration 340 : 0.016583604738116264
Loss at iteration 350 : 0.04708448052406311
Loss at iteration 360 : 0.032864559441804886
Loss at iteration 370 : 0.04226197674870491
Loss at iteration 380 : 0.0217666644603014
Loss at iteration 390 : 0.027832675725221634
Loss at iteration 400 : 0.03591737896203995
Loss at iteration 410 : 0.021614249795675278
Loss at iteration 420 : 0.03431826829910278
Loss at iteration 430 : 0.01897202990949154
Loss at iteration 440 : 0.044528622180223465
Loss at iteration 450 : 0.026997920125722885
Loss at iteration 460 : 0.028960082679986954
Loss at iteration 470 : 0.029468340799212456
Loss at iteration 480 : 0.019496865570545197
Loss at iteration 490 : 0.017050689086318016
Loss at iteration 500 : 0.026395974680781364
Loss at iteration 510 : 0.028160812333226204
Loss at iteration 520 : 0.020615773275494576
Loss at iteration 530 : 0.01669803448021412
Loss at iteration 540 : 0.011282885447144508
Loss at iteration 550 : 0.030741417780518532
Loss at iteration 560 : 0.016309542581439018
Loss at iteration 570 : 0.01738027110695839
Loss at iteration 580 : 0.02969914861023426
Loss at iteration 590 : 0.020393630489706993
Loss at iteration 600 : 0.015939505770802498
Loss at iteration 610 : 0.0369814969599247
Loss at iteration 620 : 0.01285427063703537
Loss at iteration 630 : 0.03305923938751221
Loss at iteration 640 : 0.01629508286714554
Loss at iteration 650 : 0.02373882196843624
Loss at iteration 660 : 0.013433169573545456
Loss at iteration 670 : 0.034949757158756256
Loss at iteration 680 : 0.030036088079214096
Loss at iteration 690 : 0.022784017026424408
Loss at iteration 700 : 0.023354073986411095
Loss at iteration 710 : 0.024723242968320847
Loss at iteration 720 : 0.017480239272117615
Loss at iteration 730 : 0.022153135389089584
Loss at iteration 740 : 0.012310504913330078
Loss at iteration 750 : 0.02606380358338356
Loss at iteration 760 : 0.03340050205588341
Loss at iteration 770 : 0.03212296962738037
Loss at iteration 780 : 0.030932171270251274
Loss at iteration 790 : 0.023489195853471756
Loss at iteration 800 : 0.014499034732580185
Loss at iteration 810 : 0.019035810604691505
Loss at iteration 820 : 0.04071054607629776
Loss at iteration 830 : 0.01134082768112421
Loss at iteration 840 : 0.02656831219792366
Loss at iteration 850 : 0.022028852254152298
Loss at iteration 860 : 0.015519939363002777
Loss at iteration 870 : 0.02020983211696148
Loss at iteration 880 : 0.021381326019763947
Loss at iteration 890 : 0.03257642686367035
Loss at iteration 900 : 0.022585920989513397
Loss at iteration 910 : 0.02619840018451214
Loss at iteration 920 : 0.028361786156892776
Loss at iteration 930 : 0.022441215813159943
Loss at iteration 940 : 0.03144925832748413
Loss at iteration 950 : 0.03244388848543167
Loss at iteration 960 : 0.014252297580242157
Loss at iteration 970 : 0.025717809796333313
Loss at iteration 980 : 0.0201609805226326
Loss at iteration 990 : 0.04155511409044266
Loss at iteration 1000 : 0.017364349216222763
Loss at iteration 1010 : 0.014775513671338558
Loss at iteration 1020 : 0.02594541385769844
Loss at iteration 1030 : 0.029216289520263672
Loss at iteration 1040 : 0.035289645195007324
Loss at iteration 1050 : 0.0160985104739666
Loss at iteration 1060 : 0.020512081682682037
Loss at iteration 1070 : 0.03185497969388962
Loss at iteration 1080 : 0.02556050382554531
Loss at iteration 1090 : 0.025066442787647247
Loss at iteration 1100 : 0.02449299767613411
Loss at iteration 1110 : 0.01878635212779045
Loss at iteration 1120 : 0.028421632945537567
Loss at iteration 1130 : 0.04349983483552933
Loss at iteration 1140 : 0.020975273102521896
Loss at iteration 1150 : 0.01679053343832493
Loss at iteration 1160 : 0.026045089587569237
Loss at iteration 1170 : 0.03134254738688469
Loss at iteration 1180 : 0.02376672811806202
Loss at iteration 1190 : 0.03859713301062584
Loss at iteration 1200 : 0.02230357937514782
Loss at iteration 1210 : 0.01668431982398033
The SSIM Value is: 0.7791304230690003
The PSNR Value is: 17.98805465698242
the epoch is: 70
Loss at iteration 10 : 0.04066164046525955
Loss at iteration 20 : 0.021220475435256958
Loss at iteration 30 : 0.023797499015927315
Loss at iteration 40 : 0.016436398029327393
Loss at iteration 50 : 0.02466082200407982
Loss at iteration 60 : 0.016681302338838577
Loss at iteration 70 : 0.015304801985621452
Loss at iteration 80 : 0.026194989681243896
Loss at iteration 90 : 0.03580213338136673
Loss at iteration 100 : 0.02528093010187149
Loss at iteration 110 : 0.02285001426935196
Loss at iteration 120 : 0.02366635389626026
Loss at iteration 130 : 0.024241890758275986
Loss at iteration 140 : 0.03271511569619179
Loss at iteration 150 : 0.02119750902056694
Loss at iteration 160 : 0.021443884819746017
Loss at iteration 170 : 0.01666766032576561
Loss at iteration 180 : 0.026502789929509163
Loss at iteration 190 : 0.0192624032497406
Loss at iteration 200 : 0.018933583050966263
Loss at iteration 210 : 0.011991926468908787
Loss at iteration 220 : 0.020547857508063316
Loss at iteration 230 : 0.02328980714082718
Loss at iteration 240 : 0.015750359743833542
Loss at iteration 250 : 0.03940974175930023
Loss at iteration 260 : 0.023061253130435944
Loss at iteration 270 : 0.0342654213309288
Loss at iteration 280 : 0.02730647101998329
Loss at iteration 290 : 0.020407527685165405
Loss at iteration 300 : 0.03573554754257202
Loss at iteration 310 : 0.024066118523478508
Loss at iteration 320 : 0.020692788064479828
Loss at iteration 330 : 0.02031274139881134
Loss at iteration 340 : 0.023997489362955093
Loss at iteration 350 : 0.018214629963040352
Loss at iteration 360 : 0.02235880121588707
Loss at iteration 370 : 0.019500305876135826
Loss at iteration 380 : 0.02933868020772934
Loss at iteration 390 : 0.01833108812570572
Loss at iteration 400 : 0.025560932233929634
Loss at iteration 410 : 0.0368722602725029
Loss at iteration 420 : 0.023697245866060257
Loss at iteration 430 : 0.02624030038714409
Loss at iteration 440 : 0.017397737130522728
Loss at iteration 450 : 0.013589318841695786
Loss at iteration 460 : 0.019416568800807
Loss at iteration 470 : 0.023066118359565735
Loss at iteration 480 : 0.027677886188030243
Loss at iteration 490 : 0.01729944720864296
Loss at iteration 500 : 0.019151950255036354
Loss at iteration 510 : 0.025051340460777283
Loss at iteration 520 : 0.013464145362377167
Loss at iteration 530 : 0.016138534992933273
Loss at iteration 540 : 0.026757467538118362
Loss at iteration 550 : 0.017982175573706627
Loss at iteration 560 : 0.024860737845301628
Loss at iteration 570 : 0.021591508761048317
Loss at iteration 580 : 0.04125034809112549
Loss at iteration 590 : 0.03392684832215309
Loss at iteration 600 : 0.024792945012450218
Loss at iteration 610 : 0.026182107627391815
Loss at iteration 620 : 0.02753831446170807
Loss at iteration 630 : 0.026480862870812416
Loss at iteration 640 : 0.01687867008149624
Loss at iteration 650 : 0.020619062706828117
Loss at iteration 660 : 0.02929597534239292
Loss at iteration 670 : 0.01772431656718254
Loss at iteration 680 : 0.026832614094018936
Loss at iteration 690 : 0.023992661386728287
Loss at iteration 700 : 0.039221204817295074
Loss at iteration 710 : 0.017966914921998978
Loss at iteration 720 : 0.016765817999839783
Loss at iteration 730 : 0.019327480345964432
Loss at iteration 740 : 0.01852281577885151
Loss at iteration 750 : 0.020471518859267235
Loss at iteration 760 : 0.013133672997355461
Loss at iteration 770 : 0.014756876975297928
Loss at iteration 780 : 0.023813489824533463
Loss at iteration 790 : 0.01641700603067875
Loss at iteration 800 : 0.028478361666202545
Loss at iteration 810 : 0.022761698812246323
Loss at iteration 820 : 0.042179398238658905
Loss at iteration 830 : 0.02773534506559372
Loss at iteration 840 : 0.027156801894307137
Loss at iteration 850 : 0.016258783638477325
Loss at iteration 860 : 0.02423791214823723
Loss at iteration 870 : 0.02479817345738411
Loss at iteration 880 : 0.022745665162801743
Loss at iteration 890 : 0.019503366202116013
Loss at iteration 900 : 0.017702139914035797
Loss at iteration 910 : 0.026819035410881042
Loss at iteration 920 : 0.022429946810007095
Loss at iteration 930 : 0.017250102013349533
Loss at iteration 940 : 0.03229212388396263
Loss at iteration 950 : 0.01073925755918026
Loss at iteration 960 : 0.03402509540319443
Loss at iteration 970 : 0.02527817152440548
Loss at iteration 980 : 0.020154330879449844
Loss at iteration 990 : 0.030043983832001686
Loss at iteration 1000 : 0.017826993018388748
Loss at iteration 1010 : 0.03583090752363205
Loss at iteration 1020 : 0.027870237827301025
Loss at iteration 1030 : 0.02246898040175438
Loss at iteration 1040 : 0.03024885058403015
Loss at iteration 1050 : 0.02238982729613781
Loss at iteration 1060 : 0.01687287911772728
Loss at iteration 1070 : 0.02854074165225029
Loss at iteration 1080 : 0.015544348396360874
Loss at iteration 1090 : 0.02630973607301712
Loss at iteration 1100 : 0.023895494639873505
Loss at iteration 1110 : 0.02226846292614937
Loss at iteration 1120 : 0.03813868761062622
Loss at iteration 1130 : 0.035076290369033813
Loss at iteration 1140 : 0.017664834856987
Loss at iteration 1150 : 0.0240880586206913
Loss at iteration 1160 : 0.015513788908720016
Loss at iteration 1170 : 0.02231280505657196
Loss at iteration 1180 : 0.024505477398633957
Loss at iteration 1190 : 0.022176047787070274
Loss at iteration 1200 : 0.026140740141272545
Loss at iteration 1210 : 0.05137141793966293
The SSIM Value is: 0.7809043367703755
The PSNR Value is: 18.093158022562662
the epoch is: 71
Loss at iteration 10 : 0.03272958844900131
Loss at iteration 20 : 0.022221775725483894
Loss at iteration 30 : 0.01690317690372467
Loss at iteration 40 : 0.018580306321382523
Loss at iteration 50 : 0.023999840021133423
Loss at iteration 60 : 0.020775051787495613
Loss at iteration 70 : 0.02257371135056019
Loss at iteration 80 : 0.024954287335276604
Loss at iteration 90 : 0.021898914128541946
Loss at iteration 100 : 0.030473314225673676
Loss at iteration 110 : 0.013514518737792969
Loss at iteration 120 : 0.040469709783792496
Loss at iteration 130 : 0.017112450674176216
Loss at iteration 140 : 0.020267490297555923
Loss at iteration 150 : 0.024923168122768402
Loss at iteration 160 : 0.019586272537708282
Loss at iteration 170 : 0.02343210205435753
Loss at iteration 180 : 0.019705215469002724
Loss at iteration 190 : 0.037124067544937134
Loss at iteration 200 : 0.0275054220110178
Loss at iteration 210 : 0.030460283160209656
Loss at iteration 220 : 0.030336501076817513
Loss at iteration 230 : 0.021188637241721153
Loss at iteration 240 : 0.017414797097444534
Loss at iteration 250 : 0.03116394579410553
Loss at iteration 260 : 0.02630259096622467
Loss at iteration 270 : 0.03731671720743179
Loss at iteration 280 : 0.027693182229995728
Loss at iteration 290 : 0.014746910892426968
Loss at iteration 300 : 0.03417927771806717
Loss at iteration 310 : 0.014888905920088291
Loss at iteration 320 : 0.026467934250831604
Loss at iteration 330 : 0.020222024992108345
Loss at iteration 340 : 0.023499462753534317
Loss at iteration 350 : 0.020567964762449265
Loss at iteration 360 : 0.016832750290632248
Loss at iteration 370 : 0.025446508079767227
Loss at iteration 380 : 0.02449018508195877
Loss at iteration 390 : 0.010791050270199776
Loss at iteration 400 : 0.03590138629078865
Loss at iteration 410 : 0.023833421990275383
Loss at iteration 420 : 0.027532584965229034
Loss at iteration 430 : 0.03209816664457321
Loss at iteration 440 : 0.03471778333187103
Loss at iteration 450 : 0.02459537237882614
Loss at iteration 460 : 0.02477974444627762
Loss at iteration 470 : 0.013397842645645142
Loss at iteration 480 : 0.03408769518136978
Loss at iteration 490 : 0.01981673389673233
Loss at iteration 500 : 0.02440239116549492
Loss at iteration 510 : 0.018481191247701645
Loss at iteration 520 : 0.02720763348042965
Loss at iteration 530 : 0.020358651876449585
Loss at iteration 540 : 0.018090369179844856
Loss at iteration 550 : 0.014857877045869827
Loss at iteration 560 : 0.027022019028663635
Loss at iteration 570 : 0.01349630020558834
Loss at iteration 580 : 0.03147738426923752
Loss at iteration 590 : 0.025280935689806938
Loss at iteration 600 : 0.02825368382036686
Loss at iteration 610 : 0.025271354243159294
Loss at iteration 620 : 0.02599489316344261
Loss at iteration 630 : 0.01963537372648716
Loss at iteration 640 : 0.010190056636929512
Loss at iteration 650 : 0.036821164190769196
Loss at iteration 660 : 0.024449916556477547
Loss at iteration 670 : 0.028300467878580093
Loss at iteration 680 : 0.020354796200990677
Loss at iteration 690 : 0.021192429587244987
Loss at iteration 700 : 0.016077566891908646
Loss at iteration 710 : 0.021858442574739456
Loss at iteration 720 : 0.03156258165836334
Loss at iteration 730 : 0.018122324720025063
Loss at iteration 740 : 0.01959911361336708
Loss at iteration 750 : 0.014681324362754822
Loss at iteration 760 : 0.026191633194684982
Loss at iteration 770 : 0.02709490805864334
Loss at iteration 780 : 0.017987994477152824
Loss at iteration 790 : 0.013589339330792427
Loss at iteration 800 : 0.033294714987277985
Loss at iteration 810 : 0.024004504084587097
Loss at iteration 820 : 0.025788256898522377
Loss at iteration 830 : 0.037337638437747955
Loss at iteration 840 : 0.01660507544875145
Loss at iteration 850 : 0.01241216715425253
Loss at iteration 860 : 0.03279021009802818
Loss at iteration 870 : 0.018906470388174057
Loss at iteration 880 : 0.02659371867775917
Loss at iteration 890 : 0.01744052581489086
Loss at iteration 900 : 0.014410030096769333
Loss at iteration 910 : 0.03791455924510956
Loss at iteration 920 : 0.03321576118469238
Loss at iteration 930 : 0.014087436720728874
Loss at iteration 940 : 0.024585722014307976
Loss at iteration 950 : 0.02321329340338707
Loss at iteration 960 : 0.03147309273481369
Loss at iteration 970 : 0.022623304277658463
Loss at iteration 980 : 0.023524802178144455
Loss at iteration 990 : 0.01813417859375477
Loss at iteration 1000 : 0.017094282433390617
Loss at iteration 1010 : 0.011391641572117805
Loss at iteration 1020 : 0.04291916638612747
Loss at iteration 1030 : 0.017983727157115936
Loss at iteration 1040 : 0.019979087635874748
Loss at iteration 1050 : 0.027128107845783234
Loss at iteration 1060 : 0.036611199378967285
Loss at iteration 1070 : 0.023570004850625992
Loss at iteration 1080 : 0.025666646659374237
Loss at iteration 1090 : 0.02998308464884758
Loss at iteration 1100 : 0.023579474538564682
Loss at iteration 1110 : 0.022475771605968475
Loss at iteration 1120 : 0.023537002503871918
Loss at iteration 1130 : 0.016928309574723244
Loss at iteration 1140 : 0.02563515305519104
Loss at iteration 1150 : 0.04407470300793648
Loss at iteration 1160 : 0.017759986221790314
Loss at iteration 1170 : 0.03272335231304169
Loss at iteration 1180 : 0.03491761162877083
Loss at iteration 1190 : 0.01978723704814911
Loss at iteration 1200 : 0.03369028866291046
Loss at iteration 1210 : 0.020367799326777458
The SSIM Value is: 0.7806250890096028
The PSNR Value is: 18.21909942626953
the epoch is: 72
Loss at iteration 10 : 0.02526717446744442
Loss at iteration 20 : 0.018480218946933746
Loss at iteration 30 : 0.03072361834347248
Loss at iteration 40 : 0.03254057466983795
Loss at iteration 50 : 0.03036080114543438
Loss at iteration 60 : 0.016493406146764755
Loss at iteration 70 : 0.02239178866147995
Loss at iteration 80 : 0.015439928509294987
Loss at iteration 90 : 0.02179908938705921
Loss at iteration 100 : 0.025715181604027748
Loss at iteration 110 : 0.022053251042962074
Loss at iteration 120 : 0.023060008883476257
Loss at iteration 130 : 0.010708565823733807
Loss at iteration 140 : 0.015688830986618996
Loss at iteration 150 : 0.02785402163863182
Loss at iteration 160 : 0.014903328381478786
Loss at iteration 170 : 0.029132846742868423
Loss at iteration 180 : 0.017669042572379112
Loss at iteration 190 : 0.019562656059861183
Loss at iteration 200 : 0.026648029685020447
Loss at iteration 210 : 0.021486254408955574
Loss at iteration 220 : 0.019238337874412537
Loss at iteration 230 : 0.023928530514240265
Loss at iteration 240 : 0.01832166314125061
Loss at iteration 250 : 0.015740077942609787
Loss at iteration 260 : 0.0372438058257103
Loss at iteration 270 : 0.019156141206622124
Loss at iteration 280 : 0.018000002950429916
Loss at iteration 290 : 0.026842154562473297
Loss at iteration 300 : 0.03605083003640175
Loss at iteration 310 : 0.02277684025466442
Loss at iteration 320 : 0.029485046863555908
Loss at iteration 330 : 0.02028409019112587
Loss at iteration 340 : 0.020675260573625565
Loss at iteration 350 : 0.01399083063006401
Loss at iteration 360 : 0.013747544959187508
Loss at iteration 370 : 0.031702470034360886
Loss at iteration 380 : 0.022672880440950394
Loss at iteration 390 : 0.015383854508399963
Loss at iteration 400 : 0.026704248040914536
Loss at iteration 410 : 0.02511264942586422
Loss at iteration 420 : 0.020717483013868332
Loss at iteration 430 : 0.02802262082695961
Loss at iteration 440 : 0.021833084523677826
Loss at iteration 450 : 0.028696056455373764
Loss at iteration 460 : 0.015607704408466816
Loss at iteration 470 : 0.021770061925053596
Loss at iteration 480 : 0.02392229065299034
Loss at iteration 490 : 0.027160199359059334
Loss at iteration 500 : 0.02855025976896286
Loss at iteration 510 : 0.029401540756225586
Loss at iteration 520 : 0.01816135086119175
Loss at iteration 530 : 0.020375648513436317
Loss at iteration 540 : 0.014773250557482243
Loss at iteration 550 : 0.02921755611896515
Loss at iteration 560 : 0.025369688868522644
Loss at iteration 570 : 0.019844822585582733
Loss at iteration 580 : 0.018120702356100082
Loss at iteration 590 : 0.021559640765190125
Loss at iteration 600 : 0.024571169167757034
Loss at iteration 610 : 0.01322108879685402
Loss at iteration 620 : 0.02393965795636177
Loss at iteration 630 : 0.026669941842556
Loss at iteration 640 : 0.02754511684179306
Loss at iteration 650 : 0.0214228518307209
Loss at iteration 660 : 0.02879713475704193
Loss at iteration 670 : 0.0189325250685215
Loss at iteration 680 : 0.016532232984900475
Loss at iteration 690 : 0.01999545469880104
Loss at iteration 700 : 0.026280773803591728
Loss at iteration 710 : 0.0316738486289978
Loss at iteration 720 : 0.025321515277028084
Loss at iteration 730 : 0.0212650615721941
Loss at iteration 740 : 0.015027537941932678
Loss at iteration 750 : 0.0344112291932106
Loss at iteration 760 : 0.025897761806845665
Loss at iteration 770 : 0.03192094713449478
Loss at iteration 780 : 0.0307383444160223
Loss at iteration 790 : 0.02846241369843483
Loss at iteration 800 : 0.02258795127272606
Loss at iteration 810 : 0.022296633571386337
Loss at iteration 820 : 0.009100842289626598
Loss at iteration 830 : 0.03170525282621384
Loss at iteration 840 : 0.033409904688596725
Loss at iteration 850 : 0.028492912650108337
Loss at iteration 860 : 0.020328909158706665
Loss at iteration 870 : 0.015594877302646637
Loss at iteration 880 : 0.0234100092202425
Loss at iteration 890 : 0.025526275858283043
Loss at iteration 900 : 0.016070250421762466
Loss at iteration 910 : 0.012591186910867691
Loss at iteration 920 : 0.037117939442396164
Loss at iteration 930 : 0.023041928187012672
Loss at iteration 940 : 0.02295880950987339
Loss at iteration 950 : 0.037016578018665314
Loss at iteration 960 : 0.01622202806174755
Loss at iteration 970 : 0.02005278319120407
Loss at iteration 980 : 0.0297258198261261
Loss at iteration 990 : 0.034920115023851395
Loss at iteration 1000 : 0.026822451502084732
Loss at iteration 1010 : 0.019915515556931496
Loss at iteration 1020 : 0.014511996880173683
Loss at iteration 1030 : 0.021541979163885117
Loss at iteration 1040 : 0.03213656693696976
Loss at iteration 1050 : 0.032092876732349396
Loss at iteration 1060 : 0.01995481364428997
Loss at iteration 1070 : 0.033061228692531586
Loss at iteration 1080 : 0.01245853677392006
Loss at iteration 1090 : 0.0164584182202816
Loss at iteration 1100 : 0.021541830152273178
Loss at iteration 1110 : 0.019517749547958374
Loss at iteration 1120 : 0.01674213819205761
Loss at iteration 1130 : 0.015354475006461143
Loss at iteration 1140 : 0.019276272505521774
Loss at iteration 1150 : 0.0221049003303051
Loss at iteration 1160 : 0.02209450863301754
Loss at iteration 1170 : 0.029285799711942673
Loss at iteration 1180 : 0.024454738944768906
Loss at iteration 1190 : 0.031119944527745247
Loss at iteration 1200 : 0.02432054653763771
Loss at iteration 1210 : 0.028587009757757187
The SSIM Value is: 0.786184032758077
The PSNR Value is: 18.395649464925132
the epoch is: 73
Loss at iteration 10 : 0.023286014795303345
Loss at iteration 20 : 0.02831185981631279
Loss at iteration 30 : 0.019921138882637024
Loss at iteration 40 : 0.017300095409154892
Loss at iteration 50 : 0.031532369554042816
Loss at iteration 60 : 0.027853870764374733
Loss at iteration 70 : 0.021823324263095856
Loss at iteration 80 : 0.019822729751467705
Loss at iteration 90 : 0.02085697650909424
Loss at iteration 100 : 0.014641959220170975
Loss at iteration 110 : 0.03108692169189453
Loss at iteration 120 : 0.017654959112405777
Loss at iteration 130 : 0.019998973235487938
Loss at iteration 140 : 0.021521221846342087
Loss at iteration 150 : 0.017459526658058167
Loss at iteration 160 : 0.013248419389128685
Loss at iteration 170 : 0.016153614968061447
Loss at iteration 180 : 0.026527386158704758
Loss at iteration 190 : 0.03398286923766136
Loss at iteration 200 : 0.022511767223477364
Loss at iteration 210 : 0.029203377664089203
Loss at iteration 220 : 0.019284820184111595
Loss at iteration 230 : 0.02602621540427208
Loss at iteration 240 : 0.017077183350920677
Loss at iteration 250 : 0.024010995402932167
Loss at iteration 260 : 0.03089279495179653
Loss at iteration 270 : 0.020000245422124863
Loss at iteration 280 : 0.01782727986574173
Loss at iteration 290 : 0.028294268995523453
Loss at iteration 300 : 0.021343082189559937
Loss at iteration 310 : 0.018744466826319695
Loss at iteration 320 : 0.022673387080430984
Loss at iteration 330 : 0.02410687878727913
Loss at iteration 340 : 0.03535431623458862
Loss at iteration 350 : 0.0245618037879467
Loss at iteration 360 : 0.027037007734179497
Loss at iteration 370 : 0.017843760550022125
Loss at iteration 380 : 0.01617591269314289
Loss at iteration 390 : 0.01651354506611824
Loss at iteration 400 : 0.019512582570314407
Loss at iteration 410 : 0.02342897094786167
Loss at iteration 420 : 0.015035482123494148
Loss at iteration 430 : 0.03443598374724388
Loss at iteration 440 : 0.016150085255503654
Loss at iteration 450 : 0.021138813346624374
Loss at iteration 460 : 0.03201809898018837
Loss at iteration 470 : 0.0173601433634758
Loss at iteration 480 : 0.02020629122853279
Loss at iteration 490 : 0.01540801115334034
Loss at iteration 500 : 0.017337286844849586
Loss at iteration 510 : 0.023021377623081207
Loss at iteration 520 : 0.019646037369966507
Loss at iteration 530 : 0.022099565714597702
Loss at iteration 540 : 0.020265985280275345
Loss at iteration 550 : 0.02627468667924404
Loss at iteration 560 : 0.028730202466249466
Loss at iteration 570 : 0.016594896093010902
Loss at iteration 580 : 0.018552061170339584
Loss at iteration 590 : 0.013635167852044106
Loss at iteration 600 : 0.0203915536403656
Loss at iteration 610 : 0.0336047038435936
Loss at iteration 620 : 0.025168869644403458
Loss at iteration 630 : 0.01620900258421898
Loss at iteration 640 : 0.01683298870921135
Loss at iteration 650 : 0.02315373346209526
Loss at iteration 660 : 0.03385338559746742
Loss at iteration 670 : 0.02248162403702736
Loss at iteration 680 : 0.016769638285040855
Loss at iteration 690 : 0.019236069172620773
Loss at iteration 700 : 0.017265677452087402
Loss at iteration 710 : 0.022292349487543106
Loss at iteration 720 : 0.019083337858319283
Loss at iteration 730 : 0.026697836816310883
Loss at iteration 740 : 0.013508968986570835
Loss at iteration 750 : 0.028874728828668594
Loss at iteration 760 : 0.022077783942222595
Loss at iteration 770 : 0.01410305593162775
Loss at iteration 780 : 0.029571939259767532
Loss at iteration 790 : 0.026837335899472237
Loss at iteration 800 : 0.024695003405213356
Loss at iteration 810 : 0.029530387371778488
Loss at iteration 820 : 0.024125961586833
Loss at iteration 830 : 0.016987251117825508
Loss at iteration 840 : 0.010815439745783806
Loss at iteration 850 : 0.026101578027009964
Loss at iteration 860 : 0.015528837218880653
Loss at iteration 870 : 0.020150935277342796
Loss at iteration 880 : 0.0255514457821846
Loss at iteration 890 : 0.01522553339600563
Loss at iteration 900 : 0.02067669853568077
Loss at iteration 910 : 0.017064016312360764
Loss at iteration 920 : 0.027377339079976082
Loss at iteration 930 : 0.019590992480516434
Loss at iteration 940 : 0.017008017748594284
Loss at iteration 950 : 0.02279091626405716
Loss at iteration 960 : 0.013753359206020832
Loss at iteration 970 : 0.016435354948043823
Loss at iteration 980 : 0.027820896357297897
Loss at iteration 990 : 0.014359947293996811
Loss at iteration 1000 : 0.027039336040616035
Loss at iteration 1010 : 0.017374161630868912
Loss at iteration 1020 : 0.015676390379667282
Loss at iteration 1030 : 0.038738712668418884
Loss at iteration 1040 : 0.024950072169303894
Loss at iteration 1050 : 0.04159773886203766
Loss at iteration 1060 : 0.03400532528758049
Loss at iteration 1070 : 0.01905493624508381
Loss at iteration 1080 : 0.021556157618761063
Loss at iteration 1090 : 0.021463073790073395
Loss at iteration 1100 : 0.025569645687937737
Loss at iteration 1110 : 0.023494822904467583
Loss at iteration 1120 : 0.030834782868623734
Loss at iteration 1130 : 0.018739856779575348
Loss at iteration 1140 : 0.023010721430182457
Loss at iteration 1150 : 0.017763415351510048
Loss at iteration 1160 : 0.03389749675989151
Loss at iteration 1170 : 0.0188482366502285
Loss at iteration 1180 : 0.022149143740534782
Loss at iteration 1190 : 0.013622386381030083
Loss at iteration 1200 : 0.026936890557408333
Loss at iteration 1210 : 0.021035075187683105
The SSIM Value is: 0.7938639918963114
The PSNR Value is: 19.207313537597656
the highest SSIM value is: 19.207313537597656
the epoch is: 74
Loss at iteration 10 : 0.009302817285060883
Loss at iteration 20 : 0.01705135405063629
Loss at iteration 30 : 0.013256450183689594
Loss at iteration 40 : 0.02082066610455513
Loss at iteration 50 : 0.010503340512514114
Loss at iteration 60 : 0.020907087251544
Loss at iteration 70 : 0.026640892028808594
Loss at iteration 80 : 0.03888784348964691
Loss at iteration 90 : 0.021326730027794838
Loss at iteration 100 : 0.02240787260234356
Loss at iteration 110 : 0.03323282301425934
Loss at iteration 120 : 0.015964340418577194
Loss at iteration 130 : 0.018881836906075478
Loss at iteration 140 : 0.025521408766508102
Loss at iteration 150 : 0.02595798298716545
Loss at iteration 160 : 0.018531564623117447
Loss at iteration 170 : 0.02149081416428089
Loss at iteration 180 : 0.016962939873337746
Loss at iteration 190 : 0.014818396419286728
Loss at iteration 200 : 0.025238122791051865
Loss at iteration 210 : 0.016358718276023865
Loss at iteration 220 : 0.019228681921958923
Loss at iteration 230 : 0.030353527516126633
Loss at iteration 240 : 0.030213430523872375
Loss at iteration 250 : 0.03185084089636803
Loss at iteration 260 : 0.03372751921415329
Loss at iteration 270 : 0.02407638542354107
Loss at iteration 280 : 0.03104352578520775
Loss at iteration 290 : 0.014006191864609718
Loss at iteration 300 : 0.018792834132909775
Loss at iteration 310 : 0.0172002874314785
Loss at iteration 320 : 0.02212487906217575
Loss at iteration 330 : 0.023566775023937225
Loss at iteration 340 : 0.020480837672948837
Loss at iteration 350 : 0.025085926055908203
Loss at iteration 360 : 0.016554096713662148
Loss at iteration 370 : 0.01778990775346756
Loss at iteration 380 : 0.021972738206386566
Loss at iteration 390 : 0.017094239592552185
Loss at iteration 400 : 0.019819345325231552
Loss at iteration 410 : 0.016384806483983994
Loss at iteration 420 : 0.04140575975179672
Loss at iteration 430 : 0.025837263092398643
Loss at iteration 440 : 0.016726434230804443
Loss at iteration 450 : 0.02163805440068245
Loss at iteration 460 : 0.018049225211143494
Loss at iteration 470 : 0.027416419237852097
Loss at iteration 480 : 0.020788798108696938
Loss at iteration 490 : 0.025140883401036263
Loss at iteration 500 : 0.01921183615922928
Loss at iteration 510 : 0.01897646114230156
Loss at iteration 520 : 0.022758765146136284
Loss at iteration 530 : 0.021404076367616653
Loss at iteration 540 : 0.016680018976330757
Loss at iteration 550 : 0.0231619905680418
Loss at iteration 560 : 0.02420424483716488
Loss at iteration 570 : 0.020441291853785515
Loss at iteration 580 : 0.019199509173631668
Loss at iteration 590 : 0.027299491688609123
Loss at iteration 600 : 0.019950851798057556
Loss at iteration 610 : 0.014349235221743584
Loss at iteration 620 : 0.030885223299264908
Loss at iteration 630 : 0.02390025556087494
Loss at iteration 640 : 0.021276965737342834
Loss at iteration 650 : 0.025691863149404526
Loss at iteration 660 : 0.04677676036953926
Loss at iteration 670 : 0.024510502815246582
Loss at iteration 680 : 0.017087874934077263
Loss at iteration 690 : 0.014858954586088657
Loss at iteration 700 : 0.05110778659582138
Loss at iteration 710 : 0.03411009535193443
Loss at iteration 720 : 0.02379036508500576
Loss at iteration 730 : 0.014879201538860798
Loss at iteration 740 : 0.028155356645584106
Loss at iteration 750 : 0.02294512465596199
Loss at iteration 760 : 0.01804279163479805
Loss at iteration 770 : 0.027932971715927124
Loss at iteration 780 : 0.028085775673389435
Loss at iteration 790 : 0.029463307932019234
Loss at iteration 800 : 0.018701689317822456
Loss at iteration 810 : 0.01756746508181095
Loss at iteration 820 : 0.015723273158073425
Loss at iteration 830 : 0.03368593007326126
Loss at iteration 840 : 0.01627936027944088
Loss at iteration 850 : 0.02889065258204937
Loss at iteration 860 : 0.01905803382396698
Loss at iteration 870 : 0.01803743839263916
Loss at iteration 880 : 0.026227116584777832
Loss at iteration 890 : 0.014363976195454597
Loss at iteration 900 : 0.026392769068479538
Loss at iteration 910 : 0.03075462207198143
Loss at iteration 920 : 0.011730143800377846
Loss at iteration 930 : 0.016745809465646744
Loss at iteration 940 : 0.008101483806967735
Loss at iteration 950 : 0.02625979483127594
Loss at iteration 960 : 0.019207477569580078
Loss at iteration 970 : 0.012352130375802517
Loss at iteration 980 : 0.03179566562175751
Loss at iteration 990 : 0.01473988126963377
Loss at iteration 1000 : 0.018521297723054886
Loss at iteration 1010 : 0.01538837980479002
Loss at iteration 1020 : 0.014797065407037735
Loss at iteration 1030 : 0.013460824266076088
Loss at iteration 1040 : 0.028148595243692398
Loss at iteration 1050 : 0.02925746887922287
Loss at iteration 1060 : 0.030554622411727905
Loss at iteration 1070 : 0.018134698271751404
Loss at iteration 1080 : 0.01956482231616974
Loss at iteration 1090 : 0.0330035462975502
Loss at iteration 1100 : 0.024172239005565643
Loss at iteration 1110 : 0.01831815019249916
Loss at iteration 1120 : 0.02708447352051735
Loss at iteration 1130 : 0.01828566938638687
Loss at iteration 1140 : 0.013303123414516449
Loss at iteration 1150 : 0.021242041140794754
Loss at iteration 1160 : 0.026731910184025764
Loss at iteration 1170 : 0.030677776783704758
Loss at iteration 1180 : 0.01677362062036991
Loss at iteration 1190 : 0.025085430592298508
Loss at iteration 1200 : 0.021767280995845795
Loss at iteration 1210 : 0.013669711537659168
The SSIM Value is: 0.7970187028249105
The PSNR Value is: 19.258591906229654
the highest SSIM value is: 19.258591906229654
the epoch is: 75
Loss at iteration 10 : 0.013949612155556679
Loss at iteration 20 : 0.023856624960899353
Loss at iteration 30 : 0.017494045197963715
Loss at iteration 40 : 0.015724781900644302
Loss at iteration 50 : 0.017048651352524757
Loss at iteration 60 : 0.02635057270526886
Loss at iteration 70 : 0.021873224526643753
Loss at iteration 80 : 0.02383594959974289
Loss at iteration 90 : 0.011959979310631752
Loss at iteration 100 : 0.022865502163767815
Loss at iteration 110 : 0.016943173483014107
Loss at iteration 120 : 0.029028568416833878
Loss at iteration 130 : 0.021117612719535828
Loss at iteration 140 : 0.02413899451494217
Loss at iteration 150 : 0.03776557743549347
Loss at iteration 160 : 0.02162598818540573
Loss at iteration 170 : 0.013673678040504456
Loss at iteration 180 : 0.023942843079566956
Loss at iteration 190 : 0.017267154529690742
Loss at iteration 200 : 0.021951576694846153
Loss at iteration 210 : 0.029530318453907967
Loss at iteration 220 : 0.016497047618031502
Loss at iteration 230 : 0.016792643815279007
Loss at iteration 240 : 0.013689769431948662
Loss at iteration 250 : 0.019801735877990723
Loss at iteration 260 : 0.03281566873192787
Loss at iteration 270 : 0.02062026411294937
Loss at iteration 280 : 0.014998625963926315
Loss at iteration 290 : 0.023571979254484177
Loss at iteration 300 : 0.022131480276584625
Loss at iteration 310 : 0.019546158611774445
Loss at iteration 320 : 0.023540381342172623
Loss at iteration 330 : 0.02477746456861496
Loss at iteration 340 : 0.02413773164153099
Loss at iteration 350 : 0.019445978105068207
Loss at iteration 360 : 0.026234354823827744
Loss at iteration 370 : 0.038752056658267975
Loss at iteration 380 : 0.023677542805671692
Loss at iteration 390 : 0.01606808975338936
Loss at iteration 400 : 0.014475220814347267
Loss at iteration 410 : 0.017276421189308167
Loss at iteration 420 : 0.016732458025217056
Loss at iteration 430 : 0.01805400848388672
Loss at iteration 440 : 0.029571902006864548
Loss at iteration 450 : 0.02089861035346985
Loss at iteration 460 : 0.016060560941696167
Loss at iteration 470 : 0.012716162949800491
Loss at iteration 480 : 0.021905072033405304
Loss at iteration 490 : 0.027104156091809273
Loss at iteration 500 : 0.016212601214647293
Loss at iteration 510 : 0.020968373864889145
Loss at iteration 520 : 0.010614324361085892
Loss at iteration 530 : 0.021589498966932297
Loss at iteration 540 : 0.015595996752381325
Loss at iteration 550 : 0.014429273083806038
Loss at iteration 560 : 0.02458847686648369
Loss at iteration 570 : 0.023747339844703674
Loss at iteration 580 : 0.016010556370019913
Loss at iteration 590 : 0.023297522217035294
Loss at iteration 600 : 0.01790713146328926
Loss at iteration 610 : 0.01653110422194004
Loss at iteration 620 : 0.026319488883018494
Loss at iteration 630 : 0.03016582876443863
Loss at iteration 640 : 0.037394437938928604
Loss at iteration 650 : 0.03076951578259468
Loss at iteration 660 : 0.02328498288989067
Loss at iteration 670 : 0.02809465117752552
Loss at iteration 680 : 0.02262810245156288
Loss at iteration 690 : 0.02543828636407852
Loss at iteration 700 : 0.0342680849134922
Loss at iteration 710 : 0.03942304477095604
Loss at iteration 720 : 0.017733149230480194
Loss at iteration 730 : 0.026267629116773605
Loss at iteration 740 : 0.03372488170862198
Loss at iteration 750 : 0.0228489451110363
Loss at iteration 760 : 0.030268970876932144
Loss at iteration 770 : 0.016766823828220367
Loss at iteration 780 : 0.019369732588529587
Loss at iteration 790 : 0.023351918905973434
Loss at iteration 800 : 0.024004697799682617
Loss at iteration 810 : 0.02805778756737709
Loss at iteration 820 : 0.014545251615345478
Loss at iteration 830 : 0.020247310400009155
Loss at iteration 840 : 0.028058309108018875
Loss at iteration 850 : 0.022714124992489815
Loss at iteration 860 : 0.024187393486499786
Loss at iteration 870 : 0.025858841836452484
Loss at iteration 880 : 0.022550225257873535
Loss at iteration 890 : 0.01864418014883995
Loss at iteration 900 : 0.030848953872919083
Loss at iteration 910 : 0.017998114228248596
Loss at iteration 920 : 0.03793102502822876
Loss at iteration 930 : 0.018750617280602455
Loss at iteration 940 : 0.030041765421628952
Loss at iteration 950 : 0.020867440849542618
Loss at iteration 960 : 0.029291372746229172
Loss at iteration 970 : 0.01739426888525486
Loss at iteration 980 : 0.028050947934389114
Loss at iteration 990 : 0.021748319268226624
Loss at iteration 1000 : 0.036377742886543274
Loss at iteration 1010 : 0.01958058588206768
Loss at iteration 1020 : 0.026124829426407814
Loss at iteration 1030 : 0.016430674120783806
Loss at iteration 1040 : 0.02229120582342148
Loss at iteration 1050 : 0.023101475089788437
Loss at iteration 1060 : 0.021018339321017265
Loss at iteration 1070 : 0.025264225900173187
Loss at iteration 1080 : 0.02777205966413021
Loss at iteration 1090 : 0.014152810908854008
Loss at iteration 1100 : 0.014321369118988514
Loss at iteration 1110 : 0.020556889474391937
Loss at iteration 1120 : 0.025977622717618942
Loss at iteration 1130 : 0.0289587564766407
Loss at iteration 1140 : 0.018057141453027725
Loss at iteration 1150 : 0.019685011357069016
Loss at iteration 1160 : 0.03024199791252613
Loss at iteration 1170 : 0.03146378695964813
Loss at iteration 1180 : 0.028436433523893356
Loss at iteration 1190 : 0.012868279591202736
Loss at iteration 1200 : 0.027590809389948845
Loss at iteration 1210 : 0.023907896131277084
The SSIM Value is: 0.7955336372057596
The PSNR Value is: 19.002217547098795
the epoch is: 76
Loss at iteration 10 : 0.015429726801812649
Loss at iteration 20 : 0.022677317261695862
Loss at iteration 30 : 0.015266173519194126
Loss at iteration 40 : 0.026486720889806747
Loss at iteration 50 : 0.023567698895931244
Loss at iteration 60 : 0.021542929112911224
Loss at iteration 70 : 0.025844670832157135
Loss at iteration 80 : 0.028218183666467667
Loss at iteration 90 : 0.02361614629626274
Loss at iteration 100 : 0.025670845061540604
Loss at iteration 110 : 0.012909067794680595
Loss at iteration 120 : 0.02629408985376358
Loss at iteration 130 : 0.028258781880140305
Loss at iteration 140 : 0.011551235802471638
Loss at iteration 150 : 0.013756992295384407
Loss at iteration 160 : 0.03640642762184143
Loss at iteration 170 : 0.03725028038024902
Loss at iteration 180 : 0.019151926040649414
Loss at iteration 190 : 0.020065806806087494
Loss at iteration 200 : 0.020540867000818253
Loss at iteration 210 : 0.01756645366549492
Loss at iteration 220 : 0.02231946960091591
Loss at iteration 230 : 0.017191926017403603
Loss at iteration 240 : 0.022316066548228264
Loss at iteration 250 : 0.025051506236195564
Loss at iteration 260 : 0.023012446239590645
Loss at iteration 270 : 0.01836499199271202
Loss at iteration 280 : 0.026113899424672127
Loss at iteration 290 : 0.01794499158859253
Loss at iteration 300 : 0.03766565024852753
Loss at iteration 310 : 0.013256399892270565
Loss at iteration 320 : 0.020256392657756805
Loss at iteration 330 : 0.025693712756037712
Loss at iteration 340 : 0.019629117101430893
Loss at iteration 350 : 0.02187100425362587
Loss at iteration 360 : 0.01896481215953827
Loss at iteration 370 : 0.021482203155755997
Loss at iteration 380 : 0.015479275956749916
Loss at iteration 390 : 0.023743871599435806
Loss at iteration 400 : 0.016372866928577423
Loss at iteration 410 : 0.025446631014347076
Loss at iteration 420 : 0.02324223518371582
Loss at iteration 430 : 0.029177896678447723
Loss at iteration 440 : 0.02539684996008873
Loss at iteration 450 : 0.017933502793312073
Loss at iteration 460 : 0.017333198338747025
Loss at iteration 470 : 0.031178008764982224
Loss at iteration 480 : 0.014881560578942299
Loss at iteration 490 : 0.01965237781405449
Loss at iteration 500 : 0.01522440742701292
Loss at iteration 510 : 0.019529998302459717
Loss at iteration 520 : 0.01544911414384842
Loss at iteration 530 : 0.016384873539209366
Loss at iteration 540 : 0.022844694554805756
Loss at iteration 550 : 0.039522185921669006
Loss at iteration 560 : 0.024934176355600357
Loss at iteration 570 : 0.013920134864747524
Loss at iteration 580 : 0.023542340844869614
Loss at iteration 590 : 0.028296511620283127
Loss at iteration 600 : 0.03065485879778862
Loss at iteration 610 : 0.0222590584307909
Loss at iteration 620 : 0.016963934525847435
Loss at iteration 630 : 0.021457068622112274
Loss at iteration 640 : 0.020295631140470505
Loss at iteration 650 : 0.026651013642549515
Loss at iteration 660 : 0.020887203514575958
Loss at iteration 670 : 0.03623476251959801
Loss at iteration 680 : 0.028031393885612488
Loss at iteration 690 : 0.034732211381196976
Loss at iteration 700 : 0.007906530052423477
Loss at iteration 710 : 0.016176637262105942
Loss at iteration 720 : 0.021826233714818954
Loss at iteration 730 : 0.02648109756410122
Loss at iteration 740 : 0.030371390283107758
Loss at iteration 750 : 0.015594561584293842
Loss at iteration 760 : 0.02873658388853073
Loss at iteration 770 : 0.025748495012521744
Loss at iteration 780 : 0.03223547339439392
Loss at iteration 790 : 0.01888164132833481
Loss at iteration 800 : 0.020797526463866234
Loss at iteration 810 : 0.022745955735445023
Loss at iteration 820 : 0.03388718515634537
Loss at iteration 830 : 0.024180471897125244
Loss at iteration 840 : 0.012301774695515633
Loss at iteration 850 : 0.02320726029574871
Loss at iteration 860 : 0.04004839435219765
Loss at iteration 870 : 0.013657113537192345
Loss at iteration 880 : 0.011994455009698868
Loss at iteration 890 : 0.015731021761894226
Loss at iteration 900 : 0.020878266543149948
Loss at iteration 910 : 0.01779414899647236
Loss at iteration 920 : 0.020306279882788658
Loss at iteration 930 : 0.03365352749824524
Loss at iteration 940 : 0.015464896336197853
Loss at iteration 950 : 0.009789458476006985
Loss at iteration 960 : 0.027700018137693405
Loss at iteration 970 : 0.016071049496531487
Loss at iteration 980 : 0.032898254692554474
Loss at iteration 990 : 0.023427000269293785
Loss at iteration 1000 : 0.01077251136302948
Loss at iteration 1010 : 0.01743534952402115
Loss at iteration 1020 : 0.02014322206377983
Loss at iteration 1030 : 0.011507988907396793
Loss at iteration 1040 : 0.021208155900239944
Loss at iteration 1050 : 0.025416690856218338
Loss at iteration 1060 : 0.026523631066083908
Loss at iteration 1070 : 0.015929196029901505
Loss at iteration 1080 : 0.020208686590194702
Loss at iteration 1090 : 0.026867642998695374
Loss at iteration 1100 : 0.02150651253759861
Loss at iteration 1110 : 0.03510889783501625
Loss at iteration 1120 : 0.021615663543343544
Loss at iteration 1130 : 0.019588612020015717
Loss at iteration 1140 : 0.023694029077887535
Loss at iteration 1150 : 0.025695059448480606
Loss at iteration 1160 : 0.03492642939090729
Loss at iteration 1170 : 0.0230441614985466
Loss at iteration 1180 : 0.01579931378364563
Loss at iteration 1190 : 0.02686154842376709
Loss at iteration 1200 : 0.030622243881225586
Loss at iteration 1210 : 0.008146877400577068
The SSIM Value is: 0.7943273425102234
The PSNR Value is: 19.253796831766763
the epoch is: 77
Loss at iteration 10 : 0.035230737179517746
Loss at iteration 20 : 0.021261319518089294
Loss at iteration 30 : 0.015470140613615513
Loss at iteration 40 : 0.013796617276966572
Loss at iteration 50 : 0.0172712542116642
Loss at iteration 60 : 0.020880991593003273
Loss at iteration 70 : 0.021882224828004837
Loss at iteration 80 : 0.020945491269230843
Loss at iteration 90 : 0.03026069700717926
Loss at iteration 100 : 0.02326740324497223
Loss at iteration 110 : 0.041677478700876236
Loss at iteration 120 : 0.0270627960562706
Loss at iteration 130 : 0.01870110258460045
Loss at iteration 140 : 0.020291801542043686
Loss at iteration 150 : 0.03655799850821495
Loss at iteration 160 : 0.01768791675567627
Loss at iteration 170 : 0.010651077143847942
Loss at iteration 180 : 0.0197712704539299
Loss at iteration 190 : 0.020976779982447624
Loss at iteration 200 : 0.024214616045355797
Loss at iteration 210 : 0.025581248104572296
Loss at iteration 220 : 0.04094520956277847
Loss at iteration 230 : 0.019000288099050522
Loss at iteration 240 : 0.018081579357385635
Loss at iteration 250 : 0.022663835436105728
Loss at iteration 260 : 0.016315262764692307
Loss at iteration 270 : 0.020522603765130043
Loss at iteration 280 : 0.01680021733045578
Loss at iteration 290 : 0.024744756519794464
Loss at iteration 300 : 0.022421175613999367
Loss at iteration 310 : 0.03676711767911911
Loss at iteration 320 : 0.02322489395737648
Loss at iteration 330 : 0.01977292262017727
Loss at iteration 340 : 0.019324596971273422
Loss at iteration 350 : 0.0312613770365715
Loss at iteration 360 : 0.018942488357424736
Loss at iteration 370 : 0.014904878102242947
Loss at iteration 380 : 0.014867710880935192
Loss at iteration 390 : 0.020182613283395767
Loss at iteration 400 : 0.01910562440752983
Loss at iteration 410 : 0.01900029368698597
Loss at iteration 420 : 0.014350570738315582
Loss at iteration 430 : 0.01084892451763153
Loss at iteration 440 : 0.033882394433021545
Loss at iteration 450 : 0.020115792751312256
Loss at iteration 460 : 0.01740804687142372
Loss at iteration 470 : 0.027925735339522362
Loss at iteration 480 : 0.023914653807878494
Loss at iteration 490 : 0.013269267044961452
Loss at iteration 500 : 0.02339853160083294
Loss at iteration 510 : 0.022504335269331932
Loss at iteration 520 : 0.020078158006072044
Loss at iteration 530 : 0.017068464308977127
Loss at iteration 540 : 0.0307899322360754
Loss at iteration 550 : 0.01724638044834137
Loss at iteration 560 : 0.020135872066020966
Loss at iteration 570 : 0.013503347523510456
Loss at iteration 580 : 0.022134818136692047
Loss at iteration 590 : 0.025746740400791168
Loss at iteration 600 : 0.0252385251224041
Loss at iteration 610 : 0.03133928403258324
Loss at iteration 620 : 0.01826941780745983
Loss at iteration 630 : 0.02493402361869812
Loss at iteration 640 : 0.021811217069625854
Loss at iteration 650 : 0.020998835563659668
Loss at iteration 660 : 0.022985750809311867
Loss at iteration 670 : 0.019592538475990295
Loss at iteration 680 : 0.024553701281547546
Loss at iteration 690 : 0.020752865821123123
Loss at iteration 700 : 0.0257088765501976
Loss at iteration 710 : 0.028436563909053802
Loss at iteration 720 : 0.020168446004390717
Loss at iteration 730 : 0.026015281677246094
Loss at iteration 740 : 0.020152198150753975
Loss at iteration 750 : 0.012202901765704155
Loss at iteration 760 : 0.028987284749746323
Loss at iteration 770 : 0.0198306106030941
Loss at iteration 780 : 0.019777636975049973
Loss at iteration 790 : 0.03610476478934288
Loss at iteration 800 : 0.01721378229558468
Loss at iteration 810 : 0.02301708236336708
Loss at iteration 820 : 0.022221773862838745
Loss at iteration 830 : 0.01910463534295559
Loss at iteration 840 : 0.017400983721017838
Loss at iteration 850 : 0.015917640179395676
Loss at iteration 860 : 0.017499592155218124
Loss at iteration 870 : 0.026567943394184113
Loss at iteration 880 : 0.03184457868337631
Loss at iteration 890 : 0.01918359473347664
Loss at iteration 900 : 0.02286408096551895
Loss at iteration 910 : 0.01666872948408127
Loss at iteration 920 : 0.02085706777870655
Loss at iteration 930 : 0.024914458394050598
Loss at iteration 940 : 0.020496560260653496
Loss at iteration 950 : 0.03781849518418312
Loss at iteration 960 : 0.02039022371172905
Loss at iteration 970 : 0.026168569922447205
Loss at iteration 980 : 0.026685845106840134
Loss at iteration 990 : 0.018104635179042816
Loss at iteration 1000 : 0.024973075836896896
Loss at iteration 1010 : 0.019675565883517265
Loss at iteration 1020 : 0.021307706832885742
Loss at iteration 1030 : 0.03778970614075661
Loss at iteration 1040 : 0.016413899138569832
Loss at iteration 1050 : 0.027184991165995598
Loss at iteration 1060 : 0.03268852457404137
Loss at iteration 1070 : 0.013117106631398201
Loss at iteration 1080 : 0.029339898377656937
Loss at iteration 1090 : 0.018628019839525223
Loss at iteration 1100 : 0.01101195439696312
Loss at iteration 1110 : 0.026918925344944
Loss at iteration 1120 : 0.020865289494395256
Loss at iteration 1130 : 0.020153770223259926
Loss at iteration 1140 : 0.024084139615297318
Loss at iteration 1150 : 0.02260291390120983
Loss at iteration 1160 : 0.01680280826985836
Loss at iteration 1170 : 0.02399386093020439
Loss at iteration 1180 : 0.020498355850577354
Loss at iteration 1190 : 0.016309896484017372
Loss at iteration 1200 : 0.015377206727862358
Loss at iteration 1210 : 0.027143504470586777
The SSIM Value is: 0.7953140735626221
The PSNR Value is: 19.233275667826334
the epoch is: 78
Loss at iteration 10 : 0.02620755136013031
Loss at iteration 20 : 0.019959963858127594
Loss at iteration 30 : 0.018468406051397324
Loss at iteration 40 : 0.014710788615047932
Loss at iteration 50 : 0.021898940205574036
Loss at iteration 60 : 0.025072524324059486
Loss at iteration 70 : 0.011437248438596725
Loss at iteration 80 : 0.016087951138615608
Loss at iteration 90 : 0.018218854442238808
Loss at iteration 100 : 0.02091897651553154
Loss at iteration 110 : 0.015179824084043503
Loss at iteration 120 : 0.028226181864738464
Loss at iteration 130 : 0.019811470061540604
Loss at iteration 140 : 0.036047376692295074
Loss at iteration 150 : 0.02849997766315937
Loss at iteration 160 : 0.02208986133337021
Loss at iteration 170 : 0.022783217951655388
Loss at iteration 180 : 0.022071119397878647
Loss at iteration 190 : 0.017407210543751717
Loss at iteration 200 : 0.010389087721705437
Loss at iteration 210 : 0.03795316070318222
Loss at iteration 220 : 0.009975738823413849
Loss at iteration 230 : 0.021782495081424713
Loss at iteration 240 : 0.022264264523983
Loss at iteration 250 : 0.023840870708227158
Loss at iteration 260 : 0.016030579805374146
Loss at iteration 270 : 0.01507522165775299
Loss at iteration 280 : 0.01894194260239601
Loss at iteration 290 : 0.024787671864032745
Loss at iteration 300 : 0.011260700412094593
Loss at iteration 310 : 0.020600222051143646
Loss at iteration 320 : 0.03706961125135422
Loss at iteration 330 : 0.019882265478372574
Loss at iteration 340 : 0.021068086847662926
Loss at iteration 350 : 0.016356971114873886
Loss at iteration 360 : 0.01736341044306755
Loss at iteration 370 : 0.020299924537539482
Loss at iteration 380 : 0.015667762607336044
Loss at iteration 390 : 0.02305024489760399
Loss at iteration 400 : 0.030199285596609116
Loss at iteration 410 : 0.027049746364355087
Loss at iteration 420 : 0.015903260558843613
Loss at iteration 430 : 0.02126665785908699
Loss at iteration 440 : 0.01441258005797863
Loss at iteration 450 : 0.013514688238501549
Loss at iteration 460 : 0.02819279581308365
Loss at iteration 470 : 0.027664728462696075
Loss at iteration 480 : 0.014290399849414825
Loss at iteration 490 : 0.02428915724158287
Loss at iteration 500 : 0.024020394310355186
Loss at iteration 510 : 0.019960833713412285
Loss at iteration 520 : 0.02001081220805645
Loss at iteration 530 : 0.014085531234741211
Loss at iteration 540 : 0.022868288680911064
Loss at iteration 550 : 0.03125513345003128
Loss at iteration 560 : 0.0176073145121336
Loss at iteration 570 : 0.02465282939374447
Loss at iteration 580 : 0.018008466809988022
Loss at iteration 590 : 0.021315699443221092
Loss at iteration 600 : 0.023836923763155937
Loss at iteration 610 : 0.022607039660215378
Loss at iteration 620 : 0.019415929913520813
Loss at iteration 630 : 0.03248289227485657
Loss at iteration 640 : 0.01898525282740593
Loss at iteration 650 : 0.037541117519140244
Loss at iteration 660 : 0.03515751659870148
Loss at iteration 670 : 0.01667260378599167
Loss at iteration 680 : 0.026963509619235992
Loss at iteration 690 : 0.02718750387430191
Loss at iteration 700 : 0.013382067903876305
Loss at iteration 710 : 0.020784199237823486
Loss at iteration 720 : 0.019728047773241997
Loss at iteration 730 : 0.026220466941595078
Loss at iteration 740 : 0.02365740016102791
Loss at iteration 750 : 0.022713931277394295
Loss at iteration 760 : 0.014934100210666656
Loss at iteration 770 : 0.01661342941224575
Loss at iteration 780 : 0.015913043171167374
Loss at iteration 790 : 0.015584826469421387
Loss at iteration 800 : 0.021841781213879585
Loss at iteration 810 : 0.016430381685495377
Loss at iteration 820 : 0.018427986651659012
Loss at iteration 830 : 0.02650737762451172
Loss at iteration 840 : 0.016504615545272827
Loss at iteration 850 : 0.02104858309030533
Loss at iteration 860 : 0.024670738726854324
Loss at iteration 870 : 0.018315628170967102
Loss at iteration 880 : 0.020928964018821716
Loss at iteration 890 : 0.01853376068174839
Loss at iteration 900 : 0.024407722055912018
Loss at iteration 910 : 0.024587107822299004
Loss at iteration 920 : 0.014811171218752861
Loss at iteration 930 : 0.019224977120757103
Loss at iteration 940 : 0.021646134555339813
Loss at iteration 950 : 0.025579605251550674
Loss at iteration 960 : 0.015696456655859947
Loss at iteration 970 : 0.022079020738601685
Loss at iteration 980 : 0.014227533712983131
Loss at iteration 990 : 0.010061193257570267
Loss at iteration 1000 : 0.022934796288609505
Loss at iteration 1010 : 0.023908374831080437
Loss at iteration 1020 : 0.010951644740998745
Loss at iteration 1030 : 0.02455088123679161
Loss at iteration 1040 : 0.019628355279564857
Loss at iteration 1050 : 0.014934375882148743
Loss at iteration 1060 : 0.017193030565977097
Loss at iteration 1070 : 0.028475580736994743
Loss at iteration 1080 : 0.020331714302301407
Loss at iteration 1090 : 0.020985329523682594
Loss at iteration 1100 : 0.0285334512591362
Loss at iteration 1110 : 0.03124983049929142
Loss at iteration 1120 : 0.026818983256816864
Loss at iteration 1130 : 0.01948247104883194
Loss at iteration 1140 : 0.015018736943602562
Loss at iteration 1150 : 0.02082434669137001
Loss at iteration 1160 : 0.021066807210445404
Loss at iteration 1170 : 0.021304838359355927
Loss at iteration 1180 : 0.016987768933176994
Loss at iteration 1190 : 0.022051764652132988
Loss at iteration 1200 : 0.033489104360342026
Loss at iteration 1210 : 0.029179807752370834
The SSIM Value is: 0.7987242778142293
The PSNR Value is: 19.432331784566244
the highest SSIM value is: 19.432331784566244
the epoch is: 79
Loss at iteration 10 : 0.01680966094136238
Loss at iteration 20 : 0.032942578196525574
Loss at iteration 30 : 0.027983378618955612
Loss at iteration 40 : 0.01761481910943985
Loss at iteration 50 : 0.017865976318717003
Loss at iteration 60 : 0.02683538943529129
Loss at iteration 70 : 0.019624145701527596
Loss at iteration 80 : 0.012224473059177399
Loss at iteration 90 : 0.020303308963775635
Loss at iteration 100 : 0.033480044454336166
Loss at iteration 110 : 0.01618340238928795
Loss at iteration 120 : 0.020359303802251816
Loss at iteration 130 : 0.010273069143295288
Loss at iteration 140 : 0.023146579042077065
Loss at iteration 150 : 0.038039810955524445
Loss at iteration 160 : 0.015004031360149384
Loss at iteration 170 : 0.014225711114704609
Loss at iteration 180 : 0.03402869030833244
Loss at iteration 190 : 0.019546592608094215
Loss at iteration 200 : 0.029003389179706573
Loss at iteration 210 : 0.029290951788425446
Loss at iteration 220 : 0.01835162378847599
Loss at iteration 230 : 0.02877412736415863
Loss at iteration 240 : 0.021039679646492004
Loss at iteration 250 : 0.01461359765380621
Loss at iteration 260 : 0.018460581079125404
Loss at iteration 270 : 0.016908926889300346
Loss at iteration 280 : 0.03737498074769974
Loss at iteration 290 : 0.025573797523975372
Loss at iteration 300 : 0.023632433265447617
Loss at iteration 310 : 0.03162337467074394
Loss at iteration 320 : 0.020922325551509857
Loss at iteration 330 : 0.015413372777402401
Loss at iteration 340 : 0.029688455164432526
Loss at iteration 350 : 0.02381940186023712
Loss at iteration 360 : 0.019140031188726425
Loss at iteration 370 : 0.023862071335315704
Loss at iteration 380 : 0.01686720922589302
Loss at iteration 390 : 0.014513344503939152
Loss at iteration 400 : 0.012822357006371021
Loss at iteration 410 : 0.030364062637090683
Loss at iteration 420 : 0.01497749425470829
Loss at iteration 430 : 0.031574226915836334
Loss at iteration 440 : 0.04040849953889847
Loss at iteration 450 : 0.021784242242574692
Loss at iteration 460 : 0.02163483202457428
Loss at iteration 470 : 0.03228120505809784
Loss at iteration 480 : 0.025106895714998245
Loss at iteration 490 : 0.026637032628059387
Loss at iteration 500 : 0.01781172677874565
Loss at iteration 510 : 0.015511095523834229
Loss at iteration 520 : 0.012761679477989674
Loss at iteration 530 : 0.01268081460148096
Loss at iteration 540 : 0.03498971089720726
Loss at iteration 550 : 0.01663723587989807
Loss at iteration 560 : 0.02047460526227951
Loss at iteration 570 : 0.022026585415005684
Loss at iteration 580 : 0.01799004338681698
Loss at iteration 590 : 0.019722137600183487
Loss at iteration 600 : 0.025964800268411636
Loss at iteration 610 : 0.02195981703698635
Loss at iteration 620 : 0.02873566374182701
Loss at iteration 630 : 0.0216352641582489
Loss at iteration 640 : 0.024946268647909164
Loss at iteration 650 : 0.029052790254354477
Loss at iteration 660 : 0.019940797239542007
Loss at iteration 670 : 0.015535243786871433
Loss at iteration 680 : 0.02062002196907997
Loss at iteration 690 : 0.01763254776597023
Loss at iteration 700 : 0.017630204558372498
Loss at iteration 710 : 0.013099415227770805
Loss at iteration 720 : 0.021200038492679596
Loss at iteration 730 : 0.029960572719573975
Loss at iteration 740 : 0.01924002915620804
Loss at iteration 750 : 0.021457355469465256
Loss at iteration 760 : 0.016503475606441498
Loss at iteration 770 : 0.0149543397128582
Loss at iteration 780 : 0.02360750362277031
Loss at iteration 790 : 0.024053364992141724
Loss at iteration 800 : 0.026664014905691147
Loss at iteration 810 : 0.026093337684869766
Loss at iteration 820 : 0.013988969847559929
Loss at iteration 830 : 0.019224658608436584
Loss at iteration 840 : 0.0340924896299839
Loss at iteration 850 : 0.02530246041715145
Loss at iteration 860 : 0.017955541610717773
Loss at iteration 870 : 0.024011146277189255
Loss at iteration 880 : 0.028737837448716164
Loss at iteration 890 : 0.022996345534920692
Loss at iteration 900 : 0.02834414690732956
Loss at iteration 910 : 0.02708263322710991
Loss at iteration 920 : 0.02753698080778122
Loss at iteration 930 : 0.02558249607682228
Loss at iteration 940 : 0.02826240099966526
Loss at iteration 950 : 0.01774486154317856
Loss at iteration 960 : 0.021915942430496216
Loss at iteration 970 : 0.021724876016378403
Loss at iteration 980 : 0.03177476301789284
Loss at iteration 990 : 0.02235635370016098
Loss at iteration 1000 : 0.02159322425723076
Loss at iteration 1010 : 0.020053092390298843
Loss at iteration 1020 : 0.018869537860155106
Loss at iteration 1030 : 0.031836915761232376
Loss at iteration 1040 : 0.022823797538876534
Loss at iteration 1050 : 0.01582387462258339
Loss at iteration 1060 : 0.02810513786971569
Loss at iteration 1070 : 0.02680690959095955
Loss at iteration 1080 : 0.03278137370944023
Loss at iteration 1090 : 0.02618888020515442
Loss at iteration 1100 : 0.025852736085653305
Loss at iteration 1110 : 0.017095476388931274
Loss at iteration 1120 : 0.025176014751195908
Loss at iteration 1130 : 0.025493208318948746
Loss at iteration 1140 : 0.012689203023910522
Loss at iteration 1150 : 0.02699931524693966
Loss at iteration 1160 : 0.018040545284748077
Loss at iteration 1170 : 0.013636171817779541
Loss at iteration 1180 : 0.02136083133518696
Loss at iteration 1190 : 0.014525920152664185
Loss at iteration 1200 : 0.01670343056321144
Loss at iteration 1210 : 0.02519439160823822
The SSIM Value is: 0.7956977804501851
The PSNR Value is: 19.10413996378581
the epoch is: 80
Loss at iteration 10 : 0.021960536018013954
Loss at iteration 20 : 0.010825671255588531
Loss at iteration 30 : 0.011338497512042522
Loss at iteration 40 : 0.027317078784108162
Loss at iteration 50 : 0.01951458677649498
Loss at iteration 60 : 0.02882242761552334
Loss at iteration 70 : 0.021743815392255783
Loss at iteration 80 : 0.026624340564012527
Loss at iteration 90 : 0.02295142039656639
Loss at iteration 100 : 0.019312873482704163
Loss at iteration 110 : 0.02778574638068676
Loss at iteration 120 : 0.018659202381968498
Loss at iteration 130 : 0.03615163639187813
Loss at iteration 140 : 0.02913854271173477
Loss at iteration 150 : 0.029684241861104965
Loss at iteration 160 : 0.017680158838629723
Loss at iteration 170 : 0.01929822936654091
Loss at iteration 180 : 0.017627671360969543
Loss at iteration 190 : 0.021004734560847282
Loss at iteration 200 : 0.019768958911299706
Loss at iteration 210 : 0.013476105406880379
Loss at iteration 220 : 0.01866886578500271
Loss at iteration 230 : 0.025217337533831596
Loss at iteration 240 : 0.019417956471443176
Loss at iteration 250 : 0.015155964531004429
Loss at iteration 260 : 0.01439007930457592
Loss at iteration 270 : 0.03177526220679283
Loss at iteration 280 : 0.019727323204278946
Loss at iteration 290 : 0.01513822004199028
Loss at iteration 300 : 0.02031766250729561
Loss at iteration 310 : 0.016848236322402954
Loss at iteration 320 : 0.01578325405716896
Loss at iteration 330 : 0.0322430320084095
Loss at iteration 340 : 0.01708836853504181
Loss at iteration 350 : 0.020248398184776306
Loss at iteration 360 : 0.03719600662589073
Loss at iteration 370 : 0.023738013580441475
Loss at iteration 380 : 0.02274143695831299
Loss at iteration 390 : 0.031058073043823242
Loss at iteration 400 : 0.013431847095489502
Loss at iteration 410 : 0.04138316959142685
Loss at iteration 420 : 0.01491507887840271
Loss at iteration 430 : 0.012072404846549034
Loss at iteration 440 : 0.016537629067897797
Loss at iteration 450 : 0.02242261916399002
Loss at iteration 460 : 0.017147688195109367
Loss at iteration 470 : 0.02856588363647461
Loss at iteration 480 : 0.02071978896856308
Loss at iteration 490 : 0.02893531322479248
Loss at iteration 500 : 0.027167558670043945
Loss at iteration 510 : 0.013140333816409111
Loss at iteration 520 : 0.019761569797992706
Loss at iteration 530 : 0.01207638904452324
Loss at iteration 540 : 0.03538262099027634
Loss at iteration 550 : 0.019965555518865585
Loss at iteration 560 : 0.027599798515439034
Loss at iteration 570 : 0.020154014229774475
Loss at iteration 580 : 0.028555259108543396
Loss at iteration 590 : 0.019773267209529877
Loss at iteration 600 : 0.03112025186419487
Loss at iteration 610 : 0.021098662167787552
Loss at iteration 620 : 0.016682066023349762
Loss at iteration 630 : 0.031566064804792404
Loss at iteration 640 : 0.02117108553647995
Loss at iteration 650 : 0.015604233369231224
Loss at iteration 660 : 0.02847285568714142
Loss at iteration 670 : 0.02066863141953945
Loss at iteration 680 : 0.024013996124267578
Loss at iteration 690 : 0.02020951732993126
Loss at iteration 700 : 0.02143840864300728
Loss at iteration 710 : 0.020889798179268837
Loss at iteration 720 : 0.023813318461179733
Loss at iteration 730 : 0.016313400119543076
Loss at iteration 740 : 0.013518817722797394
Loss at iteration 750 : 0.01821170002222061
Loss at iteration 760 : 0.01433822326362133
Loss at iteration 770 : 0.016169371083378792
Loss at iteration 780 : 0.020913712680339813
Loss at iteration 790 : 0.021418970078229904
Loss at iteration 800 : 0.016580864787101746
Loss at iteration 810 : 0.018876688554883003
Loss at iteration 820 : 0.021251536905765533
Loss at iteration 830 : 0.027229618281126022
Loss at iteration 840 : 0.019240085035562515
Loss at iteration 850 : 0.014168158173561096
Loss at iteration 860 : 0.019233711063861847
Loss at iteration 870 : 0.010285348631441593
Loss at iteration 880 : 0.013333726674318314
Loss at iteration 890 : 0.024736186489462852
Loss at iteration 900 : 0.018237093463540077
Loss at iteration 910 : 0.02683916501700878
Loss at iteration 920 : 0.02978881075978279
Loss at iteration 930 : 0.016574518755078316
Loss at iteration 940 : 0.014730573631823063
Loss at iteration 950 : 0.025893278419971466
Loss at iteration 960 : 0.01225155871361494
Loss at iteration 970 : 0.01674489676952362
Loss at iteration 980 : 0.023648221045732498
Loss at iteration 990 : 0.03500343859195709
Loss at iteration 1000 : 0.023133976384997368
Loss at iteration 1010 : 0.008414151147007942
Loss at iteration 1020 : 0.024717852473258972
Loss at iteration 1030 : 0.02432650327682495
Loss at iteration 1040 : 0.025416314601898193
Loss at iteration 1050 : 0.01799255982041359
Loss at iteration 1060 : 0.01891002431511879
Loss at iteration 1070 : 0.013231409713625908
Loss at iteration 1080 : 0.01621018722653389
Loss at iteration 1090 : 0.01647859439253807
Loss at iteration 1100 : 0.019040241837501526
Loss at iteration 1110 : 0.014891956001520157
Loss at iteration 1120 : 0.025151778012514114
Loss at iteration 1130 : 0.012387271039187908
Loss at iteration 1140 : 0.016590561717748642
Loss at iteration 1150 : 0.01462178397923708
Loss at iteration 1160 : 0.021265950053930283
Loss at iteration 1170 : 0.021952370181679726
Loss at iteration 1180 : 0.025806309655308723
Loss at iteration 1190 : 0.02375105582177639
Loss at iteration 1200 : 0.019310811534523964
Loss at iteration 1210 : 0.019906939938664436
The SSIM Value is: 0.7954431414604187
The PSNR Value is: 19.085113716125488
the epoch is: 81
Loss at iteration 10 : 0.020708363503217697
Loss at iteration 20 : 0.022707708179950714
Loss at iteration 30 : 0.04011588916182518
Loss at iteration 40 : 0.04063927382230759
Loss at iteration 50 : 0.016688760370016098
Loss at iteration 60 : 0.01475746463984251
Loss at iteration 70 : 0.016232704743742943
Loss at iteration 80 : 0.021295955404639244
Loss at iteration 90 : 0.0234355665743351
Loss at iteration 100 : 0.043155282735824585
Loss at iteration 110 : 0.02244178205728531
Loss at iteration 120 : 0.026774311438202858
Loss at iteration 130 : 0.015355845913290977
Loss at iteration 140 : 0.02087976410984993
Loss at iteration 150 : 0.018884604796767235
Loss at iteration 160 : 0.017607489600777626
Loss at iteration 170 : 0.030780572444200516
Loss at iteration 180 : 0.02469675987958908
Loss at iteration 190 : 0.019281990826129913
Loss at iteration 200 : 0.026564519852399826
Loss at iteration 210 : 0.015800923109054565
Loss at iteration 220 : 0.017592893913388252
Loss at iteration 230 : 0.018949154764413834
Loss at iteration 240 : 0.026176806539297104
Loss at iteration 250 : 0.022101853042840958
Loss at iteration 260 : 0.02083413116633892
Loss at iteration 270 : 0.02296641655266285
Loss at iteration 280 : 0.011642549186944962
Loss at iteration 290 : 0.014063317328691483
Loss at iteration 300 : 0.020500339567661285
Loss at iteration 310 : 0.026952598243951797
Loss at iteration 320 : 0.015844685956835747
Loss at iteration 330 : 0.01979712024331093
Loss at iteration 340 : 0.020107408985495567
Loss at iteration 350 : 0.021066509187221527
Loss at iteration 360 : 0.012880325317382812
Loss at iteration 370 : 0.0262154471129179
Loss at iteration 380 : 0.019400127232074738
Loss at iteration 390 : 0.028460178524255753
Loss at iteration 400 : 0.014354726299643517
Loss at iteration 410 : 0.017736850306391716
Loss at iteration 420 : 0.013651018030941486
Loss at iteration 430 : 0.017460497096180916
Loss at iteration 440 : 0.020805086940526962
Loss at iteration 450 : 0.015847619622945786
Loss at iteration 460 : 0.02825925499200821
Loss at iteration 470 : 0.015071197412908077
Loss at iteration 480 : 0.02722226455807686
Loss at iteration 490 : 0.012270962819457054
Loss at iteration 500 : 0.01650817319750786
Loss at iteration 510 : 0.02275974117219448
Loss at iteration 520 : 0.01318531297147274
Loss at iteration 530 : 0.018362514674663544
Loss at iteration 540 : 0.018922358751296997
Loss at iteration 550 : 0.014036617241799831
Loss at iteration 560 : 0.02059723436832428
Loss at iteration 570 : 0.03033539652824402
Loss at iteration 580 : 0.018910793587565422
Loss at iteration 590 : 0.010253195650875568
Loss at iteration 600 : 0.02112670987844467
Loss at iteration 610 : 0.014766138046979904
Loss at iteration 620 : 0.02057810127735138
Loss at iteration 630 : 0.021124135702848434
Loss at iteration 640 : 0.030268002301454544
Loss at iteration 650 : 0.016148649156093597
Loss at iteration 660 : 0.05817294865846634
Loss at iteration 670 : 0.01338808424770832
Loss at iteration 680 : 0.024481315165758133
Loss at iteration 690 : 0.015592213720083237
Loss at iteration 700 : 0.019404470920562744
Loss at iteration 710 : 0.021435769274830818
Loss at iteration 720 : 0.02768709324300289
Loss at iteration 730 : 0.012619159184396267
Loss at iteration 740 : 0.019371837377548218
Loss at iteration 750 : 0.020074566826224327
Loss at iteration 760 : 0.023798037320375443
Loss at iteration 770 : 0.018107259646058083
Loss at iteration 780 : 0.017955314368009567
Loss at iteration 790 : 0.02118455246090889
Loss at iteration 800 : 0.017055923119187355
Loss at iteration 810 : 0.0231226347386837
Loss at iteration 820 : 0.018711095675826073
Loss at iteration 830 : 0.012479880824685097
Loss at iteration 840 : 0.027944855391979218
Loss at iteration 850 : 0.02566537633538246
Loss at iteration 860 : 0.01522334199398756
Loss at iteration 870 : 0.026010824367403984
Loss at iteration 880 : 0.010495961643755436
Loss at iteration 890 : 0.017564058303833008
Loss at iteration 900 : 0.026116151362657547
Loss at iteration 910 : 0.01264108344912529
Loss at iteration 920 : 0.018281497061252594
Loss at iteration 930 : 0.02329282835125923
Loss at iteration 940 : 0.02193482592701912
Loss at iteration 950 : 0.03514190763235092
Loss at iteration 960 : 0.01637587882578373
Loss at iteration 970 : 0.016104036942124367
Loss at iteration 980 : 0.02288888767361641
Loss at iteration 990 : 0.03302835300564766
Loss at iteration 1000 : 0.028829583898186684
Loss at iteration 1010 : 0.01940799690783024
Loss at iteration 1020 : 0.030002417042851448
Loss at iteration 1030 : 0.02284383960068226
Loss at iteration 1040 : 0.01639920473098755
Loss at iteration 1050 : 0.030702725052833557
Loss at iteration 1060 : 0.014283842407166958
Loss at iteration 1070 : 0.020303694531321526
Loss at iteration 1080 : 0.01939225196838379
Loss at iteration 1090 : 0.02326621115207672
Loss at iteration 1100 : 0.01688547432422638
Loss at iteration 1110 : 0.02454940229654312
Loss at iteration 1120 : 0.01776828244328499
Loss at iteration 1130 : 0.010732261463999748
Loss at iteration 1140 : 0.021082475781440735
Loss at iteration 1150 : 0.01792512647807598
Loss at iteration 1160 : 0.03825843334197998
Loss at iteration 1170 : 0.021081089973449707
Loss at iteration 1180 : 0.023279709741473198
Loss at iteration 1190 : 0.019964400678873062
Loss at iteration 1200 : 0.015966370701789856
Loss at iteration 1210 : 0.023471083492040634
The SSIM Value is: 0.7994558135668437
The PSNR Value is: 19.679120763142905
the highest SSIM value is: 19.679120763142905
the epoch is: 82
Loss at iteration 10 : 0.011901133693754673
Loss at iteration 20 : 0.020634625107049942
Loss at iteration 30 : 0.021494682878255844
Loss at iteration 40 : 0.014307623729109764
Loss at iteration 50 : 0.013571342453360558
Loss at iteration 60 : 0.017260974273085594
Loss at iteration 70 : 0.04098847508430481
Loss at iteration 80 : 0.03315379470586777
Loss at iteration 90 : 0.019146857783198357
Loss at iteration 100 : 0.019068632274866104
Loss at iteration 110 : 0.01530160941183567
Loss at iteration 120 : 0.031234022229909897
Loss at iteration 130 : 0.01901819184422493
Loss at iteration 140 : 0.023688126355409622
Loss at iteration 150 : 0.020724959671497345
Loss at iteration 160 : 0.018750086426734924
Loss at iteration 170 : 0.016543051227927208
Loss at iteration 180 : 0.03142087534070015
Loss at iteration 190 : 0.019114408642053604
Loss at iteration 200 : 0.01759912632405758
Loss at iteration 210 : 0.021160807460546494
Loss at iteration 220 : 0.021733177825808525
Loss at iteration 230 : 0.013127378188073635
Loss at iteration 240 : 0.013048352673649788
Loss at iteration 250 : 0.025090834125876427
Loss at iteration 260 : 0.02327415719628334
Loss at iteration 270 : 0.01809754967689514
Loss at iteration 280 : 0.020727576687932014
Loss at iteration 290 : 0.020841604098677635
Loss at iteration 300 : 0.016352985054254532
Loss at iteration 310 : 0.014048364944756031
Loss at iteration 320 : 0.026665834710001945
Loss at iteration 330 : 0.018229767680168152
Loss at iteration 340 : 0.030365020036697388
Loss at iteration 350 : 0.022612731903791428
Loss at iteration 360 : 0.024836348369717598
Loss at iteration 370 : 0.03024403564631939
Loss at iteration 380 : 0.020372111350297928
Loss at iteration 390 : 0.01594417169690132
Loss at iteration 400 : 0.018541572615504265
Loss at iteration 410 : 0.02308754250407219
Loss at iteration 420 : 0.024337705224752426
Loss at iteration 430 : 0.02217433601617813
Loss at iteration 440 : 0.01933044008910656
Loss at iteration 450 : 0.028285760432481766
Loss at iteration 460 : 0.01448722742497921
Loss at iteration 470 : 0.019454307854175568
Loss at iteration 480 : 0.03800216317176819
Loss at iteration 490 : 0.008410973474383354
Loss at iteration 500 : 0.02022485062479973
Loss at iteration 510 : 0.02486109919846058
Loss at iteration 520 : 0.01677641272544861
Loss at iteration 530 : 0.009830951690673828
Loss at iteration 540 : 0.021384526044130325
Loss at iteration 550 : 0.015006832778453827
Loss at iteration 560 : 0.017144042998552322
Loss at iteration 570 : 0.014670461416244507
Loss at iteration 580 : 0.017740324139595032
Loss at iteration 590 : 0.013577829115092754
Loss at iteration 600 : 0.016980908811092377
Loss at iteration 610 : 0.02146611362695694
Loss at iteration 620 : 0.015444600954651833
Loss at iteration 630 : 0.021421559154987335
Loss at iteration 640 : 0.022773267701268196
Loss at iteration 650 : 0.01800641417503357
Loss at iteration 660 : 0.014188067987561226
Loss at iteration 670 : 0.022058479487895966
Loss at iteration 680 : 0.015743177384138107
Loss at iteration 690 : 0.028338555246591568
Loss at iteration 700 : 0.015175116248428822
Loss at iteration 710 : 0.0115507822483778
Loss at iteration 720 : 0.0322139672935009
Loss at iteration 730 : 0.023693114519119263
Loss at iteration 740 : 0.009632297791540623
Loss at iteration 750 : 0.02543497085571289
Loss at iteration 760 : 0.023211495950818062
Loss at iteration 770 : 0.01783546805381775
Loss at iteration 780 : 0.025920074433088303
Loss at iteration 790 : 0.01587831601500511
Loss at iteration 800 : 0.015559324994683266
Loss at iteration 810 : 0.021333061158657074
Loss at iteration 820 : 0.017516355961561203
Loss at iteration 830 : 0.023177962750196457
Loss at iteration 840 : 0.018363501876592636
Loss at iteration 850 : 0.02373935654759407
Loss at iteration 860 : 0.026744265109300613
Loss at iteration 870 : 0.01918398216366768
Loss at iteration 880 : 0.016906630247831345
Loss at iteration 890 : 0.02061685174703598
Loss at iteration 900 : 0.01888754591345787
Loss at iteration 910 : 0.0154403792694211
Loss at iteration 920 : 0.015755971893668175
Loss at iteration 930 : 0.01880825310945511
Loss at iteration 940 : 0.011891043744981289
Loss at iteration 950 : 0.013142898678779602
Loss at iteration 960 : 0.023130230605602264
Loss at iteration 970 : 0.031681809574365616
Loss at iteration 980 : 0.032071828842163086
Loss at iteration 990 : 0.028992369771003723
Loss at iteration 1000 : 0.022405780851840973
Loss at iteration 1010 : 0.014671532437205315
Loss at iteration 1020 : 0.027834519743919373
Loss at iteration 1030 : 0.015866689383983612
Loss at iteration 1040 : 0.01329275406897068
Loss at iteration 1050 : 0.01259457878768444
Loss at iteration 1060 : 0.013472269289195538
Loss at iteration 1070 : 0.023950375616550446
Loss at iteration 1080 : 0.03111880272626877
Loss at iteration 1090 : 0.012774791568517685
Loss at iteration 1100 : 0.01853027567267418
Loss at iteration 1110 : 0.03157229349017143
Loss at iteration 1120 : 0.013902345672249794
Loss at iteration 1130 : 0.02085522562265396
Loss at iteration 1140 : 0.02328876033425331
Loss at iteration 1150 : 0.019958972930908203
Loss at iteration 1160 : 0.016813091933727264
Loss at iteration 1170 : 0.013218803331255913
Loss at iteration 1180 : 0.023469001054763794
Loss at iteration 1190 : 0.025323525071144104
Loss at iteration 1200 : 0.01416902057826519
Loss at iteration 1210 : 0.01336202584207058
The SSIM Value is: 0.7970377206802368
The PSNR Value is: 19.27791716257731
the epoch is: 83
Loss at iteration 10 : 0.02371460199356079
Loss at iteration 20 : 0.016374098137021065
Loss at iteration 30 : 0.01672251708805561
Loss at iteration 40 : 0.034179314970970154
Loss at iteration 50 : 0.04015239328145981
Loss at iteration 60 : 0.017542628571391106
Loss at iteration 70 : 0.010834017768502235
Loss at iteration 80 : 0.01775001361966133
Loss at iteration 90 : 0.023680806159973145
Loss at iteration 100 : 0.022142522037029266
Loss at iteration 110 : 0.021436374634504318
Loss at iteration 120 : 0.03202581778168678
Loss at iteration 130 : 0.022404709830880165
Loss at iteration 140 : 0.019760925322771072
Loss at iteration 150 : 0.023064590990543365
Loss at iteration 160 : 0.025873938575387
Loss at iteration 170 : 0.01221432350575924
Loss at iteration 180 : 0.04489748924970627
Loss at iteration 190 : 0.03615643456578255
Loss at iteration 200 : 0.037425458431243896
Loss at iteration 210 : 0.02308552712202072
Loss at iteration 220 : 0.02433912642300129
Loss at iteration 230 : 0.018473738804459572
Loss at iteration 240 : 0.01883907988667488
Loss at iteration 250 : 0.02496848627924919
Loss at iteration 260 : 0.018855243921279907
Loss at iteration 270 : 0.03358025476336479
Loss at iteration 280 : 0.009978784248232841
Loss at iteration 290 : 0.0301124956458807
Loss at iteration 300 : 0.029801122844219208
Loss at iteration 310 : 0.02283770591020584
Loss at iteration 320 : 0.018131740391254425
Loss at iteration 330 : 0.021327320486307144
Loss at iteration 340 : 0.017974503338336945
Loss at iteration 350 : 0.028054943308234215
Loss at iteration 360 : 0.020499125123023987
Loss at iteration 370 : 0.012302126735448837
Loss at iteration 380 : 0.02867148630321026
Loss at iteration 390 : 0.02185174450278282
Loss at iteration 400 : 0.022973788902163506
Loss at iteration 410 : 0.022401772439479828
Loss at iteration 420 : 0.02081453613936901
Loss at iteration 430 : 0.01349648181349039
Loss at iteration 440 : 0.022729847580194473
Loss at iteration 450 : 0.016886232420802116
Loss at iteration 460 : 0.02416999265551567
Loss at iteration 470 : 0.017839903011918068
Loss at iteration 480 : 0.023945149034261703
Loss at iteration 490 : 0.02991364896297455
Loss at iteration 500 : 0.01940995454788208
Loss at iteration 510 : 0.016198141500353813
Loss at iteration 520 : 0.011266455054283142
Loss at iteration 530 : 0.025696828961372375
Loss at iteration 540 : 0.02130693569779396
Loss at iteration 550 : 0.014639238826930523
Loss at iteration 560 : 0.023464564234018326
Loss at iteration 570 : 0.03423038870096207
Loss at iteration 580 : 0.02189049683511257
Loss at iteration 590 : 0.029342317953705788
Loss at iteration 600 : 0.015650497749447823
Loss at iteration 610 : 0.018516484647989273
Loss at iteration 620 : 0.02077566087245941
Loss at iteration 630 : 0.0204192902892828
Loss at iteration 640 : 0.033257968723773956
Loss at iteration 650 : 0.025183118879795074
Loss at iteration 660 : 0.01786203682422638
Loss at iteration 670 : 0.017616942524909973
Loss at iteration 680 : 0.04152925685048103
Loss at iteration 690 : 0.025406863540410995
Loss at iteration 700 : 0.022128425538539886
Loss at iteration 710 : 0.0155568178743124
Loss at iteration 720 : 0.01726662367582321
Loss at iteration 730 : 0.024021411314606667
Loss at iteration 740 : 0.0245729498565197
Loss at iteration 750 : 0.021210459992289543
Loss at iteration 760 : 0.019106468185782433
Loss at iteration 770 : 0.023162037134170532
Loss at iteration 780 : 0.025831643491983414
Loss at iteration 790 : 0.015967126935720444
Loss at iteration 800 : 0.027007311582565308
Loss at iteration 810 : 0.028401441872119904
Loss at iteration 820 : 0.025005759671330452
Loss at iteration 830 : 0.01940825581550598
Loss at iteration 840 : 0.017250588163733482
Loss at iteration 850 : 0.015781158581376076
Loss at iteration 860 : 0.02037772908806801
Loss at iteration 870 : 0.01905681937932968
Loss at iteration 880 : 0.02502058818936348
Loss at iteration 890 : 0.03381318226456642
Loss at iteration 900 : 0.0201331228017807
Loss at iteration 910 : 0.016923027113080025
Loss at iteration 920 : 0.018451010808348656
Loss at iteration 930 : 0.019435569643974304
Loss at iteration 940 : 0.02204573154449463
Loss at iteration 950 : 0.0182059183716774
Loss at iteration 960 : 0.011412183754146099
Loss at iteration 970 : 0.036024414002895355
Loss at iteration 980 : 0.019600603729486465
Loss at iteration 990 : 0.029935356229543686
Loss at iteration 1000 : 0.04843559488654137
Loss at iteration 1010 : 0.02349141240119934
Loss at iteration 1020 : 0.028769826516509056
Loss at iteration 1030 : 0.021723754703998566
Loss at iteration 1040 : 0.01360821258276701
Loss at iteration 1050 : 0.02353791519999504
Loss at iteration 1060 : 0.013427836820483208
Loss at iteration 1070 : 0.023472562432289124
Loss at iteration 1080 : 0.02027774788439274
Loss at iteration 1090 : 0.012324249371886253
Loss at iteration 1100 : 0.021634552627801895
Loss at iteration 1110 : 0.019081110134720802
Loss at iteration 1120 : 0.020206056535243988
Loss at iteration 1130 : 0.026274925097823143
Loss at iteration 1140 : 0.01832907274365425
Loss at iteration 1150 : 0.03448242321610451
Loss at iteration 1160 : 0.013813029043376446
Loss at iteration 1170 : 0.02747693844139576
Loss at iteration 1180 : 0.02401190996170044
Loss at iteration 1190 : 0.016922717913985252
Loss at iteration 1200 : 0.01582334190607071
Loss at iteration 1210 : 0.02198592945933342
The SSIM Value is: 0.794122823079427
The PSNR Value is: 19.424381828308107
the epoch is: 84
Loss at iteration 10 : 0.018099386245012283
Loss at iteration 20 : 0.03184963017702103
Loss at iteration 30 : 0.018245071172714233
Loss at iteration 40 : 0.011586478911340237
Loss at iteration 50 : 0.014638432301580906
Loss at iteration 60 : 0.0157732255756855
Loss at iteration 70 : 0.014696801081299782
Loss at iteration 80 : 0.014972265809774399
Loss at iteration 90 : 0.017336487770080566
Loss at iteration 100 : 0.015228692442178726
Loss at iteration 110 : 0.01578471064567566
Loss at iteration 120 : 0.03321322798728943
Loss at iteration 130 : 0.016772713512182236
Loss at iteration 140 : 0.02581140026450157
Loss at iteration 150 : 0.028796296566724777
Loss at iteration 160 : 0.020318202674388885
Loss at iteration 170 : 0.016556326299905777
Loss at iteration 180 : 0.02300846390426159
Loss at iteration 190 : 0.01170349307358265
Loss at iteration 200 : 0.0173539649695158
Loss at iteration 210 : 0.016621144488453865
Loss at iteration 220 : 0.013591088354587555
Loss at iteration 230 : 0.031644307076931
Loss at iteration 240 : 0.031243445351719856
Loss at iteration 250 : 0.020800916478037834
Loss at iteration 260 : 0.023686936125159264
Loss at iteration 270 : 0.022454682737588882
Loss at iteration 280 : 0.024721629917621613
Loss at iteration 290 : 0.013662256300449371
Loss at iteration 300 : 0.028981374576687813
Loss at iteration 310 : 0.016903690993785858
Loss at iteration 320 : 0.010836259461939335
Loss at iteration 330 : 0.01652451790869236
Loss at iteration 340 : 0.02250569686293602
Loss at iteration 350 : 0.021323904395103455
Loss at iteration 360 : 0.02185756340622902
Loss at iteration 370 : 0.019920889288187027
Loss at iteration 380 : 0.026070501655340195
Loss at iteration 390 : 0.0215289406478405
Loss at iteration 400 : 0.018979523330926895
Loss at iteration 410 : 0.01670745201408863
Loss at iteration 420 : 0.019638754427433014
Loss at iteration 430 : 0.02125135436654091
Loss at iteration 440 : 0.02653370052576065
Loss at iteration 450 : 0.016408389434218407
Loss at iteration 460 : 0.021321134641766548
Loss at iteration 470 : 0.025987811386585236
Loss at iteration 480 : 0.02122725546360016
Loss at iteration 490 : 0.01567690446972847
Loss at iteration 500 : 0.01557921338826418
Loss at iteration 510 : 0.021679971367120743
Loss at iteration 520 : 0.021193085238337517
Loss at iteration 530 : 0.02167656645178795
Loss at iteration 540 : 0.014939703047275543
Loss at iteration 550 : 0.025561943650245667
Loss at iteration 560 : 0.020054545253515244
Loss at iteration 570 : 0.012749757617712021
Loss at iteration 580 : 0.017191287130117416
Loss at iteration 590 : 0.011386629194021225
Loss at iteration 600 : 0.025830956175923347
Loss at iteration 610 : 0.017306126654148102
Loss at iteration 620 : 0.0165695920586586
Loss at iteration 630 : 0.016528954729437828
Loss at iteration 640 : 0.015392493456602097
Loss at iteration 650 : 0.021086586639285088
Loss at iteration 660 : 0.012850623577833176
Loss at iteration 670 : 0.02644370123744011
Loss at iteration 680 : 0.016409222036600113
Loss at iteration 690 : 0.016521258279681206
Loss at iteration 700 : 0.020922476425766945
Loss at iteration 710 : 0.017628107219934464
Loss at iteration 720 : 0.013117358088493347
Loss at iteration 730 : 0.02550996094942093
Loss at iteration 740 : 0.0129777230322361
Loss at iteration 750 : 0.01826971396803856
Loss at iteration 760 : 0.012964300811290741
Loss at iteration 770 : 0.02402874082326889
Loss at iteration 780 : 0.03221960738301277
Loss at iteration 790 : 0.017551366239786148
Loss at iteration 800 : 0.012949378229677677
Loss at iteration 810 : 0.010062413290143013
Loss at iteration 820 : 0.032458364963531494
Loss at iteration 830 : 0.04542810469865799
Loss at iteration 840 : 0.017572766169905663
Loss at iteration 850 : 0.025534875690937042
Loss at iteration 860 : 0.03479129076004028
Loss at iteration 870 : 0.0229080431163311
Loss at iteration 880 : 0.019938882440328598
Loss at iteration 890 : 0.018662409856915474
Loss at iteration 900 : 0.03576088696718216
Loss at iteration 910 : 0.031204942613840103
Loss at iteration 920 : 0.026566531509160995
Loss at iteration 930 : 0.01646622270345688
Loss at iteration 940 : 0.026416141539812088
Loss at iteration 950 : 0.014699114486575127
Loss at iteration 960 : 0.019305674359202385
Loss at iteration 970 : 0.01712023839354515
Loss at iteration 980 : 0.019432496279478073
Loss at iteration 990 : 0.016889497637748718
Loss at iteration 1000 : 0.020669182762503624
Loss at iteration 1010 : 0.018671663478016853
Loss at iteration 1020 : 0.02683580294251442
Loss at iteration 1030 : 0.01257901731878519
Loss at iteration 1040 : 0.025345440953969955
Loss at iteration 1050 : 0.02332443930208683
Loss at iteration 1060 : 0.023608645424246788
Loss at iteration 1070 : 0.012757627293467522
Loss at iteration 1080 : 0.02823968231678009
Loss at iteration 1090 : 0.023195385932922363
Loss at iteration 1100 : 0.023590564727783203
Loss at iteration 1110 : 0.018042460083961487
Loss at iteration 1120 : 0.024529943242669106
Loss at iteration 1130 : 0.025968337431550026
Loss at iteration 1140 : 0.023533372208476067
Loss at iteration 1150 : 0.014742673374712467
Loss at iteration 1160 : 0.018463969230651855
Loss at iteration 1170 : 0.029353013262152672
Loss at iteration 1180 : 0.020533548668026924
Loss at iteration 1190 : 0.017325695604085922
Loss at iteration 1200 : 0.02516975812613964
Loss at iteration 1210 : 0.01648005098104477
The SSIM Value is: 0.797277029355367
The PSNR Value is: 19.927415529886883
the highest SSIM value is: 19.927415529886883
the epoch is: 85
Loss at iteration 10 : 0.02610941417515278
Loss at iteration 20 : 0.01610509306192398
Loss at iteration 30 : 0.037240635603666306
Loss at iteration 40 : 0.027009140700101852
Loss at iteration 50 : 0.017273658886551857
Loss at iteration 60 : 0.03324884921312332
Loss at iteration 70 : 0.015394406393170357
Loss at iteration 80 : 0.024506142362952232
Loss at iteration 90 : 0.020698314532637596
Loss at iteration 100 : 0.015285072848200798
Loss at iteration 110 : 0.017965765669941902
Loss at iteration 120 : 0.01588441990315914
Loss at iteration 130 : 0.027403466403484344
Loss at iteration 140 : 0.01820615865290165
Loss at iteration 150 : 0.015415860339999199
Loss at iteration 160 : 0.021887395530939102
Loss at iteration 170 : 0.019188839942216873
Loss at iteration 180 : 0.018856311216950417
Loss at iteration 190 : 0.018756477162241936
Loss at iteration 200 : 0.041157759726047516
Loss at iteration 210 : 0.011233258061110973
Loss at iteration 220 : 0.01637619361281395
Loss at iteration 230 : 0.018185798078775406
Loss at iteration 240 : 0.014856548979878426
Loss at iteration 250 : 0.03168702870607376
Loss at iteration 260 : 0.022238710895180702
Loss at iteration 270 : 0.02235804870724678
Loss at iteration 280 : 0.019627925008535385
Loss at iteration 290 : 0.019706089049577713
Loss at iteration 300 : 0.017924243584275246
Loss at iteration 310 : 0.023239100351929665
Loss at iteration 320 : 0.012218184769153595
Loss at iteration 330 : 0.03537483513355255
Loss at iteration 340 : 0.020157767459750175
Loss at iteration 350 : 0.01683860644698143
Loss at iteration 360 : 0.027016831561923027
Loss at iteration 370 : 0.019608160480856895
Loss at iteration 380 : 0.023621520027518272
Loss at iteration 390 : 0.027395782992243767
Loss at iteration 400 : 0.026229089125990868
Loss at iteration 410 : 0.027946794405579567
Loss at iteration 420 : 0.02378748171031475
Loss at iteration 430 : 0.01428891159594059
Loss at iteration 440 : 0.027789626270532608
Loss at iteration 450 : 0.01544809527695179
Loss at iteration 460 : 0.03293536230921745
Loss at iteration 470 : 0.017850380390882492
Loss at iteration 480 : 0.015421337448060513
Loss at iteration 490 : 0.021686140447854996
Loss at iteration 500 : 0.0163588710129261
Loss at iteration 510 : 0.024799998849630356
Loss at iteration 520 : 0.01870422065258026
Loss at iteration 530 : 0.021520771086215973
Loss at iteration 540 : 0.014729423448443413
Loss at iteration 550 : 0.014535972848534584
Loss at iteration 560 : 0.029113493859767914
Loss at iteration 570 : 0.013445371761918068
Loss at iteration 580 : 0.02150113880634308
Loss at iteration 590 : 0.028186481446027756
Loss at iteration 600 : 0.016251176595687866
Loss at iteration 610 : 0.020888647064566612
Loss at iteration 620 : 0.03144017234444618
Loss at iteration 630 : 0.021697739139199257
Loss at iteration 640 : 0.028176378458738327
Loss at iteration 650 : 0.027912158519029617
Loss at iteration 660 : 0.013174924068152905
Loss at iteration 670 : 0.027712682262063026
Loss at iteration 680 : 0.015823129564523697
Loss at iteration 690 : 0.021219264715909958
Loss at iteration 700 : 0.01377984881401062
Loss at iteration 710 : 0.030293036252260208
Loss at iteration 720 : 0.0209084153175354
Loss at iteration 730 : 0.009063361212611198
Loss at iteration 740 : 0.013393063098192215
Loss at iteration 750 : 0.009569397196173668
Loss at iteration 760 : 0.02718478813767433
Loss at iteration 770 : 0.02389877662062645
Loss at iteration 780 : 0.02103503793478012
Loss at iteration 790 : 0.022836003452539444
Loss at iteration 800 : 0.05447934567928314
Loss at iteration 810 : 0.03151094913482666
Loss at iteration 820 : 0.01830805465579033
Loss at iteration 830 : 0.01256200298666954
Loss at iteration 840 : 0.02081042341887951
Loss at iteration 850 : 0.03886103257536888
Loss at iteration 860 : 0.014906318858265877
Loss at iteration 870 : 0.02820916473865509
Loss at iteration 880 : 0.015334134921431541
Loss at iteration 890 : 0.016068793833255768
Loss at iteration 900 : 0.014783204533159733
Loss at iteration 910 : 0.021980050951242447
Loss at iteration 920 : 0.029844287782907486
Loss at iteration 930 : 0.017464954406023026
Loss at iteration 940 : 0.012146987020969391
Loss at iteration 950 : 0.020915023982524872
Loss at iteration 960 : 0.03525495156645775
Loss at iteration 970 : 0.02025555819272995
Loss at iteration 980 : 0.01597568951547146
Loss at iteration 990 : 0.025569867342710495
Loss at iteration 1000 : 0.01863095536828041
Loss at iteration 1010 : 0.013147974386811256
Loss at iteration 1020 : 0.025913473218679428
Loss at iteration 1030 : 0.01846189796924591
Loss at iteration 1040 : 0.013576027005910873
Loss at iteration 1050 : 0.0194761510938406
Loss at iteration 1060 : 0.01609690487384796
Loss at iteration 1070 : 0.009712880477309227
Loss at iteration 1080 : 0.009605182334780693
Loss at iteration 1090 : 0.016071226447820663
Loss at iteration 1100 : 0.020654333755373955
Loss at iteration 1110 : 0.017752885818481445
Loss at iteration 1120 : 0.014564624056220055
Loss at iteration 1130 : 0.019676703959703445
Loss at iteration 1140 : 0.03143972158432007
Loss at iteration 1150 : 0.019009284675121307
Loss at iteration 1160 : 0.020428700372576714
Loss at iteration 1170 : 0.02011013962328434
Loss at iteration 1180 : 0.019082963466644287
Loss at iteration 1190 : 0.033758580684661865
Loss at iteration 1200 : 0.022605348378419876
Loss at iteration 1210 : 0.016943830996751785
The SSIM Value is: 0.7881951530774435
The PSNR Value is: 17.840096028645835
the epoch is: 86
Loss at iteration 10 : 0.02690824121236801
Loss at iteration 20 : 0.014823129400610924
Loss at iteration 30 : 0.023762725293636322
Loss at iteration 40 : 0.01734384521842003
Loss at iteration 50 : 0.021323619410395622
Loss at iteration 60 : 0.02060738205909729
Loss at iteration 70 : 0.013953021727502346
Loss at iteration 80 : 0.01727261021733284
Loss at iteration 90 : 0.023478003218770027
Loss at iteration 100 : 0.019043557345867157
Loss at iteration 110 : 0.0248547475785017
Loss at iteration 120 : 0.018149390816688538
Loss at iteration 130 : 0.01992574892938137
Loss at iteration 140 : 0.02902473881840706
Loss at iteration 150 : 0.019387291744351387
Loss at iteration 160 : 0.02324276603758335
Loss at iteration 170 : 0.021722672507166862
Loss at iteration 180 : 0.020430877804756165
Loss at iteration 190 : 0.014453630894422531
Loss at iteration 200 : 0.024870015680789948
Loss at iteration 210 : 0.012470534071326256
Loss at iteration 220 : 0.02238130196928978
Loss at iteration 230 : 0.01693945750594139
Loss at iteration 240 : 0.013052338734269142
Loss at iteration 250 : 0.018188564106822014
Loss at iteration 260 : 0.016748689115047455
Loss at iteration 270 : 0.017569368705153465
Loss at iteration 280 : 0.02007889747619629
Loss at iteration 290 : 0.026377663016319275
Loss at iteration 300 : 0.017446346580982208
Loss at iteration 310 : 0.021472983062267303
Loss at iteration 320 : 0.016165100038051605
Loss at iteration 330 : 0.017093608155846596
Loss at iteration 340 : 0.014666235074400902
Loss at iteration 350 : 0.01707807369530201
Loss at iteration 360 : 0.01738627627491951
Loss at iteration 370 : 0.029461823403835297
Loss at iteration 380 : 0.02559351548552513
Loss at iteration 390 : 0.015699055045843124
Loss at iteration 400 : 0.015636155381798744
Loss at iteration 410 : 0.024210136383771896
Loss at iteration 420 : 0.029111433774232864
Loss at iteration 430 : 0.028665713965892792
Loss at iteration 440 : 0.016544951125979424
Loss at iteration 450 : 0.02170674502849579
Loss at iteration 460 : 0.0226103737950325
Loss at iteration 470 : 0.015100209042429924
Loss at iteration 480 : 0.023318247869610786
Loss at iteration 490 : 0.0167924165725708
Loss at iteration 500 : 0.0223411712795496
Loss at iteration 510 : 0.016527269035577774
Loss at iteration 520 : 0.027405109256505966
Loss at iteration 530 : 0.014193073846399784
Loss at iteration 540 : 0.016349390149116516
Loss at iteration 550 : 0.033078886568546295
Loss at iteration 560 : 0.018966108560562134
Loss at iteration 570 : 0.04146774858236313
Loss at iteration 580 : 0.01702394336462021
Loss at iteration 590 : 0.02606559544801712
Loss at iteration 600 : 0.010602466762065887
Loss at iteration 610 : 0.020895855501294136
Loss at iteration 620 : 0.028295785188674927
Loss at iteration 630 : 0.03133569657802582
Loss at iteration 640 : 0.025634516030550003
Loss at iteration 650 : 0.013859381899237633
Loss at iteration 660 : 0.013814805075526237
Loss at iteration 670 : 0.02075253240764141
Loss at iteration 680 : 0.01689489558339119
Loss at iteration 690 : 0.019964413717389107
Loss at iteration 700 : 0.020190980285406113
Loss at iteration 710 : 0.02247307449579239
Loss at iteration 720 : 0.021468451246619225
Loss at iteration 730 : 0.017717938870191574
Loss at iteration 740 : 0.01799701154232025
Loss at iteration 750 : 0.01419966109097004
Loss at iteration 760 : 0.0235569030046463
Loss at iteration 770 : 0.027700170874595642
Loss at iteration 780 : 0.013293193653225899
Loss at iteration 790 : 0.010275444015860558
Loss at iteration 800 : 0.0216111671179533
Loss at iteration 810 : 0.019103314727544785
Loss at iteration 820 : 0.020450154319405556
Loss at iteration 830 : 0.015087849460542202
Loss at iteration 840 : 0.013732032850384712
Loss at iteration 850 : 0.030464675277471542
Loss at iteration 860 : 0.017279163002967834
Loss at iteration 870 : 0.016893580555915833
Loss at iteration 880 : 0.03421587496995926
Loss at iteration 890 : 0.013740509748458862
Loss at iteration 900 : 0.01916830986738205
Loss at iteration 910 : 0.02616245299577713
Loss at iteration 920 : 0.01729620061814785
Loss at iteration 930 : 0.027246493846178055
Loss at iteration 940 : 0.017576515674591064
Loss at iteration 950 : 0.023555602878332138
Loss at iteration 960 : 0.03530044108629227
Loss at iteration 970 : 0.0165486391633749
Loss at iteration 980 : 0.018863726407289505
Loss at iteration 990 : 0.02257058396935463
Loss at iteration 1000 : 0.023234624415636063
Loss at iteration 1010 : 0.020542865619063377
Loss at iteration 1020 : 0.016424160450696945
Loss at iteration 1030 : 0.013605205342173576
Loss at iteration 1040 : 0.040438637137413025
Loss at iteration 1050 : 0.01632928103208542
Loss at iteration 1060 : 0.019615083932876587
Loss at iteration 1070 : 0.0396362766623497
Loss at iteration 1080 : 0.022484099492430687
Loss at iteration 1090 : 0.0196689385920763
Loss at iteration 1100 : 0.025353696197271347
Loss at iteration 1110 : 0.015455390326678753
Loss at iteration 1120 : 0.016870245337486267
Loss at iteration 1130 : 0.031472768634557724
Loss at iteration 1140 : 0.025625688955187798
Loss at iteration 1150 : 0.018630575388669968
Loss at iteration 1160 : 0.016550157219171524
Loss at iteration 1170 : 0.010251447558403015
Loss at iteration 1180 : 0.016446996480226517
Loss at iteration 1190 : 0.03115753084421158
Loss at iteration 1200 : 0.021633083000779152
Loss at iteration 1210 : 0.02553250640630722
The SSIM Value is: 0.7943726619084676
The PSNR Value is: 19.690413411458334
the epoch is: 87
Loss at iteration 10 : 0.02369602397084236
Loss at iteration 20 : 0.023754794150590897
Loss at iteration 30 : 0.037637874484062195
Loss at iteration 40 : 0.02849859558045864
Loss at iteration 50 : 0.013303551822900772
Loss at iteration 60 : 0.02376345545053482
Loss at iteration 70 : 0.021534036844968796
Loss at iteration 80 : 0.0191044881939888
Loss at iteration 90 : 0.025812873616814613
Loss at iteration 100 : 0.028372395783662796
Loss at iteration 110 : 0.04142798110842705
Loss at iteration 120 : 0.024017540737986565
Loss at iteration 130 : 0.019153736531734467
Loss at iteration 140 : 0.01694537326693535
Loss at iteration 150 : 0.02029709704220295
Loss at iteration 160 : 0.026753028854727745
Loss at iteration 170 : 0.029990140348672867
Loss at iteration 180 : 0.012826018035411835
Loss at iteration 190 : 0.018180813640356064
Loss at iteration 200 : 0.02028537727892399
Loss at iteration 210 : 0.01730162277817726
Loss at iteration 220 : 0.011257462203502655
Loss at iteration 230 : 0.02520761638879776
Loss at iteration 240 : 0.018824253231287003
Loss at iteration 250 : 0.02076631411910057
Loss at iteration 260 : 0.020613085478544235
Loss at iteration 270 : 0.01455506682395935
Loss at iteration 280 : 0.016088172793388367
Loss at iteration 290 : 0.033575449138879776
Loss at iteration 300 : 0.020024295896291733
Loss at iteration 310 : 0.03262364864349365
Loss at iteration 320 : 0.02029157616198063
Loss at iteration 330 : 0.020080307498574257
Loss at iteration 340 : 0.017184078693389893
Loss at iteration 350 : 0.01830170676112175
Loss at iteration 360 : 0.022727174684405327
Loss at iteration 370 : 0.02428506501019001
Loss at iteration 380 : 0.01696661487221718
Loss at iteration 390 : 0.0312044620513916
Loss at iteration 400 : 0.026264160871505737
Loss at iteration 410 : 0.035406649112701416
Loss at iteration 420 : 0.025118615478277206
Loss at iteration 430 : 0.01857616752386093
Loss at iteration 440 : 0.017261970788240433
Loss at iteration 450 : 0.012480216100811958
Loss at iteration 460 : 0.018644772469997406
Loss at iteration 470 : 0.01417229138314724
Loss at iteration 480 : 0.013905096799135208
Loss at iteration 490 : 0.02880631573498249
Loss at iteration 500 : 0.022143322974443436
Loss at iteration 510 : 0.03032706305384636
Loss at iteration 520 : 0.02382415160536766
Loss at iteration 530 : 0.012821732088923454
Loss at iteration 540 : 0.022245772182941437
Loss at iteration 550 : 0.037613775581121445
Loss at iteration 560 : 0.019637029618024826
Loss at iteration 570 : 0.01848515309393406
Loss at iteration 580 : 0.015131146647036076
Loss at iteration 590 : 0.013058053329586983
Loss at iteration 600 : 0.014108709990978241
Loss at iteration 610 : 0.02086527831852436
Loss at iteration 620 : 0.02023632638156414
Loss at iteration 630 : 0.028721941635012627
Loss at iteration 640 : 0.03311309590935707
Loss at iteration 650 : 0.02165576070547104
Loss at iteration 660 : 0.016454439610242844
Loss at iteration 670 : 0.019793909043073654
Loss at iteration 680 : 0.019907904788851738
Loss at iteration 690 : 0.018988659605383873
Loss at iteration 700 : 0.026897763833403587
Loss at iteration 710 : 0.01570807211101055
Loss at iteration 720 : 0.01355782337486744
Loss at iteration 730 : 0.02284584380686283
Loss at iteration 740 : 0.025135280564427376
Loss at iteration 750 : 0.014811504632234573
Loss at iteration 760 : 0.019763028249144554
Loss at iteration 770 : 0.022099096328020096
Loss at iteration 780 : 0.029487792402505875
Loss at iteration 790 : 0.017027059569954872
Loss at iteration 800 : 0.020631305873394012
Loss at iteration 810 : 0.01877874881029129
Loss at iteration 820 : 0.02462194114923477
Loss at iteration 830 : 0.018904749304056168
Loss at iteration 840 : 0.018338553607463837
Loss at iteration 850 : 0.022061698138713837
Loss at iteration 860 : 0.021219298243522644
Loss at iteration 870 : 0.023711197078227997
Loss at iteration 880 : 0.01982177048921585
Loss at iteration 890 : 0.017186176031827927
Loss at iteration 900 : 0.015653658658266068
Loss at iteration 910 : 0.042139604687690735
Loss at iteration 920 : 0.022115767002105713
Loss at iteration 930 : 0.016956910490989685
Loss at iteration 940 : 0.02393287606537342
Loss at iteration 950 : 0.025459982454776764
Loss at iteration 960 : 0.03832816332578659
Loss at iteration 970 : 0.020481083542108536
Loss at iteration 980 : 0.019421543926000595
Loss at iteration 990 : 0.02159343846142292
Loss at iteration 1000 : 0.010155033320188522
Loss at iteration 1010 : 0.014284486882388592
Loss at iteration 1020 : 0.027494389563798904
Loss at iteration 1030 : 0.02094695344567299
Loss at iteration 1040 : 0.023878855630755424
Loss at iteration 1050 : 0.01682317443192005
Loss at iteration 1060 : 0.01949458010494709
Loss at iteration 1070 : 0.02819918468594551
Loss at iteration 1080 : 0.014810603111982346
Loss at iteration 1090 : 0.02853631041944027
Loss at iteration 1100 : 0.021862830966711044
Loss at iteration 1110 : 0.022283144295215607
Loss at iteration 1120 : 0.014389374293386936
Loss at iteration 1130 : 0.025789722800254822
Loss at iteration 1140 : 0.02625739574432373
Loss at iteration 1150 : 0.011850995942950249
Loss at iteration 1160 : 0.021528907120227814
Loss at iteration 1170 : 0.01656421832740307
Loss at iteration 1180 : 0.021985653787851334
Loss at iteration 1190 : 0.021361103281378746
Loss at iteration 1200 : 0.014748511835932732
Loss at iteration 1210 : 0.011785771697759628
The SSIM Value is: 0.7972509066263834
The PSNR Value is: 19.30167293548584
the epoch is: 88
Loss at iteration 10 : 0.018641045317053795
Loss at iteration 20 : 0.011939335614442825
Loss at iteration 30 : 0.015655217692255974
Loss at iteration 40 : 0.03688632696866989
Loss at iteration 50 : 0.012622497044503689
Loss at iteration 60 : 0.017279746010899544
Loss at iteration 70 : 0.015809383243322372
Loss at iteration 80 : 0.02356002852320671
Loss at iteration 90 : 0.01594816893339157
Loss at iteration 100 : 0.02469651773571968
Loss at iteration 110 : 0.011095473542809486
Loss at iteration 120 : 0.02571292594075203
Loss at iteration 130 : 0.021631231531500816
Loss at iteration 140 : 0.017085567116737366
Loss at iteration 150 : 0.026521937921643257
Loss at iteration 160 : 0.030091308057308197
Loss at iteration 170 : 0.02387417107820511
Loss at iteration 180 : 0.02366626262664795
Loss at iteration 190 : 0.020573008805513382
Loss at iteration 200 : 0.0183290783315897
Loss at iteration 210 : 0.010789282619953156
Loss at iteration 220 : 0.012723613530397415
Loss at iteration 230 : 0.04545467346906662
Loss at iteration 240 : 0.027484117075800896
Loss at iteration 250 : 0.015872569754719734
Loss at iteration 260 : 0.029591672122478485
Loss at iteration 270 : 0.022954994812607765
Loss at iteration 280 : 0.020111117511987686
Loss at iteration 290 : 0.02841782569885254
Loss at iteration 300 : 0.020030422136187553
Loss at iteration 310 : 0.014345657080411911
Loss at iteration 320 : 0.01736241951584816
Loss at iteration 330 : 0.0159987211227417
Loss at iteration 340 : 0.02277400530874729
Loss at iteration 350 : 0.018376659601926804
Loss at iteration 360 : 0.029237069189548492
Loss at iteration 370 : 0.022732317447662354
Loss at iteration 380 : 0.030258871614933014
Loss at iteration 390 : 0.010330798104405403
Loss at iteration 400 : 0.022163696587085724
Loss at iteration 410 : 0.02501477114856243
Loss at iteration 420 : 0.026328377425670624
Loss at iteration 430 : 0.021709710359573364
Loss at iteration 440 : 0.03070315718650818
Loss at iteration 450 : 0.022808682173490524
Loss at iteration 460 : 0.040283046662807465
Loss at iteration 470 : 0.01770051009953022
Loss at iteration 480 : 0.012666406109929085
Loss at iteration 490 : 0.020758777856826782
Loss at iteration 500 : 0.02442673221230507
Loss at iteration 510 : 0.024876592680811882
Loss at iteration 520 : 0.025469981133937836
Loss at iteration 530 : 0.01894371584057808
Loss at iteration 540 : 0.02521715685725212
Loss at iteration 550 : 0.017687596380710602
Loss at iteration 560 : 0.014358220621943474
Loss at iteration 570 : 0.0355963334441185
Loss at iteration 580 : 0.020671717822551727
Loss at iteration 590 : 0.016959186643362045
Loss at iteration 600 : 0.01770389825105667
Loss at iteration 610 : 0.01707712560892105
Loss at iteration 620 : 0.03065044805407524
Loss at iteration 630 : 0.020000524818897247
Loss at iteration 640 : 0.023994965478777885
Loss at iteration 650 : 0.02539312094449997
Loss at iteration 660 : 0.013636039569973946
Loss at iteration 670 : 0.017085839062929153
Loss at iteration 680 : 0.014919912442564964
Loss at iteration 690 : 0.010336462408304214
Loss at iteration 700 : 0.025259822607040405
Loss at iteration 710 : 0.016116295009851456
Loss at iteration 720 : 0.015988219529390335
Loss at iteration 730 : 0.02905258722603321
Loss at iteration 740 : 0.021487701684236526
Loss at iteration 750 : 0.022879205644130707
Loss at iteration 760 : 0.01833387464284897
Loss at iteration 770 : 0.016747023910284042
Loss at iteration 780 : 0.026921819895505905
Loss at iteration 790 : 0.028782352805137634
Loss at iteration 800 : 0.02723846398293972
Loss at iteration 810 : 0.03665638715028763
Loss at iteration 820 : 0.0266225878149271
Loss at iteration 830 : 0.024376682937145233
Loss at iteration 840 : 0.03343378007411957
Loss at iteration 850 : 0.014204374514520168
Loss at iteration 860 : 0.020472843199968338
Loss at iteration 870 : 0.03437661752104759
Loss at iteration 880 : 0.028303194791078568
Loss at iteration 890 : 0.02174517698585987
Loss at iteration 900 : 0.03225184604525566
Loss at iteration 910 : 0.02343049645423889
Loss at iteration 920 : 0.01596662774682045
Loss at iteration 930 : 0.02737991139292717
Loss at iteration 940 : 0.02144548110663891
Loss at iteration 950 : 0.015244176611304283
Loss at iteration 960 : 0.023486357182264328
Loss at iteration 970 : 0.021522747352719307
Loss at iteration 980 : 0.015700604766607285
Loss at iteration 990 : 0.015271589159965515
Loss at iteration 1000 : 0.017650973051786423
Loss at iteration 1010 : 0.02127799391746521
Loss at iteration 1020 : 0.017429590225219727
Loss at iteration 1030 : 0.014894824475049973
Loss at iteration 1040 : 0.016896404325962067
Loss at iteration 1050 : 0.03830491006374359
Loss at iteration 1060 : 0.022080007940530777
Loss at iteration 1070 : 0.021727655082941055
Loss at iteration 1080 : 0.016648203134536743
Loss at iteration 1090 : 0.017568105831742287
Loss at iteration 1100 : 0.019600287079811096
Loss at iteration 1110 : 0.012119968421757221
Loss at iteration 1120 : 0.015546351671218872
Loss at iteration 1130 : 0.022190647199749947
Loss at iteration 1140 : 0.02033020555973053
Loss at iteration 1150 : 0.02740485593676567
Loss at iteration 1160 : 0.01527193933725357
Loss at iteration 1170 : 0.015113148838281631
Loss at iteration 1180 : 0.012769647873938084
Loss at iteration 1190 : 0.02296493947505951
Loss at iteration 1200 : 0.013544882647693157
Loss at iteration 1210 : 0.02709745056927204
The SSIM Value is: 0.7837870677312215
The PSNR Value is: 17.725447146097817
the epoch is: 89
Loss at iteration 10 : 0.024018023163080215
Loss at iteration 20 : 0.017170215025544167
Loss at iteration 30 : 0.017628226429224014
Loss at iteration 40 : 0.01025774423032999
Loss at iteration 50 : 0.016151653602719307
Loss at iteration 60 : 0.024500936269760132
Loss at iteration 70 : 0.02324204333126545
Loss at iteration 80 : 0.013665158301591873
Loss at iteration 90 : 0.015226507559418678
Loss at iteration 100 : 0.012517813593149185
Loss at iteration 110 : 0.031100094318389893
Loss at iteration 120 : 0.019705967977643013
Loss at iteration 130 : 0.018290089443325996
Loss at iteration 140 : 0.019247308373451233
Loss at iteration 150 : 0.02458556368947029
Loss at iteration 160 : 0.011009068228304386
Loss at iteration 170 : 0.025017451494932175
Loss at iteration 180 : 0.01431999821215868
Loss at iteration 190 : 0.020430032163858414
Loss at iteration 200 : 0.023141968995332718
Loss at iteration 210 : 0.014192966744303703
Loss at iteration 220 : 0.013125243596732616
Loss at iteration 230 : 0.03358834609389305
Loss at iteration 240 : 0.02230975031852722
Loss at iteration 250 : 0.016649551689624786
Loss at iteration 260 : 0.03538578748703003
Loss at iteration 270 : 0.020077867433428764
Loss at iteration 280 : 0.03291979432106018
Loss at iteration 290 : 0.018689487129449844
Loss at iteration 300 : 0.0187752116471529
Loss at iteration 310 : 0.01725010946393013
Loss at iteration 320 : 0.026867859065532684
Loss at iteration 330 : 0.01769757829606533
Loss at iteration 340 : 0.024575818330049515
Loss at iteration 350 : 0.023008856922388077
Loss at iteration 360 : 0.01716092973947525
Loss at iteration 370 : 0.021916966885328293
Loss at iteration 380 : 0.0184631384909153
Loss at iteration 390 : 0.021364502608776093
Loss at iteration 400 : 0.019069384783506393
Loss at iteration 410 : 0.028908617794513702
Loss at iteration 420 : 0.025563780218362808
Loss at iteration 430 : 0.015671443194150925
Loss at iteration 440 : 0.01578744314610958
Loss at iteration 450 : 0.016791129484772682
Loss at iteration 460 : 0.024964507669210434
Loss at iteration 470 : 0.028747376054525375
Loss at iteration 480 : 0.014536711387336254
Loss at iteration 490 : 0.016281675547361374
Loss at iteration 500 : 0.009872142225503922
Loss at iteration 510 : 0.016146481037139893
Loss at iteration 520 : 0.021635480225086212
Loss at iteration 530 : 0.0324876569211483
Loss at iteration 540 : 0.02304195985198021
Loss at iteration 550 : 0.01144460216164589
Loss at iteration 560 : 0.018534408882260323
Loss at iteration 570 : 0.018352877348661423
Loss at iteration 580 : 0.021555524319410324
Loss at iteration 590 : 0.016227448359131813
Loss at iteration 600 : 0.036918580532073975
Loss at iteration 610 : 0.01834537461400032
Loss at iteration 620 : 0.018405992537736893
Loss at iteration 630 : 0.023517882451415062
Loss at iteration 640 : 0.024757301434874535
Loss at iteration 650 : 0.020083464682102203
Loss at iteration 660 : 0.014011760242283344
Loss at iteration 670 : 0.018642712384462357
Loss at iteration 680 : 0.022371895611286163
Loss at iteration 690 : 0.01693800278007984
Loss at iteration 700 : 0.01780788227915764
Loss at iteration 710 : 0.013187920674681664
Loss at iteration 720 : 0.02437494695186615
Loss at iteration 730 : 0.017803747206926346
Loss at iteration 740 : 0.016915369778871536
Loss at iteration 750 : 0.027478912845253944
Loss at iteration 760 : 0.02805444598197937
Loss at iteration 770 : 0.03498145937919617
Loss at iteration 780 : 0.012953966856002808
Loss at iteration 790 : 0.012773804366588593
Loss at iteration 800 : 0.02570035494863987
Loss at iteration 810 : 0.02629849687218666
Loss at iteration 820 : 0.031991153955459595
Loss at iteration 830 : 0.01611451618373394
Loss at iteration 840 : 0.02079097181558609
Loss at iteration 850 : 0.015035081654787064
Loss at iteration 860 : 0.02198949083685875
Loss at iteration 870 : 0.017242206260561943
Loss at iteration 880 : 0.029170619323849678
Loss at iteration 890 : 0.040797099471092224
Loss at iteration 900 : 0.02215859666466713
Loss at iteration 910 : 0.0261063314974308
Loss at iteration 920 : 0.0177324078977108
Loss at iteration 930 : 0.021754762157797813
Loss at iteration 940 : 0.02876325696706772
Loss at iteration 950 : 0.03343275934457779
Loss at iteration 960 : 0.01885724626481533
Loss at iteration 970 : 0.02023369073867798
Loss at iteration 980 : 0.020138563588261604
Loss at iteration 990 : 0.01640419475734234
Loss at iteration 1000 : 0.021946750581264496
Loss at iteration 1010 : 0.022057432681322098
Loss at iteration 1020 : 0.015459658578038216
Loss at iteration 1030 : 0.014934543520212173
Loss at iteration 1040 : 0.029115751385688782
Loss at iteration 1050 : 0.020371614024043083
Loss at iteration 1060 : 0.01728232204914093
Loss at iteration 1070 : 0.01729019358754158
Loss at iteration 1080 : 0.015104754827916622
Loss at iteration 1090 : 0.014208417385816574
Loss at iteration 1100 : 0.01533212698996067
Loss at iteration 1110 : 0.024502627551555634
Loss at iteration 1120 : 0.02460295706987381
Loss at iteration 1130 : 0.026877034455537796
Loss at iteration 1140 : 0.013793823309242725
Loss at iteration 1150 : 0.016133347526192665
Loss at iteration 1160 : 0.03126566857099533
Loss at iteration 1170 : 0.023796753957867622
Loss at iteration 1180 : 0.03898397088050842
Loss at iteration 1190 : 0.014940991997718811
Loss at iteration 1200 : 0.02268137037754059
Loss at iteration 1210 : 0.03127831965684891
The SSIM Value is: 0.7880830526351928
The PSNR Value is: 17.76539961496989
the epoch is: 90
Loss at iteration 10 : 0.01773254945874214
Loss at iteration 20 : 0.016335710883140564
Loss at iteration 30 : 0.020214073359966278
Loss at iteration 40 : 0.02249222807586193
Loss at iteration 50 : 0.01435922458767891
Loss at iteration 60 : 0.015677301213145256
Loss at iteration 70 : 0.02392360009253025
Loss at iteration 80 : 0.018508123233914375
Loss at iteration 90 : 0.020098645240068436
Loss at iteration 100 : 0.01731204055249691
Loss at iteration 110 : 0.01580483838915825
Loss at iteration 120 : 0.034539103507995605
Loss at iteration 130 : 0.021360434591770172
Loss at iteration 140 : 0.018183981999754906
Loss at iteration 150 : 0.02479584328830242
Loss at iteration 160 : 0.02158989943563938
Loss at iteration 170 : 0.02291337586939335
Loss at iteration 180 : 0.01631636545062065
Loss at iteration 190 : 0.03143647313117981
Loss at iteration 200 : 0.01651480421423912
Loss at iteration 210 : 0.025605924427509308
Loss at iteration 220 : 0.01740058697760105
Loss at iteration 230 : 0.017308220267295837
Loss at iteration 240 : 0.026988903060555458
Loss at iteration 250 : 0.021471604704856873
Loss at iteration 260 : 0.019002847373485565
Loss at iteration 270 : 0.023282021284103394
Loss at iteration 280 : 0.015107018873095512
Loss at iteration 290 : 0.011205888353288174
Loss at iteration 300 : 0.02554144710302353
Loss at iteration 310 : 0.013976836577057838
Loss at iteration 320 : 0.01502067968249321
Loss at iteration 330 : 0.01683979667723179
Loss at iteration 340 : 0.0252213217318058
Loss at iteration 350 : 0.031999774277210236
Loss at iteration 360 : 0.03509695455431938
Loss at iteration 370 : 0.017067251726984978
Loss at iteration 380 : 0.029161816462874413
Loss at iteration 390 : 0.01741793379187584
Loss at iteration 400 : 0.026327451691031456
Loss at iteration 410 : 0.03180341422557831
Loss at iteration 420 : 0.021456032991409302
Loss at iteration 430 : 0.012501552700996399
Loss at iteration 440 : 0.016103027388453484
Loss at iteration 450 : 0.014958283863961697
Loss at iteration 460 : 0.016647741198539734
Loss at iteration 470 : 0.01684900000691414
Loss at iteration 480 : 0.021692104637622833
Loss at iteration 490 : 0.02239173837006092
Loss at iteration 500 : 0.020761549472808838
Loss at iteration 510 : 0.01808490790426731
Loss at iteration 520 : 0.017760496586561203
Loss at iteration 530 : 0.01719779334962368
Loss at iteration 540 : 0.016438383609056473
Loss at iteration 550 : 0.025394579395651817
Loss at iteration 560 : 0.02363666705787182
Loss at iteration 570 : 0.01808236539363861
Loss at iteration 580 : 0.01971147209405899
Loss at iteration 590 : 0.020344223827123642
Loss at iteration 600 : 0.04599810019135475
Loss at iteration 610 : 0.020677383989095688
Loss at iteration 620 : 0.035451315343379974
Loss at iteration 630 : 0.01857985556125641
Loss at iteration 640 : 0.01550334319472313
Loss at iteration 650 : 0.016212012618780136
Loss at iteration 660 : 0.014246164821088314
Loss at iteration 670 : 0.01597851887345314
Loss at iteration 680 : 0.014894381165504456
Loss at iteration 690 : 0.03614422678947449
Loss at iteration 700 : 0.016443897038698196
Loss at iteration 710 : 0.025237130001187325
Loss at iteration 720 : 0.01510971412062645
Loss at iteration 730 : 0.0184768158942461
Loss at iteration 740 : 0.01493041217327118
Loss at iteration 750 : 0.017403896898031235
Loss at iteration 760 : 0.017812984064221382
Loss at iteration 770 : 0.02300877496600151
Loss at iteration 780 : 0.028341151773929596
Loss at iteration 790 : 0.01590798795223236
Loss at iteration 800 : 0.02060631290078163
Loss at iteration 810 : 0.017793696373701096
Loss at iteration 820 : 0.034233447164297104
Loss at iteration 830 : 0.01986836828291416
Loss at iteration 840 : 0.03184761479496956
Loss at iteration 850 : 0.02539820224046707
Loss at iteration 860 : 0.010572439059615135
Loss at iteration 870 : 0.03022962063550949
Loss at iteration 880 : 0.02168181911110878
Loss at iteration 890 : 0.01901506446301937
Loss at iteration 900 : 0.015922654420137405
Loss at iteration 910 : 0.025049030780792236
Loss at iteration 920 : 0.0278977919369936
Loss at iteration 930 : 0.02567237988114357
Loss at iteration 940 : 0.022579122334718704
Loss at iteration 950 : 0.019991964101791382
Loss at iteration 960 : 0.014626109972596169
Loss at iteration 970 : 0.026566121727228165
Loss at iteration 980 : 0.015950839966535568
Loss at iteration 990 : 0.017355989664793015
Loss at iteration 1000 : 0.028593674302101135
Loss at iteration 1010 : 0.01855548471212387
Loss at iteration 1020 : 0.036062370985746384
Loss at iteration 1030 : 0.023379400372505188
Loss at iteration 1040 : 0.02193388156592846
Loss at iteration 1050 : 0.016824916005134583
Loss at iteration 1060 : 0.023361489176750183
Loss at iteration 1070 : 0.017474928870797157
Loss at iteration 1080 : 0.01256224699318409
Loss at iteration 1090 : 0.014782977290451527
Loss at iteration 1100 : 0.024356011301279068
Loss at iteration 1110 : 0.018318355083465576
Loss at iteration 1120 : 0.016291264444589615
Loss at iteration 1130 : 0.01735030487179756
Loss at iteration 1140 : 0.01591239497065544
Loss at iteration 1150 : 0.02791948802769184
Loss at iteration 1160 : 0.022072002291679382
Loss at iteration 1170 : 0.01737641543149948
Loss at iteration 1180 : 0.034968920052051544
Loss at iteration 1190 : 0.03033910132944584
Loss at iteration 1200 : 0.0203721784055233
Loss at iteration 1210 : 0.020027779042720795
The SSIM Value is: 0.7937119086583455
The PSNR Value is: 18.447622362772623
the epoch is: 91
Loss at iteration 10 : 0.019622312858700752
Loss at iteration 20 : 0.014246855862438679
Loss at iteration 30 : 0.015107238665223122
Loss at iteration 40 : 0.022740017622709274
Loss at iteration 50 : 0.04598779231309891
Loss at iteration 60 : 0.020932301878929138
Loss at iteration 70 : 0.011181719601154327
Loss at iteration 80 : 0.02574266493320465
Loss at iteration 90 : 0.022693464532494545
Loss at iteration 100 : 0.017885081470012665
Loss at iteration 110 : 0.02372588962316513
Loss at iteration 120 : 0.023634154349565506
Loss at iteration 130 : 0.027371715754270554
Loss at iteration 140 : 0.010841965675354004
Loss at iteration 150 : 0.021934136748313904
Loss at iteration 160 : 0.02241428941488266
Loss at iteration 170 : 0.024065760895609856
Loss at iteration 180 : 0.025635145604610443
Loss at iteration 190 : 0.013715687207877636
Loss at iteration 200 : 0.020630693063139915
Loss at iteration 210 : 0.020666450262069702
Loss at iteration 220 : 0.017426852136850357
Loss at iteration 230 : 0.020290831103920937
Loss at iteration 240 : 0.013810131698846817
Loss at iteration 250 : 0.02385563775897026
Loss at iteration 260 : 0.022379707545042038
Loss at iteration 270 : 0.025219572708010674
Loss at iteration 280 : 0.022731106728315353
Loss at iteration 290 : 0.012094755657017231
Loss at iteration 300 : 0.01708933711051941
Loss at iteration 310 : 0.010972599498927593
Loss at iteration 320 : 0.015994980931282043
Loss at iteration 330 : 0.02437419444322586
Loss at iteration 340 : 0.020801518112421036
Loss at iteration 350 : 0.03049992211163044
Loss at iteration 360 : 0.013969311490654945
Loss at iteration 370 : 0.016358500346541405
Loss at iteration 380 : 0.018839320167899132
Loss at iteration 390 : 0.018864719197154045
Loss at iteration 400 : 0.017342552542686462
Loss at iteration 410 : 0.013000352308154106
Loss at iteration 420 : 0.029701482504606247
Loss at iteration 430 : 0.028497595340013504
Loss at iteration 440 : 0.021045144647359848
Loss at iteration 450 : 0.022648273035883904
Loss at iteration 460 : 0.02748289704322815
Loss at iteration 470 : 0.025920072570443153
Loss at iteration 480 : 0.02135184034705162
Loss at iteration 490 : 0.02571282535791397
Loss at iteration 500 : 0.022941406816244125
Loss at iteration 510 : 0.012814201414585114
Loss at iteration 520 : 0.016478288918733597
Loss at iteration 530 : 0.023219894617795944
Loss at iteration 540 : 0.025847623124718666
Loss at iteration 550 : 0.02848951891064644
Loss at iteration 560 : 0.013405493460595608
Loss at iteration 570 : 0.016409114003181458
Loss at iteration 580 : 0.01530491840094328
Loss at iteration 590 : 0.015413990244269371
Loss at iteration 600 : 0.01795637421309948
Loss at iteration 610 : 0.02123992331326008
Loss at iteration 620 : 0.036455556750297546
Loss at iteration 630 : 0.013575472868978977
Loss at iteration 640 : 0.019094739109277725
Loss at iteration 650 : 0.022440677508711815
Loss at iteration 660 : 0.01937132328748703
Loss at iteration 670 : 0.011725137941539288
Loss at iteration 680 : 0.013736113905906677
Loss at iteration 690 : 0.016114547848701477
Loss at iteration 700 : 0.017415981739759445
Loss at iteration 710 : 0.02320609986782074
Loss at iteration 720 : 0.025394711643457413
Loss at iteration 730 : 0.018074601888656616
Loss at iteration 740 : 0.019982345402240753
Loss at iteration 750 : 0.021362528204917908
Loss at iteration 760 : 0.01725519262254238
Loss at iteration 770 : 0.0276242196559906
Loss at iteration 780 : 0.015295703895390034
Loss at iteration 790 : 0.011725765652954578
Loss at iteration 800 : 0.015969708561897278
Loss at iteration 810 : 0.022497739642858505
Loss at iteration 820 : 0.03610439598560333
Loss at iteration 830 : 0.018307194113731384
Loss at iteration 840 : 0.026350047439336777
Loss at iteration 850 : 0.026348941028118134
Loss at iteration 860 : 0.010768490843474865
Loss at iteration 870 : 0.009798025712370872
Loss at iteration 880 : 0.020967230200767517
Loss at iteration 890 : 0.022135823965072632
Loss at iteration 900 : 0.03324919566512108
Loss at iteration 910 : 0.023306604474782944
Loss at iteration 920 : 0.016957752406597137
Loss at iteration 930 : 0.019948145374655724
Loss at iteration 940 : 0.01839291676878929
Loss at iteration 950 : 0.01564820110797882
Loss at iteration 960 : 0.023253710940480232
Loss at iteration 970 : 0.02418750524520874
Loss at iteration 980 : 0.03342283144593239
Loss at iteration 990 : 0.01931815594434738
Loss at iteration 1000 : 0.023730970919132233
Loss at iteration 1010 : 0.012591450475156307
Loss at iteration 1020 : 0.023723958060145378
Loss at iteration 1030 : 0.0202013086527586
Loss at iteration 1040 : 0.019138015806674957
Loss at iteration 1050 : 0.017627600580453873
Loss at iteration 1060 : 0.028992822393774986
Loss at iteration 1070 : 0.015157509595155716
Loss at iteration 1080 : 0.01964709535241127
Loss at iteration 1090 : 0.02325325831770897
Loss at iteration 1100 : 0.021673399955034256
Loss at iteration 1110 : 0.022321214899420738
Loss at iteration 1120 : 0.018153909593820572
Loss at iteration 1130 : 0.017879433929920197
Loss at iteration 1140 : 0.012130417861044407
Loss at iteration 1150 : 0.0148012675344944
Loss at iteration 1160 : 0.019235774874687195
Loss at iteration 1170 : 0.01933952048420906
Loss at iteration 1180 : 0.027002573013305664
Loss at iteration 1190 : 0.0159082543104887
Loss at iteration 1200 : 0.013410567305982113
Loss at iteration 1210 : 0.01951131410896778
The SSIM Value is: 0.7969455718994141
The PSNR Value is: 19.954425684611003
the highest SSIM value is: 19.954425684611003
the epoch is: 92
Loss at iteration 10 : 0.023713214322924614
Loss at iteration 20 : 0.027252022176980972
Loss at iteration 30 : 0.016309484839439392
Loss at iteration 40 : 0.023538731038570404
Loss at iteration 50 : 0.02677220106124878
Loss at iteration 60 : 0.017494725063443184
Loss at iteration 70 : 0.022973377257585526
Loss at iteration 80 : 0.01605447567999363
Loss at iteration 90 : 0.016645442694425583
Loss at iteration 100 : 0.020869839936494827
Loss at iteration 110 : 0.015336996875703335
Loss at iteration 120 : 0.019726544618606567
Loss at iteration 130 : 0.015569235198199749
Loss at iteration 140 : 0.015464761294424534
Loss at iteration 150 : 0.030640430748462677
Loss at iteration 160 : 0.022929362952709198
Loss at iteration 170 : 0.037859223783016205
Loss at iteration 180 : 0.02366049773991108
Loss at iteration 190 : 0.020842064172029495
Loss at iteration 200 : 0.035554151982069016
Loss at iteration 210 : 0.014710324816405773
Loss at iteration 220 : 0.02538459002971649
Loss at iteration 230 : 0.020781388506293297
Loss at iteration 240 : 0.028293225914239883
Loss at iteration 250 : 0.013300592079758644
Loss at iteration 260 : 0.023310311138629913
Loss at iteration 270 : 0.03252892568707466
Loss at iteration 280 : 0.01817167177796364
Loss at iteration 290 : 0.037892941385507584
Loss at iteration 300 : 0.012082229368388653
Loss at iteration 310 : 0.023832878097891808
Loss at iteration 320 : 0.015859361737966537
Loss at iteration 330 : 0.020751317963004112
Loss at iteration 340 : 0.04058907926082611
Loss at iteration 350 : 0.021447796374559402
Loss at iteration 360 : 0.020746663212776184
Loss at iteration 370 : 0.019962631165981293
Loss at iteration 380 : 0.03495003655552864
Loss at iteration 390 : 0.03382400795817375
Loss at iteration 400 : 0.017964649945497513
Loss at iteration 410 : 0.01866765320301056
Loss at iteration 420 : 0.02682342380285263
Loss at iteration 430 : 0.027126438915729523
Loss at iteration 440 : 0.029245080426335335
Loss at iteration 450 : 0.025260694324970245
Loss at iteration 460 : 0.02357346937060356
Loss at iteration 470 : 0.03303084895014763
Loss at iteration 480 : 0.019429627805948257
Loss at iteration 490 : 0.02458837255835533
Loss at iteration 500 : 0.023170795291662216
Loss at iteration 510 : 0.03824852034449577
Loss at iteration 520 : 0.020817548036575317
Loss at iteration 530 : 0.017453940585255623
Loss at iteration 540 : 0.018027789890766144
Loss at iteration 550 : 0.01862194575369358
Loss at iteration 560 : 0.019473761320114136
Loss at iteration 570 : 0.012039448134601116
Loss at iteration 580 : 0.029047712683677673
Loss at iteration 590 : 0.019699443131685257
Loss at iteration 600 : 0.020566286519169807
Loss at iteration 610 : 0.023472148925065994
Loss at iteration 620 : 0.015205916948616505
Loss at iteration 630 : 0.017664894461631775
Loss at iteration 640 : 0.012169557623565197
Loss at iteration 650 : 0.01522691361606121
Loss at iteration 660 : 0.022648930549621582
Loss at iteration 670 : 0.022756505757570267
Loss at iteration 680 : 0.01445253100246191
Loss at iteration 690 : 0.028934184461832047
Loss at iteration 700 : 0.019349535927176476
Loss at iteration 710 : 0.022750766947865486
Loss at iteration 720 : 0.02375606819987297
Loss at iteration 730 : 0.018196212127804756
Loss at iteration 740 : 0.029951168224215508
Loss at iteration 750 : 0.02124720811843872
Loss at iteration 760 : 0.03363525867462158
Loss at iteration 770 : 0.023976992815732956
Loss at iteration 780 : 0.02435108833014965
Loss at iteration 790 : 0.015616828575730324
Loss at iteration 800 : 0.026763305068016052
Loss at iteration 810 : 0.008359450846910477
Loss at iteration 820 : 0.019810859113931656
Loss at iteration 830 : 0.028632180765271187
Loss at iteration 840 : 0.025867026299238205
Loss at iteration 850 : 0.015791064128279686
Loss at iteration 860 : 0.03546980395913124
Loss at iteration 870 : 0.020165221765637398
Loss at iteration 880 : 0.01105697825551033
Loss at iteration 890 : 0.01903240568935871
Loss at iteration 900 : 0.024220991879701614
Loss at iteration 910 : 0.025083741173148155
Loss at iteration 920 : 0.02354591339826584
Loss at iteration 930 : 0.01946340501308441
Loss at iteration 940 : 0.02365845814347267
Loss at iteration 950 : 0.017483292147517204
Loss at iteration 960 : 0.016933446750044823
Loss at iteration 970 : 0.01646408438682556
Loss at iteration 980 : 0.020342811942100525
Loss at iteration 990 : 0.018011923879384995
Loss at iteration 1000 : 0.020143505185842514
Loss at iteration 1010 : 0.019020089879631996
Loss at iteration 1020 : 0.012284625321626663
Loss at iteration 1030 : 0.019379818812012672
Loss at iteration 1040 : 0.02897544577717781
Loss at iteration 1050 : 0.013077117502689362
Loss at iteration 1060 : 0.02527029998600483
Loss at iteration 1070 : 0.018708422780036926
Loss at iteration 1080 : 0.013619567267596722
Loss at iteration 1090 : 0.018468566238880157
Loss at iteration 1100 : 0.023821350187063217
Loss at iteration 1110 : 0.02522176131606102
Loss at iteration 1120 : 0.014945849776268005
Loss at iteration 1130 : 0.010042420588433743
Loss at iteration 1140 : 0.018312949687242508
Loss at iteration 1150 : 0.014361878857016563
Loss at iteration 1160 : 0.019723953679203987
Loss at iteration 1170 : 0.015777993947267532
Loss at iteration 1180 : 0.02718282677233219
Loss at iteration 1190 : 0.02878653258085251
Loss at iteration 1200 : 0.025545265525579453
Loss at iteration 1210 : 0.023383023217320442
The SSIM Value is: 0.789125406742096
The PSNR Value is: 18.25016492207845
the epoch is: 93
Loss at iteration 10 : 0.014763683080673218
Loss at iteration 20 : 0.023923635482788086
Loss at iteration 30 : 0.019325897097587585
Loss at iteration 40 : 0.018697865307331085
Loss at iteration 50 : 0.012742721475660801
Loss at iteration 60 : 0.029204390943050385
Loss at iteration 70 : 0.025728456676006317
Loss at iteration 80 : 0.020736657083034515
Loss at iteration 90 : 0.01470337063074112
Loss at iteration 100 : 0.019099831581115723
Loss at iteration 110 : 0.02307581715285778
Loss at iteration 120 : 0.019447356462478638
Loss at iteration 130 : 0.021584032103419304
Loss at iteration 140 : 0.0246402770280838
Loss at iteration 150 : 0.02725825645029545
Loss at iteration 160 : 0.02306857891380787
Loss at iteration 170 : 0.02240113914012909
Loss at iteration 180 : 0.02904573827981949
Loss at iteration 190 : 0.03191373497247696
Loss at iteration 200 : 0.01846017688512802
Loss at iteration 210 : 0.023113159462809563
Loss at iteration 220 : 0.01643715426325798
Loss at iteration 230 : 0.020966943353414536
Loss at iteration 240 : 0.01837882399559021
Loss at iteration 250 : 0.02564329095184803
Loss at iteration 260 : 0.017047153785824776
Loss at iteration 270 : 0.02745044231414795
Loss at iteration 280 : 0.022197028622031212
Loss at iteration 290 : 0.02744446136057377
Loss at iteration 300 : 0.017579037696123123
Loss at iteration 310 : 0.03732762858271599
Loss at iteration 320 : 0.03248974680900574
Loss at iteration 330 : 0.014489531517028809
Loss at iteration 340 : 0.02529948204755783
Loss at iteration 350 : 0.027268871665000916
Loss at iteration 360 : 0.020713385194540024
Loss at iteration 370 : 0.023638905957341194
Loss at iteration 380 : 0.021226275712251663
Loss at iteration 390 : 0.011401809751987457
Loss at iteration 400 : 0.025623150169849396
Loss at iteration 410 : 0.03660484403371811
Loss at iteration 420 : 0.024207044392824173
Loss at iteration 430 : 0.023050371557474136
Loss at iteration 440 : 0.019718626514077187
Loss at iteration 450 : 0.012073076330125332
Loss at iteration 460 : 0.014085264876484871
Loss at iteration 470 : 0.026639902964234352
Loss at iteration 480 : 0.018260197713971138
Loss at iteration 490 : 0.021760640665888786
Loss at iteration 500 : 0.025977060198783875
Loss at iteration 510 : 0.017698606476187706
Loss at iteration 520 : 0.030670661479234695
Loss at iteration 530 : 0.026494890451431274
Loss at iteration 540 : 0.01981382444500923
Loss at iteration 550 : 0.04288017004728317
Loss at iteration 560 : 0.0162663571536541
Loss at iteration 570 : 0.02444951981306076
Loss at iteration 580 : 0.01487212534993887
Loss at iteration 590 : 0.02738366834819317
Loss at iteration 600 : 0.017006266862154007
Loss at iteration 610 : 0.014013220556080341
Loss at iteration 620 : 0.01590810716152191
Loss at iteration 630 : 0.012831797823309898
Loss at iteration 640 : 0.02660309337079525
Loss at iteration 650 : 0.014528155326843262
Loss at iteration 660 : 0.01526398304849863
Loss at iteration 670 : 0.02217167615890503
Loss at iteration 680 : 0.014980131760239601
Loss at iteration 690 : 0.020277146250009537
Loss at iteration 700 : 0.013179700821638107
Loss at iteration 710 : 0.030582569539546967
Loss at iteration 720 : 0.026781916618347168
Loss at iteration 730 : 0.014626793563365936
Loss at iteration 740 : 0.014958428218960762
Loss at iteration 750 : 0.026531191542744637
Loss at iteration 760 : 0.026360703632235527
Loss at iteration 770 : 0.02290426567196846
Loss at iteration 780 : 0.02600424364209175
Loss at iteration 790 : 0.021600814536213875
Loss at iteration 800 : 0.034990232437849045
Loss at iteration 810 : 0.017933879047632217
Loss at iteration 820 : 0.021251201629638672
Loss at iteration 830 : 0.018514424562454224
Loss at iteration 840 : 0.021797355264425278
Loss at iteration 850 : 0.017157934606075287
Loss at iteration 860 : 0.029230887070298195
Loss at iteration 870 : 0.02812511846423149
Loss at iteration 880 : 0.02851574309170246
Loss at iteration 890 : 0.022663693875074387
Loss at iteration 900 : 0.02599272131919861
Loss at iteration 910 : 0.022149253636598587
Loss at iteration 920 : 0.02503354847431183
Loss at iteration 930 : 0.02653549611568451
Loss at iteration 940 : 0.018009543418884277
Loss at iteration 950 : 0.02061443030834198
Loss at iteration 960 : 0.025915488600730896
Loss at iteration 970 : 0.020399902015924454
Loss at iteration 980 : 0.02836073748767376
Loss at iteration 990 : 0.030172772705554962
Loss at iteration 1000 : 0.02110370248556137
Loss at iteration 1010 : 0.016676921397447586
Loss at iteration 1020 : 0.032205980271101
Loss at iteration 1030 : 0.015116194263100624
Loss at iteration 1040 : 0.019801661372184753
Loss at iteration 1050 : 0.017344914376735687
Loss at iteration 1060 : 0.01659569889307022
Loss at iteration 1070 : 0.014126197434961796
Loss at iteration 1080 : 0.0163213312625885
Loss at iteration 1090 : 0.01910838857293129
Loss at iteration 1100 : 0.021419689059257507
Loss at iteration 1110 : 0.01377280242741108
Loss at iteration 1120 : 0.022769883275032043
Loss at iteration 1130 : 0.01653582789003849
Loss at iteration 1140 : 0.029608916491270065
Loss at iteration 1150 : 0.019636094570159912
Loss at iteration 1160 : 0.013796750456094742
Loss at iteration 1170 : 0.023937519639730453
Loss at iteration 1180 : 0.015362337231636047
Loss at iteration 1190 : 0.031991247087717056
Loss at iteration 1200 : 0.048793159425258636
Loss at iteration 1210 : 0.015318311750888824
The SSIM Value is: 0.8028902649879456
The PSNR Value is: 19.32470048268636
the epoch is: 94
Loss at iteration 10 : 0.01580343209207058
Loss at iteration 20 : 0.014692260883748531
Loss at iteration 30 : 0.023378340527415276
Loss at iteration 40 : 0.023050939664244652
Loss at iteration 50 : 0.024960413575172424
Loss at iteration 60 : 0.01618131622672081
Loss at iteration 70 : 0.0230927262455225
Loss at iteration 80 : 0.012432853691279888
Loss at iteration 90 : 0.03107203170657158
Loss at iteration 100 : 0.014193584211170673
Loss at iteration 110 : 0.01879182457923889
Loss at iteration 120 : 0.03500596806406975
Loss at iteration 130 : 0.040621522814035416
Loss at iteration 140 : 0.02227674424648285
Loss at iteration 150 : 0.02540970966219902
Loss at iteration 160 : 0.029454480856657028
Loss at iteration 170 : 0.016326315701007843
Loss at iteration 180 : 0.024803508073091507
Loss at iteration 190 : 0.02665242925286293
Loss at iteration 200 : 0.014765068888664246
Loss at iteration 210 : 0.036366648972034454
Loss at iteration 220 : 0.018657121807336807
Loss at iteration 230 : 0.033643756061792374
Loss at iteration 240 : 0.015313806012272835
Loss at iteration 250 : 0.01905977539718151
Loss at iteration 260 : 0.026297513395547867
Loss at iteration 270 : 0.023805560544133186
Loss at iteration 280 : 0.024413060396909714
Loss at iteration 290 : 0.02073984034359455
Loss at iteration 300 : 0.01719440333545208
Loss at iteration 310 : 0.008674653246998787
Loss at iteration 320 : 0.02284933440387249
Loss at iteration 330 : 0.01995570957660675
Loss at iteration 340 : 0.013864710927009583
Loss at iteration 350 : 0.011311020702123642
Loss at iteration 360 : 0.019665971398353577
Loss at iteration 370 : 0.01822662726044655
Loss at iteration 380 : 0.015134922228753567
Loss at iteration 390 : 0.024788903072476387
Loss at iteration 400 : 0.026083657518029213
Loss at iteration 410 : 0.024081919342279434
Loss at iteration 420 : 0.026893267408013344
Loss at iteration 430 : 0.012971028685569763
Loss at iteration 440 : 0.02891940250992775
Loss at iteration 450 : 0.020804543048143387
Loss at iteration 460 : 0.025645915418863297
Loss at iteration 470 : 0.03582300990819931
Loss at iteration 480 : 0.01990528032183647
Loss at iteration 490 : 0.019304515793919563
Loss at iteration 500 : 0.027789581567049026
Loss at iteration 510 : 0.018656965345144272
Loss at iteration 520 : 0.017474791035056114
Loss at iteration 530 : 0.01872231252491474
Loss at iteration 540 : 0.025210971012711525
Loss at iteration 550 : 0.025622613728046417
Loss at iteration 560 : 0.019351713359355927
Loss at iteration 570 : 0.025601139292120934
Loss at iteration 580 : 0.02349846065044403
Loss at iteration 590 : 0.021847577765583992
Loss at iteration 600 : 0.021118778735399246
Loss at iteration 610 : 0.01740800030529499
Loss at iteration 620 : 0.01785917766392231
Loss at iteration 630 : 0.025828134268522263
Loss at iteration 640 : 0.017173748463392258
Loss at iteration 650 : 0.02412601187825203
Loss at iteration 660 : 0.02397695556282997
Loss at iteration 670 : 0.023019157350063324
Loss at iteration 680 : 0.01975291594862938
Loss at iteration 690 : 0.014527644962072372
Loss at iteration 700 : 0.020546864718198776
Loss at iteration 710 : 0.021777505055069923
Loss at iteration 720 : 0.026245873421430588
Loss at iteration 730 : 0.03388291597366333
Loss at iteration 740 : 0.019643018022179604
Loss at iteration 750 : 0.02372746914625168
Loss at iteration 760 : 0.016494547948241234
Loss at iteration 770 : 0.01637399196624756
Loss at iteration 780 : 0.025979917496442795
Loss at iteration 790 : 0.030688848346471786
Loss at iteration 800 : 0.02599884383380413
Loss at iteration 810 : 0.018316520377993584
Loss at iteration 820 : 0.021191149950027466
Loss at iteration 830 : 0.019972674548625946
Loss at iteration 840 : 0.039225105196237564
Loss at iteration 850 : 0.018529362976551056
Loss at iteration 860 : 0.019871219992637634
Loss at iteration 870 : 0.022126438096165657
Loss at iteration 880 : 0.026082251220941544
Loss at iteration 890 : 0.01372547261416912
Loss at iteration 900 : 0.013379579409956932
Loss at iteration 910 : 0.03156183660030365
Loss at iteration 920 : 0.021910492330789566
Loss at iteration 930 : 0.02971998229622841
Loss at iteration 940 : 0.019578389823436737
Loss at iteration 950 : 0.024460919201374054
Loss at iteration 960 : 0.009739898145198822
Loss at iteration 970 : 0.014420775696635246
Loss at iteration 980 : 0.015239246189594269
Loss at iteration 990 : 0.02429252117872238
Loss at iteration 1000 : 0.019597753882408142
Loss at iteration 1010 : 0.01660827547311783
Loss at iteration 1020 : 0.02312084473669529
Loss at iteration 1030 : 0.02326885052025318
Loss at iteration 1040 : 0.014427618123590946
Loss at iteration 1050 : 0.01657717302441597
Loss at iteration 1060 : 0.0180477574467659
Loss at iteration 1070 : 0.019825957715511322
Loss at iteration 1080 : 0.020876208320260048
Loss at iteration 1090 : 0.025110533460974693
Loss at iteration 1100 : 0.021813329309225082
Loss at iteration 1110 : 0.018357079476118088
Loss at iteration 1120 : 0.024529268965125084
Loss at iteration 1130 : 0.0223349891602993
Loss at iteration 1140 : 0.017896179109811783
Loss at iteration 1150 : 0.0222175270318985
Loss at iteration 1160 : 0.02541426382958889
Loss at iteration 1170 : 0.020652830600738525
Loss at iteration 1180 : 0.011694046668708324
Loss at iteration 1190 : 0.017277183011174202
Loss at iteration 1200 : 0.024103980511426926
Loss at iteration 1210 : 0.020196858793497086
The SSIM Value is: 0.7853228052457174
The PSNR Value is: 19.206936073303222
the epoch is: 95
Loss at iteration 10 : 0.03325376287102699
Loss at iteration 20 : 0.02384495735168457
Loss at iteration 30 : 0.03427667170763016
Loss at iteration 40 : 0.015283558517694473
Loss at iteration 50 : 0.03647966682910919
Loss at iteration 60 : 0.016723688691854477
Loss at iteration 70 : 0.022775772958993912
Loss at iteration 80 : 0.026767466217279434
Loss at iteration 90 : 0.016711575910449028
Loss at iteration 100 : 0.018079984933137894
Loss at iteration 110 : 0.019560303539037704
Loss at iteration 120 : 0.025107067078351974
Loss at iteration 130 : 0.04875935614109039
Loss at iteration 140 : 0.04118816554546356
Loss at iteration 150 : 0.023746967315673828
Loss at iteration 160 : 0.02303444966673851
Loss at iteration 170 : 0.023092757910490036
Loss at iteration 180 : 0.013097722083330154
Loss at iteration 190 : 0.021045060828328133
Loss at iteration 200 : 0.02414267137646675
Loss at iteration 210 : 0.025005755946040154
Loss at iteration 220 : 0.02004026621580124
Loss at iteration 230 : 0.02038276195526123
Loss at iteration 240 : 0.027565952390432358
Loss at iteration 250 : 0.014964409172534943
Loss at iteration 260 : 0.023904675617814064
Loss at iteration 270 : 0.014586154371500015
Loss at iteration 280 : 0.01831672713160515
Loss at iteration 290 : 0.017748001962900162
Loss at iteration 300 : 0.02358066476881504
Loss at iteration 310 : 0.02226801961660385
Loss at iteration 320 : 0.022903261706233025
Loss at iteration 330 : 0.024794064462184906
Loss at iteration 340 : 0.015430336818099022
Loss at iteration 350 : 0.02419796958565712
Loss at iteration 360 : 0.04396095871925354
Loss at iteration 370 : 0.02332899533212185
Loss at iteration 380 : 0.025721943005919456
Loss at iteration 390 : 0.021289967000484467
Loss at iteration 400 : 0.04409768432378769
Loss at iteration 410 : 0.03228076174855232
Loss at iteration 420 : 0.020673193037509918
Loss at iteration 430 : 0.01889621652662754
Loss at iteration 440 : 0.02721865102648735
Loss at iteration 450 : 0.02170451544225216
Loss at iteration 460 : 0.017300697043538094
Loss at iteration 470 : 0.01692647486925125
Loss at iteration 480 : 0.01574108377099037
Loss at iteration 490 : 0.0199706070125103
Loss at iteration 500 : 0.019255101680755615
Loss at iteration 510 : 0.017303498461842537
Loss at iteration 520 : 0.013680846430361271
Loss at iteration 530 : 0.010346799157559872
Loss at iteration 540 : 0.018116505816578865
Loss at iteration 550 : 0.013673515059053898
Loss at iteration 560 : 0.014580764807760715
Loss at iteration 570 : 0.030008025467395782
Loss at iteration 580 : 0.01508641429245472
Loss at iteration 590 : 0.02213848941028118
Loss at iteration 600 : 0.009249450638890266
Loss at iteration 610 : 0.01671455428004265
Loss at iteration 620 : 0.0224001444876194
Loss at iteration 630 : 0.025123482570052147
Loss at iteration 640 : 0.021730447188019753
Loss at iteration 650 : 0.02080141007900238
Loss at iteration 660 : 0.014685295522212982
Loss at iteration 670 : 0.019661495462059975
Loss at iteration 680 : 0.02961031347513199
Loss at iteration 690 : 0.020105592906475067
Loss at iteration 700 : 0.028421776369214058
Loss at iteration 710 : 0.01984962821006775
Loss at iteration 720 : 0.02045353315770626
Loss at iteration 730 : 0.01903284154832363
Loss at iteration 740 : 0.028716858476400375
Loss at iteration 750 : 0.017915673553943634
Loss at iteration 760 : 0.023711372166872025
Loss at iteration 770 : 0.01949191465973854
Loss at iteration 780 : 0.02448570542037487
Loss at iteration 790 : 0.020033668726682663
Loss at iteration 800 : 0.02921992726624012
Loss at iteration 810 : 0.041422732174396515
Loss at iteration 820 : 0.013863880187273026
Loss at iteration 830 : 0.017643338069319725
Loss at iteration 840 : 0.018587980419397354
Loss at iteration 850 : 0.015010494738817215
Loss at iteration 860 : 0.01944967359304428
Loss at iteration 870 : 0.019278936088085175
Loss at iteration 880 : 0.028363442048430443
Loss at iteration 890 : 0.011183164082467556
Loss at iteration 900 : 0.020396899431943893
Loss at iteration 910 : 0.014540517702698708
Loss at iteration 920 : 0.0271665770560503
Loss at iteration 930 : 0.02611689642071724
Loss at iteration 940 : 0.022782720625400543
Loss at iteration 950 : 0.012749980203807354
Loss at iteration 960 : 0.018341511487960815
Loss at iteration 970 : 0.028923965990543365
Loss at iteration 980 : 0.01765413209795952
Loss at iteration 990 : 0.017180699855089188
Loss at iteration 1000 : 0.02191535383462906
Loss at iteration 1010 : 0.023270249366760254
Loss at iteration 1020 : 0.014296162873506546
Loss at iteration 1030 : 0.013714402914047241
Loss at iteration 1040 : 0.03354872763156891
Loss at iteration 1050 : 0.017553746700286865
Loss at iteration 1060 : 0.01986844092607498
Loss at iteration 1070 : 0.017644669860601425
Loss at iteration 1080 : 0.010641846805810928
Loss at iteration 1090 : 0.016338109970092773
Loss at iteration 1100 : 0.018054310232400894
Loss at iteration 1110 : 0.02709570899605751
Loss at iteration 1120 : 0.012831839732825756
Loss at iteration 1130 : 0.02150154858827591
Loss at iteration 1140 : 0.02828991413116455
Loss at iteration 1150 : 0.01988614723086357
Loss at iteration 1160 : 0.010418465360999107
Loss at iteration 1170 : 0.023386258631944656
Loss at iteration 1180 : 0.016551708802580833
Loss at iteration 1190 : 0.03238903731107712
Loss at iteration 1200 : 0.023580091074109077
Loss at iteration 1210 : 0.014974722638726234
The SSIM Value is: 0.7935414354006449
The PSNR Value is: 19.59130433400472
the epoch is: 96
Loss at iteration 10 : 0.021391374990344048
Loss at iteration 20 : 0.019295256584882736
Loss at iteration 30 : 0.01632165163755417
Loss at iteration 40 : 0.012195893563330173
Loss at iteration 50 : 0.015188375487923622
Loss at iteration 60 : 0.044939614832401276
Loss at iteration 70 : 0.020982954651117325
Loss at iteration 80 : 0.027453118935227394
Loss at iteration 90 : 0.020769771188497543
Loss at iteration 100 : 0.019076695665717125
Loss at iteration 110 : 0.012416341342031956
Loss at iteration 120 : 0.014782542362809181
Loss at iteration 130 : 0.01671426184475422
Loss at iteration 140 : 0.015517151914536953
Loss at iteration 150 : 0.01885344088077545
Loss at iteration 160 : 0.033127155154943466
Loss at iteration 170 : 0.013851235620677471
Loss at iteration 180 : 0.014420151710510254
Loss at iteration 190 : 0.02089541219174862
Loss at iteration 200 : 0.009132880717515945
Loss at iteration 210 : 0.03503275290131569
Loss at iteration 220 : 0.023708054795861244
Loss at iteration 230 : 0.020727986469864845
Loss at iteration 240 : 0.028346600010991096
Loss at iteration 250 : 0.03141287714242935
Loss at iteration 260 : 0.027871672064065933
Loss at iteration 270 : 0.018966268748044968
Loss at iteration 280 : 0.021246453747153282
Loss at iteration 290 : 0.017397241666913033
Loss at iteration 300 : 0.029127663001418114
Loss at iteration 310 : 0.01936221867799759
Loss at iteration 320 : 0.028939850628376007
Loss at iteration 330 : 0.017502307891845703
Loss at iteration 340 : 0.013547638431191444
Loss at iteration 350 : 0.01884625107049942
Loss at iteration 360 : 0.02354835346341133
Loss at iteration 370 : 0.00912068784236908
Loss at iteration 380 : 0.015770770609378815
Loss at iteration 390 : 0.018151093274354935
Loss at iteration 400 : 0.014646862633526325
Loss at iteration 410 : 0.023280736058950424
Loss at iteration 420 : 0.019676370546221733
Loss at iteration 430 : 0.023462483659386635
Loss at iteration 440 : 0.024412624537944794
Loss at iteration 450 : 0.016414109617471695
Loss at iteration 460 : 0.018301622942090034
Loss at iteration 470 : 0.01734291948378086
Loss at iteration 480 : 0.015913859009742737
Loss at iteration 490 : 0.01808938756585121
Loss at iteration 500 : 0.020605679601430893
Loss at iteration 510 : 0.025216389447450638
Loss at iteration 520 : 0.014248041436076164
Loss at iteration 530 : 0.012191465124487877
Loss at iteration 540 : 0.017033861950039864
Loss at iteration 550 : 0.0146962720900774
Loss at iteration 560 : 0.023473132401704788
Loss at iteration 570 : 0.0243461262434721
Loss at iteration 580 : 0.02897571586072445
Loss at iteration 590 : 0.01878601498901844
Loss at iteration 600 : 0.030651584267616272
Loss at iteration 610 : 0.01731288619339466
Loss at iteration 620 : 0.019357824698090553
Loss at iteration 630 : 0.020539455115795135
Loss at iteration 640 : 0.017420243471860886
Loss at iteration 650 : 0.025207271799445152
Loss at iteration 660 : 0.016846535727381706
Loss at iteration 670 : 0.01339782029390335
Loss at iteration 680 : 0.022807618603110313
Loss at iteration 690 : 0.029767422005534172
Loss at iteration 700 : 0.015281952917575836
Loss at iteration 710 : 0.03080274723470211
Loss at iteration 720 : 0.03871888667345047
Loss at iteration 730 : 0.018297318369150162
Loss at iteration 740 : 0.013935825787484646
Loss at iteration 750 : 0.01778726652264595
Loss at iteration 760 : 0.020414184778928757
Loss at iteration 770 : 0.019501902163028717
Loss at iteration 780 : 0.01503558736294508
Loss at iteration 790 : 0.014499116688966751
Loss at iteration 800 : 0.018887558951973915
Loss at iteration 810 : 0.030463863164186478
Loss at iteration 820 : 0.022057726979255676
Loss at iteration 830 : 0.016610518097877502
Loss at iteration 840 : 0.02157844975590706
Loss at iteration 850 : 0.027532078325748444
Loss at iteration 860 : 0.02510376274585724
Loss at iteration 870 : 0.01815185509622097
Loss at iteration 880 : 0.016464214771986008
Loss at iteration 890 : 0.021819129586219788
Loss at iteration 900 : 0.01699453592300415
Loss at iteration 910 : 0.029055338352918625
Loss at iteration 920 : 0.015195544809103012
Loss at iteration 930 : 0.01982717029750347
Loss at iteration 940 : 0.033968470990657806
Loss at iteration 950 : 0.021420439705252647
Loss at iteration 960 : 0.022383444011211395
Loss at iteration 970 : 0.028575414791703224
Loss at iteration 980 : 0.029381051659584045
Loss at iteration 990 : 0.02382255159318447
Loss at iteration 1000 : 0.024815110489726067
Loss at iteration 1010 : 0.02642248198390007
Loss at iteration 1020 : 0.019878342747688293
Loss at iteration 1030 : 0.023120621219277382
Loss at iteration 1040 : 0.021440912038087845
Loss at iteration 1050 : 0.01676168292760849
Loss at iteration 1060 : 0.021496953442692757
Loss at iteration 1070 : 0.017993345856666565
Loss at iteration 1080 : 0.01788235642015934
Loss at iteration 1090 : 0.01745494455099106
Loss at iteration 1100 : 0.01488795317709446
Loss at iteration 1110 : 0.017215576022863388
Loss at iteration 1120 : 0.022877609357237816
Loss at iteration 1130 : 0.02784860134124756
Loss at iteration 1140 : 0.01498652994632721
Loss at iteration 1150 : 0.043471310287714005
Loss at iteration 1160 : 0.023498347029089928
Loss at iteration 1170 : 0.02471238747239113
Loss at iteration 1180 : 0.032241955399513245
Loss at iteration 1190 : 0.015284649096429348
Loss at iteration 1200 : 0.0225924551486969
Loss at iteration 1210 : 0.022720608860254288
The SSIM Value is: 0.7794963916142782
The PSNR Value is: 17.28269386291504
the epoch is: 97
Loss at iteration 10 : 0.014559930190443993
Loss at iteration 20 : 0.018977835774421692
Loss at iteration 30 : 0.03094361163675785
Loss at iteration 40 : 0.013616517186164856
Loss at iteration 50 : 0.021080918610095978
Loss at iteration 60 : 0.01882316544651985
Loss at iteration 70 : 0.02366453781723976
Loss at iteration 80 : 0.017607253044843674
Loss at iteration 90 : 0.015767749398946762
Loss at iteration 100 : 0.03556806221604347
Loss at iteration 110 : 0.01665114238858223
Loss at iteration 120 : 0.014741959981620312
Loss at iteration 130 : 0.023525329306721687
Loss at iteration 140 : 0.018331998959183693
Loss at iteration 150 : 0.0214935764670372
Loss at iteration 160 : 0.01571028307080269
Loss at iteration 170 : 0.01582854613661766
Loss at iteration 180 : 0.02362183853983879
Loss at iteration 190 : 0.014458311721682549
Loss at iteration 200 : 0.029595468193292618
Loss at iteration 210 : 0.015917688608169556
Loss at iteration 220 : 0.018748098984360695
Loss at iteration 230 : 0.018931128084659576
Loss at iteration 240 : 0.01788097247481346
Loss at iteration 250 : 0.017171423882246017
Loss at iteration 260 : 0.02183341421186924
Loss at iteration 270 : 0.01705397665500641
Loss at iteration 280 : 0.020009677857160568
Loss at iteration 290 : 0.01337776705622673
Loss at iteration 300 : 0.020945142954587936
Loss at iteration 310 : 0.03392704576253891
Loss at iteration 320 : 0.0234222449362278
Loss at iteration 330 : 0.03149120882153511
Loss at iteration 340 : 0.03862744942307472
Loss at iteration 350 : 0.021606042981147766
Loss at iteration 360 : 0.01986384019255638
Loss at iteration 370 : 0.02529279515147209
Loss at iteration 380 : 0.006873550824820995
Loss at iteration 390 : 0.01722230203449726
Loss at iteration 400 : 0.01854933612048626
Loss at iteration 410 : 0.03504865989089012
Loss at iteration 420 : 0.013418301939964294
Loss at iteration 430 : 0.013248620554804802
Loss at iteration 440 : 0.023541606962680817
Loss at iteration 450 : 0.0299408957362175
Loss at iteration 460 : 0.025783024728298187
Loss at iteration 470 : 0.009286953136324883
Loss at iteration 480 : 0.017133228480815887
Loss at iteration 490 : 0.020717261359095573
Loss at iteration 500 : 0.014344260096549988
Loss at iteration 510 : 0.04316239804029465
Loss at iteration 520 : 0.02187974937260151
Loss at iteration 530 : 0.02753559872508049
Loss at iteration 540 : 0.02135217934846878
Loss at iteration 550 : 0.014004820957779884
Loss at iteration 560 : 0.018170088529586792
Loss at iteration 570 : 0.012253799475729465
Loss at iteration 580 : 0.014790041372179985
Loss at iteration 590 : 0.022245632484555244
Loss at iteration 600 : 0.021394550800323486
Loss at iteration 610 : 0.01651274599134922
Loss at iteration 620 : 0.016196539625525475
Loss at iteration 630 : 0.012561782263219357
Loss at iteration 640 : 0.022164583206176758
Loss at iteration 650 : 0.02296539954841137
Loss at iteration 660 : 0.030357182025909424
Loss at iteration 670 : 0.019792664796113968
Loss at iteration 680 : 0.028418852016329765
Loss at iteration 690 : 0.022061262279748917
Loss at iteration 700 : 0.027821484953165054
Loss at iteration 710 : 0.013273987919092178
Loss at iteration 720 : 0.031161200255155563
Loss at iteration 730 : 0.029975205659866333
Loss at iteration 740 : 0.030929656699299812
Loss at iteration 750 : 0.026115885004401207
Loss at iteration 760 : 0.03711964190006256
Loss at iteration 770 : 0.02236630581319332
Loss at iteration 780 : 0.017546143382787704
Loss at iteration 790 : 0.01709844544529915
Loss at iteration 800 : 0.01613178849220276
Loss at iteration 810 : 0.017511941492557526
Loss at iteration 820 : 0.013671224005520344
Loss at iteration 830 : 0.01725032366812229
Loss at iteration 840 : 0.020586669445037842
Loss at iteration 850 : 0.028459127992391586
Loss at iteration 860 : 0.025003505870699883
Loss at iteration 870 : 0.01732145994901657
Loss at iteration 880 : 0.012368169613182545
Loss at iteration 890 : 0.025806300342082977
Loss at iteration 900 : 0.020530886948108673
Loss at iteration 910 : 0.013662019744515419
Loss at iteration 920 : 0.012206305749714375
Loss at iteration 930 : 0.02099754847586155
Loss at iteration 940 : 0.019557029008865356
Loss at iteration 950 : 0.025917593389749527
Loss at iteration 960 : 0.015481874346733093
Loss at iteration 970 : 0.03180059418082237
Loss at iteration 980 : 0.015639811754226685
Loss at iteration 990 : 0.01682157814502716
Loss at iteration 1000 : 0.014502396807074547
Loss at iteration 1010 : 0.020194921642541885
Loss at iteration 1020 : 0.014904558658599854
Loss at iteration 1030 : 0.020064570009708405
Loss at iteration 1040 : 0.026464637368917465
Loss at iteration 1050 : 0.021217620000243187
Loss at iteration 1060 : 0.016069261357188225
Loss at iteration 1070 : 0.02532137744128704
Loss at iteration 1080 : 0.02215084806084633
Loss at iteration 1090 : 0.03159414976835251
Loss at iteration 1100 : 0.013949951156973839
Loss at iteration 1110 : 0.027474569156765938
Loss at iteration 1120 : 0.020483385771512985
Loss at iteration 1130 : 0.01241383422166109
Loss at iteration 1140 : 0.012562873773276806
Loss at iteration 1150 : 0.0169450081884861
Loss at iteration 1160 : 0.018730590119957924
Loss at iteration 1170 : 0.016525976359844208
Loss at iteration 1180 : 0.01718990132212639
Loss at iteration 1190 : 0.025821208953857422
Loss at iteration 1200 : 0.027822524309158325
Loss at iteration 1210 : 0.020218199118971825
The SSIM Value is: 0.7949081579844157
The PSNR Value is: 18.3940336227417
the epoch is: 98
Loss at iteration 10 : 0.02216639369726181
Loss at iteration 20 : 0.041104331612586975
Loss at iteration 30 : 0.016571441665291786
Loss at iteration 40 : 0.011849021539092064
Loss at iteration 50 : 0.019984258338809013
Loss at iteration 60 : 0.01591222546994686
Loss at iteration 70 : 0.01744842901825905
Loss at iteration 80 : 0.034946996718645096
Loss at iteration 90 : 0.027210351079702377
Loss at iteration 100 : 0.018416566774249077
Loss at iteration 110 : 0.02852044627070427
Loss at iteration 120 : 0.02110595628619194
Loss at iteration 130 : 0.02095833048224449
Loss at iteration 140 : 0.02319035492837429
Loss at iteration 150 : 0.0324908085167408
Loss at iteration 160 : 0.0271976999938488
Loss at iteration 170 : 0.025388848036527634
Loss at iteration 180 : 0.016170579940080643
Loss at iteration 190 : 0.012411914765834808
Loss at iteration 200 : 0.020256051793694496
Loss at iteration 210 : 0.02874329686164856
Loss at iteration 220 : 0.013550875708460808
Loss at iteration 230 : 0.0349297896027565
Loss at iteration 240 : 0.017991401255130768
Loss at iteration 250 : 0.025075778365135193
Loss at iteration 260 : 0.027101745828986168
Loss at iteration 270 : 0.01929105818271637
Loss at iteration 280 : 0.02461143210530281
Loss at iteration 290 : 0.01632365584373474
Loss at iteration 300 : 0.02199453115463257
Loss at iteration 310 : 0.0297350212931633
Loss at iteration 320 : 0.03094271570444107
Loss at iteration 330 : 0.00646269042044878
Loss at iteration 340 : 0.022001489996910095
Loss at iteration 350 : 0.027786632999777794
Loss at iteration 360 : 0.021082330495119095
Loss at iteration 370 : 0.01782344840466976
Loss at iteration 380 : 0.013918033801019192
Loss at iteration 390 : 0.018766505643725395
Loss at iteration 400 : 0.01516681257635355
Loss at iteration 410 : 0.015606355853378773
Loss at iteration 420 : 0.02118942327797413
Loss at iteration 430 : 0.018678542226552963
Loss at iteration 440 : 0.0343063548207283
Loss at iteration 450 : 0.026096079498529434
Loss at iteration 460 : 0.013821993954479694
Loss at iteration 470 : 0.026200108230113983
Loss at iteration 480 : 0.01449433621019125
Loss at iteration 490 : 0.020723406225442886
Loss at iteration 500 : 0.018764205276966095
Loss at iteration 510 : 0.023519344627857208
Loss at iteration 520 : 0.01229698397219181
Loss at iteration 530 : 0.02894734777510166
Loss at iteration 540 : 0.034324467182159424
Loss at iteration 550 : 0.022508667781949043
Loss at iteration 560 : 0.02433328703045845
Loss at iteration 570 : 0.013400653377175331
Loss at iteration 580 : 0.02446504309773445
Loss at iteration 590 : 0.024879446253180504
Loss at iteration 600 : 0.01823369413614273
Loss at iteration 610 : 0.01890820637345314
Loss at iteration 620 : 0.013047164306044579
Loss at iteration 630 : 0.01783858984708786
Loss at iteration 640 : 0.01391871552914381
Loss at iteration 650 : 0.010341046378016472
Loss at iteration 660 : 0.016530899330973625
Loss at iteration 670 : 0.019180016592144966
Loss at iteration 680 : 0.01728108897805214
Loss at iteration 690 : 0.012025624513626099
Loss at iteration 700 : 0.02038288302719593
Loss at iteration 710 : 0.014078360050916672
Loss at iteration 720 : 0.02432929538190365
Loss at iteration 730 : 0.027827948331832886
Loss at iteration 740 : 0.028494345024228096
Loss at iteration 750 : 0.028256172314286232
Loss at iteration 760 : 0.010371238924562931
Loss at iteration 770 : 0.01442280039191246
Loss at iteration 780 : 0.031646355986595154
Loss at iteration 790 : 0.013852624222636223
Loss at iteration 800 : 0.02650289423763752
Loss at iteration 810 : 0.017974838614463806
Loss at iteration 820 : 0.01531193032860756
Loss at iteration 830 : 0.019299672916531563
Loss at iteration 840 : 0.0303652323782444
Loss at iteration 850 : 0.018122751265764236
Loss at iteration 860 : 0.01993793621659279
Loss at iteration 870 : 0.024821996688842773
Loss at iteration 880 : 0.028064874932169914
Loss at iteration 890 : 0.022370126098394394
Loss at iteration 900 : 0.013795070350170135
Loss at iteration 910 : 0.017177194356918335
Loss at iteration 920 : 0.03610236197710037
Loss at iteration 930 : 0.015875186771154404
Loss at iteration 940 : 0.017575737088918686
Loss at iteration 950 : 0.02768721804022789
Loss at iteration 960 : 0.02348988503217697
Loss at iteration 970 : 0.025367585942149162
Loss at iteration 980 : 0.011638594791293144
Loss at iteration 990 : 0.014719100669026375
Loss at iteration 1000 : 0.01678624004125595
Loss at iteration 1010 : 0.02781248837709427
Loss at iteration 1020 : 0.01486509945243597
Loss at iteration 1030 : 0.02060193568468094
Loss at iteration 1040 : 0.02213946171104908
Loss at iteration 1050 : 0.027409721165895462
Loss at iteration 1060 : 0.022926567122340202
Loss at iteration 1070 : 0.02073380909860134
Loss at iteration 1080 : 0.016097011044621468
Loss at iteration 1090 : 0.0281373281031847
Loss at iteration 1100 : 0.02970527857542038
Loss at iteration 1110 : 0.017870282754302025
Loss at iteration 1120 : 0.017110930755734444
Loss at iteration 1130 : 0.021442808210849762
Loss at iteration 1140 : 0.020410262048244476
Loss at iteration 1150 : 0.0201277993619442
Loss at iteration 1160 : 0.013384665362536907
Loss at iteration 1170 : 0.017758969217538834
Loss at iteration 1180 : 0.02249346673488617
Loss at iteration 1190 : 0.020378200337290764
Loss at iteration 1200 : 0.02178475260734558
Loss at iteration 1210 : 0.01798040047287941
The SSIM Value is: 0.7975311040878296
The PSNR Value is: 18.89478937784831
the epoch is: 99
Loss at iteration 10 : 0.018867652863264084
Loss at iteration 20 : 0.033005256205797195
Loss at iteration 30 : 0.01979668252170086
Loss at iteration 40 : 0.01826161891222
Loss at iteration 50 : 0.02588723413646221
Loss at iteration 60 : 0.02084837108850479
Loss at iteration 70 : 0.030228266492486
Loss at iteration 80 : 0.01709640771150589
Loss at iteration 90 : 0.020805278792977333
Loss at iteration 100 : 0.023915544152259827
Loss at iteration 110 : 0.01811494305729866
Loss at iteration 120 : 0.033394187688827515
Loss at iteration 130 : 0.02065255679190159
Loss at iteration 140 : 0.016084928065538406
Loss at iteration 150 : 0.02284528873860836
Loss at iteration 160 : 0.020296212285757065
Loss at iteration 170 : 0.02776562236249447
Loss at iteration 180 : 0.023140830919146538
Loss at iteration 190 : 0.013602404855191708
Loss at iteration 200 : 0.021447857841849327
Loss at iteration 210 : 0.01735355146229267
Loss at iteration 220 : 0.017654089257121086
Loss at iteration 230 : 0.03136631101369858
Loss at iteration 240 : 0.01918742060661316
Loss at iteration 250 : 0.02900218591094017
Loss at iteration 260 : 0.010615315288305283
Loss at iteration 270 : 0.01896294578909874
Loss at iteration 280 : 0.025316810235381126
Loss at iteration 290 : 0.02485111728310585
Loss at iteration 300 : 0.019758891314268112
Loss at iteration 310 : 0.020416371524333954
Loss at iteration 320 : 0.022318098694086075
Loss at iteration 330 : 0.017141137272119522
Loss at iteration 340 : 0.013348636217415333
Loss at iteration 350 : 0.018244760110974312
Loss at iteration 360 : 0.01710471697151661
Loss at iteration 370 : 0.014665333554148674
Loss at iteration 380 : 0.02386082336306572
Loss at iteration 390 : 0.03059571050107479
Loss at iteration 400 : 0.014503104612231255
Loss at iteration 410 : 0.024505436420440674
Loss at iteration 420 : 0.022514991462230682
Loss at iteration 430 : 0.017227213829755783
Loss at iteration 440 : 0.02494259551167488
Loss at iteration 450 : 0.02542855218052864
Loss at iteration 460 : 0.027852846309542656
Loss at iteration 470 : 0.01611248031258583
Loss at iteration 480 : 0.02221844531595707
Loss at iteration 490 : 0.025711288675665855
Loss at iteration 500 : 0.018014099448919296
Loss at iteration 510 : 0.017972834408283234
Loss at iteration 520 : 0.02234068512916565
Loss at iteration 530 : 0.02314557135105133
Loss at iteration 540 : 0.02295229211449623
Loss at iteration 550 : 0.016306646168231964
Loss at iteration 560 : 0.012963458895683289
Loss at iteration 570 : 0.03614217787981033
Loss at iteration 580 : 0.01866919919848442
Loss at iteration 590 : 0.012711371295154095
Loss at iteration 600 : 0.020861513912677765
Loss at iteration 610 : 0.03157893568277359
Loss at iteration 620 : 0.010674999095499516
Loss at iteration 630 : 0.025294795632362366
Loss at iteration 640 : 0.020003091543912888
Loss at iteration 650 : 0.01690690591931343
Loss at iteration 660 : 0.02017837017774582
Loss at iteration 670 : 0.03256045654416084
Loss at iteration 680 : 0.02842799946665764
Loss at iteration 690 : 0.01016266830265522
Loss at iteration 700 : 0.012637712061405182
Loss at iteration 710 : 0.017679693177342415
Loss at iteration 720 : 0.036294322460889816
Loss at iteration 730 : 0.034958366304636
Loss at iteration 740 : 0.0200788713991642
Loss at iteration 750 : 0.037554316222667694
Loss at iteration 760 : 0.019694171845912933
Loss at iteration 770 : 0.02668614871799946
Loss at iteration 780 : 0.021687403321266174
Loss at iteration 790 : 0.014134854078292847
Loss at iteration 800 : 0.02148102968931198
Loss at iteration 810 : 0.01908690854907036
Loss at iteration 820 : 0.016129354014992714
Loss at iteration 830 : 0.019487328827381134
Loss at iteration 840 : 0.016978856176137924
Loss at iteration 850 : 0.02782345749437809
Loss at iteration 860 : 0.011943789198994637
Loss at iteration 870 : 0.02672547847032547
Loss at iteration 880 : 0.021132374182343483
Loss at iteration 890 : 0.01090702973306179
Loss at iteration 900 : 0.017397593706846237
Loss at iteration 910 : 0.02108672633767128
Loss at iteration 920 : 0.02343624457716942
Loss at iteration 930 : 0.04021069407463074
Loss at iteration 940 : 0.026885589584708214
Loss at iteration 950 : 0.026157069951295853
Loss at iteration 960 : 0.015608089976012707
Loss at iteration 970 : 0.03015388920903206
Loss at iteration 980 : 0.024038970470428467
Loss at iteration 990 : 0.017504923045635223
Loss at iteration 1000 : 0.02212480455636978
Loss at iteration 1010 : 0.02384943887591362
Loss at iteration 1020 : 0.01719813235104084
Loss at iteration 1030 : 0.0342947319149971
Loss at iteration 1040 : 0.02268056571483612
Loss at iteration 1050 : 0.015439148992300034
Loss at iteration 1060 : 0.017900753766298294
Loss at iteration 1070 : 0.014039359986782074
Loss at iteration 1080 : 0.015237873420119286
Loss at iteration 1090 : 0.020631305873394012
Loss at iteration 1100 : 0.02477755770087242
Loss at iteration 1110 : 0.025217818096280098
Loss at iteration 1120 : 0.014732595533132553
Loss at iteration 1130 : 0.018607139587402344
Loss at iteration 1140 : 0.022307343780994415
Loss at iteration 1150 : 0.025190331041812897
Loss at iteration 1160 : 0.011455588042736053
Loss at iteration 1170 : 0.02713915891945362
Loss at iteration 1180 : 0.02402215451002121
Loss at iteration 1190 : 0.018033821135759354
Loss at iteration 1200 : 0.014746633358299732
Loss at iteration 1210 : 0.014831118285655975
The SSIM Value is: 0.7922307093938191
The PSNR Value is: 17.982924207051596
the epoch is: 100
Loss at iteration 10 : 0.022689513862133026
Loss at iteration 20 : 0.017426474019885063
Loss at iteration 30 : 0.015231184661388397
Loss at iteration 40 : 0.015925321727991104
Loss at iteration 50 : 0.02138485759496689
Loss at iteration 60 : 0.013868311420083046
Loss at iteration 70 : 0.02368512563407421
Loss at iteration 80 : 0.017705542966723442
Loss at iteration 90 : 0.01550479419529438
Loss at iteration 100 : 0.025972293689846992
Loss at iteration 110 : 0.01217035111039877
Loss at iteration 120 : 0.012984821572899818
Loss at iteration 130 : 0.025806568562984467
Loss at iteration 140 : 0.02483903430402279
Loss at iteration 150 : 0.0124898049980402
Loss at iteration 160 : 0.02603994496166706
Loss at iteration 170 : 0.014995956793427467
Loss at iteration 180 : 0.026602940633893013
Loss at iteration 190 : 0.02124570868909359
Loss at iteration 200 : 0.02507912926375866
Loss at iteration 210 : 0.017857003957033157
Loss at iteration 220 : 0.02688702568411827
Loss at iteration 230 : 0.01763661578297615
Loss at iteration 240 : 0.020523887127637863
Loss at iteration 250 : 0.03630460426211357
Loss at iteration 260 : 0.01697015017271042
Loss at iteration 270 : 0.022075016051530838
Loss at iteration 280 : 0.007155158556997776
Loss at iteration 290 : 0.02031109854578972
Loss at iteration 300 : 0.015744533389806747
Loss at iteration 310 : 0.026936741545796394
Loss at iteration 320 : 0.02288389578461647
Loss at iteration 330 : 0.01052890345454216
Loss at iteration 340 : 0.018855683505535126
Loss at iteration 350 : 0.013000492937862873
Loss at iteration 360 : 0.01939060539007187
Loss at iteration 370 : 0.019206803292036057
Loss at iteration 380 : 0.018592264503240585
Loss at iteration 390 : 0.016826611012220383
Loss at iteration 400 : 0.017268909141421318
Loss at iteration 410 : 0.017433572560548782
Loss at iteration 420 : 0.01296413317322731
Loss at iteration 430 : 0.01604689471423626
Loss at iteration 440 : 0.02642391435801983
Loss at iteration 450 : 0.018256913870573044
Loss at iteration 460 : 0.031588587909936905
Loss at iteration 470 : 0.023492179811000824
Loss at iteration 480 : 0.01679559051990509
Loss at iteration 490 : 0.02996375784277916
Loss at iteration 500 : 0.016402829438447952
Loss at iteration 510 : 0.02319839969277382
Loss at iteration 520 : 0.014272854663431644
Loss at iteration 530 : 0.015773989260196686
Loss at iteration 540 : 0.009103171527385712
Loss at iteration 550 : 0.02378745935857296
Loss at iteration 560 : 0.016344375908374786
Loss at iteration 570 : 0.027979589998722076
Loss at iteration 580 : 0.013557530008256435
Loss at iteration 590 : 0.0190621018409729
Loss at iteration 600 : 0.02937794290482998
Loss at iteration 610 : 0.01491672731935978
Loss at iteration 620 : 0.022342387586832047
Loss at iteration 630 : 0.014102676883339882
Loss at iteration 640 : 0.0181977991014719
Loss at iteration 650 : 0.01843184605240822
Loss at iteration 660 : 0.027294261381030083
Loss at iteration 670 : 0.021315274760127068
Loss at iteration 680 : 0.025127507746219635
Loss at iteration 690 : 0.01629110425710678
Loss at iteration 700 : 0.01270852331072092
Loss at iteration 710 : 0.029718615114688873
Loss at iteration 720 : 0.0236820075660944
Loss at iteration 730 : 0.026807840913534164
Loss at iteration 740 : 0.013278482481837273
Loss at iteration 750 : 0.025804419070482254
Loss at iteration 760 : 0.022708870470523834
Loss at iteration 770 : 0.028770431876182556
Loss at iteration 780 : 0.028517063707113266
Loss at iteration 790 : 0.01790245808660984
Loss at iteration 800 : 0.025418296456336975
Loss at iteration 810 : 0.027059128507971764
Loss at iteration 820 : 0.01840701699256897
Loss at iteration 830 : 0.01016257144510746
Loss at iteration 840 : 0.019906995818018913
Loss at iteration 850 : 0.018770350143313408
Loss at iteration 860 : 0.019648954272270203
Loss at iteration 870 : 0.007371379062533379
Loss at iteration 880 : 0.013457633554935455
Loss at iteration 890 : 0.0213451087474823
Loss at iteration 900 : 0.027000853791832924
Loss at iteration 910 : 0.0194324292242527
Loss at iteration 920 : 0.024133512750267982
Loss at iteration 930 : 0.022342577576637268
Loss at iteration 940 : 0.035691700875759125
Loss at iteration 950 : 0.023895608261227608
Loss at iteration 960 : 0.02003277651965618
Loss at iteration 970 : 0.015411041676998138
Loss at iteration 980 : 0.015392345376312733
Loss at iteration 990 : 0.025714341551065445
Loss at iteration 1000 : 0.02541559562087059
Loss at iteration 1010 : 0.023505864664912224
Loss at iteration 1020 : 0.01297755166888237
Loss at iteration 1030 : 0.03063110262155533
Loss at iteration 1040 : 0.035133857280015945
Loss at iteration 1050 : 0.021624483168125153
Loss at iteration 1060 : 0.02601991966366768
Loss at iteration 1070 : 0.026972919702529907
Loss at iteration 1080 : 0.03204882889986038
Loss at iteration 1090 : 0.016672689467668533
Loss at iteration 1100 : 0.027044059708714485
Loss at iteration 1110 : 0.021811697632074356
Loss at iteration 1120 : 0.029295988380908966
Loss at iteration 1130 : 0.01271225418895483
Loss at iteration 1140 : 0.017703967168927193
Loss at iteration 1150 : 0.044926807284355164
Loss at iteration 1160 : 0.014637911692261696
Loss at iteration 1170 : 0.038099199533462524
Loss at iteration 1180 : 0.01815568096935749
Loss at iteration 1190 : 0.018113140016794205
Loss at iteration 1200 : 0.018989119678735733
Loss at iteration 1210 : 0.0219669658690691
The SSIM Value is: 0.791350245475769
The PSNR Value is: 18.515109252929687
the epoch is: 101
Loss at iteration 10 : 0.027514619752764702
Loss at iteration 20 : 0.02024306356906891
Loss at iteration 30 : 0.022405080497264862
Loss at iteration 40 : 0.01853010803461075
Loss at iteration 50 : 0.02526203542947769
Loss at iteration 60 : 0.02518637664616108
Loss at iteration 70 : 0.027390602976083755
Loss at iteration 80 : 0.021521691232919693
Loss at iteration 90 : 0.030486561357975006
Loss at iteration 100 : 0.02122841402888298
Loss at iteration 110 : 0.023756347596645355
Loss at iteration 120 : 0.014577198773622513
Loss at iteration 130 : 0.014489881694316864
Loss at iteration 140 : 0.019039368256926537
Loss at iteration 150 : 0.02098514325916767
Loss at iteration 160 : 0.013196933083236217
Loss at iteration 170 : 0.024613937363028526
Loss at iteration 180 : 0.03518533706665039
Loss at iteration 190 : 0.018844803795218468
Loss at iteration 200 : 0.023789919912815094
Loss at iteration 210 : 0.022622663527727127
Loss at iteration 220 : 0.020948436111211777
Loss at iteration 230 : 0.01374601200222969
Loss at iteration 240 : 0.023597028106451035
Loss at iteration 250 : 0.013394522480666637
Loss at iteration 260 : 0.0192305576056242
Loss at iteration 270 : 0.02189681865274906
Loss at iteration 280 : 0.018662136048078537
Loss at iteration 290 : 0.020091934129595757
Loss at iteration 300 : 0.017171021550893784
Loss at iteration 310 : 0.016690723598003387
Loss at iteration 320 : 0.023943381384015083
Loss at iteration 330 : 0.027438722550868988
Loss at iteration 340 : 0.021270746365189552
Loss at iteration 350 : 0.02556873857975006
Loss at iteration 360 : 0.022850332781672478
Loss at iteration 370 : 0.024455245584249496
Loss at iteration 380 : 0.016482386738061905
Loss at iteration 390 : 0.020927954465150833
Loss at iteration 400 : 0.013888954184949398
Loss at iteration 410 : 0.013993161730468273
Loss at iteration 420 : 0.017958413809537888
Loss at iteration 430 : 0.027420302852988243
Loss at iteration 440 : 0.02272099256515503
Loss at iteration 450 : 0.020679593086242676
Loss at iteration 460 : 0.02466791868209839
Loss at iteration 470 : 0.01787189021706581
Loss at iteration 480 : 0.024081896990537643
Loss at iteration 490 : 0.02225029654800892
Loss at iteration 500 : 0.02190789394080639
Loss at iteration 510 : 0.019031397998332977
Loss at iteration 520 : 0.01946854591369629
Loss at iteration 530 : 0.02311607450246811
Loss at iteration 540 : 0.013082566671073437
Loss at iteration 550 : 0.051481954753398895
Loss at iteration 560 : 0.023536264896392822
Loss at iteration 570 : 0.013345673680305481
Loss at iteration 580 : 0.029436593875288963
Loss at iteration 590 : 0.0219598226249218
Loss at iteration 600 : 0.011488918215036392
Loss at iteration 610 : 0.020940100774168968
Loss at iteration 620 : 0.043647296726703644
Loss at iteration 630 : 0.016653910279273987
Loss at iteration 640 : 0.018979281187057495
Loss at iteration 650 : 0.01638464815914631
Loss at iteration 660 : 0.019978094846010208
Loss at iteration 670 : 0.02382601797580719
Loss at iteration 680 : 0.016604047268629074
Loss at iteration 690 : 0.012212062254548073
Loss at iteration 700 : 0.015440821647644043
Loss at iteration 710 : 0.018390869721770287
Loss at iteration 720 : 0.013361860066652298
Loss at iteration 730 : 0.019430838525295258
Loss at iteration 740 : 0.01740070804953575
Loss at iteration 750 : 0.016517452895641327
Loss at iteration 760 : 0.016335923224687576
Loss at iteration 770 : 0.02006022073328495
Loss at iteration 780 : 0.015760328620672226
Loss at iteration 790 : 0.019115010276436806
Loss at iteration 800 : 0.018956061452627182
Loss at iteration 810 : 0.027807632461190224
Loss at iteration 820 : 0.022770550101995468
Loss at iteration 830 : 0.031013598665595055
Loss at iteration 840 : 0.020319174975156784
Loss at iteration 850 : 0.023908672854304314
Loss at iteration 860 : 0.017277829349040985
Loss at iteration 870 : 0.03046482801437378
Loss at iteration 880 : 0.02753268927335739
Loss at iteration 890 : 0.017291247844696045
Loss at iteration 900 : 0.014583103358745575
Loss at iteration 910 : 0.03043709695339203
Loss at iteration 920 : 0.010631327517330647
Loss at iteration 930 : 0.026170305907726288
Loss at iteration 940 : 0.020196279510855675
Loss at iteration 950 : 0.016785025596618652
Loss at iteration 960 : 0.02979852631688118
Loss at iteration 970 : 0.015718791633844376
Loss at iteration 980 : 0.015550533309578896
Loss at iteration 990 : 0.021676329895853996
Loss at iteration 1000 : 0.019619695842266083
Loss at iteration 1010 : 0.01713680662214756
Loss at iteration 1020 : 0.018380794674158096
Loss at iteration 1030 : 0.017217174172401428
Loss at iteration 1040 : 0.015977855771780014
Loss at iteration 1050 : 0.019044529646635056
Loss at iteration 1060 : 0.01186447124928236
Loss at iteration 1070 : 0.02827392891049385
Loss at iteration 1080 : 0.015707306563854218
Loss at iteration 1090 : 0.011769254691898823
Loss at iteration 1100 : 0.013415953144431114
Loss at iteration 1110 : 0.026535924524068832
Loss at iteration 1120 : 0.018406029790639877
Loss at iteration 1130 : 0.02009749971330166
Loss at iteration 1140 : 0.021188834682106972
Loss at iteration 1150 : 0.02530439756810665
Loss at iteration 1160 : 0.014189082197844982
Loss at iteration 1170 : 0.01635834202170372
Loss at iteration 1180 : 0.016123734414577484
Loss at iteration 1190 : 0.025226321071386337
Loss at iteration 1200 : 0.021600602194666862
Loss at iteration 1210 : 0.028073454275727272
The SSIM Value is: 0.7970145225524903
The PSNR Value is: 18.860480562845865
the epoch is: 102
Loss at iteration 10 : 0.02424832060933113
Loss at iteration 20 : 0.022456439211964607
Loss at iteration 30 : 0.02318679913878441
Loss at iteration 40 : 0.014529227279126644
Loss at iteration 50 : 0.04499177634716034
Loss at iteration 60 : 0.023658018559217453
Loss at iteration 70 : 0.017135843634605408
Loss at iteration 80 : 0.027567701414227486
Loss at iteration 90 : 0.03738529235124588
Loss at iteration 100 : 0.014177868142724037
Loss at iteration 110 : 0.032750822603702545
Loss at iteration 120 : 0.00982082448899746
Loss at iteration 130 : 0.0298614464700222
Loss at iteration 140 : 0.03229425847530365
Loss at iteration 150 : 0.016113774850964546
Loss at iteration 160 : 0.0083943335339427
Loss at iteration 170 : 0.03320344537496567
Loss at iteration 180 : 0.012397289276123047
Loss at iteration 190 : 0.029115445911884308
Loss at iteration 200 : 0.023846058174967766
Loss at iteration 210 : 0.022242780774831772
Loss at iteration 220 : 0.018408235162496567
Loss at iteration 230 : 0.01141102984547615
Loss at iteration 240 : 0.022875729948282242
Loss at iteration 250 : 0.03368442505598068
Loss at iteration 260 : 0.015746571123600006
Loss at iteration 270 : 0.02035336196422577
Loss at iteration 280 : 0.01981567218899727
Loss at iteration 290 : 0.016815612092614174
Loss at iteration 300 : 0.0285249762237072
Loss at iteration 310 : 0.016929494217038155
Loss at iteration 320 : 0.01931922882795334
Loss at iteration 330 : 0.02679026871919632
Loss at iteration 340 : 0.02748924121260643
Loss at iteration 350 : 0.017064088955521584
Loss at iteration 360 : 0.021746249869465828
Loss at iteration 370 : 0.018258031457662582
Loss at iteration 380 : 0.015124661847949028
Loss at iteration 390 : 0.02005826309323311
Loss at iteration 400 : 0.01317634992301464
Loss at iteration 410 : 0.019704103469848633
Loss at iteration 420 : 0.015487036667764187
Loss at iteration 430 : 0.028098244220018387
Loss at iteration 440 : 0.01644379273056984
Loss at iteration 450 : 0.03507102653384209
Loss at iteration 460 : 0.014484032057225704
Loss at iteration 470 : 0.01585371606051922
Loss at iteration 480 : 0.027076123282313347
Loss at iteration 490 : 0.017986390739679337
Loss at iteration 500 : 0.01906021684408188
Loss at iteration 510 : 0.03507937118411064
Loss at iteration 520 : 0.018173811957240105
Loss at iteration 530 : 0.03594306483864784
Loss at iteration 540 : 0.016448035836219788
Loss at iteration 550 : 0.019162433221936226
Loss at iteration 560 : 0.027353735640645027
Loss at iteration 570 : 0.024559050798416138
Loss at iteration 580 : 0.041675716638565063
Loss at iteration 590 : 0.017647098749876022
Loss at iteration 600 : 0.02493981458246708
Loss at iteration 610 : 0.014806817285716534
Loss at iteration 620 : 0.027128778398036957
Loss at iteration 630 : 0.017110515385866165
Loss at iteration 640 : 0.01632780395448208
Loss at iteration 650 : 0.03350894898176193
Loss at iteration 660 : 0.022130317986011505
Loss at iteration 670 : 0.025244006887078285
Loss at iteration 680 : 0.014961186796426773
Loss at iteration 690 : 0.01733359321951866
Loss at iteration 700 : 0.011450759135186672
Loss at iteration 710 : 0.022384129464626312
Loss at iteration 720 : 0.021754097193479538
Loss at iteration 730 : 0.015333115123212337
Loss at iteration 740 : 0.019216010347008705
Loss at iteration 750 : 0.030270736664533615
Loss at iteration 760 : 0.020052354782819748
Loss at iteration 770 : 0.020901896059513092
Loss at iteration 780 : 0.023383229970932007
Loss at iteration 790 : 0.0210124459117651
Loss at iteration 800 : 0.032035596668720245
Loss at iteration 810 : 0.013512101024389267
Loss at iteration 820 : 0.027949463576078415
Loss at iteration 830 : 0.019026026129722595
Loss at iteration 840 : 0.010879157111048698
Loss at iteration 850 : 0.02211160771548748
Loss at iteration 860 : 0.015850026160478592
Loss at iteration 870 : 0.03398746997117996
Loss at iteration 880 : 0.021670900285243988
Loss at iteration 890 : 0.017638884484767914
Loss at iteration 900 : 0.011734245344996452
Loss at iteration 910 : 0.02850046008825302
Loss at iteration 920 : 0.011441819369792938
Loss at iteration 930 : 0.019763080403208733
Loss at iteration 940 : 0.019359352067112923
Loss at iteration 950 : 0.02083009108901024
Loss at iteration 960 : 0.018685365095734596
Loss at iteration 970 : 0.011540954932570457
Loss at iteration 980 : 0.015551859512925148
Loss at iteration 990 : 0.020993687212467194
Loss at iteration 1000 : 0.03052450343966484
Loss at iteration 1010 : 0.031553592532873154
Loss at iteration 1020 : 0.035953402519226074
Loss at iteration 1030 : 0.014724134467542171
Loss at iteration 1040 : 0.03483398258686066
Loss at iteration 1050 : 0.016354424878954887
Loss at iteration 1060 : 0.03286329656839371
Loss at iteration 1070 : 0.024166220799088478
Loss at iteration 1080 : 0.01931185834109783
Loss at iteration 1090 : 0.01450614258646965
Loss at iteration 1100 : 0.01565549336373806
Loss at iteration 1110 : 0.012775588780641556
Loss at iteration 1120 : 0.02185734733939171
Loss at iteration 1130 : 0.02353859320282936
Loss at iteration 1140 : 0.0314408615231514
Loss at iteration 1150 : 0.030820000916719437
Loss at iteration 1160 : 0.017636463046073914
Loss at iteration 1170 : 0.02934662625193596
Loss at iteration 1180 : 0.019411515444517136
Loss at iteration 1190 : 0.014326299540698528
Loss at iteration 1200 : 0.019140642136335373
Loss at iteration 1210 : 0.016605999320745468
The SSIM Value is: 0.8006001114845276
The PSNR Value is: 18.810057894388834
the epoch is: 103
Loss at iteration 10 : 0.01947464793920517
Loss at iteration 20 : 0.014471037313342094
Loss at iteration 30 : 0.020019223913550377
Loss at iteration 40 : 0.03495325148105621
Loss at iteration 50 : 0.01322214212268591
Loss at iteration 60 : 0.034616388380527496
Loss at iteration 70 : 0.022879451513290405
Loss at iteration 80 : 0.011392239481210709
Loss at iteration 90 : 0.029979659244418144
Loss at iteration 100 : 0.018675383180379868
Loss at iteration 110 : 0.014016656205058098
Loss at iteration 120 : 0.013230767101049423
Loss at iteration 130 : 0.02554761804640293
Loss at iteration 140 : 0.015733394771814346
Loss at iteration 150 : 0.019899901002645493
Loss at iteration 160 : 0.01439796481281519
Loss at iteration 170 : 0.014091936871409416
Loss at iteration 180 : 0.0169384628534317
Loss at iteration 190 : 0.025184333324432373
Loss at iteration 200 : 0.02478952147066593
Loss at iteration 210 : 0.0210488922894001
Loss at iteration 220 : 0.009930727072060108
Loss at iteration 230 : 0.020468080416321754
Loss at iteration 240 : 0.01705123484134674
Loss at iteration 250 : 0.01726953685283661
Loss at iteration 260 : 0.017398089170455933
Loss at iteration 270 : 0.02524358034133911
Loss at iteration 280 : 0.015539026819169521
Loss at iteration 290 : 0.0362224280834198
Loss at iteration 300 : 0.011916961520910263
Loss at iteration 310 : 0.020562995225191116
Loss at iteration 320 : 0.04167409986257553
Loss at iteration 330 : 0.01696203276515007
Loss at iteration 340 : 0.026216603815555573
Loss at iteration 350 : 0.021850086748600006
Loss at iteration 360 : 0.014883697032928467
Loss at iteration 370 : 0.014523802325129509
Loss at iteration 380 : 0.013552569784224033
Loss at iteration 390 : 0.020642779767513275
Loss at iteration 400 : 0.02365081198513508
Loss at iteration 410 : 0.03209388256072998
Loss at iteration 420 : 0.01775730401277542
Loss at iteration 430 : 0.01867949590086937
Loss at iteration 440 : 0.019961850717663765
Loss at iteration 450 : 0.020654134452342987
Loss at iteration 460 : 0.02036658301949501
Loss at iteration 470 : 0.0251489095389843
Loss at iteration 480 : 0.020300641655921936
Loss at iteration 490 : 0.01432210486382246
Loss at iteration 500 : 0.0261126309633255
Loss at iteration 510 : 0.017672646790742874
Loss at iteration 520 : 0.01450878195464611
Loss at iteration 530 : 0.024303991347551346
Loss at iteration 540 : 0.01699896715581417
Loss at iteration 550 : 0.01849675178527832
Loss at iteration 560 : 0.017342019826173782
Loss at iteration 570 : 0.02759730815887451
Loss at iteration 580 : 0.01177715789526701
Loss at iteration 590 : 0.018149342387914658
Loss at iteration 600 : 0.016046805307269096
Loss at iteration 610 : 0.01266611646860838
Loss at iteration 620 : 0.02540215477347374
Loss at iteration 630 : 0.018599018454551697
Loss at iteration 640 : 0.019184067845344543
Loss at iteration 650 : 0.016019437462091446
Loss at iteration 660 : 0.0266408771276474
Loss at iteration 670 : 0.027023836970329285
Loss at iteration 680 : 0.025472350418567657
Loss at iteration 690 : 0.026783965528011322
Loss at iteration 700 : 0.03472764045000076
Loss at iteration 710 : 0.027756601572036743
Loss at iteration 720 : 0.01805111952126026
Loss at iteration 730 : 0.029599949717521667
Loss at iteration 740 : 0.018567632883787155
Loss at iteration 750 : 0.0236596018075943
Loss at iteration 760 : 0.01347162015736103
Loss at iteration 770 : 0.019886460155248642
Loss at iteration 780 : 0.029912713915109634
Loss at iteration 790 : 0.019392166286706924
Loss at iteration 800 : 0.02310260757803917
Loss at iteration 810 : 0.015363287180662155
Loss at iteration 820 : 0.03510008379817009
Loss at iteration 830 : 0.019086578860878944
Loss at iteration 840 : 0.021760355681180954
Loss at iteration 850 : 0.01926008053123951
Loss at iteration 860 : 0.011961938813328743
Loss at iteration 870 : 0.024638677015900612
Loss at iteration 880 : 0.022347839549183846
Loss at iteration 890 : 0.014033393934369087
Loss at iteration 900 : 0.021114757284522057
Loss at iteration 910 : 0.02065086178481579
Loss at iteration 920 : 0.025356974452733994
Loss at iteration 930 : 0.019892588257789612
Loss at iteration 940 : 0.01119143795222044
Loss at iteration 950 : 0.02143784984946251
Loss at iteration 960 : 0.023890100419521332
Loss at iteration 970 : 0.014618290588259697
Loss at iteration 980 : 0.024401739239692688
Loss at iteration 990 : 0.033168863505125046
Loss at iteration 1000 : 0.010092712938785553
Loss at iteration 1010 : 0.01647510938346386
Loss at iteration 1020 : 0.01624344289302826
Loss at iteration 1030 : 0.02340725064277649
Loss at iteration 1040 : 0.022975826635956764
Loss at iteration 1050 : 0.02382834441959858
Loss at iteration 1060 : 0.015542002394795418
Loss at iteration 1070 : 0.015222158282995224
Loss at iteration 1080 : 0.032278355211019516
Loss at iteration 1090 : 0.016632825136184692
Loss at iteration 1100 : 0.020934652537107468
Loss at iteration 1110 : 0.017225254327058792
Loss at iteration 1120 : 0.023078814148902893
Loss at iteration 1130 : 0.01964668184518814
Loss at iteration 1140 : 0.014138531871140003
Loss at iteration 1150 : 0.0175020769238472
Loss at iteration 1160 : 0.01719067618250847
Loss at iteration 1170 : 0.021688925102353096
Loss at iteration 1180 : 0.03157270699739456
Loss at iteration 1190 : 0.010834041982889175
Loss at iteration 1200 : 0.013765159994363785
Loss at iteration 1210 : 0.017783448100090027
The SSIM Value is: 0.8001550873120625
The PSNR Value is: 18.706941032409667
the epoch is: 104
Loss at iteration 10 : 0.026027273386716843
Loss at iteration 20 : 0.022065021097660065
Loss at iteration 30 : 0.01293705403804779
Loss at iteration 40 : 0.03253427520394325
Loss at iteration 50 : 0.019689258188009262
Loss at iteration 60 : 0.020875288173556328
Loss at iteration 70 : 0.01719113625586033
Loss at iteration 80 : 0.016091514378786087
Loss at iteration 90 : 0.02794976346194744
Loss at iteration 100 : 0.023030739277601242
Loss at iteration 110 : 0.025969576090574265
Loss at iteration 120 : 0.01934201270341873
Loss at iteration 130 : 0.014395004138350487
Loss at iteration 140 : 0.02181222289800644
Loss at iteration 150 : 0.0200662761926651
Loss at iteration 160 : 0.017386138439178467
Loss at iteration 170 : 0.018826033920049667
Loss at iteration 180 : 0.01009409874677658
Loss at iteration 190 : 0.029163705185055733
Loss at iteration 200 : 0.02876540645956993
Loss at iteration 210 : 0.024583417922258377
Loss at iteration 220 : 0.030238812789320946
Loss at iteration 230 : 0.021535996347665787
Loss at iteration 240 : 0.02158576250076294
Loss at iteration 250 : 0.021991487592458725
Loss at iteration 260 : 0.015863170847296715
Loss at iteration 270 : 0.011358778923749924
Loss at iteration 280 : 0.015382746234536171
Loss at iteration 290 : 0.01831251010298729
Loss at iteration 300 : 0.015220859088003635
Loss at iteration 310 : 0.013485919684171677
Loss at iteration 320 : 0.014077496714890003
Loss at iteration 330 : 0.023369118571281433
Loss at iteration 340 : 0.025765370577573776
Loss at iteration 350 : 0.017458446323871613
Loss at iteration 360 : 0.02294500172138214
Loss at iteration 370 : 0.02150520123541355
Loss at iteration 380 : 0.013411641120910645
Loss at iteration 390 : 0.021156644448637962
Loss at iteration 400 : 0.015291878953576088
Loss at iteration 410 : 0.025360722094774246
Loss at iteration 420 : 0.020378878340125084
Loss at iteration 430 : 0.02022867277264595
Loss at iteration 440 : 0.019163290038704872
Loss at iteration 450 : 0.016867725178599358
Loss at iteration 460 : 0.018085302785038948
Loss at iteration 470 : 0.026260096579790115
Loss at iteration 480 : 0.016660861670970917
Loss at iteration 490 : 0.01308509148657322
Loss at iteration 500 : 0.02121363766491413
Loss at iteration 510 : 0.02520575374364853
Loss at iteration 520 : 0.022272730246186256
Loss at iteration 530 : 0.016668029129505157
Loss at iteration 540 : 0.017919376492500305
Loss at iteration 550 : 0.027952689677476883
Loss at iteration 560 : 0.016144419088959694
Loss at iteration 570 : 0.019045980647206306
Loss at iteration 580 : 0.015283187851309776
Loss at iteration 590 : 0.014778787270188332
Loss at iteration 600 : 0.014207599684596062
Loss at iteration 610 : 0.018674934282898903
Loss at iteration 620 : 0.016700368374586105
Loss at iteration 630 : 0.03274045139551163
Loss at iteration 640 : 0.024026211351156235
Loss at iteration 650 : 0.02394559234380722
Loss at iteration 660 : 0.01958508789539337
Loss at iteration 670 : 0.02226199395954609
Loss at iteration 680 : 0.024373061954975128
Loss at iteration 690 : 0.03963502123951912
Loss at iteration 700 : 0.01836661621928215
Loss at iteration 710 : 0.03475969284772873
Loss at iteration 720 : 0.017582764849066734
Loss at iteration 730 : 0.029200812801718712
Loss at iteration 740 : 0.017746295779943466
Loss at iteration 750 : 0.03905584663152695
Loss at iteration 760 : 0.017365165054798126
Loss at iteration 770 : 0.02584008127450943
Loss at iteration 780 : 0.023261897265911102
Loss at iteration 790 : 0.02201167121529579
Loss at iteration 800 : 0.024182014167308807
Loss at iteration 810 : 0.026422835886478424
Loss at iteration 820 : 0.018422670662403107
Loss at iteration 830 : 0.023362766951322556
Loss at iteration 840 : 0.023215265944600105
Loss at iteration 850 : 0.017533663660287857
Loss at iteration 860 : 0.011333780363202095
Loss at iteration 870 : 0.02143188938498497
Loss at iteration 880 : 0.024595703929662704
Loss at iteration 890 : 0.018257517367601395
Loss at iteration 900 : 0.012445507571101189
Loss at iteration 910 : 0.026286449283361435
Loss at iteration 920 : 0.04585916921496391
Loss at iteration 930 : 0.023705320432782173
Loss at iteration 940 : 0.021029170602560043
Loss at iteration 950 : 0.016894269734621048
Loss at iteration 960 : 0.0274089016020298
Loss at iteration 970 : 0.02219148725271225
Loss at iteration 980 : 0.030143264681100845
Loss at iteration 990 : 0.019206998869776726
Loss at iteration 1000 : 0.01000918634235859
Loss at iteration 1010 : 0.01879904977977276
Loss at iteration 1020 : 0.03156981244683266
Loss at iteration 1030 : 0.023827893659472466
Loss at iteration 1040 : 0.02435551956295967
Loss at iteration 1050 : 0.0262138769030571
Loss at iteration 1060 : 0.012867984361946583
Loss at iteration 1070 : 0.021737614646553993
Loss at iteration 1080 : 0.02633475512266159
Loss at iteration 1090 : 0.012865766882896423
Loss at iteration 1100 : 0.012204209342598915
Loss at iteration 1110 : 0.02224895916879177
Loss at iteration 1120 : 0.014376870356500149
Loss at iteration 1130 : 0.01702897995710373
Loss at iteration 1140 : 0.01549459621310234
Loss at iteration 1150 : 0.029187027364969254
Loss at iteration 1160 : 0.03327428549528122
Loss at iteration 1170 : 0.02015189826488495
Loss at iteration 1180 : 0.01488657295703888
Loss at iteration 1190 : 0.0363272987306118
Loss at iteration 1200 : 0.021164173260331154
Loss at iteration 1210 : 0.023446474224328995
The SSIM Value is: 0.7991404016812642
The PSNR Value is: 19.181815592447915
the epoch is: 105
Loss at iteration 10 : 0.015460403636097908
Loss at iteration 20 : 0.019700275734066963
Loss at iteration 30 : 0.03505915030837059
Loss at iteration 40 : 0.013708304613828659
Loss at iteration 50 : 0.012498962692916393
Loss at iteration 60 : 0.020247623324394226
Loss at iteration 70 : 0.02411840856075287
Loss at iteration 80 : 0.02430134266614914
Loss at iteration 90 : 0.015430549159646034
Loss at iteration 100 : 0.017175164073705673
Loss at iteration 110 : 0.011920174583792686
Loss at iteration 120 : 0.02096722275018692
Loss at iteration 130 : 0.031577885150909424
Loss at iteration 140 : 0.025501511991024017
Loss at iteration 150 : 0.01752028614282608
Loss at iteration 160 : 0.020051531493663788
Loss at iteration 170 : 0.024379070848226547
Loss at iteration 180 : 0.014744903892278671
Loss at iteration 190 : 0.021503007039427757
Loss at iteration 200 : 0.0323789156973362
Loss at iteration 210 : 0.01890122890472412
Loss at iteration 220 : 0.02309698611497879
Loss at iteration 230 : 0.01804284192621708
Loss at iteration 240 : 0.022957149893045425
Loss at iteration 250 : 0.017054483294487
Loss at iteration 260 : 0.01448308676481247
Loss at iteration 270 : 0.02705923467874527
Loss at iteration 280 : 0.024473633617162704
Loss at iteration 290 : 0.02304433286190033
Loss at iteration 300 : 0.014202596619725227
Loss at iteration 310 : 0.024777425453066826
Loss at iteration 320 : 0.015845399349927902
Loss at iteration 330 : 0.019887078553438187
Loss at iteration 340 : 0.01216665469110012
Loss at iteration 350 : 0.027841875329613686
Loss at iteration 360 : 0.015178675763309002
Loss at iteration 370 : 0.024946171790361404
Loss at iteration 380 : 0.019445443525910378
Loss at iteration 390 : 0.020308904349803925
Loss at iteration 400 : 0.017200633883476257
Loss at iteration 410 : 0.01741357147693634
Loss at iteration 420 : 0.018272820860147476
Loss at iteration 430 : 0.014674864709377289
Loss at iteration 440 : 0.02255193516612053
Loss at iteration 450 : 0.014058691449463367
Loss at iteration 460 : 0.0221664160490036
Loss at iteration 470 : 0.026129476726055145
Loss at iteration 480 : 0.02589133009314537
Loss at iteration 490 : 0.018574673682451248
Loss at iteration 500 : 0.01593344286084175
Loss at iteration 510 : 0.016253259032964706
Loss at iteration 520 : 0.02241307683289051
Loss at iteration 530 : 0.011462640017271042
Loss at iteration 540 : 0.016977911815047264
Loss at iteration 550 : 0.028961103409528732
Loss at iteration 560 : 0.021878432482481003
Loss at iteration 570 : 0.0470099151134491
Loss at iteration 580 : 0.01851496659219265
Loss at iteration 590 : 0.030094772577285767
Loss at iteration 600 : 0.01611212268471718
Loss at iteration 610 : 0.014430427923798561
Loss at iteration 620 : 0.014711294323205948
Loss at iteration 630 : 0.015325265005230904
Loss at iteration 640 : 0.01991945691406727
Loss at iteration 650 : 0.0223870649933815
Loss at iteration 660 : 0.051095571368932724
Loss at iteration 670 : 0.023088928312063217
Loss at iteration 680 : 0.016693338751792908
Loss at iteration 690 : 0.020314564928412437
Loss at iteration 700 : 0.024497024714946747
Loss at iteration 710 : 0.01875733770430088
Loss at iteration 720 : 0.011372392997145653
Loss at iteration 730 : 0.014208940789103508
Loss at iteration 740 : 0.015535611659288406
Loss at iteration 750 : 0.013782773166894913
Loss at iteration 760 : 0.02048269286751747
Loss at iteration 770 : 0.01883765310049057
Loss at iteration 780 : 0.02365701273083687
Loss at iteration 790 : 0.021108519285917282
Loss at iteration 800 : 0.01674606092274189
Loss at iteration 810 : 0.018404191359877586
Loss at iteration 820 : 0.04047089070081711
Loss at iteration 830 : 0.016076955944299698
Loss at iteration 840 : 0.014753894880414009
Loss at iteration 850 : 0.022629406303167343
Loss at iteration 860 : 0.023560062050819397
Loss at iteration 870 : 0.017143255099654198
Loss at iteration 880 : 0.0151657834649086
Loss at iteration 890 : 0.016388671472668648
Loss at iteration 900 : 0.030125245451927185
Loss at iteration 910 : 0.03751416504383087
Loss at iteration 920 : 0.012298408895730972
Loss at iteration 930 : 0.02401052787899971
Loss at iteration 940 : 0.0219663605093956
Loss at iteration 950 : 0.018877029418945312
Loss at iteration 960 : 0.013132693246006966
Loss at iteration 970 : 0.03922654688358307
Loss at iteration 980 : 0.012374824844300747
Loss at iteration 990 : 0.026260703802108765
Loss at iteration 1000 : 0.035901010036468506
Loss at iteration 1010 : 0.02416739985346794
Loss at iteration 1020 : 0.017641525715589523
Loss at iteration 1030 : 0.017839772626757622
Loss at iteration 1040 : 0.02419222891330719
Loss at iteration 1050 : 0.01964787021279335
Loss at iteration 1060 : 0.014035100117325783
Loss at iteration 1070 : 0.017291411757469177
Loss at iteration 1080 : 0.02359895408153534
Loss at iteration 1090 : 0.029878580942749977
Loss at iteration 1100 : 0.021602820605039597
Loss at iteration 1110 : 0.017475146800279617
Loss at iteration 1120 : 0.01887206733226776
Loss at iteration 1130 : 0.01878688856959343
Loss at iteration 1140 : 0.03059592843055725
Loss at iteration 1150 : 0.015063609927892685
Loss at iteration 1160 : 0.01672060787677765
Loss at iteration 1170 : 0.01916017383337021
Loss at iteration 1180 : 0.021119950339198112
Loss at iteration 1190 : 0.015048976056277752
Loss at iteration 1200 : 0.017269626259803772
Loss at iteration 1210 : 0.014257790520787239
The SSIM Value is: 0.7949867208798727
The PSNR Value is: 18.583181381225586
the epoch is: 106
Loss at iteration 10 : 0.01818554848432541
Loss at iteration 20 : 0.021342162042856216
Loss at iteration 30 : 0.014740672893822193
Loss at iteration 40 : 0.01386258564889431
Loss at iteration 50 : 0.01844630390405655
Loss at iteration 60 : 0.015599561855196953
Loss at iteration 70 : 0.01845412701368332
Loss at iteration 80 : 0.01549314521253109
Loss at iteration 90 : 0.009847326204180717
Loss at iteration 100 : 0.01596895232796669
Loss at iteration 110 : 0.0141957588493824
Loss at iteration 120 : 0.016656240448355675
Loss at iteration 130 : 0.014090300537645817
Loss at iteration 140 : 0.027963608503341675
Loss at iteration 150 : 0.04031684249639511
Loss at iteration 160 : 0.010489416308701038
Loss at iteration 170 : 0.023302188143134117
Loss at iteration 180 : 0.012673532590270042
Loss at iteration 190 : 0.01331259123980999
Loss at iteration 200 : 0.02578364685177803
Loss at iteration 210 : 0.022264746949076653
Loss at iteration 220 : 0.017004188150167465
Loss at iteration 230 : 0.023148175328969955
Loss at iteration 240 : 0.028199031949043274
Loss at iteration 250 : 0.01553661935031414
Loss at iteration 260 : 0.01924833096563816
Loss at iteration 270 : 0.012194272130727768
Loss at iteration 280 : 0.02124795690178871
Loss at iteration 290 : 0.019192149862647057
Loss at iteration 300 : 0.02223811112344265
Loss at iteration 310 : 0.020194856449961662
Loss at iteration 320 : 0.033171430230140686
Loss at iteration 330 : 0.026738256216049194
Loss at iteration 340 : 0.03012900799512863
Loss at iteration 350 : 0.01444484107196331
Loss at iteration 360 : 0.02274462580680847
Loss at iteration 370 : 0.014348801225423813
Loss at iteration 380 : 0.02026965841650963
Loss at iteration 390 : 0.02975141629576683
Loss at iteration 400 : 0.02959136664867401
Loss at iteration 410 : 0.03241606429219246
Loss at iteration 420 : 0.020393026992678642
Loss at iteration 430 : 0.018060682341456413
Loss at iteration 440 : 0.021110769361257553
Loss at iteration 450 : 0.015417755581438541
Loss at iteration 460 : 0.0145545220002532
Loss at iteration 470 : 0.012205203995108604
Loss at iteration 480 : 0.018744181841611862
Loss at iteration 490 : 0.01910417154431343
Loss at iteration 500 : 0.016700733453035355
Loss at iteration 510 : 0.02313864231109619
Loss at iteration 520 : 0.02164328843355179
Loss at iteration 530 : 0.01786360889673233
Loss at iteration 540 : 0.014280554838478565
Loss at iteration 550 : 0.014128582552075386
Loss at iteration 560 : 0.02023262158036232
Loss at iteration 570 : 0.02195526659488678
Loss at iteration 580 : 0.02547307498753071
Loss at iteration 590 : 0.026897182688117027
Loss at iteration 600 : 0.015758834779262543
Loss at iteration 610 : 0.02161116525530815
Loss at iteration 620 : 0.028080446645617485
Loss at iteration 630 : 0.026801083236932755
Loss at iteration 640 : 0.01299997977912426
Loss at iteration 650 : 0.012155035510659218
Loss at iteration 660 : 0.016145797446370125
Loss at iteration 670 : 0.03168940544128418
Loss at iteration 680 : 0.02640034258365631
Loss at iteration 690 : 0.020297598093748093
Loss at iteration 700 : 0.013608129695057869
Loss at iteration 710 : 0.014245348982512951
Loss at iteration 720 : 0.013318762183189392
Loss at iteration 730 : 0.0274080540984869
Loss at iteration 740 : 0.01880183070898056
Loss at iteration 750 : 0.021092671900987625
Loss at iteration 760 : 0.017263449728488922
Loss at iteration 770 : 0.027187392115592957
Loss at iteration 780 : 0.019765552133321762
Loss at iteration 790 : 0.02427590638399124
Loss at iteration 800 : 0.013412992469966412
Loss at iteration 810 : 0.019097914919257164
Loss at iteration 820 : 0.019858304411172867
Loss at iteration 830 : 0.019649535417556763
Loss at iteration 840 : 0.01743137836456299
Loss at iteration 850 : 0.020741071552038193
Loss at iteration 860 : 0.03552776575088501
Loss at iteration 870 : 0.02467276155948639
Loss at iteration 880 : 0.015087783336639404
Loss at iteration 890 : 0.010310040786862373
Loss at iteration 900 : 0.028303345665335655
Loss at iteration 910 : 0.013890242204070091
Loss at iteration 920 : 0.029288243502378464
Loss at iteration 930 : 0.02042441815137863
Loss at iteration 940 : 0.016193673014640808
Loss at iteration 950 : 0.013218216598033905
Loss at iteration 960 : 0.023112140595912933
Loss at iteration 970 : 0.01739264279603958
Loss at iteration 980 : 0.02022355981171131
Loss at iteration 990 : 0.01746930181980133
Loss at iteration 1000 : 0.020681025460362434
Loss at iteration 1010 : 0.019732195883989334
Loss at iteration 1020 : 0.019480017945170403
Loss at iteration 1030 : 0.02062316983938217
Loss at iteration 1040 : 0.025897787883877754
Loss at iteration 1050 : 0.01667792722582817
Loss at iteration 1060 : 0.021204477176070213
Loss at iteration 1070 : 0.016415338963270187
Loss at iteration 1080 : 0.02640574984252453
Loss at iteration 1090 : 0.021044759079813957
Loss at iteration 1100 : 0.025510627776384354
Loss at iteration 1110 : 0.021520618349313736
Loss at iteration 1120 : 0.020962171256542206
Loss at iteration 1130 : 0.013362751342356205
Loss at iteration 1140 : 0.02125842496752739
Loss at iteration 1150 : 0.014111967757344246
Loss at iteration 1160 : 0.0230458565056324
Loss at iteration 1170 : 0.015391535125672817
Loss at iteration 1180 : 0.03355661779642105
Loss at iteration 1190 : 0.01949717104434967
Loss at iteration 1200 : 0.02729668654501438
Loss at iteration 1210 : 0.017857685685157776
The SSIM Value is: 0.8021583159764608
The PSNR Value is: 18.96956310272217
the epoch is: 107
Loss at iteration 10 : 0.014852598309516907
Loss at iteration 20 : 0.017876725643873215
Loss at iteration 30 : 0.023554272949695587
Loss at iteration 40 : 0.02120964042842388
Loss at iteration 50 : 0.02360708639025688
Loss at iteration 60 : 0.025190996006131172
Loss at iteration 70 : 0.02690056897699833
Loss at iteration 80 : 0.01949489489197731
Loss at iteration 90 : 0.01527244783937931
Loss at iteration 100 : 0.03231436014175415
Loss at iteration 110 : 0.016818463802337646
Loss at iteration 120 : 0.031374700367450714
Loss at iteration 130 : 0.011182519607245922
Loss at iteration 140 : 0.01287157740443945
Loss at iteration 150 : 0.014544384554028511
Loss at iteration 160 : 0.028066717088222504
Loss at iteration 170 : 0.020550895482301712
Loss at iteration 180 : 0.020084818825125694
Loss at iteration 190 : 0.036628223955631256
Loss at iteration 200 : 0.03678594529628754
Loss at iteration 210 : 0.01851346716284752
Loss at iteration 220 : 0.012770988047122955
Loss at iteration 230 : 0.013920053839683533
Loss at iteration 240 : 0.0312584713101387
Loss at iteration 250 : 0.024266989901661873
Loss at iteration 260 : 0.021514542400836945
Loss at iteration 270 : 0.021291550248861313
Loss at iteration 280 : 0.02481137402355671
Loss at iteration 290 : 0.017971687018871307
Loss at iteration 300 : 0.03462793678045273
Loss at iteration 310 : 0.021592654287815094
Loss at iteration 320 : 0.0337885245680809
Loss at iteration 330 : 0.016115546226501465
Loss at iteration 340 : 0.01384248211979866
Loss at iteration 350 : 0.0250076986849308
Loss at iteration 360 : 0.021165035665035248
Loss at iteration 370 : 0.016660397872328758
Loss at iteration 380 : 0.017522212117910385
Loss at iteration 390 : 0.02070610597729683
Loss at iteration 400 : 0.029739761725068092
Loss at iteration 410 : 0.01668957620859146
Loss at iteration 420 : 0.0170737374573946
Loss at iteration 430 : 0.022477339953184128
Loss at iteration 440 : 0.02469373494386673
Loss at iteration 450 : 0.017680730670690536
Loss at iteration 460 : 0.03073645383119583
Loss at iteration 470 : 0.026668021455407143
Loss at iteration 480 : 0.01073434017598629
Loss at iteration 490 : 0.020471401512622833
Loss at iteration 500 : 0.03776220604777336
Loss at iteration 510 : 0.027028672397136688
Loss at iteration 520 : 0.03136204183101654
Loss at iteration 530 : 0.01684494875371456
Loss at iteration 540 : 0.017197009176015854
Loss at iteration 550 : 0.014987225644290447
Loss at iteration 560 : 0.022179633378982544
Loss at iteration 570 : 0.014461752027273178
Loss at iteration 580 : 0.024720946326851845
Loss at iteration 590 : 0.018347900360822678
Loss at iteration 600 : 0.02772432751953602
Loss at iteration 610 : 0.02333306148648262
Loss at iteration 620 : 0.02206699550151825
Loss at iteration 630 : 0.02726524882018566
Loss at iteration 640 : 0.022453850135207176
Loss at iteration 650 : 0.02353617548942566
Loss at iteration 660 : 0.022161105647683144
Loss at iteration 670 : 0.023138564079999924
Loss at iteration 680 : 0.01834437996149063
Loss at iteration 690 : 0.01959438994526863
Loss at iteration 700 : 0.0249955914914608
Loss at iteration 710 : 0.01760929822921753
Loss at iteration 720 : 0.01633535698056221
Loss at iteration 730 : 0.01839609257876873
Loss at iteration 740 : 0.01314681489020586
Loss at iteration 750 : 0.022680338472127914
Loss at iteration 760 : 0.023174596950411797
Loss at iteration 770 : 0.023413067683577538
Loss at iteration 780 : 0.016222767531871796
Loss at iteration 790 : 0.01426050066947937
Loss at iteration 800 : 0.010474066250026226
Loss at iteration 810 : 0.02580675110220909
Loss at iteration 820 : 0.018070990219712257
Loss at iteration 830 : 0.016326459124684334
Loss at iteration 840 : 0.0313616581261158
Loss at iteration 850 : 0.03114728443324566
Loss at iteration 860 : 0.015422433614730835
Loss at iteration 870 : 0.027262862771749496
Loss at iteration 880 : 0.019951358437538147
Loss at iteration 890 : 0.014269344508647919
Loss at iteration 900 : 0.029193010181188583
Loss at iteration 910 : 0.0276301521807909
Loss at iteration 920 : 0.016982126981019974
Loss at iteration 930 : 0.021172216162085533
Loss at iteration 940 : 0.015577764250338078
Loss at iteration 950 : 0.020707188174128532
Loss at iteration 960 : 0.01321873627603054
Loss at iteration 970 : 0.014733457006514072
Loss at iteration 980 : 0.029607951641082764
Loss at iteration 990 : 0.02071063220500946
Loss at iteration 1000 : 0.019095448777079582
Loss at iteration 1010 : 0.028344785794615746
Loss at iteration 1020 : 0.019421137869358063
Loss at iteration 1030 : 0.02634645812213421
Loss at iteration 1040 : 0.023969465866684914
Loss at iteration 1050 : 0.018655866384506226
Loss at iteration 1060 : 0.01576358824968338
Loss at iteration 1070 : 0.015378312207758427
Loss at iteration 1080 : 0.01742776855826378
Loss at iteration 1090 : 0.024767057970166206
Loss at iteration 1100 : 0.014963921159505844
Loss at iteration 1110 : 0.025601431727409363
Loss at iteration 1120 : 0.02022819221019745
Loss at iteration 1130 : 0.027038000524044037
Loss at iteration 1140 : 0.019503362476825714
Loss at iteration 1150 : 0.01947142742574215
Loss at iteration 1160 : 0.01220432948321104
Loss at iteration 1170 : 0.01696019060909748
Loss at iteration 1180 : 0.015361376106739044
Loss at iteration 1190 : 0.01981903240084648
Loss at iteration 1200 : 0.01990538090467453
Loss at iteration 1210 : 0.026811260730028152
The SSIM Value is: 0.7971300959587098
The PSNR Value is: 18.657059097290038
the epoch is: 108
Loss at iteration 10 : 0.011254988610744476
Loss at iteration 20 : 0.028040628880262375
Loss at iteration 30 : 0.017840486019849777
Loss at iteration 40 : 0.013205097056925297
Loss at iteration 50 : 0.023263374343514442
Loss at iteration 60 : 0.024881649762392044
Loss at iteration 70 : 0.01933373510837555
Loss at iteration 80 : 0.025659959763288498
Loss at iteration 90 : 0.017767006531357765
Loss at iteration 100 : 0.018028300255537033
Loss at iteration 110 : 0.01959397830069065
Loss at iteration 120 : 0.019521767273545265
Loss at iteration 130 : 0.03010617569088936
Loss at iteration 140 : 0.018306773155927658
Loss at iteration 150 : 0.012031406164169312
Loss at iteration 160 : 0.021059490740299225
Loss at iteration 170 : 0.01776459440588951
Loss at iteration 180 : 0.0290854312479496
Loss at iteration 190 : 0.013050740584731102
Loss at iteration 200 : 0.011210398748517036
Loss at iteration 210 : 0.022788425907492638
Loss at iteration 220 : 0.021768204867839813
Loss at iteration 230 : 0.029624590650200844
Loss at iteration 240 : 0.023170752450823784
Loss at iteration 250 : 0.014346219599246979
Loss at iteration 260 : 0.028605423867702484
Loss at iteration 270 : 0.02730330266058445
Loss at iteration 280 : 0.014545513316988945
Loss at iteration 290 : 0.013358714058995247
Loss at iteration 300 : 0.020881393924355507
Loss at iteration 310 : 0.01698160730302334
Loss at iteration 320 : 0.016652759164571762
Loss at iteration 330 : 0.013623722828924656
Loss at iteration 340 : 0.028606567531824112
Loss at iteration 350 : 0.016633620485663414
Loss at iteration 360 : 0.018755007535219193
Loss at iteration 370 : 0.018520137295126915
Loss at iteration 380 : 0.030757993459701538
Loss at iteration 390 : 0.04003368318080902
Loss at iteration 400 : 0.02862020954489708
Loss at iteration 410 : 0.03136460855603218
Loss at iteration 420 : 0.018342306837439537
Loss at iteration 430 : 0.022094514220952988
Loss at iteration 440 : 0.018263936042785645
Loss at iteration 450 : 0.017137795686721802
Loss at iteration 460 : 0.02154594659805298
Loss at iteration 470 : 0.012852059677243233
Loss at iteration 480 : 0.010369956493377686
Loss at iteration 490 : 0.025436779484152794
Loss at iteration 500 : 0.015831368044018745
Loss at iteration 510 : 0.024338986724615097
Loss at iteration 520 : 0.017306232824921608
Loss at iteration 530 : 0.013692347332835197
Loss at iteration 540 : 0.0209987573325634
Loss at iteration 550 : 0.020254164934158325
Loss at iteration 560 : 0.018950553610920906
Loss at iteration 570 : 0.018989790230989456
Loss at iteration 580 : 0.018446484580636024
Loss at iteration 590 : 0.022043725475668907
Loss at iteration 600 : 0.02677595615386963
Loss at iteration 610 : 0.015152952633798122
Loss at iteration 620 : 0.017333924770355225
Loss at iteration 630 : 0.040026456117630005
Loss at iteration 640 : 0.023419996723532677
Loss at iteration 650 : 0.018779074773192406
Loss at iteration 660 : 0.02714744210243225
Loss at iteration 670 : 0.015457678586244583
Loss at iteration 680 : 0.023358948528766632
Loss at iteration 690 : 0.024509895592927933
Loss at iteration 700 : 0.031055891886353493
Loss at iteration 710 : 0.014727327041327953
Loss at iteration 720 : 0.012996762059628963
Loss at iteration 730 : 0.018938828259706497
Loss at iteration 740 : 0.02066056802868843
Loss at iteration 750 : 0.01963430643081665
Loss at iteration 760 : 0.01577025093138218
Loss at iteration 770 : 0.01766025461256504
Loss at iteration 780 : 0.018936730921268463
Loss at iteration 790 : 0.027885006740689278
Loss at iteration 800 : 0.015286446548998356
Loss at iteration 810 : 0.031912267208099365
Loss at iteration 820 : 0.011609002016484737
Loss at iteration 830 : 0.02461209148168564
Loss at iteration 840 : 0.019934244453907013
Loss at iteration 850 : 0.032786861062049866
Loss at iteration 860 : 0.016027916222810745
Loss at iteration 870 : 0.01333348173648119
Loss at iteration 880 : 0.024995647370815277
Loss at iteration 890 : 0.01849472150206566
Loss at iteration 900 : 0.01746704988181591
Loss at iteration 910 : 0.020779559388756752
Loss at iteration 920 : 0.01848018914461136
Loss at iteration 930 : 0.013435563072562218
Loss at iteration 940 : 0.01765049621462822
Loss at iteration 950 : 0.014669043943285942
Loss at iteration 960 : 0.020914245396852493
Loss at iteration 970 : 0.017039258033037186
Loss at iteration 980 : 0.017590347677469254
Loss at iteration 990 : 0.02183634042739868
Loss at iteration 1000 : 0.02977525070309639
Loss at iteration 1010 : 0.019355442374944687
Loss at iteration 1020 : 0.046106621623039246
Loss at iteration 1030 : 0.02275187149643898
Loss at iteration 1040 : 0.021534284576773643
Loss at iteration 1050 : 0.01854950189590454
Loss at iteration 1060 : 0.018658431246876717
Loss at iteration 1070 : 0.019415007904171944
Loss at iteration 1080 : 0.015793099999427795
Loss at iteration 1090 : 0.021092567592859268
Loss at iteration 1100 : 0.01809186115860939
Loss at iteration 1110 : 0.024344079196453094
Loss at iteration 1120 : 0.017165031284093857
Loss at iteration 1130 : 0.027736131101846695
Loss at iteration 1140 : 0.010759701952338219
Loss at iteration 1150 : 0.019468938931822777
Loss at iteration 1160 : 0.027682524174451828
Loss at iteration 1170 : 0.026768222451210022
Loss at iteration 1180 : 0.028176933526992798
Loss at iteration 1190 : 0.02415924146771431
Loss at iteration 1200 : 0.020449504256248474
Loss at iteration 1210 : 0.021084044128656387
The SSIM Value is: 0.7981214642524719
The PSNR Value is: 18.941700172424316
the epoch is: 109
Loss at iteration 10 : 0.020710505545139313
Loss at iteration 20 : 0.01692269742488861
Loss at iteration 30 : 0.017173882573843002
Loss at iteration 40 : 0.037813980132341385
Loss at iteration 50 : 0.022106816992163658
Loss at iteration 60 : 0.028767595067620277
Loss at iteration 70 : 0.02309257537126541
Loss at iteration 80 : 0.018561091274023056
Loss at iteration 90 : 0.028206078335642815
Loss at iteration 100 : 0.026404473930597305
Loss at iteration 110 : 0.017126332968473434
Loss at iteration 120 : 0.010108626447618008
Loss at iteration 130 : 0.012843613512814045
Loss at iteration 140 : 0.014903394505381584
Loss at iteration 150 : 0.025142820551991463
Loss at iteration 160 : 0.014265256002545357
Loss at iteration 170 : 0.03242389112710953
Loss at iteration 180 : 0.015347272157669067
Loss at iteration 190 : 0.030562086030840874
Loss at iteration 200 : 0.015560276806354523
Loss at iteration 210 : 0.016307519748806953
Loss at iteration 220 : 0.020416054874658585
Loss at iteration 230 : 0.019809624180197716
Loss at iteration 240 : 0.016574395820498466
Loss at iteration 250 : 0.01866365410387516
Loss at iteration 260 : 0.013721475377678871
Loss at iteration 270 : 0.011176086962223053
Loss at iteration 280 : 0.01645369827747345
Loss at iteration 290 : 0.011392833665013313
Loss at iteration 300 : 0.029725518077611923
Loss at iteration 310 : 0.01577734760940075
Loss at iteration 320 : 0.022861097007989883
Loss at iteration 330 : 0.015994708985090256
Loss at iteration 340 : 0.01676296442747116
Loss at iteration 350 : 0.03598714619874954
Loss at iteration 360 : 0.01877528429031372
Loss at iteration 370 : 0.03865831717848778
Loss at iteration 380 : 0.022964123636484146
Loss at iteration 390 : 0.026860257610678673
Loss at iteration 400 : 0.025602523237466812
Loss at iteration 410 : 0.03685353323817253
Loss at iteration 420 : 0.02314288169145584
Loss at iteration 430 : 0.019611183553934097
Loss at iteration 440 : 0.012960175983607769
Loss at iteration 450 : 0.018492868170142174
Loss at iteration 460 : 0.021882036700844765
Loss at iteration 470 : 0.02367636188864708
Loss at iteration 480 : 0.029053471982479095
Loss at iteration 490 : 0.015896476805210114
Loss at iteration 500 : 0.014623560011386871
Loss at iteration 510 : 0.018921293318271637
Loss at iteration 520 : 0.016003474593162537
Loss at iteration 530 : 0.02089349366724491
Loss at iteration 540 : 0.020374290645122528
Loss at iteration 550 : 0.015192799270153046
Loss at iteration 560 : 0.02360316552221775
Loss at iteration 570 : 0.01382727362215519
Loss at iteration 580 : 0.025526167824864388
Loss at iteration 590 : 0.020016005262732506
Loss at iteration 600 : 0.02182520367205143
Loss at iteration 610 : 0.017722237855196
Loss at iteration 620 : 0.02580464631319046
Loss at iteration 630 : 0.02706889621913433
Loss at iteration 640 : 0.014028584584593773
Loss at iteration 650 : 0.019991345703601837
Loss at iteration 660 : 0.030327703803777695
Loss at iteration 670 : 0.013631518930196762
Loss at iteration 680 : 0.01616150513291359
Loss at iteration 690 : 0.010387623682618141
Loss at iteration 700 : 0.01704220473766327
Loss at iteration 710 : 0.026369936764240265
Loss at iteration 720 : 0.017613926902413368
Loss at iteration 730 : 0.021589025855064392
Loss at iteration 740 : 0.025405319407582283
Loss at iteration 750 : 0.021220222115516663
Loss at iteration 760 : 0.01875767484307289
Loss at iteration 770 : 0.011925697326660156
Loss at iteration 780 : 0.01074892096221447
Loss at iteration 790 : 0.014919476583600044
Loss at iteration 800 : 0.02880237065255642
Loss at iteration 810 : 0.017919303849339485
Loss at iteration 820 : 0.022290898486971855
Loss at iteration 830 : 0.01382226962596178
Loss at iteration 840 : 0.016178075224161148
Loss at iteration 850 : 0.013830105774104595
Loss at iteration 860 : 0.013349911198019981
Loss at iteration 870 : 0.02368992567062378
Loss at iteration 880 : 0.0202568918466568
Loss at iteration 890 : 0.022400107234716415
Loss at iteration 900 : 0.015816673636436462
Loss at iteration 910 : 0.023430000990629196
Loss at iteration 920 : 0.01848509907722473
Loss at iteration 930 : 0.03851615637540817
Loss at iteration 940 : 0.019617415964603424
Loss at iteration 950 : 0.024814888834953308
Loss at iteration 960 : 0.02357196807861328
Loss at iteration 970 : 0.020320340991020203
Loss at iteration 980 : 0.02231062948703766
Loss at iteration 990 : 0.024566441774368286
Loss at iteration 1000 : 0.028742216527462006
Loss at iteration 1010 : 0.02372179552912712
Loss at iteration 1020 : 0.019214201718568802
Loss at iteration 1030 : 0.012803402729332447
Loss at iteration 1040 : 0.022502925246953964
Loss at iteration 1050 : 0.01921396702528
Loss at iteration 1060 : 0.030433475971221924
Loss at iteration 1070 : 0.024151667952537537
Loss at iteration 1080 : 0.01412884145975113
Loss at iteration 1090 : 0.018932633101940155
Loss at iteration 1100 : 0.016388263553380966
Loss at iteration 1110 : 0.017404897138476372
Loss at iteration 1120 : 0.013729652389883995
Loss at iteration 1130 : 0.011558963917195797
Loss at iteration 1140 : 0.04554000496864319
Loss at iteration 1150 : 0.019040260463953018
Loss at iteration 1160 : 0.030060768127441406
Loss at iteration 1170 : 0.03377482667565346
Loss at iteration 1180 : 0.021467864513397217
Loss at iteration 1190 : 0.022984998300671577
Loss at iteration 1200 : 0.014371031895279884
Loss at iteration 1210 : 0.024653900414705276
The SSIM Value is: 0.8021632750829061
The PSNR Value is: 19.005594889322918
the epoch is: 110
Loss at iteration 10 : 0.02169010229408741
Loss at iteration 20 : 0.019654568284749985
Loss at iteration 30 : 0.01448383554816246
Loss at iteration 40 : 0.020464729517698288
Loss at iteration 50 : 0.03890428692102432
Loss at iteration 60 : 0.023151934146881104
Loss at iteration 70 : 0.029255706816911697
Loss at iteration 80 : 0.012680433690547943
Loss at iteration 90 : 0.008272356353700161
Loss at iteration 100 : 0.024940909817814827
Loss at iteration 110 : 0.016387101262807846
Loss at iteration 120 : 0.014393584802746773
Loss at iteration 130 : 0.027589716017246246
Loss at iteration 140 : 0.017886998131871223
Loss at iteration 150 : 0.030565170571208
Loss at iteration 160 : 0.031355682760477066
Loss at iteration 170 : 0.03229277580976486
Loss at iteration 180 : 0.016514889895915985
Loss at iteration 190 : 0.020846081897616386
Loss at iteration 200 : 0.023271825164556503
Loss at iteration 210 : 0.021225161850452423
Loss at iteration 220 : 0.0149071104824543
Loss at iteration 230 : 0.018977653235197067
Loss at iteration 240 : 0.027823325246572495
Loss at iteration 250 : 0.016818268224596977
Loss at iteration 260 : 0.04253365099430084
Loss at iteration 270 : 0.014977206476032734
Loss at iteration 280 : 0.022262442857027054
Loss at iteration 290 : 0.013429727405309677
Loss at iteration 300 : 0.02385556325316429
Loss at iteration 310 : 0.013245061039924622
Loss at iteration 320 : 0.013169461861252785
Loss at iteration 330 : 0.028576411306858063
Loss at iteration 340 : 0.008149171248078346
Loss at iteration 350 : 0.022814955562353134
Loss at iteration 360 : 0.013427495025098324
Loss at iteration 370 : 0.0236827339977026
Loss at iteration 380 : 0.016976360231637955
Loss at iteration 390 : 0.017151135951280594
Loss at iteration 400 : 0.013180186972022057
Loss at iteration 410 : 0.017078807577490807
Loss at iteration 420 : 0.020291423425078392
Loss at iteration 430 : 0.021915413439273834
Loss at iteration 440 : 0.017717059701681137
Loss at iteration 450 : 0.02303117886185646
Loss at iteration 460 : 0.01671488955616951
Loss at iteration 470 : 0.021000325679779053
Loss at iteration 480 : 0.01769249141216278
Loss at iteration 490 : 0.017597071826457977
Loss at iteration 500 : 0.018277065828442574
Loss at iteration 510 : 0.016587013378739357
Loss at iteration 520 : 0.026521803811192513
Loss at iteration 530 : 0.016963418573141098
Loss at iteration 540 : 0.01908097043633461
Loss at iteration 550 : 0.015531206503510475
Loss at iteration 560 : 0.013799842447042465
Loss at iteration 570 : 0.02626228705048561
Loss at iteration 580 : 0.017848515883088112
Loss at iteration 590 : 0.02121087536215782
Loss at iteration 600 : 0.022953305393457413
Loss at iteration 610 : 0.020557738840579987
Loss at iteration 620 : 0.021806960925459862
Loss at iteration 630 : 0.019381070509552956
Loss at iteration 640 : 0.021702904254198074
Loss at iteration 650 : 0.0216655433177948
Loss at iteration 660 : 0.016767684370279312
Loss at iteration 670 : 0.032774217426776886
Loss at iteration 680 : 0.016933949664235115
Loss at iteration 690 : 0.023310456424951553
Loss at iteration 700 : 0.014264755882322788
Loss at iteration 710 : 0.014639141969382763
Loss at iteration 720 : 0.020161408931016922
Loss at iteration 730 : 0.01638309843838215
Loss at iteration 740 : 0.01498462539166212
Loss at iteration 750 : 0.022005483508110046
Loss at iteration 760 : 0.02718946523964405
Loss at iteration 770 : 0.017689697444438934
Loss at iteration 780 : 0.016754476353526115
Loss at iteration 790 : 0.01308559998869896
Loss at iteration 800 : 0.033234212547540665
Loss at iteration 810 : 0.011866779997944832
Loss at iteration 820 : 0.018069323152303696
Loss at iteration 830 : 0.01815401203930378
Loss at iteration 840 : 0.013362990692257881
Loss at iteration 850 : 0.012692702934145927
Loss at iteration 860 : 0.022004414349794388
Loss at iteration 870 : 0.02619575336575508
Loss at iteration 880 : 0.0346095897257328
Loss at iteration 890 : 0.021129503846168518
Loss at iteration 900 : 0.01845197007060051
Loss at iteration 910 : 0.025260237976908684
Loss at iteration 920 : 0.02014818787574768
Loss at iteration 930 : 0.019083309918642044
Loss at iteration 940 : 0.02289014868438244
Loss at iteration 950 : 0.02031124383211136
Loss at iteration 960 : 0.021083597093820572
Loss at iteration 970 : 0.02025766111910343
Loss at iteration 980 : 0.014410083182156086
Loss at iteration 990 : 0.0306527279317379
Loss at iteration 1000 : 0.02175474725663662
Loss at iteration 1010 : 0.02284274622797966
Loss at iteration 1020 : 0.02378922700881958
Loss at iteration 1030 : 0.021536920219659805
Loss at iteration 1040 : 0.01446964405477047
Loss at iteration 1050 : 0.01109426748007536
Loss at iteration 1060 : 0.029991617426276207
Loss at iteration 1070 : 0.011281006038188934
Loss at iteration 1080 : 0.014349495992064476
Loss at iteration 1090 : 0.026687853038311005
Loss at iteration 1100 : 0.016310887411236763
Loss at iteration 1110 : 0.02428925409913063
Loss at iteration 1120 : 0.01165833231061697
Loss at iteration 1130 : 0.028485527262091637
Loss at iteration 1140 : 0.014820663258433342
Loss at iteration 1150 : 0.022618290036916733
Loss at iteration 1160 : 0.011320346966385841
Loss at iteration 1170 : 0.01765795797109604
Loss at iteration 1180 : 0.020230788737535477
Loss at iteration 1190 : 0.009305514395236969
Loss at iteration 1200 : 0.01737396977841854
Loss at iteration 1210 : 0.01612750068306923
The SSIM Value is: 0.8009404063224792
The PSNR Value is: 19.10097255706787
the epoch is: 111
Loss at iteration 10 : 0.01737033575773239
Loss at iteration 20 : 0.024217816069722176
Loss at iteration 30 : 0.01747707650065422
Loss at iteration 40 : 0.01825793646275997
Loss at iteration 50 : 0.027759160846471786
Loss at iteration 60 : 0.01971973292529583
Loss at iteration 70 : 0.026351623237133026
Loss at iteration 80 : 0.012540373019874096
Loss at iteration 90 : 0.022707173600792885
Loss at iteration 100 : 0.015529160387814045
Loss at iteration 110 : 0.009722075425088406
Loss at iteration 120 : 0.025949757546186447
Loss at iteration 130 : 0.01332857459783554
Loss at iteration 140 : 0.01641969010233879
Loss at iteration 150 : 0.023321636021137238
Loss at iteration 160 : 0.012868043035268784
Loss at iteration 170 : 0.012649125419557095
Loss at iteration 180 : 0.010076818987727165
Loss at iteration 190 : 0.017867522314190865
Loss at iteration 200 : 0.015365364030003548
Loss at iteration 210 : 0.01603490673005581
Loss at iteration 220 : 0.014504246413707733
Loss at iteration 230 : 0.027248527854681015
Loss at iteration 240 : 0.01754084788262844
Loss at iteration 250 : 0.016502168029546738
Loss at iteration 260 : 0.025332480669021606
Loss at iteration 270 : 0.01742323487997055
Loss at iteration 280 : 0.01958170160651207
Loss at iteration 290 : 0.021526914089918137
Loss at iteration 300 : 0.02047967165708542
Loss at iteration 310 : 0.012534082867205143
Loss at iteration 320 : 0.018701381981372833
Loss at iteration 330 : 0.013657555915415287
Loss at iteration 340 : 0.03387986123561859
Loss at iteration 350 : 0.013751942664384842
Loss at iteration 360 : 0.010763201862573624
Loss at iteration 370 : 0.02375239133834839
Loss at iteration 380 : 0.020610060542821884
Loss at iteration 390 : 0.014428619295358658
Loss at iteration 400 : 0.0178173016756773
Loss at iteration 410 : 0.025605646893382072
Loss at iteration 420 : 0.031503088772296906
Loss at iteration 430 : 0.025373347103595734
Loss at iteration 440 : 0.022756194695830345
Loss at iteration 450 : 0.019621185958385468
Loss at iteration 460 : 0.025789160281419754
Loss at iteration 470 : 0.014049663208425045
Loss at iteration 480 : 0.014735528267920017
Loss at iteration 490 : 0.023237571120262146
Loss at iteration 500 : 0.013180827721953392
Loss at iteration 510 : 0.018788570538163185
Loss at iteration 520 : 0.012277364730834961
Loss at iteration 530 : 0.023975886404514313
Loss at iteration 540 : 0.02015192061662674
Loss at iteration 550 : 0.025672346353530884
Loss at iteration 560 : 0.021941885352134705
Loss at iteration 570 : 0.03473656624555588
Loss at iteration 580 : 0.019395504146814346
Loss at iteration 590 : 0.025790557265281677
Loss at iteration 600 : 0.02624831534922123
Loss at iteration 610 : 0.018710415810346603
Loss at iteration 620 : 0.01563401333987713
Loss at iteration 630 : 0.015385173261165619
Loss at iteration 640 : 0.01341290958225727
Loss at iteration 650 : 0.014253972098231316
Loss at iteration 660 : 0.01602540910243988
Loss at iteration 670 : 0.017694097012281418
Loss at iteration 680 : 0.014716331847012043
Loss at iteration 690 : 0.014941209927201271
Loss at iteration 700 : 0.02877119742333889
Loss at iteration 710 : 0.0280817449092865
Loss at iteration 720 : 0.024356748908758163
Loss at iteration 730 : 0.012911394238471985
Loss at iteration 740 : 0.013558851554989815
Loss at iteration 750 : 0.022954560816287994
Loss at iteration 760 : 0.02771034836769104
Loss at iteration 770 : 0.011408699676394463
Loss at iteration 780 : 0.012746768072247505
Loss at iteration 790 : 0.017664967104792595
Loss at iteration 800 : 0.022141417488455772
Loss at iteration 810 : 0.02671891078352928
Loss at iteration 820 : 0.014512760564684868
Loss at iteration 830 : 0.019632620736956596
Loss at iteration 840 : 0.02870650216937065
Loss at iteration 850 : 0.022434653714299202
Loss at iteration 860 : 0.015605313703417778
Loss at iteration 870 : 0.01715969294309616
Loss at iteration 880 : 0.021608784794807434
Loss at iteration 890 : 0.017893072217702866
Loss at iteration 900 : 0.03684750199317932
Loss at iteration 910 : 0.03074188530445099
Loss at iteration 920 : 0.030191583558917046
Loss at iteration 930 : 0.01587662287056446
Loss at iteration 940 : 0.026821935549378395
Loss at iteration 950 : 0.03208617866039276
Loss at iteration 960 : 0.018218889832496643
Loss at iteration 970 : 0.020227165892720222
Loss at iteration 980 : 0.02738972194492817
Loss at iteration 990 : 0.018684135749936104
Loss at iteration 1000 : 0.010807562619447708
Loss at iteration 1010 : 0.029517441987991333
Loss at iteration 1020 : 0.02528410032391548
Loss at iteration 1030 : 0.01806805282831192
Loss at iteration 1040 : 0.023872844874858856
Loss at iteration 1050 : 0.013825615867972374
Loss at iteration 1060 : 0.010928240604698658
Loss at iteration 1070 : 0.01790076307952404
Loss at iteration 1080 : 0.01955786906182766
Loss at iteration 1090 : 0.017973767593503
Loss at iteration 1100 : 0.02472200244665146
Loss at iteration 1110 : 0.033725179731845856
Loss at iteration 1120 : 0.01651473343372345
Loss at iteration 1130 : 0.025309216231107712
Loss at iteration 1140 : 0.0294807031750679
Loss at iteration 1150 : 0.017384469509124756
Loss at iteration 1160 : 0.01992269791662693
Loss at iteration 1170 : 0.016154617071151733
Loss at iteration 1180 : 0.01888597384095192
Loss at iteration 1190 : 0.02806134521961212
Loss at iteration 1200 : 0.01825593411922455
Loss at iteration 1210 : 0.030545515939593315
The SSIM Value is: 0.7944322069485982
The PSNR Value is: 18.613288752237956
the epoch is: 112
Loss at iteration 10 : 0.01809467375278473
Loss at iteration 20 : 0.018605617806315422
Loss at iteration 30 : 0.01709114760160446
Loss at iteration 40 : 0.02220698818564415
Loss at iteration 50 : 0.012184043414890766
Loss at iteration 60 : 0.013095252215862274
Loss at iteration 70 : 0.023955969139933586
Loss at iteration 80 : 0.011885235086083412
Loss at iteration 90 : 0.015004702843725681
Loss at iteration 100 : 0.014206168241798878
Loss at iteration 110 : 0.015339186415076256
Loss at iteration 120 : 0.023688163608312607
Loss at iteration 130 : 0.01511094905436039
Loss at iteration 140 : 0.01604635640978813
Loss at iteration 150 : 0.01809634640812874
Loss at iteration 160 : 0.032851316034793854
Loss at iteration 170 : 0.020691150799393654
Loss at iteration 180 : 0.012558025307953358
Loss at iteration 190 : 0.015486120246350765
Loss at iteration 200 : 0.026313019916415215
Loss at iteration 210 : 0.012118972837924957
Loss at iteration 220 : 0.024127621203660965
Loss at iteration 230 : 0.027888204902410507
Loss at iteration 240 : 0.02371717244386673
Loss at iteration 250 : 0.031744442880153656
Loss at iteration 260 : 0.019313132390379906
Loss at iteration 270 : 0.015171973034739494
Loss at iteration 280 : 0.01810457371175289
Loss at iteration 290 : 0.025333721190690994
Loss at iteration 300 : 0.019668737426400185
Loss at iteration 310 : 0.015142126008868217
Loss at iteration 320 : 0.01831243559718132
Loss at iteration 330 : 0.02580355852842331
Loss at iteration 340 : 0.026544440537691116
Loss at iteration 350 : 0.018885215744376183
Loss at iteration 360 : 0.01739867776632309
Loss at iteration 370 : 0.015037307515740395
Loss at iteration 380 : 0.017843546345829964
Loss at iteration 390 : 0.021981127560138702
Loss at iteration 400 : 0.018418656662106514
Loss at iteration 410 : 0.018471403047442436
Loss at iteration 420 : 0.02336067147552967
Loss at iteration 430 : 0.02563691884279251
Loss at iteration 440 : 0.019236380234360695
Loss at iteration 450 : 0.030131466686725616
Loss at iteration 460 : 0.02746656909584999
Loss at iteration 470 : 0.031680259853601456
Loss at iteration 480 : 0.020096972584724426
Loss at iteration 490 : 0.048950280994176865
Loss at iteration 500 : 0.03363111615180969
Loss at iteration 510 : 0.01661549136042595
Loss at iteration 520 : 0.02340654283761978
Loss at iteration 530 : 0.029987461864948273
Loss at iteration 540 : 0.015891505405306816
Loss at iteration 550 : 0.022268928587436676
Loss at iteration 560 : 0.022741984575986862
Loss at iteration 570 : 0.01271074078977108
Loss at iteration 580 : 0.022140752524137497
Loss at iteration 590 : 0.020930591970682144
Loss at iteration 600 : 0.027185820043087006
Loss at iteration 610 : 0.02267654612660408
Loss at iteration 620 : 0.018065588548779488
Loss at iteration 630 : 0.019193001091480255
Loss at iteration 640 : 0.021502481773495674
Loss at iteration 650 : 0.021730411797761917
Loss at iteration 660 : 0.023140516132116318
Loss at iteration 670 : 0.018203597515821457
Loss at iteration 680 : 0.013994364999234676
Loss at iteration 690 : 0.025199169293045998
Loss at iteration 700 : 0.021795719861984253
Loss at iteration 710 : 0.015491647645831108
Loss at iteration 720 : 0.032934486865997314
Loss at iteration 730 : 0.01584429293870926
Loss at iteration 740 : 0.011038333177566528
Loss at iteration 750 : 0.01701154187321663
Loss at iteration 760 : 0.020256537944078445
Loss at iteration 770 : 0.011262738145887852
Loss at iteration 780 : 0.016065243631601334
Loss at iteration 790 : 0.024309566244482994
Loss at iteration 800 : 0.015136785805225372
Loss at iteration 810 : 0.02931922674179077
Loss at iteration 820 : 0.025318149477243423
Loss at iteration 830 : 0.024594120681285858
Loss at iteration 840 : 0.029190808534622192
Loss at iteration 850 : 0.015628905966877937
Loss at iteration 860 : 0.01701704040169716
Loss at iteration 870 : 0.016011878848075867
Loss at iteration 880 : 0.02907923236489296
Loss at iteration 890 : 0.017648428678512573
Loss at iteration 900 : 0.011735824868083
Loss at iteration 910 : 0.015968844294548035
Loss at iteration 920 : 0.021206742152571678
Loss at iteration 930 : 0.021413741633296013
Loss at iteration 940 : 0.018816949799656868
Loss at iteration 950 : 0.020214352756738663
Loss at iteration 960 : 0.020684711635112762
Loss at iteration 970 : 0.02291819453239441
Loss at iteration 980 : 0.026278771460056305
Loss at iteration 990 : 0.03506287559866905
Loss at iteration 1000 : 0.015074487775564194
Loss at iteration 1010 : 0.032728057354688644
Loss at iteration 1020 : 0.01317218691110611
Loss at iteration 1030 : 0.018952175974845886
Loss at iteration 1040 : 0.026157157495617867
Loss at iteration 1050 : 0.018285248428583145
Loss at iteration 1060 : 0.02483738586306572
Loss at iteration 1070 : 0.017636369913816452
Loss at iteration 1080 : 0.0206044539809227
Loss at iteration 1090 : 0.021509068086743355
Loss at iteration 1100 : 0.02129431813955307
Loss at iteration 1110 : 0.017974376678466797
Loss at iteration 1120 : 0.015962131321430206
Loss at iteration 1130 : 0.019952937960624695
Loss at iteration 1140 : 0.022460468113422394
Loss at iteration 1150 : 0.0261649452149868
Loss at iteration 1160 : 0.018413888290524483
Loss at iteration 1170 : 0.02391568012535572
Loss at iteration 1180 : 0.024557702243328094
Loss at iteration 1190 : 0.013779409229755402
Loss at iteration 1200 : 0.01705801486968994
Loss at iteration 1210 : 0.020932964980602264
The SSIM Value is: 0.8028160651524862
The PSNR Value is: 19.78349126180013
the epoch is: 113
Loss at iteration 10 : 0.03054911643266678
Loss at iteration 20 : 0.04750075191259384
Loss at iteration 30 : 0.01894959807395935
Loss at iteration 40 : 0.030375689268112183
Loss at iteration 50 : 0.02239447832107544
Loss at iteration 60 : 0.022246770560741425
Loss at iteration 70 : 0.010432029142975807
Loss at iteration 80 : 0.013112490996718407
Loss at iteration 90 : 0.01988852396607399
Loss at iteration 100 : 0.02724241465330124
Loss at iteration 110 : 0.02661217376589775
Loss at iteration 120 : 0.016354229301214218
Loss at iteration 130 : 0.021352259442210197
Loss at iteration 140 : 0.021310854703187943
Loss at iteration 150 : 0.027293292805552483
Loss at iteration 160 : 0.023827340453863144
Loss at iteration 170 : 0.028776727616786957
Loss at iteration 180 : 0.024449827149510384
Loss at iteration 190 : 0.02531614899635315
Loss at iteration 200 : 0.01568019762635231
Loss at iteration 210 : 0.03455866873264313
Loss at iteration 220 : 0.021673262119293213
Loss at iteration 230 : 0.02828657254576683
Loss at iteration 240 : 0.009364744648337364
Loss at iteration 250 : 0.025560274720191956
Loss at iteration 260 : 0.015516835264861584
Loss at iteration 270 : 0.025812245905399323
Loss at iteration 280 : 0.019542092457413673
Loss at iteration 290 : 0.01980399526655674
Loss at iteration 300 : 0.015465122647583485
Loss at iteration 310 : 0.01707937940955162
Loss at iteration 320 : 0.019648734480142593
Loss at iteration 330 : 0.023662909865379333
Loss at iteration 340 : 0.01983724534511566
Loss at iteration 350 : 0.02567097172141075
Loss at iteration 360 : 0.020800840109586716
Loss at iteration 370 : 0.015460682101547718
Loss at iteration 380 : 0.017504246905446053
Loss at iteration 390 : 0.017098622396588326
Loss at iteration 400 : 0.03938247263431549
Loss at iteration 410 : 0.015327850356698036
Loss at iteration 420 : 0.024816997349262238
Loss at iteration 430 : 0.015048984438180923
Loss at iteration 440 : 0.029379330575466156
Loss at iteration 450 : 0.01566009595990181
Loss at iteration 460 : 0.018271755427122116
Loss at iteration 470 : 0.021110456436872482
Loss at iteration 480 : 0.01054704375565052
Loss at iteration 490 : 0.02126755565404892
Loss at iteration 500 : 0.014501404017210007
Loss at iteration 510 : 0.03427216783165932
Loss at iteration 520 : 0.020800795406103134
Loss at iteration 530 : 0.01774105243384838
Loss at iteration 540 : 0.01552677620202303
Loss at iteration 550 : 0.01983712986111641
Loss at iteration 560 : 0.022080073133111
Loss at iteration 570 : 0.017967455089092255
Loss at iteration 580 : 0.015742793679237366
Loss at iteration 590 : 0.015304738655686378
Loss at iteration 600 : 0.017175281420350075
Loss at iteration 610 : 0.029498444870114326
Loss at iteration 620 : 0.012665320187807083
Loss at iteration 630 : 0.021261002868413925
Loss at iteration 640 : 0.022939758375287056
Loss at iteration 650 : 0.02584339678287506
Loss at iteration 660 : 0.021076355129480362
Loss at iteration 670 : 0.029100801795721054
Loss at iteration 680 : 0.014197632670402527
Loss at iteration 690 : 0.02617264911532402
Loss at iteration 700 : 0.03920166939496994
Loss at iteration 710 : 0.02220800891518593
Loss at iteration 720 : 0.021733734756708145
Loss at iteration 730 : 0.02189185842871666
Loss at iteration 740 : 0.025766829028725624
Loss at iteration 750 : 0.020845141261816025
Loss at iteration 760 : 0.026074528694152832
Loss at iteration 770 : 0.015411525964736938
Loss at iteration 780 : 0.02020520344376564
Loss at iteration 790 : 0.024821311235427856
Loss at iteration 800 : 0.02150007337331772
Loss at iteration 810 : 0.02166477032005787
Loss at iteration 820 : 0.014890272170305252
Loss at iteration 830 : 0.025509100407361984
Loss at iteration 840 : 0.022307880222797394
Loss at iteration 850 : 0.014432018622756004
Loss at iteration 860 : 0.018860317766666412
Loss at iteration 870 : 0.02886993996798992
Loss at iteration 880 : 0.028442010283470154
Loss at iteration 890 : 0.01138218306005001
Loss at iteration 900 : 0.01744287647306919
Loss at iteration 910 : 0.018631352111697197
Loss at iteration 920 : 0.016892943531274796
Loss at iteration 930 : 0.01605050079524517
Loss at iteration 940 : 0.01264809537678957
Loss at iteration 950 : 0.015150891616940498
Loss at iteration 960 : 0.020390931516885757
Loss at iteration 970 : 0.015153040178120136
Loss at iteration 980 : 0.018335144966840744
Loss at iteration 990 : 0.021075645461678505
Loss at iteration 1000 : 0.03307505324482918
Loss at iteration 1010 : 0.019102048128843307
Loss at iteration 1020 : 0.01592545211315155
Loss at iteration 1030 : 0.024919237941503525
Loss at iteration 1040 : 0.02990281581878662
Loss at iteration 1050 : 0.028767667710781097
Loss at iteration 1060 : 0.013529649935662746
Loss at iteration 1070 : 0.018476804718375206
Loss at iteration 1080 : 0.015081795863807201
Loss at iteration 1090 : 0.02703925222158432
Loss at iteration 1100 : 0.017651880159974098
Loss at iteration 1110 : 0.033287979662418365
Loss at iteration 1120 : 0.02305539697408676
Loss at iteration 1130 : 0.014162903651595116
Loss at iteration 1140 : 0.023226959630846977
Loss at iteration 1150 : 0.015633465722203255
Loss at iteration 1160 : 0.02364211156964302
Loss at iteration 1170 : 0.014887122437357903
Loss at iteration 1180 : 0.018106870353221893
Loss at iteration 1190 : 0.019032549113035202
Loss at iteration 1200 : 0.02392622083425522
Loss at iteration 1210 : 0.009195005521178246
The SSIM Value is: 0.8043691913286845
The PSNR Value is: 19.183098220825194
the epoch is: 114
Loss at iteration 10 : 0.015934821218252182
Loss at iteration 20 : 0.020429806783795357
Loss at iteration 30 : 0.01986096054315567
Loss at iteration 40 : 0.01481914333999157
Loss at iteration 50 : 0.015952130779623985
Loss at iteration 60 : 0.024767562747001648
Loss at iteration 70 : 0.019640356302261353
Loss at iteration 80 : 0.01812906563282013
Loss at iteration 90 : 0.009393937885761261
Loss at iteration 100 : 0.007344105746597052
Loss at iteration 110 : 0.02252264693379402
Loss at iteration 120 : 0.02208581194281578
Loss at iteration 130 : 0.039767954498529434
Loss at iteration 140 : 0.014447309076786041
Loss at iteration 150 : 0.03205009177327156
Loss at iteration 160 : 0.01691749319434166
Loss at iteration 170 : 0.02130330726504326
Loss at iteration 180 : 0.023924674838781357
Loss at iteration 190 : 0.0317266508936882
Loss at iteration 200 : 0.022797878831624985
Loss at iteration 210 : 0.012562510557472706
Loss at iteration 220 : 0.01594717986881733
Loss at iteration 230 : 0.015201386064291
Loss at iteration 240 : 0.016776271164417267
Loss at iteration 250 : 0.015173838473856449
Loss at iteration 260 : 0.037476614117622375
Loss at iteration 270 : 0.019286371767520905
Loss at iteration 280 : 0.02434394508600235
Loss at iteration 290 : 0.01778370514512062
Loss at iteration 300 : 0.01472136378288269
Loss at iteration 310 : 0.011493239551782608
Loss at iteration 320 : 0.015621357597410679
Loss at iteration 330 : 0.018451599404215813
Loss at iteration 340 : 0.01275828666985035
Loss at iteration 350 : 0.021870266646146774
Loss at iteration 360 : 0.019877661019563675
Loss at iteration 370 : 0.021475892513990402
Loss at iteration 380 : 0.020615357905626297
Loss at iteration 390 : 0.021242842078208923
Loss at iteration 400 : 0.028275685384869576
Loss at iteration 410 : 0.024307534098625183
Loss at iteration 420 : 0.0203634612262249
Loss at iteration 430 : 0.018817035481333733
Loss at iteration 440 : 0.03692442923784256
Loss at iteration 450 : 0.02676595188677311
Loss at iteration 460 : 0.020954053848981857
Loss at iteration 470 : 0.020235080271959305
Loss at iteration 480 : 0.038252003490924835
Loss at iteration 490 : 0.022662289440631866
Loss at iteration 500 : 0.013800008222460747
Loss at iteration 510 : 0.018577106297016144
Loss at iteration 520 : 0.027966447174549103
Loss at iteration 530 : 0.02597549930214882
Loss at iteration 540 : 0.02610110677778721
Loss at iteration 550 : 0.03482859209179878
Loss at iteration 560 : 0.01940738782286644
Loss at iteration 570 : 0.022914614528417587
Loss at iteration 580 : 0.022826455533504486
Loss at iteration 590 : 0.01341394241899252
Loss at iteration 600 : 0.017374223098158836
Loss at iteration 610 : 0.027228595688939095
Loss at iteration 620 : 0.03133825957775116
Loss at iteration 630 : 0.013683285564184189
Loss at iteration 640 : 0.021892735734581947
Loss at iteration 650 : 0.01824576035141945
Loss at iteration 660 : 0.015108190476894379
Loss at iteration 670 : 0.024493727833032608
Loss at iteration 680 : 0.027455871924757957
Loss at iteration 690 : 0.01911620795726776
Loss at iteration 700 : 0.021364595741033554
Loss at iteration 710 : 0.01640457659959793
Loss at iteration 720 : 0.02689647115767002
Loss at iteration 730 : 0.012514730915427208
Loss at iteration 740 : 0.02408939227461815
Loss at iteration 750 : 0.018999749794602394
Loss at iteration 760 : 0.022272784262895584
Loss at iteration 770 : 0.02337133139371872
Loss at iteration 780 : 0.012628354132175446
Loss at iteration 790 : 0.014356205239892006
Loss at iteration 800 : 0.016052020713686943
Loss at iteration 810 : 0.023820193484425545
Loss at iteration 820 : 0.009493719786405563
Loss at iteration 830 : 0.010271952487528324
Loss at iteration 840 : 0.029605567455291748
Loss at iteration 850 : 0.013551844283938408
Loss at iteration 860 : 0.0179306510835886
Loss at iteration 870 : 0.023452069610357285
Loss at iteration 880 : 0.015298477374017239
Loss at iteration 890 : 0.022256426513195038
Loss at iteration 900 : 0.011868176981806755
Loss at iteration 910 : 0.030434438958764076
Loss at iteration 920 : 0.013713838532567024
Loss at iteration 930 : 0.01459998544305563
Loss at iteration 940 : 0.013552307151257992
Loss at iteration 950 : 0.008765220642089844
Loss at iteration 960 : 0.019904477521777153
Loss at iteration 970 : 0.021377671509981155
Loss at iteration 980 : 0.02777218446135521
Loss at iteration 990 : 0.011361048556864262
Loss at iteration 1000 : 0.02175518497824669
Loss at iteration 1010 : 0.016769234091043472
Loss at iteration 1020 : 0.027101686224341393
Loss at iteration 1030 : 0.01658005081117153
Loss at iteration 1040 : 0.015023922547698021
Loss at iteration 1050 : 0.01997465267777443
Loss at iteration 1060 : 0.016459818929433823
Loss at iteration 1070 : 0.014830796048045158
Loss at iteration 1080 : 0.017879195511341095
Loss at iteration 1090 : 0.017596285790205002
Loss at iteration 1100 : 0.022938935086131096
Loss at iteration 1110 : 0.018824387341737747
Loss at iteration 1120 : 0.007472919300198555
Loss at iteration 1130 : 0.02460850030183792
Loss at iteration 1140 : 0.034020718187093735
Loss at iteration 1150 : 0.01396337803453207
Loss at iteration 1160 : 0.018023444339632988
Loss at iteration 1170 : 0.0261456910520792
Loss at iteration 1180 : 0.012822099030017853
Loss at iteration 1190 : 0.024624643847346306
Loss at iteration 1200 : 0.021444018930196762
Loss at iteration 1210 : 0.013465302996337414
The SSIM Value is: 0.8027550538380941
The PSNR Value is: 18.710420481363933
the epoch is: 115
Loss at iteration 10 : 0.02384883537888527
Loss at iteration 20 : 0.03025885298848152
Loss at iteration 30 : 0.02367926761507988
Loss at iteration 40 : 0.020626896992325783
Loss at iteration 50 : 0.02034306712448597
Loss at iteration 60 : 0.030029207468032837
Loss at iteration 70 : 0.013633168302476406
Loss at iteration 80 : 0.015438149683177471
Loss at iteration 90 : 0.014212224632501602
Loss at iteration 100 : 0.020414266735315323
Loss at iteration 110 : 0.02310178428888321
Loss at iteration 120 : 0.015993716195225716
Loss at iteration 130 : 0.023419242352247238
Loss at iteration 140 : 0.020405815914273262
Loss at iteration 150 : 0.026621561497449875
Loss at iteration 160 : 0.017847133800387383
Loss at iteration 170 : 0.012435052543878555
Loss at iteration 180 : 0.014011350460350513
Loss at iteration 190 : 0.03541789948940277
Loss at iteration 200 : 0.01794404536485672
Loss at iteration 210 : 0.014161160215735435
Loss at iteration 220 : 0.02817072905600071
Loss at iteration 230 : 0.013158866204321384
Loss at iteration 240 : 0.020484324544668198
Loss at iteration 250 : 0.019123714417219162
Loss at iteration 260 : 0.009839674457907677
Loss at iteration 270 : 0.015498222783207893
Loss at iteration 280 : 0.024174679070711136
Loss at iteration 290 : 0.01817227713763714
Loss at iteration 300 : 0.020320307463407516
Loss at iteration 310 : 0.015404786914587021
Loss at iteration 320 : 0.02300380915403366
Loss at iteration 330 : 0.018621312454342842
Loss at iteration 340 : 0.021195724606513977
Loss at iteration 350 : 0.031122997403144836
Loss at iteration 360 : 0.014149339869618416
Loss at iteration 370 : 0.01996196061372757
Loss at iteration 380 : 0.01457005925476551
Loss at iteration 390 : 0.017635758966207504
Loss at iteration 400 : 0.018971407786011696
Loss at iteration 410 : 0.037653591483831406
Loss at iteration 420 : 0.03039613924920559
Loss at iteration 430 : 0.015223350375890732
Loss at iteration 440 : 0.014177678152918816
Loss at iteration 450 : 0.03966332972049713
Loss at iteration 460 : 0.017576418817043304
Loss at iteration 470 : 0.01696840114891529
Loss at iteration 480 : 0.015412540175020695
Loss at iteration 490 : 0.026749202981591225
Loss at iteration 500 : 0.020835204049944878
Loss at iteration 510 : 0.013944612815976143
Loss at iteration 520 : 0.02515776827931404
Loss at iteration 530 : 0.019908001646399498
Loss at iteration 540 : 0.014964094385504723
Loss at iteration 550 : 0.02589411288499832
Loss at iteration 560 : 0.027830637991428375
Loss at iteration 570 : 0.02354849874973297
Loss at iteration 580 : 0.0271097794175148
Loss at iteration 590 : 0.025746755301952362
Loss at iteration 600 : 0.017380621284246445
Loss at iteration 610 : 0.012189311906695366
Loss at iteration 620 : 0.027614055201411247
Loss at iteration 630 : 0.01341079082340002
Loss at iteration 640 : 0.01777511276304722
Loss at iteration 650 : 0.025107279419898987
Loss at iteration 660 : 0.027800755575299263
Loss at iteration 670 : 0.022747941315174103
Loss at iteration 680 : 0.02794680930674076
Loss at iteration 690 : 0.01966353878378868
Loss at iteration 700 : 0.015432693064212799
Loss at iteration 710 : 0.016739966347813606
Loss at iteration 720 : 0.027660269290208817
Loss at iteration 730 : 0.01844475418329239
Loss at iteration 740 : 0.03074449859559536
Loss at iteration 750 : 0.024155117571353912
Loss at iteration 760 : 0.014073112979531288
Loss at iteration 770 : 0.022053416818380356
Loss at iteration 780 : 0.027481835335493088
Loss at iteration 790 : 0.02129567414522171
Loss at iteration 800 : 0.020016193389892578
Loss at iteration 810 : 0.014140239916741848
Loss at iteration 820 : 0.024325240403413773
Loss at iteration 830 : 0.017972368746995926
Loss at iteration 840 : 0.029152125120162964
Loss at iteration 850 : 0.01962299831211567
Loss at iteration 860 : 0.018344789743423462
Loss at iteration 870 : 0.013942891731858253
Loss at iteration 880 : 0.018113384023308754
Loss at iteration 890 : 0.012155893258750439
Loss at iteration 900 : 0.02972382865846157
Loss at iteration 910 : 0.02378653734922409
Loss at iteration 920 : 0.02307121828198433
Loss at iteration 930 : 0.042373739182949066
Loss at iteration 940 : 0.023663844913244247
Loss at iteration 950 : 0.01867971196770668
Loss at iteration 960 : 0.03384671360254288
Loss at iteration 970 : 0.02999531291425228
Loss at iteration 980 : 0.03242949768900871
Loss at iteration 990 : 0.03342589735984802
Loss at iteration 1000 : 0.016880298033356667
Loss at iteration 1010 : 0.03468314930796623
Loss at iteration 1020 : 0.016661811619997025
Loss at iteration 1030 : 0.015179751440882683
Loss at iteration 1040 : 0.012183170765638351
Loss at iteration 1050 : 0.01690344512462616
Loss at iteration 1060 : 0.02006908506155014
Loss at iteration 1070 : 0.05239713191986084
Loss at iteration 1080 : 0.020568717271089554
Loss at iteration 1090 : 0.016254818066954613
Loss at iteration 1100 : 0.028229927644133568
Loss at iteration 1110 : 0.015349938534200191
Loss at iteration 1120 : 0.014162483625113964
Loss at iteration 1130 : 0.019574685022234917
Loss at iteration 1140 : 0.015813002362847328
Loss at iteration 1150 : 0.014255030080676079
Loss at iteration 1160 : 0.026022573933005333
Loss at iteration 1170 : 0.019441155716776848
Loss at iteration 1180 : 0.016010330989956856
Loss at iteration 1190 : 0.012141600251197815
Loss at iteration 1200 : 0.025273365899920464
Loss at iteration 1210 : 0.01774916984140873
The SSIM Value is: 0.8003960688908894
The PSNR Value is: 18.77542864481608
the epoch is: 116
Loss at iteration 10 : 0.02494777739048004
Loss at iteration 20 : 0.021246392279863358
Loss at iteration 30 : 0.032708972692489624
Loss at iteration 40 : 0.022190231829881668
Loss at iteration 50 : 0.01938769593834877
Loss at iteration 60 : 0.02011704072356224
Loss at iteration 70 : 0.02604946866631508
Loss at iteration 80 : 0.021701015532016754
Loss at iteration 90 : 0.02552061155438423
Loss at iteration 100 : 0.017496101558208466
Loss at iteration 110 : 0.03368930518627167
Loss at iteration 120 : 0.026862220838665962
Loss at iteration 130 : 0.016899798065423965
Loss at iteration 140 : 0.012650868855416775
Loss at iteration 150 : 0.024297203868627548
Loss at iteration 160 : 0.028150716796517372
Loss at iteration 170 : 0.020557168871164322
Loss at iteration 180 : 0.015569469891488552
Loss at iteration 190 : 0.01721705123782158
Loss at iteration 200 : 0.01779438927769661
Loss at iteration 210 : 0.029359042644500732
Loss at iteration 220 : 0.01937757432460785
Loss at iteration 230 : 0.018805360421538353
Loss at iteration 240 : 0.01999039202928543
Loss at iteration 250 : 0.013386333361268044
Loss at iteration 260 : 0.01294000819325447
Loss at iteration 270 : 0.01930645853281021
Loss at iteration 280 : 0.030493471771478653
Loss at iteration 290 : 0.016424082219600677
Loss at iteration 300 : 0.030211009085178375
Loss at iteration 310 : 0.014150533825159073
Loss at iteration 320 : 0.027784116566181183
Loss at iteration 330 : 0.012950136326253414
Loss at iteration 340 : 0.021599730476737022
Loss at iteration 350 : 0.024519823491573334
Loss at iteration 360 : 0.03335798904299736
Loss at iteration 370 : 0.01462977472692728
Loss at iteration 380 : 0.014295419678092003
Loss at iteration 390 : 0.018140587955713272
Loss at iteration 400 : 0.020747477188706398
Loss at iteration 410 : 0.0374949648976326
Loss at iteration 420 : 0.016613200306892395
Loss at iteration 430 : 0.023610755801200867
Loss at iteration 440 : 0.023133542388677597
Loss at iteration 450 : 0.015599535778164864
Loss at iteration 460 : 0.0173934493213892
Loss at iteration 470 : 0.015917396172881126
Loss at iteration 480 : 0.021461158990859985
Loss at iteration 490 : 0.02684692293405533
Loss at iteration 500 : 0.014982870779931545
Loss at iteration 510 : 0.03319108113646507
Loss at iteration 520 : 0.014040707610547543
Loss at iteration 530 : 0.020865565165877342
Loss at iteration 540 : 0.014093795791268349
Loss at iteration 550 : 0.019466252997517586
Loss at iteration 560 : 0.018908560276031494
Loss at iteration 570 : 0.0261557474732399
Loss at iteration 580 : 0.01722707226872444
Loss at iteration 590 : 0.02558281645178795
Loss at iteration 600 : 0.016776159405708313
Loss at iteration 610 : 0.016382666304707527
Loss at iteration 620 : 0.01329420879483223
Loss at iteration 630 : 0.015434395521879196
Loss at iteration 640 : 0.024847961962223053
Loss at iteration 650 : 0.01249665953218937
Loss at iteration 660 : 0.02288680337369442
Loss at iteration 670 : 0.022463232278823853
Loss at iteration 680 : 0.017433762550354004
Loss at iteration 690 : 0.02570805326104164
Loss at iteration 700 : 0.019868159666657448
Loss at iteration 710 : 0.02156251296401024
Loss at iteration 720 : 0.012584546580910683
Loss at iteration 730 : 0.01887115091085434
Loss at iteration 740 : 0.016593581065535545
Loss at iteration 750 : 0.020345835015177727
Loss at iteration 760 : 0.014784585684537888
Loss at iteration 770 : 0.024465708062052727
Loss at iteration 780 : 0.022891545668244362
Loss at iteration 790 : 0.017387546598911285
Loss at iteration 800 : 0.019882183521986008
Loss at iteration 810 : 0.01642555743455887
Loss at iteration 820 : 0.01779303327202797
Loss at iteration 830 : 0.019684286788105965
Loss at iteration 840 : 0.013700392097234726
Loss at iteration 850 : 0.012908466160297394
Loss at iteration 860 : 0.01568552665412426
Loss at iteration 870 : 0.02348845824599266
Loss at iteration 880 : 0.02116241492331028
Loss at iteration 890 : 0.02126830816268921
Loss at iteration 900 : 0.019107578322291374
Loss at iteration 910 : 0.0190493892878294
Loss at iteration 920 : 0.02848675474524498
Loss at iteration 930 : 0.017530959099531174
Loss at iteration 940 : 0.0229024700820446
Loss at iteration 950 : 0.01880636066198349
Loss at iteration 960 : 0.016046861186623573
Loss at iteration 970 : 0.019193077459931374
Loss at iteration 980 : 0.010307656601071358
Loss at iteration 990 : 0.024696379899978638
Loss at iteration 1000 : 0.023207124322652817
Loss at iteration 1010 : 0.02173231728374958
Loss at iteration 1020 : 0.02415873110294342
Loss at iteration 1030 : 0.01723504811525345
Loss at iteration 1040 : 0.02607617899775505
Loss at iteration 1050 : 0.018835928291082382
Loss at iteration 1060 : 0.013087000697851181
Loss at iteration 1070 : 0.02061089500784874
Loss at iteration 1080 : 0.011842742562294006
Loss at iteration 1090 : 0.025264959782361984
Loss at iteration 1100 : 0.026047471910715103
Loss at iteration 1110 : 0.023077040910720825
Loss at iteration 1120 : 0.013113471679389477
Loss at iteration 1130 : 0.007942836731672287
Loss at iteration 1140 : 0.01886899396777153
Loss at iteration 1150 : 0.018917009234428406
Loss at iteration 1160 : 0.024345852434635162
Loss at iteration 1170 : 0.014883477240800858
Loss at iteration 1180 : 0.030112605541944504
Loss at iteration 1190 : 0.016008684411644936
Loss at iteration 1200 : 0.02362578921020031
Loss at iteration 1210 : 0.025179095566272736
The SSIM Value is: 0.7992289185523986
The PSNR Value is: 19.50062262217204
the epoch is: 117
Loss at iteration 10 : 0.016388123854994774
Loss at iteration 20 : 0.013335710391402245
Loss at iteration 30 : 0.023671748116612434
Loss at iteration 40 : 0.017215754836797714
Loss at iteration 50 : 0.01649763062596321
Loss at iteration 60 : 0.03169499710202217
Loss at iteration 70 : 0.01494642160832882
Loss at iteration 80 : 0.030139070004224777
Loss at iteration 90 : 0.03345074877142906
Loss at iteration 100 : 0.016613071784377098
Loss at iteration 110 : 0.017681792378425598
Loss at iteration 120 : 0.01695617474615574
Loss at iteration 130 : 0.014272243715822697
Loss at iteration 140 : 0.021318159997463226
Loss at iteration 150 : 0.028869275003671646
Loss at iteration 160 : 0.016978155821561813
Loss at iteration 170 : 0.020544156432151794
Loss at iteration 180 : 0.021267902106046677
Loss at iteration 190 : 0.03351986035704613
Loss at iteration 200 : 0.012274140492081642
Loss at iteration 210 : 0.02251974493265152
Loss at iteration 220 : 0.02150697074830532
Loss at iteration 230 : 0.014825597405433655
Loss at iteration 240 : 0.018808497115969658
Loss at iteration 250 : 0.0212034173309803
Loss at iteration 260 : 0.025090806186199188
Loss at iteration 270 : 0.014798769727349281
Loss at iteration 280 : 0.012746062129735947
Loss at iteration 290 : 0.028657665476202965
Loss at iteration 300 : 0.011979508213698864
Loss at iteration 310 : 0.007991593331098557
Loss at iteration 320 : 0.020564017817378044
Loss at iteration 330 : 0.03287145495414734
Loss at iteration 340 : 0.02575089782476425
Loss at iteration 350 : 0.02928192913532257
Loss at iteration 360 : 0.01814853399991989
Loss at iteration 370 : 0.017758749425411224
Loss at iteration 380 : 0.02622576430439949
Loss at iteration 390 : 0.012772157788276672
Loss at iteration 400 : 0.01783427968621254
Loss at iteration 410 : 0.02575504593551159
Loss at iteration 420 : 0.01468517817556858
Loss at iteration 430 : 0.026129331439733505
Loss at iteration 440 : 0.022676005959510803
Loss at iteration 450 : 0.014330102130770683
Loss at iteration 460 : 0.016032420098781586
Loss at iteration 470 : 0.03064095973968506
Loss at iteration 480 : 0.011277866549789906
Loss at iteration 490 : 0.0173969529569149
Loss at iteration 500 : 0.014612609520554543
Loss at iteration 510 : 0.023164255544543266
Loss at iteration 520 : 0.010905605740845203
Loss at iteration 530 : 0.019315345212817192
Loss at iteration 540 : 0.01939352974295616
Loss at iteration 550 : 0.019126977771520615
Loss at iteration 560 : 0.01696060411632061
Loss at iteration 570 : 0.021291717886924744
Loss at iteration 580 : 0.019022352993488312
Loss at iteration 590 : 0.01646583527326584
Loss at iteration 600 : 0.019461611285805702
Loss at iteration 610 : 0.024097375571727753
Loss at iteration 620 : 0.016598327085375786
Loss at iteration 630 : 0.023244690150022507
Loss at iteration 640 : 0.0189678892493248
Loss at iteration 650 : 0.021643664687871933
Loss at iteration 660 : 0.020438332110643387
Loss at iteration 670 : 0.019253727048635483
Loss at iteration 680 : 0.010254178196191788
Loss at iteration 690 : 0.02983834035694599
Loss at iteration 700 : 0.02949717827141285
Loss at iteration 710 : 0.017663072794675827
Loss at iteration 720 : 0.016500895842909813
Loss at iteration 730 : 0.02249930426478386
Loss at iteration 740 : 0.025827547535300255
Loss at iteration 750 : 0.01734652742743492
Loss at iteration 760 : 0.01217947993427515
Loss at iteration 770 : 0.015339456498622894
Loss at iteration 780 : 0.024010945111513138
Loss at iteration 790 : 0.01723029464483261
Loss at iteration 800 : 0.018288394436240196
Loss at iteration 810 : 0.022241055965423584
Loss at iteration 820 : 0.02221415564417839
Loss at iteration 830 : 0.02227124758064747
Loss at iteration 840 : 0.017267724499106407
Loss at iteration 850 : 0.018857009708881378
Loss at iteration 860 : 0.02022242173552513
Loss at iteration 870 : 0.014161797240376472
Loss at iteration 880 : 0.016843823716044426
Loss at iteration 890 : 0.013522551394999027
Loss at iteration 900 : 0.01770487055182457
Loss at iteration 910 : 0.018907152116298676
Loss at iteration 920 : 0.0317816399037838
Loss at iteration 930 : 0.021068289875984192
Loss at iteration 940 : 0.02382984384894371
Loss at iteration 950 : 0.01923818141222
Loss at iteration 960 : 0.02458409033715725
Loss at iteration 970 : 0.021337144076824188
Loss at iteration 980 : 0.022782864049077034
Loss at iteration 990 : 0.019891886040568352
Loss at iteration 1000 : 0.01963062584400177
Loss at iteration 1010 : 0.016074996441602707
Loss at iteration 1020 : 0.012065881863236427
Loss at iteration 1030 : 0.01649804413318634
Loss at iteration 1040 : 0.014307558536529541
Loss at iteration 1050 : 0.026200588792562485
Loss at iteration 1060 : 0.018029265105724335
Loss at iteration 1070 : 0.027601826936006546
Loss at iteration 1080 : 0.02530675195157528
Loss at iteration 1090 : 0.025001028552651405
Loss at iteration 1100 : 0.012276172637939453
Loss at iteration 1110 : 0.019895244389772415
Loss at iteration 1120 : 0.01720323972404003
Loss at iteration 1130 : 0.02097778394818306
Loss at iteration 1140 : 0.02468355931341648
Loss at iteration 1150 : 0.02685367316007614
Loss at iteration 1160 : 0.017505016177892685
Loss at iteration 1170 : 0.01383815798908472
Loss at iteration 1180 : 0.010773765854537487
Loss at iteration 1190 : 0.03518290817737579
Loss at iteration 1200 : 0.012933773919939995
Loss at iteration 1210 : 0.019122691825032234
The SSIM Value is: 0.7948390324910481
The PSNR Value is: 17.97842706044515
the epoch is: 118
Loss at iteration 10 : 0.023751329630613327
Loss at iteration 20 : 0.021546177566051483
Loss at iteration 30 : 0.02420724183320999
Loss at iteration 40 : 0.017618464305996895
Loss at iteration 50 : 0.03569992631673813
Loss at iteration 60 : 0.028908655047416687
Loss at iteration 70 : 0.017745573073625565
Loss at iteration 80 : 0.026671912521123886
Loss at iteration 90 : 0.02272588387131691
Loss at iteration 100 : 0.027856308966875076
Loss at iteration 110 : 0.016823681071400642
Loss at iteration 120 : 0.019775589928030968
Loss at iteration 130 : 0.01247586403042078
Loss at iteration 140 : 0.017728786915540695
Loss at iteration 150 : 0.019441310316324234
Loss at iteration 160 : 0.015034297481179237
Loss at iteration 170 : 0.019780026748776436
Loss at iteration 180 : 0.011236889287829399
Loss at iteration 190 : 0.02418186329305172
Loss at iteration 200 : 0.020212877541780472
Loss at iteration 210 : 0.023732826113700867
Loss at iteration 220 : 0.015519540756940842
Loss at iteration 230 : 0.011152628809213638
Loss at iteration 240 : 0.02279628999531269
Loss at iteration 250 : 0.02610776200890541
Loss at iteration 260 : 0.020011726766824722
Loss at iteration 270 : 0.02019667625427246
Loss at iteration 280 : 0.014117076992988586
Loss at iteration 290 : 0.020984016358852386
Loss at iteration 300 : 0.023646971210837364
Loss at iteration 310 : 0.029003430157899857
Loss at iteration 320 : 0.01511618122458458
Loss at iteration 330 : 0.018068041652441025
Loss at iteration 340 : 0.017659323289990425
Loss at iteration 350 : 0.03353459760546684
Loss at iteration 360 : 0.015709176659584045
Loss at iteration 370 : 0.021526794880628586
Loss at iteration 380 : 0.015510475262999535
Loss at iteration 390 : 0.0152462562546134
Loss at iteration 400 : 0.039325132966041565
Loss at iteration 410 : 0.024048130959272385
Loss at iteration 420 : 0.016920892521739006
Loss at iteration 430 : 0.0232797022908926
Loss at iteration 440 : 0.013659154996275902
Loss at iteration 450 : 0.028815006837248802
Loss at iteration 460 : 0.015883665531873703
Loss at iteration 470 : 0.01960732601583004
Loss at iteration 480 : 0.02551860362291336
Loss at iteration 490 : 0.015662629157304764
Loss at iteration 500 : 0.033382758498191833
Loss at iteration 510 : 0.018590262159705162
Loss at iteration 520 : 0.017024241387844086
Loss at iteration 530 : 0.02980557642877102
Loss at iteration 540 : 0.016553906723856926
Loss at iteration 550 : 0.016403181478381157
Loss at iteration 560 : 0.017241017892956734
Loss at iteration 570 : 0.020019423216581345
Loss at iteration 580 : 0.03323511779308319
Loss at iteration 590 : 0.03587830811738968
Loss at iteration 600 : 0.01580929383635521
Loss at iteration 610 : 0.028061844408512115
Loss at iteration 620 : 0.021820582449436188
Loss at iteration 630 : 0.02247035875916481
Loss at iteration 640 : 0.02251923643052578
Loss at iteration 650 : 0.0149327227845788
Loss at iteration 660 : 0.011000409722328186
Loss at iteration 670 : 0.02489001490175724
Loss at iteration 680 : 0.01732621341943741
Loss at iteration 690 : 0.02567564882338047
Loss at iteration 700 : 0.02868722192943096
Loss at iteration 710 : 0.018826313316822052
Loss at iteration 720 : 0.013193531893193722
Loss at iteration 730 : 0.011390445753932
Loss at iteration 740 : 0.019706783816218376
Loss at iteration 750 : 0.015736598521471024
Loss at iteration 760 : 0.02378675527870655
Loss at iteration 770 : 0.012524766847491264
Loss at iteration 780 : 0.013501088134944439
Loss at iteration 790 : 0.01201416552066803
Loss at iteration 800 : 0.018905654549598694
Loss at iteration 810 : 0.013190430589020252
Loss at iteration 820 : 0.02433927170932293
Loss at iteration 830 : 0.01998748444020748
Loss at iteration 840 : 0.01730477064847946
Loss at iteration 850 : 0.016401566565036774
Loss at iteration 860 : 0.023830857127904892
Loss at iteration 870 : 0.023240238428115845
Loss at iteration 880 : 0.018864139914512634
Loss at iteration 890 : 0.023646270856261253
Loss at iteration 900 : 0.017370885238051414
Loss at iteration 910 : 0.01765700802206993
Loss at iteration 920 : 0.02588532865047455
Loss at iteration 930 : 0.020587289705872536
Loss at iteration 940 : 0.014909261837601662
Loss at iteration 950 : 0.018455756828188896
Loss at iteration 960 : 0.012961773201823235
Loss at iteration 970 : 0.02169126644730568
Loss at iteration 980 : 0.013418172486126423
Loss at iteration 990 : 0.014737758785486221
Loss at iteration 1000 : 0.023260995745658875
Loss at iteration 1010 : 0.021643012762069702
Loss at iteration 1020 : 0.021054137498140335
Loss at iteration 1030 : 0.013844471424818039
Loss at iteration 1040 : 0.016636840999126434
Loss at iteration 1050 : 0.027825698256492615
Loss at iteration 1060 : 0.020204005762934685
Loss at iteration 1070 : 0.0256086066365242
Loss at iteration 1080 : 0.024769943207502365
Loss at iteration 1090 : 0.03408234566450119
Loss at iteration 1100 : 0.014351312071084976
Loss at iteration 1110 : 0.016122465953230858
Loss at iteration 1120 : 0.029772115871310234
Loss at iteration 1130 : 0.01872006058692932
Loss at iteration 1140 : 0.014010826125741005
Loss at iteration 1150 : 0.022943314164876938
Loss at iteration 1160 : 0.018136363476514816
Loss at iteration 1170 : 0.015964586287736893
Loss at iteration 1180 : 0.02410191483795643
Loss at iteration 1190 : 0.01347675733268261
Loss at iteration 1200 : 0.011278124526143074
Loss at iteration 1210 : 0.029556943103671074
The SSIM Value is: 0.7951348781585693
The PSNR Value is: 19.108177185058594
the epoch is: 119
Loss at iteration 10 : 0.052490655332803726
Loss at iteration 20 : 0.04329163581132889
Loss at iteration 30 : 0.017325183376669884
Loss at iteration 40 : 0.01480536162853241
Loss at iteration 50 : 0.01079211663454771
Loss at iteration 60 : 0.017952121794223785
Loss at iteration 70 : 0.020118258893489838
Loss at iteration 80 : 0.025395626202225685
Loss at iteration 90 : 0.03434021398425102
Loss at iteration 100 : 0.013433284126222134
Loss at iteration 110 : 0.017057355493307114
Loss at iteration 120 : 0.02075538970530033
Loss at iteration 130 : 0.03762851655483246
Loss at iteration 140 : 0.014087661169469357
Loss at iteration 150 : 0.039093200117349625
Loss at iteration 160 : 0.014549641869962215
Loss at iteration 170 : 0.01288696937263012
Loss at iteration 180 : 0.023439966142177582
Loss at iteration 190 : 0.01301598735153675
Loss at iteration 200 : 0.024759551510214806
Loss at iteration 210 : 0.02041427604854107
Loss at iteration 220 : 0.019299961626529694
Loss at iteration 230 : 0.016111377626657486
Loss at iteration 240 : 0.016392584890127182
Loss at iteration 250 : 0.013371706008911133
Loss at iteration 260 : 0.015397520735859871
Loss at iteration 270 : 0.02017349749803543
Loss at iteration 280 : 0.025913693010807037
Loss at iteration 290 : 0.018903382122516632
Loss at iteration 300 : 0.011525711044669151
Loss at iteration 310 : 0.026870086789131165
Loss at iteration 320 : 0.02385227382183075
Loss at iteration 330 : 0.01746043749153614
Loss at iteration 340 : 0.014580989256501198
Loss at iteration 350 : 0.02712208777666092
Loss at iteration 360 : 0.024401551112532616
Loss at iteration 370 : 0.03070240281522274
Loss at iteration 380 : 0.014569595456123352
Loss at iteration 390 : 0.027374640107154846
Loss at iteration 400 : 0.017898108810186386
Loss at iteration 410 : 0.02497381716966629
Loss at iteration 420 : 0.022997207939624786
Loss at iteration 430 : 0.011161860078573227
Loss at iteration 440 : 0.025836078450083733
Loss at iteration 450 : 0.028717057779431343
Loss at iteration 460 : 0.028857950121164322
Loss at iteration 470 : 0.014081163331866264
Loss at iteration 480 : 0.02588864415884018
Loss at iteration 490 : 0.02001224085688591
Loss at iteration 500 : 0.022799160331487656
Loss at iteration 510 : 0.01635771617293358
Loss at iteration 520 : 0.030637923628091812
Loss at iteration 530 : 0.015718935057520866
Loss at iteration 540 : 0.0142135601490736
Loss at iteration 550 : 0.02231426164507866
Loss at iteration 560 : 0.013594589196145535
Loss at iteration 570 : 0.020114252343773842
Loss at iteration 580 : 0.02030179835855961
Loss at iteration 590 : 0.01487525925040245
Loss at iteration 600 : 0.02283245511353016
Loss at iteration 610 : 0.014623131603002548
Loss at iteration 620 : 0.016881827265024185
Loss at iteration 630 : 0.021194342523813248
Loss at iteration 640 : 0.0394713319838047
Loss at iteration 650 : 0.016292396932840347
Loss at iteration 660 : 0.015227476134896278
Loss at iteration 670 : 0.02047632448375225
Loss at iteration 680 : 0.020750239491462708
Loss at iteration 690 : 0.019503414630889893
Loss at iteration 700 : 0.03500723838806152
Loss at iteration 710 : 0.014843076467514038
Loss at iteration 720 : 0.025029025971889496
Loss at iteration 730 : 0.02731553092598915
Loss at iteration 740 : 0.02259051240980625
Loss at iteration 750 : 0.01895776391029358
Loss at iteration 760 : 0.02623187191784382
Loss at iteration 770 : 0.019020019099116325
Loss at iteration 780 : 0.023466454818844795
Loss at iteration 790 : 0.022547375410795212
Loss at iteration 800 : 0.0127702122554183
Loss at iteration 810 : 0.01823548600077629
Loss at iteration 820 : 0.011509198695421219
Loss at iteration 830 : 0.021018121391534805
Loss at iteration 840 : 0.01831122860312462
Loss at iteration 850 : 0.016245510429143906
Loss at iteration 860 : 0.03399507701396942
Loss at iteration 870 : 0.022072546184062958
Loss at iteration 880 : 0.015945564955472946
Loss at iteration 890 : 0.018801555037498474
Loss at iteration 900 : 0.02000880427658558
Loss at iteration 910 : 0.014553451910614967
Loss at iteration 920 : 0.03523855656385422
Loss at iteration 930 : 0.016464143991470337
Loss at iteration 940 : 0.030007237568497658
Loss at iteration 950 : 0.018227072432637215
Loss at iteration 960 : 0.017611149698495865
Loss at iteration 970 : 0.02713678777217865
Loss at iteration 980 : 0.016809722408652306
Loss at iteration 990 : 0.016753803938627243
Loss at iteration 1000 : 0.01766096241772175
Loss at iteration 1010 : 0.02497055009007454
Loss at iteration 1020 : 0.015553398057818413
Loss at iteration 1030 : 0.029610931873321533
Loss at iteration 1040 : 0.026984840631484985
Loss at iteration 1050 : 0.020433498546481133
Loss at iteration 1060 : 0.01781494915485382
Loss at iteration 1070 : 0.026946470141410828
Loss at iteration 1080 : 0.018451709300279617
Loss at iteration 1090 : 0.017687734216451645
Loss at iteration 1100 : 0.022529272362589836
Loss at iteration 1110 : 0.020770225673913956
Loss at iteration 1120 : 0.016847074031829834
Loss at iteration 1130 : 0.019102390855550766
Loss at iteration 1140 : 0.018848668783903122
Loss at iteration 1150 : 0.023036811500787735
Loss at iteration 1160 : 0.01989107020199299
Loss at iteration 1170 : 0.027005787938833237
Loss at iteration 1180 : 0.029925398528575897
Loss at iteration 1190 : 0.029528334736824036
Loss at iteration 1200 : 0.023038651794195175
Loss at iteration 1210 : 0.015644731000065804
The SSIM Value is: 0.8016926288604737
The PSNR Value is: 19.515531412760417
the epoch is: 120
Loss at iteration 10 : 0.02242337539792061
Loss at iteration 20 : 0.016599096357822418
Loss at iteration 30 : 0.03278020769357681
Loss at iteration 40 : 0.022603314369916916
Loss at iteration 50 : 0.03195572644472122
Loss at iteration 60 : 0.01638239063322544
Loss at iteration 70 : 0.022729724645614624
Loss at iteration 80 : 0.01874507963657379
Loss at iteration 90 : 0.022864293307065964
Loss at iteration 100 : 0.016430402174592018
Loss at iteration 110 : 0.031299889087677
Loss at iteration 120 : 0.033976662904024124
Loss at iteration 130 : 0.02133198268711567
Loss at iteration 140 : 0.014030522666871548
Loss at iteration 150 : 0.01347029022872448
Loss at iteration 160 : 0.018177684396505356
Loss at iteration 170 : 0.019630448892712593
Loss at iteration 180 : 0.015280014835298061
Loss at iteration 190 : 0.02129228413105011
Loss at iteration 200 : 0.01939092017710209
Loss at iteration 210 : 0.017831802368164062
Loss at iteration 220 : 0.018882807344198227
Loss at iteration 230 : 0.024629585444927216
Loss at iteration 240 : 0.016033846884965897
Loss at iteration 250 : 0.02332974225282669
Loss at iteration 260 : 0.01828932948410511
Loss at iteration 270 : 0.02049403078854084
Loss at iteration 280 : 0.014572948217391968
Loss at iteration 290 : 0.01976301148533821
Loss at iteration 300 : 0.026038743555545807
Loss at iteration 310 : 0.021337468177080154
Loss at iteration 320 : 0.016400881111621857
Loss at iteration 330 : 0.019150342792272568
Loss at iteration 340 : 0.018848657608032227
Loss at iteration 350 : 0.01640729233622551
Loss at iteration 360 : 0.030868392437696457
Loss at iteration 370 : 0.026552319526672363
Loss at iteration 380 : 0.007056892849504948
Loss at iteration 390 : 0.032760389149188995
Loss at iteration 400 : 0.023044589906930923
Loss at iteration 410 : 0.01766705885529518
Loss at iteration 420 : 0.020281219854950905
Loss at iteration 430 : 0.012266837991774082
Loss at iteration 440 : 0.02711423486471176
Loss at iteration 450 : 0.013141504488885403
Loss at iteration 460 : 0.02304697409272194
Loss at iteration 470 : 0.01512026134878397
Loss at iteration 480 : 0.01703076809644699
Loss at iteration 490 : 0.016518592834472656
Loss at iteration 500 : 0.021192464977502823
Loss at iteration 510 : 0.018969736993312836
Loss at iteration 520 : 0.028773322701454163
Loss at iteration 530 : 0.016001570969820023
Loss at iteration 540 : 0.01897531747817993
Loss at iteration 550 : 0.022602396085858345
Loss at iteration 560 : 0.022028174251317978
Loss at iteration 570 : 0.014885792508721352
Loss at iteration 580 : 0.014759436249732971
Loss at iteration 590 : 0.015332362614572048
Loss at iteration 600 : 0.02602958306670189
Loss at iteration 610 : 0.016523487865924835
Loss at iteration 620 : 0.01901262253522873
Loss at iteration 630 : 0.0171196386218071
Loss at iteration 640 : 0.018738718703389168
Loss at iteration 650 : 0.01884452998638153
Loss at iteration 660 : 0.03233020752668381
Loss at iteration 670 : 0.02476377971470356
Loss at iteration 680 : 0.033274125307798386
Loss at iteration 690 : 0.025374824181199074
Loss at iteration 700 : 0.021648701280355453
Loss at iteration 710 : 0.020108385011553764
Loss at iteration 720 : 0.015396185219287872
Loss at iteration 730 : 0.008990767411887646
Loss at iteration 740 : 0.01972861774265766
Loss at iteration 750 : 0.012666012160480022
Loss at iteration 760 : 0.0141011793166399
Loss at iteration 770 : 0.013561560772359371
Loss at iteration 780 : 0.015060929581522942
Loss at iteration 790 : 0.023631831631064415
Loss at iteration 800 : 0.023650502786040306
Loss at iteration 810 : 0.014595809392631054
Loss at iteration 820 : 0.019026223570108414
Loss at iteration 830 : 0.015006604604423046
Loss at iteration 840 : 0.023682400584220886
Loss at iteration 850 : 0.02755056321620941
Loss at iteration 860 : 0.022592686116695404
Loss at iteration 870 : 0.02017781138420105
Loss at iteration 880 : 0.02115069516003132
Loss at iteration 890 : 0.03467252105474472
Loss at iteration 900 : 0.014616092666983604
Loss at iteration 910 : 0.02187911793589592
Loss at iteration 920 : 0.02382064238190651
Loss at iteration 930 : 0.016272038221359253
Loss at iteration 940 : 0.014333529397845268
Loss at iteration 950 : 0.01510636880993843
Loss at iteration 960 : 0.021871788427233696
Loss at iteration 970 : 0.016707833856344223
Loss at iteration 980 : 0.023464355617761612
Loss at iteration 990 : 0.015253415331244469
Loss at iteration 1000 : 0.015828687697649002
Loss at iteration 1010 : 0.01507095992565155
Loss at iteration 1020 : 0.029037393629550934
Loss at iteration 1030 : 0.01760093867778778
Loss at iteration 1040 : 0.020831622183322906
Loss at iteration 1050 : 0.013358235359191895
Loss at iteration 1060 : 0.019970960915088654
Loss at iteration 1070 : 0.019539596512913704
Loss at iteration 1080 : 0.017091237008571625
Loss at iteration 1090 : 0.013693810440599918
Loss at iteration 1100 : 0.02718411572277546
Loss at iteration 1110 : 0.02598036825656891
Loss at iteration 1120 : 0.01563970185816288
Loss at iteration 1130 : 0.015075534582138062
Loss at iteration 1140 : 0.018819715827703476
Loss at iteration 1150 : 0.03993663936853409
Loss at iteration 1160 : 0.018980124965310097
Loss at iteration 1170 : 0.01743454858660698
Loss at iteration 1180 : 0.01807328127324581
Loss at iteration 1190 : 0.019278906285762787
Loss at iteration 1200 : 0.028537193313241005
Loss at iteration 1210 : 0.021276816725730896
The SSIM Value is: 0.7886860450108846
The PSNR Value is: 18.8068821589152
the epoch is: 121
Loss at iteration 10 : 0.009438842535018921
Loss at iteration 20 : 0.02109285071492195
Loss at iteration 30 : 0.03392455726861954
Loss at iteration 40 : 0.021027451381087303
Loss at iteration 50 : 0.029381778091192245
Loss at iteration 60 : 0.021089041605591774
Loss at iteration 70 : 0.0125664621591568
Loss at iteration 80 : 0.011031804606318474
Loss at iteration 90 : 0.024685228243470192
Loss at iteration 100 : 0.011447830125689507
Loss at iteration 110 : 0.02848700061440468
Loss at iteration 120 : 0.011996875517070293
Loss at iteration 130 : 0.016793539747595787
Loss at iteration 140 : 0.016180817037820816
Loss at iteration 150 : 0.019335879012942314
Loss at iteration 160 : 0.014728124253451824
Loss at iteration 170 : 0.017380323261022568
Loss at iteration 180 : 0.021116482093930244
Loss at iteration 190 : 0.01648106798529625
Loss at iteration 200 : 0.01405252330005169
Loss at iteration 210 : 0.015513889491558075
Loss at iteration 220 : 0.01488989032804966
Loss at iteration 230 : 0.02129185199737549
Loss at iteration 240 : 0.02307552844285965
Loss at iteration 250 : 0.016507944092154503
Loss at iteration 260 : 0.023823052644729614
Loss at iteration 270 : 0.01387935969978571
Loss at iteration 280 : 0.013906104490160942
Loss at iteration 290 : 0.0179107915610075
Loss at iteration 300 : 0.020438548177480698
Loss at iteration 310 : 0.021869229152798653
Loss at iteration 320 : 0.02701128087937832
Loss at iteration 330 : 0.027641233056783676
Loss at iteration 340 : 0.021893613040447235
Loss at iteration 350 : 0.015688249841332436
Loss at iteration 360 : 0.02380446530878544
Loss at iteration 370 : 0.026491086930036545
Loss at iteration 380 : 0.01088842935860157
Loss at iteration 390 : 0.029911013320088387
Loss at iteration 400 : 0.028151094913482666
Loss at iteration 410 : 0.023870887234807014
Loss at iteration 420 : 0.05361662432551384
Loss at iteration 430 : 0.044805556535720825
Loss at iteration 440 : 0.023264605551958084
Loss at iteration 450 : 0.016075074672698975
Loss at iteration 460 : 0.024052578955888748
Loss at iteration 470 : 0.029669852927327156
Loss at iteration 480 : 0.02900562435388565
Loss at iteration 490 : 0.014986377209424973
Loss at iteration 500 : 0.02270524948835373
Loss at iteration 510 : 0.032452695071697235
Loss at iteration 520 : 0.021518584340810776
Loss at iteration 530 : 0.02025817520916462
Loss at iteration 540 : 0.023088078945875168
Loss at iteration 550 : 0.01758492738008499
Loss at iteration 560 : 0.018950622528791428
Loss at iteration 570 : 0.011487843468785286
Loss at iteration 580 : 0.02545003592967987
Loss at iteration 590 : 0.02027915045619011
Loss at iteration 600 : 0.026188254356384277
Loss at iteration 610 : 0.027074962854385376
Loss at iteration 620 : 0.0193784162402153
Loss at iteration 630 : 0.026023689657449722
Loss at iteration 640 : 0.02930954471230507
Loss at iteration 650 : 0.03016156703233719
Loss at iteration 660 : 0.014081047847867012
Loss at iteration 670 : 0.032285355031490326
Loss at iteration 680 : 0.02025012858211994
Loss at iteration 690 : 0.009753262624144554
Loss at iteration 700 : 0.010478912852704525
Loss at iteration 710 : 0.013258851133286953
Loss at iteration 720 : 0.015757054090499878
Loss at iteration 730 : 0.011238612234592438
Loss at iteration 740 : 0.01278834417462349
Loss at iteration 750 : 0.028092924505472183
Loss at iteration 760 : 0.03078814595937729
Loss at iteration 770 : 0.013722706586122513
Loss at iteration 780 : 0.027270717546343803
Loss at iteration 790 : 0.013386962004005909
Loss at iteration 800 : 0.021393969655036926
Loss at iteration 810 : 0.024511530995368958
Loss at iteration 820 : 0.02390039712190628
Loss at iteration 830 : 0.028196746483445168
Loss at iteration 840 : 0.016152240335941315
Loss at iteration 850 : 0.020209092646837234
Loss at iteration 860 : 0.019895832985639572
Loss at iteration 870 : 0.043459273874759674
Loss at iteration 880 : 0.018758073449134827
Loss at iteration 890 : 0.024786286056041718
Loss at iteration 900 : 0.01731489785015583
Loss at iteration 910 : 0.03904758766293526
Loss at iteration 920 : 0.012620216235518456
Loss at iteration 930 : 0.02293877862393856
Loss at iteration 940 : 0.022475529462099075
Loss at iteration 950 : 0.025985408574342728
Loss at iteration 960 : 0.03545014560222626
Loss at iteration 970 : 0.010334284976124763
Loss at iteration 980 : 0.02703346312046051
Loss at iteration 990 : 0.03979478031396866
Loss at iteration 1000 : 0.03440062701702118
Loss at iteration 1010 : 0.022568684071302414
Loss at iteration 1020 : 0.015877634286880493
Loss at iteration 1030 : 0.022540103644132614
Loss at iteration 1040 : 0.014061030000448227
Loss at iteration 1050 : 0.010599981062114239
Loss at iteration 1060 : 0.019532136619091034
Loss at iteration 1070 : 0.02601400762796402
Loss at iteration 1080 : 0.02963920310139656
Loss at iteration 1090 : 0.020258989185094833
Loss at iteration 1100 : 0.02258947491645813
Loss at iteration 1110 : 0.02926717884838581
Loss at iteration 1120 : 0.01285913772881031
Loss at iteration 1130 : 0.013920958153903484
Loss at iteration 1140 : 0.014907577075064182
Loss at iteration 1150 : 0.020505286753177643
Loss at iteration 1160 : 0.01850157417356968
Loss at iteration 1170 : 0.02543332800269127
Loss at iteration 1180 : 0.01888445019721985
Loss at iteration 1190 : 0.013706437312066555
Loss at iteration 1200 : 0.01681862771511078
Loss at iteration 1210 : 0.024624831974506378
The SSIM Value is: 0.7955102741718292
The PSNR Value is: 19.582155100504558
the epoch is: 122
Loss at iteration 10 : 0.011298933066427708
Loss at iteration 20 : 0.01948169246315956
Loss at iteration 30 : 0.02003123238682747
Loss at iteration 40 : 0.012739024125039577
Loss at iteration 50 : 0.012799897231161594
Loss at iteration 60 : 0.03254459798336029
Loss at iteration 70 : 0.0266123004257679
Loss at iteration 80 : 0.025669649243354797
Loss at iteration 90 : 0.022450413554906845
Loss at iteration 100 : 0.01595504954457283
Loss at iteration 110 : 0.01911018416285515
Loss at iteration 120 : 0.020397774875164032
Loss at iteration 130 : 0.013322260230779648
Loss at iteration 140 : 0.012710120528936386
Loss at iteration 150 : 0.02294997125864029
Loss at iteration 160 : 0.01504435483366251
Loss at iteration 170 : 0.009959697723388672
Loss at iteration 180 : 0.025594988837838173
Loss at iteration 190 : 0.013356225565075874
Loss at iteration 200 : 0.026941243559122086
Loss at iteration 210 : 0.026441294699907303
Loss at iteration 220 : 0.028036218136548996
Loss at iteration 230 : 0.015480617992579937
Loss at iteration 240 : 0.017255431041121483
Loss at iteration 250 : 0.01244264654815197
Loss at iteration 260 : 0.02427743747830391
Loss at iteration 270 : 0.022565767168998718
Loss at iteration 280 : 0.031386591494083405
Loss at iteration 290 : 0.02740616165101528
Loss at iteration 300 : 0.0168151892721653
Loss at iteration 310 : 0.02543942630290985
Loss at iteration 320 : 0.014731847681105137
Loss at iteration 330 : 0.023926284164190292
Loss at iteration 340 : 0.01996486447751522
Loss at iteration 350 : 0.023640215396881104
Loss at iteration 360 : 0.011112019419670105
Loss at iteration 370 : 0.02161465585231781
Loss at iteration 380 : 0.014753730967640877
Loss at iteration 390 : 0.015418238937854767
Loss at iteration 400 : 0.01808764412999153
Loss at iteration 410 : 0.031194284558296204
Loss at iteration 420 : 0.02720450423657894
Loss at iteration 430 : 0.020279064774513245
Loss at iteration 440 : 0.028657302260398865
Loss at iteration 450 : 0.015921233221888542
Loss at iteration 460 : 0.01608024165034294
Loss at iteration 470 : 0.019339902326464653
Loss at iteration 480 : 0.02277359366416931
Loss at iteration 490 : 0.022100908681750298
Loss at iteration 500 : 0.017553962767124176
Loss at iteration 510 : 0.0123754208907485
Loss at iteration 520 : 0.024462774395942688
Loss at iteration 530 : 0.018754374235868454
Loss at iteration 540 : 0.03368067368865013
Loss at iteration 550 : 0.030153913423419
Loss at iteration 560 : 0.01744914799928665
Loss at iteration 570 : 0.018035676330327988
Loss at iteration 580 : 0.01617007702589035
Loss at iteration 590 : 0.017349619418382645
Loss at iteration 600 : 0.017907794564962387
Loss at iteration 610 : 0.013912946917116642
Loss at iteration 620 : 0.016053786501288414
Loss at iteration 630 : 0.014695215038955212
Loss at iteration 640 : 0.013791307806968689
Loss at iteration 650 : 0.022282427176833153
Loss at iteration 660 : 0.015752580016851425
Loss at iteration 670 : 0.015926696360111237
Loss at iteration 680 : 0.02013622224330902
Loss at iteration 690 : 0.02185293659567833
Loss at iteration 700 : 0.02583295851945877
Loss at iteration 710 : 0.026990126818418503
Loss at iteration 720 : 0.0142167117446661
Loss at iteration 730 : 0.023267755284905434
Loss at iteration 740 : 0.03229928016662598
Loss at iteration 750 : 0.01955951191484928
Loss at iteration 760 : 0.02266114577651024
Loss at iteration 770 : 0.01755465753376484
Loss at iteration 780 : 0.025671884417533875
Loss at iteration 790 : 0.023302294313907623
Loss at iteration 800 : 0.030297763645648956
Loss at iteration 810 : 0.025852607563138008
Loss at iteration 820 : 0.017029935494065285
Loss at iteration 830 : 0.029789581894874573
Loss at iteration 840 : 0.014715010300278664
Loss at iteration 850 : 0.013578370213508606
Loss at iteration 860 : 0.01406244095414877
Loss at iteration 870 : 0.020770929753780365
Loss at iteration 880 : 0.036644525825977325
Loss at iteration 890 : 0.02876511588692665
Loss at iteration 900 : 0.02179497294127941
Loss at iteration 910 : 0.015306977555155754
Loss at iteration 920 : 0.027187485247850418
Loss at iteration 930 : 0.025248482823371887
Loss at iteration 940 : 0.01585744507610798
Loss at iteration 950 : 0.008898311294615269
Loss at iteration 960 : 0.012053358368575573
Loss at iteration 970 : 0.013685602694749832
Loss at iteration 980 : 0.03747186437249184
Loss at iteration 990 : 0.027741726487874985
Loss at iteration 1000 : 0.02377581223845482
Loss at iteration 1010 : 0.015192138031125069
Loss at iteration 1020 : 0.02522481232881546
Loss at iteration 1030 : 0.02186240628361702
Loss at iteration 1040 : 0.01867513917386532
Loss at iteration 1050 : 0.02562388963997364
Loss at iteration 1060 : 0.021911874413490295
Loss at iteration 1070 : 0.014048771932721138
Loss at iteration 1080 : 0.013004196807742119
Loss at iteration 1090 : 0.02143879607319832
Loss at iteration 1100 : 0.025018194690346718
Loss at iteration 1110 : 0.020739195868372917
Loss at iteration 1120 : 0.020491642877459526
Loss at iteration 1130 : 0.02024044468998909
Loss at iteration 1140 : 0.03683890029788017
Loss at iteration 1150 : 0.02506134659051895
Loss at iteration 1160 : 0.02636072225868702
Loss at iteration 1170 : 0.01654777303338051
Loss at iteration 1180 : 0.01762063056230545
Loss at iteration 1190 : 0.015980418771505356
Loss at iteration 1200 : 0.017361408099532127
Loss at iteration 1210 : 0.015197474509477615
The SSIM Value is: 0.7989985823631287
The PSNR Value is: 18.663670794169107
the epoch is: 123
Loss at iteration 10 : 0.013842533342540264
Loss at iteration 20 : 0.016454458236694336
Loss at iteration 30 : 0.021146006882190704
Loss at iteration 40 : 0.01793830096721649
Loss at iteration 50 : 0.00797104462981224
Loss at iteration 60 : 0.0231189988553524
Loss at iteration 70 : 0.018079344183206558
Loss at iteration 80 : 0.014475354924798012
Loss at iteration 90 : 0.019541285932064056
Loss at iteration 100 : 0.014509787783026695
Loss at iteration 110 : 0.013509010896086693
Loss at iteration 120 : 0.029304292052984238
Loss at iteration 130 : 0.01865646243095398
Loss at iteration 140 : 0.017303338274359703
Loss at iteration 150 : 0.010916379280388355
Loss at iteration 160 : 0.021494407206773758
Loss at iteration 170 : 0.023295355960726738
Loss at iteration 180 : 0.01547031570225954
Loss at iteration 190 : 0.021400442346930504
Loss at iteration 200 : 0.03637626767158508
Loss at iteration 210 : 0.01899508759379387
Loss at iteration 220 : 0.016231322661042213
Loss at iteration 230 : 0.02302711084485054
Loss at iteration 240 : 0.01952078379690647
Loss at iteration 250 : 0.019445907324552536
Loss at iteration 260 : 0.00939031969755888
Loss at iteration 270 : 0.015094535425305367
Loss at iteration 280 : 0.03233010694384575
Loss at iteration 290 : 0.023295259103178978
Loss at iteration 300 : 0.01208475511521101
Loss at iteration 310 : 0.02458813786506653
Loss at iteration 320 : 0.011207924224436283
Loss at iteration 330 : 0.0202986728399992
Loss at iteration 340 : 0.02159862406551838
Loss at iteration 350 : 0.02475176751613617
Loss at iteration 360 : 0.026324383914470673
Loss at iteration 370 : 0.014592107385396957
Loss at iteration 380 : 0.013678706251084805
Loss at iteration 390 : 0.01859302632510662
Loss at iteration 400 : 0.01945597119629383
Loss at iteration 410 : 0.031687043607234955
Loss at iteration 420 : 0.017566218972206116
Loss at iteration 430 : 0.022745098918676376
Loss at iteration 440 : 0.01125426311045885
Loss at iteration 450 : 0.040202897042036057
Loss at iteration 460 : 0.017929935827851295
Loss at iteration 470 : 0.021997854113578796
Loss at iteration 480 : 0.01629582792520523
Loss at iteration 490 : 0.01673785410821438
Loss at iteration 500 : 0.024535931646823883
Loss at iteration 510 : 0.013701517134904861
Loss at iteration 520 : 0.019865959882736206
Loss at iteration 530 : 0.027621669694781303
Loss at iteration 540 : 0.027382519096136093
Loss at iteration 550 : 0.014517541043460369
Loss at iteration 560 : 0.016702208667993546
Loss at iteration 570 : 0.020309846848249435
Loss at iteration 580 : 0.025190476328134537
Loss at iteration 590 : 0.018808098509907722
Loss at iteration 600 : 0.022193122655153275
Loss at iteration 610 : 0.027556881308555603
Loss at iteration 620 : 0.025035753846168518
Loss at iteration 630 : 0.022845540195703506
Loss at iteration 640 : 0.022216659039258957
Loss at iteration 650 : 0.01966673880815506
Loss at iteration 660 : 0.009785434231162071
Loss at iteration 670 : 0.02013963647186756
Loss at iteration 680 : 0.022711433470249176
Loss at iteration 690 : 0.021427303552627563
Loss at iteration 700 : 0.017302989959716797
Loss at iteration 710 : 0.018038179725408554
Loss at iteration 720 : 0.016946841031312943
Loss at iteration 730 : 0.017407311126589775
Loss at iteration 740 : 0.016607224941253662
Loss at iteration 750 : 0.015028994530439377
Loss at iteration 760 : 0.015497306361794472
Loss at iteration 770 : 0.030091211199760437
Loss at iteration 780 : 0.020034682005643845
Loss at iteration 790 : 0.019566863775253296
Loss at iteration 800 : 0.01662646234035492
Loss at iteration 810 : 0.02304176427423954
Loss at iteration 820 : 0.01704290695488453
Loss at iteration 830 : 0.01615034230053425
Loss at iteration 840 : 0.03023030422627926
Loss at iteration 850 : 0.014544833451509476
Loss at iteration 860 : 0.016046997159719467
Loss at iteration 870 : 0.021854357793927193
Loss at iteration 880 : 0.0247885100543499
Loss at iteration 890 : 0.009798528626561165
Loss at iteration 900 : 0.010983537882566452
Loss at iteration 910 : 0.021543776616454124
Loss at iteration 920 : 0.014992831274867058
Loss at iteration 930 : 0.012944611720740795
Loss at iteration 940 : 0.016677165403962135
Loss at iteration 950 : 0.020161371678113937
Loss at iteration 960 : 0.014421295374631882
Loss at iteration 970 : 0.02096930332481861
Loss at iteration 980 : 0.022016284987330437
Loss at iteration 990 : 0.014033257961273193
Loss at iteration 1000 : 0.01711483672261238
Loss at iteration 1010 : 0.012372246012091637
Loss at iteration 1020 : 0.03860001266002655
Loss at iteration 1030 : 0.02485685795545578
Loss at iteration 1040 : 0.018127670511603355
Loss at iteration 1050 : 0.025221679359674454
Loss at iteration 1060 : 0.02333436906337738
Loss at iteration 1070 : 0.02536780573427677
Loss at iteration 1080 : 0.016685958951711655
Loss at iteration 1090 : 0.014227151870727539
Loss at iteration 1100 : 0.014359861612319946
Loss at iteration 1110 : 0.021277185529470444
Loss at iteration 1120 : 0.014972361735999584
Loss at iteration 1130 : 0.019780589267611504
Loss at iteration 1140 : 0.011213460005819798
Loss at iteration 1150 : 0.02091909572482109
Loss at iteration 1160 : 0.009909985587000847
Loss at iteration 1170 : 0.029127415269613266
Loss at iteration 1180 : 0.026682104915380478
Loss at iteration 1190 : 0.027198266237974167
Loss at iteration 1200 : 0.018794504925608635
Loss at iteration 1210 : 0.021150384098291397
The SSIM Value is: 0.801147731145223
The PSNR Value is: 19.15244941711426
the epoch is: 124
Loss at iteration 10 : 0.028791476041078568
Loss at iteration 20 : 0.016652414575219154
Loss at iteration 30 : 0.01976030506193638
Loss at iteration 40 : 0.016070788726210594
Loss at iteration 50 : 0.018105629831552505
Loss at iteration 60 : 0.024900589138269424
Loss at iteration 70 : 0.015843041241168976
Loss at iteration 80 : 0.018510941416025162
Loss at iteration 90 : 0.017269957810640335
Loss at iteration 100 : 0.024932019412517548
Loss at iteration 110 : 0.022264497354626656
Loss at iteration 120 : 0.02829233929514885
Loss at iteration 130 : 0.015194033272564411
Loss at iteration 140 : 0.011763880960643291
Loss at iteration 150 : 0.012715195305645466
Loss at iteration 160 : 0.01848766580224037
Loss at iteration 170 : 0.023941896855831146
Loss at iteration 180 : 0.019734002649784088
Loss at iteration 190 : 0.018182629719376564
Loss at iteration 200 : 0.016568712890148163
Loss at iteration 210 : 0.014178984798491001
Loss at iteration 220 : 0.012628914788365364
Loss at iteration 230 : 0.016374431550502777
Loss at iteration 240 : 0.028286518529057503
Loss at iteration 250 : 0.02334769070148468
Loss at iteration 260 : 0.012957004830241203
Loss at iteration 270 : 0.02302417904138565
Loss at iteration 280 : 0.026358455419540405
Loss at iteration 290 : 0.023780830204486847
Loss at iteration 300 : 0.029255777597427368
Loss at iteration 310 : 0.025861375033855438
Loss at iteration 320 : 0.024240724742412567
Loss at iteration 330 : 0.01819276250898838
Loss at iteration 340 : 0.010106837376952171
Loss at iteration 350 : 0.02554398775100708
Loss at iteration 360 : 0.01155082043260336
Loss at iteration 370 : 0.01672738417983055
Loss at iteration 380 : 0.03283586725592613
Loss at iteration 390 : 0.02432674914598465
Loss at iteration 400 : 0.01775842159986496
Loss at iteration 410 : 0.019169455394148827
Loss at iteration 420 : 0.026341184973716736
Loss at iteration 430 : 0.032497867941856384
Loss at iteration 440 : 0.018009718507528305
Loss at iteration 450 : 0.024992242455482483
Loss at iteration 460 : 0.027569454163312912
Loss at iteration 470 : 0.01963122934103012
Loss at iteration 480 : 0.03349415212869644
Loss at iteration 490 : 0.01685687154531479
Loss at iteration 500 : 0.02175106666982174
Loss at iteration 510 : 0.030961496755480766
Loss at iteration 520 : 0.012472663074731827
Loss at iteration 530 : 0.024847228080034256
Loss at iteration 540 : 0.020591845735907555
Loss at iteration 550 : 0.023319581523537636
Loss at iteration 560 : 0.020378895103931427
Loss at iteration 570 : 0.015473000705242157
Loss at iteration 580 : 0.032043177634477615
Loss at iteration 590 : 0.0377771332859993
Loss at iteration 600 : 0.019744694232940674
Loss at iteration 610 : 0.021665368229150772
Loss at iteration 620 : 0.02091955579817295
Loss at iteration 630 : 0.015547639690339565
Loss at iteration 640 : 0.01666555553674698
Loss at iteration 650 : 0.02365203946828842
Loss at iteration 660 : 0.017509790137410164
Loss at iteration 670 : 0.016422351822257042
Loss at iteration 680 : 0.02505912445485592
Loss at iteration 690 : 0.016828909516334534
Loss at iteration 700 : 0.018385134637355804
Loss at iteration 710 : 0.026632605120539665
Loss at iteration 720 : 0.018858211115002632
Loss at iteration 730 : 0.025025727227330208
Loss at iteration 740 : 0.020823579281568527
Loss at iteration 750 : 0.01498817652463913
Loss at iteration 760 : 0.02643468603491783
Loss at iteration 770 : 0.02554905228316784
Loss at iteration 780 : 0.024462491273880005
Loss at iteration 790 : 0.01476355642080307
Loss at iteration 800 : 0.02311219647526741
Loss at iteration 810 : 0.03316216170787811
Loss at iteration 820 : 0.02015102095901966
Loss at iteration 830 : 0.023126225918531418
Loss at iteration 840 : 0.015316423960030079
Loss at iteration 850 : 0.01365151908248663
Loss at iteration 860 : 0.015960410237312317
Loss at iteration 870 : 0.016885245218873024
Loss at iteration 880 : 0.021167732775211334
Loss at iteration 890 : 0.01540776900947094
Loss at iteration 900 : 0.008864300325512886
Loss at iteration 910 : 0.023893963545560837
Loss at iteration 920 : 0.016675841063261032
Loss at iteration 930 : 0.011938429437577724
Loss at iteration 940 : 0.017001651227474213
Loss at iteration 950 : 0.02181149274110794
Loss at iteration 960 : 0.01416473276913166
Loss at iteration 970 : 0.020624902099370956
Loss at iteration 980 : 0.021668607369065285
Loss at iteration 990 : 0.024181876331567764
Loss at iteration 1000 : 0.023684293031692505
Loss at iteration 1010 : 0.021008256822824478
Loss at iteration 1020 : 0.01686970889568329
Loss at iteration 1030 : 0.02130461111664772
Loss at iteration 1040 : 0.01483789924532175
Loss at iteration 1050 : 0.018794193863868713
Loss at iteration 1060 : 0.015811961144208908
Loss at iteration 1070 : 0.0289237629622221
Loss at iteration 1080 : 0.01649916172027588
Loss at iteration 1090 : 0.015865139663219452
Loss at iteration 1100 : 0.017183855175971985
Loss at iteration 1110 : 0.02441069856286049
Loss at iteration 1120 : 0.02092112973332405
Loss at iteration 1130 : 0.017310718074440956
Loss at iteration 1140 : 0.01146166492253542
Loss at iteration 1150 : 0.008765330538153648
Loss at iteration 1160 : 0.016563735902309418
Loss at iteration 1170 : 0.014232467859983444
Loss at iteration 1180 : 0.01648627407848835
Loss at iteration 1190 : 0.011620881035923958
Loss at iteration 1200 : 0.022813133895397186
Loss at iteration 1210 : 0.017944665625691414
The SSIM Value is: 0.7608338435490926
The PSNR Value is: 16.52002868652344
the epoch is: 125
Loss at iteration 10 : 0.0206480510532856
Loss at iteration 20 : 0.015019243583083153
Loss at iteration 30 : 0.025693263858556747
Loss at iteration 40 : 0.015178931877017021
Loss at iteration 50 : 0.021137621253728867
Loss at iteration 60 : 0.022167988121509552
Loss at iteration 70 : 0.023513313382864
Loss at iteration 80 : 0.0329756885766983
Loss at iteration 90 : 0.019537847489118576
Loss at iteration 100 : 0.014109132811427116
Loss at iteration 110 : 0.018574299290776253
Loss at iteration 120 : 0.016770990565419197
Loss at iteration 130 : 0.022055530920624733
Loss at iteration 140 : 0.0302882082760334
Loss at iteration 150 : 0.017933476716279984
Loss at iteration 160 : 0.027261298149824142
Loss at iteration 170 : 0.017529895529150963
Loss at iteration 180 : 0.03232666850090027
Loss at iteration 190 : 0.013578930869698524
Loss at iteration 200 : 0.015076663345098495
Loss at iteration 210 : 0.01655631512403488
Loss at iteration 220 : 0.012896213680505753
Loss at iteration 230 : 0.014572774060070515
Loss at iteration 240 : 0.021534806117415428
Loss at iteration 250 : 0.01651080697774887
Loss at iteration 260 : 0.015170807018876076
Loss at iteration 270 : 0.02172250859439373
Loss at iteration 280 : 0.01890571415424347
Loss at iteration 290 : 0.015265993773937225
Loss at iteration 300 : 0.014115111902356148
Loss at iteration 310 : 0.017453931272029877
Loss at iteration 320 : 0.018841374665498734
Loss at iteration 330 : 0.01902412623167038
Loss at iteration 340 : 0.021873416379094124
Loss at iteration 350 : 0.028613612055778503
Loss at iteration 360 : 0.01582721248269081
Loss at iteration 370 : 0.020615356042981148
Loss at iteration 380 : 0.017166556790471077
Loss at iteration 390 : 0.01061616837978363
Loss at iteration 400 : 0.030261904001235962
Loss at iteration 410 : 0.034321557730436325
Loss at iteration 420 : 0.015199460089206696
Loss at iteration 430 : 0.027243303135037422
Loss at iteration 440 : 0.014930587261915207
Loss at iteration 450 : 0.009234923869371414
Loss at iteration 460 : 0.017522811889648438
Loss at iteration 470 : 0.018002990633249283
Loss at iteration 480 : 0.01575084775686264
Loss at iteration 490 : 0.03347700834274292
Loss at iteration 500 : 0.01926257833838463
Loss at iteration 510 : 0.026636473834514618
Loss at iteration 520 : 0.015173649415373802
Loss at iteration 530 : 0.02073824219405651
Loss at iteration 540 : 0.018801752477884293
Loss at iteration 550 : 0.030824989080429077
Loss at iteration 560 : 0.024774160236120224
Loss at iteration 570 : 0.022857993841171265
Loss at iteration 580 : 0.016949495300650597
Loss at iteration 590 : 0.027030151337385178
Loss at iteration 600 : 0.009599283337593079
Loss at iteration 610 : 0.01468179002404213
Loss at iteration 620 : 0.03128275275230408
Loss at iteration 630 : 0.03335123509168625
Loss at iteration 640 : 0.021328791975975037
Loss at iteration 650 : 0.011972433887422085
Loss at iteration 660 : 0.014297663234174252
Loss at iteration 670 : 0.01885765790939331
Loss at iteration 680 : 0.02285391464829445
Loss at iteration 690 : 0.01444024033844471
Loss at iteration 700 : 0.017759893089532852
Loss at iteration 710 : 0.02072559855878353
Loss at iteration 720 : 0.01718786731362343
Loss at iteration 730 : 0.03843674436211586
Loss at iteration 740 : 0.02082856371998787
Loss at iteration 750 : 0.013799885287880898
Loss at iteration 760 : 0.026985125616192818
Loss at iteration 770 : 0.01959456503391266
Loss at iteration 780 : 0.01966013014316559
Loss at iteration 790 : 0.020977701991796494
Loss at iteration 800 : 0.021163610741496086
Loss at iteration 810 : 0.018713660538196564
Loss at iteration 820 : 0.022626593708992004
Loss at iteration 830 : 0.016993548721075058
Loss at iteration 840 : 0.014815457165241241
Loss at iteration 850 : 0.020794078707695007
Loss at iteration 860 : 0.020477687940001488
Loss at iteration 870 : 0.021977167576551437
Loss at iteration 880 : 0.023121189326047897
Loss at iteration 890 : 0.02085842937231064
Loss at iteration 900 : 0.014522647485136986
Loss at iteration 910 : 0.010258950293064117
Loss at iteration 920 : 0.02413286827504635
Loss at iteration 930 : 0.020475294440984726
Loss at iteration 940 : 0.018361365422606468
Loss at iteration 950 : 0.021347645670175552
Loss at iteration 960 : 0.027253957465291023
Loss at iteration 970 : 0.020978868007659912
Loss at iteration 980 : 0.01673879474401474
Loss at iteration 990 : 0.01316164992749691
Loss at iteration 1000 : 0.01043529249727726
Loss at iteration 1010 : 0.017031488940119743
Loss at iteration 1020 : 0.028532272204756737
Loss at iteration 1030 : 0.021443355828523636
Loss at iteration 1040 : 0.03682669997215271
Loss at iteration 1050 : 0.024262212216854095
Loss at iteration 1060 : 0.012822621501982212
Loss at iteration 1070 : 0.017542507499456406
Loss at iteration 1080 : 0.010350221768021584
Loss at iteration 1090 : 0.013707023113965988
Loss at iteration 1100 : 0.0400458499789238
Loss at iteration 1110 : 0.017679115757346153
Loss at iteration 1120 : 0.0177927166223526
Loss at iteration 1130 : 0.020101947709918022
Loss at iteration 1140 : 0.014444367028772831
Loss at iteration 1150 : 0.01947985775768757
Loss at iteration 1160 : 0.03515993058681488
Loss at iteration 1170 : 0.014378095045685768
Loss at iteration 1180 : 0.02528230845928192
Loss at iteration 1190 : 0.02244010753929615
Loss at iteration 1200 : 0.017831195145845413
Loss at iteration 1210 : 0.015551190823316574
The SSIM Value is: 0.7640444715817769
The PSNR Value is: 16.694155311584474
the epoch is: 126
Loss at iteration 10 : 0.018998267129063606
Loss at iteration 20 : 0.02048896625638008
Loss at iteration 30 : 0.02201709896326065
Loss at iteration 40 : 0.025519495829939842
Loss at iteration 50 : 0.01982530578970909
Loss at iteration 60 : 0.012172739021480083
Loss at iteration 70 : 0.01758182793855667
Loss at iteration 80 : 0.015390840359032154
Loss at iteration 90 : 0.020171742886304855
Loss at iteration 100 : 0.02874756045639515
Loss at iteration 110 : 0.02321479097008705
Loss at iteration 120 : 0.017166459932923317
Loss at iteration 130 : 0.024854769930243492
Loss at iteration 140 : 0.01236033160239458
Loss at iteration 150 : 0.011863348074257374
Loss at iteration 160 : 0.023416519165039062
Loss at iteration 170 : 0.021927114576101303
Loss at iteration 180 : 0.014768119901418686
Loss at iteration 190 : 0.028036940842866898
Loss at iteration 200 : 0.027488484978675842
Loss at iteration 210 : 0.016984008252620697
Loss at iteration 220 : 0.01996637135744095
Loss at iteration 230 : 0.018648827448487282
Loss at iteration 240 : 0.01947089284658432
Loss at iteration 250 : 0.01631147786974907
Loss at iteration 260 : 0.024119451642036438
Loss at iteration 270 : 0.016594525426626205
Loss at iteration 280 : 0.028894620016217232
Loss at iteration 290 : 0.014936776831746101
Loss at iteration 300 : 0.02988792210817337
Loss at iteration 310 : 0.011528314091265202
Loss at iteration 320 : 0.020151114091277122
Loss at iteration 330 : 0.014278222806751728
Loss at iteration 340 : 0.023981526494026184
Loss at iteration 350 : 0.01157254446297884
Loss at iteration 360 : 0.018917730078101158
Loss at iteration 370 : 0.010291265323758125
Loss at iteration 380 : 0.01738888956606388
Loss at iteration 390 : 0.011022776365280151
Loss at iteration 400 : 0.02535342425107956
Loss at iteration 410 : 0.022358959540724754
Loss at iteration 420 : 0.015520128421485424
Loss at iteration 430 : 0.02274392731487751
Loss at iteration 440 : 0.028999578207731247
Loss at iteration 450 : 0.01897367462515831
Loss at iteration 460 : 0.023313486948609352
Loss at iteration 470 : 0.013894141651690006
Loss at iteration 480 : 0.028803065419197083
Loss at iteration 490 : 0.022797755897045135
Loss at iteration 500 : 0.015364233404397964
Loss at iteration 510 : 0.021852055564522743
Loss at iteration 520 : 0.02428118884563446
Loss at iteration 530 : 0.024322375655174255
Loss at iteration 540 : 0.017400041222572327
Loss at iteration 550 : 0.021681606769561768
Loss at iteration 560 : 0.014224160462617874
Loss at iteration 570 : 0.01954391784965992
Loss at iteration 580 : 0.01651013270020485
Loss at iteration 590 : 0.020905690267682076
Loss at iteration 600 : 0.03443034365773201
Loss at iteration 610 : 0.013476725667715073
Loss at iteration 620 : 0.01939416490495205
Loss at iteration 630 : 0.02087298035621643
Loss at iteration 640 : 0.019238300621509552
Loss at iteration 650 : 0.01595786213874817
Loss at iteration 660 : 0.020872702822089195
Loss at iteration 670 : 0.02874358929693699
Loss at iteration 680 : 0.01295321062207222
Loss at iteration 690 : 0.01924733817577362
Loss at iteration 700 : 0.025511328130960464
Loss at iteration 710 : 0.022190093994140625
Loss at iteration 720 : 0.02811264805495739
Loss at iteration 730 : 0.00906266551464796
Loss at iteration 740 : 0.009508874267339706
Loss at iteration 750 : 0.018497323617339134
Loss at iteration 760 : 0.01697143167257309
Loss at iteration 770 : 0.025579232722520828
Loss at iteration 780 : 0.028102025389671326
Loss at iteration 790 : 0.02929210104048252
Loss at iteration 800 : 0.023702062666416168
Loss at iteration 810 : 0.028122009709477425
Loss at iteration 820 : 0.03422212973237038
Loss at iteration 830 : 0.03331587463617325
Loss at iteration 840 : 0.03594795614480972
Loss at iteration 850 : 0.023664120584726334
Loss at iteration 860 : 0.02256140299141407
Loss at iteration 870 : 0.018998000770807266
Loss at iteration 880 : 0.01879606768488884
Loss at iteration 890 : 0.014101387932896614
Loss at iteration 900 : 0.01964222826063633
Loss at iteration 910 : 0.014857145957648754
Loss at iteration 920 : 0.011488210409879684
Loss at iteration 930 : 0.01801724173128605
Loss at iteration 940 : 0.012919515371322632
Loss at iteration 950 : 0.01790817454457283
Loss at iteration 960 : 0.011673083528876305
Loss at iteration 970 : 0.015974048525094986
Loss at iteration 980 : 0.030245179310441017
Loss at iteration 990 : 0.015697451308369637
Loss at iteration 1000 : 0.022788606584072113
Loss at iteration 1010 : 0.01889331266283989
Loss at iteration 1020 : 0.022055454552173615
Loss at iteration 1030 : 0.01950594037771225
Loss at iteration 1040 : 0.017039082944393158
Loss at iteration 1050 : 0.024965014308691025
Loss at iteration 1060 : 0.015665581449866295
Loss at iteration 1070 : 0.01235300675034523
Loss at iteration 1080 : 0.022525127977132797
Loss at iteration 1090 : 0.011556105688214302
Loss at iteration 1100 : 0.01858583092689514
Loss at iteration 1110 : 0.022104430943727493
Loss at iteration 1120 : 0.010638469830155373
Loss at iteration 1130 : 0.0143576106056571
Loss at iteration 1140 : 0.027218837291002274
Loss at iteration 1150 : 0.02910206839442253
Loss at iteration 1160 : 0.01698429137468338
Loss at iteration 1170 : 0.02443653717637062
Loss at iteration 1180 : 0.010758222080767155
Loss at iteration 1190 : 0.021374017000198364
Loss at iteration 1200 : 0.023974938318133354
Loss at iteration 1210 : 0.01664676144719124
The SSIM Value is: 0.7931361436843872
The PSNR Value is: 19.01983534495036
the epoch is: 127
Loss at iteration 10 : 0.01966768130660057
Loss at iteration 20 : 0.025645501911640167
Loss at iteration 30 : 0.01927780732512474
Loss at iteration 40 : 0.009030241519212723
Loss at iteration 50 : 0.019777905195951462
Loss at iteration 60 : 0.019876550883054733
Loss at iteration 70 : 0.018405411392450333
Loss at iteration 80 : 0.026854824274778366
Loss at iteration 90 : 0.01954055018723011
Loss at iteration 100 : 0.023237086832523346
Loss at iteration 110 : 0.017734820023179054
Loss at iteration 120 : 0.014055234380066395
Loss at iteration 130 : 0.015393088571727276
Loss at iteration 140 : 0.023494182154536247
Loss at iteration 150 : 0.018995733931660652
Loss at iteration 160 : 0.0184578076004982
Loss at iteration 170 : 0.014303786680102348
Loss at iteration 180 : 0.016506128013134003
Loss at iteration 190 : 0.026082515716552734
Loss at iteration 200 : 0.024652890861034393
Loss at iteration 210 : 0.016882754862308502
Loss at iteration 220 : 0.0247445460408926
Loss at iteration 230 : 0.019470300525426865
Loss at iteration 240 : 0.022270241752266884
Loss at iteration 250 : 0.037190914154052734
Loss at iteration 260 : 0.012456653639674187
Loss at iteration 270 : 0.02460411563515663
Loss at iteration 280 : 0.0256042443215847
Loss at iteration 290 : 0.037470754235982895
Loss at iteration 300 : 0.015280069783329964
Loss at iteration 310 : 0.018892992287874222
Loss at iteration 320 : 0.013013331219553947
Loss at iteration 330 : 0.02188379317522049
Loss at iteration 340 : 0.02274474874138832
Loss at iteration 350 : 0.014737391844391823
Loss at iteration 360 : 0.022137751802802086
Loss at iteration 370 : 0.020300637930631638
Loss at iteration 380 : 0.018116943538188934
Loss at iteration 390 : 0.01462915912270546
Loss at iteration 400 : 0.03371558338403702
Loss at iteration 410 : 0.016884563490748405
Loss at iteration 420 : 0.024355819448828697
Loss at iteration 430 : 0.01905255950987339
Loss at iteration 440 : 0.015448717400431633
Loss at iteration 450 : 0.014453714713454247
Loss at iteration 460 : 0.027249354869127274
Loss at iteration 470 : 0.011858917772769928
Loss at iteration 480 : 0.03025335818529129
Loss at iteration 490 : 0.014688840135931969
Loss at iteration 500 : 0.02280489169061184
Loss at iteration 510 : 0.01996830850839615
Loss at iteration 520 : 0.013293297961354256
Loss at iteration 530 : 0.009855278767645359
Loss at iteration 540 : 0.025948558002710342
Loss at iteration 550 : 0.01701296865940094
Loss at iteration 560 : 0.01861170306801796
Loss at iteration 570 : 0.022909633815288544
Loss at iteration 580 : 0.01134010124951601
Loss at iteration 590 : 0.02344794198870659
Loss at iteration 600 : 0.029911091551184654
Loss at iteration 610 : 0.02522020787000656
Loss at iteration 620 : 0.025893917307257652
Loss at iteration 630 : 0.012679817155003548
Loss at iteration 640 : 0.0200410895049572
Loss at iteration 650 : 0.021061977371573448
Loss at iteration 660 : 0.017953690141439438
Loss at iteration 670 : 0.017737938091158867
Loss at iteration 680 : 0.029092110693454742
Loss at iteration 690 : 0.03728097677230835
Loss at iteration 700 : 0.016867412254214287
Loss at iteration 710 : 0.020893776789307594
Loss at iteration 720 : 0.020661095157265663
Loss at iteration 730 : 0.023227229714393616
Loss at iteration 740 : 0.012550845742225647
Loss at iteration 750 : 0.022614113986492157
Loss at iteration 760 : 0.023407191038131714
Loss at iteration 770 : 0.011444599367678165
Loss at iteration 780 : 0.021975496783852577
Loss at iteration 790 : 0.015288293361663818
Loss at iteration 800 : 0.01950831152498722
Loss at iteration 810 : 0.011137229390442371
Loss at iteration 820 : 0.015571506693959236
Loss at iteration 830 : 0.011866954155266285
Loss at iteration 840 : 0.027049586176872253
Loss at iteration 850 : 0.011876998469233513
Loss at iteration 860 : 0.028255697339773178
Loss at iteration 870 : 0.027839932590723038
Loss at iteration 880 : 0.02332599088549614
Loss at iteration 890 : 0.02783374860882759
Loss at iteration 900 : 0.016077056527137756
Loss at iteration 910 : 0.03439118713140488
Loss at iteration 920 : 0.021583426743745804
Loss at iteration 930 : 0.014637955464422703
Loss at iteration 940 : 0.03438158705830574
Loss at iteration 950 : 0.01469389908015728
Loss at iteration 960 : 0.030268177390098572
Loss at iteration 970 : 0.018973469734191895
Loss at iteration 980 : 0.012498011812567711
Loss at iteration 990 : 0.012173498049378395
Loss at iteration 1000 : 0.02156873792409897
Loss at iteration 1010 : 0.022640623152256012
Loss at iteration 1020 : 0.020557625219225883
Loss at iteration 1030 : 0.021190203726291656
Loss at iteration 1040 : 0.016624150797724724
Loss at iteration 1050 : 0.018674097955226898
Loss at iteration 1060 : 0.022157959640026093
Loss at iteration 1070 : 0.02021852135658264
Loss at iteration 1080 : 0.015995362773537636
Loss at iteration 1090 : 0.012736128643155098
Loss at iteration 1100 : 0.03731293976306915
Loss at iteration 1110 : 0.010884498246014118
Loss at iteration 1120 : 0.023736968636512756
Loss at iteration 1130 : 0.01747807115316391
Loss at iteration 1140 : 0.017864588648080826
Loss at iteration 1150 : 0.037535782903432846
Loss at iteration 1160 : 0.0201811995357275
Loss at iteration 1170 : 0.016536785289645195
Loss at iteration 1180 : 0.03267579525709152
Loss at iteration 1190 : 0.02030055969953537
Loss at iteration 1200 : 0.019772719591856003
Loss at iteration 1210 : 0.01673879288136959
The SSIM Value is: 0.7906620264053345
The PSNR Value is: 19.339920616149904
the epoch is: 128
Loss at iteration 10 : 0.015089675784111023
Loss at iteration 20 : 0.03261952847242355
Loss at iteration 30 : 0.0367138609290123
Loss at iteration 40 : 0.014430291950702667
Loss at iteration 50 : 0.01271354965865612
Loss at iteration 60 : 0.016562417149543762
Loss at iteration 70 : 0.017795786261558533
Loss at iteration 80 : 0.028368255123496056
Loss at iteration 90 : 0.02013583853840828
Loss at iteration 100 : 0.012771222740411758
Loss at iteration 110 : 0.017881864681839943
Loss at iteration 120 : 0.018856355920433998
Loss at iteration 130 : 0.02056194469332695
Loss at iteration 140 : 0.022323481738567352
Loss at iteration 150 : 0.025344332680106163
Loss at iteration 160 : 0.01604416035115719
Loss at iteration 170 : 0.019536521285772324
Loss at iteration 180 : 0.020683012902736664
Loss at iteration 190 : 0.012119685299694538
Loss at iteration 200 : 0.026932161301374435
Loss at iteration 210 : 0.03742784261703491
Loss at iteration 220 : 0.013792973011732101
Loss at iteration 230 : 0.019217748194932938
Loss at iteration 240 : 0.011695751920342445
Loss at iteration 250 : 0.022420760244131088
Loss at iteration 260 : 0.021134085953235626
Loss at iteration 270 : 0.027295077219605446
Loss at iteration 280 : 0.015930280089378357
Loss at iteration 290 : 0.034841589629650116
Loss at iteration 300 : 0.020874634385108948
Loss at iteration 310 : 0.013731912709772587
Loss at iteration 320 : 0.01626557484269142
Loss at iteration 330 : 0.013064916245639324
Loss at iteration 340 : 0.01659298874437809
Loss at iteration 350 : 0.04304700344800949
Loss at iteration 360 : 0.014253739267587662
Loss at iteration 370 : 0.017490815371274948
Loss at iteration 380 : 0.017900608479976654
Loss at iteration 390 : 0.01916375756263733
Loss at iteration 400 : 0.022608451545238495
Loss at iteration 410 : 0.01841764897108078
Loss at iteration 420 : 0.01110759750008583
Loss at iteration 430 : 0.02226167544722557
Loss at iteration 440 : 0.02188263274729252
Loss at iteration 450 : 0.025425788015127182
Loss at iteration 460 : 0.015418248251080513
Loss at iteration 470 : 0.027452068403363228
Loss at iteration 480 : 0.015004958026111126
Loss at iteration 490 : 0.017813321202993393
Loss at iteration 500 : 0.025183726102113724
Loss at iteration 510 : 0.02484307438135147
Loss at iteration 520 : 0.017864443361759186
Loss at iteration 530 : 0.012144962325692177
Loss at iteration 540 : 0.02094436250627041
Loss at iteration 550 : 0.028902949765324593
Loss at iteration 560 : 0.028621995821595192
Loss at iteration 570 : 0.018478285521268845
Loss at iteration 580 : 0.019251616671681404
Loss at iteration 590 : 0.01341874897480011
Loss at iteration 600 : 0.010429954156279564
Loss at iteration 610 : 0.01590433157980442
Loss at iteration 620 : 0.017549851909279823
Loss at iteration 630 : 0.01706906408071518
Loss at iteration 640 : 0.015884045511484146
Loss at iteration 650 : 0.015553662553429604
Loss at iteration 660 : 0.022494368255138397
Loss at iteration 670 : 0.010254871100187302
Loss at iteration 680 : 0.02991580218076706
Loss at iteration 690 : 0.016976773738861084
Loss at iteration 700 : 0.011194865219295025
Loss at iteration 710 : 0.019130803644657135
Loss at iteration 720 : 0.029908429831266403
Loss at iteration 730 : 0.01080908440053463
Loss at iteration 740 : 0.015074629336595535
Loss at iteration 750 : 0.029761021956801414
Loss at iteration 760 : 0.031507089734077454
Loss at iteration 770 : 0.01106235384941101
Loss at iteration 780 : 0.010043775662779808
Loss at iteration 790 : 0.01719442941248417
Loss at iteration 800 : 0.025642473250627518
Loss at iteration 810 : 0.024556590244174004
Loss at iteration 820 : 0.017651334404945374
Loss at iteration 830 : 0.03313470631837845
Loss at iteration 840 : 0.01706795021891594
Loss at iteration 850 : 0.015792086720466614
Loss at iteration 860 : 0.021598873659968376
Loss at iteration 870 : 0.021661031991243362
Loss at iteration 880 : 0.026034973561763763
Loss at iteration 890 : 0.016619818285107613
Loss at iteration 900 : 0.014731056988239288
Loss at iteration 910 : 0.015674103051424026
Loss at iteration 920 : 0.030725829303264618
Loss at iteration 930 : 0.02774270996451378
Loss at iteration 940 : 0.010806296952068806
Loss at iteration 950 : 0.019917285069823265
Loss at iteration 960 : 0.025813724845647812
Loss at iteration 970 : 0.017703022807836533
Loss at iteration 980 : 0.03479931503534317
Loss at iteration 990 : 0.019656412303447723
Loss at iteration 1000 : 0.017625251784920692
Loss at iteration 1010 : 0.015712300315499306
Loss at iteration 1020 : 0.016627661883831024
Loss at iteration 1030 : 0.035344742238521576
Loss at iteration 1040 : 0.013122627511620522
Loss at iteration 1050 : 0.013639451004564762
Loss at iteration 1060 : 0.017343685030937195
Loss at iteration 1070 : 0.019318703562021255
Loss at iteration 1080 : 0.00883357785642147
Loss at iteration 1090 : 0.01919759064912796
Loss at iteration 1100 : 0.018365144729614258
Loss at iteration 1110 : 0.021395020186901093
Loss at iteration 1120 : 0.0151562774553895
Loss at iteration 1130 : 0.021048415452241898
Loss at iteration 1140 : 0.017113156616687775
Loss at iteration 1150 : 0.013045595958828926
Loss at iteration 1160 : 0.024906370788812637
Loss at iteration 1170 : 0.014011848717927933
Loss at iteration 1180 : 0.022640317678451538
Loss at iteration 1190 : 0.02632126584649086
Loss at iteration 1200 : 0.020367495715618134
Loss at iteration 1210 : 0.03799964115023613
The SSIM Value is: 0.7467213153839112
The PSNR Value is: 17.036391321818034
the epoch is: 129
Loss at iteration 10 : 0.015425688587129116
Loss at iteration 20 : 0.02201683260500431
Loss at iteration 30 : 0.019305113703012466
Loss at iteration 40 : 0.014515969902276993
Loss at iteration 50 : 0.027088157832622528
Loss at iteration 60 : 0.015511542558670044
Loss at iteration 70 : 0.020334742963314056
Loss at iteration 80 : 0.018090249970555305
Loss at iteration 90 : 0.02410981059074402
Loss at iteration 100 : 0.022039860486984253
Loss at iteration 110 : 0.029372386634349823
Loss at iteration 120 : 0.019893767312169075
Loss at iteration 130 : 0.012021967209875584
Loss at iteration 140 : 0.017965350300073624
Loss at iteration 150 : 0.02517876774072647
Loss at iteration 160 : 0.01166640967130661
Loss at iteration 170 : 0.028464488685131073
Loss at iteration 180 : 0.022059552371501923
Loss at iteration 190 : 0.016247984021902084
Loss at iteration 200 : 0.011912001296877861
Loss at iteration 210 : 0.016818955540657043
Loss at iteration 220 : 0.01416441798210144
Loss at iteration 230 : 0.011228149756789207
Loss at iteration 240 : 0.018881354480981827
Loss at iteration 250 : 0.018539857119321823
Loss at iteration 260 : 0.01958238147199154
Loss at iteration 270 : 0.021753806620836258
Loss at iteration 280 : 0.019371189177036285
Loss at iteration 290 : 0.01432137843221426
Loss at iteration 300 : 0.020920781418681145
Loss at iteration 310 : 0.018138034269213676
Loss at iteration 320 : 0.01935681141912937
Loss at iteration 330 : 0.01683034375309944
Loss at iteration 340 : 0.02213401161134243
Loss at iteration 350 : 0.022546175867319107
Loss at iteration 360 : 0.02430613897740841
Loss at iteration 370 : 0.017591383308172226
Loss at iteration 380 : 0.030806230381131172
Loss at iteration 390 : 0.025778761133551598
Loss at iteration 400 : 0.022130273282527924
Loss at iteration 410 : 0.01396532729268074
Loss at iteration 420 : 0.022666873410344124
Loss at iteration 430 : 0.017410680651664734
Loss at iteration 440 : 0.013588909059762955
Loss at iteration 450 : 0.02331499382853508
Loss at iteration 460 : 0.012768872082233429
Loss at iteration 470 : 0.014916680753231049
Loss at iteration 480 : 0.017973700538277626
Loss at iteration 490 : 0.01785457879304886
Loss at iteration 500 : 0.03204230219125748
Loss at iteration 510 : 0.016751132905483246
Loss at iteration 520 : 0.017089558765292168
Loss at iteration 530 : 0.01787429302930832
Loss at iteration 540 : 0.027779720723628998
Loss at iteration 550 : 0.01633974350988865
Loss at iteration 560 : 0.0285054761916399
Loss at iteration 570 : 0.024399619549512863
Loss at iteration 580 : 0.018212631344795227
Loss at iteration 590 : 0.011442713439464569
Loss at iteration 600 : 0.0187714584171772
Loss at iteration 610 : 0.02700085937976837
Loss at iteration 620 : 0.019925907254219055
Loss at iteration 630 : 0.02490583434700966
Loss at iteration 640 : 0.02405824139714241
Loss at iteration 650 : 0.023864325135946274
Loss at iteration 660 : 0.017158143222332
Loss at iteration 670 : 0.01556386612355709
Loss at iteration 680 : 0.017779458314180374
Loss at iteration 690 : 0.01659325882792473
Loss at iteration 700 : 0.017107684165239334
Loss at iteration 710 : 0.023311519995331764
Loss at iteration 720 : 0.02185758203268051
Loss at iteration 730 : 0.011903693899512291
Loss at iteration 740 : 0.02514723688364029
Loss at iteration 750 : 0.027291234582662582
Loss at iteration 760 : 0.025152724236249924
Loss at iteration 770 : 0.028269540518522263
Loss at iteration 780 : 0.021022314205765724
Loss at iteration 790 : 0.029567407444119453
Loss at iteration 800 : 0.021690763533115387
Loss at iteration 810 : 0.012152408249676228
Loss at iteration 820 : 0.020755555480718613
Loss at iteration 830 : 0.014993605203926563
Loss at iteration 840 : 0.014172006398439407
Loss at iteration 850 : 0.017067834734916687
Loss at iteration 860 : 0.02633935771882534
Loss at iteration 870 : 0.013001573272049427
Loss at iteration 880 : 0.01357441209256649
Loss at iteration 890 : 0.019244153052568436
Loss at iteration 900 : 0.0317569337785244
Loss at iteration 910 : 0.016216643154621124
Loss at iteration 920 : 0.023790307343006134
Loss at iteration 930 : 0.017924023792147636
Loss at iteration 940 : 0.01920200325548649
Loss at iteration 950 : 0.01905992440879345
Loss at iteration 960 : 0.017348775640130043
Loss at iteration 970 : 0.024024398997426033
Loss at iteration 980 : 0.018407264724373817
Loss at iteration 990 : 0.012844538316130638
Loss at iteration 1000 : 0.012466998770833015
Loss at iteration 1010 : 0.018240053206682205
Loss at iteration 1020 : 0.02065170370042324
Loss at iteration 1030 : 0.01454746164381504
Loss at iteration 1040 : 0.012290643528103828
Loss at iteration 1050 : 0.015542956069111824
Loss at iteration 1060 : 0.01762084849178791
Loss at iteration 1070 : 0.023485053330659866
Loss at iteration 1080 : 0.022373732179403305
Loss at iteration 1090 : 0.02255723811686039
Loss at iteration 1100 : 0.016699327155947685
Loss at iteration 1110 : 0.021083561703562737
Loss at iteration 1120 : 0.01802997663617134
Loss at iteration 1130 : 0.0216226764023304
Loss at iteration 1140 : 0.01755707897245884
Loss at iteration 1150 : 0.012263365089893341
Loss at iteration 1160 : 0.033000651746988297
Loss at iteration 1170 : 0.018169976770877838
Loss at iteration 1180 : 0.017633667215704918
Loss at iteration 1190 : 0.021315734833478928
Loss at iteration 1200 : 0.02715454250574112
Loss at iteration 1210 : 0.01139543391764164
The SSIM Value is: 0.80372713804245
The PSNR Value is: 19.650269762674967
the epoch is: 130
Loss at iteration 10 : 0.014430087059736252
Loss at iteration 20 : 0.022429604083299637
Loss at iteration 30 : 0.0149109261110425
Loss at iteration 40 : 0.015529708936810493
Loss at iteration 50 : 0.020424993708729744
Loss at iteration 60 : 0.014050742611289024
Loss at iteration 70 : 0.016318853944540024
Loss at iteration 80 : 0.01691783405840397
Loss at iteration 90 : 0.009912421926856041
Loss at iteration 100 : 0.01931171678006649
Loss at iteration 110 : 0.018923789262771606
Loss at iteration 120 : 0.02118821069598198
Loss at iteration 130 : 0.016553953289985657
Loss at iteration 140 : 0.013364946469664574
Loss at iteration 150 : 0.01637941598892212
Loss at iteration 160 : 0.02198946103453636
Loss at iteration 170 : 0.020038381218910217
Loss at iteration 180 : 0.02137935906648636
Loss at iteration 190 : 0.01979248970746994
Loss at iteration 200 : 0.021497715264558792
Loss at iteration 210 : 0.018136827275156975
Loss at iteration 220 : 0.012051671743392944
Loss at iteration 230 : 0.019488021731376648
Loss at iteration 240 : 0.018712442368268967
Loss at iteration 250 : 0.02727556601166725
Loss at iteration 260 : 0.011968923732638359
Loss at iteration 270 : 0.019325708970427513
Loss at iteration 280 : 0.016741730272769928
Loss at iteration 290 : 0.026275360956788063
Loss at iteration 300 : 0.022670235484838486
Loss at iteration 310 : 0.01684526354074478
Loss at iteration 320 : 0.016223911195993423
Loss at iteration 330 : 0.02388029545545578
Loss at iteration 340 : 0.023265168070793152
Loss at iteration 350 : 0.012862071394920349
Loss at iteration 360 : 0.03243379667401314
Loss at iteration 370 : 0.018996182829141617
Loss at iteration 380 : 0.03812205046415329
Loss at iteration 390 : 0.03841092437505722
Loss at iteration 400 : 0.025410180911421776
Loss at iteration 410 : 0.027532752603292465
Loss at iteration 420 : 0.031759463250637054
Loss at iteration 430 : 0.021043535321950912
Loss at iteration 440 : 0.02314358577132225
Loss at iteration 450 : 0.015377897769212723
Loss at iteration 460 : 0.021650496870279312
Loss at iteration 470 : 0.02029729261994362
Loss at iteration 480 : 0.01156559493392706
Loss at iteration 490 : 0.02270129695534706
Loss at iteration 500 : 0.01576850935816765
Loss at iteration 510 : 0.02735023945569992
Loss at iteration 520 : 0.013347677886486053
Loss at iteration 530 : 0.017447564750909805
Loss at iteration 540 : 0.013686858117580414
Loss at iteration 550 : 0.024859869852662086
Loss at iteration 560 : 0.01549982838332653
Loss at iteration 570 : 0.01765535958111286
Loss at iteration 580 : 0.024621836841106415
Loss at iteration 590 : 0.029566200450062752
Loss at iteration 600 : 0.015235439874231815
Loss at iteration 610 : 0.021622665226459503
Loss at iteration 620 : 0.011607186868786812
Loss at iteration 630 : 0.022017939016222954
Loss at iteration 640 : 0.026737991720438004
Loss at iteration 650 : 0.01720721647143364
Loss at iteration 660 : 0.015056755393743515
Loss at iteration 670 : 0.023032179102301598
Loss at iteration 680 : 0.01810838282108307
Loss at iteration 690 : 0.025713708251714706
Loss at iteration 700 : 0.014352967031300068
Loss at iteration 710 : 0.013520179316401482
Loss at iteration 720 : 0.028005698695778847
Loss at iteration 730 : 0.017421232536435127
Loss at iteration 740 : 0.016768496483564377
Loss at iteration 750 : 0.01640285924077034
Loss at iteration 760 : 0.01829363778233528
Loss at iteration 770 : 0.019290965050458908
Loss at iteration 780 : 0.018632784485816956
Loss at iteration 790 : 0.02111246809363365
Loss at iteration 800 : 0.017820753157138824
Loss at iteration 810 : 0.022236231714487076
Loss at iteration 820 : 0.020582957193255424
Loss at iteration 830 : 0.019863219931721687
Loss at iteration 840 : 0.01803731545805931
Loss at iteration 850 : 0.02723335102200508
Loss at iteration 860 : 0.021135225892066956
Loss at iteration 870 : 0.011433391831815243
Loss at iteration 880 : 0.018261782824993134
Loss at iteration 890 : 0.0154180396348238
Loss at iteration 900 : 0.017577793449163437
Loss at iteration 910 : 0.016411587595939636
Loss at iteration 920 : 0.01301603950560093
Loss at iteration 930 : 0.022010862827301025
Loss at iteration 940 : 0.029745496809482574
Loss at iteration 950 : 0.021200008690357208
Loss at iteration 960 : 0.024566777050495148
Loss at iteration 970 : 0.018238812685012817
Loss at iteration 980 : 0.015303559601306915
Loss at iteration 990 : 0.027808712795376778
Loss at iteration 1000 : 0.015583247877657413
Loss at iteration 1010 : 0.012940684333443642
Loss at iteration 1020 : 0.019076533615589142
Loss at iteration 1030 : 0.017334189265966415
Loss at iteration 1040 : 0.01809873804450035
Loss at iteration 1050 : 0.028912870213389397
Loss at iteration 1060 : 0.016387738287448883
Loss at iteration 1070 : 0.022040460258722305
Loss at iteration 1080 : 0.022780677303671837
Loss at iteration 1090 : 0.0259418785572052
Loss at iteration 1100 : 0.014968937262892723
Loss at iteration 1110 : 0.0141599141061306
Loss at iteration 1120 : 0.02345481514930725
Loss at iteration 1130 : 0.019362585619091988
Loss at iteration 1140 : 0.014975476078689098
Loss at iteration 1150 : 0.015919668599963188
Loss at iteration 1160 : 0.029038328677415848
Loss at iteration 1170 : 0.017313089221715927
Loss at iteration 1180 : 0.01571609079837799
Loss at iteration 1190 : 0.022979799658060074
Loss at iteration 1200 : 0.018170475959777832
Loss at iteration 1210 : 0.023002006113529205
The SSIM Value is: 0.7993816057840983
The PSNR Value is: 19.71833890279134
the epoch is: 131
Loss at iteration 10 : 0.014396881684660912
Loss at iteration 20 : 0.02547473832964897
Loss at iteration 30 : 0.02444816380739212
Loss at iteration 40 : 0.025724485516548157
Loss at iteration 50 : 0.020288914442062378
Loss at iteration 60 : 0.011275585740804672
Loss at iteration 70 : 0.01718200370669365
Loss at iteration 80 : 0.017179034650325775
Loss at iteration 90 : 0.012917229905724525
Loss at iteration 100 : 0.019006293267011642
Loss at iteration 110 : 0.01864929124712944
Loss at iteration 120 : 0.022976666688919067
Loss at iteration 130 : 0.014982728287577629
Loss at iteration 140 : 0.01736614666879177
Loss at iteration 150 : 0.015380986034870148
Loss at iteration 160 : 0.01677786186337471
Loss at iteration 170 : 0.018737105652689934
Loss at iteration 180 : 0.014195417985320091
Loss at iteration 190 : 0.015904832631349564
Loss at iteration 200 : 0.019818825647234917
Loss at iteration 210 : 0.014627739787101746
Loss at iteration 220 : 0.025416430085897446
Loss at iteration 230 : 0.03509405255317688
Loss at iteration 240 : 0.016709083691239357
Loss at iteration 250 : 0.022089455276727676
Loss at iteration 260 : 0.014441566541790962
Loss at iteration 270 : 0.022247906774282455
Loss at iteration 280 : 0.025829151272773743
Loss at iteration 290 : 0.03784938156604767
Loss at iteration 300 : 0.018045544624328613
Loss at iteration 310 : 0.02406623587012291
Loss at iteration 320 : 0.02322058007121086
Loss at iteration 330 : 0.026523452252149582
Loss at iteration 340 : 0.023670844733715057
Loss at iteration 350 : 0.01817615143954754
Loss at iteration 360 : 0.0201265811920166
Loss at iteration 370 : 0.0167868472635746
Loss at iteration 380 : 0.012390894815325737
Loss at iteration 390 : 0.016691749915480614
Loss at iteration 400 : 0.022666452452540398
Loss at iteration 410 : 0.019570715725421906
Loss at iteration 420 : 0.014885169453918934
Loss at iteration 430 : 0.013419074937701225
Loss at iteration 440 : 0.01589684933423996
Loss at iteration 450 : 0.02866370603442192
Loss at iteration 460 : 0.017801115289330482
Loss at iteration 470 : 0.018659476190805435
Loss at iteration 480 : 0.013022475875914097
Loss at iteration 490 : 0.028290078043937683
Loss at iteration 500 : 0.019501643255352974
Loss at iteration 510 : 0.031188828870654106
Loss at iteration 520 : 0.018797392025589943
Loss at iteration 530 : 0.026973526924848557
Loss at iteration 540 : 0.013531685806810856
Loss at iteration 550 : 0.016455426812171936
Loss at iteration 560 : 0.028103899210691452
Loss at iteration 570 : 0.026387905701994896
Loss at iteration 580 : 0.025828970596194267
Loss at iteration 590 : 0.01827523484826088
Loss at iteration 600 : 0.013867656700313091
Loss at iteration 610 : 0.016059905290603638
Loss at iteration 620 : 0.038280412554740906
Loss at iteration 630 : 0.023468375205993652
Loss at iteration 640 : 0.03838292881846428
Loss at iteration 650 : 0.019884156063199043
Loss at iteration 660 : 0.012332433834671974
Loss at iteration 670 : 0.01867193728685379
Loss at iteration 680 : 0.01885230839252472
Loss at iteration 690 : 0.02112995833158493
Loss at iteration 700 : 0.032418977469205856
Loss at iteration 710 : 0.02424541302025318
Loss at iteration 720 : 0.010436085984110832
Loss at iteration 730 : 0.016376039013266563
Loss at iteration 740 : 0.018870536237955093
Loss at iteration 750 : 0.02227756753563881
Loss at iteration 760 : 0.019167130813002586
Loss at iteration 770 : 0.026258010417222977
Loss at iteration 780 : 0.014430904760956764
Loss at iteration 790 : 0.020465176552534103
Loss at iteration 800 : 0.017838364467024803
Loss at iteration 810 : 0.027438722550868988
Loss at iteration 820 : 0.016461918130517006
Loss at iteration 830 : 0.03783942759037018
Loss at iteration 840 : 0.019750328734517097
Loss at iteration 850 : 0.013701986521482468
Loss at iteration 860 : 0.018199000507593155
Loss at iteration 870 : 0.028737880289554596
Loss at iteration 880 : 0.02017590031027794
Loss at iteration 890 : 0.019029244780540466
Loss at iteration 900 : 0.0243753083050251
Loss at iteration 910 : 0.011705027893185616
Loss at iteration 920 : 0.023149464279413223
Loss at iteration 930 : 0.015294397249817848
Loss at iteration 940 : 0.03027547150850296
Loss at iteration 950 : 0.02745896764099598
Loss at iteration 960 : 0.018337955698370934
Loss at iteration 970 : 0.01904534548521042
Loss at iteration 980 : 0.02789890766143799
Loss at iteration 990 : 0.010365002788603306
Loss at iteration 1000 : 0.01162696536630392
Loss at iteration 1010 : 0.021119123324751854
Loss at iteration 1020 : 0.01830216497182846
Loss at iteration 1030 : 0.02125611901283264
Loss at iteration 1040 : 0.014914331957697868
Loss at iteration 1050 : 0.027888167649507523
Loss at iteration 1060 : 0.01366362627595663
Loss at iteration 1070 : 0.02702995389699936
Loss at iteration 1080 : 0.017621271312236786
Loss at iteration 1090 : 0.01754084601998329
Loss at iteration 1100 : 0.01581403613090515
Loss at iteration 1110 : 0.016402151435613632
Loss at iteration 1120 : 0.03249353915452957
Loss at iteration 1130 : 0.022541124373674393
Loss at iteration 1140 : 0.01815965585410595
Loss at iteration 1150 : 0.029521089047193527
Loss at iteration 1160 : 0.02651369944214821
Loss at iteration 1170 : 0.011189601384103298
Loss at iteration 1180 : 0.013688365928828716
Loss at iteration 1190 : 0.02901827171444893
Loss at iteration 1200 : 0.0280632171779871
Loss at iteration 1210 : 0.017992932349443436
The SSIM Value is: 0.8040607293446859
The PSNR Value is: 19.83587729136149
the epoch is: 132
Loss at iteration 10 : 0.012990310788154602
Loss at iteration 20 : 0.01139672938734293
Loss at iteration 30 : 0.012116793543100357
Loss at iteration 40 : 0.02555115520954132
Loss at iteration 50 : 0.026052042841911316
Loss at iteration 60 : 0.011015418916940689
Loss at iteration 70 : 0.016804536804556847
Loss at iteration 80 : 0.023403625935316086
Loss at iteration 90 : 0.02608058787882328
Loss at iteration 100 : 0.01590980961918831
Loss at iteration 110 : 0.016682766377925873
Loss at iteration 120 : 0.016394803300499916
Loss at iteration 130 : 0.01845218986272812
Loss at iteration 140 : 0.02210991457104683
Loss at iteration 150 : 0.018169531598687172
Loss at iteration 160 : 0.013312781229615211
Loss at iteration 170 : 0.01440974697470665
Loss at iteration 180 : 0.01519947499036789
Loss at iteration 190 : 0.022202512249350548
Loss at iteration 200 : 0.022955644875764847
Loss at iteration 210 : 0.028860002756118774
Loss at iteration 220 : 0.012339288368821144
Loss at iteration 230 : 0.028440766036510468
Loss at iteration 240 : 0.01943061500787735
Loss at iteration 250 : 0.025585414841771126
Loss at iteration 260 : 0.025097079575061798
Loss at iteration 270 : 0.01970764994621277
Loss at iteration 280 : 0.019110698252916336
Loss at iteration 290 : 0.02107967622578144
Loss at iteration 300 : 0.021675752475857735
Loss at iteration 310 : 0.014701594598591328
Loss at iteration 320 : 0.02216789871454239
Loss at iteration 330 : 0.0237291157245636
Loss at iteration 340 : 0.01719726249575615
Loss at iteration 350 : 0.024486027657985687
Loss at iteration 360 : 0.01617571897804737
Loss at iteration 370 : 0.030324110761284828
Loss at iteration 380 : 0.011152837425470352
Loss at iteration 390 : 0.016778822988271713
Loss at iteration 400 : 0.018861722201108932
Loss at iteration 410 : 0.022214798256754875
Loss at iteration 420 : 0.02486736699938774
Loss at iteration 430 : 0.011412665247917175
Loss at iteration 440 : 0.01678810454905033
Loss at iteration 450 : 0.034110963344573975
Loss at iteration 460 : 0.022054074332118034
Loss at iteration 470 : 0.016559116542339325
Loss at iteration 480 : 0.018567897379398346
Loss at iteration 490 : 0.01945372298359871
Loss at iteration 500 : 0.016858134418725967
Loss at iteration 510 : 0.024565590545535088
Loss at iteration 520 : 0.017464321106672287
Loss at iteration 530 : 0.01918647810816765
Loss at iteration 540 : 0.019024228677153587
Loss at iteration 550 : 0.009350812993943691
Loss at iteration 560 : 0.028092872351408005
Loss at iteration 570 : 0.016743991523981094
Loss at iteration 580 : 0.01566612906754017
Loss at iteration 590 : 0.023822804912924767
Loss at iteration 600 : 0.01808129996061325
Loss at iteration 610 : 0.01896708458662033
Loss at iteration 620 : 0.013952418230473995
Loss at iteration 630 : 0.021012596786022186
Loss at iteration 640 : 0.020503012463450432
Loss at iteration 650 : 0.014333024621009827
Loss at iteration 660 : 0.014551359228789806
Loss at iteration 670 : 0.022600539028644562
Loss at iteration 680 : 0.015138629823923111
Loss at iteration 690 : 0.014067616313695908
Loss at iteration 700 : 0.03172879293560982
Loss at iteration 710 : 0.017433354631066322
Loss at iteration 720 : 0.023937325924634933
Loss at iteration 730 : 0.029004093259572983
Loss at iteration 740 : 0.020569976419210434
Loss at iteration 750 : 0.0240720734000206
Loss at iteration 760 : 0.015773432329297066
Loss at iteration 770 : 0.015336109325289726
Loss at iteration 780 : 0.015263374894857407
Loss at iteration 790 : 0.024645918980240822
Loss at iteration 800 : 0.01888907700777054
Loss at iteration 810 : 0.02414545975625515
Loss at iteration 820 : 0.019333524629473686
Loss at iteration 830 : 0.0251352246850729
Loss at iteration 840 : 0.014449745416641235
Loss at iteration 850 : 0.024451132863759995
Loss at iteration 860 : 0.012983125634491444
Loss at iteration 870 : 0.02195456624031067
Loss at iteration 880 : 0.012342344969511032
Loss at iteration 890 : 0.016757406294345856
Loss at iteration 900 : 0.018833985552191734
Loss at iteration 910 : 0.020790662616491318
Loss at iteration 920 : 0.01514521799981594
Loss at iteration 930 : 0.013441778719425201
Loss at iteration 940 : 0.013336696662008762
Loss at iteration 950 : 0.022565962746739388
Loss at iteration 960 : 0.026053277775645256
Loss at iteration 970 : 0.02613273821771145
Loss at iteration 980 : 0.020188283175230026
Loss at iteration 990 : 0.022097289562225342
Loss at iteration 1000 : 0.015429142862558365
Loss at iteration 1010 : 0.028360895812511444
Loss at iteration 1020 : 0.014355848543345928
Loss at iteration 1030 : 0.014568117447197437
Loss at iteration 1040 : 0.013308282941579819
Loss at iteration 1050 : 0.020779795944690704
Loss at iteration 1060 : 0.02037631720304489
Loss at iteration 1070 : 0.011484749615192413
Loss at iteration 1080 : 0.026615560054779053
Loss at iteration 1090 : 0.01911383867263794
Loss at iteration 1100 : 0.019512124359607697
Loss at iteration 1110 : 0.03294721618294716
Loss at iteration 1120 : 0.027851715683937073
Loss at iteration 1130 : 0.029341693967580795
Loss at iteration 1140 : 0.028123831376433372
Loss at iteration 1150 : 0.015517241321504116
Loss at iteration 1160 : 0.02527434006333351
Loss at iteration 1170 : 0.016831478103995323
Loss at iteration 1180 : 0.01730921119451523
Loss at iteration 1190 : 0.01776036061346531
Loss at iteration 1200 : 0.022298870608210564
Loss at iteration 1210 : 0.023099679499864578
The SSIM Value is: 0.8013122200965881
The PSNR Value is: 19.20932782491048
the epoch is: 133
Loss at iteration 10 : 0.022311361506581306
Loss at iteration 20 : 0.026597941294312477
Loss at iteration 30 : 0.0219016931951046
Loss at iteration 40 : 0.021836159750819206
Loss at iteration 50 : 0.03622005134820938
Loss at iteration 60 : 0.02745952270925045
Loss at iteration 70 : 0.015332765877246857
Loss at iteration 80 : 0.020272737368941307
Loss at iteration 90 : 0.01843874156475067
Loss at iteration 100 : 0.011856765486299992
Loss at iteration 110 : 0.026015831157565117
Loss at iteration 120 : 0.019424617290496826
Loss at iteration 130 : 0.021287133917212486
Loss at iteration 140 : 0.025183822959661484
Loss at iteration 150 : 0.026605261489748955
Loss at iteration 160 : 0.030479859560728073
Loss at iteration 170 : 0.01591617986559868
Loss at iteration 180 : 0.022046208381652832
Loss at iteration 190 : 0.01698860339820385
Loss at iteration 200 : 0.022729279473423958
Loss at iteration 210 : 0.017705073580145836
Loss at iteration 220 : 0.029814086854457855
Loss at iteration 230 : 0.019756395369768143
Loss at iteration 240 : 0.025372928008437157
Loss at iteration 250 : 0.017964810132980347
Loss at iteration 260 : 0.021663978695869446
Loss at iteration 270 : 0.014624455943703651
Loss at iteration 280 : 0.007440554443746805
Loss at iteration 290 : 0.01645701378583908
Loss at iteration 300 : 0.02094717137515545
Loss at iteration 310 : 0.023780640214681625
Loss at iteration 320 : 0.019828110933303833
Loss at iteration 330 : 0.02555156499147415
Loss at iteration 340 : 0.02768881618976593
Loss at iteration 350 : 0.019945858046412468
Loss at iteration 360 : 0.03355248272418976
Loss at iteration 370 : 0.017617303878068924
Loss at iteration 380 : 0.018385468050837517
Loss at iteration 390 : 0.025304462760686874
Loss at iteration 400 : 0.020345361903309822
Loss at iteration 410 : 0.03334109112620354
Loss at iteration 420 : 0.014595074579119682
Loss at iteration 430 : 0.011485305614769459
Loss at iteration 440 : 0.027027718722820282
Loss at iteration 450 : 0.014674564823508263
Loss at iteration 460 : 0.01601407676935196
Loss at iteration 470 : 0.02298569306731224
Loss at iteration 480 : 0.014281751587986946
Loss at iteration 490 : 0.01820114254951477
Loss at iteration 500 : 0.020741980522871017
Loss at iteration 510 : 0.022666625678539276
Loss at iteration 520 : 0.03193436935544014
Loss at iteration 530 : 0.03139972314238548
Loss at iteration 540 : 0.02431107684969902
Loss at iteration 550 : 0.013689309358596802
Loss at iteration 560 : 0.01692180521786213
Loss at iteration 570 : 0.013108591549098492
Loss at iteration 580 : 0.02843312732875347
Loss at iteration 590 : 0.016424058005213737
Loss at iteration 600 : 0.021280840039253235
Loss at iteration 610 : 0.020994089543819427
Loss at iteration 620 : 0.019216187298297882
Loss at iteration 630 : 0.01311391219496727
Loss at iteration 640 : 0.015492348000407219
Loss at iteration 650 : 0.013330590911209583
Loss at iteration 660 : 0.011615176685154438
Loss at iteration 670 : 0.02417866140604019
Loss at iteration 680 : 0.019255071878433228
Loss at iteration 690 : 0.028226498514413834
Loss at iteration 700 : 0.02242780104279518
Loss at iteration 710 : 0.029551353305578232
Loss at iteration 720 : 0.010763546451926231
Loss at iteration 730 : 0.022461630403995514
Loss at iteration 740 : 0.021662933751940727
Loss at iteration 750 : 0.022221574559807777
Loss at iteration 760 : 0.01501987874507904
Loss at iteration 770 : 0.009542451240122318
Loss at iteration 780 : 0.021043071523308754
Loss at iteration 790 : 0.01758621446788311
Loss at iteration 800 : 0.01537260226905346
Loss at iteration 810 : 0.023640189319849014
Loss at iteration 820 : 0.028305768966674805
Loss at iteration 830 : 0.02185557223856449
Loss at iteration 840 : 0.019780263304710388
Loss at iteration 850 : 0.017094576731324196
Loss at iteration 860 : 0.011082304641604424
Loss at iteration 870 : 0.01293281838297844
Loss at iteration 880 : 0.03711560368537903
Loss at iteration 890 : 0.020192252472043037
Loss at iteration 900 : 0.01998715102672577
Loss at iteration 910 : 0.019474457949399948
Loss at iteration 920 : 0.025500532239675522
Loss at iteration 930 : 0.029035497456789017
Loss at iteration 940 : 0.017330430448055267
Loss at iteration 950 : 0.02832242101430893
Loss at iteration 960 : 0.022761130705475807
Loss at iteration 970 : 0.03736886382102966
Loss at iteration 980 : 0.02257244847714901
Loss at iteration 990 : 0.026825418695807457
Loss at iteration 1000 : 0.02492460235953331
Loss at iteration 1010 : 0.02452349290251732
Loss at iteration 1020 : 0.02098994329571724
Loss at iteration 1030 : 0.02728453278541565
Loss at iteration 1040 : 0.025592613965272903
Loss at iteration 1050 : 0.020882733166217804
Loss at iteration 1060 : 0.014074761420488358
Loss at iteration 1070 : 0.016610488295555115
Loss at iteration 1080 : 0.016104981303215027
Loss at iteration 1090 : 0.024977635592222214
Loss at iteration 1100 : 0.02255651168525219
Loss at iteration 1110 : 0.020171253010630608
Loss at iteration 1120 : 0.015394294634461403
Loss at iteration 1130 : 0.02595747448503971
Loss at iteration 1140 : 0.02885263040661812
Loss at iteration 1150 : 0.011107269674539566
Loss at iteration 1160 : 0.012141810730099678
Loss at iteration 1170 : 0.023211248219013214
Loss at iteration 1180 : 0.02639545127749443
Loss at iteration 1190 : 0.016742972657084465
Loss at iteration 1200 : 0.019107457250356674
Loss at iteration 1210 : 0.01895994506776333
The SSIM Value is: 0.7976300795873006
The PSNR Value is: 19.23987038930257
the epoch is: 134
Loss at iteration 10 : 0.024676255881786346
Loss at iteration 20 : 0.028257982805371284
Loss at iteration 30 : 0.01806417480111122
Loss at iteration 40 : 0.02955157868564129
Loss at iteration 50 : 0.01577167771756649
Loss at iteration 60 : 0.02312411740422249
Loss at iteration 70 : 0.03489558398723602
Loss at iteration 80 : 0.01301366277039051
Loss at iteration 90 : 0.024155743420124054
Loss at iteration 100 : 0.014596942812204361
Loss at iteration 110 : 0.015894321724772453
Loss at iteration 120 : 0.015890158712863922
Loss at iteration 130 : 0.032397862523794174
Loss at iteration 140 : 0.023041708394885063
Loss at iteration 150 : 0.02501831389963627
Loss at iteration 160 : 0.015158905647695065
Loss at iteration 170 : 0.025053061544895172
Loss at iteration 180 : 0.023013334721326828
Loss at iteration 190 : 0.014917335473001003
Loss at iteration 200 : 0.012917733751237392
Loss at iteration 210 : 0.02644173428416252
Loss at iteration 220 : 0.01190262008458376
Loss at iteration 230 : 0.031074848026037216
Loss at iteration 240 : 0.01586013287305832
Loss at iteration 250 : 0.023000862449407578
Loss at iteration 260 : 0.02333962544798851
Loss at iteration 270 : 0.013354284688830376
Loss at iteration 280 : 0.01777542196214199
Loss at iteration 290 : 0.026552347466349602
Loss at iteration 300 : 0.018673192709684372
Loss at iteration 310 : 0.011313745751976967
Loss at iteration 320 : 0.021723225712776184
Loss at iteration 330 : 0.018934544175863266
Loss at iteration 340 : 0.020169585943222046
Loss at iteration 350 : 0.02848297916352749
Loss at iteration 360 : 0.014006059616804123
Loss at iteration 370 : 0.022694282233715057
Loss at iteration 380 : 0.0228447075933218
Loss at iteration 390 : 0.022779766470193863
Loss at iteration 400 : 0.022769620642066002
Loss at iteration 410 : 0.02225724793970585
Loss at iteration 420 : 0.019214347004890442
Loss at iteration 430 : 0.01585087925195694
Loss at iteration 440 : 0.01955714076757431
Loss at iteration 450 : 0.02993312105536461
Loss at iteration 460 : 0.01408346462994814
Loss at iteration 470 : 0.010107604786753654
Loss at iteration 480 : 0.022013681009411812
Loss at iteration 490 : 0.013964957557618618
Loss at iteration 500 : 0.018124669790267944
Loss at iteration 510 : 0.0267266184091568
Loss at iteration 520 : 0.02501426637172699
Loss at iteration 530 : 0.022671064361929893
Loss at iteration 540 : 0.032412685453891754
Loss at iteration 550 : 0.024490348994731903
Loss at iteration 560 : 0.018871711567044258
Loss at iteration 570 : 0.02223861962556839
Loss at iteration 580 : 0.023767568171024323
Loss at iteration 590 : 0.030700266361236572
Loss at iteration 600 : 0.0188867449760437
Loss at iteration 610 : 0.01574493944644928
Loss at iteration 620 : 0.014035191386938095
Loss at iteration 630 : 0.0291458647698164
Loss at iteration 640 : 0.013042143546044827
Loss at iteration 650 : 0.03416050598025322
Loss at iteration 660 : 0.017315786331892014
Loss at iteration 670 : 0.01859653741121292
Loss at iteration 680 : 0.019566776230931282
Loss at iteration 690 : 0.03236961364746094
Loss at iteration 700 : 0.018155870959162712
Loss at iteration 710 : 0.014495530165731907
Loss at iteration 720 : 0.018983403220772743
Loss at iteration 730 : 0.015287576243281364
Loss at iteration 740 : 0.01622544229030609
Loss at iteration 750 : 0.012802831828594208
Loss at iteration 760 : 0.014743782579898834
Loss at iteration 770 : 0.014852775260806084
Loss at iteration 780 : 0.015103129670023918
Loss at iteration 790 : 0.016950568184256554
Loss at iteration 800 : 0.013857068493962288
Loss at iteration 810 : 0.02118419110774994
Loss at iteration 820 : 0.014568985439836979
Loss at iteration 830 : 0.017750350758433342
Loss at iteration 840 : 0.02391887828707695
Loss at iteration 850 : 0.020047424361109734
Loss at iteration 860 : 0.013633420690894127
Loss at iteration 870 : 0.012506181374192238
Loss at iteration 880 : 0.03027605637907982
Loss at iteration 890 : 0.01891973428428173
Loss at iteration 900 : 0.017234427854418755
Loss at iteration 910 : 0.019564634189009666
Loss at iteration 920 : 0.0199073925614357
Loss at iteration 930 : 0.014233596622943878
Loss at iteration 940 : 0.02286585047841072
Loss at iteration 950 : 0.01257774792611599
Loss at iteration 960 : 0.027686238288879395
Loss at iteration 970 : 0.02605208195745945
Loss at iteration 980 : 0.02282862365245819
Loss at iteration 990 : 0.03154821693897247
Loss at iteration 1000 : 0.015521962195634842
Loss at iteration 1010 : 0.016522549092769623
Loss at iteration 1020 : 0.01885014958679676
Loss at iteration 1030 : 0.01733674481511116
Loss at iteration 1040 : 0.021068504080176353
Loss at iteration 1050 : 0.022382117807865143
Loss at iteration 1060 : 0.01044411025941372
Loss at iteration 1070 : 0.036701105535030365
Loss at iteration 1080 : 0.021792437881231308
Loss at iteration 1090 : 0.025161035358905792
Loss at iteration 1100 : 0.020990896970033646
Loss at iteration 1110 : 0.029525797814130783
Loss at iteration 1120 : 0.018087420612573624
Loss at iteration 1130 : 0.015798524022102356
Loss at iteration 1140 : 0.020076613873243332
Loss at iteration 1150 : 0.022914975881576538
Loss at iteration 1160 : 0.0292552150785923
Loss at iteration 1170 : 0.017118219286203384
Loss at iteration 1180 : 0.016312653198838234
Loss at iteration 1190 : 0.013653215020895004
Loss at iteration 1200 : 0.021285247057676315
Loss at iteration 1210 : 0.03537388890981674
The SSIM Value is: 0.799993371963501
The PSNR Value is: 19.186113802591958
the epoch is: 135
Loss at iteration 10 : 0.010950038209557533
Loss at iteration 20 : 0.01345067285001278
Loss at iteration 30 : 0.014022108167409897
Loss at iteration 40 : 0.01898745261132717
Loss at iteration 50 : 0.01496719941496849
Loss at iteration 60 : 0.016645167022943497
Loss at iteration 70 : 0.028761038556694984
Loss at iteration 80 : 0.023242533206939697
Loss at iteration 90 : 0.025877229869365692
Loss at iteration 100 : 0.015195876359939575
Loss at iteration 110 : 0.01450381614267826
Loss at iteration 120 : 0.015016680583357811
Loss at iteration 130 : 0.015225728042423725
Loss at iteration 140 : 0.019687576219439507
Loss at iteration 150 : 0.015063652768731117
Loss at iteration 160 : 0.02302602119743824
Loss at iteration 170 : 0.015331996604800224
Loss at iteration 180 : 0.01422406081110239
Loss at iteration 190 : 0.026942946016788483
Loss at iteration 200 : 0.014735913835465908
Loss at iteration 210 : 0.015281552448868752
Loss at iteration 220 : 0.022201307117938995
Loss at iteration 230 : 0.02263016439974308
Loss at iteration 240 : 0.02562619186937809
Loss at iteration 250 : 0.016562150791287422
Loss at iteration 260 : 0.02178485319018364
Loss at iteration 270 : 0.020981645211577415
Loss at iteration 280 : 0.02461492270231247
Loss at iteration 290 : 0.02487853914499283
Loss at iteration 300 : 0.021431811153888702
Loss at iteration 310 : 0.0311228446662426
Loss at iteration 320 : 0.015497926622629166
Loss at iteration 330 : 0.018315572291612625
Loss at iteration 340 : 0.017983125522732735
Loss at iteration 350 : 0.02543640322983265
Loss at iteration 360 : 0.016624167561531067
Loss at iteration 370 : 0.015879100188612938
Loss at iteration 380 : 0.014889981597661972
Loss at iteration 390 : 0.012359008193016052
Loss at iteration 400 : 0.01563039794564247
Loss at iteration 410 : 0.023686543107032776
Loss at iteration 420 : 0.016204386949539185
Loss at iteration 430 : 0.015484457835555077
Loss at iteration 440 : 0.029395127668976784
Loss at iteration 450 : 0.016652751713991165
Loss at iteration 460 : 0.017069071531295776
Loss at iteration 470 : 0.018926924094557762
Loss at iteration 480 : 0.016757307574152946
Loss at iteration 490 : 0.019236549735069275
Loss at iteration 500 : 0.017360517755150795
Loss at iteration 510 : 0.031218675896525383
Loss at iteration 520 : 0.016323503106832504
Loss at iteration 530 : 0.01601221226155758
Loss at iteration 540 : 0.02913374826312065
Loss at iteration 550 : 0.020415985956788063
Loss at iteration 560 : 0.018727511167526245
Loss at iteration 570 : 0.020152851939201355
Loss at iteration 580 : 0.019258232787251472
Loss at iteration 590 : 0.01722034439444542
Loss at iteration 600 : 0.019570229575037956
Loss at iteration 610 : 0.014863518066704273
Loss at iteration 620 : 0.023400742560625076
Loss at iteration 630 : 0.020351678133010864
Loss at iteration 640 : 0.012066490948200226
Loss at iteration 650 : 0.03234351798892021
Loss at iteration 660 : 0.013603093102574348
Loss at iteration 670 : 0.011430365033447742
Loss at iteration 680 : 0.02045203559100628
Loss at iteration 690 : 0.02277028188109398
Loss at iteration 700 : 0.02805441990494728
Loss at iteration 710 : 0.01819356344640255
Loss at iteration 720 : 0.02193128690123558
Loss at iteration 730 : 0.019818566739559174
Loss at iteration 740 : 0.016763538122177124
Loss at iteration 750 : 0.026031211018562317
Loss at iteration 760 : 0.01539312768727541
Loss at iteration 770 : 0.013272376731038094
Loss at iteration 780 : 0.02817067876458168
Loss at iteration 790 : 0.02641850896179676
Loss at iteration 800 : 0.01637730933725834
Loss at iteration 810 : 0.016118155792355537
Loss at iteration 820 : 0.02549297735095024
Loss at iteration 830 : 0.019530292600393295
Loss at iteration 840 : 0.014467842876911163
Loss at iteration 850 : 0.019338008016347885
Loss at iteration 860 : 0.015987571328878403
Loss at iteration 870 : 0.02251952886581421
Loss at iteration 880 : 0.019030515104532242
Loss at iteration 890 : 0.0182185061275959
Loss at iteration 900 : 0.01741594448685646
Loss at iteration 910 : 0.03252347558736801
Loss at iteration 920 : 0.011398449540138245
Loss at iteration 930 : 0.02040283754467964
Loss at iteration 940 : 0.014133264310657978
Loss at iteration 950 : 0.01518353819847107
Loss at iteration 960 : 0.018584229052066803
Loss at iteration 970 : 0.02135394886136055
Loss at iteration 980 : 0.0302268099039793
Loss at iteration 990 : 0.014431948773562908
Loss at iteration 1000 : 0.01816418580710888
Loss at iteration 1010 : 0.02691413089632988
Loss at iteration 1020 : 0.025275539606809616
Loss at iteration 1030 : 0.025801848620176315
Loss at iteration 1040 : 0.02213156223297119
Loss at iteration 1050 : 0.02887440100312233
Loss at iteration 1060 : 0.017263241112232208
Loss at iteration 1070 : 0.021390337496995926
Loss at iteration 1080 : 0.026194022968411446
Loss at iteration 1090 : 0.019641250371932983
Loss at iteration 1100 : 0.016747096553444862
Loss at iteration 1110 : 0.023380529135465622
Loss at iteration 1120 : 0.01521639246493578
Loss at iteration 1130 : 0.013845794834196568
Loss at iteration 1140 : 0.016903607174754143
Loss at iteration 1150 : 0.017041724175214767
Loss at iteration 1160 : 0.011176805011928082
Loss at iteration 1170 : 0.028210528194904327
Loss at iteration 1180 : 0.019293107092380524
Loss at iteration 1190 : 0.012969249859452248
Loss at iteration 1200 : 0.020098060369491577
Loss at iteration 1210 : 0.022277172654867172
The SSIM Value is: 0.8031808018684388
The PSNR Value is: 19.680432573954263
the epoch is: 136
Loss at iteration 10 : 0.02157188020646572
Loss at iteration 20 : 0.016273077577352524
Loss at iteration 30 : 0.018329311162233353
Loss at iteration 40 : 0.014749865978956223
Loss at iteration 50 : 0.020813079550862312
Loss at iteration 60 : 0.03238900378346443
Loss at iteration 70 : 0.02697160094976425
Loss at iteration 80 : 0.017793025821447372
Loss at iteration 90 : 0.011737454682588577
Loss at iteration 100 : 0.03950528800487518
Loss at iteration 110 : 0.014409482479095459
Loss at iteration 120 : 0.03655221313238144
Loss at iteration 130 : 0.017892906442284584
Loss at iteration 140 : 0.02875503897666931
Loss at iteration 150 : 0.02068750560283661
Loss at iteration 160 : 0.01293306052684784
Loss at iteration 170 : 0.0154071394354105
Loss at iteration 180 : 0.014324738644063473
Loss at iteration 190 : 0.01590101048350334
Loss at iteration 200 : 0.02674834430217743
Loss at iteration 210 : 0.020988985896110535
Loss at iteration 220 : 0.023257136344909668
Loss at iteration 230 : 0.015273554250597954
Loss at iteration 240 : 0.024678856134414673
Loss at iteration 250 : 0.023992108181118965
Loss at iteration 260 : 0.014636456966400146
Loss at iteration 270 : 0.025560736656188965
Loss at iteration 280 : 0.02480953186750412
Loss at iteration 290 : 0.022918570786714554
Loss at iteration 300 : 0.010889689438045025
Loss at iteration 310 : 0.015108486637473106
Loss at iteration 320 : 0.027741452679038048
Loss at iteration 330 : 0.015102928504347801
Loss at iteration 340 : 0.012782447971403599
Loss at iteration 350 : 0.01344422809779644
Loss at iteration 360 : 0.018853511661291122
Loss at iteration 370 : 0.015863239765167236
Loss at iteration 380 : 0.025075748562812805
Loss at iteration 390 : 0.013794127851724625
Loss at iteration 400 : 0.028695717453956604
Loss at iteration 410 : 0.018695823848247528
Loss at iteration 420 : 0.015213575214147568
Loss at iteration 430 : 0.026688706129789352
Loss at iteration 440 : 0.015925198793411255
Loss at iteration 450 : 0.023434482514858246
Loss at iteration 460 : 0.02278079465031624
Loss at iteration 470 : 0.012786786071956158
Loss at iteration 480 : 0.014160607941448689
Loss at iteration 490 : 0.019889937713742256
Loss at iteration 500 : 0.01671616919338703
Loss at iteration 510 : 0.026369867846369743
Loss at iteration 520 : 0.01566644385457039
Loss at iteration 530 : 0.015160191804170609
Loss at iteration 540 : 0.017638545483350754
Loss at iteration 550 : 0.02192559838294983
Loss at iteration 560 : 0.018969204276800156
Loss at iteration 570 : 0.010777839459478855
Loss at iteration 580 : 0.026998689398169518
Loss at iteration 590 : 0.017194068059325218
Loss at iteration 600 : 0.024467043578624725
Loss at iteration 610 : 0.011218462139368057
Loss at iteration 620 : 0.02528117224574089
Loss at iteration 630 : 0.02162291668355465
Loss at iteration 640 : 0.02664293348789215
Loss at iteration 650 : 0.02583407610654831
Loss at iteration 660 : 0.017083315178751945
Loss at iteration 670 : 0.021594418212771416
Loss at iteration 680 : 0.020339421927928925
Loss at iteration 690 : 0.02932298555970192
Loss at iteration 700 : 0.020084582269191742
Loss at iteration 710 : 0.022431939840316772
Loss at iteration 720 : 0.023569827899336815
Loss at iteration 730 : 0.015705810859799385
Loss at iteration 740 : 0.015504587441682816
Loss at iteration 750 : 0.020321980118751526
Loss at iteration 760 : 0.022057395428419113
Loss at iteration 770 : 0.01994781382381916
Loss at iteration 780 : 0.02156277373433113
Loss at iteration 790 : 0.019508328288793564
Loss at iteration 800 : 0.014540919102728367
Loss at iteration 810 : 0.01590392179787159
Loss at iteration 820 : 0.02199944108724594
Loss at iteration 830 : 0.027344871312379837
Loss at iteration 840 : 0.016836456954479218
Loss at iteration 850 : 0.015323039144277573
Loss at iteration 860 : 0.023649336770176888
Loss at iteration 870 : 0.019094318151474
Loss at iteration 880 : 0.023704197257757187
Loss at iteration 890 : 0.02422924153506756
Loss at iteration 900 : 0.019855158403515816
Loss at iteration 910 : 0.03454248607158661
Loss at iteration 920 : 0.013494336977601051
Loss at iteration 930 : 0.021302059292793274
Loss at iteration 940 : 0.02460949495434761
Loss at iteration 950 : 0.018213633447885513
Loss at iteration 960 : 0.024793526157736778
Loss at iteration 970 : 0.01605040207505226
Loss at iteration 980 : 0.025012895464897156
Loss at iteration 990 : 0.02164037525653839
Loss at iteration 1000 : 0.01502603106200695
Loss at iteration 1010 : 0.021938689053058624
Loss at iteration 1020 : 0.023201338946819305
Loss at iteration 1030 : 0.02014700323343277
Loss at iteration 1040 : 0.012950161471962929
Loss at iteration 1050 : 0.02680908888578415
Loss at iteration 1060 : 0.02008478343486786
Loss at iteration 1070 : 0.024448402225971222
Loss at iteration 1080 : 0.015414121560752392
Loss at iteration 1090 : 0.013623110949993134
Loss at iteration 1100 : 0.028662744909524918
Loss at iteration 1110 : 0.021384265273809433
Loss at iteration 1120 : 0.020235244184732437
Loss at iteration 1130 : 0.02184249646961689
Loss at iteration 1140 : 0.009976238943636417
Loss at iteration 1150 : 0.018414638936519623
Loss at iteration 1160 : 0.022494632750749588
Loss at iteration 1170 : 0.023680834099650383
Loss at iteration 1180 : 0.021099651232361794
Loss at iteration 1190 : 0.024775147438049316
Loss at iteration 1200 : 0.01801537349820137
Loss at iteration 1210 : 0.016133837401866913
The SSIM Value is: 0.7988416075706481
The PSNR Value is: 18.83802909851074
the epoch is: 137
Loss at iteration 10 : 0.029477376490831375
Loss at iteration 20 : 0.01936246268451214
Loss at iteration 30 : 0.019475940614938736
Loss at iteration 40 : 0.015383830294013023
Loss at iteration 50 : 0.017738310620188713
Loss at iteration 60 : 0.02516326867043972
Loss at iteration 70 : 0.010900321416556835
Loss at iteration 80 : 0.006820427253842354
Loss at iteration 90 : 0.017921477556228638
Loss at iteration 100 : 0.016506241634488106
Loss at iteration 110 : 0.02260543219745159
Loss at iteration 120 : 0.024370715022087097
Loss at iteration 130 : 0.02031734399497509
Loss at iteration 140 : 0.03267024829983711
Loss at iteration 150 : 0.018654558807611465
Loss at iteration 160 : 0.011938449926674366
Loss at iteration 170 : 0.012553693726658821
Loss at iteration 180 : 0.024454381316900253
Loss at iteration 190 : 0.02295505441725254
Loss at iteration 200 : 0.02209504507482052
Loss at iteration 210 : 0.01956087537109852
Loss at iteration 220 : 0.01581226848065853
Loss at iteration 230 : 0.03246042877435684
Loss at iteration 240 : 0.015879521146416664
Loss at iteration 250 : 0.014112565666437149
Loss at iteration 260 : 0.01976395770907402
Loss at iteration 270 : 0.022824760526418686
Loss at iteration 280 : 0.03655913472175598
Loss at iteration 290 : 0.020455680787563324
Loss at iteration 300 : 0.03197726234793663
Loss at iteration 310 : 0.013378817588090897
Loss at iteration 320 : 0.015104403719305992
Loss at iteration 330 : 0.012011310085654259
Loss at iteration 340 : 0.0205036923289299
Loss at iteration 350 : 0.02427155338227749
Loss at iteration 360 : 0.020630832761526108
Loss at iteration 370 : 0.030924882739782333
Loss at iteration 380 : 0.014916648156940937
Loss at iteration 390 : 0.019979117438197136
Loss at iteration 400 : 0.011672195047140121
Loss at iteration 410 : 0.011754602193832397
Loss at iteration 420 : 0.01997782662510872
Loss at iteration 430 : 0.02826009690761566
Loss at iteration 440 : 0.015237296000123024
Loss at iteration 450 : 0.025334417819976807
Loss at iteration 460 : 0.034427836537361145
Loss at iteration 470 : 0.03266805782914162
Loss at iteration 480 : 0.018584521487355232
Loss at iteration 490 : 0.028666693717241287
Loss at iteration 500 : 0.02730640210211277
Loss at iteration 510 : 0.02555602416396141
Loss at iteration 520 : 0.0190921351313591
Loss at iteration 530 : 0.02288931980729103
Loss at iteration 540 : 0.021529391407966614
Loss at iteration 550 : 0.013174165971577168
Loss at iteration 560 : 0.017073340713977814
Loss at iteration 570 : 0.027661051601171494
Loss at iteration 580 : 0.03665262460708618
Loss at iteration 590 : 0.011767752468585968
Loss at iteration 600 : 0.014321697875857353
Loss at iteration 610 : 0.019705846905708313
Loss at iteration 620 : 0.017140422016382217
Loss at iteration 630 : 0.01454932801425457
Loss at iteration 640 : 0.016132637858390808
Loss at iteration 650 : 0.018885642290115356
Loss at iteration 660 : 0.015006516128778458
Loss at iteration 670 : 0.016236502677202225
Loss at iteration 680 : 0.012344775721430779
Loss at iteration 690 : 0.01778932847082615
Loss at iteration 700 : 0.022491831332445145
Loss at iteration 710 : 0.029525427147746086
Loss at iteration 720 : 0.016337838023900986
Loss at iteration 730 : 0.019507605582475662
Loss at iteration 740 : 0.019853336736559868
Loss at iteration 750 : 0.02148587256669998
Loss at iteration 760 : 0.013929275795817375
Loss at iteration 770 : 0.018787994980812073
Loss at iteration 780 : 0.027587540447711945
Loss at iteration 790 : 0.032896656543016434
Loss at iteration 800 : 0.01951153576374054
Loss at iteration 810 : 0.025454919785261154
Loss at iteration 820 : 0.01332480926066637
Loss at iteration 830 : 0.017982639372348785
Loss at iteration 840 : 0.031884655356407166
Loss at iteration 850 : 0.02111208438873291
Loss at iteration 860 : 0.01921466365456581
Loss at iteration 870 : 0.018675239756703377
Loss at iteration 880 : 0.014961251057684422
Loss at iteration 890 : 0.019491232931613922
Loss at iteration 900 : 0.015511286444962025
Loss at iteration 910 : 0.01991816982626915
Loss at iteration 920 : 0.01666577346622944
Loss at iteration 930 : 0.02079121023416519
Loss at iteration 940 : 0.02234487794339657
Loss at iteration 950 : 0.03314133360981941
Loss at iteration 960 : 0.02022239938378334
Loss at iteration 970 : 0.01607268676161766
Loss at iteration 980 : 0.014392148703336716
Loss at iteration 990 : 0.010740058496594429
Loss at iteration 1000 : 0.016853347420692444
Loss at iteration 1010 : 0.0196236502379179
Loss at iteration 1020 : 0.015612222254276276
Loss at iteration 1030 : 0.01806105487048626
Loss at iteration 1040 : 0.019244864583015442
Loss at iteration 1050 : 0.021965282037854195
Loss at iteration 1060 : 0.018551627174019814
Loss at iteration 1070 : 0.024186888709664345
Loss at iteration 1080 : 0.020409781485795975
Loss at iteration 1090 : 0.021901117637753487
Loss at iteration 1100 : 0.01676967367529869
Loss at iteration 1110 : 0.017809823155403137
Loss at iteration 1120 : 0.019206784665584564
Loss at iteration 1130 : 0.01887955144047737
Loss at iteration 1140 : 0.011109612882137299
Loss at iteration 1150 : 0.01638878881931305
Loss at iteration 1160 : 0.016714852303266525
Loss at iteration 1170 : 0.024132590740919113
Loss at iteration 1180 : 0.03337213397026062
Loss at iteration 1190 : 0.025895794853568077
Loss at iteration 1200 : 0.017361197620630264
Loss at iteration 1210 : 0.02278848923742771
The SSIM Value is: 0.8093406995137532
The PSNR Value is: 19.94368050893148
the epoch is: 138
Loss at iteration 10 : 0.016860026866197586
Loss at iteration 20 : 0.01970008574426174
Loss at iteration 30 : 0.028011778369545937
Loss at iteration 40 : 0.031115621328353882
Loss at iteration 50 : 0.02417248860001564
Loss at iteration 60 : 0.01467188447713852
Loss at iteration 70 : 0.016065601259469986
Loss at iteration 80 : 0.01239672303199768
Loss at iteration 90 : 0.02164653316140175
Loss at iteration 100 : 0.021116280928254128
Loss at iteration 110 : 0.018694918602705002
Loss at iteration 120 : 0.020943129435181618
Loss at iteration 130 : 0.021560654044151306
Loss at iteration 140 : 0.033143218606710434
Loss at iteration 150 : 0.02894573286175728
Loss at iteration 160 : 0.02663407102227211
Loss at iteration 170 : 0.029808174818754196
Loss at iteration 180 : 0.020152702927589417
Loss at iteration 190 : 0.03432886302471161
Loss at iteration 200 : 0.018367065116763115
Loss at iteration 210 : 0.016860976815223694
Loss at iteration 220 : 0.025817401707172394
Loss at iteration 230 : 0.021139012649655342
Loss at iteration 240 : 0.02338501252233982
Loss at iteration 250 : 0.014657041989266872
Loss at iteration 260 : 0.03482108190655708
Loss at iteration 270 : 0.02661093696951866
Loss at iteration 280 : 0.025189703330397606
Loss at iteration 290 : 0.029149897396564484
Loss at iteration 300 : 0.02017294615507126
Loss at iteration 310 : 0.029053393751382828
Loss at iteration 320 : 0.03072887845337391
Loss at iteration 330 : 0.024051597341895103
Loss at iteration 340 : 0.02148103155195713
Loss at iteration 350 : 0.012122363783419132
Loss at iteration 360 : 0.017948705703020096
Loss at iteration 370 : 0.02349139377474785
Loss at iteration 380 : 0.01544732041656971
Loss at iteration 390 : 0.028765302151441574
Loss at iteration 400 : 0.0271170474588871
Loss at iteration 410 : 0.015011852607131004
Loss at iteration 420 : 0.024050645530223846
Loss at iteration 430 : 0.015178665518760681
Loss at iteration 440 : 0.015459086745977402
Loss at iteration 450 : 0.012658190913498402
Loss at iteration 460 : 0.034973349422216415
Loss at iteration 470 : 0.021864231675863266
Loss at iteration 480 : 0.017829865217208862
Loss at iteration 490 : 0.017155958339571953
Loss at iteration 500 : 0.02099866047501564
Loss at iteration 510 : 0.019438015297055244
Loss at iteration 520 : 0.022560708224773407
Loss at iteration 530 : 0.019511966034770012
Loss at iteration 540 : 0.0250246599316597
Loss at iteration 550 : 0.024007391184568405
Loss at iteration 560 : 0.018493272364139557
Loss at iteration 570 : 0.010079431347548962
Loss at iteration 580 : 0.013299056328833103
Loss at iteration 590 : 0.017926905304193497
Loss at iteration 600 : 0.018223987892270088
Loss at iteration 610 : 0.0292588509619236
Loss at iteration 620 : 0.01381652895361185
Loss at iteration 630 : 0.02749244123697281
Loss at iteration 640 : 0.016865471377968788
Loss at iteration 650 : 0.030459890142083168
Loss at iteration 660 : 0.022602666169404984
Loss at iteration 670 : 0.01832781732082367
Loss at iteration 680 : 0.020215466618537903
Loss at iteration 690 : 0.02815048024058342
Loss at iteration 700 : 0.01549927331507206
Loss at iteration 710 : 0.019346920773386955
Loss at iteration 720 : 0.020414113998413086
Loss at iteration 730 : 0.020151499658823013
Loss at iteration 740 : 0.015913376584649086
Loss at iteration 750 : 0.024453064426779747
Loss at iteration 760 : 0.02441941574215889
Loss at iteration 770 : 0.020318705588579178
Loss at iteration 780 : 0.01798328012228012
Loss at iteration 790 : 0.024132993072271347
Loss at iteration 800 : 0.012409580871462822
Loss at iteration 810 : 0.017913073301315308
Loss at iteration 820 : 0.022834112867712975
Loss at iteration 830 : 0.02852800115942955
Loss at iteration 840 : 0.010838976129889488
Loss at iteration 850 : 0.024208586663007736
Loss at iteration 860 : 0.03049006313085556
Loss at iteration 870 : 0.015619127079844475
Loss at iteration 880 : 0.018341995775699615
Loss at iteration 890 : 0.017592154443264008
Loss at iteration 900 : 0.01386562455445528
Loss at iteration 910 : 0.0195895005017519
Loss at iteration 920 : 0.011159820482134819
Loss at iteration 930 : 0.02115149423480034
Loss at iteration 940 : 0.02252109721302986
Loss at iteration 950 : 0.03242555633187294
Loss at iteration 960 : 0.01733044907450676
Loss at iteration 970 : 0.037309348583221436
Loss at iteration 980 : 0.022905046120285988
Loss at iteration 990 : 0.020487189292907715
Loss at iteration 1000 : 0.015272684395313263
Loss at iteration 1010 : 0.02755984663963318
Loss at iteration 1020 : 0.018121544271707535
Loss at iteration 1030 : 0.013895193114876747
Loss at iteration 1040 : 0.017033182084560394
Loss at iteration 1050 : 0.018586471676826477
Loss at iteration 1060 : 0.020494289696216583
Loss at iteration 1070 : 0.020703313872218132
Loss at iteration 1080 : 0.009807052090764046
Loss at iteration 1090 : 0.015065889805555344
Loss at iteration 1100 : 0.027335088700056076
Loss at iteration 1110 : 0.013665697537362576
Loss at iteration 1120 : 0.022864792495965958
Loss at iteration 1130 : 0.017796684056520462
Loss at iteration 1140 : 0.028959617018699646
Loss at iteration 1150 : 0.015104482881724834
Loss at iteration 1160 : 0.014955141581594944
Loss at iteration 1170 : 0.018832895904779434
Loss at iteration 1180 : 0.01750166341662407
Loss at iteration 1190 : 0.020648282021284103
Loss at iteration 1200 : 0.018074359744787216
Loss at iteration 1210 : 0.01412845216691494
The SSIM Value is: 0.8060189088185629
The PSNR Value is: 19.809891192118325
the epoch is: 139
Loss at iteration 10 : 0.011735768057405949
Loss at iteration 20 : 0.026913519948720932
Loss at iteration 30 : 0.028550710529088974
Loss at iteration 40 : 0.0187701266258955
Loss at iteration 50 : 0.018120553344488144
Loss at iteration 60 : 0.01438642106950283
Loss at iteration 70 : 0.020116716623306274
Loss at iteration 80 : 0.022584963589906693
Loss at iteration 90 : 0.015494861640036106
Loss at iteration 100 : 0.014924276620149612
Loss at iteration 110 : 0.011465002782642841
Loss at iteration 120 : 0.020822273567318916
Loss at iteration 130 : 0.016730833798646927
Loss at iteration 140 : 0.020919319242239
Loss at iteration 150 : 0.012637197971343994
Loss at iteration 160 : 0.0127838971093297
Loss at iteration 170 : 0.016351869329810143
Loss at iteration 180 : 0.020315691828727722
Loss at iteration 190 : 0.017540179193019867
Loss at iteration 200 : 0.02010509930551052
Loss at iteration 210 : 0.012300213798880577
Loss at iteration 220 : 0.024241579696536064
Loss at iteration 230 : 0.021085068583488464
Loss at iteration 240 : 0.015489807352423668
Loss at iteration 250 : 0.01630190946161747
Loss at iteration 260 : 0.018003122881054878
Loss at iteration 270 : 0.017575647681951523
Loss at iteration 280 : 0.016012419015169144
Loss at iteration 290 : 0.023494377732276917
Loss at iteration 300 : 0.01595582440495491
Loss at iteration 310 : 0.016742609441280365
Loss at iteration 320 : 0.04385856166481972
Loss at iteration 330 : 0.019139112904667854
Loss at iteration 340 : 0.032585930079221725
Loss at iteration 350 : 0.015147287398576736
Loss at iteration 360 : 0.020898055285215378
Loss at iteration 370 : 0.013640347868204117
Loss at iteration 380 : 0.012163038365542889
Loss at iteration 390 : 0.020947391167283058
Loss at iteration 400 : 0.03564682975411415
Loss at iteration 410 : 0.014886610209941864
Loss at iteration 420 : 0.025984637439250946
Loss at iteration 430 : 0.018616028130054474
Loss at iteration 440 : 0.02230493724346161
Loss at iteration 450 : 0.0252836886793375
Loss at iteration 460 : 0.033432263880968094
Loss at iteration 470 : 0.023215796798467636
Loss at iteration 480 : 0.022720780223608017
Loss at iteration 490 : 0.014755641110241413
Loss at iteration 500 : 0.02020200714468956
Loss at iteration 510 : 0.02348686382174492
Loss at iteration 520 : 0.017354531213641167
Loss at iteration 530 : 0.017548061907291412
Loss at iteration 540 : 0.017281262204051018
Loss at iteration 550 : 0.01818365976214409
Loss at iteration 560 : 0.02075110748410225
Loss at iteration 570 : 0.032933443784713745
Loss at iteration 580 : 0.01589174196124077
Loss at iteration 590 : 0.02013714611530304
Loss at iteration 600 : 0.016345666721463203
Loss at iteration 610 : 0.025734711438417435
Loss at iteration 620 : 0.015652665868401527
Loss at iteration 630 : 0.019523177295923233
Loss at iteration 640 : 0.009131327271461487
Loss at iteration 650 : 0.016079537570476532
Loss at iteration 660 : 0.020628103986382484
Loss at iteration 670 : 0.019195422530174255
Loss at iteration 680 : 0.018846631050109863
Loss at iteration 690 : 0.027500448748469353
Loss at iteration 700 : 0.014214872382581234
Loss at iteration 710 : 0.015719760209321976
Loss at iteration 720 : 0.025960948318243027
Loss at iteration 730 : 0.012101329863071442
Loss at iteration 740 : 0.01743253320455551
Loss at iteration 750 : 0.014157307334244251
Loss at iteration 760 : 0.018917839974164963
Loss at iteration 770 : 0.019220950081944466
Loss at iteration 780 : 0.021496519446372986
Loss at iteration 790 : 0.020452100783586502
Loss at iteration 800 : 0.01817304454743862
Loss at iteration 810 : 0.011275596916675568
Loss at iteration 820 : 0.020301641896367073
Loss at iteration 830 : 0.015116700902581215
Loss at iteration 840 : 0.015442428179085255
Loss at iteration 850 : 0.03385792300105095
Loss at iteration 860 : 0.016603559255599976
Loss at iteration 870 : 0.016861075535416603
Loss at iteration 880 : 0.0209956131875515
Loss at iteration 890 : 0.023048773407936096
Loss at iteration 900 : 0.022793475538492203
Loss at iteration 910 : 0.020548075437545776
Loss at iteration 920 : 0.029139023274183273
Loss at iteration 930 : 0.02435564063489437
Loss at iteration 940 : 0.014443294145166874
Loss at iteration 950 : 0.013929175212979317
Loss at iteration 960 : 0.022725846618413925
Loss at iteration 970 : 0.025810670107603073
Loss at iteration 980 : 0.029494894668459892
Loss at iteration 990 : 0.020322628319263458
Loss at iteration 1000 : 0.030948437750339508
Loss at iteration 1010 : 0.014565527439117432
Loss at iteration 1020 : 0.01323613990098238
Loss at iteration 1030 : 0.015646900981664658
Loss at iteration 1040 : 0.017290838062763214
Loss at iteration 1050 : 0.01346749346703291
Loss at iteration 1060 : 0.016136664897203445
Loss at iteration 1070 : 0.029400192201137543
Loss at iteration 1080 : 0.01645096391439438
Loss at iteration 1090 : 0.011127403937280178
Loss at iteration 1100 : 0.014076810330152512
Loss at iteration 1110 : 0.008978988975286484
Loss at iteration 1120 : 0.015799416229128838
Loss at iteration 1130 : 0.010957597754895687
Loss at iteration 1140 : 0.01406550221145153
Loss at iteration 1150 : 0.015325373038649559
Loss at iteration 1160 : 0.020574288442730904
Loss at iteration 1170 : 0.026092439889907837
Loss at iteration 1180 : 0.0158102884888649
Loss at iteration 1190 : 0.011179285123944283
Loss at iteration 1200 : 0.01359932404011488
Loss at iteration 1210 : 0.010189061984419823
The SSIM Value is: 0.8005825479825338
The PSNR Value is: 19.55789108276367
the epoch is: 140
Loss at iteration 10 : 0.024883076548576355
Loss at iteration 20 : 0.01576267182826996
Loss at iteration 30 : 0.01664036512374878
Loss at iteration 40 : 0.015548882074654102
Loss at iteration 50 : 0.01487339474260807
Loss at iteration 60 : 0.018251432105898857
Loss at iteration 70 : 0.0208244901150465
Loss at iteration 80 : 0.02852826938033104
Loss at iteration 90 : 0.013607017695903778
Loss at iteration 100 : 0.018522948026657104
Loss at iteration 110 : 0.021846219897270203
Loss at iteration 120 : 0.009410843253135681
Loss at iteration 130 : 0.01837874948978424
Loss at iteration 140 : 0.023479972034692764
Loss at iteration 150 : 0.024708377197384834
Loss at iteration 160 : 0.026017693802714348
Loss at iteration 170 : 0.018632451072335243
Loss at iteration 180 : 0.02031015232205391
Loss at iteration 190 : 0.022486761212348938
Loss at iteration 200 : 0.024201344698667526
Loss at iteration 210 : 0.012064509093761444
Loss at iteration 220 : 0.015096228569746017
Loss at iteration 230 : 0.020110037177801132
Loss at iteration 240 : 0.01474835630506277
Loss at iteration 250 : 0.02508370764553547
Loss at iteration 260 : 0.024256616830825806
Loss at iteration 270 : 0.023339293897151947
Loss at iteration 280 : 0.016812385991215706
Loss at iteration 290 : 0.025665126740932465
Loss at iteration 300 : 0.01729155331850052
Loss at iteration 310 : 0.018897924572229385
Loss at iteration 320 : 0.01836404576897621
Loss at iteration 330 : 0.013889817520976067
Loss at iteration 340 : 0.024971788749098778
Loss at iteration 350 : 0.025245552882552147
Loss at iteration 360 : 0.025731544941663742
Loss at iteration 370 : 0.010187597945332527
Loss at iteration 380 : 0.016416415572166443
Loss at iteration 390 : 0.010007528588175774
Loss at iteration 400 : 0.016220375895500183
Loss at iteration 410 : 0.01868318021297455
Loss at iteration 420 : 0.020778844133019447
Loss at iteration 430 : 0.03759458288550377
Loss at iteration 440 : 0.023023206740617752
Loss at iteration 450 : 0.011709251441061497
Loss at iteration 460 : 0.015833940356969833
Loss at iteration 470 : 0.023120339959859848
Loss at iteration 480 : 0.019826669245958328
Loss at iteration 490 : 0.018092341721057892
Loss at iteration 500 : 0.015197297558188438
Loss at iteration 510 : 0.022522076964378357
Loss at iteration 520 : 0.021383026614785194
Loss at iteration 530 : 0.014910059049725533
Loss at iteration 540 : 0.016790306195616722
Loss at iteration 550 : 0.024432260543107986
Loss at iteration 560 : 0.016750723123550415
Loss at iteration 570 : 0.02367132343351841
Loss at iteration 580 : 0.019299453124403954
Loss at iteration 590 : 0.01909763552248478
Loss at iteration 600 : 0.039138566702604294
Loss at iteration 610 : 0.013979032635688782
Loss at iteration 620 : 0.013150649145245552
Loss at iteration 630 : 0.007952877320349216
Loss at iteration 640 : 0.024863634258508682
Loss at iteration 650 : 0.02010508067905903
Loss at iteration 660 : 0.025473881512880325
Loss at iteration 670 : 0.019412808120250702
Loss at iteration 680 : 0.020502356812357903
Loss at iteration 690 : 0.019115857779979706
Loss at iteration 700 : 0.019495852291584015
Loss at iteration 710 : 0.015444549731910229
Loss at iteration 720 : 0.029013145714998245
Loss at iteration 730 : 0.023683585226535797
Loss at iteration 740 : 0.03407813236117363
Loss at iteration 750 : 0.020396865904331207
Loss at iteration 760 : 0.01769954338669777
Loss at iteration 770 : 0.01998971961438656
Loss at iteration 780 : 0.02164498157799244
Loss at iteration 790 : 0.022526705637574196
Loss at iteration 800 : 0.01948409155011177
Loss at iteration 810 : 0.019068527966737747
Loss at iteration 820 : 0.01989743486046791
Loss at iteration 830 : 0.01815222203731537
Loss at iteration 840 : 0.02273736707866192
Loss at iteration 850 : 0.028393473476171494
Loss at iteration 860 : 0.032369017601013184
Loss at iteration 870 : 0.019909469410777092
Loss at iteration 880 : 0.02638242021203041
Loss at iteration 890 : 0.018185175955295563
Loss at iteration 900 : 0.035587798804044724
Loss at iteration 910 : 0.01568887010216713
Loss at iteration 920 : 0.023689068853855133
Loss at iteration 930 : 0.021321795880794525
Loss at iteration 940 : 0.01607983559370041
Loss at iteration 950 : 0.014448696747422218
Loss at iteration 960 : 0.015034577809274197
Loss at iteration 970 : 0.02021915838122368
Loss at iteration 980 : 0.022855449467897415
Loss at iteration 990 : 0.02390800416469574
Loss at iteration 1000 : 0.02502879872918129
Loss at iteration 1010 : 0.01371530257165432
Loss at iteration 1020 : 0.01724482886493206
Loss at iteration 1030 : 0.024677295237779617
Loss at iteration 1040 : 0.01757136732339859
Loss at iteration 1050 : 0.008345278911292553
Loss at iteration 1060 : 0.029537783935666084
Loss at iteration 1070 : 0.023479213938117027
Loss at iteration 1080 : 0.029432831332087517
Loss at iteration 1090 : 0.01577599346637726
Loss at iteration 1100 : 0.014813320711255074
Loss at iteration 1110 : 0.028329411521553993
Loss at iteration 1120 : 0.021801337599754333
Loss at iteration 1130 : 0.025383880361914635
Loss at iteration 1140 : 0.018291538581252098
Loss at iteration 1150 : 0.021545162424445152
Loss at iteration 1160 : 0.02973693050444126
Loss at iteration 1170 : 0.01725146546959877
Loss at iteration 1180 : 0.02050761505961418
Loss at iteration 1190 : 0.025735512375831604
Loss at iteration 1200 : 0.0231192484498024
Loss at iteration 1210 : 0.014662385918200016
The SSIM Value is: 0.8022533694903056
The PSNR Value is: 19.662099075317382
the epoch is: 141
Loss at iteration 10 : 0.022447217255830765
Loss at iteration 20 : 0.016084222123026848
Loss at iteration 30 : 0.012820364907383919
Loss at iteration 40 : 0.023083321750164032
Loss at iteration 50 : 0.024564525112509727
Loss at iteration 60 : 0.026074394583702087
Loss at iteration 70 : 0.01625298336148262
Loss at iteration 80 : 0.0372871533036232
Loss at iteration 90 : 0.026647131890058517
Loss at iteration 100 : 0.01815810054540634
Loss at iteration 110 : 0.018188368529081345
Loss at iteration 120 : 0.02078964002430439
Loss at iteration 130 : 0.01424112543463707
Loss at iteration 140 : 0.019690394401550293
Loss at iteration 150 : 0.024915598332881927
Loss at iteration 160 : 0.0261802077293396
Loss at iteration 170 : 0.01758885197341442
Loss at iteration 180 : 0.01822049915790558
Loss at iteration 190 : 0.02781866118311882
Loss at iteration 200 : 0.024888139218091965
Loss at iteration 210 : 0.015930458903312683
Loss at iteration 220 : 0.020116671919822693
Loss at iteration 230 : 0.0353810116648674
Loss at iteration 240 : 0.042797911912202835
Loss at iteration 250 : 0.028719604015350342
Loss at iteration 260 : 0.01024437602609396
Loss at iteration 270 : 0.023655764758586884
Loss at iteration 280 : 0.016030948609113693
Loss at iteration 290 : 0.01735958456993103
Loss at iteration 300 : 0.018144797533750534
Loss at iteration 310 : 0.015177732333540916
Loss at iteration 320 : 0.015257657505571842
Loss at iteration 330 : 0.019881628453731537
Loss at iteration 340 : 0.021078400313854218
Loss at iteration 350 : 0.022513587027788162
Loss at iteration 360 : 0.020090289413928986
Loss at iteration 370 : 0.036639776080846786
Loss at iteration 380 : 0.017849601805210114
Loss at iteration 390 : 0.02881193906068802
Loss at iteration 400 : 0.021357987076044083
Loss at iteration 410 : 0.02072078548371792
Loss at iteration 420 : 0.019853515550494194
Loss at iteration 430 : 0.02666737511754036
Loss at iteration 440 : 0.024446098133921623
Loss at iteration 450 : 0.012669574469327927
Loss at iteration 460 : 0.014701152220368385
Loss at iteration 470 : 0.022208765149116516
Loss at iteration 480 : 0.017659462988376617
Loss at iteration 490 : 0.013755779713392258
Loss at iteration 500 : 0.013926053419709206
Loss at iteration 510 : 0.02130073308944702
Loss at iteration 520 : 0.017621668055653572
Loss at iteration 530 : 0.016270563006401062
Loss at iteration 540 : 0.021585630252957344
Loss at iteration 550 : 0.013153874315321445
Loss at iteration 560 : 0.014511378481984138
Loss at iteration 570 : 0.016117360442876816
Loss at iteration 580 : 0.01832328364253044
Loss at iteration 590 : 0.02217327430844307
Loss at iteration 600 : 0.02305557206273079
Loss at iteration 610 : 0.025705568492412567
Loss at iteration 620 : 0.015717078000307083
Loss at iteration 630 : 0.026605810970067978
Loss at iteration 640 : 0.025153188034892082
Loss at iteration 650 : 0.016777638345956802
Loss at iteration 660 : 0.015392133966088295
Loss at iteration 670 : 0.024447781965136528
Loss at iteration 680 : 0.024946417659521103
Loss at iteration 690 : 0.022487925365567207
Loss at iteration 700 : 0.020911719650030136
Loss at iteration 710 : 0.015556784346699715
Loss at iteration 720 : 0.030921954661607742
Loss at iteration 730 : 0.02084997668862343
Loss at iteration 740 : 0.01856917142868042
Loss at iteration 750 : 0.017720624804496765
Loss at iteration 760 : 0.024869348853826523
Loss at iteration 770 : 0.012921357527375221
Loss at iteration 780 : 0.018745113164186478
Loss at iteration 790 : 0.013593659736216068
Loss at iteration 800 : 0.0182021576911211
Loss at iteration 810 : 0.03916456922888756
Loss at iteration 820 : 0.025505926460027695
Loss at iteration 830 : 0.019055116921663284
Loss at iteration 840 : 0.022536084055900574
Loss at iteration 850 : 0.016795292496681213
Loss at iteration 860 : 0.02957397699356079
Loss at iteration 870 : 0.020635409280657768
Loss at iteration 880 : 0.02356812357902527
Loss at iteration 890 : 0.022831780835986137
Loss at iteration 900 : 0.02193285897374153
Loss at iteration 910 : 0.01581226848065853
Loss at iteration 920 : 0.01623024418950081
Loss at iteration 930 : 0.026017997413873672
Loss at iteration 940 : 0.017333414405584335
Loss at iteration 950 : 0.009904555976390839
Loss at iteration 960 : 0.01902158558368683
Loss at iteration 970 : 0.0169160608202219
Loss at iteration 980 : 0.03174876794219017
Loss at iteration 990 : 0.021756716072559357
Loss at iteration 1000 : 0.028721872717142105
Loss at iteration 1010 : 0.031178146600723267
Loss at iteration 1020 : 0.016342148184776306
Loss at iteration 1030 : 0.0163210891187191
Loss at iteration 1040 : 0.021961089223623276
Loss at iteration 1050 : 0.025603272020816803
Loss at iteration 1060 : 0.017949113622307777
Loss at iteration 1070 : 0.015080520883202553
Loss at iteration 1080 : 0.018258653581142426
Loss at iteration 1090 : 0.020716076716780663
Loss at iteration 1100 : 0.01752646267414093
Loss at iteration 1110 : 0.02517792582511902
Loss at iteration 1120 : 0.01637650653719902
Loss at iteration 1130 : 0.013317635282874107
Loss at iteration 1140 : 0.015413313172757626
Loss at iteration 1150 : 0.02985849604010582
Loss at iteration 1160 : 0.02101936563849449
Loss at iteration 1170 : 0.0274655744433403
Loss at iteration 1180 : 0.016150806099176407
Loss at iteration 1190 : 0.017703549936413765
Loss at iteration 1200 : 0.017817219719290733
Loss at iteration 1210 : 0.026350289583206177
The SSIM Value is: 0.8010056813557943
The PSNR Value is: 18.831430880228677
the epoch is: 142
Loss at iteration 10 : 0.025044292211532593
Loss at iteration 20 : 0.03176917880773544
Loss at iteration 30 : 0.020504234358668327
Loss at iteration 40 : 0.02081429213285446
Loss at iteration 50 : 0.015157794579863548
Loss at iteration 60 : 0.01284340862184763
Loss at iteration 70 : 0.019439322873950005
Loss at iteration 80 : 0.02321968600153923
Loss at iteration 90 : 0.025064950808882713
Loss at iteration 100 : 0.01604960858821869
Loss at iteration 110 : 0.015123416669666767
Loss at iteration 120 : 0.012330757454037666
Loss at iteration 130 : 0.015763841569423676
Loss at iteration 140 : 0.023983407765626907
Loss at iteration 150 : 0.016198717057704926
Loss at iteration 160 : 0.025818999856710434
Loss at iteration 170 : 0.016893133521080017
Loss at iteration 180 : 0.01669984869658947
Loss at iteration 190 : 0.01851377822458744
Loss at iteration 200 : 0.022706348448991776
Loss at iteration 210 : 0.022698860615491867
Loss at iteration 220 : 0.019257936626672745
Loss at iteration 230 : 0.01903696544468403
Loss at iteration 240 : 0.023984091356396675
Loss at iteration 250 : 0.020928464829921722
Loss at iteration 260 : 0.01589834690093994
Loss at iteration 270 : 0.027197841554880142
Loss at iteration 280 : 0.020735327154397964
Loss at iteration 290 : 0.012217734009027481
Loss at iteration 300 : 0.010266600176692009
Loss at iteration 310 : 0.014506964012980461
Loss at iteration 320 : 0.02258894219994545
Loss at iteration 330 : 0.02932118996977806
Loss at iteration 340 : 0.013418971560895443
Loss at iteration 350 : 0.025411482900381088
Loss at iteration 360 : 0.035215433686971664
Loss at iteration 370 : 0.024430349469184875
Loss at iteration 380 : 0.02974148653447628
Loss at iteration 390 : 0.026136312633752823
Loss at iteration 400 : 0.028564251959323883
Loss at iteration 410 : 0.011089935898780823
Loss at iteration 420 : 0.02363486960530281
Loss at iteration 430 : 0.016826342791318893
Loss at iteration 440 : 0.012962926179170609
Loss at iteration 450 : 0.01961250975728035
Loss at iteration 460 : 0.017085283994674683
Loss at iteration 470 : 0.02380378358066082
Loss at iteration 480 : 0.01578647643327713
Loss at iteration 490 : 0.012721121311187744
Loss at iteration 500 : 0.014041312970221043
Loss at iteration 510 : 0.017584197223186493
Loss at iteration 520 : 0.01606171205639839
Loss at iteration 530 : 0.020081643015146255
Loss at iteration 540 : 0.023861370980739594
Loss at iteration 550 : 0.010692205280065536
Loss at iteration 560 : 0.016707800328731537
Loss at iteration 570 : 0.013765903189778328
Loss at iteration 580 : 0.01741933636367321
Loss at iteration 590 : 0.02335958741605282
Loss at iteration 600 : 0.015984205529093742
Loss at iteration 610 : 0.01845039427280426
Loss at iteration 620 : 0.018382735550403595
Loss at iteration 630 : 0.018027570098638535
Loss at iteration 640 : 0.020235499367117882
Loss at iteration 650 : 0.010669758543372154
Loss at iteration 660 : 0.02045745775103569
Loss at iteration 670 : 0.0178631991147995
Loss at iteration 680 : 0.017892155796289444
Loss at iteration 690 : 0.01988341473042965
Loss at iteration 700 : 0.019281666725873947
Loss at iteration 710 : 0.01782410405576229
Loss at iteration 720 : 0.03441573679447174
Loss at iteration 730 : 0.016411732882261276
Loss at iteration 740 : 0.023658042773604393
Loss at iteration 750 : 0.031133441254496574
Loss at iteration 760 : 0.02702479064464569
Loss at iteration 770 : 0.022046292200684547
Loss at iteration 780 : 0.01626507192850113
Loss at iteration 790 : 0.025139978155493736
Loss at iteration 800 : 0.016664620488882065
Loss at iteration 810 : 0.02259562723338604
Loss at iteration 820 : 0.018957171589136124
Loss at iteration 830 : 0.014435239136219025
Loss at iteration 840 : 0.018282383680343628
Loss at iteration 850 : 0.023055855184793472
Loss at iteration 860 : 0.02035331539809704
Loss at iteration 870 : 0.01700677163898945
Loss at iteration 880 : 0.020234446972608566
Loss at iteration 890 : 0.016499076038599014
Loss at iteration 900 : 0.01376095600426197
Loss at iteration 910 : 0.020504988729953766
Loss at iteration 920 : 0.019796650856733322
Loss at iteration 930 : 0.026891225948929787
Loss at iteration 940 : 0.042014218866825104
Loss at iteration 950 : 0.028453929349780083
Loss at iteration 960 : 0.017344672232866287
Loss at iteration 970 : 0.01636308990418911
Loss at iteration 980 : 0.011418737471103668
Loss at iteration 990 : 0.016117731109261513
Loss at iteration 1000 : 0.023222658783197403
Loss at iteration 1010 : 0.013244280591607094
Loss at iteration 1020 : 0.014315260574221611
Loss at iteration 1030 : 0.014533428475260735
Loss at iteration 1040 : 0.025148015469312668
Loss at iteration 1050 : 0.020305991172790527
Loss at iteration 1060 : 0.020260335877537727
Loss at iteration 1070 : 0.01639648526906967
Loss at iteration 1080 : 0.019189082086086273
Loss at iteration 1090 : 0.01974884420633316
Loss at iteration 1100 : 0.015050793066620827
Loss at iteration 1110 : 0.015811357647180557
Loss at iteration 1120 : 0.02203245647251606
Loss at iteration 1130 : 0.02054882049560547
Loss at iteration 1140 : 0.023209575563669205
Loss at iteration 1150 : 0.02013113722205162
Loss at iteration 1160 : 0.032625697553157806
Loss at iteration 1170 : 0.019925985485315323
Loss at iteration 1180 : 0.037274498492479324
Loss at iteration 1190 : 0.02359606884419918
Loss at iteration 1200 : 0.031017925590276718
Loss at iteration 1210 : 0.03329136222600937
The SSIM Value is: 0.7987096905708313
The PSNR Value is: 18.823235257466635
the epoch is: 143
Loss at iteration 10 : 0.01432391069829464
Loss at iteration 20 : 0.021024826914072037
Loss at iteration 30 : 0.015992658212780952
Loss at iteration 40 : 0.020379072055220604
Loss at iteration 50 : 0.012627621181309223
Loss at iteration 60 : 0.02067156322300434
Loss at iteration 70 : 0.016875699162483215
Loss at iteration 80 : 0.03221063315868378
Loss at iteration 90 : 0.009690497070550919
Loss at iteration 100 : 0.02899835631251335
Loss at iteration 110 : 0.022898226976394653
Loss at iteration 120 : 0.016736822202801704
Loss at iteration 130 : 0.020259827375411987
Loss at iteration 140 : 0.013348807580769062
Loss at iteration 150 : 0.025799740105867386
Loss at iteration 160 : 0.014404634945094585
Loss at iteration 170 : 0.008741394616663456
Loss at iteration 180 : 0.01817399263381958
Loss at iteration 190 : 0.020083053037524223
Loss at iteration 200 : 0.011281788349151611
Loss at iteration 210 : 0.016245290637016296
Loss at iteration 220 : 0.015130835585296154
Loss at iteration 230 : 0.018994666635990143
Loss at iteration 240 : 0.023194193840026855
Loss at iteration 250 : 0.016144754365086555
Loss at iteration 260 : 0.02145274728536606
Loss at iteration 270 : 0.027448289096355438
Loss at iteration 280 : 0.007679850794374943
Loss at iteration 290 : 0.017575930804014206
Loss at iteration 300 : 0.016107909381389618
Loss at iteration 310 : 0.017342064529657364
Loss at iteration 320 : 0.01848968118429184
Loss at iteration 330 : 0.014240085147321224
Loss at iteration 340 : 0.016857067123055458
Loss at iteration 350 : 0.019771473482251167
Loss at iteration 360 : 0.024046897888183594
Loss at iteration 370 : 0.03290748968720436
Loss at iteration 380 : 0.02217998541891575
Loss at iteration 390 : 0.02838314138352871
Loss at iteration 400 : 0.02320997044444084
Loss at iteration 410 : 0.008976749144494534
Loss at iteration 420 : 0.012550638988614082
Loss at iteration 430 : 0.019234228879213333
Loss at iteration 440 : 0.01172553189098835
Loss at iteration 450 : 0.017119592055678368
Loss at iteration 460 : 0.0225349310785532
Loss at iteration 470 : 0.016604337841272354
Loss at iteration 480 : 0.017181461676955223
Loss at iteration 490 : 0.027181027457118034
Loss at iteration 500 : 0.025732286274433136
Loss at iteration 510 : 0.014957427978515625
Loss at iteration 520 : 0.012085044756531715
Loss at iteration 530 : 0.020416487008333206
Loss at iteration 540 : 0.03873731940984726
Loss at iteration 550 : 0.016720958054065704
Loss at iteration 560 : 0.013352648355066776
Loss at iteration 570 : 0.02621946856379509
Loss at iteration 580 : 0.02004070207476616
Loss at iteration 590 : 0.03599376976490021
Loss at iteration 600 : 0.014650517143309116
Loss at iteration 610 : 0.020261278375983238
Loss at iteration 620 : 0.01575128175318241
Loss at iteration 630 : 0.029937978833913803
Loss at iteration 640 : 0.017239943146705627
Loss at iteration 650 : 0.0247793085873127
Loss at iteration 660 : 0.033120930194854736
Loss at iteration 670 : 0.01391142513602972
Loss at iteration 680 : 0.009133856743574142
Loss at iteration 690 : 0.01792122982442379
Loss at iteration 700 : 0.018967343494296074
Loss at iteration 710 : 0.018668483942747116
Loss at iteration 720 : 0.022647181525826454
Loss at iteration 730 : 0.016498923301696777
Loss at iteration 740 : 0.024214763194322586
Loss at iteration 750 : 0.01712503843009472
Loss at iteration 760 : 0.019691258668899536
Loss at iteration 770 : 0.02436927706003189
Loss at iteration 780 : 0.035455621778964996
Loss at iteration 790 : 0.03618890792131424
Loss at iteration 800 : 0.030481193214654922
Loss at iteration 810 : 0.017269456759095192
Loss at iteration 820 : 0.02321559190750122
Loss at iteration 830 : 0.022665301337838173
Loss at iteration 840 : 0.01613745279610157
Loss at iteration 850 : 0.018468763679265976
Loss at iteration 860 : 0.01866309717297554
Loss at iteration 870 : 0.027321305125951767
Loss at iteration 880 : 0.017399782314896584
Loss at iteration 890 : 0.018013987690210342
Loss at iteration 900 : 0.021695559844374657
Loss at iteration 910 : 0.029790431261062622
Loss at iteration 920 : 0.02428155019879341
Loss at iteration 930 : 0.0208105631172657
Loss at iteration 940 : 0.016276279464364052
Loss at iteration 950 : 0.012600161135196686
Loss at iteration 960 : 0.027428677305579185
Loss at iteration 970 : 0.020284514874219894
Loss at iteration 980 : 0.02047101967036724
Loss at iteration 990 : 0.015020064078271389
Loss at iteration 1000 : 0.009401990100741386
Loss at iteration 1010 : 0.024807976558804512
Loss at iteration 1020 : 0.019708240404725075
Loss at iteration 1030 : 0.02779977023601532
Loss at iteration 1040 : 0.05283945053815842
Loss at iteration 1050 : 0.01918862946331501
Loss at iteration 1060 : 0.02176714316010475
Loss at iteration 1070 : 0.01836886629462242
Loss at iteration 1080 : 0.029836002737283707
Loss at iteration 1090 : 0.022996684536337852
Loss at iteration 1100 : 0.01884552091360092
Loss at iteration 1110 : 0.017666377127170563
Loss at iteration 1120 : 0.01963944360613823
Loss at iteration 1130 : 0.030874159187078476
Loss at iteration 1140 : 0.019510839134454727
Loss at iteration 1150 : 0.015261834487318993
Loss at iteration 1160 : 0.023203574120998383
Loss at iteration 1170 : 0.02060096524655819
Loss at iteration 1180 : 0.013543743640184402
Loss at iteration 1190 : 0.016809310764074326
Loss at iteration 1200 : 0.01441226340830326
Loss at iteration 1210 : 0.020855659618973732
The SSIM Value is: 0.8023495833079021
The PSNR Value is: 19.564368311564127
the epoch is: 144
Loss at iteration 10 : 0.024414820596575737
Loss at iteration 20 : 0.014925637282431126
Loss at iteration 30 : 0.016706015914678574
Loss at iteration 40 : 0.025665324181318283
Loss at iteration 50 : 0.014165807515382767
Loss at iteration 60 : 0.01712678000330925
Loss at iteration 70 : 0.014636633917689323
Loss at iteration 80 : 0.01816333830356598
Loss at iteration 90 : 0.025818094611167908
Loss at iteration 100 : 0.0201546810567379
Loss at iteration 110 : 0.02400195226073265
Loss at iteration 120 : 0.01731373369693756
Loss at iteration 130 : 0.02908528968691826
Loss at iteration 140 : 0.021928265690803528
Loss at iteration 150 : 0.017803078517317772
Loss at iteration 160 : 0.023582305759191513
Loss at iteration 170 : 0.01632862724363804
Loss at iteration 180 : 0.01916602812707424
Loss at iteration 190 : 0.021204985678195953
Loss at iteration 200 : 0.01538475789129734
Loss at iteration 210 : 0.01591884158551693
Loss at iteration 220 : 0.023843154311180115
Loss at iteration 230 : 0.020561538636684418
Loss at iteration 240 : 0.013323470950126648
Loss at iteration 250 : 0.025776857510209084
Loss at iteration 260 : 0.01173323579132557
Loss at iteration 270 : 0.01727583445608616
Loss at iteration 280 : 0.016470037400722504
Loss at iteration 290 : 0.018456067889928818
Loss at iteration 300 : 0.012483903206884861
Loss at iteration 310 : 0.028199119493365288
Loss at iteration 320 : 0.01741986721754074
Loss at iteration 330 : 0.01608157530426979
Loss at iteration 340 : 0.025591934099793434
Loss at iteration 350 : 0.014816765673458576
Loss at iteration 360 : 0.02010776475071907
Loss at iteration 370 : 0.021585535258054733
Loss at iteration 380 : 0.014938351698219776
Loss at iteration 390 : 0.01676260307431221
Loss at iteration 400 : 0.013718459755182266
Loss at iteration 410 : 0.01766773872077465
Loss at iteration 420 : 0.02526470646262169
Loss at iteration 430 : 0.01793140545487404
Loss at iteration 440 : 0.015856176614761353
Loss at iteration 450 : 0.025403331965208054
Loss at iteration 460 : 0.025224899873137474
Loss at iteration 470 : 0.024181518703699112
Loss at iteration 480 : 0.016658306121826172
Loss at iteration 490 : 0.024698670953512192
Loss at iteration 500 : 0.015630584210157394
Loss at iteration 510 : 0.01406355481594801
Loss at iteration 520 : 0.01182921789586544
Loss at iteration 530 : 0.028117230162024498
Loss at iteration 540 : 0.039450425654649734
Loss at iteration 550 : 0.022591784596443176
Loss at iteration 560 : 0.030369699001312256
Loss at iteration 570 : 0.02300693467259407
Loss at iteration 580 : 0.01915578544139862
Loss at iteration 590 : 0.03221432492136955
Loss at iteration 600 : 0.014978807419538498
Loss at iteration 610 : 0.030154097825288773
Loss at iteration 620 : 0.028297290205955505
Loss at iteration 630 : 0.03436581790447235
Loss at iteration 640 : 0.01336559560149908
Loss at iteration 650 : 0.031231598928570747
Loss at iteration 660 : 0.015929177403450012
Loss at iteration 670 : 0.016381684690713882
Loss at iteration 680 : 0.01795600727200508
Loss at iteration 690 : 0.024531742557883263
Loss at iteration 700 : 0.016718683764338493
Loss at iteration 710 : 0.01630144566297531
Loss at iteration 720 : 0.009428711608052254
Loss at iteration 730 : 0.02523823454976082
Loss at iteration 740 : 0.02137327939271927
Loss at iteration 750 : 0.026885734871029854
Loss at iteration 760 : 0.03221636265516281
Loss at iteration 770 : 0.016192343086004257
Loss at iteration 780 : 0.01457191538065672
Loss at iteration 790 : 0.015473483130335808
Loss at iteration 800 : 0.01810210943222046
Loss at iteration 810 : 0.011730553582310677
Loss at iteration 820 : 0.014746448956429958
Loss at iteration 830 : 0.021008802577853203
Loss at iteration 840 : 0.019247187301516533
Loss at iteration 850 : 0.024306200444698334
Loss at iteration 860 : 0.029932696372270584
Loss at iteration 870 : 0.01628289744257927
Loss at iteration 880 : 0.023683257400989532
Loss at iteration 890 : 0.015225209295749664
Loss at iteration 900 : 0.013851245865225792
Loss at iteration 910 : 0.021666433662176132
Loss at iteration 920 : 0.013851257041096687
Loss at iteration 930 : 0.018101107329130173
Loss at iteration 940 : 0.026603063568472862
Loss at iteration 950 : 0.02075277455151081
Loss at iteration 960 : 0.023621145635843277
Loss at iteration 970 : 0.02726082131266594
Loss at iteration 980 : 0.020358208566904068
Loss at iteration 990 : 0.021573254838585854
Loss at iteration 1000 : 0.0172214824706316
Loss at iteration 1010 : 0.024968689307570457
Loss at iteration 1020 : 0.027122845873236656
Loss at iteration 1030 : 0.024630926549434662
Loss at iteration 1040 : 0.01283286139369011
Loss at iteration 1050 : 0.021728936582803726
Loss at iteration 1060 : 0.01172479335218668
Loss at iteration 1070 : 0.011060799472033978
Loss at iteration 1080 : 0.012058506719768047
Loss at iteration 1090 : 0.008497652597725391
Loss at iteration 1100 : 0.04014253243803978
Loss at iteration 1110 : 0.01525227352976799
Loss at iteration 1120 : 0.02551528625190258
Loss at iteration 1130 : 0.015212271362543106
Loss at iteration 1140 : 0.02080291137099266
Loss at iteration 1150 : 0.028429310768842697
Loss at iteration 1160 : 0.01980569027364254
Loss at iteration 1170 : 0.017262209206819534
Loss at iteration 1180 : 0.030995478853583336
Loss at iteration 1190 : 0.027672015130519867
Loss at iteration 1200 : 0.01670706272125244
Loss at iteration 1210 : 0.015631919726729393
The SSIM Value is: 0.8033897201220195
The PSNR Value is: 19.99686113993327
the highest SSIM value is: 19.99686113993327
the epoch is: 145
Loss at iteration 10 : 0.02036903239786625
Loss at iteration 20 : 0.020414847880601883
Loss at iteration 30 : 0.01769198849797249
Loss at iteration 40 : 0.028852827847003937
Loss at iteration 50 : 0.028006460517644882
Loss at iteration 60 : 0.014781143516302109
Loss at iteration 70 : 0.021118488162755966
Loss at iteration 80 : 0.01533607766032219
Loss at iteration 90 : 0.029975997284054756
Loss at iteration 100 : 0.017567433416843414
Loss at iteration 110 : 0.01527573261409998
Loss at iteration 120 : 0.03378348425030708
Loss at iteration 130 : 0.016170402988791466
Loss at iteration 140 : 0.022853165864944458
Loss at iteration 150 : 0.01528105977922678
Loss at iteration 160 : 0.03872966393828392
Loss at iteration 170 : 0.018754223361611366
Loss at iteration 180 : 0.012439868412911892
Loss at iteration 190 : 0.012029202654957771
Loss at iteration 200 : 0.012605349533259869
Loss at iteration 210 : 0.01790536195039749
Loss at iteration 220 : 0.015282194130122662
Loss at iteration 230 : 0.01751895248889923
Loss at iteration 240 : 0.016595296561717987
Loss at iteration 250 : 0.015696365386247635
Loss at iteration 260 : 0.012736653909087181
Loss at iteration 270 : 0.023435648530721664
Loss at iteration 280 : 0.008145494386553764
Loss at iteration 290 : 0.024614829570055008
Loss at iteration 300 : 0.017191141843795776
Loss at iteration 310 : 0.016702909022569656
Loss at iteration 320 : 0.01854832097887993
Loss at iteration 330 : 0.025166388601064682
Loss at iteration 340 : 0.019474022090435028
Loss at iteration 350 : 0.02784891426563263
Loss at iteration 360 : 0.018601171672344208
Loss at iteration 370 : 0.01974117010831833
Loss at iteration 380 : 0.03142089024186134
Loss at iteration 390 : 0.01785595715045929
Loss at iteration 400 : 0.018393751233816147
Loss at iteration 410 : 0.01620609126985073
Loss at iteration 420 : 0.019201748073101044
Loss at iteration 430 : 0.021781496703624725
Loss at iteration 440 : 0.016952186822891235
Loss at iteration 450 : 0.017434898763895035
Loss at iteration 460 : 0.02952755242586136
Loss at iteration 470 : 0.017336180433630943
Loss at iteration 480 : 0.022122729569673538
Loss at iteration 490 : 0.013471380807459354
Loss at iteration 500 : 0.02492501772940159
Loss at iteration 510 : 0.02450915239751339
Loss at iteration 520 : 0.02190379798412323
Loss at iteration 530 : 0.029663346707820892
Loss at iteration 540 : 0.027271505445241928
Loss at iteration 550 : 0.03041134588420391
Loss at iteration 560 : 0.01644165627658367
Loss at iteration 570 : 0.02604326419532299
Loss at iteration 580 : 0.016959086060523987
Loss at iteration 590 : 0.012752093374729156
Loss at iteration 600 : 0.023218616843223572
Loss at iteration 610 : 0.015157343819737434
Loss at iteration 620 : 0.025177238509058952
Loss at iteration 630 : 0.01256945263594389
Loss at iteration 640 : 0.021444737911224365
Loss at iteration 650 : 0.011631366796791553
Loss at iteration 660 : 0.020707225427031517
Loss at iteration 670 : 0.03858528286218643
Loss at iteration 680 : 0.019916046410799026
Loss at iteration 690 : 0.016534294933080673
Loss at iteration 700 : 0.012032628990709782
Loss at iteration 710 : 0.020679660141468048
Loss at iteration 720 : 0.013774429447948933
Loss at iteration 730 : 0.025551460683345795
Loss at iteration 740 : 0.01659570075571537
Loss at iteration 750 : 0.027519522234797478
Loss at iteration 760 : 0.017561975866556168
Loss at iteration 770 : 0.010174786671996117
Loss at iteration 780 : 0.017050933092832565
Loss at iteration 790 : 0.012437190860509872
Loss at iteration 800 : 0.0207991786301136
Loss at iteration 810 : 0.022587895393371582
Loss at iteration 820 : 0.0249018594622612
Loss at iteration 830 : 0.01385628804564476
Loss at iteration 840 : 0.019113941118121147
Loss at iteration 850 : 0.018482722342014313
Loss at iteration 860 : 0.021096859127283096
Loss at iteration 870 : 0.026245728135108948
Loss at iteration 880 : 0.014859131537377834
Loss at iteration 890 : 0.02248227223753929
Loss at iteration 900 : 0.033138930797576904
Loss at iteration 910 : 0.010846366174519062
Loss at iteration 920 : 0.017112422734498978
Loss at iteration 930 : 0.01660161279141903
Loss at iteration 940 : 0.017242074012756348
Loss at iteration 950 : 0.008748635649681091
Loss at iteration 960 : 0.01603100076317787
Loss at iteration 970 : 0.04360852763056755
Loss at iteration 980 : 0.01700315810739994
Loss at iteration 990 : 0.02071371115744114
Loss at iteration 1000 : 0.01912325993180275
Loss at iteration 1010 : 0.025708038359880447
Loss at iteration 1020 : 0.019897866994142532
Loss at iteration 1030 : 0.02589142695069313
Loss at iteration 1040 : 0.016763383522629738
Loss at iteration 1050 : 0.016810094937682152
Loss at iteration 1060 : 0.020455248653888702
Loss at iteration 1070 : 0.024708719924092293
Loss at iteration 1080 : 0.022516358643770218
Loss at iteration 1090 : 0.028544940054416656
Loss at iteration 1100 : 0.026651589199900627
Loss at iteration 1110 : 0.016751982271671295
Loss at iteration 1120 : 0.01605254039168358
Loss at iteration 1130 : 0.02841177210211754
Loss at iteration 1140 : 0.04726184532046318
Loss at iteration 1150 : 0.0201912522315979
Loss at iteration 1160 : 0.02062489092350006
Loss at iteration 1170 : 0.02177073061466217
Loss at iteration 1180 : 0.015184342861175537
Loss at iteration 1190 : 0.02122388780117035
Loss at iteration 1200 : 0.015033399686217308
Loss at iteration 1210 : 0.013549145311117172
The SSIM Value is: 0.7561885794003804
The PSNR Value is: 16.766833559672037
the epoch is: 146
Loss at iteration 10 : 0.01230638101696968
Loss at iteration 20 : 0.02258205972611904
Loss at iteration 30 : 0.03262154385447502
Loss at iteration 40 : 0.014919114299118519
Loss at iteration 50 : 0.019002612680196762
Loss at iteration 60 : 0.024978578090667725
Loss at iteration 70 : 0.01728520542383194
Loss at iteration 80 : 0.02100817859172821
Loss at iteration 90 : 0.03138779476284981
Loss at iteration 100 : 0.019712701439857483
Loss at iteration 110 : 0.02407175675034523
Loss at iteration 120 : 0.013708317652344704
Loss at iteration 130 : 0.018666911870241165
Loss at iteration 140 : 0.010978718288242817
Loss at iteration 150 : 0.022925496101379395
Loss at iteration 160 : 0.01634863205254078
Loss at iteration 170 : 0.015667177736759186
Loss at iteration 180 : 0.02186003513634205
Loss at iteration 190 : 0.015097120776772499
Loss at iteration 200 : 0.02016986906528473
Loss at iteration 210 : 0.011221081018447876
Loss at iteration 220 : 0.019073601812124252
Loss at iteration 230 : 0.02178073301911354
Loss at iteration 240 : 0.020870883017778397
Loss at iteration 250 : 0.02173197641968727
Loss at iteration 260 : 0.018553143367171288
Loss at iteration 270 : 0.012950615957379341
Loss at iteration 280 : 0.019001085311174393
Loss at iteration 290 : 0.014903751201927662
Loss at iteration 300 : 0.010332031175494194
Loss at iteration 310 : 0.016084978356957436
Loss at iteration 320 : 0.013763392344117165
Loss at iteration 330 : 0.0168042853474617
Loss at iteration 340 : 0.014620031230151653
Loss at iteration 350 : 0.008559297770261765
Loss at iteration 360 : 0.024929195642471313
Loss at iteration 370 : 0.02078610472381115
Loss at iteration 380 : 0.029857682064175606
Loss at iteration 390 : 0.02374999411404133
Loss at iteration 400 : 0.027459383010864258
Loss at iteration 410 : 0.018076611682772636
Loss at iteration 420 : 0.016562659293413162
Loss at iteration 430 : 0.024374548345804214
Loss at iteration 440 : 0.021689578890800476
Loss at iteration 450 : 0.016820184886455536
Loss at iteration 460 : 0.02998962253332138
Loss at iteration 470 : 0.023695282638072968
Loss at iteration 480 : 0.020749535411596298
Loss at iteration 490 : 0.019712377339601517
Loss at iteration 500 : 0.020119555294513702
Loss at iteration 510 : 0.018937867134809494
Loss at iteration 520 : 0.01999666541814804
Loss at iteration 530 : 0.014209804125130177
Loss at iteration 540 : 0.03474387153983116
Loss at iteration 550 : 0.02991878241300583
Loss at iteration 560 : 0.024253739044070244
Loss at iteration 570 : 0.013404588215053082
Loss at iteration 580 : 0.028018690645694733
Loss at iteration 590 : 0.017003554850816727
Loss at iteration 600 : 0.024676404893398285
Loss at iteration 610 : 0.020871561020612717
Loss at iteration 620 : 0.021135471761226654
Loss at iteration 630 : 0.022213149815797806
Loss at iteration 640 : 0.03452346846461296
Loss at iteration 650 : 0.01779182441532612
Loss at iteration 660 : 0.017027808353304863
Loss at iteration 670 : 0.02027755230665207
Loss at iteration 680 : 0.02119138464331627
Loss at iteration 690 : 0.02079806476831436
Loss at iteration 700 : 0.016454845666885376
Loss at iteration 710 : 0.011486181989312172
Loss at iteration 720 : 0.008696054108440876
Loss at iteration 730 : 0.012581163085997105
Loss at iteration 740 : 0.022693555802106857
Loss at iteration 750 : 0.02985147014260292
Loss at iteration 760 : 0.010841085575520992
Loss at iteration 770 : 0.028097622096538544
Loss at iteration 780 : 0.0349557101726532
Loss at iteration 790 : 0.022807320579886436
Loss at iteration 800 : 0.026494652032852173
Loss at iteration 810 : 0.013925820589065552
Loss at iteration 820 : 0.03565583750605583
Loss at iteration 830 : 0.016649998724460602
Loss at iteration 840 : 0.03702644258737564
Loss at iteration 850 : 0.023963112384080887
Loss at iteration 860 : 0.023880932480096817
Loss at iteration 870 : 0.009796972386538982
Loss at iteration 880 : 0.013832798227667809
Loss at iteration 890 : 0.038189586251974106
Loss at iteration 900 : 0.010972716845571995
Loss at iteration 910 : 0.014847889542579651
Loss at iteration 920 : 0.020317211747169495
Loss at iteration 930 : 0.02901313453912735
Loss at iteration 940 : 0.018731188029050827
Loss at iteration 950 : 0.022466935217380524
Loss at iteration 960 : 0.015672434121370316
Loss at iteration 970 : 0.019600508734583855
Loss at iteration 980 : 0.01817280426621437
Loss at iteration 990 : 0.02218989096581936
Loss at iteration 1000 : 0.020177407190203667
Loss at iteration 1010 : 0.02146228402853012
Loss at iteration 1020 : 0.02308713272213936
Loss at iteration 1030 : 0.025423094630241394
Loss at iteration 1040 : 0.013000572100281715
Loss at iteration 1050 : 0.01536328811198473
Loss at iteration 1060 : 0.019387297332286835
Loss at iteration 1070 : 0.01524277962744236
Loss at iteration 1080 : 0.021192695945501328
Loss at iteration 1090 : 0.02789306640625
Loss at iteration 1100 : 0.02337932586669922
Loss at iteration 1110 : 0.018238790333271027
Loss at iteration 1120 : 0.012796621769666672
Loss at iteration 1130 : 0.012626711279153824
Loss at iteration 1140 : 0.02462301403284073
Loss at iteration 1150 : 0.02845359966158867
Loss at iteration 1160 : 0.020363088697195053
Loss at iteration 1170 : 0.013959202915430069
Loss at iteration 1180 : 0.024861929938197136
Loss at iteration 1190 : 0.020554600283503532
Loss at iteration 1200 : 0.016506729647517204
Loss at iteration 1210 : 0.0194888673722744
The SSIM Value is: 0.8061058004697164
The PSNR Value is: 19.208994674682618
the epoch is: 147
Loss at iteration 10 : 0.014170151203870773
Loss at iteration 20 : 0.018549740314483643
Loss at iteration 30 : 0.01479170098900795
Loss at iteration 40 : 0.024728916585445404
Loss at iteration 50 : 0.013183359056711197
Loss at iteration 60 : 0.025459498167037964
Loss at iteration 70 : 0.01665513962507248
Loss at iteration 80 : 0.025311462581157684
Loss at iteration 90 : 0.023907165974378586
Loss at iteration 100 : 0.02131640538573265
Loss at iteration 110 : 0.01740419864654541
Loss at iteration 120 : 0.030112259089946747
Loss at iteration 130 : 0.033291276544332504
Loss at iteration 140 : 0.014332951977849007
Loss at iteration 150 : 0.028059493750333786
Loss at iteration 160 : 0.017718404531478882
Loss at iteration 170 : 0.02302676811814308
Loss at iteration 180 : 0.018472351133823395
Loss at iteration 190 : 0.011099306866526604
Loss at iteration 200 : 0.021679749712347984
Loss at iteration 210 : 0.017326220870018005
Loss at iteration 220 : 0.01260946411639452
Loss at iteration 230 : 0.032001469284296036
Loss at iteration 240 : 0.01973549649119377
Loss at iteration 250 : 0.027572045102715492
Loss at iteration 260 : 0.026972468942403793
Loss at iteration 270 : 0.018888838589191437
Loss at iteration 280 : 0.016147637739777565
Loss at iteration 290 : 0.01622932031750679
Loss at iteration 300 : 0.015328720211982727
Loss at iteration 310 : 0.01641002669930458
Loss at iteration 320 : 0.02215232141315937
Loss at iteration 330 : 0.02709551341831684
Loss at iteration 340 : 0.018155481666326523
Loss at iteration 350 : 0.02383769303560257
Loss at iteration 360 : 0.0117763951420784
Loss at iteration 370 : 0.028676467016339302
Loss at iteration 380 : 0.022566065192222595
Loss at iteration 390 : 0.016975007951259613
Loss at iteration 400 : 0.023895638063549995
Loss at iteration 410 : 0.02643575705587864
Loss at iteration 420 : 0.016767997294664383
Loss at iteration 430 : 0.01396313589066267
Loss at iteration 440 : 0.030390402302145958
Loss at iteration 450 : 0.024086426943540573
Loss at iteration 460 : 0.012811796739697456
Loss at iteration 470 : 0.013422376476228237
Loss at iteration 480 : 0.026121599599719048
Loss at iteration 490 : 0.016369912773370743
Loss at iteration 500 : 0.024072881788015366
Loss at iteration 510 : 0.03034360520541668
Loss at iteration 520 : 0.01711382158100605
Loss at iteration 530 : 0.021640926599502563
Loss at iteration 540 : 0.02255323715507984
Loss at iteration 550 : 0.02676190808415413
Loss at iteration 560 : 0.017469022423028946
Loss at iteration 570 : 0.032474882900714874
Loss at iteration 580 : 0.014335816726088524
Loss at iteration 590 : 0.015513040125370026
Loss at iteration 600 : 0.01694367080926895
Loss at iteration 610 : 0.015504240989685059
Loss at iteration 620 : 0.019801553338766098
Loss at iteration 630 : 0.022927116602659225
Loss at iteration 640 : 0.015114598907530308
Loss at iteration 650 : 0.01503647118806839
Loss at iteration 660 : 0.030755460262298584
Loss at iteration 670 : 0.016407448798418045
Loss at iteration 680 : 0.018165290355682373
Loss at iteration 690 : 0.019594857469201088
Loss at iteration 700 : 0.016573943197727203
Loss at iteration 710 : 0.012758787721395493
Loss at iteration 720 : 0.017189431935548782
Loss at iteration 730 : 0.019114572554826736
Loss at iteration 740 : 0.02279036119580269
Loss at iteration 750 : 0.022884391248226166
Loss at iteration 760 : 0.021160874515771866
Loss at iteration 770 : 0.014598004519939423
Loss at iteration 780 : 0.023104114457964897
Loss at iteration 790 : 0.024938039481639862
Loss at iteration 800 : 0.02032081037759781
Loss at iteration 810 : 0.012456662952899933
Loss at iteration 820 : 0.014145894907414913
Loss at iteration 830 : 0.014366162940859795
Loss at iteration 840 : 0.015327084809541702
Loss at iteration 850 : 0.016036372631788254
Loss at iteration 860 : 0.012626254931092262
Loss at iteration 870 : 0.015621719881892204
Loss at iteration 880 : 0.018572933971881866
Loss at iteration 890 : 0.015165316872298717
Loss at iteration 900 : 0.017199736088514328
Loss at iteration 910 : 0.02401670068502426
Loss at iteration 920 : 0.025566812604665756
Loss at iteration 930 : 0.04140900447964668
Loss at iteration 940 : 0.016803886741399765
Loss at iteration 950 : 0.0168195441365242
Loss at iteration 960 : 0.020375454798340797
Loss at iteration 970 : 0.018764756619930267
Loss at iteration 980 : 0.01238167192786932
Loss at iteration 990 : 0.019605908542871475
Loss at iteration 1000 : 0.014571827836334705
Loss at iteration 1010 : 0.013440851122140884
Loss at iteration 1020 : 0.023674283176660538
Loss at iteration 1030 : 0.013399044051766396
Loss at iteration 1040 : 0.023525092750787735
Loss at iteration 1050 : 0.019446147605776787
Loss at iteration 1060 : 0.02193618193268776
Loss at iteration 1070 : 0.026447750627994537
Loss at iteration 1080 : 0.0188914705067873
Loss at iteration 1090 : 0.012433243915438652
Loss at iteration 1100 : 0.023784849792718887
Loss at iteration 1110 : 0.015181630849838257
Loss at iteration 1120 : 0.03097919560968876
Loss at iteration 1130 : 0.014806566759943962
Loss at iteration 1140 : 0.014676813036203384
Loss at iteration 1150 : 0.026445232331752777
Loss at iteration 1160 : 0.01398652046918869
Loss at iteration 1170 : 0.024355027824640274
Loss at iteration 1180 : 0.03212117776274681
Loss at iteration 1190 : 0.02470436319708824
Loss at iteration 1200 : 0.022758765146136284
Loss at iteration 1210 : 0.014369692653417587
The SSIM Value is: 0.8003773331642151
The PSNR Value is: 19.549846585591634
the epoch is: 148
Loss at iteration 10 : 0.02374374493956566
Loss at iteration 20 : 0.024452868849039078
Loss at iteration 30 : 0.041731737554073334
Loss at iteration 40 : 0.024393979460000992
Loss at iteration 50 : 0.023081542924046516
Loss at iteration 60 : 0.03942892700433731
Loss at iteration 70 : 0.016332169994711876
Loss at iteration 80 : 0.0246565118432045
Loss at iteration 90 : 0.012725276872515678
Loss at iteration 100 : 0.02305646985769272
Loss at iteration 110 : 0.013101858086884022
Loss at iteration 120 : 0.022524898871779442
Loss at iteration 130 : 0.0321466326713562
Loss at iteration 140 : 0.013710107654333115
Loss at iteration 150 : 0.02255241945385933
Loss at iteration 160 : 0.03875302895903587
Loss at iteration 170 : 0.015032999217510223
Loss at iteration 180 : 0.024119213223457336
Loss at iteration 190 : 0.010579437017440796
Loss at iteration 200 : 0.020321421325206757
Loss at iteration 210 : 0.016186177730560303
Loss at iteration 220 : 0.018531322479248047
Loss at iteration 230 : 0.013400686904788017
Loss at iteration 240 : 0.013944298028945923
Loss at iteration 250 : 0.016615791246294975
Loss at iteration 260 : 0.019729498773813248
Loss at iteration 270 : 0.01361444778740406
Loss at iteration 280 : 0.01653750240802765
Loss at iteration 290 : 0.016246642917394638
Loss at iteration 300 : 0.027377702295780182
Loss at iteration 310 : 0.02191007509827614
Loss at iteration 320 : 0.02333381026983261
Loss at iteration 330 : 0.015550123527646065
Loss at iteration 340 : 0.016054484993219376
Loss at iteration 350 : 0.010405794717371464
Loss at iteration 360 : 0.02292773500084877
Loss at iteration 370 : 0.02479478344321251
Loss at iteration 380 : 0.0211980901658535
Loss at iteration 390 : 0.018806874752044678
Loss at iteration 400 : 0.022991515696048737
Loss at iteration 410 : 0.01608947105705738
Loss at iteration 420 : 0.0199989415705204
Loss at iteration 430 : 0.011262256652116776
Loss at iteration 440 : 0.03221900761127472
Loss at iteration 450 : 0.03329725190997124
Loss at iteration 460 : 0.011779583059251308
Loss at iteration 470 : 0.027858855202794075
Loss at iteration 480 : 0.022069109603762627
Loss at iteration 490 : 0.009548656642436981
Loss at iteration 500 : 0.02106896974146366
Loss at iteration 510 : 0.010633692145347595
Loss at iteration 520 : 0.027096033096313477
Loss at iteration 530 : 0.017993919551372528
Loss at iteration 540 : 0.03081463649868965
Loss at iteration 550 : 0.023030836135149002
Loss at iteration 560 : 0.032154545187950134
Loss at iteration 570 : 0.020588364452123642
Loss at iteration 580 : 0.021652355790138245
Loss at iteration 590 : 0.04174540191888809
Loss at iteration 600 : 0.024323588237166405
Loss at iteration 610 : 0.017157334834337234
Loss at iteration 620 : 0.01802663318812847
Loss at iteration 630 : 0.01874728314578533
Loss at iteration 640 : 0.0272287055850029
Loss at iteration 650 : 0.02183648571372032
Loss at iteration 660 : 0.021273910999298096
Loss at iteration 670 : 0.021233724430203438
Loss at iteration 680 : 0.023072054609656334
Loss at iteration 690 : 0.028244778513908386
Loss at iteration 700 : 0.01813739538192749
Loss at iteration 710 : 0.011876444332301617
Loss at iteration 720 : 0.01642601564526558
Loss at iteration 730 : 0.025134077295660973
Loss at iteration 740 : 0.010944581590592861
Loss at iteration 750 : 0.01213250495493412
Loss at iteration 760 : 0.019001197069883347
Loss at iteration 770 : 0.01087157428264618
Loss at iteration 780 : 0.017688319087028503
Loss at iteration 790 : 0.020566869527101517
Loss at iteration 800 : 0.026999909430742264
Loss at iteration 810 : 0.020217781886458397
Loss at iteration 820 : 0.01834491640329361
Loss at iteration 830 : 0.017730671912431717
Loss at iteration 840 : 0.019386757165193558
Loss at iteration 850 : 0.014381034299731255
Loss at iteration 860 : 0.02210867777466774
Loss at iteration 870 : 0.019286438822746277
Loss at iteration 880 : 0.022043243050575256
Loss at iteration 890 : 0.01620648056268692
Loss at iteration 900 : 0.01401938684284687
Loss at iteration 910 : 0.011043312959372997
Loss at iteration 920 : 0.01737322099506855
Loss at iteration 930 : 0.014613066799938679
Loss at iteration 940 : 0.017116565257310867
Loss at iteration 950 : 0.017315922304987907
Loss at iteration 960 : 0.024345295503735542
Loss at iteration 970 : 0.024687321856617928
Loss at iteration 980 : 0.020104900002479553
Loss at iteration 990 : 0.023308824747800827
Loss at iteration 1000 : 0.026608895510435104
Loss at iteration 1010 : 0.021375970914959908
Loss at iteration 1020 : 0.018998516723513603
Loss at iteration 1030 : 0.05104610323905945
Loss at iteration 1040 : 0.02908129245042801
Loss at iteration 1050 : 0.02261047624051571
Loss at iteration 1060 : 0.015435628592967987
Loss at iteration 1070 : 0.013499513268470764
Loss at iteration 1080 : 0.01236905250698328
Loss at iteration 1090 : 0.015244687907397747
Loss at iteration 1100 : 0.010708924382925034
Loss at iteration 1110 : 0.013312717899680138
Loss at iteration 1120 : 0.026175901293754578
Loss at iteration 1130 : 0.028676876798272133
Loss at iteration 1140 : 0.018790315836668015
Loss at iteration 1150 : 0.02339831553399563
Loss at iteration 1160 : 0.03237620368599892
Loss at iteration 1170 : 0.014414148405194283
Loss at iteration 1180 : 0.018088873475790024
Loss at iteration 1190 : 0.014348195865750313
Loss at iteration 1200 : 0.012998206540942192
Loss at iteration 1210 : 0.017418498173356056
The SSIM Value is: 0.8034778038660685
The PSNR Value is: 19.646327781677247
the epoch is: 149
Loss at iteration 10 : 0.02193932607769966
Loss at iteration 20 : 0.019675297662615776
Loss at iteration 30 : 0.018828192725777626
Loss at iteration 40 : 0.028553349897265434
Loss at iteration 50 : 0.017324969172477722
Loss at iteration 60 : 0.019213370978832245
Loss at iteration 70 : 0.013984743505716324
Loss at iteration 80 : 0.01998947374522686
Loss at iteration 90 : 0.04030242934823036
Loss at iteration 100 : 0.011154752224683762
Loss at iteration 110 : 0.018812982365489006
Loss at iteration 120 : 0.021723421290516853
Loss at iteration 130 : 0.026567939668893814
Loss at iteration 140 : 0.016873259097337723
Loss at iteration 150 : 0.015812696889042854
Loss at iteration 160 : 0.012324811890721321
Loss at iteration 170 : 0.021070260554552078
Loss at iteration 180 : 0.02089865319430828
Loss at iteration 190 : 0.02155359834432602
Loss at iteration 200 : 0.02669539302587509
Loss at iteration 210 : 0.018075931817293167
Loss at iteration 220 : 0.02192552015185356
Loss at iteration 230 : 0.01820838637650013
Loss at iteration 240 : 0.02779981680214405
Loss at iteration 250 : 0.023114029318094254
Loss at iteration 260 : 0.023222649469971657
Loss at iteration 270 : 0.016453862190246582
Loss at iteration 280 : 0.010557123459875584
Loss at iteration 290 : 0.011579364538192749
Loss at iteration 300 : 0.021176354959607124
Loss at iteration 310 : 0.018028242513537407
Loss at iteration 320 : 0.01952369138598442
Loss at iteration 330 : 0.02658228948712349
Loss at iteration 340 : 0.0204826258122921
Loss at iteration 350 : 0.03695705160498619
Loss at iteration 360 : 0.018047362565994263
Loss at iteration 370 : 0.01694243773818016
Loss at iteration 380 : 0.01635482721030712
Loss at iteration 390 : 0.01970326341688633
Loss at iteration 400 : 0.02194676734507084
Loss at iteration 410 : 0.029629457741975784
Loss at iteration 420 : 0.029569072648882866
Loss at iteration 430 : 0.01639963686466217
Loss at iteration 440 : 0.01711784489452839
Loss at iteration 450 : 0.022718137130141258
Loss at iteration 460 : 0.009739143773913383
Loss at iteration 470 : 0.02047954872250557
Loss at iteration 480 : 0.040915749967098236
Loss at iteration 490 : 0.02599429525434971
Loss at iteration 500 : 0.023017151281237602
Loss at iteration 510 : 0.023337367922067642
Loss at iteration 520 : 0.026245256885886192
Loss at iteration 530 : 0.02471194416284561
Loss at iteration 540 : 0.028777150437235832
Loss at iteration 550 : 0.03332652896642685
Loss at iteration 560 : 0.026428617537021637
Loss at iteration 570 : 0.022381503134965897
Loss at iteration 580 : 0.01754901558160782
Loss at iteration 590 : 0.018528752028942108
Loss at iteration 600 : 0.030977189540863037
Loss at iteration 610 : 0.00992057379335165
Loss at iteration 620 : 0.014188984408974648
Loss at iteration 630 : 0.017289813607931137
Loss at iteration 640 : 0.023024115711450577
Loss at iteration 650 : 0.021527085453271866
Loss at iteration 660 : 0.01829707808792591
Loss at iteration 670 : 0.018993863835930824
Loss at iteration 680 : 0.027739904820919037
Loss at iteration 690 : 0.012503527104854584
Loss at iteration 700 : 0.018068887293338776
Loss at iteration 710 : 0.026873447000980377
Loss at iteration 720 : 0.025679491460323334
Loss at iteration 730 : 0.0166948065161705
Loss at iteration 740 : 0.01912996545433998
Loss at iteration 750 : 0.026423640549182892
Loss at iteration 760 : 0.01808653026819229
Loss at iteration 770 : 0.024164889007806778
Loss at iteration 780 : 0.023168588057160378
Loss at iteration 790 : 0.008904654532670975
Loss at iteration 800 : 0.02003464847803116
Loss at iteration 810 : 0.01759316585958004
Loss at iteration 820 : 0.015384962782263756
Loss at iteration 830 : 0.018872924149036407
Loss at iteration 840 : 0.022540315985679626
Loss at iteration 850 : 0.01907297596335411
Loss at iteration 860 : 0.013365231454372406
Loss at iteration 870 : 0.018805131316184998
Loss at iteration 880 : 0.019196249544620514
Loss at iteration 890 : 0.01731254905462265
Loss at iteration 900 : 0.022661246359348297
Loss at iteration 910 : 0.016736464574933052
Loss at iteration 920 : 0.03377159684896469
Loss at iteration 930 : 0.02659713104367256
Loss at iteration 940 : 0.01610204204916954
Loss at iteration 950 : 0.023785894736647606
Loss at iteration 960 : 0.0161964762955904
Loss at iteration 970 : 0.01983565092086792
Loss at iteration 980 : 0.01750565692782402
Loss at iteration 990 : 0.020867787301540375
Loss at iteration 1000 : 0.019423160701990128
Loss at iteration 1010 : 0.013355709612369537
Loss at iteration 1020 : 0.02153237722814083
Loss at iteration 1030 : 0.014388831332325935
Loss at iteration 1040 : 0.01157204806804657
Loss at iteration 1050 : 0.029225360602140427
Loss at iteration 1060 : 0.023321663960814476
Loss at iteration 1070 : 0.015379507094621658
Loss at iteration 1080 : 0.030021198093891144
Loss at iteration 1090 : 0.01956319808959961
Loss at iteration 1100 : 0.013695379719138145
Loss at iteration 1110 : 0.01704294979572296
Loss at iteration 1120 : 0.011610006913542747
Loss at iteration 1130 : 0.02465139329433441
Loss at iteration 1140 : 0.022144505754113197
Loss at iteration 1150 : 0.01747671142220497
Loss at iteration 1160 : 0.018167559057474136
Loss at iteration 1170 : 0.0149921840056777
Loss at iteration 1180 : 0.023520279675722122
Loss at iteration 1190 : 0.021278560161590576
Loss at iteration 1200 : 0.01277719996869564
Loss at iteration 1210 : 0.016144588589668274
The SSIM Value is: 0.8051758488019307
The PSNR Value is: 20.00479539235433
the highest SSIM value is: 20.00479539235433
the epoch is: 150
Loss at iteration 10 : 0.02139509655535221
Loss at iteration 20 : 0.02437625080347061
Loss at iteration 30 : 0.0182950496673584
Loss at iteration 40 : 0.016727348789572716
Loss at iteration 50 : 0.01583714969456196
Loss at iteration 60 : 0.02116870880126953
Loss at iteration 70 : 0.022043947130441666
Loss at iteration 80 : 0.020756199955940247
Loss at iteration 90 : 0.022821374237537384
Loss at iteration 100 : 0.02098064497113228
Loss at iteration 110 : 0.028306012973189354
Loss at iteration 120 : 0.01781894639134407
Loss at iteration 130 : 0.018358446657657623
Loss at iteration 140 : 0.016653254628181458
Loss at iteration 150 : 0.014732381328940392
Loss at iteration 160 : 0.013199837878346443
Loss at iteration 170 : 0.02212364599108696
Loss at iteration 180 : 0.02037566713988781
Loss at iteration 190 : 0.012574123218655586
Loss at iteration 200 : 0.011966921389102936
Loss at iteration 210 : 0.01685149222612381
Loss at iteration 220 : 0.02577967941761017
Loss at iteration 230 : 0.018604686483740807
Loss at iteration 240 : 0.01988246478140354
Loss at iteration 250 : 0.01819372922182083
Loss at iteration 260 : 0.017629608511924744
Loss at iteration 270 : 0.020753536373376846
Loss at iteration 280 : 0.015285210683941841
Loss at iteration 290 : 0.016039902344346046
Loss at iteration 300 : 0.015529012307524681
Loss at iteration 310 : 0.01023200061172247
Loss at iteration 320 : 0.011431264691054821
Loss at iteration 330 : 0.026854075491428375
Loss at iteration 340 : 0.02147676795721054
Loss at iteration 350 : 0.012143323197960854
Loss at iteration 360 : 0.03889045864343643
Loss at iteration 370 : 0.02127533033490181
Loss at iteration 380 : 0.01257294975221157
Loss at iteration 390 : 0.010832487605512142
Loss at iteration 400 : 0.016612688079476357
Loss at iteration 410 : 0.019260236993432045
Loss at iteration 420 : 0.012418964877724648
Loss at iteration 430 : 0.03268013522028923
Loss at iteration 440 : 0.02469109371304512
Loss at iteration 450 : 0.030278224498033524
Loss at iteration 460 : 0.015250757336616516
Loss at iteration 470 : 0.01616395264863968
Loss at iteration 480 : 0.018217401579022408
Loss at iteration 490 : 0.018000464886426926
Loss at iteration 500 : 0.0259257685393095
Loss at iteration 510 : 0.026766624301671982
Loss at iteration 520 : 0.026440907269716263
Loss at iteration 530 : 0.01424125675112009
Loss at iteration 540 : 0.026131367310881615
Loss at iteration 550 : 0.014386093243956566
Loss at iteration 560 : 0.024550188332796097
Loss at iteration 570 : 0.026121489703655243
Loss at iteration 580 : 0.015156627632677555
Loss at iteration 590 : 0.01931861601769924
Loss at iteration 600 : 0.017990048974752426
Loss at iteration 610 : 0.01970883272588253
Loss at iteration 620 : 0.018302232027053833
Loss at iteration 630 : 0.01607424020767212
Loss at iteration 640 : 0.01405082456767559
Loss at iteration 650 : 0.022942788898944855
Loss at iteration 660 : 0.018625374883413315
Loss at iteration 670 : 0.0147751085460186
Loss at iteration 680 : 0.016394436359405518
Loss at iteration 690 : 0.020386599004268646
Loss at iteration 700 : 0.013145644217729568
Loss at iteration 710 : 0.025003166869282722
Loss at iteration 720 : 0.017231667414307594
Loss at iteration 730 : 0.021770203486084938
Loss at iteration 740 : 0.01824183389544487
Loss at iteration 750 : 0.013169069774448872
Loss at iteration 760 : 0.013659178279340267
Loss at iteration 770 : 0.022003062069416046
Loss at iteration 780 : 0.018525490537285805
Loss at iteration 790 : 0.021363988518714905
Loss at iteration 800 : 0.021913820877671242
Loss at iteration 810 : 0.02799748256802559
Loss at iteration 820 : 0.021945465356111526
Loss at iteration 830 : 0.026774343103170395
Loss at iteration 840 : 0.034046564251184464
Loss at iteration 850 : 0.021310361102223396
Loss at iteration 860 : 0.014811374247074127
Loss at iteration 870 : 0.022033069282770157
Loss at iteration 880 : 0.019092649221420288
Loss at iteration 890 : 0.02242935262620449
Loss at iteration 900 : 0.01707044430077076
Loss at iteration 910 : 0.012952941469848156
Loss at iteration 920 : 0.014949151314795017
Loss at iteration 930 : 0.021562300622463226
Loss at iteration 940 : 0.016760556027293205
Loss at iteration 950 : 0.015539408661425114
Loss at iteration 960 : 0.020213767886161804
Loss at iteration 970 : 0.017713457345962524
Loss at iteration 980 : 0.02274317294359207
Loss at iteration 990 : 0.02335100993514061
Loss at iteration 1000 : 0.03044867143034935
Loss at iteration 1010 : 0.018304985016584396
Loss at iteration 1020 : 0.012550834566354752
Loss at iteration 1030 : 0.019082389771938324
Loss at iteration 1040 : 0.024087311699986458
Loss at iteration 1050 : 0.01874297298491001
Loss at iteration 1060 : 0.014062581583857536
Loss at iteration 1070 : 0.022166794165968895
Loss at iteration 1080 : 0.011258360929787159
Loss at iteration 1090 : 0.01855171099305153
Loss at iteration 1100 : 0.019886627793312073
Loss at iteration 1110 : 0.010700555518269539
Loss at iteration 1120 : 0.031039902940392494
Loss at iteration 1130 : 0.0209401473402977
Loss at iteration 1140 : 0.018867718055844307
Loss at iteration 1150 : 0.01952323317527771
Loss at iteration 1160 : 0.015295630320906639
Loss at iteration 1170 : 0.024810921400785446
Loss at iteration 1180 : 0.02035897970199585
Loss at iteration 1190 : 0.027496641501784325
Loss at iteration 1200 : 0.01763264276087284
Loss at iteration 1210 : 0.020616911351680756
The SSIM Value is: 0.801975945631663
The PSNR Value is: 19.322181765238444
the epoch is: 151
Loss at iteration 10 : 0.02047271654009819
Loss at iteration 20 : 0.010848276317119598
Loss at iteration 30 : 0.025126200169324875
Loss at iteration 40 : 0.029763901606202126
Loss at iteration 50 : 0.011970454826951027
Loss at iteration 60 : 0.022075694054365158
Loss at iteration 70 : 0.021020706743001938
Loss at iteration 80 : 0.01194828748703003
Loss at iteration 90 : 0.027805127203464508
Loss at iteration 100 : 0.01699620857834816
Loss at iteration 110 : 0.01716117560863495
Loss at iteration 120 : 0.020594164729118347
Loss at iteration 130 : 0.033816978335380554
Loss at iteration 140 : 0.026275338605046272
Loss at iteration 150 : 0.02039683237671852
Loss at iteration 160 : 0.019302017986774445
Loss at iteration 170 : 0.017358344048261642
Loss at iteration 180 : 0.01914047822356224
Loss at iteration 190 : 0.012961313128471375
Loss at iteration 200 : 0.02453422173857689
Loss at iteration 210 : 0.017333311960101128
Loss at iteration 220 : 0.02747238054871559
Loss at iteration 230 : 0.0127028813585639
Loss at iteration 240 : 0.01304200105369091
Loss at iteration 250 : 0.02581377513706684
Loss at iteration 260 : 0.0285114087164402
Loss at iteration 270 : 0.01338385883718729
Loss at iteration 280 : 0.015659118071198463
Loss at iteration 290 : 0.023174593225121498
Loss at iteration 300 : 0.013360116630792618
Loss at iteration 310 : 0.013355445116758347
Loss at iteration 320 : 0.01525981817394495
Loss at iteration 330 : 0.02202780917286873
Loss at iteration 340 : 0.01849636435508728
Loss at iteration 350 : 0.012972760945558548
Loss at iteration 360 : 0.023297760635614395
Loss at iteration 370 : 0.031994812190532684
Loss at iteration 380 : 0.016792722046375275
Loss at iteration 390 : 0.01666155830025673
Loss at iteration 400 : 0.020610354840755463
Loss at iteration 410 : 0.014725539833307266
Loss at iteration 420 : 0.025367707014083862
Loss at iteration 430 : 0.025339551270008087
Loss at iteration 440 : 0.019612792879343033
Loss at iteration 450 : 0.030381720513105392
Loss at iteration 460 : 0.025608696043491364
Loss at iteration 470 : 0.019365966320037842
Loss at iteration 480 : 0.01317867822945118
Loss at iteration 490 : 0.01558990404009819
Loss at iteration 500 : 0.01724846474826336
Loss at iteration 510 : 0.02565658837556839
Loss at iteration 520 : 0.014395762234926224
Loss at iteration 530 : 0.014681320637464523
Loss at iteration 540 : 0.018526803702116013
Loss at iteration 550 : 0.016975969076156616
Loss at iteration 560 : 0.01962314546108246
Loss at iteration 570 : 0.019460055977106094
Loss at iteration 580 : 0.02376827970147133
Loss at iteration 590 : 0.01977268047630787
Loss at iteration 600 : 0.021872717887163162
Loss at iteration 610 : 0.01901961863040924
Loss at iteration 620 : 0.019428975880146027
Loss at iteration 630 : 0.024267612025141716
Loss at iteration 640 : 0.025568045675754547
Loss at iteration 650 : 0.020507926121354103
Loss at iteration 660 : 0.015266502276062965
Loss at iteration 670 : 0.023064225912094116
Loss at iteration 680 : 0.02170243300497532
Loss at iteration 690 : 0.026727784425020218
Loss at iteration 700 : 0.02108880691230297
Loss at iteration 710 : 0.010663973167538643
Loss at iteration 720 : 0.024996411055326462
Loss at iteration 730 : 0.018558550626039505
Loss at iteration 740 : 0.017749018967151642
Loss at iteration 750 : 0.017648635432124138
Loss at iteration 760 : 0.025157924741506577
Loss at iteration 770 : 0.020487062633037567
Loss at iteration 780 : 0.015589741989970207
Loss at iteration 790 : 0.02230268344283104
Loss at iteration 800 : 0.02343197725713253
Loss at iteration 810 : 0.048031602054834366
Loss at iteration 820 : 0.01723775640130043
Loss at iteration 830 : 0.022407997399568558
Loss at iteration 840 : 0.016361771151423454
Loss at iteration 850 : 0.019278336316347122
Loss at iteration 860 : 0.029635291546583176
Loss at iteration 870 : 0.02501731552183628
Loss at iteration 880 : 0.026164446026086807
Loss at iteration 890 : 0.024907829239964485
Loss at iteration 900 : 0.01903439313173294
Loss at iteration 910 : 0.029460139572620392
Loss at iteration 920 : 0.033603735268116
Loss at iteration 930 : 0.02257673442363739
Loss at iteration 940 : 0.018564632162451744
Loss at iteration 950 : 0.025691639631986618
Loss at iteration 960 : 0.023102762177586555
Loss at iteration 970 : 0.01923317462205887
Loss at iteration 980 : 0.019940169528126717
Loss at iteration 990 : 0.01290396973490715
Loss at iteration 1000 : 0.012336298823356628
Loss at iteration 1010 : 0.020247530192136765
Loss at iteration 1020 : 0.027946997433900833
Loss at iteration 1030 : 0.017474936321377754
Loss at iteration 1040 : 0.0164315328001976
Loss at iteration 1050 : 0.02312813326716423
Loss at iteration 1060 : 0.012210050597786903
Loss at iteration 1070 : 0.021017085760831833
Loss at iteration 1080 : 0.018547682091593742
Loss at iteration 1090 : 0.013708701357245445
Loss at iteration 1100 : 0.016334427520632744
Loss at iteration 1110 : 0.016478130593895912
Loss at iteration 1120 : 0.016863545402884483
Loss at iteration 1130 : 0.021746821701526642
Loss at iteration 1140 : 0.018983816727995872
Loss at iteration 1150 : 0.013599268160760403
Loss at iteration 1160 : 0.023455873131752014
Loss at iteration 1170 : 0.02013438194990158
Loss at iteration 1180 : 0.02694416232407093
Loss at iteration 1190 : 0.015017775818705559
Loss at iteration 1200 : 0.029277367517352104
Loss at iteration 1210 : 0.020691007375717163
The SSIM Value is: 0.8003007650375367
The PSNR Value is: 18.454162216186525
the epoch is: 152
Loss at iteration 10 : 0.026501215994358063
Loss at iteration 20 : 0.014806044287979603
Loss at iteration 30 : 0.026688558980822563
Loss at iteration 40 : 0.011529481038451195
Loss at iteration 50 : 0.01367650181055069
Loss at iteration 60 : 0.014071306213736534
Loss at iteration 70 : 0.025110546499490738
Loss at iteration 80 : 0.014517314732074738
Loss at iteration 90 : 0.03269897401332855
Loss at iteration 100 : 0.020154466852545738
Loss at iteration 110 : 0.0167868509888649
Loss at iteration 120 : 0.02077118307352066
Loss at iteration 130 : 0.016392504796385765
Loss at iteration 140 : 0.03500169515609741
Loss at iteration 150 : 0.01672320067882538
Loss at iteration 160 : 0.01636669784784317
Loss at iteration 170 : 0.012565307319164276
Loss at iteration 180 : 0.023327816277742386
Loss at iteration 190 : 0.015089011751115322
Loss at iteration 200 : 0.018552688881754875
Loss at iteration 210 : 0.022467654198408127
Loss at iteration 220 : 0.016488369554281235
Loss at iteration 230 : 0.032703690230846405
Loss at iteration 240 : 0.02193736843764782
Loss at iteration 250 : 0.013192513957619667
Loss at iteration 260 : 0.019947143271565437
Loss at iteration 270 : 0.020178986713290215
Loss at iteration 280 : 0.015215450897812843
Loss at iteration 290 : 0.01055312342941761
Loss at iteration 300 : 0.01590043678879738
Loss at iteration 310 : 0.01932516135275364
Loss at iteration 320 : 0.020678918808698654
Loss at iteration 330 : 0.016283594071865082
Loss at iteration 340 : 0.014525862410664558
Loss at iteration 350 : 0.016686424612998962
Loss at iteration 360 : 0.016865843906998634
Loss at iteration 370 : 0.017521873116493225
Loss at iteration 380 : 0.012337028980255127
Loss at iteration 390 : 0.02406403049826622
Loss at iteration 400 : 0.027757372707128525
Loss at iteration 410 : 0.029114505276083946
Loss at iteration 420 : 0.02230779640376568
Loss at iteration 430 : 0.016134263947606087
Loss at iteration 440 : 0.01862034946680069
Loss at iteration 450 : 0.014554889872670174
Loss at iteration 460 : 0.011700371280312538
Loss at iteration 470 : 0.01569708250463009
Loss at iteration 480 : 0.018131863325834274
Loss at iteration 490 : 0.01752939447760582
Loss at iteration 500 : 0.0274064838886261
Loss at iteration 510 : 0.014581450261175632
Loss at iteration 520 : 0.026091914623975754
Loss at iteration 530 : 0.018030421808362007
Loss at iteration 540 : 0.03047053888440132
Loss at iteration 550 : 0.011445529758930206
Loss at iteration 560 : 0.022467292845249176
Loss at iteration 570 : 0.019759206101298332
Loss at iteration 580 : 0.028243795037269592
Loss at iteration 590 : 0.023791326209902763
Loss at iteration 600 : 0.0250904131680727
Loss at iteration 610 : 0.017952311784029007
Loss at iteration 620 : 0.03184117004275322
Loss at iteration 630 : 0.021581411361694336
Loss at iteration 640 : 0.021211573854088783
Loss at iteration 650 : 0.02278415486216545
Loss at iteration 660 : 0.01847204938530922
Loss at iteration 670 : 0.025322798639535904
Loss at iteration 680 : 0.01350463554263115
Loss at iteration 690 : 0.01673457957804203
Loss at iteration 700 : 0.026753075420856476
Loss at iteration 710 : 0.02082081511616707
Loss at iteration 720 : 0.014480791985988617
Loss at iteration 730 : 0.015888124704360962
Loss at iteration 740 : 0.02966521680355072
Loss at iteration 750 : 0.010891683399677277
Loss at iteration 760 : 0.01736433431506157
Loss at iteration 770 : 0.03199566900730133
Loss at iteration 780 : 0.028270617127418518
Loss at iteration 790 : 0.011930620297789574
Loss at iteration 800 : 0.02537861093878746
Loss at iteration 810 : 0.022231265902519226
Loss at iteration 820 : 0.016524385660886765
Loss at iteration 830 : 0.0286007821559906
Loss at iteration 840 : 0.022349610924720764
Loss at iteration 850 : 0.016936318948864937
Loss at iteration 860 : 0.016316205263137817
Loss at iteration 870 : 0.023075705394148827
Loss at iteration 880 : 0.02213350310921669
Loss at iteration 890 : 0.02343146689236164
Loss at iteration 900 : 0.024234307929873466
Loss at iteration 910 : 0.021353144198656082
Loss at iteration 920 : 0.019253738224506378
Loss at iteration 930 : 0.01873466745018959
Loss at iteration 940 : 0.017229553312063217
Loss at iteration 950 : 0.015116110444068909
Loss at iteration 960 : 0.008949282579123974
Loss at iteration 970 : 0.017034780234098434
Loss at iteration 980 : 0.03419815003871918
Loss at iteration 990 : 0.018630318343639374
Loss at iteration 1000 : 0.021260298788547516
Loss at iteration 1010 : 0.016714587807655334
Loss at iteration 1020 : 0.02550084888935089
Loss at iteration 1030 : 0.021067513152956963
Loss at iteration 1040 : 0.029240939766168594
Loss at iteration 1050 : 0.029582276940345764
Loss at iteration 1060 : 0.014549247920513153
Loss at iteration 1070 : 0.03980419412255287
Loss at iteration 1080 : 0.010954279452562332
Loss at iteration 1090 : 0.01287226565182209
Loss at iteration 1100 : 0.015109702944755554
Loss at iteration 1110 : 0.009814904071390629
Loss at iteration 1120 : 0.012727349065244198
Loss at iteration 1130 : 0.025036372244358063
Loss at iteration 1140 : 0.014718933030962944
Loss at iteration 1150 : 0.03583584725856781
Loss at iteration 1160 : 0.02545813098549843
Loss at iteration 1170 : 0.015531201846897602
Loss at iteration 1180 : 0.019789833575487137
Loss at iteration 1190 : 0.025393612682819366
Loss at iteration 1200 : 0.03338358923792839
Loss at iteration 1210 : 0.019284451380372047
The SSIM Value is: 0.7915348092714946
The PSNR Value is: 18.98023687998454
the epoch is: 153
Loss at iteration 10 : 0.015570470131933689
Loss at iteration 20 : 0.018555443733930588
Loss at iteration 30 : 0.009191252291202545
Loss at iteration 40 : 0.020228873938322067
Loss at iteration 50 : 0.011949367821216583
Loss at iteration 60 : 0.023370221257209778
Loss at iteration 70 : 0.017594534903764725
Loss at iteration 80 : 0.014540576376020908
Loss at iteration 90 : 0.020712893456220627
Loss at iteration 100 : 0.015566680580377579
Loss at iteration 110 : 0.024229340255260468
Loss at iteration 120 : 0.01628148928284645
Loss at iteration 130 : 0.03267669677734375
Loss at iteration 140 : 0.016952194273471832
Loss at iteration 150 : 0.02379434183239937
Loss at iteration 160 : 0.023956704884767532
Loss at iteration 170 : 0.010706629604101181
Loss at iteration 180 : 0.021800700575113297
Loss at iteration 190 : 0.0165470689535141
Loss at iteration 200 : 0.019441884011030197
Loss at iteration 210 : 0.01719796285033226
Loss at iteration 220 : 0.013394154608249664
Loss at iteration 230 : 0.03911769390106201
Loss at iteration 240 : 0.016334131360054016
Loss at iteration 250 : 0.01750982366502285
Loss at iteration 260 : 0.02281564101576805
Loss at iteration 270 : 0.019807908684015274
Loss at iteration 280 : 0.023475492373108864
Loss at iteration 290 : 0.02084851823747158
Loss at iteration 300 : 0.02507612109184265
Loss at iteration 310 : 0.020248303189873695
Loss at iteration 320 : 0.020461222156882286
Loss at iteration 330 : 0.016507165506482124
Loss at iteration 340 : 0.026680152863264084
Loss at iteration 350 : 0.023347118869423866
Loss at iteration 360 : 0.025420743972063065
Loss at iteration 370 : 0.025438208132982254
Loss at iteration 380 : 0.011056987568736076
Loss at iteration 390 : 0.037966400384902954
Loss at iteration 400 : 0.016746271401643753
Loss at iteration 410 : 0.027481025084853172
Loss at iteration 420 : 0.024646824225783348
Loss at iteration 430 : 0.01150377094745636
Loss at iteration 440 : 0.02258160524070263
Loss at iteration 450 : 0.012174015864729881
Loss at iteration 460 : 0.03230025991797447
Loss at iteration 470 : 0.017812136560678482
Loss at iteration 480 : 0.021482665091753006
Loss at iteration 490 : 0.0338670015335083
Loss at iteration 500 : 0.013994112610816956
Loss at iteration 510 : 0.019877025857567787
Loss at iteration 520 : 0.025357455015182495
Loss at iteration 530 : 0.019560515880584717
Loss at iteration 540 : 0.01470692828297615
Loss at iteration 550 : 0.015156366862356663
Loss at iteration 560 : 0.015088329091668129
Loss at iteration 570 : 0.02856660634279251
Loss at iteration 580 : 0.02094287797808647
Loss at iteration 590 : 0.013168040663003922
Loss at iteration 600 : 0.022207368165254593
Loss at iteration 610 : 0.014554303139448166
Loss at iteration 620 : 0.021921752020716667
Loss at iteration 630 : 0.029346559196710587
Loss at iteration 640 : 0.024394281208515167
Loss at iteration 650 : 0.014562328346073627
Loss at iteration 660 : 0.018402479588985443
Loss at iteration 670 : 0.01827900856733322
Loss at iteration 680 : 0.013354718685150146
Loss at iteration 690 : 0.016596881672739983
Loss at iteration 700 : 0.013643870130181313
Loss at iteration 710 : 0.020353013649582863
Loss at iteration 720 : 0.021418888121843338
Loss at iteration 730 : 0.017798691987991333
Loss at iteration 740 : 0.018806207925081253
Loss at iteration 750 : 0.015109594911336899
Loss at iteration 760 : 0.013024999760091305
Loss at iteration 770 : 0.01968255266547203
Loss at iteration 780 : 0.01407370250672102
Loss at iteration 790 : 0.016954652965068817
Loss at iteration 800 : 0.026157869026064873
Loss at iteration 810 : 0.017948994413018227
Loss at iteration 820 : 0.021349556744098663
Loss at iteration 830 : 0.022096192464232445
Loss at iteration 840 : 0.013809903524816036
Loss at iteration 850 : 0.023864785209298134
Loss at iteration 860 : 0.016394086182117462
Loss at iteration 870 : 0.022686943411827087
Loss at iteration 880 : 0.022067394107580185
Loss at iteration 890 : 0.01238817349076271
Loss at iteration 900 : 0.01640753261744976
Loss at iteration 910 : 0.012341744266450405
Loss at iteration 920 : 0.018916968256235123
Loss at iteration 930 : 0.019433073699474335
Loss at iteration 940 : 0.016856230795383453
Loss at iteration 950 : 0.01568526402115822
Loss at iteration 960 : 0.020519724115729332
Loss at iteration 970 : 0.02160375565290451
Loss at iteration 980 : 0.017554905265569687
Loss at iteration 990 : 0.01834290288388729
Loss at iteration 1000 : 0.017903272062540054
Loss at iteration 1010 : 0.01998167671263218
Loss at iteration 1020 : 0.022487865760922432
Loss at iteration 1030 : 0.01693780906498432
Loss at iteration 1040 : 0.036953818053007126
Loss at iteration 1050 : 0.023032382130622864
Loss at iteration 1060 : 0.01930120959877968
Loss at iteration 1070 : 0.032275378704071045
Loss at iteration 1080 : 0.016538213938474655
Loss at iteration 1090 : 0.02376476675271988
Loss at iteration 1100 : 0.021365826949477196
Loss at iteration 1110 : 0.016584042459726334
Loss at iteration 1120 : 0.014867689460515976
Loss at iteration 1130 : 0.022492604330182076
Loss at iteration 1140 : 0.015279587358236313
Loss at iteration 1150 : 0.018353590741753578
Loss at iteration 1160 : 0.02091526798903942
Loss at iteration 1170 : 0.01324109360575676
Loss at iteration 1180 : 0.04692833125591278
Loss at iteration 1190 : 0.023701779544353485
Loss at iteration 1200 : 0.02191789820790291
Loss at iteration 1210 : 0.016261614859104156
The SSIM Value is: 0.8027634739875793
The PSNR Value is: 19.430112965901692
the epoch is: 154
Loss at iteration 10 : 0.013089591637253761
Loss at iteration 20 : 0.016425538808107376
Loss at iteration 30 : 0.03210555389523506
Loss at iteration 40 : 0.02939198538661003
Loss at iteration 50 : 0.023775935173034668
Loss at iteration 60 : 0.02779700979590416
Loss at iteration 70 : 0.01580129563808441
Loss at iteration 80 : 0.017299138009548187
Loss at iteration 90 : 0.015868887305259705
Loss at iteration 100 : 0.020990872755646706
Loss at iteration 110 : 0.014608219265937805
Loss at iteration 120 : 0.019596176221966743
Loss at iteration 130 : 0.01781180128455162
Loss at iteration 140 : 0.011870542541146278
Loss at iteration 150 : 0.01643337681889534
Loss at iteration 160 : 0.0375266931951046
Loss at iteration 170 : 0.024714462459087372
Loss at iteration 180 : 0.01959855854511261
Loss at iteration 190 : 0.021496862173080444
Loss at iteration 200 : 0.014170365408062935
Loss at iteration 210 : 0.017832688987255096
Loss at iteration 220 : 0.017182573676109314
Loss at iteration 230 : 0.015384741127490997
Loss at iteration 240 : 0.0211023036390543
Loss at iteration 250 : 0.015942471101880074
Loss at iteration 260 : 0.028389759361743927
Loss at iteration 270 : 0.02686638943850994
Loss at iteration 280 : 0.017033651471138
Loss at iteration 290 : 0.019146602600812912
Loss at iteration 300 : 0.02179577201604843
Loss at iteration 310 : 0.01568094827234745
Loss at iteration 320 : 0.02193877287209034
Loss at iteration 330 : 0.01730388030409813
Loss at iteration 340 : 0.012208594009280205
Loss at iteration 350 : 0.015012133866548538
Loss at iteration 360 : 0.019947201013565063
Loss at iteration 370 : 0.02525441348552704
Loss at iteration 380 : 0.023679599165916443
Loss at iteration 390 : 0.018162019550800323
Loss at iteration 400 : 0.020737987011671066
Loss at iteration 410 : 0.013843471184372902
Loss at iteration 420 : 0.013293464668095112
Loss at iteration 430 : 0.010458770208060741
Loss at iteration 440 : 0.0163823701441288
Loss at iteration 450 : 0.016408631578087807
Loss at iteration 460 : 0.015415002591907978
Loss at iteration 470 : 0.015724774450063705
Loss at iteration 480 : 0.011970577761530876
Loss at iteration 490 : 0.021026218309998512
Loss at iteration 500 : 0.042894259095191956
Loss at iteration 510 : 0.023205459117889404
Loss at iteration 520 : 0.02305316925048828
Loss at iteration 530 : 0.010554809123277664
Loss at iteration 540 : 0.018047692254185677
Loss at iteration 550 : 0.025539111346006393
Loss at iteration 560 : 0.02367432788014412
Loss at iteration 570 : 0.015991415828466415
Loss at iteration 580 : 0.022576989606022835
Loss at iteration 590 : 0.0216208603233099
Loss at iteration 600 : 0.02361294999718666
Loss at iteration 610 : 0.01971101388335228
Loss at iteration 620 : 0.02518358640372753
Loss at iteration 630 : 0.025512613356113434
Loss at iteration 640 : 0.015231605619192123
Loss at iteration 650 : 0.012058034539222717
Loss at iteration 660 : 0.022000016644597054
Loss at iteration 670 : 0.018399497494101524
Loss at iteration 680 : 0.018803564831614494
Loss at iteration 690 : 0.019079286605119705
Loss at iteration 700 : 0.01990114152431488
Loss at iteration 710 : 0.022210244089365005
Loss at iteration 720 : 0.018602311611175537
Loss at iteration 730 : 0.027687042951583862
Loss at iteration 740 : 0.016606558114290237
Loss at iteration 750 : 0.02091149426996708
Loss at iteration 760 : 0.021400785073637962
Loss at iteration 770 : 0.023196697235107422
Loss at iteration 780 : 0.013088364154100418
Loss at iteration 790 : 0.018042009323835373
Loss at iteration 800 : 0.01598501019179821
Loss at iteration 810 : 0.015624390915036201
Loss at iteration 820 : 0.028073959052562714
Loss at iteration 830 : 0.03550320118665695
Loss at iteration 840 : 0.018708987161517143
Loss at iteration 850 : 0.016615979373455048
Loss at iteration 860 : 0.022432010620832443
Loss at iteration 870 : 0.017353888601064682
Loss at iteration 880 : 0.01440234575420618
Loss at iteration 890 : 0.013620997779071331
Loss at iteration 900 : 0.014564231038093567
Loss at iteration 910 : 0.016090748831629753
Loss at iteration 920 : 0.03862101584672928
Loss at iteration 930 : 0.019799698144197464
Loss at iteration 940 : 0.011832427233457565
Loss at iteration 950 : 0.019916296005249023
Loss at iteration 960 : 0.024117980152368546
Loss at iteration 970 : 0.02693507820367813
Loss at iteration 980 : 0.015050257556140423
Loss at iteration 990 : 0.015146806836128235
Loss at iteration 1000 : 0.025121979415416718
Loss at iteration 1010 : 0.023319214582443237
Loss at iteration 1020 : 0.031906455755233765
Loss at iteration 1030 : 0.026369372382760048
Loss at iteration 1040 : 0.013881981372833252
Loss at iteration 1050 : 0.016429606825113297
Loss at iteration 1060 : 0.021007198840379715
Loss at iteration 1070 : 0.022198110818862915
Loss at iteration 1080 : 0.0252554789185524
Loss at iteration 1090 : 0.023294633254408836
Loss at iteration 1100 : 0.013206693343818188
Loss at iteration 1110 : 0.013554570265114307
Loss at iteration 1120 : 0.028555266559123993
Loss at iteration 1130 : 0.020538240671157837
Loss at iteration 1140 : 0.011051956564188004
Loss at iteration 1150 : 0.018914328888058662
Loss at iteration 1160 : 0.019685333594679832
Loss at iteration 1170 : 0.022550079971551895
Loss at iteration 1180 : 0.018367039039731026
Loss at iteration 1190 : 0.02571314573287964
Loss at iteration 1200 : 0.026868214830756187
Loss at iteration 1210 : 0.022822223603725433
The SSIM Value is: 0.7984148383140564
The PSNR Value is: 19.74369036356608
the epoch is: 155
Loss at iteration 10 : 0.0238309595733881
Loss at iteration 20 : 0.024355623871088028
Loss at iteration 30 : 0.018549714237451553
Loss at iteration 40 : 0.0330437496304512
Loss at iteration 50 : 0.01644698716700077
Loss at iteration 60 : 0.017808936536312103
Loss at iteration 70 : 0.017042044550180435
Loss at iteration 80 : 0.02238614298403263
Loss at iteration 90 : 0.022124435752630234
Loss at iteration 100 : 0.020045727491378784
Loss at iteration 110 : 0.017606453970074654
Loss at iteration 120 : 0.017521580681204796
Loss at iteration 130 : 0.01841501146554947
Loss at iteration 140 : 0.018788032233715057
Loss at iteration 150 : 0.013677515089511871
Loss at iteration 160 : 0.020686795935034752
Loss at iteration 170 : 0.017515596002340317
Loss at iteration 180 : 0.013540567830204964
Loss at iteration 190 : 0.03471583500504494
Loss at iteration 200 : 0.01803215593099594
Loss at iteration 210 : 0.016987919807434082
Loss at iteration 220 : 0.013077959418296814
Loss at iteration 230 : 0.014200186356902122
Loss at iteration 240 : 0.021412447094917297
Loss at iteration 250 : 0.010225925594568253
Loss at iteration 260 : 0.02785351686179638
Loss at iteration 270 : 0.009857557713985443
Loss at iteration 280 : 0.02249307744204998
Loss at iteration 290 : 0.014317600056529045
Loss at iteration 300 : 0.030528966337442398
Loss at iteration 310 : 0.021596839651465416
Loss at iteration 320 : 0.01192755438387394
Loss at iteration 330 : 0.022270631045103073
Loss at iteration 340 : 0.025963962078094482
Loss at iteration 350 : 0.016709133982658386
Loss at iteration 360 : 0.02145519107580185
Loss at iteration 370 : 0.02649175375699997
Loss at iteration 380 : 0.027637828141450882
Loss at iteration 390 : 0.026479776948690414
Loss at iteration 400 : 0.018648557364940643
Loss at iteration 410 : 0.020764227956533432
Loss at iteration 420 : 0.0302120391279459
Loss at iteration 430 : 0.01740838587284088
Loss at iteration 440 : 0.014866640791296959
Loss at iteration 450 : 0.02228032425045967
Loss at iteration 460 : 0.028462864458560944
Loss at iteration 470 : 0.015411041676998138
Loss at iteration 480 : 0.028155218809843063
Loss at iteration 490 : 0.015713071450591087
Loss at iteration 500 : 0.025072911754250526
Loss at iteration 510 : 0.0187457837164402
Loss at iteration 520 : 0.024044591933488846
Loss at iteration 530 : 0.019693221896886826
Loss at iteration 540 : 0.018897537142038345
Loss at iteration 550 : 0.03436865285038948
Loss at iteration 560 : 0.013930106535553932
Loss at iteration 570 : 0.03175254166126251
Loss at iteration 580 : 0.014628199860453606
Loss at iteration 590 : 0.015021337196230888
Loss at iteration 600 : 0.017351198941469193
Loss at iteration 610 : 0.023976817727088928
Loss at iteration 620 : 0.023028740659356117
Loss at iteration 630 : 0.02042216807603836
Loss at iteration 640 : 0.018223699182271957
Loss at iteration 650 : 0.02362384833395481
Loss at iteration 660 : 0.018897956237196922
Loss at iteration 670 : 0.01251034252345562
Loss at iteration 680 : 0.02548561990261078
Loss at iteration 690 : 0.021557770669460297
Loss at iteration 700 : 0.019494997337460518
Loss at iteration 710 : 0.012564409524202347
Loss at iteration 720 : 0.035360753536224365
Loss at iteration 730 : 0.014980820007622242
Loss at iteration 740 : 0.01536589302122593
Loss at iteration 750 : 0.016809264197945595
Loss at iteration 760 : 0.04283912107348442
Loss at iteration 770 : 0.036572691053152084
Loss at iteration 780 : 0.025999044999480247
Loss at iteration 790 : 0.028648287057876587
Loss at iteration 800 : 0.014660808257758617
Loss at iteration 810 : 0.019645536318421364
Loss at iteration 820 : 0.03416798263788223
Loss at iteration 830 : 0.014546508900821209
Loss at iteration 840 : 0.017142992466688156
Loss at iteration 850 : 0.018357008695602417
Loss at iteration 860 : 0.016288340091705322
Loss at iteration 870 : 0.009771378710865974
Loss at iteration 880 : 0.020451534539461136
Loss at iteration 890 : 0.01768484339118004
Loss at iteration 900 : 0.010672228410840034
Loss at iteration 910 : 0.024872757494449615
Loss at iteration 920 : 0.013491938821971416
Loss at iteration 930 : 0.01953195035457611
Loss at iteration 940 : 0.016796734184026718
Loss at iteration 950 : 0.026152394711971283
Loss at iteration 960 : 0.02114950492978096
Loss at iteration 970 : 0.013746129348874092
Loss at iteration 980 : 0.018154609948396683
Loss at iteration 990 : 0.02408222109079361
Loss at iteration 1000 : 0.013626780360937119
Loss at iteration 1010 : 0.027839895337820053
Loss at iteration 1020 : 0.013313041999936104
Loss at iteration 1030 : 0.027162015438079834
Loss at iteration 1040 : 0.008998127654194832
Loss at iteration 1050 : 0.019091658294200897
Loss at iteration 1060 : 0.028365608304739
Loss at iteration 1070 : 0.00880992878228426
Loss at iteration 1080 : 0.01772334985435009
Loss at iteration 1090 : 0.02109551802277565
Loss at iteration 1100 : 0.018750298768281937
Loss at iteration 1110 : 0.02504735253751278
Loss at iteration 1120 : 0.018120693042874336
Loss at iteration 1130 : 0.01661093346774578
Loss at iteration 1140 : 0.018962394446134567
Loss at iteration 1150 : 0.01964043825864792
Loss at iteration 1160 : 0.019920002669095993
Loss at iteration 1170 : 0.04160495847463608
Loss at iteration 1180 : 0.017383459955453873
Loss at iteration 1190 : 0.03487778082489967
Loss at iteration 1200 : 0.010772963985800743
Loss at iteration 1210 : 0.01955588161945343
The SSIM Value is: 0.7985947012901307
The PSNR Value is: 19.442841021219888
the epoch is: 156
Loss at iteration 10 : 0.01227506808936596
Loss at iteration 20 : 0.017821554094552994
Loss at iteration 30 : 0.019908150658011436
Loss at iteration 40 : 0.015575573779642582
Loss at iteration 50 : 0.019770154729485512
Loss at iteration 60 : 0.01623564586043358
Loss at iteration 70 : 0.01824694313108921
Loss at iteration 80 : 0.022623371332883835
Loss at iteration 90 : 0.01103474386036396
Loss at iteration 100 : 0.018139149993658066
Loss at iteration 110 : 0.01719876565039158
Loss at iteration 120 : 0.0205858014523983
Loss at iteration 130 : 0.02088444121181965
Loss at iteration 140 : 0.02843668684363365
Loss at iteration 150 : 0.019090035930275917
Loss at iteration 160 : 0.023022454231977463
Loss at iteration 170 : 0.021433204412460327
Loss at iteration 180 : 0.01960430108010769
Loss at iteration 190 : 0.02177569642663002
Loss at iteration 200 : 0.0204680897295475
Loss at iteration 210 : 0.02281111851334572
Loss at iteration 220 : 0.03627917170524597
Loss at iteration 230 : 0.01632353663444519
Loss at iteration 240 : 0.01774900034070015
Loss at iteration 250 : 0.012568213045597076
Loss at iteration 260 : 0.01936241239309311
Loss at iteration 270 : 0.02062465250492096
Loss at iteration 280 : 0.023569749668240547
Loss at iteration 290 : 0.01899692416191101
Loss at iteration 300 : 0.012938553467392921
Loss at iteration 310 : 0.025061756372451782
Loss at iteration 320 : 0.01368627604097128
Loss at iteration 330 : 0.02505565993487835
Loss at iteration 340 : 0.027923306450247765
Loss at iteration 350 : 0.016607269644737244
Loss at iteration 360 : 0.012892667204141617
Loss at iteration 370 : 0.017418816685676575
Loss at iteration 380 : 0.01751810871064663
Loss at iteration 390 : 0.018607528880238533
Loss at iteration 400 : 0.019872067496180534
Loss at iteration 410 : 0.034033454954624176
Loss at iteration 420 : 0.016997160390019417
Loss at iteration 430 : 0.012807418592274189
Loss at iteration 440 : 0.017145847901701927
Loss at iteration 450 : 0.022058693692088127
Loss at iteration 460 : 0.02604517713189125
Loss at iteration 470 : 0.02295040711760521
Loss at iteration 480 : 0.011527186259627342
Loss at iteration 490 : 0.017082609236240387
Loss at iteration 500 : 0.021456090733408928
Loss at iteration 510 : 0.0218731090426445
Loss at iteration 520 : 0.02311250939965248
Loss at iteration 530 : 0.02432122267782688
Loss at iteration 540 : 0.019063614308834076
Loss at iteration 550 : 0.015954116359353065
Loss at iteration 560 : 0.02081218920648098
Loss at iteration 570 : 0.02680312469601631
Loss at iteration 580 : 0.02313273958861828
Loss at iteration 590 : 0.021009206771850586
Loss at iteration 600 : 0.012978138402104378
Loss at iteration 610 : 0.034388042986392975
Loss at iteration 620 : 0.020745784044265747
Loss at iteration 630 : 0.013384034857153893
Loss at iteration 640 : 0.015026984736323357
Loss at iteration 650 : 0.026219408959150314
Loss at iteration 660 : 0.011597597040235996
Loss at iteration 670 : 0.023588398471474648
Loss at iteration 680 : 0.025979895144701004
Loss at iteration 690 : 0.017817093059420586
Loss at iteration 700 : 0.0200844407081604
Loss at iteration 710 : 0.012766972184181213
Loss at iteration 720 : 0.010503903031349182
Loss at iteration 730 : 0.014982739463448524
Loss at iteration 740 : 0.02030530385673046
Loss at iteration 750 : 0.029369894415140152
Loss at iteration 760 : 0.009447255171835423
Loss at iteration 770 : 0.018659191206097603
Loss at iteration 780 : 0.022440368309617043
Loss at iteration 790 : 0.01975114643573761
Loss at iteration 800 : 0.03313310816884041
Loss at iteration 810 : 0.01577829010784626
Loss at iteration 820 : 0.035487107932567596
Loss at iteration 830 : 0.017147419974207878
Loss at iteration 840 : 0.024423129856586456
Loss at iteration 850 : 0.015324139967560768
Loss at iteration 860 : 0.025560161098837852
Loss at iteration 870 : 0.024770153686404228
Loss at iteration 880 : 0.020058657974004745
Loss at iteration 890 : 0.02903747744858265
Loss at iteration 900 : 0.021519530564546585
Loss at iteration 910 : 0.013064910657703876
Loss at iteration 920 : 0.025424204766750336
Loss at iteration 930 : 0.019146421924233437
Loss at iteration 940 : 0.018041931092739105
Loss at iteration 950 : 0.018305307254195213
Loss at iteration 960 : 0.01601284183561802
Loss at iteration 970 : 0.015339933335781097
Loss at iteration 980 : 0.015848349779844284
Loss at iteration 990 : 0.016372263431549072
Loss at iteration 1000 : 0.018743786960840225
Loss at iteration 1010 : 0.023814164102077484
Loss at iteration 1020 : 0.013246669434010983
Loss at iteration 1030 : 0.019729245454072952
Loss at iteration 1040 : 0.02110116370022297
Loss at iteration 1050 : 0.018589194864034653
Loss at iteration 1060 : 0.013977441936731339
Loss at iteration 1070 : 0.01720990426838398
Loss at iteration 1080 : 0.010553226806223392
Loss at iteration 1090 : 0.01773390732705593
Loss at iteration 1100 : 0.015617653727531433
Loss at iteration 1110 : 0.020859604701399803
Loss at iteration 1120 : 0.03160583972930908
Loss at iteration 1130 : 0.017840003594756126
Loss at iteration 1140 : 0.019349880516529083
Loss at iteration 1150 : 0.026131993159651756
Loss at iteration 1160 : 0.01682215742766857
Loss at iteration 1170 : 0.03629766404628754
Loss at iteration 1180 : 0.022330399602651596
Loss at iteration 1190 : 0.017268948256969452
Loss at iteration 1200 : 0.016750650480389595
Loss at iteration 1210 : 0.029137268662452698
The SSIM Value is: 0.7957225839296976
The PSNR Value is: 18.335769335428875
the epoch is: 157
Loss at iteration 10 : 0.019313858821988106
Loss at iteration 20 : 0.019579332321882248
Loss at iteration 30 : 0.018708351999521255
Loss at iteration 40 : 0.01934119127690792
Loss at iteration 50 : 0.011499802581965923
Loss at iteration 60 : 0.017111970111727715
Loss at iteration 70 : 0.015589265152812004
Loss at iteration 80 : 0.012620840221643448
Loss at iteration 90 : 0.015481609851121902
Loss at iteration 100 : 0.029830925166606903
Loss at iteration 110 : 0.019493937492370605
Loss at iteration 120 : 0.0208012405782938
Loss at iteration 130 : 0.027772163972258568
Loss at iteration 140 : 0.022933170199394226
Loss at iteration 150 : 0.0246812105178833
Loss at iteration 160 : 0.025604788213968277
Loss at iteration 170 : 0.016989361494779587
Loss at iteration 180 : 0.014932279475033283
Loss at iteration 190 : 0.014941798523068428
Loss at iteration 200 : 0.024883463978767395
Loss at iteration 210 : 0.017468564212322235
Loss at iteration 220 : 0.02691776677966118
Loss at iteration 230 : 0.0131535604596138
Loss at iteration 240 : 0.024082552641630173
Loss at iteration 250 : 0.017053665593266487
Loss at iteration 260 : 0.03256017342209816
Loss at iteration 270 : 0.018661994487047195
Loss at iteration 280 : 0.019656840711832047
Loss at iteration 290 : 0.022311430424451828
Loss at iteration 300 : 0.02047358825802803
Loss at iteration 310 : 0.02075660042464733
Loss at iteration 320 : 0.013303037732839584
Loss at iteration 330 : 0.02884739637374878
Loss at iteration 340 : 0.018223784863948822
Loss at iteration 350 : 0.0330301970243454
Loss at iteration 360 : 0.01867363229393959
Loss at iteration 370 : 0.014600328169763088
Loss at iteration 380 : 0.03011508285999298
Loss at iteration 390 : 0.022033799439668655
Loss at iteration 400 : 0.019809409976005554
Loss at iteration 410 : 0.017384573817253113
Loss at iteration 420 : 0.015455597080290318
Loss at iteration 430 : 0.01633549854159355
Loss at iteration 440 : 0.01608523353934288
Loss at iteration 450 : 0.02033413201570511
Loss at iteration 460 : 0.02658805251121521
Loss at iteration 470 : 0.012851208448410034
Loss at iteration 480 : 0.01625017821788788
Loss at iteration 490 : 0.016996392980217934
Loss at iteration 500 : 0.012403639033436775
Loss at iteration 510 : 0.020942270755767822
Loss at iteration 520 : 0.02230987325310707
Loss at iteration 530 : 0.01019155140966177
Loss at iteration 540 : 0.011209364980459213
Loss at iteration 550 : 0.0209491103887558
Loss at iteration 560 : 0.017113275825977325
Loss at iteration 570 : 0.014371898025274277
Loss at iteration 580 : 0.023515217006206512
Loss at iteration 590 : 0.01293795183300972
Loss at iteration 600 : 0.01529790461063385
Loss at iteration 610 : 0.013799464330077171
Loss at iteration 620 : 0.008686377666890621
Loss at iteration 630 : 0.02591438591480255
Loss at iteration 640 : 0.016205662861466408
Loss at iteration 650 : 0.024106591939926147
Loss at iteration 660 : 0.02995465323328972
Loss at iteration 670 : 0.017620159313082695
Loss at iteration 680 : 0.03513064980506897
Loss at iteration 690 : 0.022348878905177116
Loss at iteration 700 : 0.011850262060761452
Loss at iteration 710 : 0.022390875965356827
Loss at iteration 720 : 0.03300783038139343
Loss at iteration 730 : 0.01961793750524521
Loss at iteration 740 : 0.014440163038671017
Loss at iteration 750 : 0.014710030518472195
Loss at iteration 760 : 0.018379375338554382
Loss at iteration 770 : 0.02876984514296055
Loss at iteration 780 : 0.013590333983302116
Loss at iteration 790 : 0.015809165313839912
Loss at iteration 800 : 0.019877612590789795
Loss at iteration 810 : 0.016758233308792114
Loss at iteration 820 : 0.017001468688249588
Loss at iteration 830 : 0.02992279827594757
Loss at iteration 840 : 0.02113666944205761
Loss at iteration 850 : 0.026332546025514603
Loss at iteration 860 : 0.02424485608935356
Loss at iteration 870 : 0.03103525936603546
Loss at iteration 880 : 0.020543474704027176
Loss at iteration 890 : 0.018105439841747284
Loss at iteration 900 : 0.03537524864077568
Loss at iteration 910 : 0.023499269038438797
Loss at iteration 920 : 0.022678807377815247
Loss at iteration 930 : 0.011982910335063934
Loss at iteration 940 : 0.029176389798521996
Loss at iteration 950 : 0.021206028759479523
Loss at iteration 960 : 0.024291448295116425
Loss at iteration 970 : 0.01928580552339554
Loss at iteration 980 : 0.023911500349640846
Loss at iteration 990 : 0.026016216725111008
Loss at iteration 1000 : 0.020103495568037033
Loss at iteration 1010 : 0.013469073921442032
Loss at iteration 1020 : 0.018043067306280136
Loss at iteration 1030 : 0.028760377317667007
Loss at iteration 1040 : 0.024048075079917908
Loss at iteration 1050 : 0.020823387429118156
Loss at iteration 1060 : 0.0190337635576725
Loss at iteration 1070 : 0.016163824126124382
Loss at iteration 1080 : 0.0269810538738966
Loss at iteration 1090 : 0.021874599158763885
Loss at iteration 1100 : 0.02655603736639023
Loss at iteration 1110 : 0.0205486211925745
Loss at iteration 1120 : 0.018916985020041466
Loss at iteration 1130 : 0.04314351826906204
Loss at iteration 1140 : 0.01491152960807085
Loss at iteration 1150 : 0.022879743948578835
Loss at iteration 1160 : 0.028638169169425964
Loss at iteration 1170 : 0.016962682828307152
Loss at iteration 1180 : 0.02352031320333481
Loss at iteration 1190 : 0.023112455382943153
Loss at iteration 1200 : 0.015453214757144451
Loss at iteration 1210 : 0.023260578513145447
The SSIM Value is: 0.8019865075747172
The PSNR Value is: 19.49448445638021
the epoch is: 158
Loss at iteration 10 : 0.03472422808408737
Loss at iteration 20 : 0.0350128710269928
Loss at iteration 30 : 0.022261908277869225
Loss at iteration 40 : 0.020146965980529785
Loss at iteration 50 : 0.017736490815877914
Loss at iteration 60 : 0.026139680296182632
Loss at iteration 70 : 0.022154413163661957
Loss at iteration 80 : 0.014111088588833809
Loss at iteration 90 : 0.016733184456825256
Loss at iteration 100 : 0.017443733289837837
Loss at iteration 110 : 0.017793849110603333
Loss at iteration 120 : 0.014574451372027397
Loss at iteration 130 : 0.02885427325963974
Loss at iteration 140 : 0.01916927471756935
Loss at iteration 150 : 0.014575827866792679
Loss at iteration 160 : 0.0171862430870533
Loss at iteration 170 : 0.014848325401544571
Loss at iteration 180 : 0.021424660459160805
Loss at iteration 190 : 0.013667726889252663
Loss at iteration 200 : 0.01869676262140274
Loss at iteration 210 : 0.018286678940057755
Loss at iteration 220 : 0.02215379849076271
Loss at iteration 230 : 0.01954791694879532
Loss at iteration 240 : 0.013918725773692131
Loss at iteration 250 : 0.01879432611167431
Loss at iteration 260 : 0.01184016466140747
Loss at iteration 270 : 0.023787282407283783
Loss at iteration 280 : 0.01670794188976288
Loss at iteration 290 : 0.01663968525826931
Loss at iteration 300 : 0.01642609015107155
Loss at iteration 310 : 0.014507979154586792
Loss at iteration 320 : 0.020666932687163353
Loss at iteration 330 : 0.024740753695368767
Loss at iteration 340 : 0.02745029143989086
Loss at iteration 350 : 0.02404681220650673
Loss at iteration 360 : 0.021022679284214973
Loss at iteration 370 : 0.02074001543223858
Loss at iteration 380 : 0.022690674290060997
Loss at iteration 390 : 0.024272745475172997
Loss at iteration 400 : 0.025621000677347183
Loss at iteration 410 : 0.020520953461527824
Loss at iteration 420 : 0.02010987140238285
Loss at iteration 430 : 0.018079165369272232
Loss at iteration 440 : 0.028527025133371353
Loss at iteration 450 : 0.023348279297351837
Loss at iteration 460 : 0.01726359874010086
Loss at iteration 470 : 0.029434410855174065
Loss at iteration 480 : 0.02948646992444992
Loss at iteration 490 : 0.02569051831960678
Loss at iteration 500 : 0.011547865346074104
Loss at iteration 510 : 0.015150181949138641
Loss at iteration 520 : 0.027233269065618515
Loss at iteration 530 : 0.015579676255583763
Loss at iteration 540 : 0.026932230219244957
Loss at iteration 550 : 0.012824569828808308
Loss at iteration 560 : 0.01473830733448267
Loss at iteration 570 : 0.03315524756908417
Loss at iteration 580 : 0.012271163985133171
Loss at iteration 590 : 0.016292689368128777
Loss at iteration 600 : 0.01676592230796814
Loss at iteration 610 : 0.02059946395456791
Loss at iteration 620 : 0.015207682736217976
Loss at iteration 630 : 0.01944120228290558
Loss at iteration 640 : 0.016155363991856575
Loss at iteration 650 : 0.01810760423541069
Loss at iteration 660 : 0.016988882794976234
Loss at iteration 670 : 0.033374980092048645
Loss at iteration 680 : 0.01615775376558304
Loss at iteration 690 : 0.017528604716062546
Loss at iteration 700 : 0.014177273958921432
Loss at iteration 710 : 0.007065905258059502
Loss at iteration 720 : 0.023172184824943542
Loss at iteration 730 : 0.013683311641216278
Loss at iteration 740 : 0.02718428522348404
Loss at iteration 750 : 0.016565769910812378
Loss at iteration 760 : 0.011194217018783092
Loss at iteration 770 : 0.014894381165504456
Loss at iteration 780 : 0.030469132587313652
Loss at iteration 790 : 0.02053702250123024
Loss at iteration 800 : 0.030645349994301796
Loss at iteration 810 : 0.028386028483510017
Loss at iteration 820 : 0.018621651455760002
Loss at iteration 830 : 0.01624550297856331
Loss at iteration 840 : 0.014755687676370144
Loss at iteration 850 : 0.021276194602251053
Loss at iteration 860 : 0.0166843943297863
Loss at iteration 870 : 0.019878817722201347
Loss at iteration 880 : 0.03312988579273224
Loss at iteration 890 : 0.016061218455433846
Loss at iteration 900 : 0.016526345163583755
Loss at iteration 910 : 0.036883965134620667
Loss at iteration 920 : 0.03581036254763603
Loss at iteration 930 : 0.016043398529291153
Loss at iteration 940 : 0.015650976449251175
Loss at iteration 950 : 0.01173880510032177
Loss at iteration 960 : 0.017989039421081543
Loss at iteration 970 : 0.01718885637819767
Loss at iteration 980 : 0.017242897301912308
Loss at iteration 990 : 0.01803809031844139
Loss at iteration 1000 : 0.012268655002117157
Loss at iteration 1010 : 0.0182497575879097
Loss at iteration 1020 : 0.013507637195289135
Loss at iteration 1030 : 0.01658143475651741
Loss at iteration 1040 : 0.016663260757923126
Loss at iteration 1050 : 0.013893983326852322
Loss at iteration 1060 : 0.026075154542922974
Loss at iteration 1070 : 0.013284784741699696
Loss at iteration 1080 : 0.01666669361293316
Loss at iteration 1090 : 0.028325244784355164
Loss at iteration 1100 : 0.017775800079107285
Loss at iteration 1110 : 0.017109297215938568
Loss at iteration 1120 : 0.03382010757923126
Loss at iteration 1130 : 0.023320864886045456
Loss at iteration 1140 : 0.014900049194693565
Loss at iteration 1150 : 0.0245423074811697
Loss at iteration 1160 : 0.01827974244952202
Loss at iteration 1170 : 0.025344060733914375
Loss at iteration 1180 : 0.0180804505944252
Loss at iteration 1190 : 0.012514585629105568
Loss at iteration 1200 : 0.017988985404372215
Loss at iteration 1210 : 0.01949840411543846
The SSIM Value is: 0.8016325394312541
The PSNR Value is: 20.014543088277183
the highest SSIM value is: 20.014543088277183
the epoch is: 159
Loss at iteration 10 : 0.01990484446287155
Loss at iteration 20 : 0.01737523451447487
Loss at iteration 30 : 0.03538990020751953
Loss at iteration 40 : 0.01794656179845333
Loss at iteration 50 : 0.02659670263528824
Loss at iteration 60 : 0.025073416531085968
Loss at iteration 70 : 0.01929239183664322
Loss at iteration 80 : 0.014414099976420403
Loss at iteration 90 : 0.011527866125106812
Loss at iteration 100 : 0.019433293491601944
Loss at iteration 110 : 0.012217104434967041
Loss at iteration 120 : 0.017106618732213974
Loss at iteration 130 : 0.018275896087288857
Loss at iteration 140 : 0.01096171885728836
Loss at iteration 150 : 0.025986261665821075
Loss at iteration 160 : 0.016736548393964767
Loss at iteration 170 : 0.02684639021754265
Loss at iteration 180 : 0.012698156759142876
Loss at iteration 190 : 0.025482073426246643
Loss at iteration 200 : 0.033719561994075775
Loss at iteration 210 : 0.016460463404655457
Loss at iteration 220 : 0.019830089062452316
Loss at iteration 230 : 0.013084372505545616
Loss at iteration 240 : 0.021404070779681206
Loss at iteration 250 : 0.016107754781842232
Loss at iteration 260 : 0.027028124779462814
Loss at iteration 270 : 0.016778171062469482
Loss at iteration 280 : 0.018036063760519028
Loss at iteration 290 : 0.01233634352684021
Loss at iteration 300 : 0.01875595562160015
Loss at iteration 310 : 0.020671846345067024
Loss at iteration 320 : 0.028165876865386963
Loss at iteration 330 : 0.025919370353221893
Loss at iteration 340 : 0.010281943716108799
Loss at iteration 350 : 0.013263456523418427
Loss at iteration 360 : 0.02370227500796318
Loss at iteration 370 : 0.02270125225186348
Loss at iteration 380 : 0.017728742212057114
Loss at iteration 390 : 0.018624763935804367
Loss at iteration 400 : 0.028048507869243622
Loss at iteration 410 : 0.016793420538306236
Loss at iteration 420 : 0.028291132301092148
Loss at iteration 430 : 0.03395244479179382
Loss at iteration 440 : 0.01667294092476368
Loss at iteration 450 : 0.01594965159893036
Loss at iteration 460 : 0.025800883769989014
Loss at iteration 470 : 0.014254137873649597
Loss at iteration 480 : 0.015944479033350945
Loss at iteration 490 : 0.02279289998114109
Loss at iteration 500 : 0.02215932495892048
Loss at iteration 510 : 0.01786920800805092
Loss at iteration 520 : 0.029156140983104706
Loss at iteration 530 : 0.017223238945007324
Loss at iteration 540 : 0.014560803771018982
Loss at iteration 550 : 0.021621394902467728
Loss at iteration 560 : 0.018853822723031044
Loss at iteration 570 : 0.012136672623455524
Loss at iteration 580 : 0.01786964200437069
Loss at iteration 590 : 0.006628645118325949
Loss at iteration 600 : 0.042254649102687836
Loss at iteration 610 : 0.012457935139536858
Loss at iteration 620 : 0.017728790640830994
Loss at iteration 630 : 0.022744497284293175
Loss at iteration 640 : 0.01382444053888321
Loss at iteration 650 : 0.03566347435116768
Loss at iteration 660 : 0.011735815554857254
Loss at iteration 670 : 0.010761960409581661
Loss at iteration 680 : 0.014638273045420647
Loss at iteration 690 : 0.02410195581614971
Loss at iteration 700 : 0.013142617419362068
Loss at iteration 710 : 0.01752723567187786
Loss at iteration 720 : 0.017758455127477646
Loss at iteration 730 : 0.025655316188931465
Loss at iteration 740 : 0.022981300950050354
Loss at iteration 750 : 0.024382133036851883
Loss at iteration 760 : 0.01953289471566677
Loss at iteration 770 : 0.014657851308584213
Loss at iteration 780 : 0.01100572943687439
Loss at iteration 790 : 0.035043057054281235
Loss at iteration 800 : 0.016665024682879448
Loss at iteration 810 : 0.023335710167884827
Loss at iteration 820 : 0.016020800918340683
Loss at iteration 830 : 0.018240757286548615
Loss at iteration 840 : 0.019875312224030495
Loss at iteration 850 : 0.015733402222394943
Loss at iteration 860 : 0.02244538441300392
Loss at iteration 870 : 0.017697466537356377
Loss at iteration 880 : 0.016171880066394806
Loss at iteration 890 : 0.017643678933382034
Loss at iteration 900 : 0.01520613580942154
Loss at iteration 910 : 0.02969091758131981
Loss at iteration 920 : 0.02069072425365448
Loss at iteration 930 : 0.022794600576162338
Loss at iteration 940 : 0.024034325033426285
Loss at iteration 950 : 0.019204188138246536
Loss at iteration 960 : 0.02248472534120083
Loss at iteration 970 : 0.011505970731377602
Loss at iteration 980 : 0.013253209181129932
Loss at iteration 990 : 0.017667235806584358
Loss at iteration 1000 : 0.016342326998710632
Loss at iteration 1010 : 0.016503475606441498
Loss at iteration 1020 : 0.021930333226919174
Loss at iteration 1030 : 0.02541065216064453
Loss at iteration 1040 : 0.014480754733085632
Loss at iteration 1050 : 0.015437337569892406
Loss at iteration 1060 : 0.018502280116081238
Loss at iteration 1070 : 0.024609746411442757
Loss at iteration 1080 : 0.02554309368133545
Loss at iteration 1090 : 0.028749242424964905
Loss at iteration 1100 : 0.01685105264186859
Loss at iteration 1110 : 0.025061331689357758
Loss at iteration 1120 : 0.020045388489961624
Loss at iteration 1130 : 0.018645120784640312
Loss at iteration 1140 : 0.02683722972869873
Loss at iteration 1150 : 0.02120722457766533
Loss at iteration 1160 : 0.013642214238643646
Loss at iteration 1170 : 0.019138863310217857
Loss at iteration 1180 : 0.023597929626703262
Loss at iteration 1190 : 0.018895268440246582
Loss at iteration 1200 : 0.011787425726652145
Loss at iteration 1210 : 0.023009169846773148
The SSIM Value is: 0.8070979555447896
The PSNR Value is: 19.78326784769694
the epoch is: 160
Loss at iteration 10 : 0.016022244468331337
Loss at iteration 20 : 0.018519852310419083
Loss at iteration 30 : 0.01186041533946991
Loss at iteration 40 : 0.01769714057445526
Loss at iteration 50 : 0.02328871190547943
Loss at iteration 60 : 0.018092498183250427
Loss at iteration 70 : 0.0226810984313488
Loss at iteration 80 : 0.01255066879093647
Loss at iteration 90 : 0.009837934747338295
Loss at iteration 100 : 0.0214729905128479
Loss at iteration 110 : 0.021393567323684692
Loss at iteration 120 : 0.026038996875286102
Loss at iteration 130 : 0.016745824366807938
Loss at iteration 140 : 0.02175014466047287
Loss at iteration 150 : 0.0245300754904747
Loss at iteration 160 : 0.019838357344269753
Loss at iteration 170 : 0.013627171516418457
Loss at iteration 180 : 0.01991572231054306
Loss at iteration 190 : 0.024090876802802086
Loss at iteration 200 : 0.014695807360112667
Loss at iteration 210 : 0.02099459245800972
Loss at iteration 220 : 0.027715148404240608
Loss at iteration 230 : 0.02187357284128666
Loss at iteration 240 : 0.016426613554358482
Loss at iteration 250 : 0.01961440034210682
Loss at iteration 260 : 0.0182134211063385
Loss at iteration 270 : 0.023304875940084457
Loss at iteration 280 : 0.023597080260515213
Loss at iteration 290 : 0.014313101768493652
Loss at iteration 300 : 0.015566367655992508
Loss at iteration 310 : 0.01955629512667656
Loss at iteration 320 : 0.01873687468469143
Loss at iteration 330 : 0.01128971204161644
Loss at iteration 340 : 0.028433747589588165
Loss at iteration 350 : 0.013413521461188793
Loss at iteration 360 : 0.016752172261476517
Loss at iteration 370 : 0.02021292969584465
Loss at iteration 380 : 0.021838456392288208
Loss at iteration 390 : 0.015587239526212215
Loss at iteration 400 : 0.02696968801319599
Loss at iteration 410 : 0.019960995763540268
Loss at iteration 420 : 0.028728030622005463
Loss at iteration 430 : 0.019573096185922623
Loss at iteration 440 : 0.014488393440842628
Loss at iteration 450 : 0.02222137153148651
Loss at iteration 460 : 0.021267998963594437
Loss at iteration 470 : 0.014985285699367523
Loss at iteration 480 : 0.02282857522368431
Loss at iteration 490 : 0.018683992326259613
Loss at iteration 500 : 0.0158165842294693
Loss at iteration 510 : 0.017111696302890778
Loss at iteration 520 : 0.0269674900919199
Loss at iteration 530 : 0.020618679001927376
Loss at iteration 540 : 0.03569798916578293
Loss at iteration 550 : 0.018468055874109268
Loss at iteration 560 : 0.02085384726524353
Loss at iteration 570 : 0.021385792642831802
Loss at iteration 580 : 0.016658656299114227
Loss at iteration 590 : 0.02200104109942913
Loss at iteration 600 : 0.014164276421070099
Loss at iteration 610 : 0.01871490851044655
Loss at iteration 620 : 0.026502011343836784
Loss at iteration 630 : 0.013976428657770157
Loss at iteration 640 : 0.0173652246594429
Loss at iteration 650 : 0.027662474662065506
Loss at iteration 660 : 0.013927618972957134
Loss at iteration 670 : 0.02222280204296112
Loss at iteration 680 : 0.02592676691710949
Loss at iteration 690 : 0.01956329122185707
Loss at iteration 700 : 0.019732896238565445
Loss at iteration 710 : 0.028837542980909348
Loss at iteration 720 : 0.021257055923342705
Loss at iteration 730 : 0.024646107107400894
Loss at iteration 740 : 0.027120808139443398
Loss at iteration 750 : 0.018651872873306274
Loss at iteration 760 : 0.016695387661457062
Loss at iteration 770 : 0.015057994984090328
Loss at iteration 780 : 0.013388104736804962
Loss at iteration 790 : 0.02768886089324951
Loss at iteration 800 : 0.014955643564462662
Loss at iteration 810 : 0.03254333883523941
Loss at iteration 820 : 0.016576014459133148
Loss at iteration 830 : 0.01846420019865036
Loss at iteration 840 : 0.014826814644038677
Loss at iteration 850 : 0.031775396317243576
Loss at iteration 860 : 0.00936108361929655
Loss at iteration 870 : 0.018364908173680305
Loss at iteration 880 : 0.024918124079704285
Loss at iteration 890 : 0.01909414306282997
Loss at iteration 900 : 0.033111944794654846
Loss at iteration 910 : 0.02207762561738491
Loss at iteration 920 : 0.0152305718511343
Loss at iteration 930 : 0.013839210383594036
Loss at iteration 940 : 0.014350652694702148
Loss at iteration 950 : 0.018235115334391594
Loss at iteration 960 : 0.025023123249411583
Loss at iteration 970 : 0.021112501621246338
Loss at iteration 980 : 0.01716131716966629
Loss at iteration 990 : 0.02370770461857319
Loss at iteration 1000 : 0.028903894126415253
Loss at iteration 1010 : 0.02261819690465927
Loss at iteration 1020 : 0.016892587766051292
Loss at iteration 1030 : 0.01738247089087963
Loss at iteration 1040 : 0.025618460029363632
Loss at iteration 1050 : 0.021858155727386475
Loss at iteration 1060 : 0.022174637764692307
Loss at iteration 1070 : 0.019718624651432037
Loss at iteration 1080 : 0.026942577213048935
Loss at iteration 1090 : 0.016556404531002045
Loss at iteration 1100 : 0.01563253626227379
Loss at iteration 1110 : 0.033694736659526825
Loss at iteration 1120 : 0.028803151100873947
Loss at iteration 1130 : 0.01975550875067711
Loss at iteration 1140 : 0.03307013958692551
Loss at iteration 1150 : 0.015313053503632545
Loss at iteration 1160 : 0.0322706364095211
Loss at iteration 1170 : 0.02556859329342842
Loss at iteration 1180 : 0.025698738172650337
Loss at iteration 1190 : 0.0293022021651268
Loss at iteration 1200 : 0.014960610307753086
Loss at iteration 1210 : 0.024811573326587677
The SSIM Value is: 0.8044784347216288
The PSNR Value is: 19.31582679748535
the epoch is: 161
Loss at iteration 10 : 0.013676057569682598
Loss at iteration 20 : 0.02273380570113659
Loss at iteration 30 : 0.02756003476679325
Loss at iteration 40 : 0.0150325708091259
Loss at iteration 50 : 0.015382284298539162
Loss at iteration 60 : 0.010130742564797401
Loss at iteration 70 : 0.02075297385454178
Loss at iteration 80 : 0.038945626467466354
Loss at iteration 90 : 0.033667080104351044
Loss at iteration 100 : 0.020685553550720215
Loss at iteration 110 : 0.029848897829651833
Loss at iteration 120 : 0.013071998953819275
Loss at iteration 130 : 0.02075669728219509
Loss at iteration 140 : 0.022796373814344406
Loss at iteration 150 : 0.025839827954769135
Loss at iteration 160 : 0.01669916883111
Loss at iteration 170 : 0.01631362922489643
Loss at iteration 180 : 0.017832554876804352
Loss at iteration 190 : 0.021882005035877228
Loss at iteration 200 : 0.0274612195789814
Loss at iteration 210 : 0.02526891604065895
Loss at iteration 220 : 0.018686935305595398
Loss at iteration 230 : 0.015160433016717434
Loss at iteration 240 : 0.017072901129722595
Loss at iteration 250 : 0.017550066113471985
Loss at iteration 260 : 0.013996907509863377
Loss at iteration 270 : 0.015234733000397682
Loss at iteration 280 : 0.02936464175581932
Loss at iteration 290 : 0.013482142239809036
Loss at iteration 300 : 0.014480823650956154
Loss at iteration 310 : 0.01684788055717945
Loss at iteration 320 : 0.025173231959342957
Loss at iteration 330 : 0.023116279393434525
Loss at iteration 340 : 0.018947631120681763
Loss at iteration 350 : 0.012042904272675514
Loss at iteration 360 : 0.030425969511270523
Loss at iteration 370 : 0.01496194675564766
Loss at iteration 380 : 0.02223031222820282
Loss at iteration 390 : 0.02363583818078041
Loss at iteration 400 : 0.020405882969498634
Loss at iteration 410 : 0.019871622323989868
Loss at iteration 420 : 0.016031160950660706
Loss at iteration 430 : 0.025574643164873123
Loss at iteration 440 : 0.02693546935915947
Loss at iteration 450 : 0.0349760502576828
Loss at iteration 460 : 0.02033151127398014
Loss at iteration 470 : 0.02964511699974537
Loss at iteration 480 : 0.013350844383239746
Loss at iteration 490 : 0.035774897783994675
Loss at iteration 500 : 0.023782331496477127
Loss at iteration 510 : 0.01790769211947918
Loss at iteration 520 : 0.01699390634894371
Loss at iteration 530 : 0.018447991460561752
Loss at iteration 540 : 0.020539436489343643
Loss at iteration 550 : 0.01387416198849678
Loss at iteration 560 : 0.025462916120886803
Loss at iteration 570 : 0.01693316549062729
Loss at iteration 580 : 0.021929258480668068
Loss at iteration 590 : 0.017619365826249123
Loss at iteration 600 : 0.017895374447107315
Loss at iteration 610 : 0.025924425572156906
Loss at iteration 620 : 0.017443008720874786
Loss at iteration 630 : 0.020344693213701248
Loss at iteration 640 : 0.016223154962062836
Loss at iteration 650 : 0.029514901340007782
Loss at iteration 660 : 0.01514989510178566
Loss at iteration 670 : 0.01666848361492157
Loss at iteration 680 : 0.026168107986450195
Loss at iteration 690 : 0.015488816425204277
Loss at iteration 700 : 0.017631875351071358
Loss at iteration 710 : 0.01774359494447708
Loss at iteration 720 : 0.03128524124622345
Loss at iteration 730 : 0.02308810129761696
Loss at iteration 740 : 0.02545638009905815
Loss at iteration 750 : 0.0150176165625453
Loss at iteration 760 : 0.021352913230657578
Loss at iteration 770 : 0.018201202154159546
Loss at iteration 780 : 0.01975870318710804
Loss at iteration 790 : 0.010055432096123695
Loss at iteration 800 : 0.016395030543208122
Loss at iteration 810 : 0.02019735611975193
Loss at iteration 820 : 0.010332798585295677
Loss at iteration 830 : 0.03222164511680603
Loss at iteration 840 : 0.018330827355384827
Loss at iteration 850 : 0.021618051454424858
Loss at iteration 860 : 0.025385340675711632
Loss at iteration 870 : 0.025509687140583992
Loss at iteration 880 : 0.025522790849208832
Loss at iteration 890 : 0.01285821944475174
Loss at iteration 900 : 0.014732415787875652
Loss at iteration 910 : 0.01802128739655018
Loss at iteration 920 : 0.02933550998568535
Loss at iteration 930 : 0.024277644231915474
Loss at iteration 940 : 0.018895994871854782
Loss at iteration 950 : 0.010198121890425682
Loss at iteration 960 : 0.019313175231218338
Loss at iteration 970 : 0.013886598870158195
Loss at iteration 980 : 0.020422950387001038
Loss at iteration 990 : 0.01528741605579853
Loss at iteration 1000 : 0.01899014785885811
Loss at iteration 1010 : 0.016734907403588295
Loss at iteration 1020 : 0.027565758675336838
Loss at iteration 1030 : 0.02489352971315384
Loss at iteration 1040 : 0.02201731503009796
Loss at iteration 1050 : 0.022318027913570404
Loss at iteration 1060 : 0.032329197973012924
Loss at iteration 1070 : 0.01960647851228714
Loss at iteration 1080 : 0.014476323500275612
Loss at iteration 1090 : 0.014085161499679089
Loss at iteration 1100 : 0.02413656935095787
Loss at iteration 1110 : 0.025707852095365524
Loss at iteration 1120 : 0.011493747122585773
Loss at iteration 1130 : 0.014129605144262314
Loss at iteration 1140 : 0.019972100853919983
Loss at iteration 1150 : 0.022159650921821594
Loss at iteration 1160 : 0.021181784570217133
Loss at iteration 1170 : 0.012846918776631355
Loss at iteration 1180 : 0.019163288176059723
Loss at iteration 1190 : 0.02062169834971428
Loss at iteration 1200 : 0.0230597835034132
Loss at iteration 1210 : 0.0196294654160738
The SSIM Value is: 0.7983973185221355
The PSNR Value is: 19.69458516438802
the epoch is: 162
Loss at iteration 10 : 0.030019059777259827
Loss at iteration 20 : 0.026501107960939407
Loss at iteration 30 : 0.020252587273716927
Loss at iteration 40 : 0.017438318580389023
Loss at iteration 50 : 0.022158611565828323
Loss at iteration 60 : 0.013756978325545788
Loss at iteration 70 : 0.017233481630682945
Loss at iteration 80 : 0.014254981651902199
Loss at iteration 90 : 0.014271726831793785
Loss at iteration 100 : 0.022325241938233376
Loss at iteration 110 : 0.01876288652420044
Loss at iteration 120 : 0.028560757637023926
Loss at iteration 130 : 0.015056122094392776
Loss at iteration 140 : 0.014027513563632965
Loss at iteration 150 : 0.029360216110944748
Loss at iteration 160 : 0.01854126527905464
Loss at iteration 170 : 0.016624126583337784
Loss at iteration 180 : 0.01796572282910347
Loss at iteration 190 : 0.021074345335364342
Loss at iteration 200 : 0.024608250707387924
Loss at iteration 210 : 0.02421734109520912
Loss at iteration 220 : 0.011676333844661713
Loss at iteration 230 : 0.03721880167722702
Loss at iteration 240 : 0.021424781531095505
Loss at iteration 250 : 0.012703148648142815
Loss at iteration 260 : 0.01941039226949215
Loss at iteration 270 : 0.037140145897865295
Loss at iteration 280 : 0.02234281599521637
Loss at iteration 290 : 0.020886294543743134
Loss at iteration 300 : 0.029226358979940414
Loss at iteration 310 : 0.022569436579942703
Loss at iteration 320 : 0.02164473384618759
Loss at iteration 330 : 0.01853499934077263
Loss at iteration 340 : 0.014940990135073662
Loss at iteration 350 : 0.020651673898100853
Loss at iteration 360 : 0.022839030250906944
Loss at iteration 370 : 0.020487714558839798
Loss at iteration 380 : 0.017267238348722458
Loss at iteration 390 : 0.014917667023837566
Loss at iteration 400 : 0.013613423332571983
Loss at iteration 410 : 0.018118787556886673
Loss at iteration 420 : 0.012949821539223194
Loss at iteration 430 : 0.0139485327526927
Loss at iteration 440 : 0.02758415974676609
Loss at iteration 450 : 0.02149713784456253
Loss at iteration 460 : 0.021404225379228592
Loss at iteration 470 : 0.04800957441329956
Loss at iteration 480 : 0.02097037062048912
Loss at iteration 490 : 0.014891376718878746
Loss at iteration 500 : 0.013845494017004967
Loss at iteration 510 : 0.014329574070870876
Loss at iteration 520 : 0.017718510702252388
Loss at iteration 530 : 0.01832585409283638
Loss at iteration 540 : 0.019787950441241264
Loss at iteration 550 : 0.011315909214317799
Loss at iteration 560 : 0.009135184809565544
Loss at iteration 570 : 0.027538038790225983
Loss at iteration 580 : 0.023358553647994995
Loss at iteration 590 : 0.020564381033182144
Loss at iteration 600 : 0.01678149215877056
Loss at iteration 610 : 0.009302882477641106
Loss at iteration 620 : 0.01728718727827072
Loss at iteration 630 : 0.01903175562620163
Loss at iteration 640 : 0.022540245205163956
Loss at iteration 650 : 0.015855442732572556
Loss at iteration 660 : 0.019985344260931015
Loss at iteration 670 : 0.02361522801220417
Loss at iteration 680 : 0.02018934302031994
Loss at iteration 690 : 0.032087359577417374
Loss at iteration 700 : 0.020100530236959457
Loss at iteration 710 : 0.014109788462519646
Loss at iteration 720 : 0.025594303384423256
Loss at iteration 730 : 0.015277661383152008
Loss at iteration 740 : 0.0277450792491436
Loss at iteration 750 : 0.025834139436483383
Loss at iteration 760 : 0.017087751999497414
Loss at iteration 770 : 0.017283953726291656
Loss at iteration 780 : 0.0166176650673151
Loss at iteration 790 : 0.028292827308177948
Loss at iteration 800 : 0.020471274852752686
Loss at iteration 810 : 0.02200200781226158
Loss at iteration 820 : 0.013929026201367378
Loss at iteration 830 : 0.017855873331427574
Loss at iteration 840 : 0.01951693370938301
Loss at iteration 850 : 0.029822949320077896
Loss at iteration 860 : 0.023861899971961975
Loss at iteration 870 : 0.025147149339318275
Loss at iteration 880 : 0.029636843129992485
Loss at iteration 890 : 0.019063439220190048
Loss at iteration 900 : 0.029275845736265182
Loss at iteration 910 : 0.021296868100762367
Loss at iteration 920 : 0.021437015384435654
Loss at iteration 930 : 0.02145485021173954
Loss at iteration 940 : 0.01928175427019596
Loss at iteration 950 : 0.015026601031422615
Loss at iteration 960 : 0.020087361335754395
Loss at iteration 970 : 0.02115253172814846
Loss at iteration 980 : 0.018709182739257812
Loss at iteration 990 : 0.01775306835770607
Loss at iteration 1000 : 0.014919271692633629
Loss at iteration 1010 : 0.017896359786391258
Loss at iteration 1020 : 0.019016409292817116
Loss at iteration 1030 : 0.019877804443240166
Loss at iteration 1040 : 0.01901554875075817
Loss at iteration 1050 : 0.021639475598931313
Loss at iteration 1060 : 0.013864662498235703
Loss at iteration 1070 : 0.022143378853797913
Loss at iteration 1080 : 0.017854241654276848
Loss at iteration 1090 : 0.01992541179060936
Loss at iteration 1100 : 0.014926742762327194
Loss at iteration 1110 : 0.014660101383924484
Loss at iteration 1120 : 0.018453162163496017
Loss at iteration 1130 : 0.01711616851389408
Loss at iteration 1140 : 0.033994339406490326
Loss at iteration 1150 : 0.019068848341703415
Loss at iteration 1160 : 0.015443038195371628
Loss at iteration 1170 : 0.03286461532115936
Loss at iteration 1180 : 0.011072320863604546
Loss at iteration 1190 : 0.01785106398165226
Loss at iteration 1200 : 0.015173578634858131
Loss at iteration 1210 : 0.017816536128520966
The SSIM Value is: 0.8057596325874329
The PSNR Value is: 19.514234224955242
the epoch is: 163
Loss at iteration 10 : 0.014723513275384903
Loss at iteration 20 : 0.030698265880346298
Loss at iteration 30 : 0.02133585885167122
Loss at iteration 40 : 0.018748689442873
Loss at iteration 50 : 0.015124820172786713
Loss at iteration 60 : 0.026091838255524635
Loss at iteration 70 : 0.014130094088613987
Loss at iteration 80 : 0.026670731604099274
Loss at iteration 90 : 0.020397109910845757
Loss at iteration 100 : 0.032295484095811844
Loss at iteration 110 : 0.016757339239120483
Loss at iteration 120 : 0.028501253575086594
Loss at iteration 130 : 0.01630832627415657
Loss at iteration 140 : 0.016236290335655212
Loss at iteration 150 : 0.018289659172296524
Loss at iteration 160 : 0.02549589052796364
Loss at iteration 170 : 0.03617548197507858
Loss at iteration 180 : 0.02149345725774765
Loss at iteration 190 : 0.011841215193271637
Loss at iteration 200 : 0.029752204194664955
Loss at iteration 210 : 0.018945464864373207
Loss at iteration 220 : 0.020341794937849045
Loss at iteration 230 : 0.021556328982114792
Loss at iteration 240 : 0.014830137602984905
Loss at iteration 250 : 0.03685859963297844
Loss at iteration 260 : 0.013477053493261337
Loss at iteration 270 : 0.016510862857103348
Loss at iteration 280 : 0.020117711275815964
Loss at iteration 290 : 0.01356374192982912
Loss at iteration 300 : 0.015197892673313618
Loss at iteration 310 : 0.01950184255838394
Loss at iteration 320 : 0.030109867453575134
Loss at iteration 330 : 0.017498552799224854
Loss at iteration 340 : 0.013129225000739098
Loss at iteration 350 : 0.022174442186951637
Loss at iteration 360 : 0.02646438404917717
Loss at iteration 370 : 0.021213557571172714
Loss at iteration 380 : 0.025940343737602234
Loss at iteration 390 : 0.025341704487800598
Loss at iteration 400 : 0.015747398138046265
Loss at iteration 410 : 0.03259121999144554
Loss at iteration 420 : 0.02327839657664299
Loss at iteration 430 : 0.015356725081801414
Loss at iteration 440 : 0.020582906901836395
Loss at iteration 450 : 0.014842169359326363
Loss at iteration 460 : 0.018183507025241852
Loss at iteration 470 : 0.01588716357946396
Loss at iteration 480 : 0.02988891676068306
Loss at iteration 490 : 0.01848040148615837
Loss at iteration 500 : 0.022431863471865654
Loss at iteration 510 : 0.013950832188129425
Loss at iteration 520 : 0.028611470013856888
Loss at iteration 530 : 0.012787193059921265
Loss at iteration 540 : 0.016364172101020813
Loss at iteration 550 : 0.027416275814175606
Loss at iteration 560 : 0.014352166093885899
Loss at iteration 570 : 0.021951276808977127
Loss at iteration 580 : 0.012857124209403992
Loss at iteration 590 : 0.009606347419321537
Loss at iteration 600 : 0.019369272515177727
Loss at iteration 610 : 0.02170076221227646
Loss at iteration 620 : 0.01919557712972164
Loss at iteration 630 : 0.015365388244390488
Loss at iteration 640 : 0.01972373202443123
Loss at iteration 650 : 0.02065230719745159
Loss at iteration 660 : 0.014717294834554195
Loss at iteration 670 : 0.020427308976650238
Loss at iteration 680 : 0.015902910381555557
Loss at iteration 690 : 0.012077867984771729
Loss at iteration 700 : 0.03356980159878731
Loss at iteration 710 : 0.020327508449554443
Loss at iteration 720 : 0.03377225995063782
Loss at iteration 730 : 0.02365562506020069
Loss at iteration 740 : 0.022170446813106537
Loss at iteration 750 : 0.015897536650300026
Loss at iteration 760 : 0.01840975135564804
Loss at iteration 770 : 0.027820833027362823
Loss at iteration 780 : 0.015655171126127243
Loss at iteration 790 : 0.01646963693201542
Loss at iteration 800 : 0.028725899755954742
Loss at iteration 810 : 0.019999278709292412
Loss at iteration 820 : 0.03345135226845741
Loss at iteration 830 : 0.01763119362294674
Loss at iteration 840 : 0.018176058307290077
Loss at iteration 850 : 0.01855432614684105
Loss at iteration 860 : 0.01768142729997635
Loss at iteration 870 : 0.01665826141834259
Loss at iteration 880 : 0.021617300808429718
Loss at iteration 890 : 0.015211677178740501
Loss at iteration 900 : 0.0118295568972826
Loss at iteration 910 : 0.039717551320791245
Loss at iteration 920 : 0.012453237548470497
Loss at iteration 930 : 0.020950939506292343
Loss at iteration 940 : 0.018420405685901642
Loss at iteration 950 : 0.02333167940378189
Loss at iteration 960 : 0.015080519020557404
Loss at iteration 970 : 0.015434205532073975
Loss at iteration 980 : 0.02310861460864544
Loss at iteration 990 : 0.015506034716963768
Loss at iteration 1000 : 0.02566172368824482
Loss at iteration 1010 : 0.022916661575436592
Loss at iteration 1020 : 0.013456737622618675
Loss at iteration 1030 : 0.021942324936389923
Loss at iteration 1040 : 0.02117895893752575
Loss at iteration 1050 : 0.02548077702522278
Loss at iteration 1060 : 0.01914454624056816
Loss at iteration 1070 : 0.021863946691155434
Loss at iteration 1080 : 0.025305921211838722
Loss at iteration 1090 : 0.013527851551771164
Loss at iteration 1100 : 0.021665135398507118
Loss at iteration 1110 : 0.03459637612104416
Loss at iteration 1120 : 0.02487953007221222
Loss at iteration 1130 : 0.0315706804394722
Loss at iteration 1140 : 0.01990966685116291
Loss at iteration 1150 : 0.017844025045633316
Loss at iteration 1160 : 0.028278598561882973
Loss at iteration 1170 : 0.01924821361899376
Loss at iteration 1180 : 0.028471648693084717
Loss at iteration 1190 : 0.02566404640674591
Loss at iteration 1200 : 0.027381926774978638
Loss at iteration 1210 : 0.012170877307653427
The SSIM Value is: 0.8014262159665425
The PSNR Value is: 19.69402281443278
the epoch is: 164
Loss at iteration 10 : 0.01216425746679306
Loss at iteration 20 : 0.02497018128633499
Loss at iteration 30 : 0.010213830508291721
Loss at iteration 40 : 0.013397349044680595
Loss at iteration 50 : 0.01729295775294304
Loss at iteration 60 : 0.021554291248321533
Loss at iteration 70 : 0.02681455947458744
Loss at iteration 80 : 0.012186627835035324
Loss at iteration 90 : 0.024550912901759148
Loss at iteration 100 : 0.01570962741971016
Loss at iteration 110 : 0.011276576668024063
Loss at iteration 120 : 0.021416349336504936
Loss at iteration 130 : 0.02131403610110283
Loss at iteration 140 : 0.029910409823060036
Loss at iteration 150 : 0.025743212550878525
Loss at iteration 160 : 0.015950502827763557
Loss at iteration 170 : 0.01628250814974308
Loss at iteration 180 : 0.02969345822930336
Loss at iteration 190 : 0.018554847687482834
Loss at iteration 200 : 0.011708255857229233
Loss at iteration 210 : 0.025821315124630928
Loss at iteration 220 : 0.028283484280109406
Loss at iteration 230 : 0.026858851313591003
Loss at iteration 240 : 0.02655882015824318
Loss at iteration 250 : 0.014834471046924591
Loss at iteration 260 : 0.011686649173498154
Loss at iteration 270 : 0.02218957617878914
Loss at iteration 280 : 0.021424952894449234
Loss at iteration 290 : 0.019912995398044586
Loss at iteration 300 : 0.02457660809159279
Loss at iteration 310 : 0.023441772907972336
Loss at iteration 320 : 0.019462157040834427
Loss at iteration 330 : 0.015323569998145103
Loss at iteration 340 : 0.019624657928943634
Loss at iteration 350 : 0.019656846299767494
Loss at iteration 360 : 0.014091863296926022
Loss at iteration 370 : 0.019672241061925888
Loss at iteration 380 : 0.0186111219227314
Loss at iteration 390 : 0.02494424395263195
Loss at iteration 400 : 0.029837828129529953
Loss at iteration 410 : 0.018227994441986084
Loss at iteration 420 : 0.02719227597117424
Loss at iteration 430 : 0.02094111032783985
Loss at iteration 440 : 0.0152260297909379
Loss at iteration 450 : 0.028626684099435806
Loss at iteration 460 : 0.030127566307783127
Loss at iteration 470 : 0.02660510689020157
Loss at iteration 480 : 0.015181577764451504
Loss at iteration 490 : 0.014524831436574459
Loss at iteration 500 : 0.019519556313753128
Loss at iteration 510 : 0.018037371337413788
Loss at iteration 520 : 0.019828729331493378
Loss at iteration 530 : 0.01648380048573017
Loss at iteration 540 : 0.012498406693339348
Loss at iteration 550 : 0.02544465661048889
Loss at iteration 560 : 0.01736801117658615
Loss at iteration 570 : 0.020974911749362946
Loss at iteration 580 : 0.02414103038609028
Loss at iteration 590 : 0.026302751153707504
Loss at iteration 600 : 0.02150939404964447
Loss at iteration 610 : 0.024031730368733406
Loss at iteration 620 : 0.01562380138784647
Loss at iteration 630 : 0.015261993743479252
Loss at iteration 640 : 0.0103218425065279
Loss at iteration 650 : 0.012881842441856861
Loss at iteration 660 : 0.023884639143943787
Loss at iteration 670 : 0.02044656127691269
Loss at iteration 680 : 0.024138782173395157
Loss at iteration 690 : 0.016338739544153214
Loss at iteration 700 : 0.01397681888192892
Loss at iteration 710 : 0.028467873111367226
Loss at iteration 720 : 0.02432837523519993
Loss at iteration 730 : 0.010078012011945248
Loss at iteration 740 : 0.014971795491874218
Loss at iteration 750 : 0.018390897661447525
Loss at iteration 760 : 0.01675082929432392
Loss at iteration 770 : 0.0186997689306736
Loss at iteration 780 : 0.02013299986720085
Loss at iteration 790 : 0.018192222341895103
Loss at iteration 800 : 0.0143737168982625
Loss at iteration 810 : 0.01732897199690342
Loss at iteration 820 : 0.026047131046652794
Loss at iteration 830 : 0.023473192006349564
Loss at iteration 840 : 0.008074887096881866
Loss at iteration 850 : 0.026685593649744987
Loss at iteration 860 : 0.01786920242011547
Loss at iteration 870 : 0.014909815043210983
Loss at iteration 880 : 0.02102109044790268
Loss at iteration 890 : 0.009868031367659569
Loss at iteration 900 : 0.019490882754325867
Loss at iteration 910 : 0.021588940173387527
Loss at iteration 920 : 0.02258554846048355
Loss at iteration 930 : 0.017940454185009003
Loss at iteration 940 : 0.00900365598499775
Loss at iteration 950 : 0.01602157950401306
Loss at iteration 960 : 0.024720944464206696
Loss at iteration 970 : 0.021282682195305824
Loss at iteration 980 : 0.011579450219869614
Loss at iteration 990 : 0.015609249472618103
Loss at iteration 1000 : 0.015438229776918888
Loss at iteration 1010 : 0.012096773833036423
Loss at iteration 1020 : 0.024053562432527542
Loss at iteration 1030 : 0.027421370148658752
Loss at iteration 1040 : 0.012693286873400211
Loss at iteration 1050 : 0.020339449867606163
Loss at iteration 1060 : 0.02663750946521759
Loss at iteration 1070 : 0.01387942023575306
Loss at iteration 1080 : 0.024096958339214325
Loss at iteration 1090 : 0.06074311584234238
Loss at iteration 1100 : 0.028549108654260635
Loss at iteration 1110 : 0.018001295626163483
Loss at iteration 1120 : 0.01809106022119522
Loss at iteration 1130 : 0.013678643852472305
Loss at iteration 1140 : 0.02064557373523712
Loss at iteration 1150 : 0.0294635072350502
Loss at iteration 1160 : 0.026232877746224403
Loss at iteration 1170 : 0.024219658225774765
Loss at iteration 1180 : 0.014272388070821762
Loss at iteration 1190 : 0.020098377019166946
Loss at iteration 1200 : 0.012699835002422333
Loss at iteration 1210 : 0.013936690986156464
The SSIM Value is: 0.8048252860705057
The PSNR Value is: 19.39512284596761
the epoch is: 165
Loss at iteration 10 : 0.014683796092867851
Loss at iteration 20 : 0.014992100186645985
Loss at iteration 30 : 0.018109530210494995
Loss at iteration 40 : 0.02165582776069641
Loss at iteration 50 : 0.022293729707598686
Loss at iteration 60 : 0.013527906499803066
Loss at iteration 70 : 0.022034648805856705
Loss at iteration 80 : 0.01844344474375248
Loss at iteration 90 : 0.026147957891225815
Loss at iteration 100 : 0.01643788442015648
Loss at iteration 110 : 0.022070929408073425
Loss at iteration 120 : 0.02115541510283947
Loss at iteration 130 : 0.018472496420145035
Loss at iteration 140 : 0.02373068779706955
Loss at iteration 150 : 0.023038286715745926
Loss at iteration 160 : 0.020097043365240097
Loss at iteration 170 : 0.016253646463155746
Loss at iteration 180 : 0.025725219398736954
Loss at iteration 190 : 0.02219994179904461
Loss at iteration 200 : 0.01703372225165367
Loss at iteration 210 : 0.017682230100035667
Loss at iteration 220 : 0.012252477928996086
Loss at iteration 230 : 0.01474776677787304
Loss at iteration 240 : 0.020339248701930046
Loss at iteration 250 : 0.04441803693771362
Loss at iteration 260 : 0.012239659205079079
Loss at iteration 270 : 0.017587769776582718
Loss at iteration 280 : 0.02498447708785534
Loss at iteration 290 : 0.021804701536893845
Loss at iteration 300 : 0.017387250438332558
Loss at iteration 310 : 0.024742914363741875
Loss at iteration 320 : 0.01951598934829235
Loss at iteration 330 : 0.01843245141208172
Loss at iteration 340 : 0.027405977249145508
Loss at iteration 350 : 0.012554609216749668
Loss at iteration 360 : 0.022008156403899193
Loss at iteration 370 : 0.02330205775797367
Loss at iteration 380 : 0.023002419620752335
Loss at iteration 390 : 0.02489602565765381
Loss at iteration 400 : 0.022228090092539787
Loss at iteration 410 : 0.027405358850955963
Loss at iteration 420 : 0.015187578275799751
Loss at iteration 430 : 0.01718074455857277
Loss at iteration 440 : 0.015180337242782116
Loss at iteration 450 : 0.025172945111989975
Loss at iteration 460 : 0.01851893961429596
Loss at iteration 470 : 0.01414676196873188
Loss at iteration 480 : 0.011189605109393597
Loss at iteration 490 : 0.017142176628112793
Loss at iteration 500 : 0.019322529435157776
Loss at iteration 510 : 0.024034949019551277
Loss at iteration 520 : 0.03417326882481575
Loss at iteration 530 : 0.02113383263349533
Loss at iteration 540 : 0.01956513337790966
Loss at iteration 550 : 0.017523743212223053
Loss at iteration 560 : 0.013483066111803055
Loss at iteration 570 : 0.03386450558900833
Loss at iteration 580 : 0.02216031216084957
Loss at iteration 590 : 0.022198420017957687
Loss at iteration 600 : 0.017453070729970932
Loss at iteration 610 : 0.02283359318971634
Loss at iteration 620 : 0.019047748297452927
Loss at iteration 630 : 0.01719539985060692
Loss at iteration 640 : 0.02009418047964573
Loss at iteration 650 : 0.019613824784755707
Loss at iteration 660 : 0.012556883506476879
Loss at iteration 670 : 0.021118449047207832
Loss at iteration 680 : 0.021999727934598923
Loss at iteration 690 : 0.015052331611514091
Loss at iteration 700 : 0.013315880671143532
Loss at iteration 710 : 0.023961983621120453
Loss at iteration 720 : 0.01787504367530346
Loss at iteration 730 : 0.0191515926271677
Loss at iteration 740 : 0.020077019929885864
Loss at iteration 750 : 0.021826626732945442
Loss at iteration 760 : 0.022064559161663055
Loss at iteration 770 : 0.021039588376879692
Loss at iteration 780 : 0.016420161351561546
Loss at iteration 790 : 0.0165430698543787
Loss at iteration 800 : 0.01178653072565794
Loss at iteration 810 : 0.02659188210964203
Loss at iteration 820 : 0.01185157336294651
Loss at iteration 830 : 0.017528124153614044
Loss at iteration 840 : 0.02056536264717579
Loss at iteration 850 : 0.023242279887199402
Loss at iteration 860 : 0.03436867520213127
Loss at iteration 870 : 0.022713463753461838
Loss at iteration 880 : 0.015040479600429535
Loss at iteration 890 : 0.015670575201511383
Loss at iteration 900 : 0.019736019894480705
Loss at iteration 910 : 0.017408132553100586
Loss at iteration 920 : 0.022409092634916306
Loss at iteration 930 : 0.014287433587014675
Loss at iteration 940 : 0.011595509946346283
Loss at iteration 950 : 0.027371846139431
Loss at iteration 960 : 0.010812489315867424
Loss at iteration 970 : 0.025665588676929474
Loss at iteration 980 : 0.027334555983543396
Loss at iteration 990 : 0.01972687430679798
Loss at iteration 1000 : 0.013187282718718052
Loss at iteration 1010 : 0.021792661398649216
Loss at iteration 1020 : 0.030412055552005768
Loss at iteration 1030 : 0.02726144716143608
Loss at iteration 1040 : 0.018855882808566093
Loss at iteration 1050 : 0.01690380834043026
Loss at iteration 1060 : 0.026220224797725677
Loss at iteration 1070 : 0.02593672089278698
Loss at iteration 1080 : 0.022680744528770447
Loss at iteration 1090 : 0.031563498079776764
Loss at iteration 1100 : 0.0229142177850008
Loss at iteration 1110 : 0.016270345076918602
Loss at iteration 1120 : 0.014709489420056343
Loss at iteration 1130 : 0.029851943254470825
Loss at iteration 1140 : 0.01810859516263008
Loss at iteration 1150 : 0.01630796492099762
Loss at iteration 1160 : 0.019640199840068817
Loss at iteration 1170 : 0.022571779787540436
Loss at iteration 1180 : 0.017800183966755867
Loss at iteration 1190 : 0.018239015713334084
Loss at iteration 1200 : 0.026252947747707367
Loss at iteration 1210 : 0.021055517718195915
The SSIM Value is: 0.8067115545272827
The PSNR Value is: 19.729252815246582
the epoch is: 166
Loss at iteration 10 : 0.015575937926769257
Loss at iteration 20 : 0.010252331383526325
Loss at iteration 30 : 0.019275609403848648
Loss at iteration 40 : 0.020151358097791672
Loss at iteration 50 : 0.014513235539197922
Loss at iteration 60 : 0.018090983852744102
Loss at iteration 70 : 0.020133620128035545
Loss at iteration 80 : 0.018591757863759995
Loss at iteration 90 : 0.023790638893842697
Loss at iteration 100 : 0.01375960186123848
Loss at iteration 110 : 0.018481360748410225
Loss at iteration 120 : 0.02403172291815281
Loss at iteration 130 : 0.01983325369656086
Loss at iteration 140 : 0.016042344272136688
Loss at iteration 150 : 0.019642502069473267
Loss at iteration 160 : 0.018327638506889343
Loss at iteration 170 : 0.025888219475746155
Loss at iteration 180 : 0.010185357183218002
Loss at iteration 190 : 0.01822473295032978
Loss at iteration 200 : 0.019077861681580544
Loss at iteration 210 : 0.022808533161878586
Loss at iteration 220 : 0.03230319917201996
Loss at iteration 230 : 0.012868991121649742
Loss at iteration 240 : 0.02152218669652939
Loss at iteration 250 : 0.021182190626859665
Loss at iteration 260 : 0.02241424284875393
Loss at iteration 270 : 0.021964630112051964
Loss at iteration 280 : 0.02141723781824112
Loss at iteration 290 : 0.026302937418222427
Loss at iteration 300 : 0.021504243835806847
Loss at iteration 310 : 0.011371729895472527
Loss at iteration 320 : 0.012770076282322407
Loss at iteration 330 : 0.02185574360191822
Loss at iteration 340 : 0.03447100147604942
Loss at iteration 350 : 0.01679755002260208
Loss at iteration 360 : 0.018598100170493126
Loss at iteration 370 : 0.015773611143231392
Loss at iteration 380 : 0.022998742759227753
Loss at iteration 390 : 0.01915629580616951
Loss at iteration 400 : 0.02556809037923813
Loss at iteration 410 : 0.01915690302848816
Loss at iteration 420 : 0.017174772918224335
Loss at iteration 430 : 0.01859498769044876
Loss at iteration 440 : 0.023613424971699715
Loss at iteration 450 : 0.02015409618616104
Loss at iteration 460 : 0.02093249373137951
Loss at iteration 470 : 0.032445330172777176
Loss at iteration 480 : 0.024347078055143356
Loss at iteration 490 : 0.02177181839942932
Loss at iteration 500 : 0.01992752030491829
Loss at iteration 510 : 0.01673850230872631
Loss at iteration 520 : 0.015853848308324814
Loss at iteration 530 : 0.024152742698788643
Loss at iteration 540 : 0.015061880461871624
Loss at iteration 550 : 0.02909734472632408
Loss at iteration 560 : 0.019458169117569923
Loss at iteration 570 : 0.016752785071730614
Loss at iteration 580 : 0.02666769176721573
Loss at iteration 590 : 0.021354015916585922
Loss at iteration 600 : 0.013616845943033695
Loss at iteration 610 : 0.015374665148556232
Loss at iteration 620 : 0.0203023012727499
Loss at iteration 630 : 0.022212844341993332
Loss at iteration 640 : 0.01506658922880888
Loss at iteration 650 : 0.017161168158054352
Loss at iteration 660 : 0.02235376089811325
Loss at iteration 670 : 0.01588371954858303
Loss at iteration 680 : 0.023447029292583466
Loss at iteration 690 : 0.02168557420372963
Loss at iteration 700 : 0.018575312569737434
Loss at iteration 710 : 0.01720089092850685
Loss at iteration 720 : 0.016082724556326866
Loss at iteration 730 : 0.015386217273771763
Loss at iteration 740 : 0.016840219497680664
Loss at iteration 750 : 0.03148552402853966
Loss at iteration 760 : 0.016122203320264816
Loss at iteration 770 : 0.01836700364947319
Loss at iteration 780 : 0.01722661405801773
Loss at iteration 790 : 0.01666766218841076
Loss at iteration 800 : 0.023321188986301422
Loss at iteration 810 : 0.01292591542005539
Loss at iteration 820 : 0.01951896771788597
Loss at iteration 830 : 0.016746079549193382
Loss at iteration 840 : 0.019368315115571022
Loss at iteration 850 : 0.018136119470000267
Loss at iteration 860 : 0.017745042219758034
Loss at iteration 870 : 0.019052263349294662
Loss at iteration 880 : 0.03297129645943642
Loss at iteration 890 : 0.013589557260274887
Loss at iteration 900 : 0.013578934594988823
Loss at iteration 910 : 0.016598781570792198
Loss at iteration 920 : 0.019515391439199448
Loss at iteration 930 : 0.018795540556311607
Loss at iteration 940 : 0.016851041465997696
Loss at iteration 950 : 0.01569567620754242
Loss at iteration 960 : 0.011990323662757874
Loss at iteration 970 : 0.016609899699687958
Loss at iteration 980 : 0.018982265144586563
Loss at iteration 990 : 0.022193241864442825
Loss at iteration 1000 : 0.017144644632935524
Loss at iteration 1010 : 0.013238056562840939
Loss at iteration 1020 : 0.015990762040019035
Loss at iteration 1030 : 0.027443524450063705
Loss at iteration 1040 : 0.022576427087187767
Loss at iteration 1050 : 0.02344355545938015
Loss at iteration 1060 : 0.03850031644105911
Loss at iteration 1070 : 0.016611184924840927
Loss at iteration 1080 : 0.021150298416614532
Loss at iteration 1090 : 0.03180811554193497
Loss at iteration 1100 : 0.011046509258449078
Loss at iteration 1110 : 0.016717977821826935
Loss at iteration 1120 : 0.019306927919387817
Loss at iteration 1130 : 0.01760709285736084
Loss at iteration 1140 : 0.02369925007224083
Loss at iteration 1150 : 0.015758924186229706
Loss at iteration 1160 : 0.021609807386994362
Loss at iteration 1170 : 0.02456376515328884
Loss at iteration 1180 : 0.020864922553300858
Loss at iteration 1190 : 0.027315989136695862
Loss at iteration 1200 : 0.016348641365766525
Loss at iteration 1210 : 0.02137790247797966
The SSIM Value is: 0.8070770025253295
The PSNR Value is: 19.930927530924478
the epoch is: 167
Loss at iteration 10 : 0.03286794573068619
Loss at iteration 20 : 0.023249514400959015
Loss at iteration 30 : 0.016374513506889343
Loss at iteration 40 : 0.017836302518844604
Loss at iteration 50 : 0.014449361711740494
Loss at iteration 60 : 0.02213909849524498
Loss at iteration 70 : 0.021685533225536346
Loss at iteration 80 : 0.012359360232949257
Loss at iteration 90 : 0.025371531024575233
Loss at iteration 100 : 0.013056883588433266
Loss at iteration 110 : 0.028740715235471725
Loss at iteration 120 : 0.015655281022191048
Loss at iteration 130 : 0.015395784750580788
Loss at iteration 140 : 0.026858016848564148
Loss at iteration 150 : 0.02312205359339714
Loss at iteration 160 : 0.018895089626312256
Loss at iteration 170 : 0.019944313913583755
Loss at iteration 180 : 0.013486969284713268
Loss at iteration 190 : 0.018690355122089386
Loss at iteration 200 : 0.023761805146932602
Loss at iteration 210 : 0.01750638522207737
Loss at iteration 220 : 0.021119212731719017
Loss at iteration 230 : 0.016658026725053787
Loss at iteration 240 : 0.022409336641430855
Loss at iteration 250 : 0.015251288190484047
Loss at iteration 260 : 0.015607163310050964
Loss at iteration 270 : 0.014761553145945072
Loss at iteration 280 : 0.01182395126670599
Loss at iteration 290 : 0.025734061375260353
Loss at iteration 300 : 0.023813124746084213
Loss at iteration 310 : 0.008431565947830677
Loss at iteration 320 : 0.0185235608369112
Loss at iteration 330 : 0.019540321081876755
Loss at iteration 340 : 0.01683777943253517
Loss at iteration 350 : 0.016797874122858047
Loss at iteration 360 : 0.012400906533002853
Loss at iteration 370 : 0.03314106911420822
Loss at iteration 380 : 0.016537122428417206
Loss at iteration 390 : 0.02267277240753174
Loss at iteration 400 : 0.020635899156332016
Loss at iteration 410 : 0.012744850479066372
Loss at iteration 420 : 0.027905836701393127
Loss at iteration 430 : 0.011425977572798729
Loss at iteration 440 : 0.02107670158147812
Loss at iteration 450 : 0.01554799173027277
Loss at iteration 460 : 0.01805083639919758
Loss at iteration 470 : 0.01769612915813923
Loss at iteration 480 : 0.020815549418330193
Loss at iteration 490 : 0.02420061081647873
Loss at iteration 500 : 0.01794978231191635
Loss at iteration 510 : 0.023019123822450638
Loss at iteration 520 : 0.014925367198884487
Loss at iteration 530 : 0.02248392626643181
Loss at iteration 540 : 0.02161625772714615
Loss at iteration 550 : 0.015645474195480347
Loss at iteration 560 : 0.023084372282028198
Loss at iteration 570 : 0.01818045973777771
Loss at iteration 580 : 0.0251927450299263
Loss at iteration 590 : 0.02300800010561943
Loss at iteration 600 : 0.01588279753923416
Loss at iteration 610 : 0.017627881839871407
Loss at iteration 620 : 0.016950134187936783
Loss at iteration 630 : 0.027423355728387833
Loss at iteration 640 : 0.02746223658323288
Loss at iteration 650 : 0.022243306040763855
Loss at iteration 660 : 0.020678279921412468
Loss at iteration 670 : 0.016170496121048927
Loss at iteration 680 : 0.021309927105903625
Loss at iteration 690 : 0.014782332815229893
Loss at iteration 700 : 0.01361129991710186
Loss at iteration 710 : 0.03959924355149269
Loss at iteration 720 : 0.0152477091178298
Loss at iteration 730 : 0.01828158274292946
Loss at iteration 740 : 0.017889469861984253
Loss at iteration 750 : 0.03549640253186226
Loss at iteration 760 : 0.02390342205762863
Loss at iteration 770 : 0.025379979982972145
Loss at iteration 780 : 0.026305291801691055
Loss at iteration 790 : 0.017349308356642723
Loss at iteration 800 : 0.010297936387360096
Loss at iteration 810 : 0.01740279607474804
Loss at iteration 820 : 0.024737775325775146
Loss at iteration 830 : 0.01965714618563652
Loss at iteration 840 : 0.015653574839234352
Loss at iteration 850 : 0.018346458673477173
Loss at iteration 860 : 0.024563338607549667
Loss at iteration 870 : 0.00994329247623682
Loss at iteration 880 : 0.031168416142463684
Loss at iteration 890 : 0.011702543124556541
Loss at iteration 900 : 0.019287843257188797
Loss at iteration 910 : 0.0211632139980793
Loss at iteration 920 : 0.017565688118338585
Loss at iteration 930 : 0.02036181464791298
Loss at iteration 940 : 0.01337470579892397
Loss at iteration 950 : 0.01568242907524109
Loss at iteration 960 : 0.013318782672286034
Loss at iteration 970 : 0.021037321537733078
Loss at iteration 980 : 0.019102729856967926
Loss at iteration 990 : 0.02578219771385193
Loss at iteration 1000 : 0.016610683873295784
Loss at iteration 1010 : 0.021593160927295685
Loss at iteration 1020 : 0.01382090151309967
Loss at iteration 1030 : 0.01813441514968872
Loss at iteration 1040 : 0.023300016298890114
Loss at iteration 1050 : 0.016974100843071938
Loss at iteration 1060 : 0.01711108162999153
Loss at iteration 1070 : 0.010728409513831139
Loss at iteration 1080 : 0.017458226531744003
Loss at iteration 1090 : 0.022027935832738876
Loss at iteration 1100 : 0.0227662306278944
Loss at iteration 1110 : 0.025527862831950188
Loss at iteration 1120 : 0.015420384705066681
Loss at iteration 1130 : 0.016595132648944855
Loss at iteration 1140 : 0.022038966417312622
Loss at iteration 1150 : 0.02248986065387726
Loss at iteration 1160 : 0.014548891223967075
Loss at iteration 1170 : 0.017362266778945923
Loss at iteration 1180 : 0.016634196043014526
Loss at iteration 1190 : 0.017531313002109528
Loss at iteration 1200 : 0.009884502738714218
Loss at iteration 1210 : 0.011344585567712784
The SSIM Value is: 0.8041289806365967
The PSNR Value is: 20.065962282816567
the highest SSIM value is: 20.065962282816567
the epoch is: 168
Loss at iteration 10 : 0.017156828194856644
Loss at iteration 20 : 0.030459150671958923
Loss at iteration 30 : 0.015184854157269001
Loss at iteration 40 : 0.019954301416873932
Loss at iteration 50 : 0.018110044300556183
Loss at iteration 60 : 0.017433730885386467
Loss at iteration 70 : 0.0285356268286705
Loss at iteration 80 : 0.03795792907476425
Loss at iteration 90 : 0.015510346740484238
Loss at iteration 100 : 0.021791331470012665
Loss at iteration 110 : 0.02665293961763382
Loss at iteration 120 : 0.01032327301800251
Loss at iteration 130 : 0.016008760780096054
Loss at iteration 140 : 0.010248487815260887
Loss at iteration 150 : 0.026368260383605957
Loss at iteration 160 : 0.02385532297194004
Loss at iteration 170 : 0.017143379896879196
Loss at iteration 180 : 0.015813222154974937
Loss at iteration 190 : 0.015895137563347816
Loss at iteration 200 : 0.021137865260243416
Loss at iteration 210 : 0.011002033948898315
Loss at iteration 220 : 0.019924074411392212
Loss at iteration 230 : 0.011519606225192547
Loss at iteration 240 : 0.017432864755392075
Loss at iteration 250 : 0.033444542437791824
Loss at iteration 260 : 0.019335949793457985
Loss at iteration 270 : 0.026620391756296158
Loss at iteration 280 : 0.013819340616464615
Loss at iteration 290 : 0.017924681305885315
Loss at iteration 300 : 0.01017831452190876
Loss at iteration 310 : 0.019439946860074997
Loss at iteration 320 : 0.02866392582654953
Loss at iteration 330 : 0.030836332589387894
Loss at iteration 340 : 0.013293316587805748
Loss at iteration 350 : 0.025713343173265457
Loss at iteration 360 : 0.01389914657920599
Loss at iteration 370 : 0.020009547472000122
Loss at iteration 380 : 0.01458747312426567
Loss at iteration 390 : 0.01347237080335617
Loss at iteration 400 : 0.01461720373481512
Loss at iteration 410 : 0.014184132218360901
Loss at iteration 420 : 0.02416284941136837
Loss at iteration 430 : 0.013378316536545753
Loss at iteration 440 : 0.010855887085199356
Loss at iteration 450 : 0.01767640933394432
Loss at iteration 460 : 0.017192356288433075
Loss at iteration 470 : 0.02686871774494648
Loss at iteration 480 : 0.0197426900267601
Loss at iteration 490 : 0.013518782332539558
Loss at iteration 500 : 0.017486141994595528
Loss at iteration 510 : 0.01899484544992447
Loss at iteration 520 : 0.02191539853811264
Loss at iteration 530 : 0.021206993609666824
Loss at iteration 540 : 0.0290396548807621
Loss at iteration 550 : 0.02413807436823845
Loss at iteration 560 : 0.016933245584368706
Loss at iteration 570 : 0.03054443560540676
Loss at iteration 580 : 0.022223252803087234
Loss at iteration 590 : 0.015894748270511627
Loss at iteration 600 : 0.03411728888750076
Loss at iteration 610 : 0.017084233462810516
Loss at iteration 620 : 0.02639653906226158
Loss at iteration 630 : 0.01175525039434433
Loss at iteration 640 : 0.019591402262449265
Loss at iteration 650 : 0.02231954224407673
Loss at iteration 660 : 0.02186666615307331
Loss at iteration 670 : 0.014953941106796265
Loss at iteration 680 : 0.02488933503627777
Loss at iteration 690 : 0.023960301652550697
Loss at iteration 700 : 0.034397270530462265
Loss at iteration 710 : 0.01307128556072712
Loss at iteration 720 : 0.023841146379709244
Loss at iteration 730 : 0.01643400825560093
Loss at iteration 740 : 0.020434094592928886
Loss at iteration 750 : 0.018361426889896393
Loss at iteration 760 : 0.014277058653533459
Loss at iteration 770 : 0.02844931185245514
Loss at iteration 780 : 0.027326863259077072
Loss at iteration 790 : 0.021334204822778702
Loss at iteration 800 : 0.014632871374487877
Loss at iteration 810 : 0.021275827661156654
Loss at iteration 820 : 0.015732381492853165
Loss at iteration 830 : 0.021452385932207108
Loss at iteration 840 : 0.025133170187473297
Loss at iteration 850 : 0.01657898724079132
Loss at iteration 860 : 0.023563554510474205
Loss at iteration 870 : 0.014980737119913101
Loss at iteration 880 : 0.017280854284763336
Loss at iteration 890 : 0.01652820035815239
Loss at iteration 900 : 0.01651574857532978
Loss at iteration 910 : 0.016923094168305397
Loss at iteration 920 : 0.017196785658597946
Loss at iteration 930 : 0.019209928810596466
Loss at iteration 940 : 0.01588079333305359
Loss at iteration 950 : 0.018517276272177696
Loss at iteration 960 : 0.011761767789721489
Loss at iteration 970 : 0.025887764990329742
Loss at iteration 980 : 0.017383642494678497
Loss at iteration 990 : 0.016807440668344498
Loss at iteration 1000 : 0.017676938325166702
Loss at iteration 1010 : 0.01636141911149025
Loss at iteration 1020 : 0.016292134299874306
Loss at iteration 1030 : 0.010415295138955116
Loss at iteration 1040 : 0.016053957864642143
Loss at iteration 1050 : 0.032119978219270706
Loss at iteration 1060 : 0.027517519891262054
Loss at iteration 1070 : 0.03277145326137543
Loss at iteration 1080 : 0.028158176690340042
Loss at iteration 1090 : 0.014409494586288929
Loss at iteration 1100 : 0.022395245730876923
Loss at iteration 1110 : 0.026397455483675003
Loss at iteration 1120 : 0.016012314707040787
Loss at iteration 1130 : 0.025449290871620178
Loss at iteration 1140 : 0.011740422807633877
Loss at iteration 1150 : 0.016930999234318733
Loss at iteration 1160 : 0.012185975909233093
Loss at iteration 1170 : 0.014150779694318771
Loss at iteration 1180 : 0.017317920923233032
Loss at iteration 1190 : 0.02586561068892479
Loss at iteration 1200 : 0.01880568265914917
Loss at iteration 1210 : 0.03476381674408913
The SSIM Value is: 0.8056830843289693
The PSNR Value is: 19.598763084411623
the epoch is: 169
Loss at iteration 10 : 0.034853577613830566
Loss at iteration 20 : 0.02167516201734543
Loss at iteration 30 : 0.009339939802885056
Loss at iteration 40 : 0.023898005485534668
Loss at iteration 50 : 0.018227338790893555
Loss at iteration 60 : 0.011492092162370682
Loss at iteration 70 : 0.014880834147334099
Loss at iteration 80 : 0.018525617197155952
Loss at iteration 90 : 0.014726423658430576
Loss at iteration 100 : 0.015928834676742554
Loss at iteration 110 : 0.014044690877199173
Loss at iteration 120 : 0.01253872737288475
Loss at iteration 130 : 0.017018886283040047
Loss at iteration 140 : 0.022739730775356293
Loss at iteration 150 : 0.015858866274356842
Loss at iteration 160 : 0.020595630630850792
Loss at iteration 170 : 0.018040595576167107
Loss at iteration 180 : 0.013647103682160378
Loss at iteration 190 : 0.01700148545205593
Loss at iteration 200 : 0.01926267147064209
Loss at iteration 210 : 0.014146033674478531
Loss at iteration 220 : 0.021384701132774353
Loss at iteration 230 : 0.026090938597917557
Loss at iteration 240 : 0.021399909630417824
Loss at iteration 250 : 0.016280632466077805
Loss at iteration 260 : 0.027934480458498
Loss at iteration 270 : 0.02477443590760231
Loss at iteration 280 : 0.01571209914982319
Loss at iteration 290 : 0.012517058290541172
Loss at iteration 300 : 0.019810523837804794
Loss at iteration 310 : 0.017066186293959618
Loss at iteration 320 : 0.020984355360269547
Loss at iteration 330 : 0.02080637589097023
Loss at iteration 340 : 0.016879457980394363
Loss at iteration 350 : 0.01607576012611389
Loss at iteration 360 : 0.03145695850253105
Loss at iteration 370 : 0.029456984251737595
Loss at iteration 380 : 0.017822526395320892
Loss at iteration 390 : 0.022639025002717972
Loss at iteration 400 : 0.014867464080452919
Loss at iteration 410 : 0.010595502331852913
Loss at iteration 420 : 0.014955483376979828
Loss at iteration 430 : 0.017730962485074997
Loss at iteration 440 : 0.022154025733470917
Loss at iteration 450 : 0.015107857994735241
Loss at iteration 460 : 0.02987070381641388
Loss at iteration 470 : 0.029605012387037277
Loss at iteration 480 : 0.012125449255108833
Loss at iteration 490 : 0.01569915935397148
Loss at iteration 500 : 0.02822055295109749
Loss at iteration 510 : 0.026620978489518166
Loss at iteration 520 : 0.012918399646878242
Loss at iteration 530 : 0.025901297107338905
Loss at iteration 540 : 0.012048695236444473
Loss at iteration 550 : 0.018368253484368324
Loss at iteration 560 : 0.019710902124643326
Loss at iteration 570 : 0.01224677637219429
Loss at iteration 580 : 0.021947676315903664
Loss at iteration 590 : 0.027084026485681534
Loss at iteration 600 : 0.01391648780554533
Loss at iteration 610 : 0.03208926320075989
Loss at iteration 620 : 0.024777205660939217
Loss at iteration 630 : 0.023680929094552994
Loss at iteration 640 : 0.02123662456870079
Loss at iteration 650 : 0.02134278230369091
Loss at iteration 660 : 0.014855656772851944
Loss at iteration 670 : 0.01621653512120247
Loss at iteration 680 : 0.010062962770462036
Loss at iteration 690 : 0.020170044153928757
Loss at iteration 700 : 0.02428671531379223
Loss at iteration 710 : 0.01067967340350151
Loss at iteration 720 : 0.018981393426656723
Loss at iteration 730 : 0.012099537067115307
Loss at iteration 740 : 0.015748633071780205
Loss at iteration 750 : 0.017163077369332314
Loss at iteration 760 : 0.026077751070261
Loss at iteration 770 : 0.01954091154038906
Loss at iteration 780 : 0.021107643842697144
Loss at iteration 790 : 0.0216602124273777
Loss at iteration 800 : 0.017208056524395943
Loss at iteration 810 : 0.013374468311667442
Loss at iteration 820 : 0.017384447157382965
Loss at iteration 830 : 0.010746238753199577
Loss at iteration 840 : 0.019713938236236572
Loss at iteration 850 : 0.02367459610104561
Loss at iteration 860 : 0.015242436900734901
Loss at iteration 870 : 0.018995746970176697
Loss at iteration 880 : 0.022093504667282104
Loss at iteration 890 : 0.016505513340234756
Loss at iteration 900 : 0.01770642027258873
Loss at iteration 910 : 0.02229396626353264
Loss at iteration 920 : 0.0258796326816082
Loss at iteration 930 : 0.01793896220624447
Loss at iteration 940 : 0.014794828370213509
Loss at iteration 950 : 0.02090149186551571
Loss at iteration 960 : 0.019341621547937393
Loss at iteration 970 : 0.026639923453330994
Loss at iteration 980 : 0.02216215804219246
Loss at iteration 990 : 0.020221177488565445
Loss at iteration 1000 : 0.029728922992944717
Loss at iteration 1010 : 0.017460033297538757
Loss at iteration 1020 : 0.017959799617528915
Loss at iteration 1030 : 0.01895000785589218
Loss at iteration 1040 : 0.022699937224388123
Loss at iteration 1050 : 0.009953186847269535
Loss at iteration 1060 : 0.020360805094242096
Loss at iteration 1070 : 0.02009645849466324
Loss at iteration 1080 : 0.021713605150580406
Loss at iteration 1090 : 0.02757512405514717
Loss at iteration 1100 : 0.013357479125261307
Loss at iteration 1110 : 0.019701482728123665
Loss at iteration 1120 : 0.018232397735118866
Loss at iteration 1130 : 0.012017038650810719
Loss at iteration 1140 : 0.012370426207780838
Loss at iteration 1150 : 0.014422805979847908
Loss at iteration 1160 : 0.022011645138263702
Loss at iteration 1170 : 0.02115015685558319
Loss at iteration 1180 : 0.020923592150211334
Loss at iteration 1190 : 0.02866709604859352
Loss at iteration 1200 : 0.02363860048353672
Loss at iteration 1210 : 0.013902377337217331
The SSIM Value is: 0.7989389181137085
The PSNR Value is: 19.771878306070963
the epoch is: 170
Loss at iteration 10 : 0.029976453632116318
Loss at iteration 20 : 0.024482451379299164
Loss at iteration 30 : 0.012881535105407238
Loss at iteration 40 : 0.02013874053955078
Loss at iteration 50 : 0.02222047559916973
Loss at iteration 60 : 0.01844203844666481
Loss at iteration 70 : 0.02755211479961872
Loss at iteration 80 : 0.019427582621574402
Loss at iteration 90 : 0.02256372943520546
Loss at iteration 100 : 0.019737880676984787
Loss at iteration 110 : 0.0192545335739851
Loss at iteration 120 : 0.01986117660999298
Loss at iteration 130 : 0.016459021717309952
Loss at iteration 140 : 0.02238476648926735
Loss at iteration 150 : 0.020054608583450317
Loss at iteration 160 : 0.018614642322063446
Loss at iteration 170 : 0.030148722231388092
Loss at iteration 180 : 0.0263382438570261
Loss at iteration 190 : 0.02006547525525093
Loss at iteration 200 : 0.017911212518811226
Loss at iteration 210 : 0.016728095710277557
Loss at iteration 220 : 0.01986098475754261
Loss at iteration 230 : 0.021931622177362442
Loss at iteration 240 : 0.02302691712975502
Loss at iteration 250 : 0.014821499586105347
Loss at iteration 260 : 0.023447439074516296
Loss at iteration 270 : 0.019896648824214935
Loss at iteration 280 : 0.02994396537542343
Loss at iteration 290 : 0.019183358177542686
Loss at iteration 300 : 0.014779753983020782
Loss at iteration 310 : 0.012178000062704086
Loss at iteration 320 : 0.018315566703677177
Loss at iteration 330 : 0.029199538752436638
Loss at iteration 340 : 0.020565349608659744
Loss at iteration 350 : 0.016479944810271263
Loss at iteration 360 : 0.02490641549229622
Loss at iteration 370 : 0.01846245303750038
Loss at iteration 380 : 0.02387327328324318
Loss at iteration 390 : 0.016480116173624992
Loss at iteration 400 : 0.02224358357489109
Loss at iteration 410 : 0.013935407623648643
Loss at iteration 420 : 0.013286344707012177
Loss at iteration 430 : 0.023233242332935333
Loss at iteration 440 : 0.026637263596057892
Loss at iteration 450 : 0.027360282838344574
Loss at iteration 460 : 0.0181589312851429
Loss at iteration 470 : 0.018466390669345856
Loss at iteration 480 : 0.019344814121723175
Loss at iteration 490 : 0.016390923410654068
Loss at iteration 500 : 0.021910566836595535
Loss at iteration 510 : 0.010078881867229939
Loss at iteration 520 : 0.03911110386252403
Loss at iteration 530 : 0.02583554945886135
Loss at iteration 540 : 0.013247506693005562
Loss at iteration 550 : 0.022675232961773872
Loss at iteration 560 : 0.017261028289794922
Loss at iteration 570 : 0.022008132189512253
Loss at iteration 580 : 0.020268991589546204
Loss at iteration 590 : 0.018789999186992645
Loss at iteration 600 : 0.02698923461139202
Loss at iteration 610 : 0.03436960279941559
Loss at iteration 620 : 0.012123175896704197
Loss at iteration 630 : 0.0249593798071146
Loss at iteration 640 : 0.031183645129203796
Loss at iteration 650 : 0.014101024717092514
Loss at iteration 660 : 0.01606101170182228
Loss at iteration 670 : 0.02174014411866665
Loss at iteration 680 : 0.02942465990781784
Loss at iteration 690 : 0.028381425887346268
Loss at iteration 700 : 0.024901334196329117
Loss at iteration 710 : 0.019655577838420868
Loss at iteration 720 : 0.015009971335530281
Loss at iteration 730 : 0.010343785397708416
Loss at iteration 740 : 0.0220924261957407
Loss at iteration 750 : 0.02253950573503971
Loss at iteration 760 : 0.016632387414574623
Loss at iteration 770 : 0.01880992203950882
Loss at iteration 780 : 0.017331121489405632
Loss at iteration 790 : 0.015485215932130814
Loss at iteration 800 : 0.029870763421058655
Loss at iteration 810 : 0.014723027125000954
Loss at iteration 820 : 0.01721741072833538
Loss at iteration 830 : 0.021054554730653763
Loss at iteration 840 : 0.01818985864520073
Loss at iteration 850 : 0.015349967405200005
Loss at iteration 860 : 0.016330359503626823
Loss at iteration 870 : 0.027344660833477974
Loss at iteration 880 : 0.017275642603635788
Loss at iteration 890 : 0.020474744960665703
Loss at iteration 900 : 0.014723077416419983
Loss at iteration 910 : 0.01724228262901306
Loss at iteration 920 : 0.016408761963248253
Loss at iteration 930 : 0.010205652564764023
Loss at iteration 940 : 0.01319478452205658
Loss at iteration 950 : 0.01998242735862732
Loss at iteration 960 : 0.018725953996181488
Loss at iteration 970 : 0.024368591606616974
Loss at iteration 980 : 0.022633938118815422
Loss at iteration 990 : 0.02587023191154003
Loss at iteration 1000 : 0.024208957329392433
Loss at iteration 1010 : 0.017453784123063087
Loss at iteration 1020 : 0.027594933286309242
Loss at iteration 1030 : 0.01497852336615324
Loss at iteration 1040 : 0.01732289418578148
Loss at iteration 1050 : 0.02581622265279293
Loss at iteration 1060 : 0.01089819148182869
Loss at iteration 1070 : 0.0202037300914526
Loss at iteration 1080 : 0.02237750217318535
Loss at iteration 1090 : 0.016955655068159103
Loss at iteration 1100 : 0.017717139795422554
Loss at iteration 1110 : 0.02145416848361492
Loss at iteration 1120 : 0.017406824976205826
Loss at iteration 1130 : 0.02212076261639595
Loss at iteration 1140 : 0.01855342462658882
Loss at iteration 1150 : 0.014557961374521255
Loss at iteration 1160 : 0.018952947109937668
Loss at iteration 1170 : 0.02811378985643387
Loss at iteration 1180 : 0.020002517849206924
Loss at iteration 1190 : 0.014880637638270855
Loss at iteration 1200 : 0.014651244506239891
Loss at iteration 1210 : 0.01802673563361168
The SSIM Value is: 0.8048893332481384
The PSNR Value is: 19.76323846181234
the epoch is: 171
Loss at iteration 10 : 0.014280370436608791
Loss at iteration 20 : 0.009940944612026215
Loss at iteration 30 : 0.019619163125753403
Loss at iteration 40 : 0.015396054834127426
Loss at iteration 50 : 0.014757167547941208
Loss at iteration 60 : 0.025686930865049362
Loss at iteration 70 : 0.008659791201353073
Loss at iteration 80 : 0.020364968106150627
Loss at iteration 90 : 0.024239912629127502
Loss at iteration 100 : 0.01156242098659277
Loss at iteration 110 : 0.020660368725657463
Loss at iteration 120 : 0.02126738615334034
Loss at iteration 130 : 0.016338787972927094
Loss at iteration 140 : 0.016667712479829788
Loss at iteration 150 : 0.018531668931245804
Loss at iteration 160 : 0.031000938266515732
Loss at iteration 170 : 0.013688762672245502
Loss at iteration 180 : 0.01380394771695137
Loss at iteration 190 : 0.024726014584302902
Loss at iteration 200 : 0.021961743012070656
Loss at iteration 210 : 0.01727352663874626
Loss at iteration 220 : 0.02948758751153946
Loss at iteration 230 : 0.02344251610338688
Loss at iteration 240 : 0.020427772775292397
Loss at iteration 250 : 0.019700417295098305
Loss at iteration 260 : 0.018615979701280594
Loss at iteration 270 : 0.025915049016475677
Loss at iteration 280 : 0.016389112919569016
Loss at iteration 290 : 0.02211538515985012
Loss at iteration 300 : 0.029370397329330444
Loss at iteration 310 : 0.013966256752610207
Loss at iteration 320 : 0.0253477580845356
Loss at iteration 330 : 0.019670218229293823
Loss at iteration 340 : 0.010887065902352333
Loss at iteration 350 : 0.02723313868045807
Loss at iteration 360 : 0.015973597764968872
Loss at iteration 370 : 0.018073730170726776
Loss at iteration 380 : 0.012384459376335144
Loss at iteration 390 : 0.008580615743994713
Loss at iteration 400 : 0.021135132759809494
Loss at iteration 410 : 0.014381710439920425
Loss at iteration 420 : 0.021773535758256912
Loss at iteration 430 : 0.021273666992783546
Loss at iteration 440 : 0.014929492026567459
Loss at iteration 450 : 0.019490761682391167
Loss at iteration 460 : 0.02138625830411911
Loss at iteration 470 : 0.019828392192721367
Loss at iteration 480 : 0.018567446619272232
Loss at iteration 490 : 0.02774057164788246
Loss at iteration 500 : 0.01817598193883896
Loss at iteration 510 : 0.018757672980427742
Loss at iteration 520 : 0.02676326036453247
Loss at iteration 530 : 0.010151278227567673
Loss at iteration 540 : 0.018318943679332733
Loss at iteration 550 : 0.024081163108348846
Loss at iteration 560 : 0.013721181079745293
Loss at iteration 570 : 0.025451168417930603
Loss at iteration 580 : 0.016925156116485596
Loss at iteration 590 : 0.021869540214538574
Loss at iteration 600 : 0.019262690097093582
Loss at iteration 610 : 0.017496710643172264
Loss at iteration 620 : 0.02349073998630047
Loss at iteration 630 : 0.018061254173517227
Loss at iteration 640 : 0.03046710230410099
Loss at iteration 650 : 0.016074012964963913
Loss at iteration 660 : 0.01222548633813858
Loss at iteration 670 : 0.014833884313702583
Loss at iteration 680 : 0.022404929623007774
Loss at iteration 690 : 0.020418312400579453
Loss at iteration 700 : 0.019975990056991577
Loss at iteration 710 : 0.023366084322333336
Loss at iteration 720 : 0.015206124633550644
Loss at iteration 730 : 0.009712472558021545
Loss at iteration 740 : 0.01706840470433235
Loss at iteration 750 : 0.021252423524856567
Loss at iteration 760 : 0.020786749199032784
Loss at iteration 770 : 0.011319827288389206
Loss at iteration 780 : 0.03510073199868202
Loss at iteration 790 : 0.016435634344816208
Loss at iteration 800 : 0.013533242046833038
Loss at iteration 810 : 0.021413784474134445
Loss at iteration 820 : 0.014932466670870781
Loss at iteration 830 : 0.023466985672712326
Loss at iteration 840 : 0.014542805962264538
Loss at iteration 850 : 0.02026592195034027
Loss at iteration 860 : 0.016508402302861214
Loss at iteration 870 : 0.01688915118575096
Loss at iteration 880 : 0.016607359051704407
Loss at iteration 890 : 0.01303328201174736
Loss at iteration 900 : 0.01879177801311016
Loss at iteration 910 : 0.015980396419763565
Loss at iteration 920 : 0.027901282534003258
Loss at iteration 930 : 0.02099081315100193
Loss at iteration 940 : 0.022347962483763695
Loss at iteration 950 : 0.02062363550066948
Loss at iteration 960 : 0.022604426369071007
Loss at iteration 970 : 0.01670975238084793
Loss at iteration 980 : 0.019871892407536507
Loss at iteration 990 : 0.04105762392282486
Loss at iteration 1000 : 0.020980767905712128
Loss at iteration 1010 : 0.02564264088869095
Loss at iteration 1020 : 0.013210496865212917
Loss at iteration 1030 : 0.01925450749695301
Loss at iteration 1040 : 0.02330024167895317
Loss at iteration 1050 : 0.01538475789129734
Loss at iteration 1060 : 0.02010292559862137
Loss at iteration 1070 : 0.037974581122398376
Loss at iteration 1080 : 0.014308142475783825
Loss at iteration 1090 : 0.01358792558312416
Loss at iteration 1100 : 0.016819149255752563
Loss at iteration 1110 : 0.022712966427206993
Loss at iteration 1120 : 0.016847403720021248
Loss at iteration 1130 : 0.020256109535694122
Loss at iteration 1140 : 0.022810669615864754
Loss at iteration 1150 : 0.01242971234023571
Loss at iteration 1160 : 0.024210061877965927
Loss at iteration 1170 : 0.02330704778432846
Loss at iteration 1180 : 0.012105128727853298
Loss at iteration 1190 : 0.015959471464157104
Loss at iteration 1200 : 0.01165818888694048
Loss at iteration 1210 : 0.020517712458968163
The SSIM Value is: 0.8045028368631999
The PSNR Value is: 19.381001154581707
the epoch is: 172
Loss at iteration 10 : 0.019727297127246857
Loss at iteration 20 : 0.023587683215737343
Loss at iteration 30 : 0.014405770227313042
Loss at iteration 40 : 0.018950289115309715
Loss at iteration 50 : 0.02814687229692936
Loss at iteration 60 : 0.0159333236515522
Loss at iteration 70 : 0.020733855664730072
Loss at iteration 80 : 0.023400621488690376
Loss at iteration 90 : 0.015345609746873379
Loss at iteration 100 : 0.0121300108730793
Loss at iteration 110 : 0.014261890202760696
Loss at iteration 120 : 0.012733967043459415
Loss at iteration 130 : 0.010203542187809944
Loss at iteration 140 : 0.019269533455371857
Loss at iteration 150 : 0.02263936772942543
Loss at iteration 160 : 0.02032865583896637
Loss at iteration 170 : 0.03144782409071922
Loss at iteration 180 : 0.019101155921816826
Loss at iteration 190 : 0.018561245873570442
Loss at iteration 200 : 0.010976646095514297
Loss at iteration 210 : 0.013847803696990013
Loss at iteration 220 : 0.01094873808324337
Loss at iteration 230 : 0.022574055939912796
Loss at iteration 240 : 0.019411996006965637
Loss at iteration 250 : 0.02977875806391239
Loss at iteration 260 : 0.0209817998111248
Loss at iteration 270 : 0.01844654604792595
Loss at iteration 280 : 0.024815328419208527
Loss at iteration 290 : 0.022840218618512154
Loss at iteration 300 : 0.029388893395662308
Loss at iteration 310 : 0.023397235199809074
Loss at iteration 320 : 0.02160794287919998
Loss at iteration 330 : 0.016430804505944252
Loss at iteration 340 : 0.011151570826768875
Loss at iteration 350 : 0.022075634449720383
Loss at iteration 360 : 0.011646842584013939
Loss at iteration 370 : 0.019392866641283035
Loss at iteration 380 : 0.035205237567424774
Loss at iteration 390 : 0.030454715713858604
Loss at iteration 400 : 0.020769406110048294
Loss at iteration 410 : 0.019186273217201233
Loss at iteration 420 : 0.015633603557944298
Loss at iteration 430 : 0.01529918797314167
Loss at iteration 440 : 0.018087103962898254
Loss at iteration 450 : 0.018481019884347916
Loss at iteration 460 : 0.010076508857309818
Loss at iteration 470 : 0.03468601405620575
Loss at iteration 480 : 0.031488556414842606
Loss at iteration 490 : 0.019031036645174026
Loss at iteration 500 : 0.016796693205833435
Loss at iteration 510 : 0.016471702605485916
Loss at iteration 520 : 0.014726593159139156
Loss at iteration 530 : 0.022153476253151894
Loss at iteration 540 : 0.03993266820907593
Loss at iteration 550 : 0.017815351486206055
Loss at iteration 560 : 0.01911499723792076
Loss at iteration 570 : 0.016011716797947884
Loss at iteration 580 : 0.02312481589615345
Loss at iteration 590 : 0.01466912217438221
Loss at iteration 600 : 0.01723862998187542
Loss at iteration 610 : 0.014733152464032173
Loss at iteration 620 : 0.017974546179175377
Loss at iteration 630 : 0.028388161212205887
Loss at iteration 640 : 0.019243240356445312
Loss at iteration 650 : 0.019879503175616264
Loss at iteration 660 : 0.017309987917542458
Loss at iteration 670 : 0.015751825645565987
Loss at iteration 680 : 0.020146001130342484
Loss at iteration 690 : 0.011855719611048698
Loss at iteration 700 : 0.017413429915905
Loss at iteration 710 : 0.017291193827986717
Loss at iteration 720 : 0.018363751471042633
Loss at iteration 730 : 0.018840674310922623
Loss at iteration 740 : 0.024443577975034714
Loss at iteration 750 : 0.018285252153873444
Loss at iteration 760 : 0.01745627447962761
Loss at iteration 770 : 0.02579602599143982
Loss at iteration 780 : 0.02195771038532257
Loss at iteration 790 : 0.01364478562027216
Loss at iteration 800 : 0.012922767549753189
Loss at iteration 810 : 0.023621266707777977
Loss at iteration 820 : 0.014916108921170235
Loss at iteration 830 : 0.027230773121118546
Loss at iteration 840 : 0.01896187663078308
Loss at iteration 850 : 0.01846640557050705
Loss at iteration 860 : 0.0262946505099535
Loss at iteration 870 : 0.018622668460011482
Loss at iteration 880 : 0.014285572804510593
Loss at iteration 890 : 0.03127578645944595
Loss at iteration 900 : 0.018149390816688538
Loss at iteration 910 : 0.010228564962744713
Loss at iteration 920 : 0.01495723519474268
Loss at iteration 930 : 0.017564095556735992
Loss at iteration 940 : 0.024255581200122833
Loss at iteration 950 : 0.02232293412089348
Loss at iteration 960 : 0.01629098877310753
Loss at iteration 970 : 0.014923413284122944
Loss at iteration 980 : 0.030757956206798553
Loss at iteration 990 : 0.015373832546174526
Loss at iteration 1000 : 0.027225371450185776
Loss at iteration 1010 : 0.016348611563444138
Loss at iteration 1020 : 0.021439936012029648
Loss at iteration 1030 : 0.015238936990499496
Loss at iteration 1040 : 0.033221449702978134
Loss at iteration 1050 : 0.011409135535359383
Loss at iteration 1060 : 0.018213817849755287
Loss at iteration 1070 : 0.024046294391155243
Loss at iteration 1080 : 0.018451489508152008
Loss at iteration 1090 : 0.014154006727039814
Loss at iteration 1100 : 0.02115911804139614
Loss at iteration 1110 : 0.01630714163184166
Loss at iteration 1120 : 0.00927657913416624
Loss at iteration 1130 : 0.014896189793944359
Loss at iteration 1140 : 0.012717243283987045
Loss at iteration 1150 : 0.01688181236386299
Loss at iteration 1160 : 0.022422872483730316
Loss at iteration 1170 : 0.028494829311966896
Loss at iteration 1180 : 0.022187571972608566
Loss at iteration 1190 : 0.011645343154668808
Loss at iteration 1200 : 0.01761440373957157
Loss at iteration 1210 : 0.023185497149825096
The SSIM Value is: 0.8046349485715231
The PSNR Value is: 19.944195048014322
the epoch is: 173
Loss at iteration 10 : 0.02254663221538067
Loss at iteration 20 : 0.01893112249672413
Loss at iteration 30 : 0.01266484148800373
Loss at iteration 40 : 0.027838442474603653
Loss at iteration 50 : 0.014933187514543533
Loss at iteration 60 : 0.024322882294654846
Loss at iteration 70 : 0.012088241055607796
Loss at iteration 80 : 0.028900373727083206
Loss at iteration 90 : 0.021710187196731567
Loss at iteration 100 : 0.01828918606042862
Loss at iteration 110 : 0.023911140859127045
Loss at iteration 120 : 0.01968708634376526
Loss at iteration 130 : 0.020612293854355812
Loss at iteration 140 : 0.03493449091911316
Loss at iteration 150 : 0.016110287979245186
Loss at iteration 160 : 0.014198986813426018
Loss at iteration 170 : 0.02080649882555008
Loss at iteration 180 : 0.024896793067455292
Loss at iteration 190 : 0.023175185546278954
Loss at iteration 200 : 0.017671458423137665
Loss at iteration 210 : 0.019404396414756775
Loss at iteration 220 : 0.034725122153759
Loss at iteration 230 : 0.02555108442902565
Loss at iteration 240 : 0.015981480479240417
Loss at iteration 250 : 0.011656628921627998
Loss at iteration 260 : 0.01351486798375845
Loss at iteration 270 : 0.027477167546749115
Loss at iteration 280 : 0.013500992208719254
Loss at iteration 290 : 0.024290740489959717
Loss at iteration 300 : 0.02109445072710514
Loss at iteration 310 : 0.023468147963285446
Loss at iteration 320 : 0.01873786374926567
Loss at iteration 330 : 0.01487939152866602
Loss at iteration 340 : 0.014182135462760925
Loss at iteration 350 : 0.012920990586280823
Loss at iteration 360 : 0.019437680020928383
Loss at iteration 370 : 0.017578914761543274
Loss at iteration 380 : 0.019260793924331665
Loss at iteration 390 : 0.016971806064248085
Loss at iteration 400 : 0.019151505082845688
Loss at iteration 410 : 0.014104923233389854
Loss at iteration 420 : 0.02256794646382332
Loss at iteration 430 : 0.01643446832895279
Loss at iteration 440 : 0.01618209481239319
Loss at iteration 450 : 0.010558954440057278
Loss at iteration 460 : 0.02261938527226448
Loss at iteration 470 : 0.01363890990614891
Loss at iteration 480 : 0.014019522815942764
Loss at iteration 490 : 0.01569320261478424
Loss at iteration 500 : 0.01333724707365036
Loss at iteration 510 : 0.01167629286646843
Loss at iteration 520 : 0.021799039095640182
Loss at iteration 530 : 0.01569288596510887
Loss at iteration 540 : 0.019681416451931
Loss at iteration 550 : 0.020871909335255623
Loss at iteration 560 : 0.012849325314164162
Loss at iteration 570 : 0.04140664264559746
Loss at iteration 580 : 0.016084089875221252
Loss at iteration 590 : 0.01338473055511713
Loss at iteration 600 : 0.03353724628686905
Loss at iteration 610 : 0.02281351387500763
Loss at iteration 620 : 0.021848570555448532
Loss at iteration 630 : 0.014178959652781487
Loss at iteration 640 : 0.012113883160054684
Loss at iteration 650 : 0.013746926560997963
Loss at iteration 660 : 0.009015260264277458
Loss at iteration 670 : 0.013806382194161415
Loss at iteration 680 : 0.03358249366283417
Loss at iteration 690 : 0.01082918606698513
Loss at iteration 700 : 0.025481753051280975
Loss at iteration 710 : 0.019388653337955475
Loss at iteration 720 : 0.024941617622971535
Loss at iteration 730 : 0.01974988728761673
Loss at iteration 740 : 0.0165580864995718
Loss at iteration 750 : 0.01537240855395794
Loss at iteration 760 : 0.015128695406019688
Loss at iteration 770 : 0.02745729684829712
Loss at iteration 780 : 0.03530845791101456
Loss at iteration 790 : 0.02938258647918701
Loss at iteration 800 : 0.023773174732923508
Loss at iteration 810 : 0.02226690575480461
Loss at iteration 820 : 0.009341223165392876
Loss at iteration 830 : 0.011684359051287174
Loss at iteration 840 : 0.012174805626273155
Loss at iteration 850 : 0.012962959706783295
Loss at iteration 860 : 0.018228799104690552
Loss at iteration 870 : 0.028515826910734177
Loss at iteration 880 : 0.013421102426946163
Loss at iteration 890 : 0.01649772748351097
Loss at iteration 900 : 0.015210798941552639
Loss at iteration 910 : 0.016057245433330536
Loss at iteration 920 : 0.021974049508571625
Loss at iteration 930 : 0.025799773633480072
Loss at iteration 940 : 0.01864330843091011
Loss at iteration 950 : 0.023553267121315002
Loss at iteration 960 : 0.020820308476686478
Loss at iteration 970 : 0.014876289293169975
Loss at iteration 980 : 0.017739295959472656
Loss at iteration 990 : 0.014314173720777035
Loss at iteration 1000 : 0.018774600699543953
Loss at iteration 1010 : 0.015439523383975029
Loss at iteration 1020 : 0.011190606281161308
Loss at iteration 1030 : 0.029002297669649124
Loss at iteration 1040 : 0.017387211322784424
Loss at iteration 1050 : 0.023256581276655197
Loss at iteration 1060 : 0.01937134936451912
Loss at iteration 1070 : 0.022974221035838127
Loss at iteration 1080 : 0.016766589134931564
Loss at iteration 1090 : 0.019914763048291206
Loss at iteration 1100 : 0.015968382358551025
Loss at iteration 1110 : 0.01556811947375536
Loss at iteration 1120 : 0.02008676342666149
Loss at iteration 1130 : 0.019027162343263626
Loss at iteration 1140 : 0.03777845948934555
Loss at iteration 1150 : 0.015941884368658066
Loss at iteration 1160 : 0.01579413376748562
Loss at iteration 1170 : 0.018909264355897903
Loss at iteration 1180 : 0.01765013299882412
Loss at iteration 1190 : 0.012158838100731373
Loss at iteration 1200 : 0.012813735753297806
Loss at iteration 1210 : 0.01837613433599472
The SSIM Value is: 0.8089179635047913
The PSNR Value is: 19.968561299641927
the epoch is: 174
Loss at iteration 10 : 0.012822072952985764
Loss at iteration 20 : 0.01478603295981884
Loss at iteration 30 : 0.023132450878620148
Loss at iteration 40 : 0.024985231459140778
Loss at iteration 50 : 0.019464392215013504
Loss at iteration 60 : 0.019026275724172592
Loss at iteration 70 : 0.01805339753627777
Loss at iteration 80 : 0.02374487742781639
Loss at iteration 90 : 0.012031891383230686
Loss at iteration 100 : 0.01377177331596613
Loss at iteration 110 : 0.03275550156831741
Loss at iteration 120 : 0.018270526081323624
Loss at iteration 130 : 0.015041091479361057
Loss at iteration 140 : 0.02031492441892624
Loss at iteration 150 : 0.018266208469867706
Loss at iteration 160 : 0.02254357933998108
Loss at iteration 170 : 0.012563731521368027
Loss at iteration 180 : 0.03564200550317764
Loss at iteration 190 : 0.02434750460088253
Loss at iteration 200 : 0.028997916728258133
Loss at iteration 210 : 0.019079703837633133
Loss at iteration 220 : 0.017651788890361786
Loss at iteration 230 : 0.021375348791480064
Loss at iteration 240 : 0.01795804128050804
Loss at iteration 250 : 0.014414023607969284
Loss at iteration 260 : 0.021095113828778267
Loss at iteration 270 : 0.019734730944037437
Loss at iteration 280 : 0.013254170306026936
Loss at iteration 290 : 0.018272170796990395
Loss at iteration 300 : 0.019323274493217468
Loss at iteration 310 : 0.01460975967347622
Loss at iteration 320 : 0.018097948282957077
Loss at iteration 330 : 0.015794485807418823
Loss at iteration 340 : 0.017993636429309845
Loss at iteration 350 : 0.01611621305346489
Loss at iteration 360 : 0.0280316062271595
Loss at iteration 370 : 0.021098120138049126
Loss at iteration 380 : 0.025987016037106514
Loss at iteration 390 : 0.021157938987016678
Loss at iteration 400 : 0.023445310071110725
Loss at iteration 410 : 0.016407255083322525
Loss at iteration 420 : 0.019010882824659348
Loss at iteration 430 : 0.01224592700600624
Loss at iteration 440 : 0.01939712092280388
Loss at iteration 450 : 0.021640511229634285
Loss at iteration 460 : 0.01984398066997528
Loss at iteration 470 : 0.011966712772846222
Loss at iteration 480 : 0.014147674664855003
Loss at iteration 490 : 0.021114017814397812
Loss at iteration 500 : 0.016947630792856216
Loss at iteration 510 : 0.01760534569621086
Loss at iteration 520 : 0.028462640941143036
Loss at iteration 530 : 0.016748620197176933
Loss at iteration 540 : 0.01870795339345932
Loss at iteration 550 : 0.024396810680627823
Loss at iteration 560 : 0.01202155277132988
Loss at iteration 570 : 0.016279399394989014
Loss at iteration 580 : 0.015348898246884346
Loss at iteration 590 : 0.02457910031080246
Loss at iteration 600 : 0.01928146556019783
Loss at iteration 610 : 0.012096023187041283
Loss at iteration 620 : 0.026895595714449883
Loss at iteration 630 : 0.017959412187337875
Loss at iteration 640 : 0.017599845305085182
Loss at iteration 650 : 0.01628195121884346
Loss at iteration 660 : 0.01159519050270319
Loss at iteration 670 : 0.010651951655745506
Loss at iteration 680 : 0.01979154720902443
Loss at iteration 690 : 0.032860852777957916
Loss at iteration 700 : 0.01963522657752037
Loss at iteration 710 : 0.017094101756811142
Loss at iteration 720 : 0.016254419460892677
Loss at iteration 730 : 0.020899875089526176
Loss at iteration 740 : 0.019253026694059372
Loss at iteration 750 : 0.020749982446432114
Loss at iteration 760 : 0.01712905243039131
Loss at iteration 770 : 0.022450968623161316
Loss at iteration 780 : 0.017878996208310127
Loss at iteration 790 : 0.015514872968196869
Loss at iteration 800 : 0.012794427573680878
Loss at iteration 810 : 0.026664402335882187
Loss at iteration 820 : 0.021034417673945427
Loss at iteration 830 : 0.014137238264083862
Loss at iteration 840 : 0.027403410524129868
Loss at iteration 850 : 0.018376676365733147
Loss at iteration 860 : 0.03251928836107254
Loss at iteration 870 : 0.017620764672756195
Loss at iteration 880 : 0.012033659964799881
Loss at iteration 890 : 0.016700053587555885
Loss at iteration 900 : 0.023595184087753296
Loss at iteration 910 : 0.014462461695075035
Loss at iteration 920 : 0.01885398104786873
Loss at iteration 930 : 0.02450440637767315
Loss at iteration 940 : 0.017131490632891655
Loss at iteration 950 : 0.01586754247546196
Loss at iteration 960 : 0.015231568366289139
Loss at iteration 970 : 0.026939857751131058
Loss at iteration 980 : 0.01847229339182377
Loss at iteration 990 : 0.016467303037643433
Loss at iteration 1000 : 0.027278752997517586
Loss at iteration 1010 : 0.019768936559557915
Loss at iteration 1020 : 0.02237701043486595
Loss at iteration 1030 : 0.029649168252944946
Loss at iteration 1040 : 0.019851187244057655
Loss at iteration 1050 : 0.02348969131708145
Loss at iteration 1060 : 0.016084402799606323
Loss at iteration 1070 : 0.016309453174471855
Loss at iteration 1080 : 0.019770124927163124
Loss at iteration 1090 : 0.01705195941030979
Loss at iteration 1100 : 0.016637180000543594
Loss at iteration 1110 : 0.023492569103837013
Loss at iteration 1120 : 0.015899240970611572
Loss at iteration 1130 : 0.030870867893099785
Loss at iteration 1140 : 0.018109729513525963
Loss at iteration 1150 : 0.03026292473077774
Loss at iteration 1160 : 0.024287987500429153
Loss at iteration 1170 : 0.01725376397371292
Loss at iteration 1180 : 0.020259493961930275
Loss at iteration 1190 : 0.022019952535629272
Loss at iteration 1200 : 0.03156394138932228
Loss at iteration 1210 : 0.017165400087833405
The SSIM Value is: 0.8034000635147095
The PSNR Value is: 18.9398707707723
the epoch is: 175
Loss at iteration 10 : 0.020729977637529373
Loss at iteration 20 : 0.010193001478910446
Loss at iteration 30 : 0.017890917137265205
Loss at iteration 40 : 0.022494956851005554
Loss at iteration 50 : 0.019639628008008003
Loss at iteration 60 : 0.013764018192887306
Loss at iteration 70 : 0.031004304066300392
Loss at iteration 80 : 0.020352039486169815
Loss at iteration 90 : 0.016307134181261063
Loss at iteration 100 : 0.022110184654593468
Loss at iteration 110 : 0.025331620126962662
Loss at iteration 120 : 0.02329869009554386
Loss at iteration 130 : 0.015683915466070175
Loss at iteration 140 : 0.026060495525598526
Loss at iteration 150 : 0.023013293743133545
Loss at iteration 160 : 0.017511196434497833
Loss at iteration 170 : 0.019612684845924377
Loss at iteration 180 : 0.016636524349451065
Loss at iteration 190 : 0.017818665131926537
Loss at iteration 200 : 0.01936909928917885
Loss at iteration 210 : 0.022589117288589478
Loss at iteration 220 : 0.03050091490149498
Loss at iteration 230 : 0.020140759646892548
Loss at iteration 240 : 0.027624521404504776
Loss at iteration 250 : 0.028066206723451614
Loss at iteration 260 : 0.015835879370570183
Loss at iteration 270 : 0.017039693892002106
Loss at iteration 280 : 0.019494086503982544
Loss at iteration 290 : 0.018835466355085373
Loss at iteration 300 : 0.01817133277654648
Loss at iteration 310 : 0.022578885778784752
Loss at iteration 320 : 0.022224999964237213
Loss at iteration 330 : 0.016891399398446083
Loss at iteration 340 : 0.023022135719656944
Loss at iteration 350 : 0.01616646908223629
Loss at iteration 360 : 0.012666949070990086
Loss at iteration 370 : 0.018066158518195152
Loss at iteration 380 : 0.019849726930260658
Loss at iteration 390 : 0.01148915197700262
Loss at iteration 400 : 0.014234780333936214
Loss at iteration 410 : 0.014715578407049179
Loss at iteration 420 : 0.014939753338694572
Loss at iteration 430 : 0.017363470047712326
Loss at iteration 440 : 0.02379123866558075
Loss at iteration 450 : 0.016138216480612755
Loss at iteration 460 : 0.015113158151507378
Loss at iteration 470 : 0.025108162313699722
Loss at iteration 480 : 0.019345996901392937
Loss at iteration 490 : 0.01879429817199707
Loss at iteration 500 : 0.027071326971054077
Loss at iteration 510 : 0.022123444825410843
Loss at iteration 520 : 0.01329430378973484
Loss at iteration 530 : 0.028229311108589172
Loss at iteration 540 : 0.02814716286957264
Loss at iteration 550 : 0.01830798014998436
Loss at iteration 560 : 0.019103366881608963
Loss at iteration 570 : 0.02516947314143181
Loss at iteration 580 : 0.027437005192041397
Loss at iteration 590 : 0.02951727993786335
Loss at iteration 600 : 0.011789249256253242
Loss at iteration 610 : 0.027918625622987747
Loss at iteration 620 : 0.01909741386771202
Loss at iteration 630 : 0.01601037010550499
Loss at iteration 640 : 0.020189402624964714
Loss at iteration 650 : 0.01854780502617359
Loss at iteration 660 : 0.024264194071292877
Loss at iteration 670 : 0.01959332637488842
Loss at iteration 680 : 0.01685960963368416
Loss at iteration 690 : 0.023990293964743614
Loss at iteration 700 : 0.024657409638166428
Loss at iteration 710 : 0.030046233907341957
Loss at iteration 720 : 0.020482081919908524
Loss at iteration 730 : 0.02603771537542343
Loss at iteration 740 : 0.01768941432237625
Loss at iteration 750 : 0.012443240731954575
Loss at iteration 760 : 0.02021654136478901
Loss at iteration 770 : 0.014105360023677349
Loss at iteration 780 : 0.013229550793766975
Loss at iteration 790 : 0.015420916490256786
Loss at iteration 800 : 0.016121840104460716
Loss at iteration 810 : 0.013290767557919025
Loss at iteration 820 : 0.02751791849732399
Loss at iteration 830 : 0.015360306948423386
Loss at iteration 840 : 0.017023703083395958
Loss at iteration 850 : 0.015760280191898346
Loss at iteration 860 : 0.01679838076233864
Loss at iteration 870 : 0.019529782235622406
Loss at iteration 880 : 0.02746552973985672
Loss at iteration 890 : 0.015467416495084763
Loss at iteration 900 : 0.01762150228023529
Loss at iteration 910 : 0.014460834674537182
Loss at iteration 920 : 0.018988993018865585
Loss at iteration 930 : 0.017268946394324303
Loss at iteration 940 : 0.02053810842335224
Loss at iteration 950 : 0.011333012953400612
Loss at iteration 960 : 0.013343017548322678
Loss at iteration 970 : 0.019893469288945198
Loss at iteration 980 : 0.014144121669232845
Loss at iteration 990 : 0.02844459004700184
Loss at iteration 1000 : 0.02343027852475643
Loss at iteration 1010 : 0.01799093186855316
Loss at iteration 1020 : 0.014658926986157894
Loss at iteration 1030 : 0.008891208097338676
Loss at iteration 1040 : 0.024917423725128174
Loss at iteration 1050 : 0.01870676875114441
Loss at iteration 1060 : 0.04163233935832977
Loss at iteration 1070 : 0.01518191210925579
Loss at iteration 1080 : 0.017707310616970062
Loss at iteration 1090 : 0.017915328964591026
Loss at iteration 1100 : 0.024735547602176666
Loss at iteration 1110 : 0.01800427958369255
Loss at iteration 1120 : 0.018741555511951447
Loss at iteration 1130 : 0.03575662150979042
Loss at iteration 1140 : 0.024958185851573944
Loss at iteration 1150 : 0.012952325865626335
Loss at iteration 1160 : 0.02134074456989765
Loss at iteration 1170 : 0.02573070488870144
Loss at iteration 1180 : 0.026473255828022957
Loss at iteration 1190 : 0.009144304320216179
Loss at iteration 1200 : 0.022427817806601524
Loss at iteration 1210 : 0.015395494177937508
The SSIM Value is: 0.8053683280944824
The PSNR Value is: 19.57229169209798
the epoch is: 176
Loss at iteration 10 : 0.02604256197810173
Loss at iteration 20 : 0.01747015491127968
Loss at iteration 30 : 0.02820112183690071
Loss at iteration 40 : 0.028020326048135757
Loss at iteration 50 : 0.010699914768338203
Loss at iteration 60 : 0.01876761019229889
Loss at iteration 70 : 0.010446639731526375
Loss at iteration 80 : 0.018805917352437973
Loss at iteration 90 : 0.027146803215146065
Loss at iteration 100 : 0.02955242246389389
Loss at iteration 110 : 0.030312959104776382
Loss at iteration 120 : 0.019756827503442764
Loss at iteration 130 : 0.01446618139743805
Loss at iteration 140 : 0.010032465681433678
Loss at iteration 150 : 0.03631632775068283
Loss at iteration 160 : 0.030651286244392395
Loss at iteration 170 : 0.015719188377261162
Loss at iteration 180 : 0.018235251307487488
Loss at iteration 190 : 0.02124885469675064
Loss at iteration 200 : 0.02056274563074112
Loss at iteration 210 : 0.018336279317736626
Loss at iteration 220 : 0.0190203245729208
Loss at iteration 230 : 0.02338200993835926
Loss at iteration 240 : 0.02372441254556179
Loss at iteration 250 : 0.0224350206553936
Loss at iteration 260 : 0.01983954757452011
Loss at iteration 270 : 0.014837872236967087
Loss at iteration 280 : 0.016547836363315582
Loss at iteration 290 : 0.017571644857525826
Loss at iteration 300 : 0.025629395619034767
Loss at iteration 310 : 0.02215167135000229
Loss at iteration 320 : 0.012132635340094566
Loss at iteration 330 : 0.03112097829580307
Loss at iteration 340 : 0.023617811501026154
Loss at iteration 350 : 0.013522112742066383
Loss at iteration 360 : 0.018353426828980446
Loss at iteration 370 : 0.016891200095415115
Loss at iteration 380 : 0.02270699292421341
Loss at iteration 390 : 0.009060430340468884
Loss at iteration 400 : 0.01458972878754139
Loss at iteration 410 : 0.018620487302541733
Loss at iteration 420 : 0.021037373691797256
Loss at iteration 430 : 0.01777936890721321
Loss at iteration 440 : 0.015857350081205368
Loss at iteration 450 : 0.013529503718018532
Loss at iteration 460 : 0.018480855971574783
Loss at iteration 470 : 0.035645369440317154
Loss at iteration 480 : 0.02006058767437935
Loss at iteration 490 : 0.012755487114191055
Loss at iteration 500 : 0.020185653120279312
Loss at iteration 510 : 0.01164637878537178
Loss at iteration 520 : 0.023667562752962112
Loss at iteration 530 : 0.010952981188893318
Loss at iteration 540 : 0.03039591759443283
Loss at iteration 550 : 0.027209922671318054
Loss at iteration 560 : 0.029948581010103226
Loss at iteration 570 : 0.016349852085113525
Loss at iteration 580 : 0.009648103266954422
Loss at iteration 590 : 0.011272827163338661
Loss at iteration 600 : 0.010281195864081383
Loss at iteration 610 : 0.019276177510619164
Loss at iteration 620 : 0.017720412462949753
Loss at iteration 630 : 0.019258977845311165
Loss at iteration 640 : 0.016602030023932457
Loss at iteration 650 : 0.018757646903395653
Loss at iteration 660 : 0.014325286261737347
Loss at iteration 670 : 0.018884964287281036
Loss at iteration 680 : 0.02428201213479042
Loss at iteration 690 : 0.021143991500139236
Loss at iteration 700 : 0.014422811567783356
Loss at iteration 710 : 0.01337895542383194
Loss at iteration 720 : 0.02374657429754734
Loss at iteration 730 : 0.018533365800976753
Loss at iteration 740 : 0.013305186294019222
Loss at iteration 750 : 0.02630533091723919
Loss at iteration 760 : 0.015599185600876808
Loss at iteration 770 : 0.01824885606765747
Loss at iteration 780 : 0.032649531960487366
Loss at iteration 790 : 0.024552911520004272
Loss at iteration 800 : 0.018224254250526428
Loss at iteration 810 : 0.017712168395519257
Loss at iteration 820 : 0.018575191497802734
Loss at iteration 830 : 0.015452306717634201
Loss at iteration 840 : 0.016780242323875427
Loss at iteration 850 : 0.018483184278011322
Loss at iteration 860 : 0.016038421541452408
Loss at iteration 870 : 0.015140729025006294
Loss at iteration 880 : 0.010837843641638756
Loss at iteration 890 : 0.020677734166383743
Loss at iteration 900 : 0.01700369454920292
Loss at iteration 910 : 0.03306827321648598
Loss at iteration 920 : 0.02134784683585167
Loss at iteration 930 : 0.021014830097556114
Loss at iteration 940 : 0.019824378192424774
Loss at iteration 950 : 0.02290324494242668
Loss at iteration 960 : 0.016056545078754425
Loss at iteration 970 : 0.019164524972438812
Loss at iteration 980 : 0.021466903388500214
Loss at iteration 990 : 0.017867352813482285
Loss at iteration 1000 : 0.02589588426053524
Loss at iteration 1010 : 0.01956992596387863
Loss at iteration 1020 : 0.019300714135169983
Loss at iteration 1030 : 0.01791863888502121
Loss at iteration 1040 : 0.0186791829764843
Loss at iteration 1050 : 0.012316790409386158
Loss at iteration 1060 : 0.016144562512636185
Loss at iteration 1070 : 0.02112177014350891
Loss at iteration 1080 : 0.0444364957511425
Loss at iteration 1090 : 0.016927320510149002
Loss at iteration 1100 : 0.02087218314409256
Loss at iteration 1110 : 0.020707476884126663
Loss at iteration 1120 : 0.021826498210430145
Loss at iteration 1130 : 0.014372016303241253
Loss at iteration 1140 : 0.022083275020122528
Loss at iteration 1150 : 0.0212862528860569
Loss at iteration 1160 : 0.02113444358110428
Loss at iteration 1170 : 0.024276934564113617
Loss at iteration 1180 : 0.014626029878854752
Loss at iteration 1190 : 0.016049228608608246
Loss at iteration 1200 : 0.020394500344991684
Loss at iteration 1210 : 0.021775459870696068
The SSIM Value is: 0.8008974472681681
The PSNR Value is: 19.491083971659343
the epoch is: 177
Loss at iteration 10 : 0.018069330602884293
Loss at iteration 20 : 0.018283959478139877
Loss at iteration 30 : 0.011636609211564064
Loss at iteration 40 : 0.01238006167113781
Loss at iteration 50 : 0.01713685318827629
Loss at iteration 60 : 0.017691541463136673
Loss at iteration 70 : 0.017590437084436417
Loss at iteration 80 : 0.022063739597797394
Loss at iteration 90 : 0.021335482597351074
Loss at iteration 100 : 0.03318285942077637
Loss at iteration 110 : 0.03192790970206261
Loss at iteration 120 : 0.020869430154561996
Loss at iteration 130 : 0.0133547093719244
Loss at iteration 140 : 0.021504908800125122
Loss at iteration 150 : 0.02205045148730278
Loss at iteration 160 : 0.03241775929927826
Loss at iteration 170 : 0.019783228635787964
Loss at iteration 180 : 0.016420681029558182
Loss at iteration 190 : 0.02585676684975624
Loss at iteration 200 : 0.02344791404902935
Loss at iteration 210 : 0.019679637625813484
Loss at iteration 220 : 0.018142882734537125
Loss at iteration 230 : 0.015468747355043888
Loss at iteration 240 : 0.019918035715818405
Loss at iteration 250 : 0.016581472009420395
Loss at iteration 260 : 0.03640104457736015
Loss at iteration 270 : 0.021334122866392136
Loss at iteration 280 : 0.02168864570558071
Loss at iteration 290 : 0.016603752970695496
Loss at iteration 300 : 0.01770109310746193
Loss at iteration 310 : 0.014684110879898071
Loss at iteration 320 : 0.020933041349053383
Loss at iteration 330 : 0.01456284336745739
Loss at iteration 340 : 0.017305944114923477
Loss at iteration 350 : 0.031298279762268066
Loss at iteration 360 : 0.01824677363038063
Loss at iteration 370 : 0.0211087204515934
Loss at iteration 380 : 0.011500457301735878
Loss at iteration 390 : 0.014091082848608494
Loss at iteration 400 : 0.021359777078032494
Loss at iteration 410 : 0.01685262657701969
Loss at iteration 420 : 0.020796416327357292
Loss at iteration 430 : 0.013522340916097164
Loss at iteration 440 : 0.019040696322917938
Loss at iteration 450 : 0.024915676563978195
Loss at iteration 460 : 0.017953962087631226
Loss at iteration 470 : 0.018897680565714836
Loss at iteration 480 : 0.02770555391907692
Loss at iteration 490 : 0.013226961717009544
Loss at iteration 500 : 0.014227023348212242
Loss at iteration 510 : 0.021810654550790787
Loss at iteration 520 : 0.019380666315555573
Loss at iteration 530 : 0.015589120797812939
Loss at iteration 540 : 0.017119063064455986
Loss at iteration 550 : 0.015529857948422432
Loss at iteration 560 : 0.020994016900658607
Loss at iteration 570 : 0.023110156878829002
Loss at iteration 580 : 0.016523830592632294
Loss at iteration 590 : 0.009870706126093864
Loss at iteration 600 : 0.01642630062997341
Loss at iteration 610 : 0.02324007824063301
Loss at iteration 620 : 0.019558187574148178
Loss at iteration 630 : 0.010679055005311966
Loss at iteration 640 : 0.018802128732204437
Loss at iteration 650 : 0.025047369301319122
Loss at iteration 660 : 0.0218522772192955
Loss at iteration 670 : 0.023381009697914124
Loss at iteration 680 : 0.027730315923690796
Loss at iteration 690 : 0.01652555912733078
Loss at iteration 700 : 0.01851280964910984
Loss at iteration 710 : 0.019753746688365936
Loss at iteration 720 : 0.0187539029866457
Loss at iteration 730 : 0.02947738766670227
Loss at iteration 740 : 0.029804788529872894
Loss at iteration 750 : 0.02138250321149826
Loss at iteration 760 : 0.024652238935232162
Loss at iteration 770 : 0.01767076551914215
Loss at iteration 780 : 0.015269966796040535
Loss at iteration 790 : 0.03675302118062973
Loss at iteration 800 : 0.020947309210896492
Loss at iteration 810 : 0.025882836431264877
Loss at iteration 820 : 0.015050779096782207
Loss at iteration 830 : 0.01609417237341404
Loss at iteration 840 : 0.012825503945350647
Loss at iteration 850 : 0.019097376614809036
Loss at iteration 860 : 0.018533647060394287
Loss at iteration 870 : 0.02549867145717144
Loss at iteration 880 : 0.024019217118620872
Loss at iteration 890 : 0.018952306360006332
Loss at iteration 900 : 0.016858331859111786
Loss at iteration 910 : 0.021318428218364716
Loss at iteration 920 : 0.01921413652598858
Loss at iteration 930 : 0.014527365565299988
Loss at iteration 940 : 0.023955434560775757
Loss at iteration 950 : 0.027139369398355484
Loss at iteration 960 : 0.020560920238494873
Loss at iteration 970 : 0.02120330184698105
Loss at iteration 980 : 0.022531716153025627
Loss at iteration 990 : 0.016722191125154495
Loss at iteration 1000 : 0.01584039255976677
Loss at iteration 1010 : 0.014769514091312885
Loss at iteration 1020 : 0.018922699615359306
Loss at iteration 1030 : 0.0189969539642334
Loss at iteration 1040 : 0.013007144443690777
Loss at iteration 1050 : 0.021778777241706848
Loss at iteration 1060 : 0.017453404143452644
Loss at iteration 1070 : 0.017751440405845642
Loss at iteration 1080 : 0.03548643738031387
Loss at iteration 1090 : 0.023609254509210587
Loss at iteration 1100 : 0.018210913985967636
Loss at iteration 1110 : 0.01726972684264183
Loss at iteration 1120 : 0.01592797413468361
Loss at iteration 1130 : 0.01511400006711483
Loss at iteration 1140 : 0.01933126151561737
Loss at iteration 1150 : 0.012279071845114231
Loss at iteration 1160 : 0.01638965867459774
Loss at iteration 1170 : 0.015279720537364483
Loss at iteration 1180 : 0.019075658172369003
Loss at iteration 1190 : 0.0192561075091362
Loss at iteration 1200 : 0.020576005801558495
Loss at iteration 1210 : 0.019448457285761833
The SSIM Value is: 0.8070530732472737
The PSNR Value is: 19.738079897562663
the epoch is: 178
Loss at iteration 10 : 0.022681232541799545
Loss at iteration 20 : 0.013321952894330025
Loss at iteration 30 : 0.010486318729817867
Loss at iteration 40 : 0.017717961221933365
Loss at iteration 50 : 0.012034852057695389
Loss at iteration 60 : 0.014979144558310509
Loss at iteration 70 : 0.024659425020217896
Loss at iteration 80 : 0.028035849332809448
Loss at iteration 90 : 0.019328268244862556
Loss at iteration 100 : 0.030020497739315033
Loss at iteration 110 : 0.03295748680830002
Loss at iteration 120 : 0.018935585394501686
Loss at iteration 130 : 0.03261691704392433
Loss at iteration 140 : 0.012937361374497414
Loss at iteration 150 : 0.017860908061265945
Loss at iteration 160 : 0.021741660311818123
Loss at iteration 170 : 0.026543062180280685
Loss at iteration 180 : 0.012184596620500088
Loss at iteration 190 : 0.02178024873137474
Loss at iteration 200 : 0.012794777750968933
Loss at iteration 210 : 0.017308421432971954
Loss at iteration 220 : 0.020037677139043808
Loss at iteration 230 : 0.06290885806083679
Loss at iteration 240 : 0.01916622370481491
Loss at iteration 250 : 0.02005888521671295
Loss at iteration 260 : 0.02597511000931263
Loss at iteration 270 : 0.012676669284701347
Loss at iteration 280 : 0.023783765733242035
Loss at iteration 290 : 0.017480602487921715
Loss at iteration 300 : 0.012216196395456791
Loss at iteration 310 : 0.018635723739862442
Loss at iteration 320 : 0.02016598917543888
Loss at iteration 330 : 0.023321766406297684
Loss at iteration 340 : 0.015675421804189682
Loss at iteration 350 : 0.010004186071455479
Loss at iteration 360 : 0.01417683344334364
Loss at iteration 370 : 0.015560547821223736
Loss at iteration 380 : 0.02080758847296238
Loss at iteration 390 : 0.02511061541736126
Loss at iteration 400 : 0.01613830029964447
Loss at iteration 410 : 0.019560471177101135
Loss at iteration 420 : 0.02187977358698845
Loss at iteration 430 : 0.012610445730388165
Loss at iteration 440 : 0.024834536015987396
Loss at iteration 450 : 0.014047238975763321
Loss at iteration 460 : 0.017824646085500717
Loss at iteration 470 : 0.026861954480409622
Loss at iteration 480 : 0.02280164510011673
Loss at iteration 490 : 0.02307368442416191
Loss at iteration 500 : 0.026672642678022385
Loss at iteration 510 : 0.033835519105196
Loss at iteration 520 : 0.018776798620820045
Loss at iteration 530 : 0.03143376111984253
Loss at iteration 540 : 0.02922159805893898
Loss at iteration 550 : 0.015183700248599052
Loss at iteration 560 : 0.011809966526925564
Loss at iteration 570 : 0.01639857329428196
Loss at iteration 580 : 0.030859582126140594
Loss at iteration 590 : 0.03505082055926323
Loss at iteration 600 : 0.013688928447663784
Loss at iteration 610 : 0.021100040525197983
Loss at iteration 620 : 0.01714494079351425
Loss at iteration 630 : 0.012430365197360516
Loss at iteration 640 : 0.014212527312338352
Loss at iteration 650 : 0.020646270364522934
Loss at iteration 660 : 0.011478634551167488
Loss at iteration 670 : 0.016255483031272888
Loss at iteration 680 : 0.011923889629542828
Loss at iteration 690 : 0.01725224032998085
Loss at iteration 700 : 0.02279793657362461
Loss at iteration 710 : 0.012679780833423138
Loss at iteration 720 : 0.018251661211252213
Loss at iteration 730 : 0.01941731572151184
Loss at iteration 740 : 0.02615673467516899
Loss at iteration 750 : 0.01578424498438835
Loss at iteration 760 : 0.018957579508423805
Loss at iteration 770 : 0.015502694062888622
Loss at iteration 780 : 0.02274378016591072
Loss at iteration 790 : 0.013316408731043339
Loss at iteration 800 : 0.012854423373937607
Loss at iteration 810 : 0.0192054845392704
Loss at iteration 820 : 0.02825281023979187
Loss at iteration 830 : 0.03445490822196007
Loss at iteration 840 : 0.03553551062941551
Loss at iteration 850 : 0.016004374250769615
Loss at iteration 860 : 0.019130650907754898
Loss at iteration 870 : 0.01616392470896244
Loss at iteration 880 : 0.01693459041416645
Loss at iteration 890 : 0.02355000749230385
Loss at iteration 900 : 0.030032165348529816
Loss at iteration 910 : 0.02265559323132038
Loss at iteration 920 : 0.01599103957414627
Loss at iteration 930 : 0.020413925871253014
Loss at iteration 940 : 0.03820765018463135
Loss at iteration 950 : 0.019175000488758087
Loss at iteration 960 : 0.014113467186689377
Loss at iteration 970 : 0.01931201107800007
Loss at iteration 980 : 0.023581497371196747
Loss at iteration 990 : 0.012873190455138683
Loss at iteration 1000 : 0.027514107525348663
Loss at iteration 1010 : 0.018640901893377304
Loss at iteration 1020 : 0.015063175931572914
Loss at iteration 1030 : 0.03181617707014084
Loss at iteration 1040 : 0.01903296262025833
Loss at iteration 1050 : 0.016457542777061462
Loss at iteration 1060 : 0.013698535971343517
Loss at iteration 1070 : 0.017980214208364487
Loss at iteration 1080 : 0.028128355741500854
Loss at iteration 1090 : 0.014466514810919762
Loss at iteration 1100 : 0.027732009068131447
Loss at iteration 1110 : 0.011734845116734505
Loss at iteration 1120 : 0.013960600830614567
Loss at iteration 1130 : 0.022682584822177887
Loss at iteration 1140 : 0.031177502125501633
Loss at iteration 1150 : 0.013069545850157738
Loss at iteration 1160 : 0.012584889307618141
Loss at iteration 1170 : 0.009532890282571316
Loss at iteration 1180 : 0.013511113822460175
Loss at iteration 1190 : 0.012805502861738205
Loss at iteration 1200 : 0.019990794360637665
Loss at iteration 1210 : 0.016063662245869637
The SSIM Value is: 0.8046586831410726
The PSNR Value is: 19.383534113566082
the epoch is: 179
Loss at iteration 10 : 0.01813824474811554
Loss at iteration 20 : 0.013864096254110336
Loss at iteration 30 : 0.025932855904102325
Loss at iteration 40 : 0.019919218495488167
Loss at iteration 50 : 0.012712379917502403
Loss at iteration 60 : 0.029361896216869354
Loss at iteration 70 : 0.038320355117321014
Loss at iteration 80 : 0.023689299821853638
Loss at iteration 90 : 0.02378634735941887
Loss at iteration 100 : 0.019695591181516647
Loss at iteration 110 : 0.016938142478466034
Loss at iteration 120 : 0.01193212904036045
Loss at iteration 130 : 0.017871523275971413
Loss at iteration 140 : 0.01932212896645069
Loss at iteration 150 : 0.02664942666888237
Loss at iteration 160 : 0.02132466994225979
Loss at iteration 170 : 0.017262466251850128
Loss at iteration 180 : 0.01768057979643345
Loss at iteration 190 : 0.013093128800392151
Loss at iteration 200 : 0.02234676480293274
Loss at iteration 210 : 0.01761200651526451
Loss at iteration 220 : 0.02420518733561039
Loss at iteration 230 : 0.021900329738855362
Loss at iteration 240 : 0.014187830500304699
Loss at iteration 250 : 0.012517347931861877
Loss at iteration 260 : 0.025169838219881058
Loss at iteration 270 : 0.01762619987130165
Loss at iteration 280 : 0.0178357120603323
Loss at iteration 290 : 0.019121894612908363
Loss at iteration 300 : 0.02025928907096386
Loss at iteration 310 : 0.024234941229224205
Loss at iteration 320 : 0.02779308520257473
Loss at iteration 330 : 0.015159742906689644
Loss at iteration 340 : 0.019975271075963974
Loss at iteration 350 : 0.01861969195306301
Loss at iteration 360 : 0.03145046532154083
Loss at iteration 370 : 0.025127844884991646
Loss at iteration 380 : 0.025191428139805794
Loss at iteration 390 : 0.031019169837236404
Loss at iteration 400 : 0.021555457264184952
Loss at iteration 410 : 0.01307738572359085
Loss at iteration 420 : 0.020417600870132446
Loss at iteration 430 : 0.014931589365005493
Loss at iteration 440 : 0.013409703969955444
Loss at iteration 450 : 0.02574334293603897
Loss at iteration 460 : 0.01949264667928219
Loss at iteration 470 : 0.016248730942606926
Loss at iteration 480 : 0.016583222895860672
Loss at iteration 490 : 0.01435457356274128
Loss at iteration 500 : 0.012816276401281357
Loss at iteration 510 : 0.020772743970155716
Loss at iteration 520 : 0.016818571835756302
Loss at iteration 530 : 0.022172711789608
Loss at iteration 540 : 0.017314694821834564
Loss at iteration 550 : 0.020621608942747116
Loss at iteration 560 : 0.024924784898757935
Loss at iteration 570 : 0.012899024412035942
Loss at iteration 580 : 0.022668832913041115
Loss at iteration 590 : 0.013899354264140129
Loss at iteration 600 : 0.0074322521686553955
Loss at iteration 610 : 0.014390859752893448
Loss at iteration 620 : 0.019127918407320976
Loss at iteration 630 : 0.017575901001691818
Loss at iteration 640 : 0.029445406049489975
Loss at iteration 650 : 0.013158509507775307
Loss at iteration 660 : 0.0278934258967638
Loss at iteration 670 : 0.01623949222266674
Loss at iteration 680 : 0.01461457833647728
Loss at iteration 690 : 0.01810891553759575
Loss at iteration 700 : 0.024779317900538445
Loss at iteration 710 : 0.01482408121228218
Loss at iteration 720 : 0.042314667254686356
Loss at iteration 730 : 0.03190077096223831
Loss at iteration 740 : 0.010202979668974876
Loss at iteration 750 : 0.00811474584043026
Loss at iteration 760 : 0.01920367032289505
Loss at iteration 770 : 0.02502409555017948
Loss at iteration 780 : 0.01050018984824419
Loss at iteration 790 : 0.021747149527072906
Loss at iteration 800 : 0.02330498769879341
Loss at iteration 810 : 0.021248098462820053
Loss at iteration 820 : 0.012871569953858852
Loss at iteration 830 : 0.013899424113333225
Loss at iteration 840 : 0.013755973428487778
Loss at iteration 850 : 0.020672310143709183
Loss at iteration 860 : 0.013551125302910805
Loss at iteration 870 : 0.027233829721808434
Loss at iteration 880 : 0.02689734846353531
Loss at iteration 890 : 0.016858616843819618
Loss at iteration 900 : 0.02355807274580002
Loss at iteration 910 : 0.026659134775400162
Loss at iteration 920 : 0.015857648104429245
Loss at iteration 930 : 0.01965641789138317
Loss at iteration 940 : 0.023800276219844818
Loss at iteration 950 : 0.012767291627824306
Loss at iteration 960 : 0.02070457860827446
Loss at iteration 970 : 0.01616186648607254
Loss at iteration 980 : 0.01865745522081852
Loss at iteration 990 : 0.019095346331596375
Loss at iteration 1000 : 0.014492182061076164
Loss at iteration 1010 : 0.014391862787306309
Loss at iteration 1020 : 0.010976649820804596
Loss at iteration 1030 : 0.011060787364840508
Loss at iteration 1040 : 0.016586562618613243
Loss at iteration 1050 : 0.018395647406578064
Loss at iteration 1060 : 0.016246771439909935
Loss at iteration 1070 : 0.008791523054242134
Loss at iteration 1080 : 0.026812901720404625
Loss at iteration 1090 : 0.03385331481695175
Loss at iteration 1100 : 0.015900127589702606
Loss at iteration 1110 : 0.013284250162541866
Loss at iteration 1120 : 0.00856323353946209
Loss at iteration 1130 : 0.021558796986937523
Loss at iteration 1140 : 0.02284974604845047
Loss at iteration 1150 : 0.01377075631171465
Loss at iteration 1160 : 0.026131708174943924
Loss at iteration 1170 : 0.02245882712304592
Loss at iteration 1180 : 0.013756798580288887
Loss at iteration 1190 : 0.02288047783076763
Loss at iteration 1200 : 0.016171248629689217
Loss at iteration 1210 : 0.018826637417078018
The SSIM Value is: 0.802409807840983
The PSNR Value is: 19.547323671976724
the epoch is: 180
Loss at iteration 10 : 0.02435769885778427
Loss at iteration 20 : 0.021827921271324158
Loss at iteration 30 : 0.011473467573523521
Loss at iteration 40 : 0.032649025321006775
Loss at iteration 50 : 0.03844175487756729
Loss at iteration 60 : 0.02092074230313301
Loss at iteration 70 : 0.016610097140073776
Loss at iteration 80 : 0.016050850972533226
Loss at iteration 90 : 0.028569482266902924
Loss at iteration 100 : 0.02028922736644745
Loss at iteration 110 : 0.009630161337554455
Loss at iteration 120 : 0.0127268610522151
Loss at iteration 130 : 0.022002145648002625
Loss at iteration 140 : 0.017671581357717514
Loss at iteration 150 : 0.01086253672838211
Loss at iteration 160 : 0.017672313377261162
Loss at iteration 170 : 0.01198938861489296
Loss at iteration 180 : 0.01637706719338894
Loss at iteration 190 : 0.016226891428232193
Loss at iteration 200 : 0.013639327138662338
Loss at iteration 210 : 0.01548252534121275
Loss at iteration 220 : 0.03899894654750824
Loss at iteration 230 : 0.016599446535110474
Loss at iteration 240 : 0.024129096418619156
Loss at iteration 250 : 0.010675271973013878
Loss at iteration 260 : 0.011049380525946617
Loss at iteration 270 : 0.010421263054013252
Loss at iteration 280 : 0.021306747570633888
Loss at iteration 290 : 0.03389798849821091
Loss at iteration 300 : 0.026787608861923218
Loss at iteration 310 : 0.015507644973695278
Loss at iteration 320 : 0.016272956505417824
Loss at iteration 330 : 0.028535762801766396
Loss at iteration 340 : 0.023227518424391747
Loss at iteration 350 : 0.02052079699933529
Loss at iteration 360 : 0.016648897901177406
Loss at iteration 370 : 0.021320059895515442
Loss at iteration 380 : 0.013418301939964294
Loss at iteration 390 : 0.015856629237532616
Loss at iteration 400 : 0.013140461407601833
Loss at iteration 410 : 0.013529451563954353
Loss at iteration 420 : 0.01100912131369114
Loss at iteration 430 : 0.020916098728775978
Loss at iteration 440 : 0.03598800674080849
Loss at iteration 450 : 0.02322196215391159
Loss at iteration 460 : 0.017310786992311478
Loss at iteration 470 : 0.014647012576460838
Loss at iteration 480 : 0.026852110400795937
Loss at iteration 490 : 0.01178845576941967
Loss at iteration 500 : 0.01695314049720764
Loss at iteration 510 : 0.0228283628821373
Loss at iteration 520 : 0.02556784637272358
Loss at iteration 530 : 0.024333631619811058
Loss at iteration 540 : 0.014920314773917198
Loss at iteration 550 : 0.020887112244963646
Loss at iteration 560 : 0.018172241747379303
Loss at iteration 570 : 0.02324005216360092
Loss at iteration 580 : 0.017299119383096695
Loss at iteration 590 : 0.02061539702117443
Loss at iteration 600 : 0.025046642869710922
Loss at iteration 610 : 0.018482213839888573
Loss at iteration 620 : 0.01687338575720787
Loss at iteration 630 : 0.017451925203204155
Loss at iteration 640 : 0.019930122420191765
Loss at iteration 650 : 0.024977970868349075
Loss at iteration 660 : 0.01198451966047287
Loss at iteration 670 : 0.019801467657089233
Loss at iteration 680 : 0.030413225293159485
Loss at iteration 690 : 0.01798686757683754
Loss at iteration 700 : 0.019119925796985626
Loss at iteration 710 : 0.020230701193213463
Loss at iteration 720 : 0.019496437162160873
Loss at iteration 730 : 0.014458228833973408
Loss at iteration 740 : 0.022079739719629288
Loss at iteration 750 : 0.02212902158498764
Loss at iteration 760 : 0.017874430865049362
Loss at iteration 770 : 0.023682517930865288
Loss at iteration 780 : 0.02755868434906006
Loss at iteration 790 : 0.021843131631612778
Loss at iteration 800 : 0.007844301871955395
Loss at iteration 810 : 0.01901857927441597
Loss at iteration 820 : 0.0377887487411499
Loss at iteration 830 : 0.015547162853181362
Loss at iteration 840 : 0.012813003733754158
Loss at iteration 850 : 0.022293131798505783
Loss at iteration 860 : 0.022111712023615837
Loss at iteration 870 : 0.031982097774744034
Loss at iteration 880 : 0.01661783829331398
Loss at iteration 890 : 0.019309481605887413
Loss at iteration 900 : 0.02382533997297287
Loss at iteration 910 : 0.023540664464235306
Loss at iteration 920 : 0.010979017242789268
Loss at iteration 930 : 0.00998503714799881
Loss at iteration 940 : 0.019219666719436646
Loss at iteration 950 : 0.02036498673260212
Loss at iteration 960 : 0.010377200320363045
Loss at iteration 970 : 0.018951918929815292
Loss at iteration 980 : 0.02092212811112404
Loss at iteration 990 : 0.018513616174459457
Loss at iteration 1000 : 0.017816031351685524
Loss at iteration 1010 : 0.02258756011724472
Loss at iteration 1020 : 0.012920282781124115
Loss at iteration 1030 : 0.017816010862588882
Loss at iteration 1040 : 0.010559994727373123
Loss at iteration 1050 : 0.017955319955945015
Loss at iteration 1060 : 0.01983810029923916
Loss at iteration 1070 : 0.02354314550757408
Loss at iteration 1080 : 0.021040603518486023
Loss at iteration 1090 : 0.022016946226358414
Loss at iteration 1100 : 0.011774776503443718
Loss at iteration 1110 : 0.020179037004709244
Loss at iteration 1120 : 0.023597538471221924
Loss at iteration 1130 : 0.01681624725461006
Loss at iteration 1140 : 0.03526470065116882
Loss at iteration 1150 : 0.016489142552018166
Loss at iteration 1160 : 0.0204324871301651
Loss at iteration 1170 : 0.015141963958740234
Loss at iteration 1180 : 0.019651144742965698
Loss at iteration 1190 : 0.024924349039793015
Loss at iteration 1200 : 0.01647273264825344
Loss at iteration 1210 : 0.022267252206802368
The SSIM Value is: 0.803406023979187
The PSNR Value is: 20.1343178431193
the highest SSIM value is: 20.1343178431193
the epoch is: 181
Loss at iteration 10 : 0.013414787128567696
Loss at iteration 20 : 0.02146434783935547
Loss at iteration 30 : 0.03144196793437004
Loss at iteration 40 : 0.015439185313880444
Loss at iteration 50 : 0.018735915422439575
Loss at iteration 60 : 0.015154022723436356
Loss at iteration 70 : 0.01799766533076763
Loss at iteration 80 : 0.022442294284701347
Loss at iteration 90 : 0.028374098241329193
Loss at iteration 100 : 0.01624663546681404
Loss at iteration 110 : 0.022540951147675514
Loss at iteration 120 : 0.01203735452145338
Loss at iteration 130 : 0.033739350736141205
Loss at iteration 140 : 0.024153724312782288
Loss at iteration 150 : 0.024274852126836777
Loss at iteration 160 : 0.01393558457493782
Loss at iteration 170 : 0.015325208194553852
Loss at iteration 180 : 0.013431833125650883
Loss at iteration 190 : 0.012542197480797768
Loss at iteration 200 : 0.01711517944931984
Loss at iteration 210 : 0.018039828166365623
Loss at iteration 220 : 0.014892074279487133
Loss at iteration 230 : 0.017107043415308
Loss at iteration 240 : 0.022052159532904625
Loss at iteration 250 : 0.01785416156053543
Loss at iteration 260 : 0.022311750799417496
Loss at iteration 270 : 0.022517062723636627
Loss at iteration 280 : 0.01549258641898632
Loss at iteration 290 : 0.018695270642638206
Loss at iteration 300 : 0.018900293856859207
Loss at iteration 310 : 0.0183140579611063
Loss at iteration 320 : 0.025198277086019516
Loss at iteration 330 : 0.00939122959971428
Loss at iteration 340 : 0.02050016075372696
Loss at iteration 350 : 0.012245239689946175
Loss at iteration 360 : 0.03148626163601875
Loss at iteration 370 : 0.019609743729233742
Loss at iteration 380 : 0.019470516592264175
Loss at iteration 390 : 0.023263391107320786
Loss at iteration 400 : 0.031344618648290634
Loss at iteration 410 : 0.026375144720077515
Loss at iteration 420 : 0.020226867869496346
Loss at iteration 430 : 0.013819356448948383
Loss at iteration 440 : 0.012783494777977467
Loss at iteration 450 : 0.03026632033288479
Loss at iteration 460 : 0.015610985457897186
Loss at iteration 470 : 0.02875731885433197
Loss at iteration 480 : 0.01713976263999939
Loss at iteration 490 : 0.01584816351532936
Loss at iteration 500 : 0.025480173528194427
Loss at iteration 510 : 0.01645113341510296
Loss at iteration 520 : 0.02335970848798752
Loss at iteration 530 : 0.03681598976254463
Loss at iteration 540 : 0.014284417033195496
Loss at iteration 550 : 0.023204678669571877
Loss at iteration 560 : 0.013980554416775703
Loss at iteration 570 : 0.018380580469965935
Loss at iteration 580 : 0.024040527641773224
Loss at iteration 590 : 0.01780351623892784
Loss at iteration 600 : 0.011488529853522778
Loss at iteration 610 : 0.011085202917456627
Loss at iteration 620 : 0.014697425998747349
Loss at iteration 630 : 0.014311603270471096
Loss at iteration 640 : 0.018564481288194656
Loss at iteration 650 : 0.015019560232758522
Loss at iteration 660 : 0.016070084646344185
Loss at iteration 670 : 0.01791783794760704
Loss at iteration 680 : 0.019376955926418304
Loss at iteration 690 : 0.03034837916493416
Loss at iteration 700 : 0.024391839280724525
Loss at iteration 710 : 0.02811024710536003
Loss at iteration 720 : 0.015134366229176521
Loss at iteration 730 : 0.017870817333459854
Loss at iteration 740 : 0.02305341511964798
Loss at iteration 750 : 0.015393144451081753
Loss at iteration 760 : 0.023180928081274033
Loss at iteration 770 : 0.03125987574458122
Loss at iteration 780 : 0.019487813115119934
Loss at iteration 790 : 0.013074863702058792
Loss at iteration 800 : 0.02926085889339447
Loss at iteration 810 : 0.022117648273706436
Loss at iteration 820 : 0.01547909714281559
Loss at iteration 830 : 0.023559963330626488
Loss at iteration 840 : 0.02466750331223011
Loss at iteration 850 : 0.01796063221991062
Loss at iteration 860 : 0.017715388908982277
Loss at iteration 870 : 0.019631212577223778
Loss at iteration 880 : 0.0190233513712883
Loss at iteration 890 : 0.03311727195978165
Loss at iteration 900 : 0.021357515826821327
Loss at iteration 910 : 0.016212638467550278
Loss at iteration 920 : 0.015487896278500557
Loss at iteration 930 : 0.0158364437520504
Loss at iteration 940 : 0.007121841888874769
Loss at iteration 950 : 0.016859591007232666
Loss at iteration 960 : 0.01874355971813202
Loss at iteration 970 : 0.013227703049778938
Loss at iteration 980 : 0.024160435423254967
Loss at iteration 990 : 0.016032785177230835
Loss at iteration 1000 : 0.02299804426729679
Loss at iteration 1010 : 0.02207324653863907
Loss at iteration 1020 : 0.0218270942568779
Loss at iteration 1030 : 0.028405025601387024
Loss at iteration 1040 : 0.014715077355504036
Loss at iteration 1050 : 0.02114262990653515
Loss at iteration 1060 : 0.027274565771222115
Loss at iteration 1070 : 0.018634092062711716
Loss at iteration 1080 : 0.019109802320599556
Loss at iteration 1090 : 0.019458549097180367
Loss at iteration 1100 : 0.023832444101572037
Loss at iteration 1110 : 0.03182801976799965
Loss at iteration 1120 : 0.01117551140487194
Loss at iteration 1130 : 0.012507861480116844
Loss at iteration 1140 : 0.02856266498565674
Loss at iteration 1150 : 0.022960137575864792
Loss at iteration 1160 : 0.023316793143749237
Loss at iteration 1170 : 0.0075601316057145596
Loss at iteration 1180 : 0.026928283274173737
Loss at iteration 1190 : 0.01757153496146202
Loss at iteration 1200 : 0.03734804317355156
Loss at iteration 1210 : 0.0131901316344738
The SSIM Value is: 0.8052725712458293
The PSNR Value is: 20.30158322652181
the highest SSIM value is: 20.30158322652181
the epoch is: 182
Loss at iteration 10 : 0.030868403613567352
Loss at iteration 20 : 0.02069154940545559
Loss at iteration 30 : 0.038422681391239166
Loss at iteration 40 : 0.02757636457681656
Loss at iteration 50 : 0.015982741490006447
Loss at iteration 60 : 0.021174650639295578
Loss at iteration 70 : 0.015854399651288986
Loss at iteration 80 : 0.0280672125518322
Loss at iteration 90 : 0.019836530089378357
Loss at iteration 100 : 0.01561651099473238
Loss at iteration 110 : 0.019172735512256622
Loss at iteration 120 : 0.01453626062721014
Loss at iteration 130 : 0.017202511429786682
Loss at iteration 140 : 0.01314559392631054
Loss at iteration 150 : 0.019892752170562744
Loss at iteration 160 : 0.026135701686143875
Loss at iteration 170 : 0.018860213458538055
Loss at iteration 180 : 0.03349103033542633
Loss at iteration 190 : 0.02541620284318924
Loss at iteration 200 : 0.01955839991569519
Loss at iteration 210 : 0.01796288974583149
Loss at iteration 220 : 0.020900875329971313
Loss at iteration 230 : 0.02386895753443241
Loss at iteration 240 : 0.019936010241508484
Loss at iteration 250 : 0.017993250861763954
Loss at iteration 260 : 0.017507651820778847
Loss at iteration 270 : 0.02117738500237465
Loss at iteration 280 : 0.02172067202627659
Loss at iteration 290 : 0.029818236827850342
Loss at iteration 300 : 0.01905837096273899
Loss at iteration 310 : 0.026716245338320732
Loss at iteration 320 : 0.021717634052038193
Loss at iteration 330 : 0.010387446731328964
Loss at iteration 340 : 0.025549016892910004
Loss at iteration 350 : 0.013990169391036034
Loss at iteration 360 : 0.009218915365636349
Loss at iteration 370 : 0.018649445846676826
Loss at iteration 380 : 0.018097281455993652
Loss at iteration 390 : 0.01757645234465599
Loss at iteration 400 : 0.026357196271419525
Loss at iteration 410 : 0.022023214027285576
Loss at iteration 420 : 0.01619197428226471
Loss at iteration 430 : 0.012483036145567894
Loss at iteration 440 : 0.01733197644352913
Loss at iteration 450 : 0.019928734749555588
Loss at iteration 460 : 0.01663338392972946
Loss at iteration 470 : 0.021433282643556595
Loss at iteration 480 : 0.020521964877843857
Loss at iteration 490 : 0.014996267855167389
Loss at iteration 500 : 0.027120565995573997
Loss at iteration 510 : 0.02582686021924019
Loss at iteration 520 : 0.020992781966924667
Loss at iteration 530 : 0.021036755293607712
Loss at iteration 540 : 0.022819453850388527
Loss at iteration 550 : 0.017104193568229675
Loss at iteration 560 : 0.029828350991010666
Loss at iteration 570 : 0.024652991443872452
Loss at iteration 580 : 0.018406040966510773
Loss at iteration 590 : 0.029111895710229874
Loss at iteration 600 : 0.020795505493879318
Loss at iteration 610 : 0.020061064511537552
Loss at iteration 620 : 0.022959701716899872
Loss at iteration 630 : 0.010328118689358234
Loss at iteration 640 : 0.016315337270498276
Loss at iteration 650 : 0.020181704312562943
Loss at iteration 660 : 0.013724791817367077
Loss at iteration 670 : 0.01857135444879532
Loss at iteration 680 : 0.016581255942583084
Loss at iteration 690 : 0.02352127432823181
Loss at iteration 700 : 0.022793032228946686
Loss at iteration 710 : 0.030266880989074707
Loss at iteration 720 : 0.014046677388250828
Loss at iteration 730 : 0.019178954884409904
Loss at iteration 740 : 0.024379700422286987
Loss at iteration 750 : 0.027201980352401733
Loss at iteration 760 : 0.01985321380198002
Loss at iteration 770 : 0.016285499557852745
Loss at iteration 780 : 0.020871400833129883
Loss at iteration 790 : 0.01796819269657135
Loss at iteration 800 : 0.020289598032832146
Loss at iteration 810 : 0.018292222172021866
Loss at iteration 820 : 0.028961511328816414
Loss at iteration 830 : 0.01710275188088417
Loss at iteration 840 : 0.013428771868348122
Loss at iteration 850 : 0.02351108193397522
Loss at iteration 860 : 0.01604958437383175
Loss at iteration 870 : 0.03027779795229435
Loss at iteration 880 : 0.018289780244231224
Loss at iteration 890 : 0.018979884684085846
Loss at iteration 900 : 0.014480740763247013
Loss at iteration 910 : 0.02399413473904133
Loss at iteration 920 : 0.011855601333081722
Loss at iteration 930 : 0.015331047587096691
Loss at iteration 940 : 0.0284353569149971
Loss at iteration 950 : 0.012068934738636017
Loss at iteration 960 : 0.0223354771733284
Loss at iteration 970 : 0.014181135222315788
Loss at iteration 980 : 0.023443635553121567
Loss at iteration 990 : 0.01777147874236107
Loss at iteration 1000 : 0.018919777125120163
Loss at iteration 1010 : 0.023160599172115326
Loss at iteration 1020 : 0.016405658796429634
Loss at iteration 1030 : 0.009577922523021698
Loss at iteration 1040 : 0.017446883022785187
Loss at iteration 1050 : 0.014688427560031414
Loss at iteration 1060 : 0.017211582511663437
Loss at iteration 1070 : 0.027454841881990433
Loss at iteration 1080 : 0.026579272001981735
Loss at iteration 1090 : 0.03078669309616089
Loss at iteration 1100 : 0.019682930782437325
Loss at iteration 1110 : 0.020671680569648743
Loss at iteration 1120 : 0.020562119781970978
Loss at iteration 1130 : 0.012480208650231361
Loss at iteration 1140 : 0.021041784435510635
Loss at iteration 1150 : 0.021856237202882767
Loss at iteration 1160 : 0.015270398929715157
Loss at iteration 1170 : 0.03945918753743172
Loss at iteration 1180 : 0.014789963141083717
Loss at iteration 1190 : 0.019592059776186943
Loss at iteration 1200 : 0.02453646808862686
Loss at iteration 1210 : 0.01835102215409279
The SSIM Value is: 0.8030187169710795
The PSNR Value is: 20.385664240519205
the highest SSIM value is: 20.385664240519205
the epoch is: 183
Loss at iteration 10 : 0.018230747431516647
Loss at iteration 20 : 0.016269885003566742
Loss at iteration 30 : 0.02007749117910862
Loss at iteration 40 : 0.025895345956087112
Loss at iteration 50 : 0.021475929766893387
Loss at iteration 60 : 0.018909266218543053
Loss at iteration 70 : 0.01803930476307869
Loss at iteration 80 : 0.019476650282740593
Loss at iteration 90 : 0.018768638372421265
Loss at iteration 100 : 0.01890821009874344
Loss at iteration 110 : 0.016807347536087036
Loss at iteration 120 : 0.018557874485850334
Loss at iteration 130 : 0.012823794968426228
Loss at iteration 140 : 0.022356631234288216
Loss at iteration 150 : 0.018434736877679825
Loss at iteration 160 : 0.013671763241291046
Loss at iteration 170 : 0.018679149448871613
Loss at iteration 180 : 0.01891913264989853
Loss at iteration 190 : 0.025063877925276756
Loss at iteration 200 : 0.023536913096904755
Loss at iteration 210 : 0.012999988161027431
Loss at iteration 220 : 0.025452744215726852
Loss at iteration 230 : 0.013893615454435349
Loss at iteration 240 : 0.023083291947841644
Loss at iteration 250 : 0.01639978215098381
Loss at iteration 260 : 0.017391012981534004
Loss at iteration 270 : 0.013551519252359867
Loss at iteration 280 : 0.024834247305989265
Loss at iteration 290 : 0.013204085640609264
Loss at iteration 300 : 0.021940680220723152
Loss at iteration 310 : 0.012345955707132816
Loss at iteration 320 : 0.01536292489618063
Loss at iteration 330 : 0.012395920231938362
Loss at iteration 340 : 0.023704972118139267
Loss at iteration 350 : 0.017277348786592484
Loss at iteration 360 : 0.02481589838862419
Loss at iteration 370 : 0.021552259102463722
Loss at iteration 380 : 0.024700168520212173
Loss at iteration 390 : 0.013014160096645355
Loss at iteration 400 : 0.01507573202252388
Loss at iteration 410 : 0.018086066469550133
Loss at iteration 420 : 0.025376293808221817
Loss at iteration 430 : 0.017166737467050552
Loss at iteration 440 : 0.0192917101085186
Loss at iteration 450 : 0.031224610283970833
Loss at iteration 460 : 0.01752142794430256
Loss at iteration 470 : 0.022596023976802826
Loss at iteration 480 : 0.012197817675769329
Loss at iteration 490 : 0.025866400450468063
Loss at iteration 500 : 0.013315195217728615
Loss at iteration 510 : 0.037188880145549774
Loss at iteration 520 : 0.01940920576453209
Loss at iteration 530 : 0.01365230605006218
Loss at iteration 540 : 0.02153788134455681
Loss at iteration 550 : 0.015721997246146202
Loss at iteration 560 : 0.014321811497211456
Loss at iteration 570 : 0.02484421245753765
Loss at iteration 580 : 0.02294742316007614
Loss at iteration 590 : 0.03108803555369377
Loss at iteration 600 : 0.015459447167813778
Loss at iteration 610 : 0.015455109998583794
Loss at iteration 620 : 0.009870236739516258
Loss at iteration 630 : 0.014472374692559242
Loss at iteration 640 : 0.015092458575963974
Loss at iteration 650 : 0.02471577376127243
Loss at iteration 660 : 0.0195529293268919
Loss at iteration 670 : 0.013303195126354694
Loss at iteration 680 : 0.01152532733976841
Loss at iteration 690 : 0.009333853609859943
Loss at iteration 700 : 0.013720205053687096
Loss at iteration 710 : 0.028409257531166077
Loss at iteration 720 : 0.019678572192788124
Loss at iteration 730 : 0.01813260093331337
Loss at iteration 740 : 0.02367517538368702
Loss at iteration 750 : 0.017845729365944862
Loss at iteration 760 : 0.01378057524561882
Loss at iteration 770 : 0.01161121018230915
Loss at iteration 780 : 0.018282096832990646
Loss at iteration 790 : 0.023885518312454224
Loss at iteration 800 : 0.017432261258363724
Loss at iteration 810 : 0.016701307147741318
Loss at iteration 820 : 0.02217899262905121
Loss at iteration 830 : 0.02469559572637081
Loss at iteration 840 : 0.01602843590080738
Loss at iteration 850 : 0.024366550147533417
Loss at iteration 860 : 0.017140638083219528
Loss at iteration 870 : 0.01541190966963768
Loss at iteration 880 : 0.022601081058382988
Loss at iteration 890 : 0.017155177891254425
Loss at iteration 900 : 0.015263533219695091
Loss at iteration 910 : 0.011557874269783497
Loss at iteration 920 : 0.01974731683731079
Loss at iteration 930 : 0.03285389393568039
Loss at iteration 940 : 0.014409471303224564
Loss at iteration 950 : 0.02369893155992031
Loss at iteration 960 : 0.01813890039920807
Loss at iteration 970 : 0.0137404166162014
Loss at iteration 980 : 0.022994015365839005
Loss at iteration 990 : 0.01966722309589386
Loss at iteration 1000 : 0.016568925231695175
Loss at iteration 1010 : 0.026432063430547714
Loss at iteration 1020 : 0.024495918303728104
Loss at iteration 1030 : 0.013477198779582977
Loss at iteration 1040 : 0.02216784656047821
Loss at iteration 1050 : 0.015682561323046684
Loss at iteration 1060 : 0.018733471632003784
Loss at iteration 1070 : 0.02336105704307556
Loss at iteration 1080 : 0.022852640599012375
Loss at iteration 1090 : 0.026579806581139565
Loss at iteration 1100 : 0.014275720342993736
Loss at iteration 1110 : 0.0149804363027215
Loss at iteration 1120 : 0.013504216447472572
Loss at iteration 1130 : 0.025541536509990692
Loss at iteration 1140 : 0.024204326793551445
Loss at iteration 1150 : 0.020060177892446518
Loss at iteration 1160 : 0.030538519844412804
Loss at iteration 1170 : 0.021646134555339813
Loss at iteration 1180 : 0.021050794050097466
Loss at iteration 1190 : 0.01889754645526409
Loss at iteration 1200 : 0.01216498389840126
Loss at iteration 1210 : 0.023805227130651474
The SSIM Value is: 0.7660039226214092
The PSNR Value is: 17.35334186553955
the epoch is: 184
Loss at iteration 10 : 0.018413782119750977
Loss at iteration 20 : 0.019707847386598587
Loss at iteration 30 : 0.02425505965948105
Loss at iteration 40 : 0.013880060985684395
Loss at iteration 50 : 0.023241076618433
Loss at iteration 60 : 0.015509366989135742
Loss at iteration 70 : 0.018535161390900612
Loss at iteration 80 : 0.020398501306772232
Loss at iteration 90 : 0.011453112587332726
Loss at iteration 100 : 0.018930306658148766
Loss at iteration 110 : 0.027787966653704643
Loss at iteration 120 : 0.018710199743509293
Loss at iteration 130 : 0.01982683129608631
Loss at iteration 140 : 0.02271544188261032
Loss at iteration 150 : 0.03144370764493942
Loss at iteration 160 : 0.03320534527301788
Loss at iteration 170 : 0.018115760758519173
Loss at iteration 180 : 0.013052050955593586
Loss at iteration 190 : 0.031244153156876564
Loss at iteration 200 : 0.022444508969783783
Loss at iteration 210 : 0.020370420068502426
Loss at iteration 220 : 0.026821758598089218
Loss at iteration 230 : 0.01826641336083412
Loss at iteration 240 : 0.02045445889234543
Loss at iteration 250 : 0.032978422939777374
Loss at iteration 260 : 0.015480096451938152
Loss at iteration 270 : 0.014559581875801086
Loss at iteration 280 : 0.02236289158463478
Loss at iteration 290 : 0.02951722964644432
Loss at iteration 300 : 0.025747237727046013
Loss at iteration 310 : 0.02132074162364006
Loss at iteration 320 : 0.020244363695383072
Loss at iteration 330 : 0.020732659846544266
Loss at iteration 340 : 0.016087505966424942
Loss at iteration 350 : 0.018141986802220345
Loss at iteration 360 : 0.015495102852582932
Loss at iteration 370 : 0.017176741734147072
Loss at iteration 380 : 0.02071283757686615
Loss at iteration 390 : 0.016266757622361183
Loss at iteration 400 : 0.012114817276597023
Loss at iteration 410 : 0.024380233138799667
Loss at iteration 420 : 0.021159829571843147
Loss at iteration 430 : 0.01739475317299366
Loss at iteration 440 : 0.021887142211198807
Loss at iteration 450 : 0.011686783283948898
Loss at iteration 460 : 0.01703522354364395
Loss at iteration 470 : 0.014446841552853584
Loss at iteration 480 : 0.015511177480220795
Loss at iteration 490 : 0.015008211135864258
Loss at iteration 500 : 0.016511457040905952
Loss at iteration 510 : 0.021893687546253204
Loss at iteration 520 : 0.02495584264397621
Loss at iteration 530 : 0.02042638510465622
Loss at iteration 540 : 0.011066458187997341
Loss at iteration 550 : 0.016374817118048668
Loss at iteration 560 : 0.020941510796546936
Loss at iteration 570 : 0.010723114013671875
Loss at iteration 580 : 0.024667154997587204
Loss at iteration 590 : 0.01386787835508585
Loss at iteration 600 : 0.010402429848909378
Loss at iteration 610 : 0.01615864597260952
Loss at iteration 620 : 0.017425794154405594
Loss at iteration 630 : 0.016560040414333344
Loss at iteration 640 : 0.010765028186142445
Loss at iteration 650 : 0.01946462132036686
Loss at iteration 660 : 0.020937129855155945
Loss at iteration 670 : 0.023595724254846573
Loss at iteration 680 : 0.018486041575670242
Loss at iteration 690 : 0.017267480492591858
Loss at iteration 700 : 0.012081880122423172
Loss at iteration 710 : 0.030703548341989517
Loss at iteration 720 : 0.018852129578590393
Loss at iteration 730 : 0.017226567491889
Loss at iteration 740 : 0.016384372487664223
Loss at iteration 750 : 0.01942799799144268
Loss at iteration 760 : 0.035253554582595825
Loss at iteration 770 : 0.032485783100128174
Loss at iteration 780 : 0.01676638051867485
Loss at iteration 790 : 0.015048358589410782
Loss at iteration 800 : 0.019143735989928246
Loss at iteration 810 : 0.02767029032111168
Loss at iteration 820 : 0.026442330330610275
Loss at iteration 830 : 0.02221531793475151
Loss at iteration 840 : 0.018067989498376846
Loss at iteration 850 : 0.024142775684595108
Loss at iteration 860 : 0.016127046197652817
Loss at iteration 870 : 0.03362441807985306
Loss at iteration 880 : 0.01897931657731533
Loss at iteration 890 : 0.021108577027916908
Loss at iteration 900 : 0.010717672295868397
Loss at iteration 910 : 0.02514791302382946
Loss at iteration 920 : 0.01614084094762802
Loss at iteration 930 : 0.023975612595677376
Loss at iteration 940 : 0.01941048353910446
Loss at iteration 950 : 0.011160824447870255
Loss at iteration 960 : 0.017373401671648026
Loss at iteration 970 : 0.021953925490379333
Loss at iteration 980 : 0.034784603863954544
Loss at iteration 990 : 0.015500307083129883
Loss at iteration 1000 : 0.013443538919091225
Loss at iteration 1010 : 0.013987865298986435
Loss at iteration 1020 : 0.018886204808950424
Loss at iteration 1030 : 0.019117023795843124
Loss at iteration 1040 : 0.01597468927502632
Loss at iteration 1050 : 0.01621970906853676
Loss at iteration 1060 : 0.026341687887907028
Loss at iteration 1070 : 0.01571054197847843
Loss at iteration 1080 : 0.01637185364961624
Loss at iteration 1090 : 0.0200229249894619
Loss at iteration 1100 : 0.02765345387160778
Loss at iteration 1110 : 0.023006156086921692
Loss at iteration 1120 : 0.012108471244573593
Loss at iteration 1130 : 0.008564329706132412
Loss at iteration 1140 : 0.013788042590022087
Loss at iteration 1150 : 0.018825337290763855
Loss at iteration 1160 : 0.01576247625052929
Loss at iteration 1170 : 0.01276136003434658
Loss at iteration 1180 : 0.015290401875972748
Loss at iteration 1190 : 0.018750593066215515
Loss at iteration 1200 : 0.015391523018479347
Loss at iteration 1210 : 0.011128142476081848
The SSIM Value is: 0.8002751032511394
The PSNR Value is: 20.184384727478026
the epoch is: 185
Loss at iteration 10 : 0.01494690589606762
Loss at iteration 20 : 0.020844716578722
Loss at iteration 30 : 0.01288620661944151
Loss at iteration 40 : 0.018518975004553795
Loss at iteration 50 : 0.023192808032035828
Loss at iteration 60 : 0.014031941071152687
Loss at iteration 70 : 0.015871316194534302
Loss at iteration 80 : 0.015874357894062996
Loss at iteration 90 : 0.021353913471102715
Loss at iteration 100 : 0.01722976192831993
Loss at iteration 110 : 0.025300756096839905
Loss at iteration 120 : 0.018616799265146255
Loss at iteration 130 : 0.017419829964637756
Loss at iteration 140 : 0.027202602475881577
Loss at iteration 150 : 0.017018519341945648
Loss at iteration 160 : 0.02642865478992462
Loss at iteration 170 : 0.021019991487264633
Loss at iteration 180 : 0.02166695147752762
Loss at iteration 190 : 0.011456766165792942
Loss at iteration 200 : 0.01891465112566948
Loss at iteration 210 : 0.016971271485090256
Loss at iteration 220 : 0.02265363745391369
Loss at iteration 230 : 0.020639996975660324
Loss at iteration 240 : 0.01249135285615921
Loss at iteration 250 : 0.02821299061179161
Loss at iteration 260 : 0.03125202655792236
Loss at iteration 270 : 0.024924136698246002
Loss at iteration 280 : 0.011542025953531265
Loss at iteration 290 : 0.016346124932169914
Loss at iteration 300 : 0.030667442828416824
Loss at iteration 310 : 0.011213129386305809
Loss at iteration 320 : 0.015164725482463837
Loss at iteration 330 : 0.03519534692168236
Loss at iteration 340 : 0.011055986396968365
Loss at iteration 350 : 0.01623324118554592
Loss at iteration 360 : 0.016760043799877167
Loss at iteration 370 : 0.01842428185045719
Loss at iteration 380 : 0.01455902773886919
Loss at iteration 390 : 0.01733679510653019
Loss at iteration 400 : 0.020521916449069977
Loss at iteration 410 : 0.022029118612408638
Loss at iteration 420 : 0.021425005048513412
Loss at iteration 430 : 0.02770000323653221
Loss at iteration 440 : 0.017827488481998444
Loss at iteration 450 : 0.02116841822862625
Loss at iteration 460 : 0.016361745074391365
Loss at iteration 470 : 0.016413923352956772
Loss at iteration 480 : 0.03474019095301628
Loss at iteration 490 : 0.023717273026704788
Loss at iteration 500 : 0.02118251845240593
Loss at iteration 510 : 0.019368566572666168
Loss at iteration 520 : 0.014899007976055145
Loss at iteration 530 : 0.014505980536341667
Loss at iteration 540 : 0.011618717573583126
Loss at iteration 550 : 0.012794308364391327
Loss at iteration 560 : 0.033174701035022736
Loss at iteration 570 : 0.013830211013555527
Loss at iteration 580 : 0.011119252070784569
Loss at iteration 590 : 0.013663573190569878
Loss at iteration 600 : 0.015164203010499477
Loss at iteration 610 : 0.018990408629179
Loss at iteration 620 : 0.016196858137845993
Loss at iteration 630 : 0.013988323509693146
Loss at iteration 640 : 0.02573072724044323
Loss at iteration 650 : 0.026830192655324936
Loss at iteration 660 : 0.013160363771021366
Loss at iteration 670 : 0.03288891911506653
Loss at iteration 680 : 0.01583769917488098
Loss at iteration 690 : 0.01429489441215992
Loss at iteration 700 : 0.018404889851808548
Loss at iteration 710 : 0.027850288897752762
Loss at iteration 720 : 0.01928585395216942
Loss at iteration 730 : 0.026574626564979553
Loss at iteration 740 : 0.010839167982339859
Loss at iteration 750 : 0.017795158550143242
Loss at iteration 760 : 0.017174862325191498
Loss at iteration 770 : 0.01577087678015232
Loss at iteration 780 : 0.01812748610973358
Loss at iteration 790 : 0.019297843798995018
Loss at iteration 800 : 0.014034162275493145
Loss at iteration 810 : 0.02720705233514309
Loss at iteration 820 : 0.018892791122198105
Loss at iteration 830 : 0.016795752570033073
Loss at iteration 840 : 0.01965022087097168
Loss at iteration 850 : 0.016292110085487366
Loss at iteration 860 : 0.02196919173002243
Loss at iteration 870 : 0.014758451841771603
Loss at iteration 880 : 0.01966388151049614
Loss at iteration 890 : 0.015194285660982132
Loss at iteration 900 : 0.017902996391057968
Loss at iteration 910 : 0.016784977167844772
Loss at iteration 920 : 0.018118737265467644
Loss at iteration 930 : 0.0153725016862154
Loss at iteration 940 : 0.009746064431965351
Loss at iteration 950 : 0.016778703778982162
Loss at iteration 960 : 0.019538037478923798
Loss at iteration 970 : 0.0299818217754364
Loss at iteration 980 : 0.027376042678952217
Loss at iteration 990 : 0.018428433686494827
Loss at iteration 1000 : 0.017796939238905907
Loss at iteration 1010 : 0.01373968180269003
Loss at iteration 1020 : 0.022644411772489548
Loss at iteration 1030 : 0.0180549044162035
Loss at iteration 1040 : 0.015720481052994728
Loss at iteration 1050 : 0.017208198085427284
Loss at iteration 1060 : 0.023650115355849266
Loss at iteration 1070 : 0.02435961365699768
Loss at iteration 1080 : 0.012320959940552711
Loss at iteration 1090 : 0.01882985793054104
Loss at iteration 1100 : 0.011603452265262604
Loss at iteration 1110 : 0.017798040062189102
Loss at iteration 1120 : 0.021892858669161797
Loss at iteration 1130 : 0.017248166725039482
Loss at iteration 1140 : 0.031550075858831406
Loss at iteration 1150 : 0.02910051867365837
Loss at iteration 1160 : 0.02418982982635498
Loss at iteration 1170 : 0.015022999607026577
Loss at iteration 1180 : 0.01262519508600235
Loss at iteration 1190 : 0.014981082640588284
Loss at iteration 1200 : 0.027005527168512344
Loss at iteration 1210 : 0.020932557061314583
The SSIM Value is: 0.7980889280637106
The PSNR Value is: 19.783065478007
the epoch is: 186
Loss at iteration 10 : 0.016889045014977455
Loss at iteration 20 : 0.02629496157169342
Loss at iteration 30 : 0.018630241975188255
Loss at iteration 40 : 0.0178022813051939
Loss at iteration 50 : 0.0243537575006485
Loss at iteration 60 : 0.021891087293624878
Loss at iteration 70 : 0.017117977142333984
Loss at iteration 80 : 0.026528023183345795
Loss at iteration 90 : 0.023897254839539528
Loss at iteration 100 : 0.02311832457780838
Loss at iteration 110 : 0.017664659768342972
Loss at iteration 120 : 0.018237348645925522
Loss at iteration 130 : 0.02273980714380741
Loss at iteration 140 : 0.01747184991836548
Loss at iteration 150 : 0.01934395357966423
Loss at iteration 160 : 0.01776665635406971
Loss at iteration 170 : 0.02200816199183464
Loss at iteration 180 : 0.022900857031345367
Loss at iteration 190 : 0.019300255924463272
Loss at iteration 200 : 0.024394912645220757
Loss at iteration 210 : 0.02387409657239914
Loss at iteration 220 : 0.020111002027988434
Loss at iteration 230 : 0.021691035479307175
Loss at iteration 240 : 0.016346197575330734
Loss at iteration 250 : 0.01777581311762333
Loss at iteration 260 : 0.011837962083518505
Loss at iteration 270 : 0.025840867310762405
Loss at iteration 280 : 0.020143404603004456
Loss at iteration 290 : 0.025197530165314674
Loss at iteration 300 : 0.00907149724662304
Loss at iteration 310 : 0.010165324434638023
Loss at iteration 320 : 0.02737969532608986
Loss at iteration 330 : 0.017550669610500336
Loss at iteration 340 : 0.025078579783439636
Loss at iteration 350 : 0.02807721495628357
Loss at iteration 360 : 0.011703796684741974
Loss at iteration 370 : 0.02917679026722908
Loss at iteration 380 : 0.019426055252552032
Loss at iteration 390 : 0.015268616378307343
Loss at iteration 400 : 0.029529737308621407
Loss at iteration 410 : 0.01231023482978344
Loss at iteration 420 : 0.024957530200481415
Loss at iteration 430 : 0.015166973695158958
Loss at iteration 440 : 0.015238120220601559
Loss at iteration 450 : 0.02343154326081276
Loss at iteration 460 : 0.023595811799168587
Loss at iteration 470 : 0.0272439606487751
Loss at iteration 480 : 0.021014302968978882
Loss at iteration 490 : 0.01635199412703514
Loss at iteration 500 : 0.0299425907433033
Loss at iteration 510 : 0.018824532628059387
Loss at iteration 520 : 0.013251670636236668
Loss at iteration 530 : 0.017887422814965248
Loss at iteration 540 : 0.031068217009305954
Loss at iteration 550 : 0.014269832521677017
Loss at iteration 560 : 0.018364232033491135
Loss at iteration 570 : 0.014209852553904057
Loss at iteration 580 : 0.021134406328201294
Loss at iteration 590 : 0.011423381045460701
Loss at iteration 600 : 0.02032952383160591
Loss at iteration 610 : 0.008635051548480988
Loss at iteration 620 : 0.03110882081091404
Loss at iteration 630 : 0.02393059805035591
Loss at iteration 640 : 0.013736741617321968
Loss at iteration 650 : 0.0249762125313282
Loss at iteration 660 : 0.012941980734467506
Loss at iteration 670 : 0.015153350308537483
Loss at iteration 680 : 0.019002724438905716
Loss at iteration 690 : 0.01660454086959362
Loss at iteration 700 : 0.013711192645132542
Loss at iteration 710 : 0.029912862926721573
Loss at iteration 720 : 0.018582399934530258
Loss at iteration 730 : 0.01767401397228241
Loss at iteration 740 : 0.013115780428051949
Loss at iteration 750 : 0.01711917854845524
Loss at iteration 760 : 0.018532203510403633
Loss at iteration 770 : 0.020706811919808388
Loss at iteration 780 : 0.01356297917664051
Loss at iteration 790 : 0.025374282151460648
Loss at iteration 800 : 0.02442173846065998
Loss at iteration 810 : 0.02056739665567875
Loss at iteration 820 : 0.013632794842123985
Loss at iteration 830 : 0.013195967301726341
Loss at iteration 840 : 0.022937340661883354
Loss at iteration 850 : 0.01851239986717701
Loss at iteration 860 : 0.016854921355843544
Loss at iteration 870 : 0.023121165111660957
Loss at iteration 880 : 0.01965440809726715
Loss at iteration 890 : 0.015767041593790054
Loss at iteration 900 : 0.02044660970568657
Loss at iteration 910 : 0.028901901096105576
Loss at iteration 920 : 0.024385761469602585
Loss at iteration 930 : 0.012680409476161003
Loss at iteration 940 : 0.01725931279361248
Loss at iteration 950 : 0.014664637856185436
Loss at iteration 960 : 0.03553343191742897
Loss at iteration 970 : 0.008633408695459366
Loss at iteration 980 : 0.014964282512664795
Loss at iteration 990 : 0.02079533040523529
Loss at iteration 1000 : 0.01527328509837389
Loss at iteration 1010 : 0.018046539276838303
Loss at iteration 1020 : 0.013590516522526741
Loss at iteration 1030 : 0.01847519725561142
Loss at iteration 1040 : 0.014826125465333462
Loss at iteration 1050 : 0.03211752697825432
Loss at iteration 1060 : 0.018908489495515823
Loss at iteration 1070 : 0.035799745470285416
Loss at iteration 1080 : 0.019962146878242493
Loss at iteration 1090 : 0.022017184644937515
Loss at iteration 1100 : 0.02458067052066326
Loss at iteration 1110 : 0.010561417788267136
Loss at iteration 1120 : 0.027503617107868195
Loss at iteration 1130 : 0.013942752033472061
Loss at iteration 1140 : 0.013892430812120438
Loss at iteration 1150 : 0.014558274298906326
Loss at iteration 1160 : 0.02144637703895569
Loss at iteration 1170 : 0.01971924677491188
Loss at iteration 1180 : 0.026403583586215973
Loss at iteration 1190 : 0.025853939354419708
Loss at iteration 1200 : 0.020245492458343506
Loss at iteration 1210 : 0.01790429651737213
The SSIM Value is: 0.7976455092430115
The PSNR Value is: 19.77389316558838
the epoch is: 187
Loss at iteration 10 : 0.012527337297797203
Loss at iteration 20 : 0.017071731388568878
Loss at iteration 30 : 0.02589281275868416
Loss at iteration 40 : 0.01585940644145012
Loss at iteration 50 : 0.015810446813702583
Loss at iteration 60 : 0.014104390516877174
Loss at iteration 70 : 0.016440846025943756
Loss at iteration 80 : 0.02677799016237259
Loss at iteration 90 : 0.016997773200273514
Loss at iteration 100 : 0.029414309188723564
Loss at iteration 110 : 0.017237305641174316
Loss at iteration 120 : 0.01123152393847704
Loss at iteration 130 : 0.024967104196548462
Loss at iteration 140 : 0.01598450168967247
Loss at iteration 150 : 0.02642272412776947
Loss at iteration 160 : 0.017634138464927673
Loss at iteration 170 : 0.026104692369699478
Loss at iteration 180 : 0.019486134871840477
Loss at iteration 190 : 0.015169662423431873
Loss at iteration 200 : 0.01912868581712246
Loss at iteration 210 : 0.021992407739162445
Loss at iteration 220 : 0.02204829826951027
Loss at iteration 230 : 0.015526622533798218
Loss at iteration 240 : 0.029332194477319717
Loss at iteration 250 : 0.01854383759200573
Loss at iteration 260 : 0.017290374264121056
Loss at iteration 270 : 0.016917001456022263
Loss at iteration 280 : 0.01991540566086769
Loss at iteration 290 : 0.013588469475507736
Loss at iteration 300 : 0.021046116948127747
Loss at iteration 310 : 0.011595934629440308
Loss at iteration 320 : 0.019070541486144066
Loss at iteration 330 : 0.019063424319028854
Loss at iteration 340 : 0.016695888713002205
Loss at iteration 350 : 0.019630402326583862
Loss at iteration 360 : 0.02055031806230545
Loss at iteration 370 : 0.030604099854826927
Loss at iteration 380 : 0.015553101897239685
Loss at iteration 390 : 0.025436893105506897
Loss at iteration 400 : 0.016436349600553513
Loss at iteration 410 : 0.02524770423769951
Loss at iteration 420 : 0.014226481318473816
Loss at iteration 430 : 0.019532328471541405
Loss at iteration 440 : 0.028839847072958946
Loss at iteration 450 : 0.020679613575339317
Loss at iteration 460 : 0.01207183301448822
Loss at iteration 470 : 0.01642586849629879
Loss at iteration 480 : 0.013777746818959713
Loss at iteration 490 : 0.02771296724677086
Loss at iteration 500 : 0.02856115810573101
Loss at iteration 510 : 0.01982647180557251
Loss at iteration 520 : 0.0224209763109684
Loss at iteration 530 : 0.021175865083932877
Loss at iteration 540 : 0.02153177373111248
Loss at iteration 550 : 0.03122992254793644
Loss at iteration 560 : 0.014349345117807388
Loss at iteration 570 : 0.01953582838177681
Loss at iteration 580 : 0.017876697704195976
Loss at iteration 590 : 0.01230841688811779
Loss at iteration 600 : 0.019100939854979515
Loss at iteration 610 : 0.019806422293186188
Loss at iteration 620 : 0.01404520496726036
Loss at iteration 630 : 0.021426042541861534
Loss at iteration 640 : 0.01188661903142929
Loss at iteration 650 : 0.015595681965351105
Loss at iteration 660 : 0.019873594865202904
Loss at iteration 670 : 0.020031776279211044
Loss at iteration 680 : 0.023098237812519073
Loss at iteration 690 : 0.01523924246430397
Loss at iteration 700 : 0.017249809578061104
Loss at iteration 710 : 0.020174182951450348
Loss at iteration 720 : 0.022954657673835754
Loss at iteration 730 : 0.020230039954185486
Loss at iteration 740 : 0.012268215417861938
Loss at iteration 750 : 0.02408178336918354
Loss at iteration 760 : 0.021722223609685898
Loss at iteration 770 : 0.021520163863897324
Loss at iteration 780 : 0.02157895267009735
Loss at iteration 790 : 0.02169136330485344
Loss at iteration 800 : 0.02442212961614132
Loss at iteration 810 : 0.02572581171989441
Loss at iteration 820 : 0.017197441309690475
Loss at iteration 830 : 0.017839083448052406
Loss at iteration 840 : 0.008791245520114899
Loss at iteration 850 : 0.0169023796916008
Loss at iteration 860 : 0.023295771330595016
Loss at iteration 870 : 0.027014892548322678
Loss at iteration 880 : 0.023246249184012413
Loss at iteration 890 : 0.018264876678586006
Loss at iteration 900 : 0.02608366310596466
Loss at iteration 910 : 0.02049211785197258
Loss at iteration 920 : 0.025041643530130386
Loss at iteration 930 : 0.01996007189154625
Loss at iteration 940 : 0.019627787172794342
Loss at iteration 950 : 0.01807544380426407
Loss at iteration 960 : 0.01665256917476654
Loss at iteration 970 : 0.014685913920402527
Loss at iteration 980 : 0.018614046275615692
Loss at iteration 990 : 0.01968715898692608
Loss at iteration 1000 : 0.014985723420977592
Loss at iteration 1010 : 0.016295848414301872
Loss at iteration 1020 : 0.025644320994615555
Loss at iteration 1030 : 0.017130285501480103
Loss at iteration 1040 : 0.012827202677726746
Loss at iteration 1050 : 0.01540709100663662
Loss at iteration 1060 : 0.010216062888503075
Loss at iteration 1070 : 0.017760274931788445
Loss at iteration 1080 : 0.01735684648156166
Loss at iteration 1090 : 0.0182284377515316
Loss at iteration 1100 : 0.021367065608501434
Loss at iteration 1110 : 0.01506645418703556
Loss at iteration 1120 : 0.02433616854250431
Loss at iteration 1130 : 0.029335318133234978
Loss at iteration 1140 : 0.014442170970141888
Loss at iteration 1150 : 0.021854044869542122
Loss at iteration 1160 : 0.017681023105978966
Loss at iteration 1170 : 0.01342497207224369
Loss at iteration 1180 : 0.02384864166378975
Loss at iteration 1190 : 0.01857002079486847
Loss at iteration 1200 : 0.01551842875778675
Loss at iteration 1210 : 0.013339969329535961
The SSIM Value is: 0.8037527918815612
The PSNR Value is: 19.978645769755044
the epoch is: 188
