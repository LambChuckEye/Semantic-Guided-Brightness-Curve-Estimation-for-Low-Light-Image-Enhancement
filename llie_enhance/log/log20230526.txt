/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
只使用curve进行训练
Namespace(gpu_id=1, img_path='/home/wsz/workspace/Data/SAM_test/our485/low/', img_val_path='/home/wsz/workspace/Data/SAM_test/eval15/low/', batch_size=7, lr=0.0002, weight_decay=1e-08, pretrain_dir=None, num_epochs=400, display_iter=10, snapshots_folder='workdirs/snapshots_folder_lolv1_SAM_2023052')
Total examples: 12283
Total examples: 454
the device is: cuda:0
######## Start IAT Training #########
the epoch is: 0
Loss at iteration 10 : 0.007350178901106119
Loss at iteration 20 : 0.0009424947784282267
Loss at iteration 30 : 0.00012768877786584198
Loss at iteration 40 : 0.00032860939973033965
Loss at iteration 50 : 0.0005819363286718726
Loss at iteration 60 : 0.003887869417667389
Loss at iteration 70 : 0.00011106950114481151
Loss at iteration 80 : 0.0033885601442307234
Loss at iteration 90 : 0.00012301751121412963
Loss at iteration 100 : 0.00021445227321237326
Loss at iteration 110 : 9.02385072549805e-05
Loss at iteration 120 : 0.0004879926855210215
Loss at iteration 130 : 0.0008708032546564937
Loss at iteration 140 : 0.00015379022806882858
Loss at iteration 150 : 0.00026967909070663154
Loss at iteration 160 : 0.0001836797600844875
Loss at iteration 170 : 0.003697123844176531
Loss at iteration 180 : 0.0010062482906505466
Loss at iteration 190 : 0.002358661964535713
Loss at iteration 200 : 0.0003890153602696955
Loss at iteration 210 : 0.0018844223814085126
Loss at iteration 220 : 0.001980576431378722
Loss at iteration 230 : 0.003878768067806959
Loss at iteration 240 : 0.002831028075888753
Loss at iteration 250 : 0.0003056580317206681
Loss at iteration 260 : 0.0028647305443882942
Loss at iteration 270 : 6.3094194047153e-05
Loss at iteration 280 : 0.00032453451422043145
Loss at iteration 290 : 0.0007434544386342168
Loss at iteration 300 : 0.0027294084429740906
Loss at iteration 310 : 0.001797048607841134
Loss at iteration 320 : 0.0008954654913395643
Loss at iteration 330 : 0.00011111105413874611
Loss at iteration 340 : 0.002542506903409958
Loss at iteration 350 : 0.0006734825437888503
Loss at iteration 360 : 0.006064916029572487
Loss at iteration 370 : 8.79594444995746e-05
Loss at iteration 380 : 0.0029056149069219828
Loss at iteration 390 : 0.00045109650818631053
Loss at iteration 400 : 0.0012451268266886473
Loss at iteration 410 : 0.0004860147018916905
Loss at iteration 420 : 0.001870545675046742
Loss at iteration 430 : 0.00044544044067151845
Loss at iteration 440 : 3.733412813744508e-05
Loss at iteration 450 : 0.007070723921060562
Loss at iteration 460 : 0.0022493384312838316
Loss at iteration 470 : 0.0030252172145992517
Loss at iteration 480 : 0.0003251795133110136
Loss at iteration 490 : 6.686548294965178e-05
Loss at iteration 500 : 0.0001331222738372162
Loss at iteration 510 : 0.000320540857501328
Loss at iteration 520 : 9.823844447964802e-05
Loss at iteration 530 : 0.0026782196946442127
Loss at iteration 540 : 0.004454521927982569
Loss at iteration 550 : 0.00017722761549521238
Loss at iteration 560 : 0.0001244288869202137
Loss at iteration 570 : 0.00030652800342068076
Loss at iteration 580 : 0.0005015283823013306
Loss at iteration 590 : 0.0015117443399503827
Loss at iteration 600 : 0.003263547085225582
Loss at iteration 610 : 0.0023494556080549955
Loss at iteration 620 : 7.51250481698662e-05
Loss at iteration 630 : 0.0001895590830827132
Loss at iteration 640 : 0.00030105197220109403
Loss at iteration 650 : 0.005164162255823612
Loss at iteration 660 : 0.0009130151011049747
Loss at iteration 670 : 0.00019622256513684988
Loss at iteration 680 : 0.00039403769187629223
Loss at iteration 690 : 0.00502758240327239
Loss at iteration 700 : 0.0002462597331032157
Loss at iteration 710 : 0.0007338027935475111
Loss at iteration 720 : 0.00387280504219234
Loss at iteration 730 : 0.006177137140184641
Loss at iteration 740 : 0.0037332128267735243
Loss at iteration 750 : 0.00016715240781195462
Loss at iteration 760 : 0.001873837667517364
Loss at iteration 770 : 0.0033328430727124214
Loss at iteration 780 : 0.0002607778296805918
Loss at iteration 790 : 0.0005010763998143375
Loss at iteration 800 : 0.003856378374621272
Loss at iteration 810 : 0.0007622526027262211
Loss at iteration 820 : 8.844590047374368e-05
Loss at iteration 830 : 0.0008306766394525766
Loss at iteration 840 : 0.0005441014072857797
Loss at iteration 850 : 0.0009406061144545674
Loss at iteration 860 : 0.0014723907224833965
Loss at iteration 870 : 0.00017508564633317292
Loss at iteration 880 : 6.728836160618812e-05
Loss at iteration 890 : 0.00037177710328251123
Loss at iteration 900 : 0.00019446326768957078
Loss at iteration 910 : 0.0002420454693492502
Loss at iteration 920 : 0.000878557504620403
Loss at iteration 930 : 0.0007636923110112548
Loss at iteration 940 : 0.0024280224461108446
Loss at iteration 950 : 0.00029055681079626083
Loss at iteration 960 : 0.0002383665123488754
Loss at iteration 970 : 9.682457312010229e-05
Loss at iteration 980 : 0.0011510413605719805
Loss at iteration 990 : 0.00036531267687678337
Loss at iteration 1000 : 0.00541116576641798
Loss at iteration 1010 : 0.007988231256604195
Loss at iteration 1020 : 0.0002848815929610282
Loss at iteration 1030 : 0.0002079883124679327
Loss at iteration 1040 : 0.00022464507492259145
Loss at iteration 1050 : 0.0008997516706585884
Loss at iteration 1060 : 0.0010936909820884466
Loss at iteration 1070 : 0.00021259236382320523
Loss at iteration 1080 : 0.000518808257766068
Loss at iteration 1090 : 0.00019075947056990117
Loss at iteration 1100 : 0.0032715569250285625
Loss at iteration 1110 : 0.0038382457569241524
Loss at iteration 1120 : 0.003497024532407522
Loss at iteration 1130 : 0.00016058475011959672
Loss at iteration 1140 : 0.0032190463971346617
Loss at iteration 1150 : 0.006788895931094885
Loss at iteration 1160 : 0.004275784362107515
Loss at iteration 1170 : 0.0034609874710440636
Loss at iteration 1180 : 0.00024857002426870167
Loss at iteration 1190 : 0.0003739029634743929
Loss at iteration 1200 : 0.00010896225285250694
Loss at iteration 1210 : 0.0008204932673834264
Loss at iteration 1220 : 6.531449616886675e-05
Loss at iteration 1230 : 0.0023576763924211264
Loss at iteration 1240 : 7.430070400005206e-05
Loss at iteration 1250 : 0.005771556403487921
Loss at iteration 1260 : 0.0002577011182438582
Loss at iteration 1270 : 0.00036441104020923376
Loss at iteration 1280 : 0.004162002354860306
Loss at iteration 1290 : 0.00346682732924819
Loss at iteration 1300 : 0.0001764650223776698
Loss at iteration 1310 : 0.00013271899661049247
Loss at iteration 1320 : 0.00011705199722200632
Loss at iteration 1330 : 0.0012737929355353117
Loss at iteration 1340 : 0.000542350288014859
Loss at iteration 1350 : 0.002030684147030115
Loss at iteration 1360 : 0.00028412893880158663
Loss at iteration 1370 : 0.0007628364255651832
Loss at iteration 1380 : 0.00018266074766870588
Loss at iteration 1390 : 0.011775831691920757
Loss at iteration 1400 : 0.000692525994963944
Loss at iteration 1410 : 0.0009774238569661975
Loss at iteration 1420 : 0.001802933169528842
Loss at iteration 1430 : 0.007331870496273041
Loss at iteration 1440 : 0.0007697801338508725
Loss at iteration 1450 : 0.0006143525242805481
Loss at iteration 1460 : 0.00015523160982411355
Loss at iteration 1470 : 0.0027799601666629314
Loss at iteration 1480 : 0.0002917190722655505
Loss at iteration 1490 : 0.0034992641303688288
Loss at iteration 1500 : 0.00471349386498332
Loss at iteration 1510 : 0.00015682325465604663
Loss at iteration 1520 : 6.223163654794917e-05
Loss at iteration 1530 : 0.0003656631160993129
Loss at iteration 1540 : 0.0033445372246205807
Loss at iteration 1550 : 0.00036262243520468473
Loss at iteration 1560 : 0.0007877909811213613
Loss at iteration 1570 : 0.00030832603806629777
Loss at iteration 1580 : 0.0002376771590206772
Loss at iteration 1590 : 0.0007993578910827637
Loss at iteration 1600 : 0.00013065522944089025
Loss at iteration 1610 : 0.0023336168378591537
Loss at iteration 1620 : 0.0003361462731845677
Loss at iteration 1630 : 0.0001983966212719679
Loss at iteration 1640 : 0.0004863182548433542
Loss at iteration 1650 : 0.00014028897567186505
Loss at iteration 1660 : 0.0005609927466139197
Loss at iteration 1670 : 0.0034558940678834915
Loss at iteration 1680 : 0.0006440513534471393
Loss at iteration 1690 : 0.0003082884941250086
Loss at iteration 1700 : 0.0001838687458075583
Loss at iteration 1710 : 5.581195728154853e-05
Loss at iteration 1720 : 0.0010336111299693584
Loss at iteration 1730 : 0.0001726369810057804
Loss at iteration 1740 : 0.0001812394184526056
Loss at iteration 1750 : 0.00020487920846790075
The SSIM Value is: 0.918821283242776
The PSNR Value is: 42.966356065304794
the highest SSIM value is: 42.966356065304794
the epoch is: 1
Loss at iteration 10 : 0.005313573405146599
Loss at iteration 20 : 0.00039530755020678043
Loss at iteration 30 : 0.004830135498195887
Loss at iteration 40 : 0.009457074105739594
Loss at iteration 50 : 0.000653195776976645
Loss at iteration 60 : 0.0005483592394739389
Loss at iteration 70 : 0.0004992850008420646
Loss at iteration 80 : 6.737907824572176e-05
Loss at iteration 90 : 0.003376193344593048
Loss at iteration 100 : 0.0004974317271262407
Loss at iteration 110 : 0.005681113339960575
Loss at iteration 120 : 0.0005223347106948495
Loss at iteration 130 : 0.0004586189170368016
Loss at iteration 140 : 0.002630680799484253
Loss at iteration 150 : 0.003457524348050356
Loss at iteration 160 : 0.00014679241576232016
Loss at iteration 170 : 0.00014828350686002523
Loss at iteration 180 : 0.0002821321540977806
Loss at iteration 190 : 0.00017021624080371112
Loss at iteration 200 : 0.00034217117354273796
Loss at iteration 210 : 0.0007345688063651323
Loss at iteration 220 : 0.0008861353853717446
Loss at iteration 230 : 0.00025720091070979834
Loss at iteration 240 : 0.0004901845823042095
Loss at iteration 250 : 0.0021555719431489706
Loss at iteration 260 : 0.00033886361052282155
Loss at iteration 270 : 0.00010644375288393348
Loss at iteration 280 : 0.00020875172049272805
Loss at iteration 290 : 0.0029544737190008163
Loss at iteration 300 : 0.003709771204739809
Loss at iteration 310 : 0.01479971781373024
Loss at iteration 320 : 0.0006373889627866447
Loss at iteration 330 : 0.0006225466495379806
Loss at iteration 340 : 0.00038245331961661577
Loss at iteration 350 : 0.00031161372317001224
Loss at iteration 360 : 0.00043989531695842743
Loss at iteration 370 : 0.00021159074094612151
Loss at iteration 380 : 0.0016580326482653618
Loss at iteration 390 : 0.003091855440288782
Loss at iteration 400 : 0.0012240735813975334
Loss at iteration 410 : 0.00026380218332633376
Loss at iteration 420 : 7.572205504402518e-05
Loss at iteration 430 : 0.00010491278953850269
Loss at iteration 440 : 0.0001592624030308798
Loss at iteration 450 : 0.000878764723893255
Loss at iteration 460 : 0.00023183169832918793
Loss at iteration 470 : 0.00013854260032530874
Loss at iteration 480 : 0.002950540976598859
Loss at iteration 490 : 0.003484870307147503
Loss at iteration 500 : 0.00033615983556956053
Loss at iteration 510 : 0.0054769935086369514
Loss at iteration 520 : 0.006090276874601841
Loss at iteration 530 : 0.00086392363300547
Loss at iteration 540 : 0.00014080823166295886
Loss at iteration 550 : 0.005800290964543819
Loss at iteration 560 : 0.0020428698044270277
Loss at iteration 570 : 0.0002151308726752177
Loss at iteration 580 : 0.00011487468145787716
Loss at iteration 590 : 0.00029949433519504964
Loss at iteration 600 : 0.005382312461733818
Loss at iteration 610 : 0.0004906455287709832
Loss at iteration 620 : 0.0020904114935547113
Loss at iteration 630 : 0.00025401302264072
Loss at iteration 640 : 0.0006157481693662703
Loss at iteration 650 : 0.0005518129328265786
Loss at iteration 660 : 0.0040357159450650215
Loss at iteration 670 : 0.00017933377239387482
Loss at iteration 680 : 0.000683403923176229
Loss at iteration 690 : 0.0010652834316715598
Loss at iteration 700 : 0.00042281480273231864
Loss at iteration 710 : 0.003203731495887041
Loss at iteration 720 : 0.00018378016829956323
Loss at iteration 730 : 0.0007034128066152334
Loss at iteration 740 : 0.00039755419129505754
Loss at iteration 750 : 0.0005014798953197896
Loss at iteration 760 : 0.00020976029918529093
Loss at iteration 770 : 0.00023787761165294796
Loss at iteration 780 : 0.00027508591301739216
Loss at iteration 790 : 0.0032149460166692734
Loss at iteration 800 : 0.0001971340534510091
Loss at iteration 810 : 0.001296511385589838
Loss at iteration 820 : 0.00011850053124362603
Loss at iteration 830 : 0.004103158134967089
Loss at iteration 840 : 0.0019127445993945003
Loss at iteration 850 : 0.0001953360188053921
Loss at iteration 860 : 0.0041829487308859825
Loss at iteration 870 : 0.00030944004538469017
Loss at iteration 880 : 0.00044882638030685484
Loss at iteration 890 : 0.00011034288763767108
Loss at iteration 900 : 0.0007537489291280508
Loss at iteration 910 : 0.0006143099744804204
Loss at iteration 920 : 0.001056690001860261
Loss at iteration 930 : 0.001096496358513832
Loss at iteration 940 : 0.002086372347548604
Loss at iteration 950 : 0.0036275992169976234
Loss at iteration 960 : 0.00014665380876976997
Loss at iteration 970 : 0.00013791798846796155
Loss at iteration 980 : 0.0002262041816720739
Loss at iteration 990 : 7.791824464220554e-05
Loss at iteration 1000 : 0.00024118274450302124
Loss at iteration 1010 : 0.0020466861315071583
Loss at iteration 1020 : 0.00035973830381408334
Loss at iteration 1030 : 0.0013572772732004523
Loss at iteration 1040 : 0.0017469144659116864
Loss at iteration 1050 : 0.0003748155140783638
Loss at iteration 1060 : 0.0005765940295532346
Loss at iteration 1070 : 0.0013892758870497346
Loss at iteration 1080 : 0.00013113566092215478
Loss at iteration 1090 : 0.00043633769382722676
Loss at iteration 1100 : 0.0008918846724554896
Loss at iteration 1110 : 0.0009405817836523056
Loss at iteration 1120 : 0.00019340691505931318
Loss at iteration 1130 : 0.000152804990648292
Loss at iteration 1140 : 7.340306183323264e-05
Loss at iteration 1150 : 0.0005041025578975677
Loss at iteration 1160 : 9.981281618820503e-05
Loss at iteration 1170 : 5.8282606914872304e-05
Loss at iteration 1180 : 0.0009118203888647258
Loss at iteration 1190 : 0.00036404695129022
Loss at iteration 1200 : 0.00012103888730052859
Loss at iteration 1210 : 0.0005863956757821143
Loss at iteration 1220 : 0.0003029776562470943
Loss at iteration 1230 : 0.0020021896343678236
Loss at iteration 1240 : 0.0012626961106434464
Loss at iteration 1250 : 0.00015677488408982754
Loss at iteration 1260 : 0.0007279596175067127
Loss at iteration 1270 : 0.0038512861356139183
Loss at iteration 1280 : 0.0006379756378009915
Loss at iteration 1290 : 0.00017381235375069082
Loss at iteration 1300 : 0.0005220115417614579
Loss at iteration 1310 : 0.001981833018362522
Loss at iteration 1320 : 0.00028897757874801755
Loss at iteration 1330 : 0.0006232434534467757
Loss at iteration 1340 : 5.636418063659221e-05
Loss at iteration 1350 : 0.0003109512908849865
Loss at iteration 1360 : 0.0031182882376015186
Loss at iteration 1370 : 0.0003697747888509184
Loss at iteration 1380 : 0.0006202151998877525
Loss at iteration 1390 : 0.003396859858185053
Loss at iteration 1400 : 0.0007351653184741735
Loss at iteration 1410 : 0.00020822891383431852
Loss at iteration 1420 : 0.0038467703852802515
Loss at iteration 1430 : 0.0004324815818108618
Loss at iteration 1440 : 0.009862249717116356
Loss at iteration 1450 : 0.000986774917691946
Loss at iteration 1460 : 0.0003428882628213614
Loss at iteration 1470 : 0.0006805001758038998
Loss at iteration 1480 : 0.0034414371475577354
Loss at iteration 1490 : 0.0003802546125371009
Loss at iteration 1500 : 0.0008794462191872299
Loss at iteration 1510 : 0.0029667485505342484
Loss at iteration 1520 : 0.0006502952892333269
Loss at iteration 1530 : 0.00010353126708650962
Loss at iteration 1540 : 0.005267859436571598
Loss at iteration 1550 : 0.00014964428555686027
Loss at iteration 1560 : 0.000349920941516757
Loss at iteration 1570 : 0.00022129673743620515
Loss at iteration 1580 : 0.00024374155327677727
Loss at iteration 1590 : 0.0005016142968088388
Loss at iteration 1600 : 0.0010252309730276465
Loss at iteration 1610 : 0.0012401547282934189
Loss at iteration 1620 : 0.00036567694041877985
Loss at iteration 1630 : 0.0003157412284053862
Loss at iteration 1640 : 0.00021638523321598768
Loss at iteration 1650 : 0.011328548192977905
Loss at iteration 1660 : 0.00014483263657893986
Loss at iteration 1670 : 0.00016445179062429816
Loss at iteration 1680 : 0.0002224085183115676
Loss at iteration 1690 : 0.0001981890673050657
Loss at iteration 1700 : 0.0066332509741187096
Loss at iteration 1710 : 0.00011196391278645024
Loss at iteration 1720 : 0.004335855133831501
Loss at iteration 1730 : 0.0014543597353622317
Loss at iteration 1740 : 0.00011747472308343276
Loss at iteration 1750 : 0.00044730299850925803
The SSIM Value is: 0.938770943538733
The PSNR Value is: 43.813889780758764
the highest SSIM value is: 43.813889780758764
the epoch is: 2
Loss at iteration 10 : 0.0014204233884811401
Loss at iteration 20 : 0.002218163339421153
Loss at iteration 30 : 0.0012136369477957487
Loss at iteration 40 : 0.00017626627231948078
Loss at iteration 50 : 0.00015087012434378266
Loss at iteration 60 : 0.0018837506650015712
Loss at iteration 70 : 0.000335410179104656
Loss at iteration 80 : 0.00011162023292854428
Loss at iteration 90 : 0.00023711964604444802
Loss at iteration 100 : 0.00044071199954487383
Loss at iteration 110 : 0.00037393998354673386
Loss at iteration 120 : 0.000843445654027164
Loss at iteration 130 : 0.0003575138689484447
Loss at iteration 140 : 0.00021933023526798934
Loss at iteration 150 : 0.00017480732640251517
Loss at iteration 160 : 0.00014717695012222975
Loss at iteration 170 : 0.000611287890933454
Loss at iteration 180 : 0.0004081355291418731
Loss at iteration 190 : 0.0010188756277784705
Loss at iteration 200 : 0.00015696274931542575
Loss at iteration 210 : 7.73663487052545e-05
Loss at iteration 220 : 0.0008932951604947448
Loss at iteration 230 : 0.0006328824674710631
Loss at iteration 240 : 0.003148432122543454
Loss at iteration 250 : 0.004693637602031231
Loss at iteration 260 : 0.0005469730240292847
Loss at iteration 270 : 0.0009701316594146192
Loss at iteration 280 : 0.0028638066723942757
Loss at iteration 290 : 0.0011899239616468549
Loss at iteration 300 : 0.006165062077343464
Loss at iteration 310 : 0.000998245901428163
Loss at iteration 320 : 0.00021445407764986157
Loss at iteration 330 : 0.00020023249089717865
Loss at iteration 340 : 0.00071956985630095
Loss at iteration 350 : 0.0003123439382761717
Loss at iteration 360 : 0.0007886816747486591
Loss at iteration 370 : 0.0002753640292212367
Loss at iteration 380 : 0.0019187149591743946
Loss at iteration 390 : 8.334965241374448e-05
Loss at iteration 400 : 0.0008806271944195032
Loss at iteration 410 : 0.000235644169151783
Loss at iteration 420 : 0.0029354169964790344
Loss at iteration 430 : 0.000836743856780231
Loss at iteration 440 : 0.00010369896335760131
Loss at iteration 450 : 0.0016406121430918574
Loss at iteration 460 : 0.00024889741325750947
Loss at iteration 470 : 0.00226104655303061
Loss at iteration 480 : 0.006939741782844067
Loss at iteration 490 : 0.00016853764827828854
Loss at iteration 500 : 0.0001390096585964784
Loss at iteration 510 : 0.0002060790720861405
Loss at iteration 520 : 0.0007908855914138258
Loss at iteration 530 : 7.658354297745973e-05
Loss at iteration 540 : 0.00628526508808136
Loss at iteration 550 : 0.00341605581343174
Loss at iteration 560 : 0.0005982412840239704
Loss at iteration 570 : 0.0005356962792575359
Loss at iteration 580 : 0.0040223440155386925
Loss at iteration 590 : 0.0003449559735599905
Loss at iteration 600 : 0.0008785619866102934
Loss at iteration 610 : 0.004711463116109371
Loss at iteration 620 : 0.003634176217019558
Loss at iteration 630 : 0.0005109853227622807
Loss at iteration 640 : 0.002999937627464533
Loss at iteration 650 : 0.0001341259339824319
Loss at iteration 660 : 0.00018710117728915066
Loss at iteration 670 : 0.00017274175479542464
Loss at iteration 680 : 0.00029236028785817325
Loss at iteration 690 : 0.0017063483828678727
Loss at iteration 700 : 0.0009906524792313576
Loss at iteration 710 : 0.009839843958616257
Loss at iteration 720 : 0.0012845966266468167
Loss at iteration 730 : 0.000510369660332799
Loss at iteration 740 : 0.00016752968076616526
Loss at iteration 750 : 0.00012188291293568909
Loss at iteration 760 : 8.108950714813545e-05
Loss at iteration 770 : 0.0008988467161543667
Loss at iteration 780 : 0.0021927859634160995
Loss at iteration 790 : 0.0016500444617122412
Loss at iteration 800 : 0.00016699638217687607
Loss at iteration 810 : 0.0005062641575932503
Loss at iteration 820 : 0.011815072037279606
Loss at iteration 830 : 8.117457764456049e-05
Loss at iteration 840 : 0.00031265662983059883
Loss at iteration 850 : 0.0010731727816164494
Loss at iteration 860 : 0.0021742265671491623
Loss at iteration 870 : 0.0035301828756928444
Loss at iteration 880 : 8.723639621166512e-05
Loss at iteration 890 : 0.0017520410474389791
Loss at iteration 900 : 0.00020745553774759173
Loss at iteration 910 : 0.00018900053692050278
Loss at iteration 920 : 0.0011103308061137795
Loss at iteration 930 : 0.0005987947806715965
Loss at iteration 940 : 0.00024055314133875072
Loss at iteration 950 : 0.0014457402285188437
Loss at iteration 960 : 0.0002136356197297573
Loss at iteration 970 : 0.00016103794041555375
Loss at iteration 980 : 0.004481688141822815
Loss at iteration 990 : 0.002561525907367468
Loss at iteration 1000 : 0.0003230554284527898
Loss at iteration 1010 : 0.003176060738041997
Loss at iteration 1020 : 0.00040377851109951735
Loss at iteration 1030 : 0.0001660300767980516
Loss at iteration 1040 : 0.0007488663541153073
Loss at iteration 1050 : 0.0005090797785669565
Loss at iteration 1060 : 0.0002803819952532649
Loss at iteration 1070 : 0.0004909802228212357
Loss at iteration 1080 : 0.0017554752994328737
Loss at iteration 1090 : 0.001380579313263297
Loss at iteration 1100 : 0.00011012227332685143
Loss at iteration 1110 : 0.00030465275631286204
Loss at iteration 1120 : 0.011054456233978271
Loss at iteration 1130 : 0.0001589572784723714
Loss at iteration 1140 : 0.00038438860792666674
Loss at iteration 1150 : 0.0005720526678487659
Loss at iteration 1160 : 0.0034693554043769836
Loss at iteration 1170 : 0.0003682904352899641
Loss at iteration 1180 : 0.0023398667108267546
Loss at iteration 1190 : 0.00044323745532892644
Loss at iteration 1200 : 0.0016131952870637178
Loss at iteration 1210 : 0.00022402836475521326
Loss at iteration 1220 : 0.00030176923610270023
Loss at iteration 1230 : 7.337496936088428e-05
Loss at iteration 1240 : 0.010743532329797745
Loss at iteration 1250 : 0.0025509903207421303
Loss at iteration 1260 : 0.003108892124146223
Loss at iteration 1270 : 0.00020940208924002945
Loss at iteration 1280 : 0.001623803749680519
Loss at iteration 1290 : 0.004917479585856199
Loss at iteration 1300 : 0.011196966283023357
Loss at iteration 1310 : 0.004438199568539858
Loss at iteration 1320 : 0.000180170958628878
Loss at iteration 1330 : 0.002032726537436247
Loss at iteration 1340 : 0.0016478378092870116
Loss at iteration 1350 : 0.005405765026807785
Loss at iteration 1360 : 0.0016430539544671774
Loss at iteration 1370 : 0.0010222203563898802
Loss at iteration 1380 : 0.00015289339353330433
Loss at iteration 1390 : 0.0001460674830013886
Loss at iteration 1400 : 0.0032049547880887985
Loss at iteration 1410 : 0.0002024955756496638
Loss at iteration 1420 : 5.6697237596381456e-05
Loss at iteration 1430 : 0.001390650519169867
Loss at iteration 1440 : 0.001497180201113224
Loss at iteration 1450 : 7.338116847677156e-05
Loss at iteration 1460 : 0.00021617120364680886
Loss at iteration 1470 : 0.00013625179417431355
Loss at iteration 1480 : 0.00017662823665887117
Loss at iteration 1490 : 0.008982358500361443
Loss at iteration 1500 : 0.00042832025792449713
Loss at iteration 1510 : 0.00014156541146803647
Loss at iteration 1520 : 0.0002116807590937242
Loss at iteration 1530 : 0.0002813805767800659
Loss at iteration 1540 : 0.0003137336752843112
Loss at iteration 1550 : 0.0007254802621901035
Loss at iteration 1560 : 0.001182476757094264
Loss at iteration 1570 : 0.00021301175002008677
Loss at iteration 1580 : 8.180594886653125e-05
Loss at iteration 1590 : 0.0025903056375682354
Loss at iteration 1600 : 0.00029427424306049943
Loss at iteration 1610 : 0.00044210971100255847
Loss at iteration 1620 : 0.001943809213116765
Loss at iteration 1630 : 0.0028397305868566036
Loss at iteration 1640 : 0.00010469279368408024
Loss at iteration 1650 : 0.0033979336731135845
Loss at iteration 1660 : 0.00028724895673803985
Loss at iteration 1670 : 9.243031672667712e-05
Loss at iteration 1680 : 0.0009139938047155738
Loss at iteration 1690 : 0.00012401746062096208
Loss at iteration 1700 : 0.00010684644803404808
Loss at iteration 1710 : 0.00041645829332992435
Loss at iteration 1720 : 0.004983485210686922
Loss at iteration 1730 : 0.0007782215252518654
Loss at iteration 1740 : 0.0012267348356544971
Loss at iteration 1750 : 0.00025140016805380583
The SSIM Value is: 0.9469297905062789
The PSNR Value is: 44.13409853821809
the highest SSIM value is: 44.13409853821809
the epoch is: 3
Loss at iteration 10 : 0.00017604725144337863
Loss at iteration 20 : 0.0005283709615468979
Loss at iteration 30 : 0.00014912377810105681
Loss at iteration 40 : 7.743812602711841e-05
Loss at iteration 50 : 0.0006687181885354221
Loss at iteration 60 : 0.0036116978153586388
Loss at iteration 70 : 0.0004594481142703444
Loss at iteration 80 : 0.0007215419318526983
Loss at iteration 90 : 0.00024164695059880614
Loss at iteration 100 : 0.000233971411944367
Loss at iteration 110 : 0.00014455679047387093
Loss at iteration 120 : 0.010188328102231026
Loss at iteration 130 : 0.00010515854955883697
Loss at iteration 140 : 0.0006883159512653947
Loss at iteration 150 : 0.0004716122057288885
Loss at iteration 160 : 0.00014730330440215766
Loss at iteration 170 : 0.00015056354459375143
Loss at iteration 180 : 0.00022257196542341262
Loss at iteration 190 : 0.00010871015547309071
Loss at iteration 200 : 0.002409345470368862
Loss at iteration 210 : 0.0002142464800272137
Loss at iteration 220 : 0.00015017090481705964
Loss at iteration 230 : 0.00035217416007071733
Loss at iteration 240 : 0.0010267924517393112
Loss at iteration 250 : 0.0003891878295689821
Loss at iteration 260 : 0.004848566837608814
Loss at iteration 270 : 0.0002853562473319471
Loss at iteration 280 : 7.104480027919635e-05
Loss at iteration 290 : 0.00394231453537941
Loss at iteration 300 : 0.00014673787518404424
Loss at iteration 310 : 0.0006150080007500947
Loss at iteration 320 : 0.0002211142418673262
Loss at iteration 330 : 0.0005012319888919592
Loss at iteration 340 : 0.00012843817239627242
Loss at iteration 350 : 0.0002636426652316004
Loss at iteration 360 : 0.005688761360943317
Loss at iteration 370 : 0.002828714670613408
Loss at iteration 380 : 0.0005128440679982305
Loss at iteration 390 : 0.00017953045608010143
Loss at iteration 400 : 0.0006084047490730882
Loss at iteration 410 : 0.0029047110583633184
Loss at iteration 420 : 0.000647219130769372
Loss at iteration 430 : 0.0005963529692962766
Loss at iteration 440 : 0.00015828481991775334
Loss at iteration 450 : 0.004660320933908224
Loss at iteration 460 : 0.0002303422661498189
Loss at iteration 470 : 0.00010383143671788275
Loss at iteration 480 : 0.0005925092846155167
Loss at iteration 490 : 0.0003678020148072392
Loss at iteration 500 : 9.114445856539533e-05
Loss at iteration 510 : 0.0006607410032302141
Loss at iteration 520 : 0.004352455493062735
Loss at iteration 530 : 0.00010007678065449
Loss at iteration 540 : 0.007294520735740662
Loss at iteration 550 : 0.0001681838184595108
Loss at iteration 560 : 5.594687536358833e-05
Loss at iteration 570 : 0.00019398995209485292
Loss at iteration 580 : 0.0034994366578757763
Loss at iteration 590 : 0.006578163243830204
Loss at iteration 600 : 0.0018365539144724607
Loss at iteration 610 : 0.00029197221738286316
Loss at iteration 620 : 0.004579722881317139
Loss at iteration 630 : 0.0042185126803815365
Loss at iteration 640 : 0.004960924852639437
Loss at iteration 650 : 0.001059431117027998
Loss at iteration 660 : 0.004380673635751009
Loss at iteration 670 : 0.0012196453753858805
Loss at iteration 680 : 0.0032642933074384928
Loss at iteration 690 : 0.0020797017496079206
Loss at iteration 700 : 0.0051981243304908276
Loss at iteration 710 : 0.0018383441492915154
Loss at iteration 720 : 0.003007077146321535
Loss at iteration 730 : 0.00020703024347312748
Loss at iteration 740 : 0.0008544567972421646
Loss at iteration 750 : 0.0011144564487040043
Loss at iteration 760 : 0.0002772963198367506
Loss at iteration 770 : 0.0002600274747237563
Loss at iteration 780 : 0.000323917658533901
Loss at iteration 790 : 0.00029714382253587246
Loss at iteration 800 : 0.0024208989925682545
Loss at iteration 810 : 0.004346733912825584
Loss at iteration 820 : 0.002373659983277321
Loss at iteration 830 : 0.0001358649751637131
Loss at iteration 840 : 9.048252832144499e-05
Loss at iteration 850 : 0.0002776885812636465
Loss at iteration 860 : 0.00027447714819572866
Loss at iteration 870 : 0.0011039999080821872
Loss at iteration 880 : 0.010944494977593422
Loss at iteration 890 : 0.0006669207941740751
Loss at iteration 900 : 0.0005218125297687948
Loss at iteration 910 : 0.0007620014366693795
Loss at iteration 920 : 0.003656842513009906
Loss at iteration 930 : 0.0007942865486256778
Loss at iteration 940 : 0.0007355250418186188
Loss at iteration 950 : 0.00021840224508196115
Loss at iteration 960 : 0.0008271855767816305
Loss at iteration 970 : 0.0005334021407179534
Loss at iteration 980 : 0.0031087344978004694
Loss at iteration 990 : 0.0046359458938241005
Loss at iteration 1000 : 0.0005271335248835385
Loss at iteration 1010 : 0.0030423032585531473
Loss at iteration 1020 : 0.0003058704314753413
Loss at iteration 1030 : 9.207006951328367e-05
Loss at iteration 1040 : 0.0033841929398477077
Loss at iteration 1050 : 0.0006132774287834764
Loss at iteration 1060 : 0.00015648083353880793
Loss at iteration 1070 : 0.00024817720986902714
Loss at iteration 1080 : 0.00016739100101403892
Loss at iteration 1090 : 0.0019954757299274206
Loss at iteration 1100 : 0.001441554632037878
Loss at iteration 1110 : 0.0001985011767828837
Loss at iteration 1120 : 0.00020545271399896592
Loss at iteration 1130 : 0.0007384786149486899
Loss at iteration 1140 : 0.0011904822895303369
Loss at iteration 1150 : 9.52670889091678e-05
Loss at iteration 1160 : 5.9508496633498e-05
Loss at iteration 1170 : 0.0005884823622182012
Loss at iteration 1180 : 0.0008651487296447158
Loss at iteration 1190 : 0.0005996898398734629
Loss at iteration 1200 : 0.00012917275307700038
Loss at iteration 1210 : 0.0001867108658188954
Loss at iteration 1220 : 0.0018081909511238337
Loss at iteration 1230 : 0.001032198197208345
Loss at iteration 1240 : 0.0005632431712001562
Loss at iteration 1250 : 0.006948983296751976
Loss at iteration 1260 : 0.0003107033553533256
Loss at iteration 1270 : 0.004194204695522785
Loss at iteration 1280 : 8.508544851792976e-05
Loss at iteration 1290 : 0.0028147746343165636
Loss at iteration 1300 : 0.000207300647161901
Loss at iteration 1310 : 0.0005889852764084935
Loss at iteration 1320 : 9.808660979615524e-05
Loss at iteration 1330 : 0.0006632762961089611
Loss at iteration 1340 : 0.00012294130283407867
Loss at iteration 1350 : 0.0006413576193153858
Loss at iteration 1360 : 3.4375225368421525e-05
Loss at iteration 1370 : 8.52746597956866e-05
Loss at iteration 1380 : 8.301100024254993e-05
Loss at iteration 1390 : 0.0016774898394942284
Loss at iteration 1400 : 0.00031808746280148625
Loss at iteration 1410 : 0.00016297184629365802
Loss at iteration 1420 : 0.00015708176943007857
Loss at iteration 1430 : 0.0030836525838822126
Loss at iteration 1440 : 0.00048372315359301865
Loss at iteration 1450 : 0.0021404814906418324
Loss at iteration 1460 : 0.0028423317708075047
Loss at iteration 1470 : 0.00019098698976449668
Loss at iteration 1480 : 0.002731926739215851
Loss at iteration 1490 : 0.0007726370822638273
Loss at iteration 1500 : 0.0003407122567296028
Loss at iteration 1510 : 0.0015168439131230116
Loss at iteration 1520 : 0.00038463258533738554
Loss at iteration 1530 : 0.00014044801355339587
Loss at iteration 1540 : 0.0011202648747712374
Loss at iteration 1550 : 0.0022637168876826763
Loss at iteration 1560 : 8.075274672592059e-05
Loss at iteration 1570 : 0.001987428404390812
Loss at iteration 1580 : 4.359038211987354e-05
Loss at iteration 1590 : 0.0038841008208692074
Loss at iteration 1600 : 0.0007161391549743712
Loss at iteration 1610 : 0.0014183683088049293
Loss at iteration 1620 : 0.00012690905714407563
Loss at iteration 1630 : 8.21726061985828e-05
Loss at iteration 1640 : 0.0011909154709428549
Loss at iteration 1650 : 0.004388188943266869
Loss at iteration 1660 : 0.002390607725828886
Loss at iteration 1670 : 0.0001177879748865962
Loss at iteration 1680 : 0.00015169463586062193
Loss at iteration 1690 : 0.0018942694878205657
Loss at iteration 1700 : 0.0005695057334378362
Loss at iteration 1710 : 0.009864147752523422
Loss at iteration 1720 : 0.00033080272260122
Loss at iteration 1730 : 6.547938392031938e-05
Loss at iteration 1740 : 0.0040146829560399055
Loss at iteration 1750 : 0.01055980660021305
The SSIM Value is: 0.8417042917879668
The PSNR Value is: 41.40543361277307
the epoch is: 4
Loss at iteration 10 : 8.769026317168027e-05
Loss at iteration 20 : 0.00013359567674342543
Loss at iteration 30 : 0.00020051626779604703
Loss at iteration 40 : 0.001545668113976717
Loss at iteration 50 : 0.0001533039758214727
Loss at iteration 60 : 0.0002068403991870582
Loss at iteration 70 : 0.0001437771861674264
Loss at iteration 80 : 0.0018381404224783182
Loss at iteration 90 : 0.00024155677238013595
Loss at iteration 100 : 0.0011894094059243798
Loss at iteration 110 : 0.0009564933134242892
Loss at iteration 120 : 0.0023378184996545315
Loss at iteration 130 : 0.005245031323283911
Loss at iteration 140 : 0.0023319232277572155
Loss at iteration 150 : 0.0006763998535461724
Loss at iteration 160 : 0.004140006378293037
Loss at iteration 170 : 0.00012756405340041965
Loss at iteration 180 : 0.00040912145050242543
Loss at iteration 190 : 0.0023554242216050625
Loss at iteration 200 : 0.0002714932488743216
Loss at iteration 210 : 0.0021241232752799988
Loss at iteration 220 : 0.0005466039292514324
Loss at iteration 230 : 9.90595726761967e-05
Loss at iteration 240 : 0.00330997072160244
Loss at iteration 250 : 0.0002064587315544486
Loss at iteration 260 : 0.00019545151735655963
Loss at iteration 270 : 0.0004735351540148258
Loss at iteration 280 : 0.0014465271960943937
Loss at iteration 290 : 9.90392582025379e-05
Loss at iteration 300 : 0.0025510573759675026
Loss at iteration 310 : 0.005015037953853607
Loss at iteration 320 : 0.00019600079394876957
Loss at iteration 330 : 0.00012297529610805213
Loss at iteration 340 : 0.00019993947353214025
Loss at iteration 350 : 0.00016472532297484577
Loss at iteration 360 : 0.004086936358362436
Loss at iteration 370 : 0.00044605362927541137
Loss at iteration 380 : 0.00030427679303102195
Loss at iteration 390 : 0.0004916337784379721
Loss at iteration 400 : 0.00046065356582403183
Loss at iteration 410 : 0.0044762808829545975
Loss at iteration 420 : 0.0011305612279102206
Loss at iteration 430 : 0.0008770469576120377
Loss at iteration 440 : 0.0005728896940127015
Loss at iteration 450 : 6.835046224296093e-05
Loss at iteration 460 : 0.002371573355048895
Loss at iteration 470 : 8.322360372403637e-05
Loss at iteration 480 : 0.00022017909213900566
Loss at iteration 490 : 0.00016142056847456843
Loss at iteration 500 : 0.00019781451555900276
Loss at iteration 510 : 0.00047256838297471404
Loss at iteration 520 : 0.00015637351316399872
Loss at iteration 530 : 0.004994066432118416
Loss at iteration 540 : 0.002430758671835065
Loss at iteration 550 : 0.0016372473910450935
Loss at iteration 560 : 0.0024066264741122723
Loss at iteration 570 : 0.00043449067743495107
Loss at iteration 580 : 0.0002505241136532277
Loss at iteration 590 : 8.038841770030558e-05
Loss at iteration 600 : 0.0012261769734323025
Loss at iteration 610 : 0.000350292946677655
Loss at iteration 620 : 0.005179830361157656
Loss at iteration 630 : 0.0004179108655080199
Loss at iteration 640 : 0.0020493099000304937
Loss at iteration 650 : 0.0008131330250762403
Loss at iteration 660 : 0.0001627500168979168
Loss at iteration 670 : 0.0006146430969238281
Loss at iteration 680 : 0.00026809380506165326
Loss at iteration 690 : 0.0003087708028033376
Loss at iteration 700 : 0.008491888642311096
Loss at iteration 710 : 0.00013303036394063383
Loss at iteration 720 : 0.0012021928559988737
Loss at iteration 730 : 0.00014911234029568732
Loss at iteration 740 : 0.0031801348086446524
Loss at iteration 750 : 6.872107769595459e-05
Loss at iteration 760 : 0.002978650154545903
Loss at iteration 770 : 0.0005115920794196427
Loss at iteration 780 : 0.00014664769696537405
Loss at iteration 790 : 0.0006140272598713636
Loss at iteration 800 : 0.00034280860563740134
Loss at iteration 810 : 0.0002067249151878059
Loss at iteration 820 : 0.0016491845017299056
Loss at iteration 830 : 0.0033103753812611103
Loss at iteration 840 : 0.00019501903443597257
Loss at iteration 850 : 0.0017523944843560457
Loss at iteration 860 : 0.00017095284420065582
Loss at iteration 870 : 0.008787966333329678
Loss at iteration 880 : 0.0003995573497377336
Loss at iteration 890 : 0.003296209964901209
Loss at iteration 900 : 0.0014222599565982819
Loss at iteration 910 : 0.0004796806606464088
Loss at iteration 920 : 0.00210768124088645
Loss at iteration 930 : 0.0009472605888731778
Loss at iteration 940 : 0.00023185275495052338
Loss at iteration 950 : 0.00012946940842084587
Loss at iteration 960 : 0.0014969680923968554
Loss at iteration 970 : 0.0029085767455399036
Loss at iteration 980 : 0.0010341752786189318
Loss at iteration 990 : 0.0011177193373441696
Loss at iteration 1000 : 0.0008175586699508131
Loss at iteration 1010 : 0.00020684156334027648
Loss at iteration 1020 : 0.0007311038207262754
Loss at iteration 1030 : 0.00047471176367253065
Loss at iteration 1040 : 5.881225661141798e-05
Loss at iteration 1050 : 0.00018544909835327417
Loss at iteration 1060 : 0.0049955639988183975
Loss at iteration 1070 : 0.00019354253890924156
Loss at iteration 1080 : 0.0003043492906726897
Loss at iteration 1090 : 0.0006203977973200381
Loss at iteration 1100 : 7.954680040711537e-05
Loss at iteration 1110 : 0.004424253478646278
Loss at iteration 1120 : 0.00013433783897198737
Loss at iteration 1130 : 0.0009296450298279524
Loss at iteration 1140 : 0.0006218415219336748
Loss at iteration 1150 : 0.0018138076411560178
Loss at iteration 1160 : 0.006841264199465513
Loss at iteration 1170 : 0.0006438400596380234
Loss at iteration 1180 : 0.001122359884902835
Loss at iteration 1190 : 0.0003696271451190114
Loss at iteration 1200 : 0.0005442457040771842
Loss at iteration 1210 : 0.00022836198331788182
Loss at iteration 1220 : 0.0003149179683532566
Loss at iteration 1230 : 0.00044859739136882126
Loss at iteration 1240 : 0.00015640257333870977
Loss at iteration 1250 : 0.0001792523544281721
Loss at iteration 1260 : 0.0002823223767336458
Loss at iteration 1270 : 0.002063108840957284
Loss at iteration 1280 : 0.00012274461914785206
Loss at iteration 1290 : 0.00047396973241120577
Loss at iteration 1300 : 0.001651233877055347
Loss at iteration 1310 : 0.0019743330776691437
Loss at iteration 1320 : 0.0005463041015900671
Loss at iteration 1330 : 0.0017136987298727036
Loss at iteration 1340 : 0.0003883966710418463
Loss at iteration 1350 : 0.00014508786262013018
Loss at iteration 1360 : 0.0044898889027535915
Loss at iteration 1370 : 9.417712135473266e-05
Loss at iteration 1380 : 0.00036137824645265937
Loss at iteration 1390 : 0.00043459332664497197
Loss at iteration 1400 : 0.0024329260922968388
Loss at iteration 1410 : 0.0011528742033988237
Loss at iteration 1420 : 0.0003317738592159003
Loss at iteration 1430 : 0.00039689248660579324
Loss at iteration 1440 : 0.00012395369412843138
Loss at iteration 1450 : 0.004020304884761572
Loss at iteration 1460 : 0.000197663001017645
Loss at iteration 1470 : 0.00017022034444380552
Loss at iteration 1480 : 0.0008424851694144309
Loss at iteration 1490 : 0.004776331130415201
Loss at iteration 1500 : 0.0001363932533422485
Loss at iteration 1510 : 0.00024282005324494094
Loss at iteration 1520 : 0.0002250182442367077
Loss at iteration 1530 : 0.001122203073464334
Loss at iteration 1540 : 0.00012244116805959493
Loss at iteration 1550 : 0.005358345806598663
Loss at iteration 1560 : 0.0004693119553849101
Loss at iteration 1570 : 0.0007051792927086353
Loss at iteration 1580 : 0.00018734714831225574
Loss at iteration 1590 : 0.0001263059239136055
Loss at iteration 1600 : 0.00229742843657732
Loss at iteration 1610 : 0.00011935156362596899
Loss at iteration 1620 : 0.0018723758403211832
Loss at iteration 1630 : 0.0001010868581943214
Loss at iteration 1640 : 0.003130237339064479
Loss at iteration 1650 : 0.0002217144356109202
Loss at iteration 1660 : 0.0007177242659963667
Loss at iteration 1670 : 0.0002466925070621073
Loss at iteration 1680 : 0.00019565157708711922
Loss at iteration 1690 : 8.787273691268638e-05
Loss at iteration 1700 : 0.001018641283735633
Loss at iteration 1710 : 0.00699852779507637
Loss at iteration 1720 : 0.00206721480935812
Loss at iteration 1730 : 0.0005117348628118634
Loss at iteration 1740 : 0.00161110726185143
Loss at iteration 1750 : 0.010190731845796108
The SSIM Value is: 0.9547120906445423
The PSNR Value is: 44.258718719566446
the highest SSIM value is: 44.258718719566446
the epoch is: 5
Loss at iteration 10 : 0.001317374175414443
Loss at iteration 20 : 0.00010239471157547086
Loss at iteration 30 : 8.208901272155344e-05
Loss at iteration 40 : 0.006318369880318642
Loss at iteration 50 : 0.0017048503505066037
Loss at iteration 60 : 0.0016716145910322666
Loss at iteration 70 : 0.00033696205355226994
Loss at iteration 80 : 0.0005077761015854776
Loss at iteration 90 : 0.0008496530936099589
Loss at iteration 100 : 0.011385328136384487
Loss at iteration 110 : 0.00023452822642866522
Loss at iteration 120 : 0.0004461004864424467
Loss at iteration 130 : 0.0005217710277065635
Loss at iteration 140 : 0.000551834178622812
Loss at iteration 150 : 0.0025687129236757755
Loss at iteration 160 : 0.014069621451199055
Loss at iteration 170 : 0.0004932923475280404
Loss at iteration 180 : 0.00314900279045105
Loss at iteration 190 : 0.00019069442350883037
Loss at iteration 200 : 0.00018352344341110438
Loss at iteration 210 : 0.000237456159084104
Loss at iteration 220 : 0.00023807139950804412
Loss at iteration 230 : 0.0017535813385620713
Loss at iteration 240 : 0.0022572579327970743
Loss at iteration 250 : 0.0001127628784161061
Loss at iteration 260 : 0.0011786323739215732
Loss at iteration 270 : 0.0002981291036121547
Loss at iteration 280 : 0.0002213291882071644
Loss at iteration 290 : 5.384931864682585e-05
Loss at iteration 300 : 7.846525113563985e-05
Loss at iteration 310 : 0.00032329902751371264
Loss at iteration 320 : 0.00022785871988162398
Loss at iteration 330 : 0.0007983548566699028
Loss at iteration 340 : 0.00010899093467742205
Loss at iteration 350 : 0.0004898469778709114
Loss at iteration 360 : 0.002238280838355422
Loss at iteration 370 : 0.0022204252891242504
Loss at iteration 380 : 0.00037256654468365014
Loss at iteration 390 : 0.0002493074571248144
Loss at iteration 400 : 0.0014964774018153548
Loss at iteration 410 : 0.001366663840599358
Loss at iteration 420 : 0.00027372458134777844
Loss at iteration 430 : 0.0003328518941998482
Loss at iteration 440 : 0.0003042466414626688
Loss at iteration 450 : 0.0007842580089345574
Loss at iteration 460 : 0.00011430918675614521
Loss at iteration 470 : 0.003907945938408375
Loss at iteration 480 : 0.0016593802720308304
Loss at iteration 490 : 0.0001282955054193735
Loss at iteration 500 : 0.0002787726989481598
Loss at iteration 510 : 0.0011589224450290203
Loss at iteration 520 : 0.00026331422850489616
Loss at iteration 530 : 0.0004189149185549468
Loss at iteration 540 : 9.567226516082883e-05
Loss at iteration 550 : 0.0002719665935728699
Loss at iteration 560 : 0.0005479571409523487
Loss at iteration 570 : 0.00010966194531647488
Loss at iteration 580 : 0.0005371182924136519
Loss at iteration 590 : 0.0018391184275969863
Loss at iteration 600 : 0.0004789523663930595
Loss at iteration 610 : 0.0014430014416575432
Loss at iteration 620 : 0.0016305886674672365
Loss at iteration 630 : 7.332905806833878e-05
Loss at iteration 640 : 0.00019830025848932564
Loss at iteration 650 : 0.005288189277052879
Loss at iteration 660 : 0.0007652996573597193
Loss at iteration 670 : 0.00074525031959638
Loss at iteration 680 : 0.00024147643125616014
Loss at iteration 690 : 0.0026858996134251356
Loss at iteration 700 : 0.0005049891769886017
Loss at iteration 710 : 0.00015816032828297466
Loss at iteration 720 : 0.0002402714017080143
Loss at iteration 730 : 7.076532347127795e-05
Loss at iteration 740 : 0.0023970287293195724
Loss at iteration 750 : 0.005437019746750593
Loss at iteration 760 : 0.0026941692922264338
Loss at iteration 770 : 0.0005665307980962098
Loss at iteration 780 : 0.00024521289742551744
Loss at iteration 790 : 0.0024037573020905256
Loss at iteration 800 : 0.0001765070774126798
Loss at iteration 810 : 0.0033252222929149866
Loss at iteration 820 : 0.00014169051428325474
Loss at iteration 830 : 0.0020295169670134783
Loss at iteration 840 : 0.001314995693974197
Loss at iteration 850 : 0.0002834359183907509
Loss at iteration 860 : 0.0006419469136744738
Loss at iteration 870 : 0.0021020956337451935
Loss at iteration 880 : 0.003024233039468527
Loss at iteration 890 : 0.00012666048132814467
Loss at iteration 900 : 0.0004981883685104549
Loss at iteration 910 : 0.0006999709876254201
Loss at iteration 920 : 0.00019000341126229614
Loss at iteration 930 : 0.00020947173470631242
Loss at iteration 940 : 0.001021119998767972
Loss at iteration 950 : 0.011288287118077278
Loss at iteration 960 : 0.00010842962365131825
Loss at iteration 970 : 0.00021932974050287157
Loss at iteration 980 : 0.00010475713497726247
Loss at iteration 990 : 0.00020956725347787142
Loss at iteration 1000 : 0.000629298621788621
Loss at iteration 1010 : 0.0003713098412845284
Loss at iteration 1020 : 0.008778666146099567
Loss at iteration 1030 : 0.0006706430576741695
Loss at iteration 1040 : 0.003093370469287038
Loss at iteration 1050 : 0.0009261038503609598
Loss at iteration 1060 : 0.0003086735960096121
Loss at iteration 1070 : 0.0008557403343729675
Loss at iteration 1080 : 0.00039770908188074827
Loss at iteration 1090 : 0.0035137254744768143
Loss at iteration 1100 : 0.0005633890395984054
Loss at iteration 1110 : 0.00015640445053577423
Loss at iteration 1120 : 0.001854805159382522
Loss at iteration 1130 : 0.0001412591664120555
Loss at iteration 1140 : 0.0011363117955625057
Loss at iteration 1150 : 0.00032571260817348957
Loss at iteration 1160 : 0.002177636604756117
Loss at iteration 1170 : 0.0003036626148968935
Loss at iteration 1180 : 0.00021388322056736797
Loss at iteration 1190 : 0.003190792165696621
Loss at iteration 1200 : 0.00024615091388113797
Loss at iteration 1210 : 0.0019468277459964156
Loss at iteration 1220 : 0.006038573104888201
Loss at iteration 1230 : 0.0009872043738141656
Loss at iteration 1240 : 0.0032122561242431402
Loss at iteration 1250 : 0.0013049421831965446
Loss at iteration 1260 : 0.0008081793785095215
Loss at iteration 1270 : 0.00022231144248507917
Loss at iteration 1280 : 0.003021509386599064
Loss at iteration 1290 : 0.00027450110064819455
Loss at iteration 1300 : 0.00015667823026888072
Loss at iteration 1310 : 0.00027337309438735247
Loss at iteration 1320 : 0.00020121096167713404
Loss at iteration 1330 : 0.002551810350269079
Loss at iteration 1340 : 0.0032049082219600677
Loss at iteration 1350 : 0.00019426073413342237
Loss at iteration 1360 : 0.0006310841999948025
Loss at iteration 1370 : 0.0001582232944201678
Loss at iteration 1380 : 0.0009801499545574188
Loss at iteration 1390 : 6.903457688167691e-05
Loss at iteration 1400 : 0.0005096429958939552
Loss at iteration 1410 : 0.0009223471861332655
Loss at iteration 1420 : 0.0004952271701768041
Loss at iteration 1430 : 5.503569991560653e-05
Loss at iteration 1440 : 0.0018678976921364665
Loss at iteration 1450 : 0.0008956710225902498
Loss at iteration 1460 : 0.0005013573099859059
Loss at iteration 1470 : 0.004389258101582527
Loss at iteration 1480 : 0.00019896187586709857
Loss at iteration 1490 : 9.602586942492053e-05
Loss at iteration 1500 : 0.0023314340505748987
Loss at iteration 1510 : 0.0004890033742412925
Loss at iteration 1520 : 0.0002228080265922472
Loss at iteration 1530 : 4.591134347720072e-05
Loss at iteration 1540 : 0.0004021069617010653
Loss at iteration 1550 : 0.00020212860545143485
Loss at iteration 1560 : 0.00012620064080692828
Loss at iteration 1570 : 0.0036513644736260176
Loss at iteration 1580 : 0.00035148829920217395
Loss at iteration 1590 : 0.0024890443310141563
Loss at iteration 1600 : 0.0005140306893736124
Loss at iteration 1610 : 0.0035243756137788296
Loss at iteration 1620 : 0.0009008191409520805
Loss at iteration 1630 : 0.001029604347422719
Loss at iteration 1640 : 8.012178295757622e-05
Loss at iteration 1650 : 0.002390348818153143
Loss at iteration 1660 : 0.0011361686047166586
Loss at iteration 1670 : 0.0049107810482382774
Loss at iteration 1680 : 0.0005050235195085406
Loss at iteration 1690 : 0.007593683432787657
Loss at iteration 1700 : 0.00012187339598312974
Loss at iteration 1710 : 0.00025165523402392864
Loss at iteration 1720 : 0.00016000529285520315
Loss at iteration 1730 : 0.000516446481924504
Loss at iteration 1740 : 0.0026915790513157845
Loss at iteration 1750 : 0.00012189072731416672
The SSIM Value is: 0.957376917028217
The PSNR Value is: 44.49468519614131
the highest SSIM value is: 44.49468519614131
the epoch is: 6
Loss at iteration 10 : 0.0020702227484434843
Loss at iteration 20 : 0.006471761502325535
Loss at iteration 30 : 0.0041160606779158115
Loss at iteration 40 : 0.0029174708761274815
Loss at iteration 50 : 0.006424793042242527
Loss at iteration 60 : 0.00026743003400042653
Loss at iteration 70 : 6.749746535206214e-05
Loss at iteration 80 : 7.093435124261305e-05
Loss at iteration 90 : 0.001343806623481214
Loss at iteration 100 : 0.00018619102775119245
Loss at iteration 110 : 0.0009249827126041055
Loss at iteration 120 : 0.0005301040364429355
Loss at iteration 130 : 0.0034916778095066547
Loss at iteration 140 : 0.00029077412909828126
Loss at iteration 150 : 0.007698660716414452
Loss at iteration 160 : 0.0022600237280130386
Loss at iteration 170 : 0.004417248535901308
Loss at iteration 180 : 0.00589522160589695
Loss at iteration 190 : 0.00561817130073905
Loss at iteration 200 : 0.01071042101830244
Loss at iteration 210 : 0.004804316908121109
Loss at iteration 220 : 0.00022277820971794426
Loss at iteration 230 : 0.0005911856424063444
Loss at iteration 240 : 7.455935701727867e-05
Loss at iteration 250 : 0.00010981709056068212
Loss at iteration 260 : 0.00017122711869888008
Loss at iteration 270 : 8.20099376142025e-05
Loss at iteration 280 : 0.0025711474008858204
Loss at iteration 290 : 0.00022024827194400132
Loss at iteration 300 : 0.00012105352652724832
Loss at iteration 310 : 0.00013201982073951513
Loss at iteration 320 : 0.005200977437198162
Loss at iteration 330 : 0.00030746666016057134
Loss at iteration 340 : 0.004797863774001598
Loss at iteration 350 : 0.00031868828227743506
Loss at iteration 360 : 0.0002650804235599935
Loss at iteration 370 : 0.00019672780763357878
Loss at iteration 380 : 0.0005552173242904246
Loss at iteration 390 : 9.3082882813178e-05
Loss at iteration 400 : 0.00041092350147664547
Loss at iteration 410 : 0.0006591306300833821
Loss at iteration 420 : 0.0001896055182442069
Loss at iteration 430 : 0.00013967575796414167
Loss at iteration 440 : 0.00028058356838300824
Loss at iteration 450 : 0.0007578768418170512
Loss at iteration 460 : 0.0006119291647337377
Loss at iteration 470 : 0.00030469917692244053
Loss at iteration 480 : 5.258993405732326e-05
Loss at iteration 490 : 0.00028310506604611874
Loss at iteration 500 : 8.196772978408262e-05
Loss at iteration 510 : 0.0010845924261957407
Loss at iteration 520 : 0.003925635479390621
Loss at iteration 530 : 0.002165950834751129
Loss at iteration 540 : 0.00017532876518089324
Loss at iteration 550 : 0.0013862093910574913
Loss at iteration 560 : 9.186609531752765e-05
Loss at iteration 570 : 0.0021875803358852863
Loss at iteration 580 : 0.0001807395601645112
Loss at iteration 590 : 9.860277350526303e-05
Loss at iteration 600 : 0.00018881754658650607
Loss at iteration 610 : 0.0031708297319710255
Loss at iteration 620 : 0.0021868732292205095
Loss at iteration 630 : 0.0005063422722741961
Loss at iteration 640 : 0.0027172518894076347
Loss at iteration 650 : 0.0002664938219822943
Loss at iteration 660 : 6.480891170212999e-05
Loss at iteration 670 : 0.0032446898985654116
Loss at iteration 680 : 0.00040747737511992455
Loss at iteration 690 : 0.00022345606703311205
Loss at iteration 700 : 0.002280990593135357
Loss at iteration 710 : 0.002865289803594351
Loss at iteration 720 : 0.0007822639890946448
Loss at iteration 730 : 0.00395112344995141
Loss at iteration 740 : 0.00030906652682460845
Loss at iteration 750 : 0.00016685464652255177
Loss at iteration 760 : 0.0063959513790905476
Loss at iteration 770 : 0.0005208568763919175
Loss at iteration 780 : 0.0008514616638422012
Loss at iteration 790 : 0.00011103821452707052
Loss at iteration 800 : 0.00047992749023251235
Loss at iteration 810 : 0.00011691068357322365
Loss at iteration 820 : 0.00029797415481880307
Loss at iteration 830 : 0.007458735257387161
Loss at iteration 840 : 0.002177561866119504
Loss at iteration 850 : 0.006428394932299852
Loss at iteration 860 : 0.006404769606888294
Loss at iteration 870 : 0.00029768169042654335
Loss at iteration 880 : 0.00025051392731256783
Loss at iteration 890 : 0.0009883908787742257
Loss at iteration 900 : 7.444041693815961e-05
Loss at iteration 910 : 9.850844799075276e-05
Loss at iteration 920 : 0.00013163845869712532
Loss at iteration 930 : 0.00031937204767018557
Loss at iteration 940 : 0.00013627903535962105
Loss at iteration 950 : 0.0007245116285048425
Loss at iteration 960 : 0.0004278399865143001
Loss at iteration 970 : 0.00014743724022991955
Loss at iteration 980 : 0.003167395945638418
Loss at iteration 990 : 0.0016793018439784646
Loss at iteration 1000 : 0.0014848036225885153
Loss at iteration 1010 : 0.00016766678891144693
Loss at iteration 1020 : 0.00016855934518389404
Loss at iteration 1030 : 0.00124752102419734
Loss at iteration 1040 : 0.000476916873594746
Loss at iteration 1050 : 0.00023096517543308437
Loss at iteration 1060 : 0.0005630201776511967
Loss at iteration 1070 : 0.00011524922592798248
Loss at iteration 1080 : 0.00018593764980323613
Loss at iteration 1090 : 0.0065011680126190186
Loss at iteration 1100 : 0.003148092422634363
Loss at iteration 1110 : 0.00016589484584983438
Loss at iteration 1120 : 0.00016371876699849963
Loss at iteration 1130 : 0.0002355642500333488
Loss at iteration 1140 : 0.0006993949646130204
Loss at iteration 1150 : 6.371315976139158e-05
Loss at iteration 1160 : 7.275351526914164e-05
Loss at iteration 1170 : 0.010754801332950592
Loss at iteration 1180 : 0.0009472344536334276
Loss at iteration 1190 : 0.0018283972749486566
Loss at iteration 1200 : 0.00036621885374188423
Loss at iteration 1210 : 0.0012687109410762787
Loss at iteration 1220 : 8.241442264989018e-05
Loss at iteration 1230 : 0.0011730100959539413
Loss at iteration 1240 : 0.004116636235266924
Loss at iteration 1250 : 0.0005344467936083674
Loss at iteration 1260 : 0.00023617528495378792
Loss at iteration 1270 : 0.0010468788677826524
Loss at iteration 1280 : 0.0029154540970921516
Loss at iteration 1290 : 0.003695177845656872
Loss at iteration 1300 : 0.00023839596542529762
Loss at iteration 1310 : 0.003087115241214633
Loss at iteration 1320 : 0.00018615112639963627
Loss at iteration 1330 : 0.00011144379095640033
Loss at iteration 1340 : 0.002133818343281746
Loss at iteration 1350 : 0.001910309074446559
Loss at iteration 1360 : 0.0008872243342921138
Loss at iteration 1370 : 0.00012849779159296304
Loss at iteration 1380 : 0.0001805347274057567
Loss at iteration 1390 : 0.00048676456208340824
Loss at iteration 1400 : 0.00028816008125431836
Loss at iteration 1410 : 0.001186995767056942
Loss at iteration 1420 : 0.0021182505879551172
Loss at iteration 1430 : 0.0015039448626339436
Loss at iteration 1440 : 0.00047634984366595745
Loss at iteration 1450 : 0.0001957175845745951
Loss at iteration 1460 : 0.003163883462548256
Loss at iteration 1470 : 0.0015940230805426836
Loss at iteration 1480 : 0.004788047168403864
Loss at iteration 1490 : 0.0003250990412198007
Loss at iteration 1500 : 0.0006982329650782049
Loss at iteration 1510 : 0.001374008017592132
Loss at iteration 1520 : 0.00040196964982897043
Loss at iteration 1530 : 3.918106449418701e-05
Loss at iteration 1540 : 0.0001244434097316116
Loss at iteration 1550 : 0.007367746438831091
Loss at iteration 1560 : 0.0003278121002949774
Loss at iteration 1570 : 0.002800184767693281
Loss at iteration 1580 : 0.0022849864326417446
Loss at iteration 1590 : 0.0009602707577869296
Loss at iteration 1600 : 0.0006421154830604792
Loss at iteration 1610 : 0.0008909826865419745
Loss at iteration 1620 : 0.0090413186699152
Loss at iteration 1630 : 0.007904989644885063
Loss at iteration 1640 : 0.0010572654427960515
Loss at iteration 1650 : 0.00046768970787525177
Loss at iteration 1660 : 0.0005531861097551882
Loss at iteration 1670 : 0.0031983782537281513
Loss at iteration 1680 : 0.0017559383995831013
Loss at iteration 1690 : 3.959122477681376e-05
Loss at iteration 1700 : 0.0008770313579589128
Loss at iteration 1710 : 0.0006140614859759808
Loss at iteration 1720 : 0.00014805528917349875
Loss at iteration 1730 : 9.199563646689057e-05
Loss at iteration 1740 : 0.0002828408032655716
Loss at iteration 1750 : 4.660789272747934e-05
The SSIM Value is: 0.9803031013400544
The PSNR Value is: 45.7185763724575
the highest SSIM value is: 45.7185763724575
the epoch is: 7
Loss at iteration 10 : 0.0007998161599971354
Loss at iteration 20 : 0.0010740042198449373
Loss at iteration 30 : 0.0001396564912283793
Loss at iteration 40 : 0.00020054337801411748
Loss at iteration 50 : 0.0012493983376771212
Loss at iteration 60 : 0.0012151325354352593
Loss at iteration 70 : 9.273983596358448e-05
Loss at iteration 80 : 0.00024814807693473995
Loss at iteration 90 : 0.0003876780974678695
Loss at iteration 100 : 0.000203269679332152
Loss at iteration 110 : 0.0007035079761408269
Loss at iteration 120 : 0.0005065400619059801
Loss at iteration 130 : 0.0001461201172787696
Loss at iteration 140 : 0.00023523601703345776
Loss at iteration 150 : 0.001118645304813981
Loss at iteration 160 : 9.229563875123858e-05
Loss at iteration 170 : 6.366187881212682e-05
Loss at iteration 180 : 0.0010840629693120718
Loss at iteration 190 : 0.0014097032835707068
Loss at iteration 200 : 0.00023053187760524452
Loss at iteration 210 : 0.00022186586284078658
Loss at iteration 220 : 0.010758358985185623
Loss at iteration 230 : 0.0016955946339294314
Loss at iteration 240 : 0.0006424684543162584
Loss at iteration 250 : 0.00011969059414695948
Loss at iteration 260 : 0.0005265625077299774
Loss at iteration 270 : 0.0037514199502766132
Loss at iteration 280 : 0.000599263294134289
Loss at iteration 290 : 0.0004378333978820592
Loss at iteration 300 : 0.004643650725483894
Loss at iteration 310 : 0.00014646194176748395
Loss at iteration 320 : 0.0016563651151955128
Loss at iteration 330 : 0.0001730969815980643
Loss at iteration 340 : 0.00010923947411356494
Loss at iteration 350 : 0.0004881576751358807
Loss at iteration 360 : 0.0002735683519858867
Loss at iteration 370 : 8.57575359987095e-05
Loss at iteration 380 : 0.0005102913710288703
Loss at iteration 390 : 0.00011681269097607583
Loss at iteration 400 : 0.004996036645025015
Loss at iteration 410 : 0.00378181179985404
Loss at iteration 420 : 0.0002079884143313393
Loss at iteration 430 : 4.537845961749554e-05
Loss at iteration 440 : 0.00037921074545010924
Loss at iteration 450 : 0.000591197342146188
Loss at iteration 460 : 0.0004590671160258353
Loss at iteration 470 : 0.00015616101154591888
Loss at iteration 480 : 0.004099826794117689
Loss at iteration 490 : 0.00011120100680273026
Loss at iteration 500 : 0.00023716782743576914
Loss at iteration 510 : 0.004525438882410526
Loss at iteration 520 : 0.0033049630001187325
Loss at iteration 530 : 0.0011182858143001795
Loss at iteration 540 : 0.00014704425120726228
Loss at iteration 550 : 0.0001770192466210574
Loss at iteration 560 : 0.00037547177635133266
Loss at iteration 570 : 0.00039003498386591673
Loss at iteration 580 : 0.0030154180712997913
Loss at iteration 590 : 0.00026186933973804116
Loss at iteration 600 : 0.0004045581736136228
Loss at iteration 610 : 5.3449424740392715e-05
Loss at iteration 620 : 0.0016132565215229988
Loss at iteration 630 : 0.001894582761451602
Loss at iteration 640 : 0.00024590763496235013
Loss at iteration 650 : 0.00021517911227419972
Loss at iteration 660 : 0.00045840785605832934
Loss at iteration 670 : 0.00041778181912377477
Loss at iteration 680 : 0.0001387164811603725
Loss at iteration 690 : 0.00021670255227945745
Loss at iteration 700 : 0.0004419573815539479
Loss at iteration 710 : 0.004509914666414261
Loss at iteration 720 : 9.946124191628769e-05
Loss at iteration 730 : 0.0003052904212381691
Loss at iteration 740 : 0.0002506458549760282
Loss at iteration 750 : 0.0009462379384785891
Loss at iteration 760 : 0.0006413744413293898
Loss at iteration 770 : 0.00022911562700755894
Loss at iteration 780 : 0.003627822268754244
Loss at iteration 790 : 0.0002822326496243477
Loss at iteration 800 : 0.0008684844360686839
Loss at iteration 810 : 0.0041290451772511005
Loss at iteration 820 : 0.0069847749546170235
Loss at iteration 830 : 0.00017268129158765078
Loss at iteration 840 : 9.564610809320584e-05
Loss at iteration 850 : 0.0002930656191892922
Loss at iteration 860 : 7.098294736351818e-05
Loss at iteration 870 : 0.0003200861974619329
Loss at iteration 880 : 0.0007062391960062087
Loss at iteration 890 : 0.0018443346489220858
Loss at iteration 900 : 0.0003373331273905933
Loss at iteration 910 : 0.0006718094227835536
Loss at iteration 920 : 0.006361157633364201
Loss at iteration 930 : 0.006090797483921051
Loss at iteration 940 : 4.903808076051064e-05
Loss at iteration 950 : 0.0001462311774957925
Loss at iteration 960 : 0.0004751587694045156
Loss at iteration 970 : 0.00014506297884508967
Loss at iteration 980 : 0.0032842843793332577
Loss at iteration 990 : 0.002357341116294265
Loss at iteration 1000 : 0.0017313570715487003
Loss at iteration 1010 : 0.0035814428701996803
Loss at iteration 1020 : 0.00025450706016272306
Loss at iteration 1030 : 0.0003337870875839144
Loss at iteration 1040 : 0.0006281285895965993
Loss at iteration 1050 : 0.0007873159484006464
Loss at iteration 1060 : 0.0002983822487294674
Loss at iteration 1070 : 0.0003775784862227738
Loss at iteration 1080 : 0.007544964086264372
Loss at iteration 1090 : 0.0006213964079506695
Loss at iteration 1100 : 0.00021136733994353563
Loss at iteration 1110 : 5.6767650676192716e-05
Loss at iteration 1120 : 0.0008525513112545013
Loss at iteration 1130 : 0.001953208353370428
Loss at iteration 1140 : 0.0006317450315691531
Loss at iteration 1150 : 0.0009355242364108562
Loss at iteration 1160 : 0.0006958362646400928
Loss at iteration 1170 : 0.00020683987531811
Loss at iteration 1180 : 0.002909093163907528
Loss at iteration 1190 : 0.00013730890350416303
Loss at iteration 1200 : 0.00032964861020445824
Loss at iteration 1210 : 0.0033732005394995213
Loss at iteration 1220 : 0.0001019397604977712
Loss at iteration 1230 : 0.0015265218680724502
Loss at iteration 1240 : 0.0043863896280527115
Loss at iteration 1250 : 0.00046246915007941425
Loss at iteration 1260 : 0.0011173398233950138
Loss at iteration 1270 : 0.005442260764539242
Loss at iteration 1280 : 0.0010142235551029444
Loss at iteration 1290 : 0.00034756376408040524
Loss at iteration 1300 : 0.00035713304532691836
Loss at iteration 1310 : 0.0010045170783996582
Loss at iteration 1320 : 0.0002918941609095782
Loss at iteration 1330 : 0.00729713961482048
Loss at iteration 1340 : 0.0008676658617332578
Loss at iteration 1350 : 0.002193516818806529
Loss at iteration 1360 : 0.00027702131774276495
Loss at iteration 1370 : 0.00022001800243742764
Loss at iteration 1380 : 0.007071608677506447
Loss at iteration 1390 : 0.0008390953298658133
Loss at iteration 1400 : 0.00014782119251322
Loss at iteration 1410 : 0.0004709759377874434
Loss at iteration 1420 : 0.001096987398341298
Loss at iteration 1430 : 0.005236402153968811
Loss at iteration 1440 : 0.0003763259737752378
Loss at iteration 1450 : 0.00010196995572187006
Loss at iteration 1460 : 0.00019183217955287546
Loss at iteration 1470 : 0.000531631987541914
Loss at iteration 1480 : 0.00016600974777247757
Loss at iteration 1490 : 0.00010168457811232656
Loss at iteration 1500 : 0.00055370555492118
Loss at iteration 1510 : 0.005523283965885639
Loss at iteration 1520 : 0.0015606809174641967
Loss at iteration 1530 : 0.0007337538991123438
Loss at iteration 1540 : 0.003496418008580804
Loss at iteration 1550 : 0.0011616053525358438
Loss at iteration 1560 : 0.0002690731780603528
Loss at iteration 1570 : 0.00010862638737307861
Loss at iteration 1580 : 0.0008405969711020589
Loss at iteration 1590 : 0.00021267789998091757
Loss at iteration 1600 : 0.00020267438958398998
Loss at iteration 1610 : 0.0030541939195245504
Loss at iteration 1620 : 0.0002617814461700618
Loss at iteration 1630 : 0.00012583141506183892
Loss at iteration 1640 : 0.0005333823501132429
Loss at iteration 1650 : 0.005281041841953993
Loss at iteration 1660 : 0.0003834133967757225
Loss at iteration 1670 : 0.00018793385243043303
Loss at iteration 1680 : 0.00010095481411553919
Loss at iteration 1690 : 0.00014759677287656814
Loss at iteration 1700 : 0.0012823191937059164
Loss at iteration 1710 : 0.0003186779795214534
Loss at iteration 1720 : 0.0002110383938997984
Loss at iteration 1730 : 0.0011014787014573812
Loss at iteration 1740 : 0.0002438271330902353
Loss at iteration 1750 : 0.0019529367564246058
The SSIM Value is: 0.9816901043123085
The PSNR Value is: 45.882900803099645
the highest SSIM value is: 45.882900803099645
the epoch is: 8
Loss at iteration 10 : 0.00020878866780549288
Loss at iteration 20 : 0.00014186170301400125
Loss at iteration 30 : 0.002547475742176175
Loss at iteration 40 : 0.0001620846160221845
Loss at iteration 50 : 0.00019505017553456128
Loss at iteration 60 : 0.0004074042371939868
Loss at iteration 70 : 0.002111610257998109
Loss at iteration 80 : 0.0029354116413742304
Loss at iteration 90 : 7.911110878922045e-05
Loss at iteration 100 : 0.00010579263471299782
Loss at iteration 110 : 0.00015765524585731328
Loss at iteration 120 : 0.00020319355826359242
Loss at iteration 130 : 0.0007466863607987761
Loss at iteration 140 : 0.00011322299542371184
Loss at iteration 150 : 0.0004966171109117568
Loss at iteration 160 : 0.00010640111577231437
Loss at iteration 170 : 0.0005746911629103124
Loss at iteration 180 : 0.000269819051027298
Loss at iteration 190 : 0.0015846455935388803
Loss at iteration 200 : 0.0003002822631970048
Loss at iteration 210 : 0.0035315656568855047
Loss at iteration 220 : 0.0003530565300025046
Loss at iteration 230 : 0.00012203947699163109
Loss at iteration 240 : 0.00029834959423169494
Loss at iteration 250 : 0.0008564532618038356
Loss at iteration 260 : 0.0028867803048342466
Loss at iteration 270 : 0.00018947063654195517
Loss at iteration 280 : 0.0001906417601276189
Loss at iteration 290 : 0.0011889999732375145
Loss at iteration 300 : 0.00045574980322271585
Loss at iteration 310 : 0.00043033217662014067
Loss at iteration 320 : 0.0003141614724881947
Loss at iteration 330 : 0.00036279080086387694
Loss at iteration 340 : 0.001229706103913486
Loss at iteration 350 : 0.00024284703249577433
Loss at iteration 360 : 0.0038197250105440617
Loss at iteration 370 : 0.0001981602981686592
Loss at iteration 380 : 0.00014098173414822668
Loss at iteration 390 : 0.00019655369396787137
Loss at iteration 400 : 0.00016558115021325648
Loss at iteration 410 : 0.00010384112829342484
Loss at iteration 420 : 0.0020805075764656067
Loss at iteration 430 : 0.0005406382842920721
Loss at iteration 440 : 0.0029086126014590263
Loss at iteration 450 : 0.00014344032388180494
Loss at iteration 460 : 0.0006939643062651157
Loss at iteration 470 : 0.0006162580684758723
Loss at iteration 480 : 0.00022920154151506722
Loss at iteration 490 : 0.00010611608013277873
Loss at iteration 500 : 0.0028170242439955473
Loss at iteration 510 : 0.0005896496004424989
Loss at iteration 520 : 0.0015028840862214565
Loss at iteration 530 : 0.00019752953085117042
Loss at iteration 540 : 0.00013075496826786548
Loss at iteration 550 : 0.00023832291481085122
Loss at iteration 560 : 0.000719216070137918
Loss at iteration 570 : 0.0004934827447868884
Loss at iteration 580 : 0.00044990371679887176
Loss at iteration 590 : 0.0023590901400893927
Loss at iteration 600 : 0.00022288714535534382
Loss at iteration 610 : 0.0003491131938062608
Loss at iteration 620 : 0.0050538512878119946
Loss at iteration 630 : 0.00047984474804252386
Loss at iteration 640 : 0.00018523153266869485
Loss at iteration 650 : 0.002596232108771801
Loss at iteration 660 : 0.0008876408683136106
Loss at iteration 670 : 0.0003097539010923356
Loss at iteration 680 : 3.2858071790542454e-05
Loss at iteration 690 : 0.0004727038322016597
Loss at iteration 700 : 9.565815707901493e-05
Loss at iteration 710 : 0.001983156893402338
Loss at iteration 720 : 0.0037697183433920145
Loss at iteration 730 : 0.00033493409864604473
Loss at iteration 740 : 0.0007140679517760873
Loss at iteration 750 : 4.62463685835246e-05
Loss at iteration 760 : 0.0004141638637520373
Loss at iteration 770 : 0.00026968843303620815
Loss at iteration 780 : 0.0008303476497530937
Loss at iteration 790 : 0.000378905184334144
Loss at iteration 800 : 0.00018216742319054902
Loss at iteration 810 : 0.002075017662718892
Loss at iteration 820 : 9.906436753226444e-05
Loss at iteration 830 : 7.997906504897401e-05
Loss at iteration 840 : 0.00031027200748212636
Loss at iteration 850 : 0.0010284148156642914
Loss at iteration 860 : 0.0009614827577024698
Loss at iteration 870 : 0.0002722506760619581
Loss at iteration 880 : 0.0002999443677254021
Loss at iteration 890 : 0.001835645642131567
Loss at iteration 900 : 0.001735050929710269
Loss at iteration 910 : 0.0008402748499065638
Loss at iteration 920 : 0.0022502171341329813
Loss at iteration 930 : 0.00043297739466652274
Loss at iteration 940 : 0.0001507203560322523
Loss at iteration 950 : 8.28485208330676e-05
Loss at iteration 960 : 0.00022983233793638647
Loss at iteration 970 : 0.0034786073956638575
Loss at iteration 980 : 0.00028317392570897937
Loss at iteration 990 : 0.0017980776028707623
Loss at iteration 1000 : 0.000875860161613673
Loss at iteration 1010 : 6.85388658894226e-05
Loss at iteration 1020 : 0.00036526212352328
Loss at iteration 1030 : 0.0035371268168091774
Loss at iteration 1040 : 0.0001885296660475433
Loss at iteration 1050 : 0.0004596355720423162
Loss at iteration 1060 : 0.011401517316699028
Loss at iteration 1070 : 0.00414532283321023
Loss at iteration 1080 : 0.0032566783484071493
Loss at iteration 1090 : 0.00024720298824831843
Loss at iteration 1100 : 7.718938286416233e-05
Loss at iteration 1110 : 0.00013213339843787253
Loss at iteration 1120 : 0.0001677114487392828
Loss at iteration 1130 : 0.00011205703049199656
Loss at iteration 1140 : 0.0008315237937495112
Loss at iteration 1150 : 0.0034089558757841587
Loss at iteration 1160 : 0.001443269313313067
Loss at iteration 1170 : 8.903156412998214e-05
Loss at iteration 1180 : 0.00038937016506679356
Loss at iteration 1190 : 0.0006094144773669541
Loss at iteration 1200 : 0.0012764509301632643
Loss at iteration 1210 : 0.000498178240377456
Loss at iteration 1220 : 0.0005341217038221657
Loss at iteration 1230 : 5.2306237193988636e-05
Loss at iteration 1240 : 0.0006984676001593471
Loss at iteration 1250 : 0.0007189732859842479
Loss at iteration 1260 : 0.0004764887853525579
Loss at iteration 1270 : 0.0021337310317903757
Loss at iteration 1280 : 0.0012669466668739915
Loss at iteration 1290 : 0.000167850885191001
Loss at iteration 1300 : 0.0001494229945819825
Loss at iteration 1310 : 0.0004731729277409613
Loss at iteration 1320 : 9.833438525674865e-05
Loss at iteration 1330 : 0.005766294896602631
Loss at iteration 1340 : 0.0002694351423997432
Loss at iteration 1350 : 0.003408279735594988
Loss at iteration 1360 : 0.00021895435929764062
Loss at iteration 1370 : 0.0009395776432938874
Loss at iteration 1380 : 0.0004304864560253918
Loss at iteration 1390 : 0.0007352760876528919
Loss at iteration 1400 : 0.00028269056929275393
Loss at iteration 1410 : 0.0011388960992917418
Loss at iteration 1420 : 0.0007336732232943177
Loss at iteration 1430 : 0.001174730365164578
Loss at iteration 1440 : 0.003934465814381838
Loss at iteration 1450 : 0.0005252192495390773
Loss at iteration 1460 : 0.00010706245666369796
Loss at iteration 1470 : 0.00015862354484852403
Loss at iteration 1480 : 0.0037794033996760845
Loss at iteration 1490 : 0.0022332011722028255
Loss at iteration 1500 : 0.0002699091855902225
Loss at iteration 1510 : 0.00034892483381554484
Loss at iteration 1520 : 0.000547749106772244
Loss at iteration 1530 : 0.00010900454071816057
Loss at iteration 1540 : 0.001745774643495679
Loss at iteration 1550 : 0.00026376493042334914
Loss at iteration 1560 : 0.00280653964728117
Loss at iteration 1570 : 0.0031637558713555336
Loss at iteration 1580 : 6.399714766303077e-05
Loss at iteration 1590 : 0.00043772056233137846
Loss at iteration 1600 : 0.0019654245115816593
Loss at iteration 1610 : 0.00016686265007592738
Loss at iteration 1620 : 0.003775964491069317
Loss at iteration 1630 : 0.003870314219966531
Loss at iteration 1640 : 0.0006160754710435867
Loss at iteration 1650 : 0.0009318874217569828
Loss at iteration 1660 : 0.00022283646103460342
Loss at iteration 1670 : 0.000488708377815783
Loss at iteration 1680 : 0.00021844488219358027
Loss at iteration 1690 : 0.0003258735523559153
Loss at iteration 1700 : 0.0008266132790595293
Loss at iteration 1710 : 0.00066998356487602
Loss at iteration 1720 : 0.002646419918164611
Loss at iteration 1730 : 0.00047886971151456237
Loss at iteration 1740 : 0.002721931552514434
Loss at iteration 1750 : 0.00010752669186331332
The SSIM Value is: 0.9745999041632933
The PSNR Value is: 45.429297722383744
the epoch is: 9
Loss at iteration 10 : 0.00016610304010100663
Loss at iteration 20 : 0.0006388630717992783
Loss at iteration 30 : 8.653572149341926e-05
Loss at iteration 40 : 0.003184328321367502
Loss at iteration 50 : 0.00338398152962327
Loss at iteration 60 : 0.0007319676224142313
Loss at iteration 70 : 0.0005548396147787571
Loss at iteration 80 : 0.001247041393071413
Loss at iteration 90 : 0.0024916608817875385
Loss at iteration 100 : 0.00020450304145924747
Loss at iteration 110 : 0.0009322017431259155
Loss at iteration 120 : 0.0037182318046689034
Loss at iteration 130 : 0.0012619760818779469
Loss at iteration 140 : 0.007310852874070406
Loss at iteration 150 : 0.006520703434944153
Loss at iteration 160 : 0.0002690415713004768
Loss at iteration 170 : 0.003679506480693817
Loss at iteration 180 : 0.00043076046858914196
Loss at iteration 190 : 9.871117072179914e-05
Loss at iteration 200 : 8.880221139406785e-05
Loss at iteration 210 : 0.0005086301825940609
Loss at iteration 220 : 0.0026838737539947033
Loss at iteration 230 : 0.0004045983077958226
Loss at iteration 240 : 0.006437198258936405
Loss at iteration 250 : 0.003913495223969221
Loss at iteration 260 : 0.0001314887049375102
Loss at iteration 270 : 0.0027432756032794714
Loss at iteration 280 : 0.007051565684378147
Loss at iteration 290 : 0.0001317095011472702
Loss at iteration 300 : 0.002127996413037181
Loss at iteration 310 : 0.0022309075575321913
Loss at iteration 320 : 0.00020237657008692622
Loss at iteration 330 : 0.007778868079185486
Loss at iteration 340 : 0.007084255572408438
Loss at iteration 350 : 0.00021065864711999893
Loss at iteration 360 : 0.0010030129924416542
Loss at iteration 370 : 0.00013414549175649881
Loss at iteration 380 : 0.0007796831196174026
Loss at iteration 390 : 0.00020315544679760933
Loss at iteration 400 : 0.0008436349453404546
Loss at iteration 410 : 0.0009335706708952785
Loss at iteration 420 : 0.0006915313424542546
Loss at iteration 430 : 0.0008035526843741536
Loss at iteration 440 : 0.0021559884771704674
Loss at iteration 450 : 0.005064946599304676
Loss at iteration 460 : 0.003451485186815262
Loss at iteration 470 : 9.427523764315993e-05
Loss at iteration 480 : 0.010620792396366596
Loss at iteration 490 : 0.0003008173080161214
Loss at iteration 500 : 0.00031323370058089495
Loss at iteration 510 : 0.0016500081401318312
Loss at iteration 520 : 0.00035251901135779917
Loss at iteration 530 : 0.006078721955418587
Loss at iteration 540 : 0.0001437469618394971
Loss at iteration 550 : 0.0006339447572827339
Loss at iteration 560 : 0.0007650419138371944
Loss at iteration 570 : 0.00032497302163392305
Loss at iteration 580 : 0.00011025564162991941
Loss at iteration 590 : 0.0017892487812787294
Loss at iteration 600 : 0.00030694724409841
Loss at iteration 610 : 0.0039826249703764915
Loss at iteration 620 : 0.0013428999809548259
Loss at iteration 630 : 0.0006183715886436403
Loss at iteration 640 : 0.00042538857087492943
Loss at iteration 650 : 0.00014267429651226848
Loss at iteration 660 : 0.00064734963234514
Loss at iteration 670 : 0.0012249094434082508
Loss at iteration 680 : 0.002711944980546832
Loss at iteration 690 : 0.0001152305121649988
Loss at iteration 700 : 0.003663283307105303
Loss at iteration 710 : 0.00013607226719614118
Loss at iteration 720 : 0.0007204052526503801
Loss at iteration 730 : 0.00020245841005817056
Loss at iteration 740 : 0.0017108824104070663
Loss at iteration 750 : 0.0003692212048918009
Loss at iteration 760 : 0.004369913600385189
Loss at iteration 770 : 8.090617484413087e-05
Loss at iteration 780 : 0.0003107655793428421
Loss at iteration 790 : 0.0010636912193149328
Loss at iteration 800 : 0.002181323477998376
Loss at iteration 810 : 0.00041780935134738684
Loss at iteration 820 : 0.0002270079276058823
Loss at iteration 830 : 0.0007230576011352241
Loss at iteration 840 : 0.00010234434739686549
Loss at iteration 850 : 0.0006819003028795123
Loss at iteration 860 : 0.006523709278553724
Loss at iteration 870 : 0.0048531461507081985
Loss at iteration 880 : 0.0002587995259091258
Loss at iteration 890 : 0.00039730226853862405
Loss at iteration 900 : 0.0006761589320376515
Loss at iteration 910 : 0.0003746774164028466
Loss at iteration 920 : 0.00014427895075641572
Loss at iteration 930 : 0.012747306376695633
Loss at iteration 940 : 9.285507258027792e-05
Loss at iteration 950 : 0.00039250345434993505
Loss at iteration 960 : 0.00011220965825486928
Loss at iteration 970 : 0.00020473203039728105
Loss at iteration 980 : 0.000623269472271204
Loss at iteration 990 : 0.003657724941149354
Loss at iteration 1000 : 0.0003114650025963783
Loss at iteration 1010 : 0.0005408620927482843
Loss at iteration 1020 : 0.0009636585018597543
Loss at iteration 1030 : 0.0004967062268406153
Loss at iteration 1040 : 0.0036925007589161396
Loss at iteration 1050 : 0.0003581036871764809
Loss at iteration 1060 : 0.002175813540816307
Loss at iteration 1070 : 0.00014675910642836243
Loss at iteration 1080 : 0.00020102599228266627
Loss at iteration 1090 : 0.0010486433748155832
Loss at iteration 1100 : 0.00023509001766797155
Loss at iteration 1110 : 0.0006906674243509769
Loss at iteration 1120 : 0.00010826028301380575
Loss at iteration 1130 : 0.0009534604614600539
Loss at iteration 1140 : 0.00019501266069710255
Loss at iteration 1150 : 0.003504397114738822
Loss at iteration 1160 : 0.0003130044206045568
Loss at iteration 1170 : 0.00011685772915370762
Loss at iteration 1180 : 0.0032843342050909996
Loss at iteration 1190 : 8.533128857379779e-05
Loss at iteration 1200 : 0.0002274444850627333
Loss at iteration 1210 : 0.00033281452488154173
Loss at iteration 1220 : 0.003313548630103469
Loss at iteration 1230 : 0.0002756916801445186
Loss at iteration 1240 : 0.000324083783198148
Loss at iteration 1250 : 0.00021367892622947693
Loss at iteration 1260 : 0.00024798489175736904
Loss at iteration 1270 : 0.005789274349808693
Loss at iteration 1280 : 9.625915845390409e-05
Loss at iteration 1290 : 0.00015187362441793084
Loss at iteration 1300 : 0.0030414497014135122
Loss at iteration 1310 : 0.002895028330385685
Loss at iteration 1320 : 0.003086104756221175
Loss at iteration 1330 : 9.786298323888332e-05
Loss at iteration 1340 : 0.0001095256011467427
Loss at iteration 1350 : 0.0004367965739220381
Loss at iteration 1360 : 0.0010073559824377298
Loss at iteration 1370 : 0.00019416719442233443
Loss at iteration 1380 : 0.0015763880219310522
Loss at iteration 1390 : 0.0005437771906144917
Loss at iteration 1400 : 8.231999527197331e-05
Loss at iteration 1410 : 0.00031492934795096517
Loss at iteration 1420 : 0.00012264010729268193
Loss at iteration 1430 : 0.0005338339251466095
Loss at iteration 1440 : 0.00019755447283387184
Loss at iteration 1450 : 0.0006181492935866117
Loss at iteration 1460 : 0.0025021519977599382
Loss at iteration 1470 : 0.00017362760263495147
Loss at iteration 1480 : 0.00017388882406521589
Loss at iteration 1490 : 0.00044764892663806677
Loss at iteration 1500 : 0.0016650018515065312
Loss at iteration 1510 : 0.00033799803350120783
Loss at iteration 1520 : 0.0002986996260005981
Loss at iteration 1530 : 0.0003397007822059095
Loss at iteration 1540 : 0.0009529321105219424
Loss at iteration 1550 : 0.0007044566445983946
Loss at iteration 1560 : 0.003186142770573497
Loss at iteration 1570 : 0.0004813669074792415
Loss at iteration 1580 : 0.004113884177058935
Loss at iteration 1590 : 0.00015387126768473536
Loss at iteration 1600 : 9.291507740272209e-05
Loss at iteration 1610 : 0.005605095531791449
Loss at iteration 1620 : 0.0035241355653852224
Loss at iteration 1630 : 0.000513397273607552
Loss at iteration 1640 : 0.004781277850270271
Loss at iteration 1650 : 0.004421754740178585
Loss at iteration 1660 : 0.0002695354341994971
Loss at iteration 1670 : 0.0020397768821567297
Loss at iteration 1680 : 0.0030566584318876266
Loss at iteration 1690 : 0.00011500295659061521
Loss at iteration 1700 : 0.0008760957862250507
Loss at iteration 1710 : 0.0003392414946574718
Loss at iteration 1720 : 0.005516550038009882
Loss at iteration 1730 : 0.00027611968107521534
Loss at iteration 1740 : 0.0006158179021440446
Loss at iteration 1750 : 0.0005248293746262789
The SSIM Value is: 0.9857743621397649
The PSNR Value is: 46.21840311672194
the highest SSIM value is: 46.21840311672194
the epoch is: 10
Loss at iteration 10 : 7.417133019771427e-05
Loss at iteration 20 : 6.931768439244479e-05
Loss at iteration 30 : 0.00018634350271895528
Loss at iteration 40 : 0.0019047618843615055
Loss at iteration 50 : 0.00024865177692845464
Loss at iteration 60 : 0.00037954444997012615
Loss at iteration 70 : 0.0033625406213104725
Loss at iteration 80 : 7.617614755872637e-05
Loss at iteration 90 : 0.00011326363892294466
Loss at iteration 100 : 0.00029007336706854403
Loss at iteration 110 : 0.00015656866889912635
Loss at iteration 120 : 0.00015503486793022603
Loss at iteration 130 : 0.00015972918481566012
Loss at iteration 140 : 0.00010356811253586784
Loss at iteration 150 : 0.0005989724304527044
Loss at iteration 160 : 0.000102113866887521
Loss at iteration 170 : 0.0003503348561935127
Loss at iteration 180 : 0.007263348437845707
Loss at iteration 190 : 0.00014136733079794794
Loss at iteration 200 : 0.0013676153030246496
Loss at iteration 210 : 0.0024631950072944164
Loss at iteration 220 : 0.0038691763766109943
Loss at iteration 230 : 0.0003728268202394247
Loss at iteration 240 : 0.0032718328293412924
Loss at iteration 250 : 0.0004326421476434916
Loss at iteration 260 : 0.0002030210744123906
Loss at iteration 270 : 0.003541010431945324
Loss at iteration 280 : 0.0023760339245200157
Loss at iteration 290 : 0.0005772084696218371
Loss at iteration 300 : 0.007724577561020851
Loss at iteration 310 : 0.0006120242760516703
Loss at iteration 320 : 0.003132173791527748
Loss at iteration 330 : 0.0029888739809393883
Loss at iteration 340 : 0.0006189994164742529
Loss at iteration 350 : 0.0005177434650249779
Loss at iteration 360 : 0.0003600296622607857
Loss at iteration 370 : 9.73126880126074e-05
Loss at iteration 380 : 0.0018268516287207603
Loss at iteration 390 : 0.001695005688816309
Loss at iteration 400 : 0.0002507478347979486
Loss at iteration 410 : 0.007756011560559273
Loss at iteration 420 : 0.0004093712195754051
Loss at iteration 430 : 0.0007756738923490047
Loss at iteration 440 : 0.00038114897324703634
Loss at iteration 450 : 0.001905669691041112
Loss at iteration 460 : 0.0034177349880337715
Loss at iteration 470 : 0.00022351725783664733
Loss at iteration 480 : 0.003574578557163477
Loss at iteration 490 : 0.0008496993687003851
Loss at iteration 500 : 0.0019191582687199116
Loss at iteration 510 : 0.000252674741204828
Loss at iteration 520 : 6.87246210873127e-05
Loss at iteration 530 : 0.00012700821389444172
Loss at iteration 540 : 0.0008634543628431857
Loss at iteration 550 : 5.94969023950398e-05
Loss at iteration 560 : 0.0030071684159338474
Loss at iteration 570 : 0.00022858216834720224
Loss at iteration 580 : 0.0006973756244406104
Loss at iteration 590 : 0.0018318342044949532
Loss at iteration 600 : 0.002281663939356804
Loss at iteration 610 : 0.001038466114550829
Loss at iteration 620 : 0.003372213104739785
Loss at iteration 630 : 0.0012903070310130715
Loss at iteration 640 : 0.00020764920918736607
Loss at iteration 650 : 9.968776430469006e-05
Loss at iteration 660 : 0.000129493695567362
Loss at iteration 670 : 0.0015409458428621292
Loss at iteration 680 : 0.00017506979929748923
Loss at iteration 690 : 0.0008861857932060957
Loss at iteration 700 : 0.0005152755184099078
Loss at iteration 710 : 0.00023817145847715437
Loss at iteration 720 : 0.0013113628374412656
Loss at iteration 730 : 0.0054320283234119415
Loss at iteration 740 : 0.0004140274249948561
Loss at iteration 750 : 6.811795174144208e-05
Loss at iteration 760 : 0.0005348256090655923
Loss at iteration 770 : 0.0006013149977661669
Loss at iteration 780 : 0.0008575796382501721
Loss at iteration 790 : 0.0004751024825964123
Loss at iteration 800 : 3.487949652480893e-05
Loss at iteration 810 : 6.77906718919985e-05
Loss at iteration 820 : 0.00771282147616148
Loss at iteration 830 : 0.0006413348019123077
Loss at iteration 840 : 0.0001981855893973261
Loss at iteration 850 : 0.0003907479695044458
Loss at iteration 860 : 0.0016669279430061579
Loss at iteration 870 : 0.0035407315008342266
Loss at iteration 880 : 0.0009763598209246993
Loss at iteration 890 : 0.00011487059236969799
Loss at iteration 900 : 0.0006609341944567859
Loss at iteration 910 : 0.0004853654245380312
Loss at iteration 920 : 0.001728851580992341
Loss at iteration 930 : 0.00024082051822915673
Loss at iteration 940 : 0.003068354446440935
Loss at iteration 950 : 0.0036589126102626324
Loss at iteration 960 : 0.00043246682616882026
Loss at iteration 970 : 0.00023704682826064527
Loss at iteration 980 : 0.00022534791787620634
Loss at iteration 990 : 0.0002474596258252859
Loss at iteration 1000 : 7.35748908482492e-05
Loss at iteration 1010 : 0.00012046402844134718
Loss at iteration 1020 : 0.0017038907390087843
Loss at iteration 1030 : 0.000696065544616431
Loss at iteration 1040 : 0.0007847537053748965
Loss at iteration 1050 : 0.0003004412283189595
Loss at iteration 1060 : 0.002808429067954421
Loss at iteration 1070 : 0.009335532784461975
Loss at iteration 1080 : 0.000275123689789325
Loss at iteration 1090 : 0.0052999346517026424
Loss at iteration 1100 : 0.00031130952993407845
Loss at iteration 1110 : 0.0024182184133678675
Loss at iteration 1120 : 0.0003964314528275281
Loss at iteration 1130 : 0.00010743258462753147
Loss at iteration 1140 : 0.002879669424146414
Loss at iteration 1150 : 0.0004422028723638505
Loss at iteration 1160 : 0.0003551096888259053
Loss at iteration 1170 : 8.595779945608228e-05
Loss at iteration 1180 : 0.0008716083830222487
Loss at iteration 1190 : 0.004657319746911526
Loss at iteration 1200 : 0.00027855075313709676
Loss at iteration 1210 : 0.00011711575643857941
Loss at iteration 1220 : 0.00023919451632536948
Loss at iteration 1230 : 0.008916029706597328
Loss at iteration 1240 : 0.0005999986315146089
Loss at iteration 1250 : 0.0004080688231624663
Loss at iteration 1260 : 0.0003207510453648865
Loss at iteration 1270 : 0.0013553362805396318
Loss at iteration 1280 : 0.0004219906695652753
Loss at iteration 1290 : 9.668570419307798e-05
Loss at iteration 1300 : 0.00015242432709783316
Loss at iteration 1310 : 0.0005902420380152762
Loss at iteration 1320 : 0.00418210169300437
Loss at iteration 1330 : 0.0006234181928448379
Loss at iteration 1340 : 7.457064930349588e-05
Loss at iteration 1350 : 0.002749573439359665
Loss at iteration 1360 : 0.00015358548262156546
Loss at iteration 1370 : 0.0006093054544180632
Loss at iteration 1380 : 0.0014134817756712437
Loss at iteration 1390 : 0.0007488435949198902
Loss at iteration 1400 : 0.0028084826190024614
Loss at iteration 1410 : 0.0028824913315474987
Loss at iteration 1420 : 0.0032953270711004734
Loss at iteration 1430 : 0.0007901362259872258
Loss at iteration 1440 : 0.0004282782319933176
Loss at iteration 1450 : 0.001770084723830223
Loss at iteration 1460 : 0.00467853294685483
Loss at iteration 1470 : 0.0023158227559179068
Loss at iteration 1480 : 0.0062212832272052765
Loss at iteration 1490 : 0.000563150504603982
Loss at iteration 1500 : 0.00022949457343202084
Loss at iteration 1510 : 0.0003769247268792242
Loss at iteration 1520 : 0.0002335537428734824
Loss at iteration 1530 : 0.002647586865350604
Loss at iteration 1540 : 0.00012125843204557896
Loss at iteration 1550 : 0.0006414966192096472
Loss at iteration 1560 : 0.0016813351539894938
Loss at iteration 1570 : 0.001305505633354187
Loss at iteration 1580 : 0.00012048846110701561
Loss at iteration 1590 : 0.0009983702329918742
Loss at iteration 1600 : 0.00694239279255271
Loss at iteration 1610 : 4.700956924352795e-05
Loss at iteration 1620 : 0.0010284954914823174
Loss at iteration 1630 : 0.003529119770973921
Loss at iteration 1640 : 0.0007248362526297569
Loss at iteration 1650 : 0.0069122109562158585
Loss at iteration 1660 : 0.00021721732628066093
Loss at iteration 1670 : 0.006792066618800163
Loss at iteration 1680 : 0.00018855446251109242
Loss at iteration 1690 : 0.00012316428183112293
Loss at iteration 1700 : 0.004053947050124407
Loss at iteration 1710 : 0.0001438748586224392
Loss at iteration 1720 : 0.00026871307636611164
Loss at iteration 1730 : 0.002728368854150176
Loss at iteration 1740 : 9.651766595197842e-05
Loss at iteration 1750 : 0.002922701183706522
The SSIM Value is: 0.987043580688569
The PSNR Value is: 46.15244985572042
the epoch is: 11
Loss at iteration 10 : 0.0015048650093376637
Loss at iteration 20 : 0.0001198513200506568
Loss at iteration 30 : 0.00017059441597666591
Loss at iteration 40 : 0.0075969398021698
Loss at iteration 50 : 0.00010904912778642029
Loss at iteration 60 : 0.0012365374714136124
Loss at iteration 70 : 0.0014588069170713425
Loss at iteration 80 : 0.00045624375343322754
Loss at iteration 90 : 0.00015904924657661468
Loss at iteration 100 : 0.0004547795979306102
Loss at iteration 110 : 0.0006596995517611504
Loss at iteration 120 : 0.005331345368176699
Loss at iteration 130 : 0.00035070593003183603
Loss at iteration 140 : 0.004604153335094452
Loss at iteration 150 : 4.873982470599003e-05
Loss at iteration 160 : 0.0010271142236888409
Loss at iteration 170 : 0.0003490352537482977
Loss at iteration 180 : 0.0006803569267503917
Loss at iteration 190 : 0.00012472874368540943
Loss at iteration 200 : 0.0011472650803625584
Loss at iteration 210 : 0.00026317036827094853
Loss at iteration 220 : 0.003573792753741145
Loss at iteration 230 : 0.0019109202548861504
Loss at iteration 240 : 0.00032029941212385893
Loss at iteration 250 : 0.003253752365708351
Loss at iteration 260 : 0.00017029844457283616
Loss at iteration 270 : 0.0006739377859048545
Loss at iteration 280 : 0.000892375479452312
Loss at iteration 290 : 0.0047364626079797745
Loss at iteration 300 : 0.0015168641693890095
Loss at iteration 310 : 0.0023377127945423126
Loss at iteration 320 : 0.0007981377420946956
Loss at iteration 330 : 0.0014502564445137978
Loss at iteration 340 : 0.0015971646644175053
Loss at iteration 350 : 0.0006654065800830722
Loss at iteration 360 : 0.002466990612447262
Loss at iteration 370 : 0.0004797691653948277
Loss at iteration 380 : 0.0004063391825184226
Loss at iteration 390 : 0.0004459541232790798
Loss at iteration 400 : 0.0004019720945507288
Loss at iteration 410 : 0.00015340126992668957
Loss at iteration 420 : 0.001959840999916196
Loss at iteration 430 : 0.003046371042728424
Loss at iteration 440 : 9.409268386662006e-05
Loss at iteration 450 : 0.00010820508032338694
Loss at iteration 460 : 0.00031476133153773844
Loss at iteration 470 : 0.0059780338779091835
Loss at iteration 480 : 0.0004895548918284476
Loss at iteration 490 : 0.0017910512397065759
Loss at iteration 500 : 0.0005836593918502331
Loss at iteration 510 : 0.00022368188365362585
Loss at iteration 520 : 0.00024955382104963064
Loss at iteration 530 : 0.0022677513770759106
Loss at iteration 540 : 0.0005373506573960185
Loss at iteration 550 : 0.00027355016209185123
Loss at iteration 560 : 0.002141518983989954
Loss at iteration 570 : 0.00016654503997415304
Loss at iteration 580 : 0.002153357956558466
Loss at iteration 590 : 0.00011130121856695041
Loss at iteration 600 : 0.005703062284737825
Loss at iteration 610 : 0.00016928954573813826
Loss at iteration 620 : 0.00015534568228758872
Loss at iteration 630 : 0.004101068712770939
Loss at iteration 640 : 0.0003071671526413411
Loss at iteration 650 : 0.0006372442585416138
Loss at iteration 660 : 2.9509223168133758e-05
Loss at iteration 670 : 0.0010319460416212678
Loss at iteration 680 : 0.0006185949314385653
Loss at iteration 690 : 0.0002477993839420378
Loss at iteration 700 : 0.0034755829256027937
Loss at iteration 710 : 0.0002761688083410263
Loss at iteration 720 : 0.000532225240021944
Loss at iteration 730 : 0.00022763069136999547
Loss at iteration 740 : 0.0012062388705089688
Loss at iteration 750 : 0.00017361436039209366
Loss at iteration 760 : 0.00017212313832715154
Loss at iteration 770 : 0.003252126509323716
Loss at iteration 780 : 0.0003940723545383662
Loss at iteration 790 : 0.00018593348795548081
Loss at iteration 800 : 0.00031831610249355435
Loss at iteration 810 : 0.004223279654979706
Loss at iteration 820 : 0.00018136380822397768
Loss at iteration 830 : 0.0024677347391843796
Loss at iteration 840 : 2.4838558601913974e-05
Loss at iteration 850 : 0.0024534384720027447
Loss at iteration 860 : 0.00010132127499673516
Loss at iteration 870 : 0.0001908399281091988
Loss at iteration 880 : 0.0026343166828155518
Loss at iteration 890 : 0.0015165787190198898
Loss at iteration 900 : 9.104359924094751e-05
Loss at iteration 910 : 8.785424870438874e-05
Loss at iteration 920 : 8.96213750820607e-05
Loss at iteration 930 : 0.0020179455168545246
Loss at iteration 940 : 0.00012721135863102973
Loss at iteration 950 : 0.00016999623039737344
Loss at iteration 960 : 7.895702583482489e-05
Loss at iteration 970 : 0.00015841962886042893
Loss at iteration 980 : 0.00029561988776549697
Loss at iteration 990 : 0.003269593231379986
Loss at iteration 1000 : 0.00018809486937243491
Loss at iteration 1010 : 0.00023160025011748075
Loss at iteration 1020 : 0.0002456298971083015
Loss at iteration 1030 : 0.0047074188478291035
Loss at iteration 1040 : 0.00017668177315499634
Loss at iteration 1050 : 0.0030012382194399834
Loss at iteration 1060 : 0.0008410695008933544
Loss at iteration 1070 : 0.00018064097093883902
Loss at iteration 1080 : 0.0003247294225730002
Loss at iteration 1090 : 0.0002747939433902502
Loss at iteration 1100 : 0.00013910462439525872
Loss at iteration 1110 : 0.003549246583133936
Loss at iteration 1120 : 5.9632438933476806e-05
Loss at iteration 1130 : 0.00021201664640102535
Loss at iteration 1140 : 0.00016038809553720057
Loss at iteration 1150 : 0.0001355582062387839
Loss at iteration 1160 : 0.0014298557071015239
Loss at iteration 1170 : 0.0037982449866831303
Loss at iteration 1180 : 8.43321395223029e-05
Loss at iteration 1190 : 0.0026103761047124863
Loss at iteration 1200 : 0.0005800093058496714
Loss at iteration 1210 : 0.003914922941476107
Loss at iteration 1220 : 0.0002592653618194163
Loss at iteration 1230 : 0.00044526177225634456
Loss at iteration 1240 : 0.0005044674035161734
Loss at iteration 1250 : 0.00019093355513177812
Loss at iteration 1260 : 0.003321990603581071
Loss at iteration 1270 : 0.0003764604916796088
Loss at iteration 1280 : 4.9588506954023615e-05
Loss at iteration 1290 : 0.00019240498659200966
Loss at iteration 1300 : 0.00041772599797695875
Loss at iteration 1310 : 0.00017437223868910223
Loss at iteration 1320 : 0.0005889995372854173
Loss at iteration 1330 : 0.0003004362224601209
Loss at iteration 1340 : 0.00014439952792599797
Loss at iteration 1350 : 0.00017015727644320577
Loss at iteration 1360 : 0.0010640635155141354
Loss at iteration 1370 : 0.0002771753934212029
Loss at iteration 1380 : 0.0004328742506913841
Loss at iteration 1390 : 0.000976927694864571
Loss at iteration 1400 : 0.0012569219106808305
Loss at iteration 1410 : 0.00039328463026322424
Loss at iteration 1420 : 0.012731770984828472
Loss at iteration 1430 : 0.00022489737602882087
Loss at iteration 1440 : 0.0069378819316625595
Loss at iteration 1450 : 0.00024361218675039709
Loss at iteration 1460 : 0.0013468583347275853
Loss at iteration 1470 : 0.0005005559069104493
Loss at iteration 1480 : 0.0005695304134860635
Loss at iteration 1490 : 0.00018452647782396525
Loss at iteration 1500 : 0.00021488417405635118
Loss at iteration 1510 : 0.0008891588659025729
Loss at iteration 1520 : 0.00018539559096097946
Loss at iteration 1530 : 0.004139218013733625
Loss at iteration 1540 : 0.00021585950162261724
Loss at iteration 1550 : 0.00017664114420767874
Loss at iteration 1560 : 0.0010963837848976254
Loss at iteration 1570 : 0.0001724210596876219
Loss at iteration 1580 : 0.005241699051111937
Loss at iteration 1590 : 0.0005397503264248371
Loss at iteration 1600 : 0.0006147227250039577
Loss at iteration 1610 : 0.0003342373529449105
Loss at iteration 1620 : 0.00013941268844064325
Loss at iteration 1630 : 0.00018824533617589623
Loss at iteration 1640 : 0.005571196787059307
Loss at iteration 1650 : 0.00045286520617082715
Loss at iteration 1660 : 0.0006874615210108459
Loss at iteration 1670 : 0.0005075298249721527
Loss at iteration 1680 : 0.00037191581213846803
Loss at iteration 1690 : 4.617410013452172e-05
Loss at iteration 1700 : 7.094220200087875e-05
Loss at iteration 1710 : 0.0006971883703954518
Loss at iteration 1720 : 0.0001209041802212596
Loss at iteration 1730 : 0.0014824159443378448
Loss at iteration 1740 : 0.00028669158928096294
Loss at iteration 1750 : 0.0007482476066797972
The SSIM Value is: 0.9825575732449603
The PSNR Value is: 45.9770216689761
the epoch is: 12
Loss at iteration 10 : 0.0002155556867364794
Loss at iteration 20 : 0.00033998096478171647
Loss at iteration 30 : 0.0005516187520697713
Loss at iteration 40 : 0.0007896568858996034
Loss at iteration 50 : 0.007390985265374184
Loss at iteration 60 : 0.0002288363320985809
Loss at iteration 70 : 0.005597302224487066
Loss at iteration 80 : 6.961854523979127e-05
Loss at iteration 90 : 0.0003296872600913048
Loss at iteration 100 : 0.00018899507995229214
Loss at iteration 110 : 0.0002585453330539167
Loss at iteration 120 : 0.00020248681539669633
Loss at iteration 130 : 0.00041814730502665043
Loss at iteration 140 : 0.00021199214097578079
Loss at iteration 150 : 0.0010597913060337305
Loss at iteration 160 : 0.00019316677935421467
Loss at iteration 170 : 0.00017598368867766112
Loss at iteration 180 : 0.0002627850335557014
Loss at iteration 190 : 0.00029558833921328187
Loss at iteration 200 : 7.746856135781854e-05
Loss at iteration 210 : 0.00013706315075978637
Loss at iteration 220 : 0.00032673258101567626
Loss at iteration 230 : 0.000788264733273536
Loss at iteration 240 : 0.000760189606808126
Loss at iteration 250 : 0.001075114356353879
Loss at iteration 260 : 0.0004599572566803545
Loss at iteration 270 : 0.000264633767073974
Loss at iteration 280 : 0.0008876272477209568
Loss at iteration 290 : 0.00010044414375443012
Loss at iteration 300 : 0.002270472701638937
Loss at iteration 310 : 0.0005690964171662927
Loss at iteration 320 : 0.00041596623486839235
Loss at iteration 330 : 9.525938367005438e-05
Loss at iteration 340 : 0.0048407819122076035
Loss at iteration 350 : 0.004215072840452194
Loss at iteration 360 : 0.0006441935547627509
Loss at iteration 370 : 0.0004946193075738847
Loss at iteration 380 : 0.0002755891182459891
Loss at iteration 390 : 0.00019204696582164615
Loss at iteration 400 : 0.0003309708263259381
Loss at iteration 410 : 9.285270789405331e-05
Loss at iteration 420 : 0.00023771591077093035
Loss at iteration 430 : 0.003841341705992818
Loss at iteration 440 : 0.0006678604404442012
Loss at iteration 450 : 0.00013221072731539607
Loss at iteration 460 : 5.567410698859021e-05
Loss at iteration 470 : 0.0005503762513399124
Loss at iteration 480 : 0.0005067075253464282
Loss at iteration 490 : 0.00014274865679908544
Loss at iteration 500 : 0.001040555303916335
Loss at iteration 510 : 0.00010709185153245926
Loss at iteration 520 : 0.0009130990947596729
Loss at iteration 530 : 0.0005491951596923172
Loss at iteration 540 : 0.0008975071832537651
Loss at iteration 550 : 0.004935554228723049
Loss at iteration 560 : 0.001156531972810626
Loss at iteration 570 : 0.00043571629794314504
Loss at iteration 580 : 7.709008059464395e-05
Loss at iteration 590 : 0.001368110068142414
Loss at iteration 600 : 0.0002882179687730968
Loss at iteration 610 : 0.002977886004373431
Loss at iteration 620 : 0.0007188936579041183
Loss at iteration 630 : 0.005422254092991352
Loss at iteration 640 : 0.0004131919122301042
Loss at iteration 650 : 0.0037055741995573044
Loss at iteration 660 : 3.4201788366772234e-05
Loss at iteration 670 : 6.120594480307773e-05
Loss at iteration 680 : 0.0023195170797407627
Loss at iteration 690 : 0.00014662551984656602
Loss at iteration 700 : 0.0016284879529848695
Loss at iteration 710 : 0.000399900833144784
Loss at iteration 720 : 0.00022168367286212742
Loss at iteration 730 : 7.191381882876158e-05
Loss at iteration 740 : 0.00021459057461470366
Loss at iteration 750 : 0.00017599684360902756
Loss at iteration 760 : 0.002675187774002552
Loss at iteration 770 : 8.992370567284524e-05
Loss at iteration 780 : 0.00020357882021926343
Loss at iteration 790 : 0.0001579282688908279
Loss at iteration 800 : 5.6764951295917854e-05
Loss at iteration 810 : 0.0003176746831741184
Loss at iteration 820 : 0.000834661943372339
Loss at iteration 830 : 0.0009554594289511442
Loss at iteration 840 : 0.006886722985655069
Loss at iteration 850 : 0.00016599163063801825
Loss at iteration 860 : 0.000935429590754211
Loss at iteration 870 : 0.0048868912272155285
Loss at iteration 880 : 0.00038857298204675317
Loss at iteration 890 : 0.007297590374946594
Loss at iteration 900 : 0.00015774751955177635
Loss at iteration 910 : 0.0014360774075612426
Loss at iteration 920 : 0.0009320505196228623
Loss at iteration 930 : 0.011388203129172325
Loss at iteration 940 : 0.0006087234942242503
Loss at iteration 950 : 0.0003812883805949241
Loss at iteration 960 : 0.00013055258023086935
Loss at iteration 970 : 0.0017679418670013547
Loss at iteration 980 : 0.0003289445012342185
Loss at iteration 990 : 0.00020190169743727893
Loss at iteration 1000 : 0.005400749854743481
Loss at iteration 1010 : 0.0005467638839036226
Loss at iteration 1020 : 0.003843404585495591
Loss at iteration 1030 : 0.00022443455236498266
Loss at iteration 1040 : 0.0007599845412187278
Loss at iteration 1050 : 0.0006973599665798247
Loss at iteration 1060 : 0.0051722279749810696
Loss at iteration 1070 : 9.687335113994777e-05
Loss at iteration 1080 : 0.00017940709949471056
Loss at iteration 1090 : 0.0006882702000439167
Loss at iteration 1100 : 0.0020720704924315214
Loss at iteration 1110 : 0.002303500659763813
Loss at iteration 1120 : 0.00030046948813833296
Loss at iteration 1130 : 0.0003018034331034869
Loss at iteration 1140 : 0.00013112301530782133
Loss at iteration 1150 : 0.00038116821087896824
Loss at iteration 1160 : 0.00016453910211566836
Loss at iteration 1170 : 0.00041309569496661425
Loss at iteration 1180 : 0.0004848369280807674
Loss at iteration 1190 : 0.00013797073916066438
Loss at iteration 1200 : 0.003775982651859522
Loss at iteration 1210 : 0.006443442776799202
Loss at iteration 1220 : 0.0021118372678756714
Loss at iteration 1230 : 0.0006993105635046959
Loss at iteration 1240 : 0.0028125622775405645
Loss at iteration 1250 : 0.0005365199176594615
Loss at iteration 1260 : 0.0002961178543046117
Loss at iteration 1270 : 0.002377830445766449
Loss at iteration 1280 : 8.12249636510387e-05
Loss at iteration 1290 : 9.464743197895586e-05
Loss at iteration 1300 : 0.00046662986278533936
Loss at iteration 1310 : 0.0021757171489298344
Loss at iteration 1320 : 0.01445587445050478
Loss at iteration 1330 : 0.0024549472145736217
Loss at iteration 1340 : 0.0005859389202669263
Loss at iteration 1350 : 0.00014572989312000573
Loss at iteration 1360 : 0.0004354190023150295
Loss at iteration 1370 : 0.00022147284471429884
Loss at iteration 1380 : 0.00034634614712558687
Loss at iteration 1390 : 0.00010717597615439445
Loss at iteration 1400 : 0.00015339397941716015
Loss at iteration 1410 : 0.0003239764191675931
Loss at iteration 1420 : 0.004639528691768646
Loss at iteration 1430 : 0.00020938630041200668
Loss at iteration 1440 : 0.001173972268588841
Loss at iteration 1450 : 0.0003588824765756726
Loss at iteration 1460 : 6.326385482680053e-05
Loss at iteration 1470 : 0.00027914135716855526
Loss at iteration 1480 : 8.275701839011163e-05
Loss at iteration 1490 : 0.0005475154030136764
Loss at iteration 1500 : 0.0034988471306860447
Loss at iteration 1510 : 0.0019032929558306932
Loss at iteration 1520 : 0.0002745108213275671
Loss at iteration 1530 : 0.0006577648455277085
Loss at iteration 1540 : 0.00025384585023857653
Loss at iteration 1550 : 0.0011950412299484015
Loss at iteration 1560 : 0.0010839863680303097
Loss at iteration 1570 : 0.00015239580534398556
Loss at iteration 1580 : 0.00012124738714192063
Loss at iteration 1590 : 0.0019126434344798326
Loss at iteration 1600 : 0.006826294586062431
Loss at iteration 1610 : 0.00010821392061188817
Loss at iteration 1620 : 0.002378394128754735
Loss at iteration 1630 : 6.56347765470855e-05
Loss at iteration 1640 : 9.169640543404967e-05
Loss at iteration 1650 : 6.748177111148834e-05
Loss at iteration 1660 : 0.00018433498917147517
Loss at iteration 1670 : 8.752541907597333e-05
Loss at iteration 1680 : 0.0022446250077337027
Loss at iteration 1690 : 0.000419703486841172
Loss at iteration 1700 : 0.0007648117025382817
Loss at iteration 1710 : 0.0008525034645572305
Loss at iteration 1720 : 0.0008727950043976307
Loss at iteration 1730 : 0.0011312991846352816
Loss at iteration 1740 : 0.003327802987769246
Loss at iteration 1750 : 0.00034511208650656044
The SSIM Value is: 0.9600915048878623
The PSNR Value is: 44.55207085294345
the epoch is: 13
Loss at iteration 10 : 0.00011305578664178029
Loss at iteration 20 : 0.0020377589389681816
Loss at iteration 30 : 7.859408651711419e-05
Loss at iteration 40 : 0.0012051085941493511
Loss at iteration 50 : 0.006152779795229435
Loss at iteration 60 : 0.00023714842973276973
Loss at iteration 70 : 0.00022983619419392198
Loss at iteration 80 : 0.006610393058508635
Loss at iteration 90 : 9.923111065290868e-05
Loss at iteration 100 : 0.0010678066173568368
Loss at iteration 110 : 0.0035413457080721855
Loss at iteration 120 : 6.912225217092782e-05
Loss at iteration 130 : 0.00034620589576661587
Loss at iteration 140 : 0.0002576294064056128
Loss at iteration 150 : 0.00024668750120326877
Loss at iteration 160 : 0.0008984599262475967
Loss at iteration 170 : 0.00015850638737902045
Loss at iteration 180 : 0.002938801422715187
Loss at iteration 190 : 0.0009199484484270215
Loss at iteration 200 : 0.00018729723524302244
Loss at iteration 210 : 0.00023181241704151034
Loss at iteration 220 : 0.0002879411622416228
Loss at iteration 230 : 8.718087337911129e-05
Loss at iteration 240 : 0.002546506468206644
Loss at iteration 250 : 0.002068481408059597
Loss at iteration 260 : 0.0031109200790524483
Loss at iteration 270 : 0.0037690086755901575
Loss at iteration 280 : 6.905080226715654e-05
Loss at iteration 290 : 0.0031991186551749706
Loss at iteration 300 : 0.002333133015781641
Loss at iteration 310 : 0.0002885864523705095
Loss at iteration 320 : 0.002994960406795144
Loss at iteration 330 : 0.005258127115666866
Loss at iteration 340 : 0.00041713970131240785
Loss at iteration 350 : 0.0004304270551074296
Loss at iteration 360 : 0.00018710416043177247
Loss at iteration 370 : 5.5662429076619446e-05
Loss at iteration 380 : 0.001043552765622735
Loss at iteration 390 : 0.00011895868374267593
Loss at iteration 400 : 0.00016713938384782523
Loss at iteration 410 : 0.003238497767597437
Loss at iteration 420 : 0.00016009656246751547
Loss at iteration 430 : 0.002306184032931924
Loss at iteration 440 : 0.0009372596396133304
Loss at iteration 450 : 0.00017295655561611056
Loss at iteration 460 : 0.0003335009387228638
Loss at iteration 470 : 0.00040000834269449115
Loss at iteration 480 : 0.00015673237794544548
Loss at iteration 490 : 6.363930879160762e-05
Loss at iteration 500 : 0.0005273763090372086
Loss at iteration 510 : 0.0001060579888871871
Loss at iteration 520 : 0.0027723275125026703
Loss at iteration 530 : 0.00019376807904336601
Loss at iteration 540 : 5.29311437276192e-05
Loss at iteration 550 : 0.00022451713448390365
Loss at iteration 560 : 0.001336620538495481
Loss at iteration 570 : 0.0002993863890878856
Loss at iteration 580 : 0.000672308262437582
Loss at iteration 590 : 0.005078505724668503
Loss at iteration 600 : 9.418769332114607e-05
Loss at iteration 610 : 0.0001290250802412629
Loss at iteration 620 : 0.002370423637330532
Loss at iteration 630 : 0.0003766515583265573
Loss at iteration 640 : 0.00037848210195079446
Loss at iteration 650 : 0.0002936671662610024
Loss at iteration 660 : 0.005074421875178814
Loss at iteration 670 : 0.0017616713885217905
Loss at iteration 680 : 0.0004199729592073709
Loss at iteration 690 : 0.00020978617249056697
Loss at iteration 700 : 0.000363379018381238
Loss at iteration 710 : 0.00014549458865076303
Loss at iteration 720 : 0.00044733280083164573
Loss at iteration 730 : 0.0006428356282413006
Loss at iteration 740 : 0.0007837418233975768
Loss at iteration 750 : 0.0004490547871682793
Loss at iteration 760 : 0.00013540418876800686
Loss at iteration 770 : 4.5036955270916224e-05
Loss at iteration 780 : 0.0008695831638760865
Loss at iteration 790 : 0.0069311875849962234
Loss at iteration 800 : 0.00042904101428575814
Loss at iteration 810 : 0.00011151935905218124
Loss at iteration 820 : 0.00031433196272701025
Loss at iteration 830 : 0.00022522328072227538
Loss at iteration 840 : 0.000353809300577268
Loss at iteration 850 : 0.00018293960602022707
Loss at iteration 860 : 0.002065801527351141
Loss at iteration 870 : 0.0003081625036429614
Loss at iteration 880 : 0.0004155836650170386
Loss at iteration 890 : 0.0005107545293867588
Loss at iteration 900 : 0.002075889613479376
Loss at iteration 910 : 0.002561134286224842
Loss at iteration 920 : 0.0009073774563148618
Loss at iteration 930 : 0.0009003981249406934
Loss at iteration 940 : 0.0019195184577256441
Loss at iteration 950 : 0.0006641600048169494
Loss at iteration 960 : 0.0020750481635332108
Loss at iteration 970 : 0.00010909352567978203
Loss at iteration 980 : 0.00019980194338131696
Loss at iteration 990 : 0.0003058837610296905
Loss at iteration 1000 : 0.0004863940121140331
Loss at iteration 1010 : 9.092315303860232e-05
Loss at iteration 1020 : 0.0018235919997096062
Loss at iteration 1030 : 0.00014085511793382466
Loss at iteration 1040 : 0.00035958868102170527
Loss at iteration 1050 : 0.00044673681259155273
Loss at iteration 1060 : 0.0009622351499274373
Loss at iteration 1070 : 0.004508486017584801
Loss at iteration 1080 : 0.004648442845791578
Loss at iteration 1090 : 0.0005561904981732368
Loss at iteration 1100 : 0.0038896272890269756
Loss at iteration 1110 : 0.00021785286662634462
Loss at iteration 1120 : 0.0006937071448192
Loss at iteration 1130 : 0.00024521470186300576
Loss at iteration 1140 : 0.0014934887876734138
Loss at iteration 1150 : 0.0003256781492382288
Loss at iteration 1160 : 0.000120437158329878
Loss at iteration 1170 : 0.00032813166035339236
Loss at iteration 1180 : 0.0017926035216078162
Loss at iteration 1190 : 9.969632810680196e-05
Loss at iteration 1200 : 0.0006697417120449245
Loss at iteration 1210 : 0.0002113466471200809
Loss at iteration 1220 : 0.00011724995420081541
Loss at iteration 1230 : 0.0001551845925860107
Loss at iteration 1240 : 0.0006610346608795226
Loss at iteration 1250 : 0.00022064606309868395
Loss at iteration 1260 : 0.0002658634912222624
Loss at iteration 1270 : 0.0006435621762648225
Loss at iteration 1280 : 0.005181434098631144
Loss at iteration 1290 : 0.0008512666681781411
Loss at iteration 1300 : 0.0003372615319676697
Loss at iteration 1310 : 0.0002484116703271866
Loss at iteration 1320 : 0.0017506700241938233
Loss at iteration 1330 : 0.004087372682988644
Loss at iteration 1340 : 0.004542360547930002
Loss at iteration 1350 : 0.002061384730041027
Loss at iteration 1360 : 0.002473557600751519
Loss at iteration 1370 : 0.0005492595373652875
Loss at iteration 1380 : 7.813437696313486e-05
Loss at iteration 1390 : 0.0001341391762252897
Loss at iteration 1400 : 0.005832409020513296
Loss at iteration 1410 : 0.0009310117457062006
Loss at iteration 1420 : 0.0010736833792179823
Loss at iteration 1430 : 0.0006357088568620384
Loss at iteration 1440 : 0.0001985691924346611
Loss at iteration 1450 : 0.000955511350184679
Loss at iteration 1460 : 0.0005142426816746593
Loss at iteration 1470 : 0.0008531446801498532
Loss at iteration 1480 : 0.000366571155609563
Loss at iteration 1490 : 0.00016180574311874807
Loss at iteration 1500 : 0.00012289240839891136
Loss at iteration 1510 : 0.0003040420124307275
Loss at iteration 1520 : 0.00027644014335237443
Loss at iteration 1530 : 0.0001459007617086172
Loss at iteration 1540 : 0.001202998450025916
Loss at iteration 1550 : 0.0002237542939838022
Loss at iteration 1560 : 0.00911712646484375
Loss at iteration 1570 : 0.004584106151014566
Loss at iteration 1580 : 7.383145566564053e-05
Loss at iteration 1590 : 0.00017422236851416528
Loss at iteration 1600 : 0.005079552996903658
Loss at iteration 1610 : 0.0024071019142866135
Loss at iteration 1620 : 0.0021741650998592377
Loss at iteration 1630 : 0.0032908045686781406
Loss at iteration 1640 : 0.0025726701132953167
Loss at iteration 1650 : 0.0013216320658102632
Loss at iteration 1660 : 0.0005923620774410665
Loss at iteration 1670 : 0.00033499166602268815
Loss at iteration 1680 : 0.0004456561873666942
Loss at iteration 1690 : 0.00020980292174499482
Loss at iteration 1700 : 0.0033907091710716486
Loss at iteration 1710 : 0.007959384471178055
Loss at iteration 1720 : 0.0029738466255366802
Loss at iteration 1730 : 0.0038134297356009483
Loss at iteration 1740 : 0.000512407161295414
Loss at iteration 1750 : 0.00132339121773839
The SSIM Value is: 0.9839069394288084
The PSNR Value is: 46.16481151664835
the epoch is: 14
Loss at iteration 10 : 0.00039764237590134144
Loss at iteration 20 : 0.00016042360221035779
Loss at iteration 30 : 0.0003008900966960937
Loss at iteration 40 : 0.0009835762903094292
Loss at iteration 50 : 0.00026181797147728503
Loss at iteration 60 : 0.0005425765411928296
Loss at iteration 70 : 7.527988782385364e-05
Loss at iteration 80 : 0.0028937850147485733
Loss at iteration 90 : 0.00011169746721861884
Loss at iteration 100 : 0.0003571587731130421
Loss at iteration 110 : 0.00014817062765359879
Loss at iteration 120 : 0.0007387029472738504
Loss at iteration 130 : 0.00157718057744205
Loss at iteration 140 : 0.00021343951812013984
Loss at iteration 150 : 0.0031271474435925484
Loss at iteration 160 : 0.0009106732904911041
Loss at iteration 170 : 0.0008219731971621513
Loss at iteration 180 : 0.002772978274151683
Loss at iteration 190 : 0.0021959063597023487
Loss at iteration 200 : 0.0006684280815534294
Loss at iteration 210 : 0.00014402586384676397
Loss at iteration 220 : 7.868737884564325e-05
Loss at iteration 230 : 0.00016389564552810043
Loss at iteration 240 : 0.00011536770762177184
Loss at iteration 250 : 0.0019009889801964164
Loss at iteration 260 : 0.00014802752411924303
Loss at iteration 270 : 0.0014455994823947549
Loss at iteration 280 : 0.002471631160005927
Loss at iteration 290 : 0.0036032618954777718
Loss at iteration 300 : 0.0007327126804739237
Loss at iteration 310 : 0.001982396002858877
Loss at iteration 320 : 0.0005710073746740818
Loss at iteration 330 : 0.005226136650890112
Loss at iteration 340 : 0.002610186580568552
Loss at iteration 350 : 0.00012495661212597042
Loss at iteration 360 : 0.0001876055175671354
Loss at iteration 370 : 0.0003464197798166424
Loss at iteration 380 : 0.0005277901072986424
Loss at iteration 390 : 0.003185574198141694
Loss at iteration 400 : 0.00011063093552365899
Loss at iteration 410 : 0.0036719869822263718
Loss at iteration 420 : 7.907815597718582e-05
Loss at iteration 430 : 0.00019853802223224193
Loss at iteration 440 : 0.0002489425241947174
Loss at iteration 450 : 0.0006064731860533357
Loss at iteration 460 : 0.0005876700743101537
Loss at iteration 470 : 0.0002161700394935906
Loss at iteration 480 : 0.001040435628965497
Loss at iteration 490 : 0.0005086022429168224
Loss at iteration 500 : 0.0025990321300923824
Loss at iteration 510 : 0.0007025736849755049
Loss at iteration 520 : 0.0031353028025478125
Loss at iteration 530 : 0.00025673297932371497
Loss at iteration 540 : 0.004432319197803736
Loss at iteration 550 : 0.0019391991663724184
Loss at iteration 560 : 0.0001681216963334009
Loss at iteration 570 : 0.004784104414284229
Loss at iteration 580 : 9.401603892911226e-05
Loss at iteration 590 : 0.00383591465651989
Loss at iteration 600 : 0.0024011782370507717
Loss at iteration 610 : 0.0002462213742546737
Loss at iteration 620 : 0.0022635473869740963
Loss at iteration 630 : 0.0007180090178735554
Loss at iteration 640 : 0.000990473898127675
Loss at iteration 650 : 0.0031277614179998636
Loss at iteration 660 : 0.005750512238591909
Loss at iteration 670 : 0.0005173149984329939
Loss at iteration 680 : 0.0006361586274579167
Loss at iteration 690 : 0.0006590808043256402
Loss at iteration 700 : 0.00017272791592404246
Loss at iteration 710 : 0.0007192391203716397
Loss at iteration 720 : 0.00023803782823961228
Loss at iteration 730 : 0.00037406623596325517
Loss at iteration 740 : 8.317272295244038e-05
Loss at iteration 750 : 0.000860353815369308
Loss at iteration 760 : 0.00017554980877321213
Loss at iteration 770 : 0.00010800999007187784
Loss at iteration 780 : 0.002169165061786771
Loss at iteration 790 : 0.0004633108910638839
Loss at iteration 800 : 0.00022950363927520812
Loss at iteration 810 : 0.0001266241742996499
Loss at iteration 820 : 0.0017188265919685364
Loss at iteration 830 : 0.0002341569634154439
Loss at iteration 840 : 0.0011340347118675709
Loss at iteration 850 : 0.00018508841458242387
Loss at iteration 860 : 0.00015456363325938582
Loss at iteration 870 : 0.002472401363775134
Loss at iteration 880 : 7.880289194872603e-05
Loss at iteration 890 : 0.003207300091162324
Loss at iteration 900 : 0.0008949567563831806
Loss at iteration 910 : 0.00021762120013590902
Loss at iteration 920 : 0.0026669094804674387
Loss at iteration 930 : 5.84823137614876e-05
Loss at iteration 940 : 0.0035644033923745155
Loss at iteration 950 : 0.0028927153907716274
Loss at iteration 960 : 0.0021742782555520535
Loss at iteration 970 : 0.00011491957411635667
Loss at iteration 980 : 0.00029182518483139575
Loss at iteration 990 : 0.005007362458854914
Loss at iteration 1000 : 0.0036736829206347466
Loss at iteration 1010 : 0.0009129809914156795
Loss at iteration 1020 : 0.00814773142337799
Loss at iteration 1030 : 0.0003772493510041386
Loss at iteration 1040 : 0.0011500079417601228
Loss at iteration 1050 : 0.00040013930993154645
Loss at iteration 1060 : 0.000232371297897771
Loss at iteration 1070 : 0.00023160167620517313
Loss at iteration 1080 : 0.00022044783690944314
Loss at iteration 1090 : 0.00021530466619879007
Loss at iteration 1100 : 4.117049684282392e-05
Loss at iteration 1110 : 0.00010084722453029826
Loss at iteration 1120 : 0.00013637696974910796
Loss at iteration 1130 : 0.00018049866775982082
Loss at iteration 1140 : 0.0003060796589124948
Loss at iteration 1150 : 0.0006984426290728152
Loss at iteration 1160 : 5.401017551776022e-05
Loss at iteration 1170 : 0.00032079164520837367
Loss at iteration 1180 : 0.004286327864974737
Loss at iteration 1190 : 0.0006478280993178487
Loss at iteration 1200 : 0.00201622536405921
Loss at iteration 1210 : 0.003144063986837864
Loss at iteration 1220 : 0.00013389828382059932
Loss at iteration 1230 : 0.0006787455640733242
Loss at iteration 1240 : 0.00032100258977152407
Loss at iteration 1250 : 0.0004188584862276912
Loss at iteration 1260 : 0.000522006070241332
Loss at iteration 1270 : 0.0015023794258013368
Loss at iteration 1280 : 7.157113577704877e-05
Loss at iteration 1290 : 0.0011157665867358446
Loss at iteration 1300 : 0.004421146586537361
Loss at iteration 1310 : 0.00020248102373443544
Loss at iteration 1320 : 0.000122606594231911
Loss at iteration 1330 : 0.00018220909987576306
Loss at iteration 1340 : 0.0010874945437535644
Loss at iteration 1350 : 0.00023810628044884652
Loss at iteration 1360 : 0.00021194240252953023
Loss at iteration 1370 : 0.002468652557581663
Loss at iteration 1380 : 0.0023540628608316183
Loss at iteration 1390 : 0.00010201529948972166
Loss at iteration 1400 : 9.553539712214842e-05
Loss at iteration 1410 : 0.00039961247239261866
Loss at iteration 1420 : 0.00024003922590054572
Loss at iteration 1430 : 0.000210869824513793
Loss at iteration 1440 : 0.00022020115284249187
Loss at iteration 1450 : 0.0005456905346363783
Loss at iteration 1460 : 0.003934415988624096
Loss at iteration 1470 : 0.0007891959976404905
Loss at iteration 1480 : 0.005175594240427017
Loss at iteration 1490 : 8.701105252839625e-05
Loss at iteration 1500 : 0.000168579543242231
Loss at iteration 1510 : 0.004378693178296089
Loss at iteration 1520 : 4.5958819100633264e-05
Loss at iteration 1530 : 0.0001620710827410221
Loss at iteration 1540 : 0.004799654707312584
Loss at iteration 1550 : 0.00017250681412406266
Loss at iteration 1560 : 0.00017594429664313793
Loss at iteration 1570 : 0.001094506005756557
Loss at iteration 1580 : 0.0030612745322287083
Loss at iteration 1590 : 9.193396545015275e-05
Loss at iteration 1600 : 0.00016090180724859238
Loss at iteration 1610 : 6.550236867042258e-05
Loss at iteration 1620 : 0.00015177650493569672
Loss at iteration 1630 : 0.00011691453983075917
Loss at iteration 1640 : 0.0008378017810173333
Loss at iteration 1650 : 0.00012995216820854694
Loss at iteration 1660 : 0.00022116024047136307
Loss at iteration 1670 : 0.0009465687326155603
Loss at iteration 1680 : 0.00018871328211389482
Loss at iteration 1690 : 0.00033208957756869495
Loss at iteration 1700 : 0.00013807942741550505
Loss at iteration 1710 : 0.00010423653293401003
Loss at iteration 1720 : 0.0010928531410172582
Loss at iteration 1730 : 0.00012583310308400542
Loss at iteration 1740 : 0.0007427178206853569
Loss at iteration 1750 : 0.005307375453412533
The SSIM Value is: 0.9775701056230436
The PSNR Value is: 45.69494470730752
the epoch is: 15
Loss at iteration 10 : 0.0019861129112541676
Loss at iteration 20 : 0.0005802083760499954
Loss at iteration 30 : 0.0005747720133513212
Loss at iteration 40 : 0.00024412573839072138
Loss at iteration 50 : 0.000764362164773047
Loss at iteration 60 : 0.00025809466023929417
Loss at iteration 70 : 0.0001118458021664992
Loss at iteration 80 : 0.0007919608615338802
Loss at iteration 90 : 0.0002470140461809933
Loss at iteration 100 : 0.00010066272807307541
Loss at iteration 110 : 0.0009058918221853673
Loss at iteration 120 : 0.00017690360255073756
Loss at iteration 130 : 0.0011974950321018696
Loss at iteration 140 : 0.003598131239414215
Loss at iteration 150 : 0.0005383538664318621
Loss at iteration 160 : 4.699178316514008e-05
Loss at iteration 170 : 0.0010727057233452797
Loss at iteration 180 : 0.002016378566622734
Loss at iteration 190 : 0.00024080251751001924
Loss at iteration 200 : 0.00022311379143502563
Loss at iteration 210 : 9.74323702394031e-05
Loss at iteration 220 : 0.0009233402088284492
Loss at iteration 230 : 0.0017184645403176546
Loss at iteration 240 : 0.00016531064466107637
Loss at iteration 250 : 0.00019486239762045443
Loss at iteration 260 : 5.475378202390857e-05
Loss at iteration 270 : 0.001474619610235095
Loss at iteration 280 : 0.004418851342052221
Loss at iteration 290 : 0.00017577264225110412
Loss at iteration 300 : 0.0010063786758109927
Loss at iteration 310 : 0.00024625155492685735
Loss at iteration 320 : 0.0005781893851235509
Loss at iteration 330 : 0.0004715625545941293
Loss at iteration 340 : 0.00028195398044772446
Loss at iteration 350 : 0.0001900272472994402
Loss at iteration 360 : 0.00018393788195680827
Loss at iteration 370 : 0.002991381799802184
Loss at iteration 380 : 0.009531618095934391
Loss at iteration 390 : 0.0004815476422663778
Loss at iteration 400 : 0.0004497012705542147
Loss at iteration 410 : 5.356990732252598e-05
Loss at iteration 420 : 7.166415161918849e-05
Loss at iteration 430 : 0.00011264999920967966
Loss at iteration 440 : 0.00025593588361516595
Loss at iteration 450 : 0.0009122273186221719
Loss at iteration 460 : 0.0022211242467164993
Loss at iteration 470 : 0.00037244096165522933
Loss at iteration 480 : 0.0014308835379779339
Loss at iteration 490 : 0.0011440220987424254
Loss at iteration 500 : 0.0011906871804967523
Loss at iteration 510 : 0.00017454811313655227
Loss at iteration 520 : 0.0005336340982466936
Loss at iteration 530 : 0.0004098997451364994
Loss at iteration 540 : 0.0022566779516637325
Loss at iteration 550 : 0.0005028617451898754
Loss at iteration 560 : 9.318080265074968e-05
Loss at iteration 570 : 0.0004502496449276805
Loss at iteration 580 : 0.0015958475414663553
Loss at iteration 590 : 0.000987860606983304
Loss at iteration 600 : 0.00016951069119386375
Loss at iteration 610 : 0.0038882128428667784
Loss at iteration 620 : 0.0005101817077957094
Loss at iteration 630 : 0.0034638666547834873
Loss at iteration 640 : 0.00010802577889990062
Loss at iteration 650 : 0.0003227998677175492
Loss at iteration 660 : 0.001956108957529068
Loss at iteration 670 : 0.0022031101398169994
Loss at iteration 680 : 0.0001666194584686309
Loss at iteration 690 : 0.004552708938717842
Loss at iteration 700 : 0.00027930433861911297
Loss at iteration 710 : 0.004293990321457386
Loss at iteration 720 : 0.0004137565556447953
Loss at iteration 730 : 0.00011201990855624899
Loss at iteration 740 : 0.00031680340180173516
Loss at iteration 750 : 0.000464532378828153
Loss at iteration 760 : 0.00016495057207066566
Loss at iteration 770 : 0.0009657279588282108
Loss at iteration 780 : 9.016071999212727e-05
Loss at iteration 790 : 0.0032964262645691633
Loss at iteration 800 : 0.00034161278745159507
Loss at iteration 810 : 0.0001237982651218772
Loss at iteration 820 : 0.00015014977543614805
Loss at iteration 830 : 7.13867848389782e-05
Loss at iteration 840 : 0.00010645507427398115
Loss at iteration 850 : 0.0002659406454768032
Loss at iteration 860 : 0.0011372942244634032
Loss at iteration 870 : 0.0009440438007004559
Loss at iteration 880 : 0.0004086834378540516
Loss at iteration 890 : 0.00048268423415720463
Loss at iteration 900 : 0.000340731639880687
Loss at iteration 910 : 0.00022855002316646278
Loss at iteration 920 : 0.00019883448840118945
Loss at iteration 930 : 0.00012158206664025784
Loss at iteration 940 : 0.004758715629577637
Loss at iteration 950 : 0.0004292441881261766
Loss at iteration 960 : 0.0004942534142173827
Loss at iteration 970 : 0.000423240679083392
Loss at iteration 980 : 0.0013552717864513397
Loss at iteration 990 : 0.0031529641710221767
Loss at iteration 1000 : 0.00032320863101631403
Loss at iteration 1010 : 0.006223245989531279
Loss at iteration 1020 : 0.0047296807169914246
Loss at iteration 1030 : 5.1078466640319675e-05
Loss at iteration 1040 : 0.0015299570513889194
Loss at iteration 1050 : 0.002089808462187648
Loss at iteration 1060 : 0.00040604366222396493
Loss at iteration 1070 : 0.0011304424842819571
Loss at iteration 1080 : 0.0005923939170315862
Loss at iteration 1090 : 0.003228019690141082
Loss at iteration 1100 : 0.0007349677616730332
Loss at iteration 1110 : 0.0014139857375994325
Loss at iteration 1120 : 0.0019235311774536967
Loss at iteration 1130 : 5.4493288189405575e-05
Loss at iteration 1140 : 0.00019116817566100508
Loss at iteration 1150 : 0.0002636851277202368
Loss at iteration 1160 : 0.0001417836465407163
Loss at iteration 1170 : 0.0001618813257664442
Loss at iteration 1180 : 0.000392816960811615
Loss at iteration 1190 : 0.0008881629328243434
Loss at iteration 1200 : 0.0002266945957671851
Loss at iteration 1210 : 0.00019766032346524298
Loss at iteration 1220 : 0.0021406440064311028
Loss at iteration 1230 : 0.00014372062287293375
Loss at iteration 1240 : 0.00014652586833108217
Loss at iteration 1250 : 0.0002286161034135148
Loss at iteration 1260 : 0.0030555773992091417
Loss at iteration 1270 : 0.0001430347765563056
Loss at iteration 1280 : 0.0006736714858561754
Loss at iteration 1290 : 0.0016176558565348387
Loss at iteration 1300 : 0.0024033780209720135
Loss at iteration 1310 : 0.004017475992441177
Loss at iteration 1320 : 0.002996644005179405
Loss at iteration 1330 : 0.000554099096916616
Loss at iteration 1340 : 0.0005346685647964478
Loss at iteration 1350 : 0.0003005386970471591
Loss at iteration 1360 : 0.0001995569036807865
Loss at iteration 1370 : 0.001114324084483087
Loss at iteration 1380 : 0.0010150789748877287
Loss at iteration 1390 : 0.0010220152325928211
Loss at iteration 1400 : 0.002469085855409503
Loss at iteration 1410 : 0.0004080772050656378
Loss at iteration 1420 : 0.001674407278187573
Loss at iteration 1430 : 0.00016533686721231788
Loss at iteration 1440 : 9.367668826598674e-05
Loss at iteration 1450 : 0.0014640034642070532
Loss at iteration 1460 : 0.0010833530686795712
Loss at iteration 1470 : 0.0002741970820352435
Loss at iteration 1480 : 0.00027007487369701266
Loss at iteration 1490 : 0.0006855243118479848
Loss at iteration 1500 : 0.0007300895522348583
Loss at iteration 1510 : 0.00013287996989674866
Loss at iteration 1520 : 0.0024474801030009985
Loss at iteration 1530 : 0.00011223628098377958
Loss at iteration 1540 : 0.0013611544854938984
Loss at iteration 1550 : 0.0007872459245845675
Loss at iteration 1560 : 0.0001427115930709988
Loss at iteration 1570 : 0.00017037047655321658
Loss at iteration 1580 : 0.0011547768954187632
Loss at iteration 1590 : 0.00014734448632225394
Loss at iteration 1600 : 0.0007387456716969609
Loss at iteration 1610 : 0.004774344619363546
Loss at iteration 1620 : 0.000306802277918905
Loss at iteration 1630 : 0.00047147669829428196
Loss at iteration 1640 : 0.000880094594322145
Loss at iteration 1650 : 0.00018962076865136623
Loss at iteration 1660 : 0.004237036220729351
Loss at iteration 1670 : 0.0001188586320495233
Loss at iteration 1680 : 0.004144147504121065
Loss at iteration 1690 : 6.421869329642504e-05
Loss at iteration 1700 : 5.88674665777944e-05
Loss at iteration 1710 : 0.001357300323434174
Loss at iteration 1720 : 0.0002677641750779003
Loss at iteration 1730 : 0.0003573549911379814
Loss at iteration 1740 : 0.0008917218074202538
Loss at iteration 1750 : 0.0001328424841631204
The SSIM Value is: 0.986158283534029
The PSNR Value is: 46.382984047944326
the highest SSIM value is: 46.382984047944326
the epoch is: 16
Loss at iteration 10 : 0.0001872237044153735
Loss at iteration 20 : 0.00022108401753939688
Loss at iteration 30 : 0.0015236116014420986
Loss at iteration 40 : 0.000403606187319383
Loss at iteration 50 : 0.0013893734430894256
Loss at iteration 60 : 0.0011804713867604733
Loss at iteration 70 : 0.00030378537485376
Loss at iteration 80 : 0.0001972732279682532
Loss at iteration 90 : 0.00017319658945780247
Loss at iteration 100 : 0.0016101179644465446
Loss at iteration 110 : 0.00021110297529958189
Loss at iteration 120 : 0.0003932375693693757
Loss at iteration 130 : 0.00020516396034508944
Loss at iteration 140 : 0.003472109790891409
Loss at iteration 150 : 0.001046644290909171
Loss at iteration 160 : 0.009197648614645004
Loss at iteration 170 : 0.0001713822566671297
Loss at iteration 180 : 0.003321416210383177
Loss at iteration 190 : 0.00023352645803242922
Loss at iteration 200 : 0.00010026640666183084
Loss at iteration 210 : 0.0025651822797954082
Loss at iteration 220 : 0.00013691087951883674
Loss at iteration 230 : 0.0005831041489727795
Loss at iteration 240 : 0.0011730147525668144
Loss at iteration 250 : 0.0022758315317332745
Loss at iteration 260 : 0.00012684892863035202
Loss at iteration 270 : 0.0001752847747411579
Loss at iteration 280 : 0.00033173986594192684
Loss at iteration 290 : 0.0001806657965062186
Loss at iteration 300 : 0.003782610408961773
Loss at iteration 310 : 0.002849884331226349
Loss at iteration 320 : 0.004111065529286861
Loss at iteration 330 : 0.0005367186386138201
Loss at iteration 340 : 0.0015919182915240526
Loss at iteration 350 : 0.00020745805522892624
Loss at iteration 360 : 0.0006333331693895161
Loss at iteration 370 : 0.00011801055370597169
Loss at iteration 380 : 0.00016797089483588934
Loss at iteration 390 : 0.0009657273767516017
Loss at iteration 400 : 0.0002902682754211128
Loss at iteration 410 : 0.0023209641221910715
Loss at iteration 420 : 0.00023773028806317598
Loss at iteration 430 : 0.0028165574185550213
Loss at iteration 440 : 0.0029999837279319763
Loss at iteration 450 : 0.00013674533693119884
Loss at iteration 460 : 0.00026604713639244437
Loss at iteration 470 : 8.27225812827237e-05
Loss at iteration 480 : 0.0006825306918472052
Loss at iteration 490 : 0.00042331559234298766
Loss at iteration 500 : 0.0009468356147408485
Loss at iteration 510 : 7.965347322169691e-05
Loss at iteration 520 : 0.00022385743795894086
Loss at iteration 530 : 0.000141224343678914
Loss at iteration 540 : 0.00017663274775259197
Loss at iteration 550 : 0.00040570023702457547
Loss at iteration 560 : 0.0003206596593372524
Loss at iteration 570 : 7.826175715308636e-05
Loss at iteration 580 : 0.00026310529210604727
Loss at iteration 590 : 0.004417316056787968
Loss at iteration 600 : 0.0007551150629296899
Loss at iteration 610 : 0.0004316676058806479
Loss at iteration 620 : 0.002355164149776101
Loss at iteration 630 : 0.0009939903393387794
Loss at iteration 640 : 0.00019914351287297904
Loss at iteration 650 : 0.00015593451098538935
Loss at iteration 660 : 8.461072866339236e-05
Loss at iteration 670 : 0.00040406727930530906
Loss at iteration 680 : 0.003929613158106804
Loss at iteration 690 : 0.00281089567579329
Loss at iteration 700 : 8.201781747629866e-05
Loss at iteration 710 : 0.0009181298082694411
Loss at iteration 720 : 0.00031423717155121267
Loss at iteration 730 : 0.007589046843349934
Loss at iteration 740 : 0.0030256127938628197
Loss at iteration 750 : 0.004024877678602934
Loss at iteration 760 : 0.00023405971296597272
Loss at iteration 770 : 0.0006998273311182857
Loss at iteration 780 : 0.00015782688569743186
Loss at iteration 790 : 0.0001104047114495188
Loss at iteration 800 : 0.0006171008571982384
Loss at iteration 810 : 0.004604638088494539
Loss at iteration 820 : 0.004150416702032089
Loss at iteration 830 : 0.00043991405982524157
Loss at iteration 840 : 0.000627930392511189
Loss at iteration 850 : 0.0001656097883824259
Loss at iteration 860 : 0.0035026019904762506
Loss at iteration 870 : 0.0006835664971731603
Loss at iteration 880 : 0.005797103513032198
Loss at iteration 890 : 0.0019467002712190151
Loss at iteration 900 : 0.000537417596206069
Loss at iteration 910 : 0.0002993335947394371
Loss at iteration 920 : 0.0035678893327713013
Loss at iteration 930 : 0.00023706094361841679
Loss at iteration 940 : 0.0060479408130049706
Loss at iteration 950 : 0.0007231947965919971
Loss at iteration 960 : 0.00015197652101051062
Loss at iteration 970 : 0.00029060622910037637
Loss at iteration 980 : 0.010984532535076141
Loss at iteration 990 : 0.00018799465033225715
Loss at iteration 1000 : 0.000222501577809453
Loss at iteration 1010 : 0.00022604492551181465
Loss at iteration 1020 : 0.004021362867206335
Loss at iteration 1030 : 0.00020483830303419381
Loss at iteration 1040 : 0.003922703675925732
Loss at iteration 1050 : 0.00017892445612233132
Loss at iteration 1060 : 0.0004208108293823898
Loss at iteration 1070 : 7.706910400884226e-05
Loss at iteration 1080 : 0.003507602261379361
Loss at iteration 1090 : 0.00031242729164659977
Loss at iteration 1100 : 0.0026293527334928513
Loss at iteration 1110 : 0.004308820702135563
Loss at iteration 1120 : 0.0002214220876339823
Loss at iteration 1130 : 0.00019024463836103678
Loss at iteration 1140 : 0.0002870223543141037
Loss at iteration 1150 : 0.0003388437326066196
Loss at iteration 1160 : 0.00012806820450350642
Loss at iteration 1170 : 0.0005861245444975793
Loss at iteration 1180 : 0.0002272014389745891
Loss at iteration 1190 : 0.0003368771285749972
Loss at iteration 1200 : 0.0012354743666946888
Loss at iteration 1210 : 0.0033453903160989285
Loss at iteration 1220 : 0.0004070327850058675
Loss at iteration 1230 : 0.0003906197380274534
Loss at iteration 1240 : 0.0008008818258531392
Loss at iteration 1250 : 0.0002617235586512834
Loss at iteration 1260 : 0.0028698896057903767
Loss at iteration 1270 : 0.0008820068323984742
Loss at iteration 1280 : 0.001938263769261539
Loss at iteration 1290 : 0.000379497796529904
Loss at iteration 1300 : 0.0024429303593933582
Loss at iteration 1310 : 0.0017130307387560606
Loss at iteration 1320 : 0.0022584532853215933
Loss at iteration 1330 : 0.0002137242117896676
Loss at iteration 1340 : 0.0005262540653347969
Loss at iteration 1350 : 0.0023175813257694244
Loss at iteration 1360 : 0.0005423293332569301
Loss at iteration 1370 : 0.0001769544032867998
Loss at iteration 1380 : 0.00430565420538187
Loss at iteration 1390 : 0.006406418979167938
Loss at iteration 1400 : 0.0012439289130270481
Loss at iteration 1410 : 0.0006261889939196408
Loss at iteration 1420 : 0.003271268680691719
Loss at iteration 1430 : 7.519892096752301e-05
Loss at iteration 1440 : 0.0015953604597598314
Loss at iteration 1450 : 0.000205331074539572
Loss at iteration 1460 : 0.00018622780044097453
Loss at iteration 1470 : 0.0021823798306286335
Loss at iteration 1480 : 0.0003324691788293421
Loss at iteration 1490 : 0.003025270998477936
Loss at iteration 1500 : 8.460359822493047e-05
Loss at iteration 1510 : 0.0033231398556381464
Loss at iteration 1520 : 0.00014088433817960322
Loss at iteration 1530 : 0.004044380038976669
Loss at iteration 1540 : 0.0009775469079613686
Loss at iteration 1550 : 0.000182153977220878
Loss at iteration 1560 : 0.002343124942854047
Loss at iteration 1570 : 0.00021146307699382305
Loss at iteration 1580 : 0.0014679376035928726
Loss at iteration 1590 : 0.00044091150630265474
Loss at iteration 1600 : 0.00017877948994282633
Loss at iteration 1610 : 8.19906999822706e-05
Loss at iteration 1620 : 0.0031313940417021513
Loss at iteration 1630 : 0.0017806427786126733
Loss at iteration 1640 : 0.0002865490969270468
Loss at iteration 1650 : 0.00014625796757172793
Loss at iteration 1660 : 0.0001112638128688559
Loss at iteration 1670 : 0.00021182687487453222
Loss at iteration 1680 : 0.0007799058803357184
Loss at iteration 1690 : 0.006072337739169598
Loss at iteration 1700 : 0.00014692169497720897
Loss at iteration 1710 : 0.000695908791385591
Loss at iteration 1720 : 0.0001689468917902559
Loss at iteration 1730 : 0.0019006666261702776
Loss at iteration 1740 : 0.0023138211108744144
Loss at iteration 1750 : 0.004222789779305458
The SSIM Value is: 0.9787336808469327
The PSNR Value is: 45.88166797528708
the epoch is: 17
Loss at iteration 10 : 0.0002192998945247382
Loss at iteration 20 : 0.002631743671372533
Loss at iteration 30 : 0.000857221195474267
Loss at iteration 40 : 0.0017486711731180549
Loss at iteration 50 : 7.976961205713451e-05
Loss at iteration 60 : 0.007941745221614838
Loss at iteration 70 : 0.0018986794166266918
Loss at iteration 80 : 0.0005198244471102953
Loss at iteration 90 : 0.001226439606398344
Loss at iteration 100 : 0.00015175847511272877
Loss at iteration 110 : 0.0007736978586763144
Loss at iteration 120 : 0.00015480075671803206
Loss at iteration 130 : 0.00041362669435329735
Loss at iteration 140 : 0.0008537773974239826
Loss at iteration 150 : 0.0001292972156079486
Loss at iteration 160 : 0.00016167786088772118
Loss at iteration 170 : 0.0034475852735340595
Loss at iteration 180 : 0.0011536782840266824
Loss at iteration 190 : 0.00015745415294077247
Loss at iteration 200 : 0.00022844628256279975
Loss at iteration 210 : 0.004112602677196264
Loss at iteration 220 : 0.0002851086319424212
Loss at iteration 230 : 0.0005386626580730081
Loss at iteration 240 : 0.0007686825701966882
Loss at iteration 250 : 0.00021014915546402335
Loss at iteration 260 : 0.0003925844212062657
Loss at iteration 270 : 0.0011649222578853369
Loss at iteration 280 : 0.0008064029389061034
Loss at iteration 290 : 0.0001474169985158369
Loss at iteration 300 : 0.00015562483167741448
Loss at iteration 310 : 0.00034951046109199524
Loss at iteration 320 : 0.0002293959551025182
Loss at iteration 330 : 0.0004115658812224865
Loss at iteration 340 : 0.0021233102306723595
Loss at iteration 350 : 0.0021733189933001995
Loss at iteration 360 : 0.0002544326998759061
Loss at iteration 370 : 0.0016916097374632955
Loss at iteration 380 : 0.0003322451957501471
Loss at iteration 390 : 0.0002360418438911438
Loss at iteration 400 : 0.00018369927420280874
Loss at iteration 410 : 0.0034019118174910545
Loss at iteration 420 : 0.0019177929498255253
Loss at iteration 430 : 0.0015701495576649904
Loss at iteration 440 : 0.0032087548170238733
Loss at iteration 450 : 0.001622906536795199
Loss at iteration 460 : 0.00011759121116483584
Loss at iteration 470 : 0.0012325120624154806
Loss at iteration 480 : 9.4807350251358e-05
Loss at iteration 490 : 0.00023457483621314168
Loss at iteration 500 : 0.004054269753396511
Loss at iteration 510 : 0.002050320152193308
Loss at iteration 520 : 8.102475840132684e-05
Loss at iteration 530 : 0.0001377659646095708
Loss at iteration 540 : 0.0056453244760632515
Loss at iteration 550 : 7.431931589962915e-05
Loss at iteration 560 : 0.00013137464702595025
Loss at iteration 570 : 8.447574509773403e-05
Loss at iteration 580 : 0.005322573706507683
Loss at iteration 590 : 0.0003260800731368363
Loss at iteration 600 : 7.57882371544838e-05
Loss at iteration 610 : 0.0006696009659208357
Loss at iteration 620 : 0.00022538656776305288
Loss at iteration 630 : 0.0012989218812435865
Loss at iteration 640 : 0.0009025585022754967
Loss at iteration 650 : 0.0008843433461152017
Loss at iteration 660 : 0.007839448750019073
Loss at iteration 670 : 7.94186198618263e-05
Loss at iteration 680 : 0.0003051019157283008
Loss at iteration 690 : 8.836753841023892e-05
Loss at iteration 700 : 0.0013836994767189026
Loss at iteration 710 : 0.0015606018714606762
Loss at iteration 720 : 9.999528265325353e-05
Loss at iteration 730 : 0.005117989610880613
Loss at iteration 740 : 0.0024681880604475737
Loss at iteration 750 : 0.001184395863674581
Loss at iteration 760 : 0.00023047914146445692
Loss at iteration 770 : 0.0010758588323369622
Loss at iteration 780 : 0.0006546092336066067
Loss at iteration 790 : 0.0016402273904532194
Loss at iteration 800 : 0.0002588699571788311
Loss at iteration 810 : 6.073663826100528e-05
Loss at iteration 820 : 0.000249603675911203
Loss at iteration 830 : 0.00020871216838713735
Loss at iteration 840 : 0.00025663571432232857
Loss at iteration 850 : 0.0003088079974986613
Loss at iteration 860 : 0.00024530309019610286
Loss at iteration 870 : 0.0014185607433319092
Loss at iteration 880 : 0.0003007710329256952
Loss at iteration 890 : 0.0003312960034236312
Loss at iteration 900 : 0.0009165568044409156
Loss at iteration 910 : 0.00138141680508852
Loss at iteration 920 : 0.000166249941685237
Loss at iteration 930 : 0.0010380590101704001
Loss at iteration 940 : 9.184470400214195e-05
Loss at iteration 950 : 0.0028963976074010134
Loss at iteration 960 : 0.00014656491111963987
Loss at iteration 970 : 0.0022860546596348286
Loss at iteration 980 : 0.0002979038981720805
Loss at iteration 990 : 0.0001811036781873554
Loss at iteration 1000 : 0.0002338967751711607
Loss at iteration 1010 : 0.0018343664705753326
Loss at iteration 1020 : 0.002193074906244874
Loss at iteration 1030 : 0.0005502170533873141
Loss at iteration 1040 : 0.00020175027020741254
Loss at iteration 1050 : 0.00012921761663164943
Loss at iteration 1060 : 0.0030004349537193775
Loss at iteration 1070 : 0.0009036550181917846
Loss at iteration 1080 : 0.0001307157363044098
Loss at iteration 1090 : 8.776970935286954e-05
Loss at iteration 1100 : 0.00011193621321581304
Loss at iteration 1110 : 0.005620350129902363
Loss at iteration 1120 : 0.00015041754522826523
Loss at iteration 1130 : 0.0013009347021579742
Loss at iteration 1140 : 0.0008472427725791931
Loss at iteration 1150 : 0.0001069382851710543
Loss at iteration 1160 : 0.00044628666364587843
Loss at iteration 1170 : 0.0008044883143156767
Loss at iteration 1180 : 0.000416032038629055
Loss at iteration 1190 : 0.0018503665924072266
Loss at iteration 1200 : 5.7946286688093096e-05
Loss at iteration 1210 : 0.0029444198589771986
Loss at iteration 1220 : 0.003588309744372964
Loss at iteration 1230 : 0.00022718602849636227
Loss at iteration 1240 : 0.0017110916087403893
Loss at iteration 1250 : 0.0032476605847477913
Loss at iteration 1260 : 0.0011169842910021544
Loss at iteration 1270 : 0.00021896403632126749
Loss at iteration 1280 : 9.144989599008113e-05
Loss at iteration 1290 : 0.0032735734712332487
Loss at iteration 1300 : 0.00025960139464586973
Loss at iteration 1310 : 0.0007897904142737389
Loss at iteration 1320 : 0.0026919262018054724
Loss at iteration 1330 : 0.004418055061250925
Loss at iteration 1340 : 0.005472206976264715
Loss at iteration 1350 : 0.0014961590059101582
Loss at iteration 1360 : 0.00013935116294305772
Loss at iteration 1370 : 0.005129248835146427
Loss at iteration 1380 : 0.00042742316145449877
Loss at iteration 1390 : 0.0020189164206385612
Loss at iteration 1400 : 0.0002887430018745363
Loss at iteration 1410 : 0.0009570434922352433
Loss at iteration 1420 : 0.00043397361878305674
Loss at iteration 1430 : 0.0005473769269883633
Loss at iteration 1440 : 0.0009140081820078194
Loss at iteration 1450 : 0.001785185420885682
Loss at iteration 1460 : 0.00013907764514442533
Loss at iteration 1470 : 0.00224342942237854
Loss at iteration 1480 : 0.00041938372305594385
Loss at iteration 1490 : 0.00013686732563655823
Loss at iteration 1500 : 0.000371379719581455
Loss at iteration 1510 : 0.0006576126907020807
Loss at iteration 1520 : 0.0023884717375040054
Loss at iteration 1530 : 0.0007734899409115314
Loss at iteration 1540 : 0.001085874275304377
Loss at iteration 1550 : 0.0003657696070149541
Loss at iteration 1560 : 0.00020041620882693678
Loss at iteration 1570 : 0.0018270472064614296
Loss at iteration 1580 : 0.0023850928992033005
Loss at iteration 1590 : 0.00029447159613482654
Loss at iteration 1600 : 0.0006808124016970396
Loss at iteration 1610 : 5.1018734666286036e-05
Loss at iteration 1620 : 0.000981600140221417
Loss at iteration 1630 : 0.002009207848459482
Loss at iteration 1640 : 0.004404209554195404
Loss at iteration 1650 : 0.0003057524445466697
Loss at iteration 1660 : 9.419496200280264e-05
Loss at iteration 1670 : 8.095813973341137e-05
Loss at iteration 1680 : 0.0022461048793047667
Loss at iteration 1690 : 0.003045080229640007
Loss at iteration 1700 : 0.0021888623014092445
Loss at iteration 1710 : 6.347808812279254e-05
Loss at iteration 1720 : 0.002808208577334881
Loss at iteration 1730 : 0.005927573889493942
Loss at iteration 1740 : 0.0003335288492962718
Loss at iteration 1750 : 0.0038820188492536545
The SSIM Value is: 0.9767376385333779
The PSNR Value is: 45.59449115618735
the epoch is: 18
Loss at iteration 10 : 0.001676979474723339
Loss at iteration 20 : 4.2184274207102135e-05
Loss at iteration 30 : 8.879067900124937e-05
Loss at iteration 40 : 0.0005013606860302389
Loss at iteration 50 : 0.00039285721140913665
Loss at iteration 60 : 0.0006755754584446549
Loss at iteration 70 : 0.0030671183485537767
Loss at iteration 80 : 0.003897195914760232
Loss at iteration 90 : 0.004931386094540358
Loss at iteration 100 : 0.0004025979433208704
Loss at iteration 110 : 0.0007611123146489263
Loss at iteration 120 : 0.00020842936646658927
Loss at iteration 130 : 0.00010411282710265368
Loss at iteration 140 : 5.457207589643076e-05
Loss at iteration 150 : 0.0053830621764063835
Loss at iteration 160 : 0.0005138472770340741
Loss at iteration 170 : 0.0002517281682230532
Loss at iteration 180 : 0.0010001601185649633
Loss at iteration 190 : 0.000108043008367531
Loss at iteration 200 : 8.48952477099374e-05
Loss at iteration 210 : 0.00020304156350903213
Loss at iteration 220 : 0.0016455042641609907
Loss at iteration 230 : 0.0005464720306918025
Loss at iteration 240 : 0.00016721345309633762
Loss at iteration 250 : 0.00017494767962489277
Loss at iteration 260 : 0.00012131868425058201
Loss at iteration 270 : 0.00017462765390519053
Loss at iteration 280 : 0.0007576295174658298
Loss at iteration 290 : 0.00013756356202065945
Loss at iteration 300 : 0.00021356655634008348
Loss at iteration 310 : 0.00041006336687132716
Loss at iteration 320 : 0.003912928979843855
Loss at iteration 330 : 0.0005940654082223773
Loss at iteration 340 : 0.003199084894731641
Loss at iteration 350 : 0.0003251470916438848
Loss at iteration 360 : 0.0009817194659262896
Loss at iteration 370 : 0.0044286008924245834
Loss at iteration 380 : 0.0004643909342121333
Loss at iteration 390 : 0.00044067460112273693
Loss at iteration 400 : 0.0003506780485622585
Loss at iteration 410 : 0.00040643487591296434
Loss at iteration 420 : 0.002126833889633417
Loss at iteration 430 : 0.00010646185546647757
Loss at iteration 440 : 0.00010565013508312404
Loss at iteration 450 : 0.003040770534425974
Loss at iteration 460 : 0.00017314545402769
Loss at iteration 470 : 0.0022329306229948997
Loss at iteration 480 : 0.0030515380203723907
Loss at iteration 490 : 0.00301370513625443
Loss at iteration 500 : 0.00033392844488844275
Loss at iteration 510 : 0.00013457551540341228
Loss at iteration 520 : 0.00015899990103207529
Loss at iteration 530 : 0.00027076801052317023
Loss at iteration 540 : 0.0002660190802998841
Loss at iteration 550 : 0.00011365424143150449
Loss at iteration 560 : 0.000671513844281435
Loss at iteration 570 : 0.0017151732463389635
Loss at iteration 580 : 0.00038092496106401086
Loss at iteration 590 : 0.000991016742773354
Loss at iteration 600 : 0.002607278060168028
Loss at iteration 610 : 0.0006227280246093869
Loss at iteration 620 : 0.0002954880765173584
Loss at iteration 630 : 0.0006793752545490861
Loss at iteration 640 : 0.0001953129394678399
Loss at iteration 650 : 0.00010780561569845304
Loss at iteration 660 : 6.298546941252425e-05
Loss at iteration 670 : 0.009005207568407059
Loss at iteration 680 : 0.00014535817899741232
Loss at iteration 690 : 0.005467018112540245
Loss at iteration 700 : 0.0002296440943609923
Loss at iteration 710 : 0.005374280735850334
Loss at iteration 720 : 0.0006044007604941726
Loss at iteration 730 : 0.001713637262582779
Loss at iteration 740 : 0.00015360652469098568
Loss at iteration 750 : 0.0015519903972744942
Loss at iteration 760 : 0.003179497318342328
Loss at iteration 770 : 2.4467226467095315e-05
Loss at iteration 780 : 0.0003280403034295887
Loss at iteration 790 : 0.00012952584074810147
Loss at iteration 800 : 0.00045593149843625724
Loss at iteration 810 : 0.0001450222625862807
Loss at iteration 820 : 0.0002568705822341144
Loss at iteration 830 : 0.0006628261180594563
Loss at iteration 840 : 8.680509199621156e-05
Loss at iteration 850 : 0.0002561797446105629
Loss at iteration 860 : 0.0005472187767736614
Loss at iteration 870 : 4.6228386054281145e-05
Loss at iteration 880 : 0.0001598277740413323
Loss at iteration 890 : 0.006802436430007219
Loss at iteration 900 : 0.0010641526896506548
Loss at iteration 910 : 9.051102824741974e-05
Loss at iteration 920 : 0.0008781127398833632
Loss at iteration 930 : 0.0029708039946854115
Loss at iteration 940 : 0.00032643828308209777
Loss at iteration 950 : 0.0018470011418685317
Loss at iteration 960 : 0.0005775726749561727
Loss at iteration 970 : 0.0006336027290672064
Loss at iteration 980 : 0.0003263304242864251
Loss at iteration 990 : 0.00024037185357883573
Loss at iteration 1000 : 0.0002120752033079043
Loss at iteration 1010 : 0.00021521099552046508
Loss at iteration 1020 : 0.0010811917018145323
Loss at iteration 1030 : 0.0026808767579495907
Loss at iteration 1040 : 0.0015688942512497306
Loss at iteration 1050 : 0.00042570714140310884
Loss at iteration 1060 : 0.0002708019455894828
Loss at iteration 1070 : 0.00261297426186502
Loss at iteration 1080 : 0.0026939385570585728
Loss at iteration 1090 : 0.0001335029082838446
Loss at iteration 1100 : 0.0005934152286499739
Loss at iteration 1110 : 0.00023730531393084675
Loss at iteration 1120 : 0.0005218746373429894
Loss at iteration 1130 : 0.002978304401040077
Loss at iteration 1140 : 0.0025490596890449524
Loss at iteration 1150 : 0.0007656076923012733
Loss at iteration 1160 : 0.00010924049274763092
Loss at iteration 1170 : 0.0002813348837662488
Loss at iteration 1180 : 0.00011980409180978313
Loss at iteration 1190 : 0.0004421586636453867
Loss at iteration 1200 : 0.0008686927612870932
Loss at iteration 1210 : 0.00020035116176586598
Loss at iteration 1220 : 0.0003224759129807353
Loss at iteration 1230 : 0.0002688016975298524
Loss at iteration 1240 : 5.9621117543429136e-05
Loss at iteration 1250 : 0.0006476934649981558
Loss at iteration 1260 : 0.0037009113002568483
Loss at iteration 1270 : 0.00045846198918297887
Loss at iteration 1280 : 0.00012992127449251711
Loss at iteration 1290 : 0.00531433941796422
Loss at iteration 1300 : 0.00399797735735774
Loss at iteration 1310 : 0.005101052578538656
Loss at iteration 1320 : 9.146359661826864e-05
Loss at iteration 1330 : 0.0010895805899053812
Loss at iteration 1340 : 0.0002507971948944032
Loss at iteration 1350 : 0.0008568267803639174
Loss at iteration 1360 : 0.004106262698769569
Loss at iteration 1370 : 0.00012886652257293463
Loss at iteration 1380 : 0.000730886880774051
Loss at iteration 1390 : 0.00013875006698071957
Loss at iteration 1400 : 0.006848117336630821
Loss at iteration 1410 : 0.0005200089071877301
Loss at iteration 1420 : 8.013443584786728e-05
Loss at iteration 1430 : 0.0010428584646433592
Loss at iteration 1440 : 0.002503875410184264
Loss at iteration 1450 : 0.0008938980754464865
Loss at iteration 1460 : 0.0005466678994707763
Loss at iteration 1470 : 0.004804548341780901
Loss at iteration 1480 : 0.0035200323909521103
Loss at iteration 1490 : 8.629016519989818e-05
Loss at iteration 1500 : 0.0002087813918478787
Loss at iteration 1510 : 0.004062724765390158
Loss at iteration 1520 : 0.0032341284677386284
Loss at iteration 1530 : 0.0055606793612241745
Loss at iteration 1540 : 0.0028262194246053696
Loss at iteration 1550 : 0.0003543256316334009
Loss at iteration 1560 : 0.0017874647164717317
Loss at iteration 1570 : 0.0008125655585899949
Loss at iteration 1580 : 0.0001331144740106538
Loss at iteration 1590 : 0.00043864542385563254
Loss at iteration 1600 : 0.0004419984470587224
Loss at iteration 1610 : 0.0004809573874808848
Loss at iteration 1620 : 0.00012266990961506963
Loss at iteration 1630 : 0.0003995383158326149
Loss at iteration 1640 : 0.008201109245419502
Loss at iteration 1650 : 0.00013734873209614307
Loss at iteration 1660 : 0.00015317198995035142
Loss at iteration 1670 : 0.0005124285817146301
Loss at iteration 1680 : 0.00018774185446090996
Loss at iteration 1690 : 7.597600779263303e-05
Loss at iteration 1700 : 0.00016351336671505123
Loss at iteration 1710 : 0.001155624515376985
Loss at iteration 1720 : 0.004003147594630718
Loss at iteration 1730 : 0.0012354515492916107
Loss at iteration 1740 : 0.002916406374424696
Loss at iteration 1750 : 0.0003858056152239442
The SSIM Value is: 0.9785189640416972
The PSNR Value is: 45.74797687026373
the epoch is: 19
Loss at iteration 10 : 0.0002590493531897664
Loss at iteration 20 : 0.00048701572814024985
Loss at iteration 30 : 0.0005742317880503833
Loss at iteration 40 : 0.00025216987705789506
Loss at iteration 50 : 0.0010620973771438003
Loss at iteration 60 : 0.0001078634086297825
Loss at iteration 70 : 0.0004264811868779361
Loss at iteration 80 : 0.0024579213932156563
Loss at iteration 90 : 0.00010116897465195507
Loss at iteration 100 : 0.00011326953972456977
Loss at iteration 110 : 5.5286909628193825e-05
Loss at iteration 120 : 7.288105553016067e-05
Loss at iteration 130 : 0.00023089666501618922
Loss at iteration 140 : 0.00012516241986304522
Loss at iteration 150 : 0.0004258007393218577
Loss at iteration 160 : 0.0016809761291369796
Loss at iteration 170 : 0.00012370188778731972
Loss at iteration 180 : 0.0029310439713299274
Loss at iteration 190 : 0.0001882595825009048
Loss at iteration 200 : 0.000146791513543576
Loss at iteration 210 : 0.0001649456680752337
Loss at iteration 220 : 7.17826042091474e-05
Loss at iteration 230 : 0.003731237258762121
Loss at iteration 240 : 0.0012332939077168703
Loss at iteration 250 : 0.0003195579338353127
Loss at iteration 260 : 0.00215520360507071
Loss at iteration 270 : 0.0005857552750967443
Loss at iteration 280 : 0.0003792566421907395
Loss at iteration 290 : 0.000985807040706277
Loss at iteration 300 : 0.002979281358420849
Loss at iteration 310 : 7.114513573469594e-05
Loss at iteration 320 : 0.00045707033132202923
Loss at iteration 330 : 0.00020768912509083748
Loss at iteration 340 : 0.0005858491640537977
Loss at iteration 350 : 0.0001864076912170276
Loss at iteration 360 : 0.00021761536481790245
Loss at iteration 370 : 0.00023488036822527647
Loss at iteration 380 : 0.00029950804309919477
Loss at iteration 390 : 0.006481975317001343
Loss at iteration 400 : 0.0004765856429003179
Loss at iteration 410 : 0.00010156721691600978
Loss at iteration 420 : 0.00011236345017096028
Loss at iteration 430 : 0.0001232098729815334
Loss at iteration 440 : 0.0030138781294226646
Loss at iteration 450 : 0.0002612299285829067
Loss at iteration 460 : 0.0001412773272022605
Loss at iteration 470 : 0.00033443793654441833
Loss at iteration 480 : 0.00018076755804941058
Loss at iteration 490 : 8.358745981240645e-05
Loss at iteration 500 : 0.0005635355482809246
Loss at iteration 510 : 0.00019593205070123076
Loss at iteration 520 : 0.00017872727767098695
Loss at iteration 530 : 0.0002442646655254066
Loss at iteration 540 : 0.0002276430604979396
Loss at iteration 550 : 8.456172508886084e-05
Loss at iteration 560 : 0.003219742327928543
Loss at iteration 570 : 0.00012082910689059645
Loss at iteration 580 : 0.00020004279213026166
Loss at iteration 590 : 0.0006966799264773726
Loss at iteration 600 : 0.005194685887545347
Loss at iteration 610 : 0.005859995726495981
Loss at iteration 620 : 0.003816958051174879
Loss at iteration 630 : 0.0013659996911883354
Loss at iteration 640 : 0.0002717826864682138
Loss at iteration 650 : 0.0037637162022292614
Loss at iteration 660 : 0.00033104734029620886
Loss at iteration 670 : 0.0002548751945141703
Loss at iteration 680 : 0.00047521834494546056
Loss at iteration 690 : 0.0003371459897607565
Loss at iteration 700 : 0.00034477567533031106
Loss at iteration 710 : 0.00025510735576972365
Loss at iteration 720 : 7.641738193342462e-05
Loss at iteration 730 : 0.000635336444247514
Loss at iteration 740 : 0.0001558719959575683
Loss at iteration 750 : 0.0009085093042813241
Loss at iteration 760 : 0.001028767554089427
Loss at iteration 770 : 0.00030307710403576493
Loss at iteration 780 : 0.0005374089814722538
Loss at iteration 790 : 0.0009306063875555992
Loss at iteration 800 : 0.00038369392859749496
Loss at iteration 810 : 0.00043956414447166026
Loss at iteration 820 : 0.00011791224096668884
Loss at iteration 830 : 0.001499476027674973
Loss at iteration 840 : 0.0017495278734713793
Loss at iteration 850 : 9.939297888195142e-05
Loss at iteration 860 : 0.00021716629271395504
Loss at iteration 870 : 0.00013167259749025106
Loss at iteration 880 : 7.145895506255329e-05
Loss at iteration 890 : 7.746451592538506e-05
Loss at iteration 900 : 0.00011283140338491648
Loss at iteration 910 : 0.0004144832491874695
Loss at iteration 920 : 0.0005070656770840287
Loss at iteration 930 : 0.0004880180349573493
Loss at iteration 940 : 0.0038503282703459263
Loss at iteration 950 : 0.003304685465991497
Loss at iteration 960 : 0.0006476730341091752
Loss at iteration 970 : 0.0001285973994527012
Loss at iteration 980 : 0.0003912946558557451
Loss at iteration 990 : 0.000228773700655438
Loss at iteration 1000 : 0.00032070482848212123
Loss at iteration 1010 : 0.0004712378140538931
Loss at iteration 1020 : 0.00028201655368320644
Loss at iteration 1030 : 4.092603558092378e-05
Loss at iteration 1040 : 0.00012434041127562523
Loss at iteration 1050 : 0.0001380980684189126
Loss at iteration 1060 : 0.00037113740108907223
Loss at iteration 1070 : 0.0001881531934486702
Loss at iteration 1080 : 0.0005426256102509797
Loss at iteration 1090 : 0.00041260154102928936
Loss at iteration 1100 : 0.00010657818347681314
Loss at iteration 1110 : 9.17216602829285e-05
Loss at iteration 1120 : 0.0008551049395464361
Loss at iteration 1130 : 0.00016542692901566625
Loss at iteration 1140 : 9.010571375256404e-05
Loss at iteration 1150 : 9.350597247248515e-05
Loss at iteration 1160 : 0.0004056984616909176
Loss at iteration 1170 : 0.00019341373990755528
Loss at iteration 1180 : 0.0010283492738381028
Loss at iteration 1190 : 0.0007787324720993638
Loss at iteration 1200 : 0.00036925560561940074
Loss at iteration 1210 : 0.00029359603649936616
Loss at iteration 1220 : 0.006192097440361977
Loss at iteration 1230 : 0.005737753584980965
Loss at iteration 1240 : 0.0029451954178512096
Loss at iteration 1250 : 0.00017417756316717714
Loss at iteration 1260 : 8.18551707197912e-05
Loss at iteration 1270 : 0.00011217680003028363
Loss at iteration 1280 : 0.00025701988488435745
Loss at iteration 1290 : 0.002891381736844778
Loss at iteration 1300 : 0.0005102288560010493
Loss at iteration 1310 : 0.002238966291770339
Loss at iteration 1320 : 0.00019174507178831846
Loss at iteration 1330 : 0.0008708646055310965
Loss at iteration 1340 : 0.00018737622303888202
Loss at iteration 1350 : 0.0003351971972733736
Loss at iteration 1360 : 0.00019697776588145643
Loss at iteration 1370 : 9.43891063798219e-05
Loss at iteration 1380 : 0.00039361888775601983
Loss at iteration 1390 : 0.0001512226735940203
Loss at iteration 1400 : 0.0007103542448021472
Loss at iteration 1410 : 0.00028958075563423336
Loss at iteration 1420 : 0.00038476180634461343
Loss at iteration 1430 : 0.00016210538160521537
Loss at iteration 1440 : 0.0009573670104146004
Loss at iteration 1450 : 0.0020792996510863304
Loss at iteration 1460 : 0.00020557831157930195
Loss at iteration 1470 : 0.0013806376373395324
Loss at iteration 1480 : 0.00016745441826060414
Loss at iteration 1490 : 0.00039726312388665974
Loss at iteration 1500 : 0.00030507126939482987
Loss at iteration 1510 : 0.00017228836077265441
Loss at iteration 1520 : 0.002560447435826063
Loss at iteration 1530 : 0.00017618716810829937
Loss at iteration 1540 : 0.00023354508448392153
Loss at iteration 1550 : 0.00017666479106992483
Loss at iteration 1560 : 0.00034394822432659566
Loss at iteration 1570 : 0.0002520453999750316
Loss at iteration 1580 : 0.00045135823893360794
Loss at iteration 1590 : 0.00344809889793396
Loss at iteration 1600 : 0.0005927146412432194
Loss at iteration 1610 : 0.0012662597000598907
Loss at iteration 1620 : 0.0037886190693825483
Loss at iteration 1630 : 0.00024196197045966983
Loss at iteration 1640 : 0.005374549422413111
Loss at iteration 1650 : 0.0013080479111522436
Loss at iteration 1660 : 0.00037252838956192136
Loss at iteration 1670 : 0.00012014042295049876
Loss at iteration 1680 : 0.00032741689938120544
Loss at iteration 1690 : 0.0023100150283426046
Loss at iteration 1700 : 0.0009896820411086082
Loss at iteration 1710 : 3.6420558899408206e-05
Loss at iteration 1720 : 0.0014495188370347023
Loss at iteration 1730 : 0.00020862137898802757
Loss at iteration 1740 : 0.00010684568405849859
Loss at iteration 1750 : 0.0003419157292228192
The SSIM Value is: 0.9894382781656829
The PSNR Value is: 45.95293605065031
the epoch is: 20
Loss at iteration 10 : 0.00021768722217530012
Loss at iteration 20 : 0.0010163632687181234
Loss at iteration 30 : 6.333539204206318e-05
Loss at iteration 40 : 0.00026558665558695793
Loss at iteration 50 : 0.0010348474606871605
Loss at iteration 60 : 0.0026531540788710117
Loss at iteration 70 : 0.00032038631616160274
Loss at iteration 80 : 0.00024425802985206246
Loss at iteration 90 : 0.0003723808331415057
Loss at iteration 100 : 0.0032727057114243507
Loss at iteration 110 : 0.00020189584756735712
Loss at iteration 120 : 0.0004453055444173515
Loss at iteration 130 : 0.0004248209879733622
Loss at iteration 140 : 0.0012772348709404469
Loss at iteration 150 : 9.888699423754588e-05
Loss at iteration 160 : 0.0033917927648872137
Loss at iteration 170 : 0.00025641711545176804
Loss at iteration 180 : 0.00037845151382498443
Loss at iteration 190 : 0.00018607756646815687
Loss at iteration 200 : 0.0002939690602943301
Loss at iteration 210 : 0.00014589361671824008
Loss at iteration 220 : 0.0004370080423541367
Loss at iteration 230 : 0.00020291146938689053
Loss at iteration 240 : 0.0003434281679801643
Loss at iteration 250 : 0.0018277807394042611
Loss at iteration 260 : 0.0005278792232275009
Loss at iteration 270 : 0.003355551278218627
Loss at iteration 280 : 0.004249479155987501
Loss at iteration 290 : 0.00031597702763974667
Loss at iteration 300 : 0.003612499451264739
Loss at iteration 310 : 0.0004570547607727349
Loss at iteration 320 : 7.653153443243355e-05
Loss at iteration 330 : 0.0004936900804750621
Loss at iteration 340 : 0.00024368525191675872
Loss at iteration 350 : 0.0031365053728222847
Loss at iteration 360 : 0.0004151843022555113
Loss at iteration 370 : 0.001704318798147142
Loss at iteration 380 : 0.00012207562394905835
Loss at iteration 390 : 0.0016176949720829725
Loss at iteration 400 : 0.0020497122313827276
Loss at iteration 410 : 0.0029349206015467644
Loss at iteration 420 : 0.00030165541102178395
Loss at iteration 430 : 0.004221202805638313
Loss at iteration 440 : 0.002192097483202815
Loss at iteration 450 : 7.146474672481418e-05
Loss at iteration 460 : 0.0024048255290836096
Loss at iteration 470 : 0.0020570748019963503
Loss at iteration 480 : 0.00022469053510576487
Loss at iteration 490 : 0.004905201960355043
Loss at iteration 500 : 0.0005092439823783934
Loss at iteration 510 : 0.0027523182798177004
Loss at iteration 520 : 0.00037840037839487195
Loss at iteration 530 : 0.00013092388689983636
Loss at iteration 540 : 0.0003316679794806987
Loss at iteration 550 : 0.00046854495303705335
Loss at iteration 560 : 0.0017920166719704866
Loss at iteration 570 : 0.0011928027961403131
Loss at iteration 580 : 0.002647070912644267
Loss at iteration 590 : 0.0004476876347325742
Loss at iteration 600 : 0.0027450965717434883
Loss at iteration 610 : 0.0002165476616937667
Loss at iteration 620 : 0.00037814804818481207
Loss at iteration 630 : 0.0025247028097510338
Loss at iteration 640 : 0.00030397690716199577
Loss at iteration 650 : 0.0009000713471323252
Loss at iteration 660 : 5.387856799643487e-05
Loss at iteration 670 : 0.00034602812957018614
Loss at iteration 680 : 0.0027637439779937267
Loss at iteration 690 : 0.0002801279188133776
Loss at iteration 700 : 0.0011728884419426322
Loss at iteration 710 : 0.0005848974105902016
Loss at iteration 720 : 0.0007479978958144784
Loss at iteration 730 : 0.00019733690714929253
Loss at iteration 740 : 8.843634714139625e-05
Loss at iteration 750 : 0.00012472993694245815
Loss at iteration 760 : 0.00023807218531146646
Loss at iteration 770 : 0.00011068081221310422
Loss at iteration 780 : 0.0001521256344858557
Loss at iteration 790 : 0.0005164640606380999
Loss at iteration 800 : 0.00043299057870171964
Loss at iteration 810 : 0.0020725862123072147
Loss at iteration 820 : 0.00018286904378328472
Loss at iteration 830 : 0.003307734150439501
Loss at iteration 840 : 0.0005939843249507248
Loss at iteration 850 : 0.005047886166721582
Loss at iteration 860 : 0.0010938204359263182
Loss at iteration 870 : 0.0032969326712191105
Loss at iteration 880 : 0.0005238272715359926
Loss at iteration 890 : 0.003439820371568203
Loss at iteration 900 : 0.0008890212047845125
Loss at iteration 910 : 0.001067140605300665
Loss at iteration 920 : 0.0031291916966438293
Loss at iteration 930 : 0.0005909858737140894
Loss at iteration 940 : 0.0005023006815463305
Loss at iteration 950 : 0.0012858479749411345
Loss at iteration 960 : 0.0028147916309535503
Loss at iteration 970 : 0.0006086442735977471
Loss at iteration 980 : 0.00022098392946645617
Loss at iteration 990 : 0.0007471670396625996
Loss at iteration 1000 : 0.0013580841477960348
Loss at iteration 1010 : 0.00019854484708048403
Loss at iteration 1020 : 0.001104881172068417
Loss at iteration 1030 : 0.001433828379958868
Loss at iteration 1040 : 0.0010392669355496764
Loss at iteration 1050 : 0.0008676727884449065
Loss at iteration 1060 : 0.00023471162421628833
Loss at iteration 1070 : 0.003772342810407281
Loss at iteration 1080 : 0.00016952730948105454
Loss at iteration 1090 : 0.00024453873629681766
Loss at iteration 1100 : 0.0002614710247144103
Loss at iteration 1110 : 0.00035880738869309425
Loss at iteration 1120 : 0.0009536886354908347
Loss at iteration 1130 : 0.0005612348904833198
Loss at iteration 1140 : 8.893201447790489e-05
Loss at iteration 1150 : 0.0002799886860884726
Loss at iteration 1160 : 0.00013348241918720305
Loss at iteration 1170 : 6.773931818315759e-05
Loss at iteration 1180 : 0.0001554665359435603
Loss at iteration 1190 : 0.0034782555885612965
Loss at iteration 1200 : 0.003041547257453203
Loss at iteration 1210 : 0.0003113555139862001
Loss at iteration 1220 : 0.000730374245904386
Loss at iteration 1230 : 0.00018446888134349138
Loss at iteration 1240 : 0.0006139172473922372
Loss at iteration 1250 : 0.00016104892711155117
Loss at iteration 1260 : 0.0021679725032299757
Loss at iteration 1270 : 9.686763223726302e-05
Loss at iteration 1280 : 0.000565522990655154
Loss at iteration 1290 : 0.005858337040990591
Loss at iteration 1300 : 0.0019747649785131216
Loss at iteration 1310 : 0.0001221982529386878
Loss at iteration 1320 : 0.000133938025101088
Loss at iteration 1330 : 0.0029896702617406845
Loss at iteration 1340 : 0.0003354160871822387
Loss at iteration 1350 : 0.00018699915381148458
Loss at iteration 1360 : 0.0007363461190834641
Loss at iteration 1370 : 0.00020709860837087035
Loss at iteration 1380 : 0.0011591307120397687
Loss at iteration 1390 : 0.00010567704157438129
Loss at iteration 1400 : 0.0003876972768921405
Loss at iteration 1410 : 0.00023725582286715508
Loss at iteration 1420 : 0.0007331767119467258
Loss at iteration 1430 : 0.0008063810528255999
Loss at iteration 1440 : 0.00019765639444813132
Loss at iteration 1450 : 0.0019757121335715055
Loss at iteration 1460 : 0.004384767729789019
Loss at iteration 1470 : 0.0002185932535212487
Loss at iteration 1480 : 0.0001654265506658703
Loss at iteration 1490 : 0.00027327475254423916
Loss at iteration 1500 : 0.0030961008742451668
Loss at iteration 1510 : 0.002397994277998805
Loss at iteration 1520 : 0.00022973422892391682
Loss at iteration 1530 : 0.0010457184398546815
Loss at iteration 1540 : 0.0004530118312686682
Loss at iteration 1550 : 0.0009852172806859016
Loss at iteration 1560 : 0.0008803993696346879
Loss at iteration 1570 : 0.0013383700279518962
Loss at iteration 1580 : 0.0002404112892691046
Loss at iteration 1590 : 0.0029251400846987963
Loss at iteration 1600 : 0.0006460864678956568
Loss at iteration 1610 : 0.00014928661403246224
Loss at iteration 1620 : 0.0001807070802897215
Loss at iteration 1630 : 0.00036109291249886155
Loss at iteration 1640 : 9.350182517664507e-05
Loss at iteration 1650 : 0.002388023305684328
Loss at iteration 1660 : 0.0001956374035216868
Loss at iteration 1670 : 0.00026774784782901406
Loss at iteration 1680 : 0.0028510831762105227
Loss at iteration 1690 : 0.002394663402810693
Loss at iteration 1700 : 0.004816940985620022
Loss at iteration 1710 : 0.00026532344054430723
Loss at iteration 1720 : 0.0019189341692253947
Loss at iteration 1730 : 0.0036182275507599115
Loss at iteration 1740 : 0.002106557134538889
Loss at iteration 1750 : 0.00029392860596999526
The SSIM Value is: 0.9885326661990077
The PSNR Value is: 46.71433658851926
the highest SSIM value is: 46.71433658851926
the epoch is: 21
Loss at iteration 10 : 7.876163726905361e-05
Loss at iteration 20 : 0.0002389418805250898
Loss at iteration 30 : 0.00033149344380944967
Loss at iteration 40 : 0.0017129175830632448
Loss at iteration 50 : 0.0005453166086226702
Loss at iteration 60 : 0.00032463952084071934
Loss at iteration 70 : 0.000372991431504488
Loss at iteration 80 : 0.001676101004704833
Loss at iteration 90 : 0.00949129369109869
Loss at iteration 100 : 0.0017224822659045458
Loss at iteration 110 : 0.00023269923985935748
Loss at iteration 120 : 0.0004777742433361709
Loss at iteration 130 : 0.00017077564552892
Loss at iteration 140 : 0.005307866260409355
Loss at iteration 150 : 0.0006358225364238024
Loss at iteration 160 : 0.0037292176857590675
Loss at iteration 170 : 0.0007273852825164795
Loss at iteration 180 : 0.00018644507508724928
Loss at iteration 190 : 0.0004022453213110566
Loss at iteration 200 : 0.0016342399176210165
Loss at iteration 210 : 0.00019092044385615736
Loss at iteration 220 : 0.003421194851398468
Loss at iteration 230 : 0.0005086833261884749
Loss at iteration 240 : 0.0001130745658883825
Loss at iteration 250 : 0.0001705837348708883
Loss at iteration 260 : 0.0003232976596336812
Loss at iteration 270 : 0.00030257488833740354
Loss at iteration 280 : 0.0002780191716738045
Loss at iteration 290 : 0.0008511621272191405
Loss at iteration 300 : 0.0025410326197743416
Loss at iteration 310 : 0.002140413038432598
Loss at iteration 320 : 0.00038304078043438494
Loss at iteration 330 : 0.0003125160001218319
Loss at iteration 340 : 0.002847902476787567
Loss at iteration 350 : 0.006197160575538874
Loss at iteration 360 : 0.000878603314049542
Loss at iteration 370 : 0.0009783415589481592
Loss at iteration 380 : 0.0004003560752607882
Loss at iteration 390 : 0.0001354122068732977
Loss at iteration 400 : 0.000933388655539602
Loss at iteration 410 : 0.00014603504678234458
Loss at iteration 420 : 0.002988002263009548
Loss at iteration 430 : 0.00020738443708978593
Loss at iteration 440 : 0.00021671460126526654
Loss at iteration 450 : 9.61122423177585e-05
Loss at iteration 460 : 0.0025990460999310017
Loss at iteration 470 : 0.0008125659660436213
Loss at iteration 480 : 0.0009816677775233984
Loss at iteration 490 : 0.0004653010983020067
Loss at iteration 500 : 0.000824232236482203
Loss at iteration 510 : 7.331294182222337e-05
Loss at iteration 520 : 0.00021108391229063272
Loss at iteration 530 : 0.0005230550304986537
Loss at iteration 540 : 0.0005040799733251333
Loss at iteration 550 : 0.002372178714722395
Loss at iteration 560 : 0.0006708776927553117
Loss at iteration 570 : 0.0019021473126485944
Loss at iteration 580 : 0.004032542929053307
Loss at iteration 590 : 0.00022077973699197173
Loss at iteration 600 : 0.0008755785529501736
Loss at iteration 610 : 0.0044339923188090324
Loss at iteration 620 : 0.0009055520640686154
Loss at iteration 630 : 0.0034697209484875202
Loss at iteration 640 : 0.00012153221177868545
Loss at iteration 650 : 0.00016031492850743234
Loss at iteration 660 : 0.00010763700993265957
Loss at iteration 670 : 0.00016950975987128913
Loss at iteration 680 : 0.0012511342065408826
Loss at iteration 690 : 7.199450919870287e-05
Loss at iteration 700 : 0.007411549799144268
Loss at iteration 710 : 0.0004023381043225527
Loss at iteration 720 : 0.0012606083182618022
Loss at iteration 730 : 0.0017540667904540896
Loss at iteration 740 : 0.0015272664604708552
Loss at iteration 750 : 0.00011233650729991496
Loss at iteration 760 : 0.00013846346701029688
Loss at iteration 770 : 0.0007844095816835761
Loss at iteration 780 : 0.00012141944171162322
Loss at iteration 790 : 0.00022643392730969936
Loss at iteration 800 : 0.00044785335194319487
Loss at iteration 810 : 0.0001970629527932033
Loss at iteration 820 : 0.0005083172000013292
Loss at iteration 830 : 0.0006012646481394768
Loss at iteration 840 : 0.0011987992329522967
Loss at iteration 850 : 0.0004628912138286978
Loss at iteration 860 : 0.0001847391831688583
Loss at iteration 870 : 0.0005093094077892601
Loss at iteration 880 : 0.00035038942587561905
Loss at iteration 890 : 0.0004814321582671255
Loss at iteration 900 : 0.0005032972549088299
Loss at iteration 910 : 0.00010368711082264781
Loss at iteration 920 : 0.0002304513764102012
Loss at iteration 930 : 0.0005617808783426881
Loss at iteration 940 : 0.002549205906689167
Loss at iteration 950 : 0.0022017559967935085
Loss at iteration 960 : 0.00454914104193449
Loss at iteration 970 : 0.0013389716623350978
Loss at iteration 980 : 0.0003457034763414413
Loss at iteration 990 : 8.482397242914885e-05
Loss at iteration 1000 : 9.475914703216404e-05
Loss at iteration 1010 : 0.0005050540203228593
Loss at iteration 1020 : 0.0026041832752525806
Loss at iteration 1030 : 0.006569780874997377
Loss at iteration 1040 : 0.005041930824518204
Loss at iteration 1050 : 0.00017907863366417587
Loss at iteration 1060 : 0.00014011900930199772
Loss at iteration 1070 : 0.003619870636612177
Loss at iteration 1080 : 0.0003525378415361047
Loss at iteration 1090 : 0.0003676167980302125
Loss at iteration 1100 : 0.0005386255215853453
Loss at iteration 1110 : 0.0025599137879908085
Loss at iteration 1120 : 0.00032303083571605384
Loss at iteration 1130 : 0.003305907128378749
Loss at iteration 1140 : 0.0008378380443900824
Loss at iteration 1150 : 0.00013263343134894967
Loss at iteration 1160 : 0.0023298191372305155
Loss at iteration 1170 : 0.0006355626974254847
Loss at iteration 1180 : 0.0022548872511833906
Loss at iteration 1190 : 0.0018239289056509733
Loss at iteration 1200 : 0.004073960706591606
Loss at iteration 1210 : 0.0011984648881480098
Loss at iteration 1220 : 0.0019110708963125944
Loss at iteration 1230 : 0.0006540758186019957
Loss at iteration 1240 : 0.0005996190593577921
Loss at iteration 1250 : 0.00044590607285499573
Loss at iteration 1260 : 0.003050637897104025
Loss at iteration 1270 : 7.881224883021787e-05
Loss at iteration 1280 : 0.00021342094987630844
Loss at iteration 1290 : 0.0010490003041923046
Loss at iteration 1300 : 0.0001365362695651129
Loss at iteration 1310 : 0.00020897331705782562
Loss at iteration 1320 : 0.0060354312881827354
Loss at iteration 1330 : 0.0003489090013317764
Loss at iteration 1340 : 0.00014156734687276185
Loss at iteration 1350 : 0.001844721962697804
Loss at iteration 1360 : 0.0025006840005517006
Loss at iteration 1370 : 0.00012438867997843772
Loss at iteration 1380 : 0.0045018671080470085
Loss at iteration 1390 : 0.00043810566421598196
Loss at iteration 1400 : 0.0003380523412488401
Loss at iteration 1410 : 0.0011666911887004972
Loss at iteration 1420 : 0.00045911199413239956
Loss at iteration 1430 : 0.0001807058579288423
Loss at iteration 1440 : 0.0010580930393189192
Loss at iteration 1450 : 0.0004583104746416211
Loss at iteration 1460 : 0.0029895140323787928
Loss at iteration 1470 : 0.000127508828882128
Loss at iteration 1480 : 0.002523098373785615
Loss at iteration 1490 : 0.0015700343064963818
Loss at iteration 1500 : 0.0007875720039010048
Loss at iteration 1510 : 0.00034108327236026525
Loss at iteration 1520 : 0.002382114762440324
Loss at iteration 1530 : 0.0010736590484157205
Loss at iteration 1540 : 0.0030610773246735334
Loss at iteration 1550 : 0.0003387595643289387
Loss at iteration 1560 : 0.00016559704090468585
Loss at iteration 1570 : 0.0017425250262022018
Loss at iteration 1580 : 0.0029678838327527046
Loss at iteration 1590 : 0.0006157350726425648
Loss at iteration 1600 : 0.00012558115122374147
Loss at iteration 1610 : 0.0001958480861503631
Loss at iteration 1620 : 0.0004681380232796073
Loss at iteration 1630 : 0.0033769968431442976
Loss at iteration 1640 : 0.0006570579134859145
Loss at iteration 1650 : 0.0001616754016140476
Loss at iteration 1660 : 0.002865986432880163
Loss at iteration 1670 : 0.0029018293134868145
Loss at iteration 1680 : 0.00017905927961692214
Loss at iteration 1690 : 0.004753811750560999
Loss at iteration 1700 : 0.0003745859139598906
Loss at iteration 1710 : 0.00022636157518718392
Loss at iteration 1720 : 0.0002134592505171895
Loss at iteration 1730 : 8.118672121781856e-05
Loss at iteration 1740 : 0.003692321013659239
Loss at iteration 1750 : 0.00027293612947687507
The SSIM Value is: 0.9891346527616358
The PSNR Value is: 46.57362437773381
the epoch is: 22
Loss at iteration 10 : 0.000816853775177151
Loss at iteration 20 : 0.0001254202943528071
Loss at iteration 30 : 6.845267489552498e-05
Loss at iteration 40 : 0.0028915812727063894
Loss at iteration 50 : 0.0004989150911569595
Loss at iteration 60 : 0.0035057198256254196
Loss at iteration 70 : 0.00025259211543016136
Loss at iteration 80 : 0.0032935377676039934
Loss at iteration 90 : 0.0002277465828228742
Loss at iteration 100 : 0.00016216746007557958
Loss at iteration 110 : 0.00015273725148290396
Loss at iteration 120 : 0.001515099429525435
Loss at iteration 130 : 0.0021371720358729362
Loss at iteration 140 : 0.0013305551838129759
Loss at iteration 150 : 0.007341905031353235
Loss at iteration 160 : 0.0023259941954165697
Loss at iteration 170 : 0.002788575366139412
Loss at iteration 180 : 0.0010402945335954428
Loss at iteration 190 : 0.002003046218305826
Loss at iteration 200 : 0.00025868858210742474
Loss at iteration 210 : 0.0028948637191206217
Loss at iteration 220 : 0.001962269190698862
Loss at iteration 230 : 0.00020552900969050825
Loss at iteration 240 : 0.000823291833512485
Loss at iteration 250 : 0.00020027859136462212
Loss at iteration 260 : 0.0011367584811523557
Loss at iteration 270 : 0.00313580222427845
Loss at iteration 280 : 0.0001380896137561649
Loss at iteration 290 : 0.00018172046111430973
Loss at iteration 300 : 0.0004312219680286944
Loss at iteration 310 : 0.003108837641775608
Loss at iteration 320 : 0.0002602222375571728
Loss at iteration 330 : 0.0029521253891289234
Loss at iteration 340 : 0.0031553658191114664
Loss at iteration 350 : 0.0006816590903326869
Loss at iteration 360 : 0.00023943593259900808
Loss at iteration 370 : 0.00177841039840132
Loss at iteration 380 : 0.0001830642286222428
Loss at iteration 390 : 0.0005055258516222239
Loss at iteration 400 : 8.345829701283947e-05
Loss at iteration 410 : 0.0021439248230308294
Loss at iteration 420 : 0.0028757101390510798
Loss at iteration 430 : 0.0025411301758140326
Loss at iteration 440 : 0.00018735819321591407
Loss at iteration 450 : 7.714728417340666e-05
Loss at iteration 460 : 0.00016553244495298713
Loss at iteration 470 : 0.0014995805686339736
Loss at iteration 480 : 0.00022845997591502964
Loss at iteration 490 : 0.0006723406258970499
Loss at iteration 500 : 0.00011418625945225358
Loss at iteration 510 : 0.0006853920640423894
Loss at iteration 520 : 0.0004698566044680774
Loss at iteration 530 : 0.00027418028912507
Loss at iteration 540 : 0.002645459957420826
Loss at iteration 550 : 0.00014260342868510634
Loss at iteration 560 : 0.0044116852805018425
Loss at iteration 570 : 0.0013008497189730406
Loss at iteration 580 : 0.005818396341055632
Loss at iteration 590 : 7.245368033181876e-05
Loss at iteration 600 : 0.00014660353190265596
Loss at iteration 610 : 0.00016942780348472297
Loss at iteration 620 : 0.0067842090502381325
Loss at iteration 630 : 7.390702376142144e-05
Loss at iteration 640 : 0.0038176255766302347
Loss at iteration 650 : 0.0002846285642590374
Loss at iteration 660 : 0.00022178006474860013
Loss at iteration 670 : 0.001103774062357843
Loss at iteration 680 : 0.0023390909191221
Loss at iteration 690 : 0.0001660097186686471
Loss at iteration 700 : 0.00018065083713736385
Loss at iteration 710 : 0.001759292557835579
Loss at iteration 720 : 0.000623136933427304
Loss at iteration 730 : 0.00021142122568562627
Loss at iteration 740 : 0.0001757261634338647
Loss at iteration 750 : 0.0003841503639705479
Loss at iteration 760 : 0.00020575520466081798
Loss at iteration 770 : 0.00010694965749280527
Loss at iteration 780 : 0.0006678819190710783
Loss at iteration 790 : 0.0002894920762628317
Loss at iteration 800 : 0.004206881858408451
Loss at iteration 810 : 0.0002568874042481184
Loss at iteration 820 : 0.00023325679649133235
Loss at iteration 830 : 0.0006023284513503313
Loss at iteration 840 : 0.0011954882647842169
Loss at iteration 850 : 0.0007930640131235123
Loss at iteration 860 : 8.814982720650733e-05
Loss at iteration 870 : 0.00014238279254641384
Loss at iteration 880 : 0.002750757383182645
Loss at iteration 890 : 0.0002542771981097758
Loss at iteration 900 : 0.0004523035022430122
Loss at iteration 910 : 0.003493174910545349
Loss at iteration 920 : 0.00020657294953707606
Loss at iteration 930 : 0.0027427123859524727
Loss at iteration 940 : 0.0002349901187699288
Loss at iteration 950 : 0.00016716617392376065
Loss at iteration 960 : 0.0003841589204967022
Loss at iteration 970 : 0.002532551996409893
Loss at iteration 980 : 0.0002969072957057506
Loss at iteration 990 : 0.002430029446259141
Loss at iteration 1000 : 0.002942882478237152
Loss at iteration 1010 : 0.00034657565993256867
Loss at iteration 1020 : 0.0021308069117367268
Loss at iteration 1030 : 0.004861341789364815
Loss at iteration 1040 : 0.00017453588952776045
Loss at iteration 1050 : 0.0017902613617479801
Loss at iteration 1060 : 0.003479174105450511
Loss at iteration 1070 : 0.0003811136120930314
Loss at iteration 1080 : 0.00018687601550482213
Loss at iteration 1090 : 0.0020225737243890762
Loss at iteration 1100 : 0.00011513888603076339
Loss at iteration 1110 : 0.0002096992393489927
Loss at iteration 1120 : 0.0031624576076865196
Loss at iteration 1130 : 0.005822252482175827
Loss at iteration 1140 : 8.294589497381821e-05
Loss at iteration 1150 : 0.0010241048876196146
Loss at iteration 1160 : 0.0006772567285224795
Loss at iteration 1170 : 0.007062530145049095
Loss at iteration 1180 : 0.0010776252020150423
Loss at iteration 1190 : 0.00024572102120146155
Loss at iteration 1200 : 0.00031514998408965766
Loss at iteration 1210 : 0.0004031784483231604
Loss at iteration 1220 : 0.00020759651670232415
Loss at iteration 1230 : 0.0002569925563875586
Loss at iteration 1240 : 0.002102196915075183
Loss at iteration 1250 : 0.0028651347383856773
Loss at iteration 1260 : 0.0033105644397437572
Loss at iteration 1270 : 0.00428416021168232
Loss at iteration 1280 : 0.0006669595604762435
Loss at iteration 1290 : 0.0002538000117056072
Loss at iteration 1300 : 0.00024115765700116754
Loss at iteration 1310 : 0.0003278775548096746
Loss at iteration 1320 : 0.0016155701596289873
Loss at iteration 1330 : 0.00018587062368169427
Loss at iteration 1340 : 0.00019064931257162243
Loss at iteration 1350 : 0.0005235708085820079
Loss at iteration 1360 : 0.0001379771565552801
Loss at iteration 1370 : 8.457050716970116e-05
Loss at iteration 1380 : 0.00012731370225083083
Loss at iteration 1390 : 0.0017038451042026281
Loss at iteration 1400 : 0.00018570249085314572
Loss at iteration 1410 : 0.00015588258975185454
Loss at iteration 1420 : 0.00022805121261626482
Loss at iteration 1430 : 0.0004174096684437245
Loss at iteration 1440 : 0.002196183195337653
Loss at iteration 1450 : 0.0035813176073133945
Loss at iteration 1460 : 0.00044174547656439245
Loss at iteration 1470 : 0.000469627178972587
Loss at iteration 1480 : 0.00605250196531415
Loss at iteration 1490 : 0.00015367254673037678
Loss at iteration 1500 : 0.0008303754730150104
Loss at iteration 1510 : 0.00013226026203483343
Loss at iteration 1520 : 0.000589492847211659
Loss at iteration 1530 : 0.00011536113743204623
Loss at iteration 1540 : 0.003149564377963543
Loss at iteration 1550 : 0.00011616327537922189
Loss at iteration 1560 : 0.00036515924148261547
Loss at iteration 1570 : 0.0006624183733947575
Loss at iteration 1580 : 0.002347729867324233
Loss at iteration 1590 : 0.00011953704233746976
Loss at iteration 1600 : 0.0011634360998868942
Loss at iteration 1610 : 0.0002582712913863361
Loss at iteration 1620 : 0.00014452237519435585
Loss at iteration 1630 : 0.00011018887744285166
Loss at iteration 1640 : 0.004880622029304504
Loss at iteration 1650 : 0.0009109748643822968
Loss at iteration 1660 : 6.612024299101904e-05
Loss at iteration 1670 : 5.84611261729151e-05
Loss at iteration 1680 : 0.003305616322904825
Loss at iteration 1690 : 0.0012218619231134653
Loss at iteration 1700 : 7.675506640225649e-05
Loss at iteration 1710 : 0.008285490795969963
Loss at iteration 1720 : 5.947199679212645e-05
Loss at iteration 1730 : 0.00038083549588918686
Loss at iteration 1740 : 0.000282016524579376
Loss at iteration 1750 : 0.0014554800000041723
The SSIM Value is: 0.9869524403290602
The PSNR Value is: 46.55826700521461
the epoch is: 23
Loss at iteration 10 : 0.00031831502565182745
Loss at iteration 20 : 0.00034540443448349833
Loss at iteration 30 : 0.0003025468031410128
Loss at iteration 40 : 0.0031893234699964523
Loss at iteration 50 : 0.0022406005300581455
Loss at iteration 60 : 0.004227788653224707
Loss at iteration 70 : 0.0009191941935569048
Loss at iteration 80 : 0.00012905735638923943
Loss at iteration 90 : 0.00010630406904965639
Loss at iteration 100 : 0.0010125254048034549
Loss at iteration 110 : 0.000653692230116576
Loss at iteration 120 : 0.0022217929363250732
Loss at iteration 130 : 0.00048226877697743475
Loss at iteration 140 : 0.00016957131447270513
Loss at iteration 150 : 0.0033280926290899515
Loss at iteration 160 : 0.0036647040396928787
Loss at iteration 170 : 9.914411202771589e-05
Loss at iteration 180 : 0.00014566599566023797
Loss at iteration 190 : 0.002543036825954914
Loss at iteration 200 : 0.0022051972337067127
Loss at iteration 210 : 0.0023920354433357716
Loss at iteration 220 : 0.00019200361566618085
Loss at iteration 230 : 0.0005538531113415956
Loss at iteration 240 : 0.0005346084362827241
Loss at iteration 250 : 0.00021697930060327053
Loss at iteration 260 : 0.00043598783668130636
Loss at iteration 270 : 0.008022107183933258
Loss at iteration 280 : 0.0008477658848278224
Loss at iteration 290 : 0.0009135592263191938
Loss at iteration 300 : 0.0017369850538671017
Loss at iteration 310 : 0.003670682664960623
Loss at iteration 320 : 0.00016428584058303386
Loss at iteration 330 : 0.0017672072863206267
Loss at iteration 340 : 0.0019606221467256546
Loss at iteration 350 : 0.0017829897115007043
Loss at iteration 360 : 0.003955051302909851
Loss at iteration 370 : 7.406953955069184e-05
Loss at iteration 380 : 0.0026611939538270235
Loss at iteration 390 : 0.00010969321010634303
Loss at iteration 400 : 0.00015764460840728134
Loss at iteration 410 : 0.005579147022217512
Loss at iteration 420 : 0.004401088692247868
Loss at iteration 430 : 7.836018630769104e-05
Loss at iteration 440 : 0.00015725629054941237
Loss at iteration 450 : 0.0030877122189849615
Loss at iteration 460 : 0.0003258895012550056
Loss at iteration 470 : 0.0002048012538580224
Loss at iteration 480 : 0.0011349862907081842
Loss at iteration 490 : 0.00015602608618792146
Loss at iteration 500 : 0.00019750020874198526
Loss at iteration 510 : 0.00011016005009878427
Loss at iteration 520 : 0.0012289725709706545
Loss at iteration 530 : 0.004368574358522892
Loss at iteration 540 : 0.0014132533688098192
Loss at iteration 550 : 0.0008369196439161897
Loss at iteration 560 : 0.00042648648377507925
Loss at iteration 570 : 0.0036586930509656668
Loss at iteration 580 : 0.0020587099716067314
Loss at iteration 590 : 0.0006955121061764657
Loss at iteration 600 : 0.0011280073085799813
Loss at iteration 610 : 0.004684383049607277
Loss at iteration 620 : 0.00015358705422841012
Loss at iteration 630 : 0.0004488159320317209
Loss at iteration 640 : 0.0009832164505496621
Loss at iteration 650 : 0.00011538685794221237
Loss at iteration 660 : 0.00926617905497551
Loss at iteration 670 : 0.00013823772314935923
Loss at iteration 680 : 0.00010291908256476745
Loss at iteration 690 : 0.002708291867747903
Loss at iteration 700 : 0.0009647957631386817
Loss at iteration 710 : 0.0042609418742358685
Loss at iteration 720 : 0.000616487639490515
Loss at iteration 730 : 0.0037908568046987057
Loss at iteration 740 : 0.0008672456024214625
Loss at iteration 750 : 0.0005299399490468204
Loss at iteration 760 : 0.0005268970271572471
Loss at iteration 770 : 8.629097283119336e-05
Loss at iteration 780 : 0.00040583667578175664
Loss at iteration 790 : 0.0002542323200032115
Loss at iteration 800 : 0.0003439556749071926
Loss at iteration 810 : 3.525941792759113e-05
Loss at iteration 820 : 0.0002176599227823317
Loss at iteration 830 : 9.533589036436751e-05
Loss at iteration 840 : 0.0029312355909496546
Loss at iteration 850 : 0.0014272377593442798
Loss at iteration 860 : 0.0007841677870601416
Loss at iteration 870 : 0.00046003219904378057
Loss at iteration 880 : 0.0004505623655859381
Loss at iteration 890 : 0.0025578313507139683
Loss at iteration 900 : 0.0022070801351219416
Loss at iteration 910 : 0.0002500900300219655
Loss at iteration 920 : 0.0007848662789911032
Loss at iteration 930 : 0.0009067159844562411
Loss at iteration 940 : 0.00016624880663584918
Loss at iteration 950 : 0.004862200003117323
Loss at iteration 960 : 0.0010787025094032288
Loss at iteration 970 : 0.000133841997012496
Loss at iteration 980 : 0.003111443482339382
Loss at iteration 990 : 0.00012540211901068687
Loss at iteration 1000 : 0.00032746553188189864
Loss at iteration 1010 : 0.0018740311497822404
Loss at iteration 1020 : 0.0004592189216054976
Loss at iteration 1030 : 0.0007486259564757347
Loss at iteration 1040 : 0.0008568934281356633
Loss at iteration 1050 : 0.0028208917938172817
Loss at iteration 1060 : 0.00100691057741642
Loss at iteration 1070 : 0.0010746296029537916
Loss at iteration 1080 : 0.000929434085264802
Loss at iteration 1090 : 0.00013121026859153062
Loss at iteration 1100 : 0.0006889713113196194
Loss at iteration 1110 : 0.0008987014880403876
Loss at iteration 1120 : 0.00027309212600812316
Loss at iteration 1130 : 0.0004744137986563146
Loss at iteration 1140 : 0.0019928980618715286
Loss at iteration 1150 : 0.00020897143986076117
Loss at iteration 1160 : 0.0004986008862033486
Loss at iteration 1170 : 0.003454145509749651
Loss at iteration 1180 : 0.001279024058021605
Loss at iteration 1190 : 0.00012639544729609042
Loss at iteration 1200 : 0.0004661519196815789
Loss at iteration 1210 : 7.189871394075453e-05
Loss at iteration 1220 : 0.000600986008066684
Loss at iteration 1230 : 0.0008029977325350046
Loss at iteration 1240 : 0.003693312406539917
Loss at iteration 1250 : 0.0003012505767401308
Loss at iteration 1260 : 0.00014641127199865878
Loss at iteration 1270 : 0.004132915288209915
Loss at iteration 1280 : 0.0035549893509596586
Loss at iteration 1290 : 0.0005148957134224474
Loss at iteration 1300 : 0.00023056183999869972
Loss at iteration 1310 : 0.0001861482742242515
Loss at iteration 1320 : 0.0005405688425526023
Loss at iteration 1330 : 0.0026422287337481976
Loss at iteration 1340 : 0.0003365470911376178
Loss at iteration 1350 : 0.0005856477655470371
Loss at iteration 1360 : 0.00012983917258679867
Loss at iteration 1370 : 0.0003338757378514856
Loss at iteration 1380 : 0.00030733601306565106
Loss at iteration 1390 : 0.0024407138116657734
Loss at iteration 1400 : 0.0006979522295296192
Loss at iteration 1410 : 0.0003954692801926285
Loss at iteration 1420 : 6.356721132760867e-05
Loss at iteration 1430 : 0.00011654519039439037
Loss at iteration 1440 : 0.0006370458868332207
Loss at iteration 1450 : 0.0008733973954804242
Loss at iteration 1460 : 0.0001308458304265514
Loss at iteration 1470 : 0.000123514691949822
Loss at iteration 1480 : 0.0001587388978805393
Loss at iteration 1490 : 0.00017351651331409812
Loss at iteration 1500 : 0.0012140099424868822
Loss at iteration 1510 : 0.003339731600135565
Loss at iteration 1520 : 0.0006700967205688357
Loss at iteration 1530 : 0.0011935026850551367
Loss at iteration 1540 : 0.0003563867649063468
Loss at iteration 1550 : 0.00016369654622394592
Loss at iteration 1560 : 0.0002511701313778758
Loss at iteration 1570 : 0.00015158907626755536
Loss at iteration 1580 : 0.0002763095253612846
Loss at iteration 1590 : 0.00016914201842155308
Loss at iteration 1600 : 0.001130922930315137
Loss at iteration 1610 : 6.5741223806981e-05
Loss at iteration 1620 : 0.00019752848311327398
Loss at iteration 1630 : 0.003036246169358492
Loss at iteration 1640 : 0.0006445852341130376
Loss at iteration 1650 : 0.00040825241012498736
Loss at iteration 1660 : 0.0016489170957356691
Loss at iteration 1670 : 0.004013632424175739
Loss at iteration 1680 : 0.0001404129870934412
Loss at iteration 1690 : 0.007909945212304592
Loss at iteration 1700 : 0.00021410969202406704
Loss at iteration 1710 : 0.0003079065936617553
Loss at iteration 1720 : 0.00019057432655245066
Loss at iteration 1730 : 0.0001281950098928064
Loss at iteration 1740 : 0.0018399856053292751
Loss at iteration 1750 : 0.0013936806935817003
The SSIM Value is: 0.986263939068706
The PSNR Value is: 46.48461262875191
the epoch is: 24
Loss at iteration 10 : 0.00013006097287870944
Loss at iteration 20 : 0.004582196474075317
Loss at iteration 30 : 0.000508152530528605
Loss at iteration 40 : 0.0008484192076139152
Loss at iteration 50 : 0.006562964990735054
Loss at iteration 60 : 0.0011514214565977454
Loss at iteration 70 : 0.0002594425459392369
Loss at iteration 80 : 0.0007263795123435557
Loss at iteration 90 : 0.0003689554869197309
Loss at iteration 100 : 3.474110781098716e-05
Loss at iteration 110 : 0.00017334827862214297
Loss at iteration 120 : 0.0031599802896380424
Loss at iteration 130 : 0.0018268608255311847
Loss at iteration 140 : 0.00046730355825275183
Loss at iteration 150 : 0.007535486947745085
Loss at iteration 160 : 0.0004010989214293659
Loss at iteration 170 : 0.0010223520221188664
Loss at iteration 180 : 0.0002055062068393454
Loss at iteration 190 : 0.000478740461403504
Loss at iteration 200 : 4.940473445458338e-05
Loss at iteration 210 : 0.00047451601130887866
Loss at iteration 220 : 0.0013887957902625203
Loss at iteration 230 : 0.00022311147768050432
Loss at iteration 240 : 0.00047212402569130063
Loss at iteration 250 : 0.003218901576474309
Loss at iteration 260 : 0.007330392021685839
Loss at iteration 270 : 0.0001390308461850509
Loss at iteration 280 : 0.0014230599626898766
Loss at iteration 290 : 0.00027350333402864635
Loss at iteration 300 : 0.006864998023957014
Loss at iteration 310 : 0.0003289797459729016
Loss at iteration 320 : 0.00015259407518897206
Loss at iteration 330 : 0.0025533814914524555
Loss at iteration 340 : 0.00021934433607384562
Loss at iteration 350 : 0.0024382630363106728
Loss at iteration 360 : 0.00012574487482197583
Loss at iteration 370 : 0.00021748756989836693
Loss at iteration 380 : 0.0005836908239871264
Loss at iteration 390 : 0.0012589225079864264
Loss at iteration 400 : 4.6134580770740286e-05
Loss at iteration 410 : 8.489986066706479e-05
Loss at iteration 420 : 0.0002497436653356999
Loss at iteration 430 : 8.493012137478217e-05
Loss at iteration 440 : 0.002228609286248684
Loss at iteration 450 : 0.00020253119873814285
Loss at iteration 460 : 0.00015474509564228356
Loss at iteration 470 : 0.00012817681999877095
Loss at iteration 480 : 0.00031737599056214094
Loss at iteration 490 : 0.00022560333309229463
Loss at iteration 500 : 0.002432368928566575
Loss at iteration 510 : 0.00027920480351895094
Loss at iteration 520 : 0.0016669537872076035
Loss at iteration 530 : 0.00029603077564388514
Loss at iteration 540 : 0.0011570986825972795
Loss at iteration 550 : 0.0006827589240856469
Loss at iteration 560 : 0.0006787681486457586
Loss at iteration 570 : 5.9157235227758065e-05
Loss at iteration 580 : 0.0001452275610063225
Loss at iteration 590 : 0.00014068068412598222
Loss at iteration 600 : 0.0028561626095324755
Loss at iteration 610 : 0.00043885293416678905
Loss at iteration 620 : 0.0001803537452360615
Loss at iteration 630 : 0.0008506594458594918
Loss at iteration 640 : 0.00021909519273322076
Loss at iteration 650 : 0.004062036983668804
Loss at iteration 660 : 0.0007787786889821291
Loss at iteration 670 : 0.00013720437709707767
Loss at iteration 680 : 0.0002583361347205937
Loss at iteration 690 : 0.000232747319387272
Loss at iteration 700 : 6.693528121104464e-05
Loss at iteration 710 : 0.00012137578596593812
Loss at iteration 720 : 0.0005182438180781901
Loss at iteration 730 : 0.0020740805193781853
Loss at iteration 740 : 0.00016000820323824883
Loss at iteration 750 : 5.6877579481806606e-05
Loss at iteration 760 : 0.00043287506559863687
Loss at iteration 770 : 9.70455730566755e-05
Loss at iteration 780 : 0.0006043458124622703
Loss at iteration 790 : 0.0009479967411607504
Loss at iteration 800 : 0.0009311920730397105
Loss at iteration 810 : 0.005156481638550758
Loss at iteration 820 : 0.004085912834852934
Loss at iteration 830 : 0.0019914195872843266
Loss at iteration 840 : 0.005884895101189613
Loss at iteration 850 : 4.611948679666966e-05
Loss at iteration 860 : 0.00013071208377368748
Loss at iteration 870 : 0.00022746395552530885
Loss at iteration 880 : 0.000645732507109642
Loss at iteration 890 : 0.0003771148039959371
Loss at iteration 900 : 0.001689813332632184
Loss at iteration 910 : 0.00047996072680689394
Loss at iteration 920 : 0.0013980779331177473
Loss at iteration 930 : 7.640662079211324e-05
Loss at iteration 940 : 0.0005785473040305078
Loss at iteration 950 : 0.0001299528667004779
Loss at iteration 960 : 0.00021826513693667948
Loss at iteration 970 : 0.0002856362843886018
Loss at iteration 980 : 0.00024390491307713091
Loss at iteration 990 : 0.003831310197710991
Loss at iteration 1000 : 9.637664334150031e-05
Loss at iteration 1010 : 0.0011105325538665056
Loss at iteration 1020 : 0.00011465392890386283
Loss at iteration 1030 : 0.00493267085403204
Loss at iteration 1040 : 0.0001450718700652942
Loss at iteration 1050 : 0.00017281214240938425
Loss at iteration 1060 : 0.0012669205898419023
Loss at iteration 1070 : 0.003849125001579523
Loss at iteration 1080 : 0.00018851309141609818
Loss at iteration 1090 : 0.00011486303992569447
Loss at iteration 1100 : 0.00023797375615686178
Loss at iteration 1110 : 0.00019167724531143904
Loss at iteration 1120 : 0.005733487196266651
Loss at iteration 1130 : 0.00034498266177251935
Loss at iteration 1140 : 0.0023347712121903896
Loss at iteration 1150 : 0.000986722414381802
Loss at iteration 1160 : 0.00020773000142071396
Loss at iteration 1170 : 0.0011393583845347166
Loss at iteration 1180 : 0.0004056110046803951
Loss at iteration 1190 : 0.0008424147963523865
Loss at iteration 1200 : 7.463355723302811e-05
Loss at iteration 1210 : 4.4172193156555295e-05
Loss at iteration 1220 : 3.564701182767749e-05
Loss at iteration 1230 : 0.00036242484929971397
Loss at iteration 1240 : 0.00015330335008911788
Loss at iteration 1250 : 0.0002485652803443372
Loss at iteration 1260 : 0.001310917199589312
Loss at iteration 1270 : 5.169707947061397e-05
Loss at iteration 1280 : 0.0005414187326095998
Loss at iteration 1290 : 0.00042986954213120043
Loss at iteration 1300 : 0.0001074950851034373
Loss at iteration 1310 : 0.0015340741956606507
Loss at iteration 1320 : 0.0013194759376347065
Loss at iteration 1330 : 0.0005842879763804376
Loss at iteration 1340 : 0.0030083181336522102
Loss at iteration 1350 : 0.0004816183936782181
Loss at iteration 1360 : 0.00019520857313182205
Loss at iteration 1370 : 0.00045384588884189725
Loss at iteration 1380 : 0.0046421438455581665
Loss at iteration 1390 : 0.0002279210602864623
Loss at iteration 1400 : 7.745105540379882e-05
Loss at iteration 1410 : 0.00316097354516387
Loss at iteration 1420 : 0.0001513101888122037
Loss at iteration 1430 : 0.0006042583845555782
Loss at iteration 1440 : 0.0016174620250239968
Loss at iteration 1450 : 0.0006468389183282852
Loss at iteration 1460 : 0.00018170925613958389
Loss at iteration 1470 : 0.00047003477811813354
Loss at iteration 1480 : 0.002123891608789563
Loss at iteration 1490 : 0.00019144595717079937
Loss at iteration 1500 : 0.0007013180293142796
Loss at iteration 1510 : 0.00012807533494196832
Loss at iteration 1520 : 0.00010676179954316467
Loss at iteration 1530 : 0.001339386566542089
Loss at iteration 1540 : 0.00036684045335277915
Loss at iteration 1550 : 0.000464575772639364
Loss at iteration 1560 : 0.004019600804895163
Loss at iteration 1570 : 0.0014176187105476856
Loss at iteration 1580 : 0.003168381517753005
Loss at iteration 1590 : 0.0011270424583926797
Loss at iteration 1600 : 0.0006023571477271616
Loss at iteration 1610 : 0.0017374421004205942
Loss at iteration 1620 : 7.489100971724838e-05
Loss at iteration 1630 : 0.00030038843397051096
Loss at iteration 1640 : 7.38184098736383e-05
Loss at iteration 1650 : 0.0017006200505420566
Loss at iteration 1660 : 0.0002777415211312473
Loss at iteration 1670 : 0.0002544026356190443
Loss at iteration 1680 : 0.00018736188940238208
Loss at iteration 1690 : 0.0009537356672808528
Loss at iteration 1700 : 0.0002215496642747894
Loss at iteration 1710 : 0.0002881996042560786
Loss at iteration 1720 : 0.0004334597906563431
Loss at iteration 1730 : 0.00016868568491190672
Loss at iteration 1740 : 0.0011531421914696693
Loss at iteration 1750 : 0.008970746770501137
The SSIM Value is: 0.9797160238158861
The PSNR Value is: 46.369559829980794
the epoch is: 25
Loss at iteration 10 : 0.0009499550214968622
Loss at iteration 20 : 0.0029063851106911898
Loss at iteration 30 : 0.0004291906370781362
Loss at iteration 40 : 0.001762113068252802
Loss at iteration 50 : 0.00016942204092629254
Loss at iteration 60 : 0.00038812871207483113
Loss at iteration 70 : 0.00019816930580418557
Loss at iteration 80 : 0.0001535087067168206
Loss at iteration 90 : 0.0012534987181425095
Loss at iteration 100 : 0.0006488081999123096
Loss at iteration 110 : 0.001120247645303607
Loss at iteration 120 : 0.0038767517544329166
Loss at iteration 130 : 0.0035763680934906006
Loss at iteration 140 : 0.0034235843922942877
Loss at iteration 150 : 9.083955228561535e-05
Loss at iteration 160 : 0.00025827516219578683
Loss at iteration 170 : 0.00024291183217428625
Loss at iteration 180 : 0.00013580919767264277
Loss at iteration 190 : 0.0007901725475676358
Loss at iteration 200 : 0.0003142367349937558
Loss at iteration 210 : 0.00014722836203873158
Loss at iteration 220 : 0.00018271250883117318
Loss at iteration 230 : 0.003243325976654887
Loss at iteration 240 : 0.000942347920499742
Loss at iteration 250 : 0.0002689363027457148
Loss at iteration 260 : 0.0035977321676909924
Loss at iteration 270 : 0.00027614980353973806
Loss at iteration 280 : 0.0016280371928587556
Loss at iteration 290 : 0.0006177715258672833
Loss at iteration 300 : 0.0016271743224933743
Loss at iteration 310 : 0.00011174136307090521
Loss at iteration 320 : 0.0008206047350540757
Loss at iteration 330 : 0.000903700536582619
Loss at iteration 340 : 0.000295849924441427
Loss at iteration 350 : 0.0015989100793376565
Loss at iteration 360 : 0.0003532433765940368
Loss at iteration 370 : 0.0019698075484484434
Loss at iteration 380 : 0.005025322083383799
Loss at iteration 390 : 0.0020770151168107986
Loss at iteration 400 : 0.0005932984640821815
Loss at iteration 410 : 0.0005039433017373085
Loss at iteration 420 : 0.00019411857647355646
Loss at iteration 430 : 0.0071601057425141335
Loss at iteration 440 : 0.0004418918106239289
Loss at iteration 450 : 0.0002506077871657908
Loss at iteration 460 : 0.00017802821821533144
Loss at iteration 470 : 0.0003527432563714683
Loss at iteration 480 : 0.0019590570591390133
Loss at iteration 490 : 0.003636972513049841
Loss at iteration 500 : 0.00036332744639366865
Loss at iteration 510 : 0.001430984353646636
Loss at iteration 520 : 0.0018050679937005043
Loss at iteration 530 : 0.00048158568097278476
Loss at iteration 540 : 0.0001762819301802665
Loss at iteration 550 : 0.001703028567135334
Loss at iteration 560 : 0.00029549654573202133
Loss at iteration 570 : 0.00016907327517401427
Loss at iteration 580 : 0.0004641875275410712
Loss at iteration 590 : 0.003260144032537937
Loss at iteration 600 : 0.00038259252323769033
Loss at iteration 610 : 0.000524194270838052
Loss at iteration 620 : 0.00013729420606978238
Loss at iteration 630 : 0.00026065620477311313
Loss at iteration 640 : 0.0008594393730163574
Loss at iteration 650 : 0.00033465883461758494
Loss at iteration 660 : 0.006045256741344929
Loss at iteration 670 : 0.00031798676354810596
Loss at iteration 680 : 0.00020537443924695253
Loss at iteration 690 : 0.0013417453737929463
Loss at iteration 700 : 0.00012808003521058708
Loss at iteration 710 : 0.00015429803170263767
Loss at iteration 720 : 9.297362703364342e-05
Loss at iteration 730 : 0.00432909419760108
Loss at iteration 740 : 0.004362479317933321
Loss at iteration 750 : 0.0027240952476859093
Loss at iteration 760 : 0.0005700121400877833
Loss at iteration 770 : 0.0002614101686049253
Loss at iteration 780 : 0.00042227155063301325
Loss at iteration 790 : 0.0005169991054572165
Loss at iteration 800 : 0.0017453948967158794
Loss at iteration 810 : 0.0002534958766773343
Loss at iteration 820 : 0.0013588657602667809
Loss at iteration 830 : 0.0002881228574551642
Loss at iteration 840 : 0.00017798779299482703
Loss at iteration 850 : 0.004462285898625851
Loss at iteration 860 : 0.0002581335720606148
Loss at iteration 870 : 0.00018132207333110273
Loss at iteration 880 : 0.0004907420370727777
Loss at iteration 890 : 9.735006460687146e-05
Loss at iteration 900 : 0.00717666931450367
Loss at iteration 910 : 0.00040114368312060833
Loss at iteration 920 : 0.002496741246432066
Loss at iteration 930 : 0.0017895697383210063
Loss at iteration 940 : 0.0031543488148599863
Loss at iteration 950 : 9.305946150561795e-05
Loss at iteration 960 : 0.0012424546293914318
Loss at iteration 970 : 0.0004958870122209191
Loss at iteration 980 : 0.0001976188796106726
Loss at iteration 990 : 0.00032089583692140877
Loss at iteration 1000 : 0.00209483178332448
Loss at iteration 1010 : 0.000665093248244375
Loss at iteration 1020 : 0.0006239991053007543
Loss at iteration 1030 : 0.004446142353117466
Loss at iteration 1040 : 0.0038368955720216036
Loss at iteration 1050 : 0.0004980028606951237
Loss at iteration 1060 : 9.912355744745582e-05
Loss at iteration 1070 : 4.916145553579554e-05
Loss at iteration 1080 : 0.00016275601228699088
Loss at iteration 1090 : 0.00014720394392497838
Loss at iteration 1100 : 0.0001605347788427025
Loss at iteration 1110 : 0.00020383817900437862
Loss at iteration 1120 : 0.0002564700844231993
Loss at iteration 1130 : 0.00017668900545686483
Loss at iteration 1140 : 5.833001705468632e-05
Loss at iteration 1150 : 0.00010736795957200229
Loss at iteration 1160 : 0.000895551114808768
Loss at iteration 1170 : 0.003365304321050644
Loss at iteration 1180 : 0.00019270925258751959
Loss at iteration 1190 : 0.0003267904685344547
Loss at iteration 1200 : 0.00022075849119573832
Loss at iteration 1210 : 0.004412139765918255
Loss at iteration 1220 : 0.002496879082173109
Loss at iteration 1230 : 0.0025062523782253265
Loss at iteration 1240 : 0.0028878787998110056
Loss at iteration 1250 : 0.00020108307944610715
Loss at iteration 1260 : 8.612816600361839e-05
Loss at iteration 1270 : 0.00015092252579052
Loss at iteration 1280 : 0.006262423004955053
Loss at iteration 1290 : 0.0001696047547738999
Loss at iteration 1300 : 0.0055107297375798225
Loss at iteration 1310 : 0.002411905210465193
Loss at iteration 1320 : 0.00336234993301332
Loss at iteration 1330 : 0.0001046777397277765
Loss at iteration 1340 : 0.001622016541659832
Loss at iteration 1350 : 0.003001946024596691
Loss at iteration 1360 : 0.001218966324813664
Loss at iteration 1370 : 0.00019961156067438424
Loss at iteration 1380 : 0.0006413664668798447
Loss at iteration 1390 : 0.001603717333637178
Loss at iteration 1400 : 0.0027436683885753155
Loss at iteration 1410 : 0.0006923002656549215
Loss at iteration 1420 : 0.0002756575122475624
Loss at iteration 1430 : 0.00011853312753373757
Loss at iteration 1440 : 0.000621977960690856
Loss at iteration 1450 : 0.0001817948796087876
Loss at iteration 1460 : 0.00030236877501010895
Loss at iteration 1470 : 0.0007742759771645069
Loss at iteration 1480 : 0.000830940087325871
Loss at iteration 1490 : 0.00022442566114477813
Loss at iteration 1500 : 0.0035228836350142956
Loss at iteration 1510 : 0.0011401234660297632
Loss at iteration 1520 : 0.0031039470341056585
Loss at iteration 1530 : 0.0006987199303694069
Loss at iteration 1540 : 0.004383073654025793
Loss at iteration 1550 : 0.0012480008881539106
Loss at iteration 1560 : 0.0030285597313195467
Loss at iteration 1570 : 0.000997621682472527
Loss at iteration 1580 : 0.004586756695061922
Loss at iteration 1590 : 0.00013324963219929487
Loss at iteration 1600 : 0.00010822578042279929
Loss at iteration 1610 : 0.004744849167764187
Loss at iteration 1620 : 0.00027718028286471963
Loss at iteration 1630 : 0.00243177218362689
Loss at iteration 1640 : 0.00013111344014760107
Loss at iteration 1650 : 0.00010720419959397987
Loss at iteration 1660 : 0.00016508503176737577
Loss at iteration 1670 : 0.0002400086377747357
Loss at iteration 1680 : 0.0032546990551054478
Loss at iteration 1690 : 0.000138344315928407
Loss at iteration 1700 : 0.0004900863859802485
Loss at iteration 1710 : 0.001003722078166902
Loss at iteration 1720 : 0.003623466705903411
Loss at iteration 1730 : 0.003624310251325369
Loss at iteration 1740 : 0.001123466296121478
Loss at iteration 1750 : 0.0008165818871930242
The SSIM Value is: 0.9857537108370911
The PSNR Value is: 46.720519435563276
the highest SSIM value is: 46.720519435563276
the epoch is: 26
Loss at iteration 10 : 0.00010380467574577779
Loss at iteration 20 : 0.003720169886946678
Loss at iteration 30 : 0.00010886559903156012
Loss at iteration 40 : 0.0012547869700938463
Loss at iteration 50 : 4.93840743729379e-05
Loss at iteration 60 : 0.008848260156810284
Loss at iteration 70 : 0.00029554666252806783
Loss at iteration 80 : 0.00039072538493201137
Loss at iteration 90 : 0.0002894515637308359
Loss at iteration 100 : 0.00022874285059515387
Loss at iteration 110 : 0.0005112574435770512
Loss at iteration 120 : 0.00028594324248842895
Loss at iteration 130 : 0.003789785085245967
Loss at iteration 140 : 0.00014613420353271067
Loss at iteration 150 : 0.0024071289226412773
Loss at iteration 160 : 0.0004143512633163482
Loss at iteration 170 : 0.00011559571430552751
Loss at iteration 180 : 0.003981264308094978
Loss at iteration 190 : 0.0001297542912652716
Loss at iteration 200 : 0.0016227473970502615
Loss at iteration 210 : 0.00019461556803435087
Loss at iteration 220 : 0.001064271666109562
Loss at iteration 230 : 0.00028642715187743306
Loss at iteration 240 : 0.00022202235413715243
Loss at iteration 250 : 0.00043365650344640017
Loss at iteration 260 : 0.0007844700594432652
Loss at iteration 270 : 0.0004185616853646934
Loss at iteration 280 : 9.128174133365974e-05
Loss at iteration 290 : 0.00021183074568398297
Loss at iteration 300 : 0.0055002798326313496
Loss at iteration 310 : 0.0003616775793489069
Loss at iteration 320 : 0.00021346844732761383
Loss at iteration 330 : 0.00011819809878943488
Loss at iteration 340 : 0.0002275091246701777
Loss at iteration 350 : 0.0005596189294010401
Loss at iteration 360 : 0.00342333666048944
Loss at iteration 370 : 0.0002699426840990782
Loss at iteration 380 : 0.00027519676950760186
Loss at iteration 390 : 0.0002139104763045907
Loss at iteration 400 : 0.0020427322015166283
Loss at iteration 410 : 0.0012270123697817326
Loss at iteration 420 : 0.00032311712857335806
Loss at iteration 430 : 0.001501147635281086
Loss at iteration 440 : 0.00021985155763104558
Loss at iteration 450 : 0.0002198232978116721
Loss at iteration 460 : 0.0003540735924616456
Loss at iteration 470 : 0.00018638436449691653
Loss at iteration 480 : 6.922235479578376e-05
Loss at iteration 490 : 0.00021343848493415862
Loss at iteration 500 : 0.0005268119857646525
Loss at iteration 510 : 0.00018043188902083784
Loss at iteration 520 : 0.0018687748815864325
Loss at iteration 530 : 0.00039891147753223777
Loss at iteration 540 : 0.0015059055294841528
Loss at iteration 550 : 0.0010581763926893473
Loss at iteration 560 : 0.0004021535278297961
Loss at iteration 570 : 0.00335574708878994
Loss at iteration 580 : 0.0005838297074660659
Loss at iteration 590 : 0.000239519911701791
Loss at iteration 600 : 0.0002623872132971883
Loss at iteration 610 : 0.0005947045283392072
Loss at iteration 620 : 0.0015103258192539215
Loss at iteration 630 : 0.0005752856959588826
Loss at iteration 640 : 0.002691560424864292
Loss at iteration 650 : 0.0012228775303810835
Loss at iteration 660 : 0.001013394445180893
Loss at iteration 670 : 0.0001134929116233252
Loss at iteration 680 : 0.003890310414135456
Loss at iteration 690 : 0.0011673097033053637
Loss at iteration 700 : 0.0004975501797161996
Loss at iteration 710 : 0.0002914716023951769
Loss at iteration 720 : 0.0002796902845147997
Loss at iteration 730 : 0.00012817195965908468
Loss at iteration 740 : 0.0003525256470311433
Loss at iteration 750 : 5.371457518776879e-05
Loss at iteration 760 : 0.00018230181012768298
Loss at iteration 770 : 0.0001429195690434426
Loss at iteration 780 : 0.00018650738638825715
Loss at iteration 790 : 0.0008767928229644895
Loss at iteration 800 : 0.0005074633518233895
Loss at iteration 810 : 0.0004235394299030304
Loss at iteration 820 : 0.00046281679533421993
Loss at iteration 830 : 0.0009396853856742382
Loss at iteration 840 : 0.00018832943169400096
Loss at iteration 850 : 0.000148773702676408
Loss at iteration 860 : 0.0012870419304817915
Loss at iteration 870 : 0.00021568858937826008
Loss at iteration 880 : 0.00014127414033282548
Loss at iteration 890 : 0.0005387339042499661
Loss at iteration 900 : 0.0005705629591830075
Loss at iteration 910 : 0.00015750412421766669
Loss at iteration 920 : 0.002388778841122985
Loss at iteration 930 : 0.0017906908178701997
Loss at iteration 940 : 0.0002025657013291493
Loss at iteration 950 : 0.00021757463400717825
Loss at iteration 960 : 0.00010659275721991435
Loss at iteration 970 : 0.0008155085379257798
Loss at iteration 980 : 0.0001247188774868846
Loss at iteration 990 : 0.000541857851203531
Loss at iteration 1000 : 0.0002958019031211734
Loss at iteration 1010 : 0.0004066872061230242
Loss at iteration 1020 : 0.004320709966123104
Loss at iteration 1030 : 0.00034771140781231225
Loss at iteration 1040 : 0.0003092488623224199
Loss at iteration 1050 : 0.00031791016226634383
Loss at iteration 1060 : 0.009564260020852089
Loss at iteration 1070 : 0.00024250864225905389
Loss at iteration 1080 : 0.004927625879645348
Loss at iteration 1090 : 0.0002995958784595132
Loss at iteration 1100 : 0.0004437446186784655
Loss at iteration 1110 : 0.0005739122861996293
Loss at iteration 1120 : 0.007085565477609634
Loss at iteration 1130 : 0.0028526741079986095
Loss at iteration 1140 : 0.00458791246637702
Loss at iteration 1150 : 0.0003138062311336398
Loss at iteration 1160 : 0.0003433372767176479
Loss at iteration 1170 : 8.94237746251747e-05
Loss at iteration 1180 : 0.00030411279294639826
Loss at iteration 1190 : 0.0023816502653062344
Loss at iteration 1200 : 0.0012008826015517116
Loss at iteration 1210 : 0.00022391488892026246
Loss at iteration 1220 : 0.004806318320333958
Loss at iteration 1230 : 0.00013366146595217288
Loss at iteration 1240 : 0.002606550930067897
Loss at iteration 1250 : 0.0017746828962117434
Loss at iteration 1260 : 5.0748891226248816e-05
Loss at iteration 1270 : 0.001662408816628158
Loss at iteration 1280 : 0.0006832903018221259
Loss at iteration 1290 : 0.00035578059032559395
Loss at iteration 1300 : 0.0002463046694174409
Loss at iteration 1310 : 0.00017507656593807042
Loss at iteration 1320 : 0.0007837010198272765
Loss at iteration 1330 : 0.0005958459223620594
Loss at iteration 1340 : 8.377268386539072e-05
Loss at iteration 1350 : 0.0014221135061234236
Loss at iteration 1360 : 0.0030288370326161385
Loss at iteration 1370 : 0.00572750810533762
Loss at iteration 1380 : 0.0021939347498118877
Loss at iteration 1390 : 0.002191236475482583
Loss at iteration 1400 : 0.00023193842207547277
Loss at iteration 1410 : 0.0003037938440684229
Loss at iteration 1420 : 0.00013624799612443894
Loss at iteration 1430 : 0.000477861613035202
Loss at iteration 1440 : 0.00017736019799485803
Loss at iteration 1450 : 0.00036692869616672397
Loss at iteration 1460 : 0.0017786517273634672
Loss at iteration 1470 : 0.00011238191655138507
Loss at iteration 1480 : 0.00013929199485573918
Loss at iteration 1490 : 8.664426422910765e-05
Loss at iteration 1500 : 0.0019806467462331057
Loss at iteration 1510 : 0.0021483490709215403
Loss at iteration 1520 : 0.0007706711767241359
Loss at iteration 1530 : 0.0005915577057749033
Loss at iteration 1540 : 0.0003214898461010307
Loss at iteration 1550 : 0.00039748140261508524
Loss at iteration 1560 : 0.0035472209565341473
Loss at iteration 1570 : 0.0001796754659153521
Loss at iteration 1580 : 0.004290229640901089
Loss at iteration 1590 : 0.0004021876666229218
Loss at iteration 1600 : 0.0006529800593852997
Loss at iteration 1610 : 0.0016784673789516091
Loss at iteration 1620 : 0.0005042213015258312
Loss at iteration 1630 : 0.003623568918555975
Loss at iteration 1640 : 0.003131039207801223
Loss at iteration 1650 : 0.0033572399988770485
Loss at iteration 1660 : 0.00016848064842633903
Loss at iteration 1670 : 0.0005821597878821194
Loss at iteration 1680 : 0.00018539992743171751
Loss at iteration 1690 : 0.0003435018006712198
Loss at iteration 1700 : 0.001066437573172152
Loss at iteration 1710 : 0.005167952738702297
Loss at iteration 1720 : 0.0005653687985613942
Loss at iteration 1730 : 0.0001583382545504719
Loss at iteration 1740 : 0.003612873610109091
Loss at iteration 1750 : 0.0001837597374105826
The SSIM Value is: 0.985494040445084
The PSNR Value is: 46.69707940433519
the epoch is: 27
Loss at iteration 10 : 0.0038678499404340982
Loss at iteration 20 : 0.0005394433392211795
Loss at iteration 30 : 0.0007196158403530717
Loss at iteration 40 : 0.000118071555334609
Loss at iteration 50 : 7.344342157011852e-05
Loss at iteration 60 : 0.002344256965443492
Loss at iteration 70 : 0.00017586663307156414
Loss at iteration 80 : 0.0028812794480472803
Loss at iteration 90 : 0.003905093064531684
Loss at iteration 100 : 0.0016321346629410982
Loss at iteration 110 : 0.00041915435576811433
Loss at iteration 120 : 0.000215162115637213
Loss at iteration 130 : 0.00018879471463151276
Loss at iteration 140 : 0.00024946965277194977
Loss at iteration 150 : 0.0018876171670854092
Loss at iteration 160 : 0.00027111361850984395
Loss at iteration 170 : 0.0013263049768283963
Loss at iteration 180 : 0.0009725068230181932
Loss at iteration 190 : 0.0016039410838857293
Loss at iteration 200 : 0.0008191170636564493
Loss at iteration 210 : 0.00012053086538799107
Loss at iteration 220 : 0.001238637720234692
Loss at iteration 230 : 0.0007401497568935156
Loss at iteration 240 : 0.0003340642433613539
Loss at iteration 250 : 0.0002768197446130216
Loss at iteration 260 : 0.0031551122665405273
Loss at iteration 270 : 0.0028847879730165005
Loss at iteration 280 : 0.00020679141744039953
Loss at iteration 290 : 0.00010074856254504994
Loss at iteration 300 : 0.00014512946654576808
Loss at iteration 310 : 0.0037710261531174183
Loss at iteration 320 : 0.00014253794506657869
Loss at iteration 330 : 0.0007099273498170078
Loss at iteration 340 : 0.00017801127978600562
Loss at iteration 350 : 0.00022105977404862642
Loss at iteration 360 : 0.00032241555163636804
Loss at iteration 370 : 0.0019416220020502806
Loss at iteration 380 : 0.00025312002981081605
Loss at iteration 390 : 0.0025902255438268185
Loss at iteration 400 : 0.00025009168894030154
Loss at iteration 410 : 0.0002547000767663121
Loss at iteration 420 : 0.0010403813794255257
Loss at iteration 430 : 0.001386910444125533
Loss at iteration 440 : 0.00041382183553650975
Loss at iteration 450 : 9.218882769346237e-05
Loss at iteration 460 : 0.0003394716768525541
Loss at iteration 470 : 0.00038272180245257914
Loss at iteration 480 : 2.6931880711345002e-05
Loss at iteration 490 : 0.00020430912263691425
Loss at iteration 500 : 0.0005536926910281181
Loss at iteration 510 : 8.277117012767121e-05
Loss at iteration 520 : 0.0017014407785609365
Loss at iteration 530 : 0.00011669047671603039
Loss at iteration 540 : 0.005424307193607092
Loss at iteration 550 : 0.0021177218295633793
Loss at iteration 560 : 0.00039657301385886967
Loss at iteration 570 : 0.00010508691048016772
Loss at iteration 580 : 8.597598935011774e-05
Loss at iteration 590 : 0.0004934349562972784
Loss at iteration 600 : 0.0005757981562055647
Loss at iteration 610 : 9.906535706249997e-05
Loss at iteration 620 : 0.0022068247199058533
Loss at iteration 630 : 0.0030045565217733383
Loss at iteration 640 : 0.0010622431291267276
Loss at iteration 650 : 0.0028410861268639565
Loss at iteration 660 : 0.0011391552397981286
Loss at iteration 670 : 0.0005968133336864412
Loss at iteration 680 : 0.00030581551254726946
Loss at iteration 690 : 0.0002668114611878991
Loss at iteration 700 : 0.00015450692444574088
Loss at iteration 710 : 0.005257229320704937
Loss at iteration 720 : 0.0037673022598028183
Loss at iteration 730 : 7.693450606893748e-05
Loss at iteration 740 : 0.00012378327664919198
Loss at iteration 750 : 0.0003987395321018994
Loss at iteration 760 : 0.0008593337843194604
Loss at iteration 770 : 0.0002048266469500959
Loss at iteration 780 : 0.007167257368564606
Loss at iteration 790 : 0.00010737069533206522
Loss at iteration 800 : 0.0005418703076429665
Loss at iteration 810 : 0.0003096899017691612
Loss at iteration 820 : 0.00011781062494264916
Loss at iteration 830 : 0.00033334444742649794
Loss at iteration 840 : 0.0002749113773461431
Loss at iteration 850 : 0.0004052785807289183
Loss at iteration 860 : 0.0035436339676380157
Loss at iteration 870 : 0.0005672226543538272
Loss at iteration 880 : 0.00023214682005345821
Loss at iteration 890 : 0.004132403992116451
Loss at iteration 900 : 0.0001416015875292942
Loss at iteration 910 : 0.002121706958860159
Loss at iteration 920 : 0.0009492840617895126
Loss at iteration 930 : 0.0002783306408673525
Loss at iteration 940 : 0.00019822161993943155
Loss at iteration 950 : 0.000568801595363766
Loss at iteration 960 : 0.0022928614635020494
Loss at iteration 970 : 0.0006586889503523707
Loss at iteration 980 : 0.0004514512838795781
Loss at iteration 990 : 0.002276443410664797
Loss at iteration 1000 : 5.716376472264528e-05
Loss at iteration 1010 : 0.0021056118421256542
Loss at iteration 1020 : 0.0001763992477208376
Loss at iteration 1030 : 5.476827209349722e-05
Loss at iteration 1040 : 0.0012831224594265223
Loss at iteration 1050 : 0.00047746431664563715
Loss at iteration 1060 : 0.0035849646665155888
Loss at iteration 1070 : 0.0003443698806222528
Loss at iteration 1080 : 0.0007284905877895653
Loss at iteration 1090 : 0.0004107053973712027
Loss at iteration 1100 : 0.0024103533942252398
Loss at iteration 1110 : 0.00014721063780598342
Loss at iteration 1120 : 0.0033629455137997866
Loss at iteration 1130 : 0.00035899539943784475
Loss at iteration 1140 : 0.00010516679321881384
Loss at iteration 1150 : 0.0007168359006755054
Loss at iteration 1160 : 0.0007867502281442285
Loss at iteration 1170 : 0.0026625553146004677
Loss at iteration 1180 : 0.002903685439378023
Loss at iteration 1190 : 0.00027765173581428826
Loss at iteration 1200 : 0.00047798140440136194
Loss at iteration 1210 : 0.0023751265835016966
Loss at iteration 1220 : 0.0007349741645157337
Loss at iteration 1230 : 0.00022797836572863162
Loss at iteration 1240 : 0.0014883774565532804
Loss at iteration 1250 : 0.0003790038754232228
Loss at iteration 1260 : 9.609328117221594e-05
Loss at iteration 1270 : 0.00012366024020593613
Loss at iteration 1280 : 0.00012552528642117977
Loss at iteration 1290 : 0.0001013030851026997
Loss at iteration 1300 : 0.00048048992175608873
Loss at iteration 1310 : 0.0037543829530477524
Loss at iteration 1320 : 0.00025671650655567646
Loss at iteration 1330 : 0.00017335274606011808
Loss at iteration 1340 : 0.00015023630112409592
Loss at iteration 1350 : 0.00028807303169742227
Loss at iteration 1360 : 0.0023586940951645374
Loss at iteration 1370 : 0.0009504264453426003
Loss at iteration 1380 : 0.0003100138856098056
Loss at iteration 1390 : 0.00018303198157809675
Loss at iteration 1400 : 0.0006022868910804391
Loss at iteration 1410 : 0.00012616867024917156
Loss at iteration 1420 : 0.006671460345387459
Loss at iteration 1430 : 8.1038182543125e-05
Loss at iteration 1440 : 0.000374581606592983
Loss at iteration 1450 : 0.0007222244748845696
Loss at iteration 1460 : 0.0008809507708065212
Loss at iteration 1470 : 0.003912209067493677
Loss at iteration 1480 : 0.0002818295906763524
Loss at iteration 1490 : 0.0006879246793687344
Loss at iteration 1500 : 0.001345743890851736
Loss at iteration 1510 : 0.0026127109304070473
Loss at iteration 1520 : 0.0037193940952420235
Loss at iteration 1530 : 0.0006263567483983934
Loss at iteration 1540 : 0.00017542234854772687
Loss at iteration 1550 : 0.0008698556339368224
Loss at iteration 1560 : 0.0016281919088214636
Loss at iteration 1570 : 0.00026871112640947104
Loss at iteration 1580 : 0.0009154132567346096
Loss at iteration 1590 : 0.0003601409844122827
Loss at iteration 1600 : 0.0036107380874454975
Loss at iteration 1610 : 0.00193495093844831
Loss at iteration 1620 : 0.00021235444000922143
Loss at iteration 1630 : 0.000496704364195466
Loss at iteration 1640 : 0.00029279623413458467
Loss at iteration 1650 : 0.00027626455994322896
Loss at iteration 1660 : 0.0001745046756695956
Loss at iteration 1670 : 0.0009438616689294577
Loss at iteration 1680 : 0.000726704893168062
Loss at iteration 1690 : 0.004904983565211296
Loss at iteration 1700 : 0.00038960762321949005
Loss at iteration 1710 : 0.00026027736021205783
Loss at iteration 1720 : 0.0037809184286743402
Loss at iteration 1730 : 0.0005204480257816613
Loss at iteration 1740 : 0.0004726510087493807
Loss at iteration 1750 : 0.0017791371792554855
The SSIM Value is: 0.9786900338359866
The PSNR Value is: 46.20755508607705
the epoch is: 28
Loss at iteration 10 : 0.0023372643627226353
Loss at iteration 20 : 0.00026691090897656977
Loss at iteration 30 : 0.0005185240879654884
Loss at iteration 40 : 0.00011773304140660912
Loss at iteration 50 : 0.0016455803997814655
Loss at iteration 60 : 0.0005719546461477876
Loss at iteration 70 : 0.0001700347347650677
Loss at iteration 80 : 0.0011250044917687774
Loss at iteration 90 : 0.0001557929499540478
Loss at iteration 100 : 0.00018809472385328263
Loss at iteration 110 : 0.003681558184325695
Loss at iteration 120 : 0.0006366926827467978
Loss at iteration 130 : 4.730057844426483e-05
Loss at iteration 140 : 0.00012470362707972527
Loss at iteration 150 : 0.004021236672997475
Loss at iteration 160 : 0.0006475773407146335
Loss at iteration 170 : 0.0006694998010061681
Loss at iteration 180 : 0.00017500334070064127
Loss at iteration 190 : 0.00029267248464748263
Loss at iteration 200 : 0.003618999384343624
Loss at iteration 210 : 0.0003427505725994706
Loss at iteration 220 : 0.0002476093650329858
Loss at iteration 230 : 0.0066389222629368305
Loss at iteration 240 : 0.003866990329697728
Loss at iteration 250 : 0.0003468348004389554
Loss at iteration 260 : 0.00010497935727471486
Loss at iteration 270 : 0.00029935009661130607
Loss at iteration 280 : 7.50196777516976e-05
Loss at iteration 290 : 0.004698963835835457
Loss at iteration 300 : 0.003436723491176963
Loss at iteration 310 : 0.00026251390227116644
Loss at iteration 320 : 0.0003042130556423217
Loss at iteration 330 : 0.002047128975391388
Loss at iteration 340 : 0.0015723004471510649
Loss at iteration 350 : 0.00016395928105339408
Loss at iteration 360 : 0.00012671365402638912
Loss at iteration 370 : 0.00022975254978518933
Loss at iteration 380 : 0.004333728924393654
Loss at iteration 390 : 0.0039005479775369167
Loss at iteration 400 : 0.0018877441762015224
Loss at iteration 410 : 0.0035151634365320206
Loss at iteration 420 : 0.000363274069968611
Loss at iteration 430 : 0.004615587182343006
Loss at iteration 440 : 0.0001952706661541015
Loss at iteration 450 : 0.0001024586454150267
Loss at iteration 460 : 0.00022367639758158475
Loss at iteration 470 : 0.0006540096364915371
Loss at iteration 480 : 5.725153096136637e-05
Loss at iteration 490 : 0.00015569067909382284
Loss at iteration 500 : 0.0010545778786763549
Loss at iteration 510 : 0.00016908424731809646
Loss at iteration 520 : 0.00011165898467879742
Loss at iteration 530 : 0.003655955195426941
Loss at iteration 540 : 0.0012748542940244079
Loss at iteration 550 : 0.00021609055693261325
Loss at iteration 560 : 0.0029244706965982914
Loss at iteration 570 : 0.0004560541710816324
Loss at iteration 580 : 0.0008232747204601765
Loss at iteration 590 : 0.005914407782256603
Loss at iteration 600 : 5.918341048527509e-05
Loss at iteration 610 : 0.0003345111617818475
Loss at iteration 620 : 0.00035472388844937086
Loss at iteration 630 : 0.0005634765839204192
Loss at iteration 640 : 0.00243487604893744
Loss at iteration 650 : 0.0002582500164862722
Loss at iteration 660 : 0.00019890103430952877
Loss at iteration 670 : 0.00016570260049775243
Loss at iteration 680 : 0.0005153304664418101
Loss at iteration 690 : 0.00363763514906168
Loss at iteration 700 : 0.0006018044659867883
Loss at iteration 710 : 5.3563395340461284e-05
Loss at iteration 720 : 0.00012717474601231515
Loss at iteration 730 : 0.0023938952945172787
Loss at iteration 740 : 0.006011562421917915
Loss at iteration 750 : 0.0007182942936196923
Loss at iteration 760 : 0.0004683994920924306
Loss at iteration 770 : 0.0007103399257175624
Loss at iteration 780 : 0.001585328602232039
Loss at iteration 790 : 0.0013204095885157585
Loss at iteration 800 : 0.0013259504921734333
Loss at iteration 810 : 0.0005575675168074667
Loss at iteration 820 : 0.0020227713976055384
Loss at iteration 830 : 0.00029501947574317455
Loss at iteration 840 : 0.0007785417838022113
Loss at iteration 850 : 0.0002099510165862739
Loss at iteration 860 : 0.002822446171194315
Loss at iteration 870 : 0.00010699224367272109
Loss at iteration 880 : 6.825031596235931e-05
Loss at iteration 890 : 0.0013930763816460967
Loss at iteration 900 : 0.003032032400369644
Loss at iteration 910 : 0.000533152895513922
Loss at iteration 920 : 0.0003472117241472006
Loss at iteration 930 : 0.00028948939871042967
Loss at iteration 940 : 0.00023719173623248935
Loss at iteration 950 : 0.0033385129645466805
Loss at iteration 960 : 0.0032753157429397106
Loss at iteration 970 : 0.00021471298532560468
Loss at iteration 980 : 0.0011638968717306852
Loss at iteration 990 : 0.0001202388884848915
Loss at iteration 1000 : 0.00018482340965420008
Loss at iteration 1010 : 0.006087471731007099
Loss at iteration 1020 : 0.0008032761979848146
Loss at iteration 1030 : 0.000684700789861381
Loss at iteration 1040 : 0.0006441156729124486
Loss at iteration 1050 : 0.00046534743160009384
Loss at iteration 1060 : 0.00024481600848957896
Loss at iteration 1070 : 0.00015326798893511295
Loss at iteration 1080 : 0.0010492150904610753
Loss at iteration 1090 : 0.00018388970056548715
Loss at iteration 1100 : 0.0036700915079563856
Loss at iteration 1110 : 0.00011488900054246187
Loss at iteration 1120 : 0.0017730172257870436
Loss at iteration 1130 : 0.0014890226302668452
Loss at iteration 1140 : 0.00026774831349030137
Loss at iteration 1150 : 6.316602230072021e-05
Loss at iteration 1160 : 0.0001611318439245224
Loss at iteration 1170 : 0.0032583579886704683
Loss at iteration 1180 : 0.0007248598849400878
Loss at iteration 1190 : 0.004482886288315058
Loss at iteration 1200 : 6.732686597388238e-05
Loss at iteration 1210 : 0.00016254140064120293
Loss at iteration 1220 : 0.00017089744505938143
Loss at iteration 1230 : 0.0004091265145689249
Loss at iteration 1240 : 0.0013747336342930794
Loss at iteration 1250 : 0.0017021514941006899
Loss at iteration 1260 : 0.0004958069184795022
Loss at iteration 1270 : 0.0004229481564834714
Loss at iteration 1280 : 7.387074583675712e-05
Loss at iteration 1290 : 0.00011813353921752423
Loss at iteration 1300 : 0.0016823739279061556
Loss at iteration 1310 : 0.0002472467895131558
Loss at iteration 1320 : 0.0033441861160099506
Loss at iteration 1330 : 0.002022793982177973
Loss at iteration 1340 : 0.0012168544344604015
Loss at iteration 1350 : 0.0016194736817851663
Loss at iteration 1360 : 0.0022717337124049664
Loss at iteration 1370 : 0.00010278097033733502
Loss at iteration 1380 : 0.00043313438072800636
Loss at iteration 1390 : 0.0004801223985850811
Loss at iteration 1400 : 0.0026640251744538546
Loss at iteration 1410 : 0.00035339477472007275
Loss at iteration 1420 : 0.0017505045980215073
Loss at iteration 1430 : 0.000134000409161672
Loss at iteration 1440 : 0.0001483184314565733
Loss at iteration 1450 : 6.739264790667221e-05
Loss at iteration 1460 : 0.00021385439322330058
Loss at iteration 1470 : 0.0004098417120985687
Loss at iteration 1480 : 0.00194092420861125
Loss at iteration 1490 : 0.0021716924384236336
Loss at iteration 1500 : 0.00013081893848720938
Loss at iteration 1510 : 0.0053266845643520355
Loss at iteration 1520 : 0.00013720904826186597
Loss at iteration 1530 : 0.00017541924898978323
Loss at iteration 1540 : 9.863393643172458e-05
Loss at iteration 1550 : 0.00038568914169445634
Loss at iteration 1560 : 0.0009199735941365361
Loss at iteration 1570 : 0.0015502520836889744
Loss at iteration 1580 : 0.0005685212090611458
Loss at iteration 1590 : 0.0014142822474241257
Loss at iteration 1600 : 0.000596823578234762
Loss at iteration 1610 : 0.00014510467008221895
Loss at iteration 1620 : 0.0002798445930238813
Loss at iteration 1630 : 0.0035893013700842857
Loss at iteration 1640 : 0.0003147960524074733
Loss at iteration 1650 : 0.00017530590412206948
Loss at iteration 1660 : 0.0008874243358150125
Loss at iteration 1670 : 0.00016172559116967022
Loss at iteration 1680 : 0.0006144187645986676
Loss at iteration 1690 : 0.00014851344167254865
Loss at iteration 1700 : 0.0009033243986777961
Loss at iteration 1710 : 4.703492231783457e-05
Loss at iteration 1720 : 0.00010565400589257479
Loss at iteration 1730 : 7.997498323675245e-05
Loss at iteration 1740 : 0.00071593007305637
Loss at iteration 1750 : 0.0002048177266260609
The SSIM Value is: 0.9791012934125992
The PSNR Value is: 46.03059151729298
the epoch is: 29
Loss at iteration 10 : 0.0008803837699815631
Loss at iteration 20 : 0.001527783926576376
Loss at iteration 30 : 0.0005837418138980865
Loss at iteration 40 : 0.00026913732290267944
Loss at iteration 50 : 0.0034992529544979334
Loss at iteration 60 : 0.0004175215435680002
Loss at iteration 70 : 0.00031155048054642975
Loss at iteration 80 : 0.00065060262568295
Loss at iteration 90 : 0.00047719525173306465
Loss at iteration 100 : 0.000620587554294616
Loss at iteration 110 : 0.0002918402024079114
Loss at iteration 120 : 0.0019843531772494316
Loss at iteration 130 : 0.0002218435547547415
Loss at iteration 140 : 0.0005026257713325322
Loss at iteration 150 : 0.00025250701582990587
Loss at iteration 160 : 0.00010015929001383483
Loss at iteration 170 : 0.0004021958739031106
Loss at iteration 180 : 0.001168163027614355
Loss at iteration 190 : 0.0014235780108720064
Loss at iteration 200 : 0.0005246255313977599
Loss at iteration 210 : 0.004066690802574158
Loss at iteration 220 : 0.0005390208098106086
Loss at iteration 230 : 0.0023869650904089212
Loss at iteration 240 : 0.001936787273734808
Loss at iteration 250 : 0.000320371676934883
Loss at iteration 260 : 9.798719838727266e-05
Loss at iteration 270 : 0.0024815904907882214
Loss at iteration 280 : 0.00038265425246208906
Loss at iteration 290 : 0.00011830207949969918
Loss at iteration 300 : 0.0005539769772440195
Loss at iteration 310 : 0.001243625651113689
Loss at iteration 320 : 0.0001416870072716847
Loss at iteration 330 : 0.00012910636723972857
Loss at iteration 340 : 6.446530460380018e-05
Loss at iteration 350 : 0.0006318205269053578
Loss at iteration 360 : 0.00028974952874705195
Loss at iteration 370 : 0.0004044820670969784
Loss at iteration 380 : 0.0005456239450722933
Loss at iteration 390 : 0.00274518970400095
Loss at iteration 400 : 0.00033411706681363285
Loss at iteration 410 : 0.00013305361790116876
Loss at iteration 420 : 0.0010642082197591662
Loss at iteration 430 : 0.0004789248632732779
Loss at iteration 440 : 0.008149873465299606
Loss at iteration 450 : 0.0042247348465025425
Loss at iteration 460 : 0.0016805214108899236
Loss at iteration 470 : 0.00021751831809524447
Loss at iteration 480 : 0.000511808495502919
Loss at iteration 490 : 0.003429840784519911
Loss at iteration 500 : 0.0009800744010135531
Loss at iteration 510 : 8.62222004798241e-05
Loss at iteration 520 : 0.00047566290595568717
Loss at iteration 530 : 0.0019237471278756857
Loss at iteration 540 : 0.0002146827755495906
Loss at iteration 550 : 0.0005231152754276991
Loss at iteration 560 : 8.996355609269813e-05
Loss at iteration 570 : 0.0003330584440845996
Loss at iteration 580 : 0.001486603170633316
Loss at iteration 590 : 0.00011500119580887258
Loss at iteration 600 : 0.005151564255356789
Loss at iteration 610 : 0.0004240044509060681
Loss at iteration 620 : 0.0002841244568116963
Loss at iteration 630 : 9.620255877962336e-05
Loss at iteration 640 : 8.100066770566627e-05
Loss at iteration 650 : 0.0010458636097609997
Loss at iteration 660 : 0.0002945117885246873
Loss at iteration 670 : 0.0023009744472801685
Loss at iteration 680 : 0.000421792792622
Loss at iteration 690 : 0.0001833596616052091
Loss at iteration 700 : 0.0005409839795902371
Loss at iteration 710 : 0.005452083423733711
Loss at iteration 720 : 9.20481834327802e-05
Loss at iteration 730 : 0.00017480223323218524
Loss at iteration 740 : 0.0001106920390157029
Loss at iteration 750 : 0.003999321721494198
Loss at iteration 760 : 0.0001292161614401266
Loss at iteration 770 : 0.00010907176329055801
Loss at iteration 780 : 0.00014519799151457846
Loss at iteration 790 : 0.0005252932896837592
Loss at iteration 800 : 0.00031021091854199767
Loss at iteration 810 : 0.0027347260620445013
Loss at iteration 820 : 7.219552935566753e-05
Loss at iteration 830 : 0.00024705874966457486
Loss at iteration 840 : 3.254000694141723e-05
Loss at iteration 850 : 0.00022039981558918953
Loss at iteration 860 : 0.0015703558456152678
Loss at iteration 870 : 0.004634397104382515
Loss at iteration 880 : 0.00024671212304383516
Loss at iteration 890 : 0.00017626733460929245
Loss at iteration 900 : 0.00017614653916098177
Loss at iteration 910 : 0.00012085540947737172
Loss at iteration 920 : 0.00019037876336369663
Loss at iteration 930 : 0.00030669488478451967
Loss at iteration 940 : 0.0046646203845739365
Loss at iteration 950 : 0.0070360321551561356
Loss at iteration 960 : 0.000371987116523087
Loss at iteration 970 : 9.644606325309724e-05
Loss at iteration 980 : 0.0024320699740201235
Loss at iteration 990 : 0.003260388970375061
Loss at iteration 1000 : 0.002022383501753211
Loss at iteration 1010 : 0.0003598894109018147
Loss at iteration 1020 : 0.00021486215700861067
Loss at iteration 1030 : 0.0028010259848088026
Loss at iteration 1040 : 0.0001817578886402771
Loss at iteration 1050 : 0.00010584421397652477
Loss at iteration 1060 : 0.0025182433892041445
Loss at iteration 1070 : 0.00030544260516762733
Loss at iteration 1080 : 5.3555086196865886e-05
Loss at iteration 1090 : 0.000505708740092814
Loss at iteration 1100 : 0.0001373871782561764
Loss at iteration 1110 : 0.0007282739388756454
Loss at iteration 1120 : 0.00031923394999466836
Loss at iteration 1130 : 0.00035426495014689863
Loss at iteration 1140 : 0.00296036247164011
Loss at iteration 1150 : 0.0033792145550251007
Loss at iteration 1160 : 0.00033360207453370094
Loss at iteration 1170 : 0.004119656048715115
Loss at iteration 1180 : 8.903086563805118e-05
Loss at iteration 1190 : 0.00016634527128189802
Loss at iteration 1200 : 0.001994830323383212
Loss at iteration 1210 : 0.0025213030166924
Loss at iteration 1220 : 0.001191446790471673
Loss at iteration 1230 : 0.0001554350310470909
Loss at iteration 1240 : 0.0004188024322502315
Loss at iteration 1250 : 0.000881910091266036
Loss at iteration 1260 : 0.0010402328334748745
Loss at iteration 1270 : 0.0014070033794268966
Loss at iteration 1280 : 0.00023601806606166065
Loss at iteration 1290 : 0.00015039343270473182
Loss at iteration 1300 : 0.00020495803619269282
Loss at iteration 1310 : 0.0001653179933782667
Loss at iteration 1320 : 0.00331804808229208
Loss at iteration 1330 : 0.0006216801702976227
Loss at iteration 1340 : 0.00029785832157358527
Loss at iteration 1350 : 0.005907628685235977
Loss at iteration 1360 : 0.001993752783164382
Loss at iteration 1370 : 0.00016101459914352745
Loss at iteration 1380 : 0.0019390650559216738
Loss at iteration 1390 : 0.005018758587539196
Loss at iteration 1400 : 0.0015552130062133074
Loss at iteration 1410 : 7.146002462832257e-05
Loss at iteration 1420 : 0.002508918521925807
Loss at iteration 1430 : 0.0006238214555196464
Loss at iteration 1440 : 0.003360630478709936
Loss at iteration 1450 : 0.0010332576930522919
Loss at iteration 1460 : 7.171824108809233e-05
Loss at iteration 1470 : 7.725150499027222e-05
Loss at iteration 1480 : 0.0010209546890109777
Loss at iteration 1490 : 0.00023616006365045905
Loss at iteration 1500 : 0.002029730472713709
Loss at iteration 1510 : 0.00048259174218401313
Loss at iteration 1520 : 0.0002014550263993442
Loss at iteration 1530 : 0.00017386012768838555
Loss at iteration 1540 : 0.0021940073929727077
Loss at iteration 1550 : 0.00014249734522309154
Loss at iteration 1560 : 0.00013970305735711008
Loss at iteration 1570 : 8.543187868781388e-05
Loss at iteration 1580 : 0.0001401798945153132
Loss at iteration 1590 : 0.00022953105508349836
Loss at iteration 1600 : 0.005472918506711721
Loss at iteration 1610 : 0.0007647866732440889
Loss at iteration 1620 : 0.00014201790327206254
Loss at iteration 1630 : 0.0026240390725433826
Loss at iteration 1640 : 0.00017036774079315364
Loss at iteration 1650 : 0.00017535068036522716
Loss at iteration 1660 : 0.00024673540610820055
Loss at iteration 1670 : 0.001831181813031435
Loss at iteration 1680 : 0.0002739567426033318
Loss at iteration 1690 : 0.0007307081250473857
Loss at iteration 1700 : 0.002361184684559703
Loss at iteration 1710 : 0.0003754646750167012
Loss at iteration 1720 : 0.0024805234279483557
Loss at iteration 1730 : 0.00020773644791916013
Loss at iteration 1740 : 0.0002118592383340001
Loss at iteration 1750 : 0.0010268103796988726
The SSIM Value is: 0.9798103838765149
The PSNR Value is: 46.382141617426264
the epoch is: 30
Loss at iteration 10 : 0.0018410349730402231
Loss at iteration 20 : 0.0004379588062874973
Loss at iteration 30 : 0.002510011661797762
Loss at iteration 40 : 0.0014765826053917408
Loss at iteration 50 : 0.0030003683641552925
Loss at iteration 60 : 0.000489002326503396
Loss at iteration 70 : 0.0023352589923888445
Loss at iteration 80 : 0.000175794237293303
Loss at iteration 90 : 0.0010285935131832957
Loss at iteration 100 : 0.00011029122833861038
Loss at iteration 110 : 0.005060683004558086
Loss at iteration 120 : 0.0007547858403995633
Loss at iteration 130 : 0.0001864458608906716
Loss at iteration 140 : 0.00017751328414306045
Loss at iteration 150 : 0.0014484574785456061
Loss at iteration 160 : 0.0004688955959863961
Loss at iteration 170 : 0.0005131837096996605
Loss at iteration 180 : 0.005345748737454414
Loss at iteration 190 : 0.004321957007050514
Loss at iteration 200 : 0.0005493454518727958
Loss at iteration 210 : 0.0009751389152370393
Loss at iteration 220 : 0.00010401882900623605
Loss at iteration 230 : 0.000894592609256506
Loss at iteration 240 : 0.00014279945753514767
Loss at iteration 250 : 0.002570509910583496
Loss at iteration 260 : 0.00031927262898534536
Loss at iteration 270 : 0.0006862977752462029
Loss at iteration 280 : 0.000463737640529871
Loss at iteration 290 : 0.0002297827013535425
Loss at iteration 300 : 0.0017422873061150312
Loss at iteration 310 : 0.005056688096374273
Loss at iteration 320 : 0.00018805102445185184
Loss at iteration 330 : 0.0002815767074935138
Loss at iteration 340 : 0.00012474737013690174
Loss at iteration 350 : 0.00028019107412546873
Loss at iteration 360 : 0.00034964492078870535
Loss at iteration 370 : 0.004145397804677486
Loss at iteration 380 : 0.0030195179861038923
Loss at iteration 390 : 0.0005928755854256451
Loss at iteration 400 : 0.00010275490785716102
Loss at iteration 410 : 0.00011539736442500725
Loss at iteration 420 : 0.0011825053952634335
Loss at iteration 430 : 0.00018449308117851615
Loss at iteration 440 : 0.0004971661255694926
Loss at iteration 450 : 0.00011223361798329279
Loss at iteration 460 : 0.000281237909803167
Loss at iteration 470 : 0.000242655718466267
Loss at iteration 480 : 0.0005448395968414843
Loss at iteration 490 : 0.00012551034160424024
Loss at iteration 500 : 0.00022224993153940886
Loss at iteration 510 : 0.0017017470672726631
Loss at iteration 520 : 0.00019950818386860192
Loss at iteration 530 : 6.588807445950806e-05
Loss at iteration 540 : 0.0029654153622686863
Loss at iteration 550 : 0.0007517974590882659
Loss at iteration 560 : 0.002911355346441269
Loss at iteration 570 : 9.207159746438265e-05
Loss at iteration 580 : 0.00011390329746063799
Loss at iteration 590 : 0.00010365282651036978
Loss at iteration 600 : 0.00023108981258701533
Loss at iteration 610 : 0.0003662700473796576
Loss at iteration 620 : 0.00013964084791950881
Loss at iteration 630 : 0.00021319935331121087
Loss at iteration 640 : 0.00015969481319189072
Loss at iteration 650 : 0.004406379535794258
Loss at iteration 660 : 0.00021587713854387403
Loss at iteration 670 : 0.00022101422655396163
Loss at iteration 680 : 0.0039146640338003635
Loss at iteration 690 : 0.0001322814350714907
Loss at iteration 700 : 0.0006341454572975636
Loss at iteration 710 : 8.369307033717632e-05
Loss at iteration 720 : 0.0019793466199189425
Loss at iteration 730 : 0.0001331893727183342
Loss at iteration 740 : 0.001821435522288084
Loss at iteration 750 : 0.0003595009329728782
Loss at iteration 760 : 0.00012391449126880616
Loss at iteration 770 : 0.00036802445538342
Loss at iteration 780 : 0.0018347452860325575
Loss at iteration 790 : 0.0004539835499599576
Loss at iteration 800 : 0.00027378511731512845
Loss at iteration 810 : 0.0004267081676516682
Loss at iteration 820 : 0.00013915315503254533
Loss at iteration 830 : 0.0002888119488488883
Loss at iteration 840 : 0.0001263334124814719
Loss at iteration 850 : 0.00015442282892763615
Loss at iteration 860 : 0.0020608738996088505
Loss at iteration 870 : 0.00035196891985833645
Loss at iteration 880 : 0.0004893311997875571
Loss at iteration 890 : 0.0003207383560948074
Loss at iteration 900 : 0.0006209889543242753
Loss at iteration 910 : 0.00044125106069259346
Loss at iteration 920 : 0.00024956485140137374
Loss at iteration 930 : 0.00037177756894379854
Loss at iteration 940 : 0.00045685991062782705
Loss at iteration 950 : 0.0007180781103670597
Loss at iteration 960 : 0.0043943822383880615
Loss at iteration 970 : 0.00041648928890936077
Loss at iteration 980 : 0.00038003400550223887
Loss at iteration 990 : 0.00013617685181088746
Loss at iteration 1000 : 0.0003602331562433392
Loss at iteration 1010 : 0.00019171679741702974
Loss at iteration 1020 : 0.003909416496753693
Loss at iteration 1030 : 0.0003616187605075538
Loss at iteration 1040 : 0.0004462937358766794
Loss at iteration 1050 : 0.00027582660550251603
Loss at iteration 1060 : 6.197522452566773e-05
Loss at iteration 1070 : 0.0021809707395732403
Loss at iteration 1080 : 0.0002979841083288193
Loss at iteration 1090 : 0.00015291386807803065
Loss at iteration 1100 : 0.0003185646201018244
Loss at iteration 1110 : 0.0005021016695536673
Loss at iteration 1120 : 0.0006370616611093283
Loss at iteration 1130 : 0.00514806155115366
Loss at iteration 1140 : 0.0023903727997094393
Loss at iteration 1150 : 0.00032405342790298164
Loss at iteration 1160 : 0.0005296972813084722
Loss at iteration 1170 : 0.003794968593865633
Loss at iteration 1180 : 0.0006356460507959127
Loss at iteration 1190 : 0.0024264224339276552
Loss at iteration 1200 : 0.0008927915478125215
Loss at iteration 1210 : 0.00014933067723177373
Loss at iteration 1220 : 0.0034612342715263367
Loss at iteration 1230 : 0.0004552486934699118
Loss at iteration 1240 : 0.00012681591033469886
Loss at iteration 1250 : 0.003507353598251939
Loss at iteration 1260 : 0.00215360545553267
Loss at iteration 1270 : 0.0016262381104752421
Loss at iteration 1280 : 0.0031828158535063267
Loss at iteration 1290 : 0.00014074126374907792
Loss at iteration 1300 : 0.00061536964494735
Loss at iteration 1310 : 0.00034537125611677766
Loss at iteration 1320 : 0.0001467703259550035
Loss at iteration 1330 : 0.0007300922297872603
Loss at iteration 1340 : 0.0005586215993389487
Loss at iteration 1350 : 7.810628449078649e-05
Loss at iteration 1360 : 0.003019897732883692
Loss at iteration 1370 : 9.710330778034404e-05
Loss at iteration 1380 : 7.634041685378179e-05
Loss at iteration 1390 : 0.0001318655558861792
Loss at iteration 1400 : 0.00033175316639244556
Loss at iteration 1410 : 0.00023427011910825968
Loss at iteration 1420 : 0.0002365032269153744
Loss at iteration 1430 : 0.00012853648513555527
Loss at iteration 1440 : 0.001775436569005251
Loss at iteration 1450 : 0.00021025192108936608
Loss at iteration 1460 : 0.0002538309199735522
Loss at iteration 1470 : 0.0018672654405236244
Loss at iteration 1480 : 0.0039026797749102116
Loss at iteration 1490 : 0.00023821111244615167
Loss at iteration 1500 : 0.005842097103595734
Loss at iteration 1510 : 0.00013401366595644504
Loss at iteration 1520 : 0.0005342295626178384
Loss at iteration 1530 : 0.0035692653618752956
Loss at iteration 1540 : 0.0007135046762414277
Loss at iteration 1550 : 0.00036240826011635363
Loss at iteration 1560 : 0.0007055825553834438
Loss at iteration 1570 : 8.830065780784935e-05
Loss at iteration 1580 : 0.0005017691873945296
Loss at iteration 1590 : 0.00015416814130730927
Loss at iteration 1600 : 0.0005163629539310932
Loss at iteration 1610 : 0.00016570338630117476
Loss at iteration 1620 : 0.0003720566164702177
Loss at iteration 1630 : 0.00037251057801768184
Loss at iteration 1640 : 0.0024489015340805054
Loss at iteration 1650 : 6.984182982705534e-05
Loss at iteration 1660 : 0.00027559223235584795
Loss at iteration 1670 : 0.0002249702374683693
Loss at iteration 1680 : 0.0008998593548312783
Loss at iteration 1690 : 8.226155478041619e-05
Loss at iteration 1700 : 0.0007679619593545794
Loss at iteration 1710 : 0.00033736793557181954
Loss at iteration 1720 : 0.00011284794891253114
Loss at iteration 1730 : 0.00012176834570709616
Loss at iteration 1740 : 0.0002272554556839168
Loss at iteration 1750 : 0.0011088820174336433
The SSIM Value is: 0.9889791038067856
The PSNR Value is: 45.792635125735785
the epoch is: 31
Loss at iteration 10 : 0.00023597203835379332
Loss at iteration 20 : 7.435509178321809e-05
Loss at iteration 30 : 0.0007761672604829073
Loss at iteration 40 : 0.0035911602899432182
Loss at iteration 50 : 0.00018612244457472116
Loss at iteration 60 : 0.00045602762838825583
Loss at iteration 70 : 0.00015282336971722543
Loss at iteration 80 : 0.00025077027385123074
Loss at iteration 90 : 0.0006055907579138875
Loss at iteration 100 : 0.002745059784501791
Loss at iteration 110 : 0.0001854098227340728
Loss at iteration 120 : 0.0003267188440077007
Loss at iteration 130 : 0.0024160954635590315
Loss at iteration 140 : 0.0018776218639686704
Loss at iteration 150 : 0.001131426659412682
Loss at iteration 160 : 0.0018491061637178063
Loss at iteration 170 : 0.003288890467956662
Loss at iteration 180 : 0.0004967953427694738
Loss at iteration 190 : 0.0004975006449967623
Loss at iteration 200 : 0.0018209225963801146
Loss at iteration 210 : 0.005737763829529285
Loss at iteration 220 : 0.00022407791402656585
Loss at iteration 230 : 0.00033282145159319043
Loss at iteration 240 : 0.0004619007231667638
Loss at iteration 250 : 0.0004478046321310103
Loss at iteration 260 : 0.000326268607750535
Loss at iteration 270 : 0.0009791648481041193
Loss at iteration 280 : 0.002570781856775284
Loss at iteration 290 : 0.00026443376555107534
Loss at iteration 300 : 7.699709385633469e-05
Loss at iteration 310 : 0.00010464951628819108
Loss at iteration 320 : 7.0273905294016e-05
Loss at iteration 330 : 0.0007069592247717083
Loss at iteration 340 : 0.00018260107026435435
Loss at iteration 350 : 9.299753583036363e-05
Loss at iteration 360 : 0.0015046857297420502
Loss at iteration 370 : 0.000364077917765826
Loss at iteration 380 : 0.005327041260898113
Loss at iteration 390 : 9.885225153993815e-05
Loss at iteration 400 : 0.0030411193147301674
Loss at iteration 410 : 0.0021834387443959713
Loss at iteration 420 : 6.653708260273561e-05
Loss at iteration 430 : 5.9969621361233294e-05
Loss at iteration 440 : 0.00018756130884867162
Loss at iteration 450 : 0.001061371760442853
Loss at iteration 460 : 0.00177385238930583
Loss at iteration 470 : 0.00014084413123782724
Loss at iteration 480 : 0.00021377070515882224
Loss at iteration 490 : 0.00020776913152076304
Loss at iteration 500 : 0.00019988446729257703
Loss at iteration 510 : 0.0007718674023635685
Loss at iteration 520 : 0.002624342916533351
Loss at iteration 530 : 0.0014410458970814943
Loss at iteration 540 : 0.000696640694513917
Loss at iteration 550 : 4.261326466803439e-05
Loss at iteration 560 : 0.00658472441136837
Loss at iteration 570 : 0.003486827714368701
Loss at iteration 580 : 0.00027421387494541705
Loss at iteration 590 : 7.607948646182194e-05
Loss at iteration 600 : 8.608158532297239e-05
Loss at iteration 610 : 0.0037233317270874977
Loss at iteration 620 : 0.0007918743649497628
Loss at iteration 630 : 0.0014504882274195552
Loss at iteration 640 : 0.0007307942723855376
Loss at iteration 650 : 0.0012549541424959898
Loss at iteration 660 : 0.0005412079044617712
Loss at iteration 670 : 0.00012758966477122158
Loss at iteration 680 : 0.0029786473605781794
Loss at iteration 690 : 0.0006822202121838927
Loss at iteration 700 : 0.0010283604497089982
Loss at iteration 710 : 0.003063379554077983
Loss at iteration 720 : 0.0006846324540674686
Loss at iteration 730 : 0.00010597084474284202
Loss at iteration 740 : 0.00030521684675477445
Loss at iteration 750 : 0.0037720457185059786
Loss at iteration 760 : 0.002753044944256544
Loss at iteration 770 : 0.00015821073611732572
Loss at iteration 780 : 0.002111318986862898
Loss at iteration 790 : 0.0008605715702287853
Loss at iteration 800 : 0.00013401437900029123
Loss at iteration 810 : 6.420548015739769e-05
Loss at iteration 820 : 0.0005172768142074347
Loss at iteration 830 : 0.00017254073463845998
Loss at iteration 840 : 0.00036594568518921733
Loss at iteration 850 : 0.0007908992702141404
Loss at iteration 860 : 0.0003173840814270079
Loss at iteration 870 : 0.009441159665584564
Loss at iteration 880 : 0.0034653027541935444
Loss at iteration 890 : 0.0006554336869157851
Loss at iteration 900 : 0.00022136933694127947
Loss at iteration 910 : 0.0036295766476541758
Loss at iteration 920 : 0.0005421196110546589
Loss at iteration 930 : 0.00015898869605734944
Loss at iteration 940 : 0.00226914812810719
Loss at iteration 950 : 8.254639396909624e-05
Loss at iteration 960 : 0.0006754780770279467
Loss at iteration 970 : 0.0020580049604177475
Loss at iteration 980 : 7.196735532488674e-05
Loss at iteration 990 : 0.001028842874802649
Loss at iteration 1000 : 0.0023640086874365807
Loss at iteration 1010 : 0.00024272182781714946
Loss at iteration 1020 : 0.00028740696143358946
Loss at iteration 1030 : 0.00028378673596307635
Loss at iteration 1040 : 0.00015134605928324163
Loss at iteration 1050 : 0.0005274263676255941
Loss at iteration 1060 : 0.0035512391477823257
Loss at iteration 1070 : 0.0004713207308668643
Loss at iteration 1080 : 0.0031610659789294004
Loss at iteration 1090 : 0.00017648082575760782
Loss at iteration 1100 : 0.00022169234580360353
Loss at iteration 1110 : 0.00020441354718059301
Loss at iteration 1120 : 0.0026915348134934902
Loss at iteration 1130 : 9.082375618163496e-05
Loss at iteration 1140 : 0.00010650863987393677
Loss at iteration 1150 : 0.0010170894674956799
Loss at iteration 1160 : 0.00028672098414972425
Loss at iteration 1170 : 0.0004255548119544983
Loss at iteration 1180 : 0.0001555396302137524
Loss at iteration 1190 : 0.0014695955906063318
Loss at iteration 1200 : 0.00010611095058266073
Loss at iteration 1210 : 0.002334168180823326
Loss at iteration 1220 : 0.0006373465294018388
Loss at iteration 1230 : 0.0035290392115712166
Loss at iteration 1240 : 0.0001889777195174247
Loss at iteration 1250 : 0.0005025106947869062
Loss at iteration 1260 : 0.0005776647012680769
Loss at iteration 1270 : 0.0001770594681147486
Loss at iteration 1280 : 0.0005253444542177022
Loss at iteration 1290 : 0.0008312950376421213
Loss at iteration 1300 : 0.0027721321675926447
Loss at iteration 1310 : 0.0003648912825156003
Loss at iteration 1320 : 0.0001950823061633855
Loss at iteration 1330 : 0.00017291371477767825
Loss at iteration 1340 : 0.002801659982651472
Loss at iteration 1350 : 0.0023575325030833483
Loss at iteration 1360 : 0.0009298576042056084
Loss at iteration 1370 : 0.0007915254100225866
Loss at iteration 1380 : 0.00011712704872479662
Loss at iteration 1390 : 0.0004468749393709004
Loss at iteration 1400 : 7.905130041763186e-05
Loss at iteration 1410 : 0.005365128628909588
Loss at iteration 1420 : 0.0002775719331111759
Loss at iteration 1430 : 0.00023755637812428176
Loss at iteration 1440 : 0.0014637073036283255
Loss at iteration 1450 : 0.0003285078564658761
Loss at iteration 1460 : 0.0010601547546684742
Loss at iteration 1470 : 0.002662111073732376
Loss at iteration 1480 : 0.0008141840808093548
Loss at iteration 1490 : 0.00017350597772747278
Loss at iteration 1500 : 0.0002002638066187501
Loss at iteration 1510 : 0.002724254038184881
Loss at iteration 1520 : 0.002312866970896721
Loss at iteration 1530 : 0.00015095886192284524
Loss at iteration 1540 : 0.000731981941498816
Loss at iteration 1550 : 0.0004946338012814522
Loss at iteration 1560 : 0.0005434444174170494
Loss at iteration 1570 : 0.0002964720770251006
Loss at iteration 1580 : 0.0005243972991593182
Loss at iteration 1590 : 0.00015267886919900775
Loss at iteration 1600 : 0.00030828904709778726
Loss at iteration 1610 : 0.00024853378999978304
Loss at iteration 1620 : 0.0003520907193887979
Loss at iteration 1630 : 0.005420839414000511
Loss at iteration 1640 : 0.004357523284852505
Loss at iteration 1650 : 0.0018890504725277424
Loss at iteration 1660 : 6.63877435727045e-05
Loss at iteration 1670 : 0.0001811745169106871
Loss at iteration 1680 : 0.0003707013966049999
Loss at iteration 1690 : 0.0003562739002518356
Loss at iteration 1700 : 0.00017542127170599997
Loss at iteration 1710 : 0.0010302357841283083
Loss at iteration 1720 : 0.0034389584325253963
Loss at iteration 1730 : 0.00012946045899298042
Loss at iteration 1740 : 0.002703586360439658
Loss at iteration 1750 : 0.00026316355797462165
The SSIM Value is: 0.9852217318990683
The PSNR Value is: 46.21902417296355
the epoch is: 32
Loss at iteration 10 : 0.0002551554935052991
Loss at iteration 20 : 0.0001812991249607876
Loss at iteration 30 : 0.004139660391956568
Loss at iteration 40 : 0.004673822782933712
Loss at iteration 50 : 0.0020411242730915546
Loss at iteration 60 : 0.0008020594250410795
Loss at iteration 70 : 0.00031281038536690176
Loss at iteration 80 : 0.0004933428135700524
Loss at iteration 90 : 0.0002744893135968596
Loss at iteration 100 : 0.0044780271127820015
Loss at iteration 110 : 0.0010795091511681676
Loss at iteration 120 : 0.0009165860246866941
Loss at iteration 130 : 0.0035645035095512867
Loss at iteration 140 : 0.0010051907738670707
Loss at iteration 150 : 0.0004938661586493254
Loss at iteration 160 : 0.0010997067438438535
Loss at iteration 170 : 0.0060338350012898445
Loss at iteration 180 : 0.0018838702235370874
Loss at iteration 190 : 0.004257268272340298
Loss at iteration 200 : 0.00013470134581439197
Loss at iteration 210 : 0.0006497923750430346
Loss at iteration 220 : 0.0006740593817085028
Loss at iteration 230 : 0.00020027661230415106
Loss at iteration 240 : 7.428441313095391e-05
Loss at iteration 250 : 0.00017653265967965126
Loss at iteration 260 : 0.004143776372075081
Loss at iteration 270 : 0.00014145618479233235
Loss at iteration 280 : 6.008645141264424e-05
Loss at iteration 290 : 0.0016208849847316742
Loss at iteration 300 : 0.002719585783779621
Loss at iteration 310 : 0.0005307055544108152
Loss at iteration 320 : 0.00391258904710412
Loss at iteration 330 : 0.0014355641324073076
Loss at iteration 340 : 0.0006013332749716938
Loss at iteration 350 : 0.00016616353241261095
Loss at iteration 360 : 0.00018854255904443562
Loss at iteration 370 : 0.0002952819922938943
Loss at iteration 380 : 0.0006787404417991638
Loss at iteration 390 : 0.00022987984993960708
Loss at iteration 400 : 0.00014569131599273533
Loss at iteration 410 : 0.0019095749594271183
Loss at iteration 420 : 0.0011975988745689392
Loss at iteration 430 : 0.004195430316030979
Loss at iteration 440 : 0.0001463253574911505
Loss at iteration 450 : 0.0001682108559180051
Loss at iteration 460 : 0.00017762307834345847
Loss at iteration 470 : 0.0015662525547668338
Loss at iteration 480 : 0.0001472175499657169
Loss at iteration 490 : 0.0013686059974133968
Loss at iteration 500 : 0.0006743614794686437
Loss at iteration 510 : 0.0003694880288094282
Loss at iteration 520 : 0.0009618948679417372
Loss at iteration 530 : 5.2585077355615795e-05
Loss at iteration 540 : 7.024518708931282e-05
Loss at iteration 550 : 0.0045737880282104015
Loss at iteration 560 : 0.003208439564332366
Loss at iteration 570 : 0.00042489630868658423
Loss at iteration 580 : 0.00017400778597220778
Loss at iteration 590 : 0.0003512551775202155
Loss at iteration 600 : 0.0006481821183115244
Loss at iteration 610 : 0.0011996908579021692
Loss at iteration 620 : 0.0001895752502605319
Loss at iteration 630 : 0.0009939078008756042
Loss at iteration 640 : 0.00014985685993451625
Loss at iteration 650 : 0.0037954046856611967
Loss at iteration 660 : 0.00044114451156929135
Loss at iteration 670 : 0.0009653107263147831
Loss at iteration 680 : 5.268850509310141e-05
Loss at iteration 690 : 0.000358900404535234
Loss at iteration 700 : 0.0001724099856801331
Loss at iteration 710 : 0.0007153282058425248
Loss at iteration 720 : 0.001993939746171236
Loss at iteration 730 : 0.0019586249254643917
Loss at iteration 740 : 0.0005977341206744313
Loss at iteration 750 : 0.00014858864597044885
Loss at iteration 760 : 0.0005445868009701371
Loss at iteration 770 : 0.00010104961256729439
Loss at iteration 780 : 0.0019515990279614925
Loss at iteration 790 : 0.005675651133060455
Loss at iteration 800 : 0.00473572826012969
Loss at iteration 810 : 0.0012670534197241068
Loss at iteration 820 : 0.0035724793560802937
Loss at iteration 830 : 0.00016976878396235406
Loss at iteration 840 : 0.0001263255689991638
Loss at iteration 850 : 0.0005160722648724914
Loss at iteration 860 : 0.00021300281514413655
Loss at iteration 870 : 0.00017983035650104284
Loss at iteration 880 : 0.00015617019380442798
Loss at iteration 890 : 0.0010863782372325659
Loss at iteration 900 : 0.0024542314931750298
Loss at iteration 910 : 0.00012367941963020712
Loss at iteration 920 : 0.0002631553797982633
Loss at iteration 930 : 0.00035043677780777216
Loss at iteration 940 : 0.0018517158459872007
Loss at iteration 950 : 0.0007047964027151465
Loss at iteration 960 : 0.00011494758655317128
Loss at iteration 970 : 0.00020710087846964598
Loss at iteration 980 : 0.0005674075800925493
Loss at iteration 990 : 0.0001291884545935318
Loss at iteration 1000 : 0.00038811739068478346
Loss at iteration 1010 : 0.007366772275418043
Loss at iteration 1020 : 8.941434498410672e-05
Loss at iteration 1030 : 0.005966467782855034
Loss at iteration 1040 : 0.0003603183140512556
Loss at iteration 1050 : 0.0007785889320075512
Loss at iteration 1060 : 0.004907178692519665
Loss at iteration 1070 : 0.0002685717772692442
Loss at iteration 1080 : 0.00039958598790690303
Loss at iteration 1090 : 0.0004041935026179999
Loss at iteration 1100 : 0.0002450464235153049
Loss at iteration 1110 : 0.00031411301461048424
Loss at iteration 1120 : 0.00020770117407664657
Loss at iteration 1130 : 0.00019515433814376593
Loss at iteration 1140 : 0.0010297391563653946
Loss at iteration 1150 : 0.004520345013588667
Loss at iteration 1160 : 0.004491368308663368
Loss at iteration 1170 : 7.274253584910184e-05
Loss at iteration 1180 : 0.0021815903019160032
Loss at iteration 1190 : 0.00017179426504299045
Loss at iteration 1200 : 0.0006501756724901497
Loss at iteration 1210 : 0.0001777669822331518
Loss at iteration 1220 : 0.0003724279231391847
Loss at iteration 1230 : 0.0001556551142130047
Loss at iteration 1240 : 0.0005788829294033349
Loss at iteration 1250 : 0.0025205009151250124
Loss at iteration 1260 : 0.00041574201895855367
Loss at iteration 1270 : 0.0010790996020659804
Loss at iteration 1280 : 0.00012573259300552309
Loss at iteration 1290 : 0.0007536439225077629
Loss at iteration 1300 : 0.0027232100255787373
Loss at iteration 1310 : 0.00018649872799869627
Loss at iteration 1320 : 0.00039928758633323014
Loss at iteration 1330 : 0.00022985506802797318
Loss at iteration 1340 : 0.00013958857744000852
Loss at iteration 1350 : 0.0007133844192139804
Loss at iteration 1360 : 0.002388404682278633
Loss at iteration 1370 : 0.00021458530682139099
Loss at iteration 1380 : 0.004312602803111076
Loss at iteration 1390 : 0.00017903122352436185
Loss at iteration 1400 : 0.001506884815171361
Loss at iteration 1410 : 8.276209700852633e-05
Loss at iteration 1420 : 0.0010680692503228784
Loss at iteration 1430 : 0.00017915177159011364
Loss at iteration 1440 : 6.541953916894272e-05
Loss at iteration 1450 : 4.1019946365850046e-05
Loss at iteration 1460 : 0.0003141194174531847
Loss at iteration 1470 : 0.0008945901645347476
Loss at iteration 1480 : 0.00040177072514779866
Loss at iteration 1490 : 8.864200935931876e-05
Loss at iteration 1500 : 0.00019114857423119247
Loss at iteration 1510 : 0.0010650556068867445
Loss at iteration 1520 : 0.00018133022240363061
Loss at iteration 1530 : 0.0013353823451325297
Loss at iteration 1540 : 4.322274980950169e-05
Loss at iteration 1550 : 0.002013232558965683
Loss at iteration 1560 : 0.0033884900622069836
Loss at iteration 1570 : 0.009193387813866138
Loss at iteration 1580 : 0.00030291234725154936
Loss at iteration 1590 : 0.0003487245994620025
Loss at iteration 1600 : 0.001156577025540173
Loss at iteration 1610 : 0.00065200513927266
Loss at iteration 1620 : 7.387803634628654e-05
Loss at iteration 1630 : 0.0002629305818118155
Loss at iteration 1640 : 0.00016160018276423216
Loss at iteration 1650 : 0.0012270925799384713
Loss at iteration 1660 : 0.0015189184341579676
Loss at iteration 1670 : 0.00019617186626419425
Loss at iteration 1680 : 0.000676579074934125
Loss at iteration 1690 : 5.652593245031312e-05
Loss at iteration 1700 : 0.0005464609712362289
Loss at iteration 1710 : 0.0003456486447248608
Loss at iteration 1720 : 0.00022382936731446534
Loss at iteration 1730 : 0.0002490192127879709
Loss at iteration 1740 : 0.0026931532192975283
Loss at iteration 1750 : 0.00013178253720980138
The SSIM Value is: 0.9879911002346072
The PSNR Value is: 46.06892716832098
the epoch is: 33
Loss at iteration 10 : 0.00011617202108027413
Loss at iteration 20 : 8.161571167875081e-05
Loss at iteration 30 : 5.753884033765644e-05
Loss at iteration 40 : 0.00010587360156932846
Loss at iteration 50 : 0.00020028215658385307
Loss at iteration 60 : 0.00038359410245902836
Loss at iteration 70 : 0.00010874409053940326
Loss at iteration 80 : 7.285641913767904e-05
Loss at iteration 90 : 0.002798914909362793
Loss at iteration 100 : 0.0002951544302050024
Loss at iteration 110 : 0.000162519994773902
Loss at iteration 120 : 3.205528628313914e-05
Loss at iteration 130 : 0.0016681085107848048
Loss at iteration 140 : 0.00011698337038978934
Loss at iteration 150 : 0.000753071450162679
Loss at iteration 160 : 0.0005006667925044894
Loss at iteration 170 : 0.0035354234278202057
Loss at iteration 180 : 0.003563791047781706
Loss at iteration 190 : 0.00416627898812294
Loss at iteration 200 : 0.00453073950484395
Loss at iteration 210 : 0.0002130734355887398
Loss at iteration 220 : 0.0004778142902068794
Loss at iteration 230 : 0.00016387637879233807
Loss at iteration 240 : 0.002632115501910448
Loss at iteration 250 : 0.0003186977410223335
Loss at iteration 260 : 0.001059342292137444
Loss at iteration 270 : 0.00011854148760903627
Loss at iteration 280 : 0.0010368134826421738
Loss at iteration 290 : 0.00010917010513367131
Loss at iteration 300 : 5.1486749725881964e-05
Loss at iteration 310 : 0.00013829361705575138
Loss at iteration 320 : 0.00029001006623730063
Loss at iteration 330 : 0.00013414560817182064
Loss at iteration 340 : 0.0016756579279899597
Loss at iteration 350 : 0.0030826088041067123
Loss at iteration 360 : 0.00016918452456593513
Loss at iteration 370 : 0.0008762089419178665
Loss at iteration 380 : 0.0012100625317543745
Loss at iteration 390 : 8.561364666093141e-05
Loss at iteration 400 : 0.0002709555847104639
Loss at iteration 410 : 0.002737212460488081
Loss at iteration 420 : 0.0005652250838465989
Loss at iteration 430 : 0.0024270908907055855
Loss at iteration 440 : 0.0020926797296851873
Loss at iteration 450 : 0.0005964412121102214
Loss at iteration 460 : 0.0026316517032682896
Loss at iteration 470 : 0.0006174748996272683
Loss at iteration 480 : 0.0004014681908302009
Loss at iteration 490 : 0.0038223545998334885
Loss at iteration 500 : 0.00022385238844435662
Loss at iteration 510 : 9.0590983745642e-05
Loss at iteration 520 : 0.0001271782093681395
Loss at iteration 530 : 0.000409785658121109
Loss at iteration 540 : 4.689951674663462e-05
Loss at iteration 550 : 0.0003488677029963583
Loss at iteration 560 : 0.00013793582911603153
Loss at iteration 570 : 0.0005079600960016251
Loss at iteration 580 : 0.000143031298648566
Loss at iteration 590 : 0.0001707619958324358
Loss at iteration 600 : 0.003782415296882391
Loss at iteration 610 : 0.0028713217470794916
Loss at iteration 620 : 0.0008504964644089341
Loss at iteration 630 : 0.005061795003712177
Loss at iteration 640 : 7.793489203322679e-05
Loss at iteration 650 : 0.0007141979294829071
Loss at iteration 660 : 0.001309448853135109
Loss at iteration 670 : 0.00026560836704447865
Loss at iteration 680 : 0.001268331310711801
Loss at iteration 690 : 0.0001058301204466261
Loss at iteration 700 : 0.0003209529968444258
Loss at iteration 710 : 0.0005035834037698805
Loss at iteration 720 : 0.0003704107948578894
Loss at iteration 730 : 0.0008915679645724595
Loss at iteration 740 : 0.0009204314555972815
Loss at iteration 750 : 0.004457246977835894
Loss at iteration 760 : 0.002425928134471178
Loss at iteration 770 : 0.0002827627176884562
Loss at iteration 780 : 0.00011921816621907055
Loss at iteration 790 : 0.00010954070603474975
Loss at iteration 800 : 0.00021918080165050924
Loss at iteration 810 : 0.007709820754826069
Loss at iteration 820 : 0.00366756203584373
Loss at iteration 830 : 0.001343839685432613
Loss at iteration 840 : 0.004661711864173412
Loss at iteration 850 : 8.758441254030913e-05
Loss at iteration 860 : 0.0006356372614391148
Loss at iteration 870 : 0.001063029863871634
Loss at iteration 880 : 0.003292523790150881
Loss at iteration 890 : 8.985026943264529e-05
Loss at iteration 900 : 0.0009349484462291002
Loss at iteration 910 : 6.51978116366081e-05
Loss at iteration 920 : 0.0008316205348819494
Loss at iteration 930 : 8.243299089372158e-05
Loss at iteration 940 : 0.0013233092613518238
Loss at iteration 950 : 0.0002919982944149524
Loss at iteration 960 : 8.790295396465808e-05
Loss at iteration 970 : 5.417776992544532e-05
Loss at iteration 980 : 0.0004970345180481672
Loss at iteration 990 : 0.00043857915443368256
Loss at iteration 1000 : 0.0013483469374477863
Loss at iteration 1010 : 0.0003518792218528688
Loss at iteration 1020 : 0.00013653305359184742
Loss at iteration 1030 : 0.003721618792042136
Loss at iteration 1040 : 0.001627078978344798
Loss at iteration 1050 : 0.0005176318809390068
Loss at iteration 1060 : 9.681290976004675e-05
Loss at iteration 1070 : 0.006700327154248953
Loss at iteration 1080 : 0.00029478943906724453
Loss at iteration 1090 : 0.0035003903321921825
Loss at iteration 1100 : 0.0005159249994903803
Loss at iteration 1110 : 0.00025783112505450845
Loss at iteration 1120 : 8.720085315871984e-05
Loss at iteration 1130 : 0.00014928216114640236
Loss at iteration 1140 : 0.00035510375164449215
Loss at iteration 1150 : 0.00023492366017308086
Loss at iteration 1160 : 0.0004861499182879925
Loss at iteration 1170 : 0.00021783594274893403
Loss at iteration 1180 : 0.002538192318752408
Loss at iteration 1190 : 0.00043182639637961984
Loss at iteration 1200 : 0.0003032412496395409
Loss at iteration 1210 : 0.0008302969508804381
Loss at iteration 1220 : 0.00029101682594045997
Loss at iteration 1230 : 0.00034643919207155704
Loss at iteration 1240 : 0.00020218436839058995
Loss at iteration 1250 : 0.00011595521937124431
Loss at iteration 1260 : 0.0007312775123864412
Loss at iteration 1270 : 0.000371225003618747
Loss at iteration 1280 : 0.0021974726114422083
Loss at iteration 1290 : 0.0023883001413196325
Loss at iteration 1300 : 0.001623047748580575
Loss at iteration 1310 : 0.0004507782869040966
Loss at iteration 1320 : 0.001991445431485772
Loss at iteration 1330 : 0.0036426540464162827
Loss at iteration 1340 : 0.00047234620433300734
Loss at iteration 1350 : 0.0019031825941056013
Loss at iteration 1360 : 7.939575152704492e-05
Loss at iteration 1370 : 0.0026252581737935543
Loss at iteration 1380 : 0.000322813808452338
Loss at iteration 1390 : 0.0001505202817497775
Loss at iteration 1400 : 0.0021273819729685783
Loss at iteration 1410 : 0.00025615107733756304
Loss at iteration 1420 : 5.7658668083604425e-05
Loss at iteration 1430 : 0.005657123401761055
Loss at iteration 1440 : 0.00026855641044676304
Loss at iteration 1450 : 0.0022125798277556896
Loss at iteration 1460 : 0.003892902983352542
Loss at iteration 1470 : 0.005428120493888855
Loss at iteration 1480 : 0.002447922248393297
Loss at iteration 1490 : 0.00019280263222754002
Loss at iteration 1500 : 0.0003900122828781605
Loss at iteration 1510 : 0.0006637820042669773
Loss at iteration 1520 : 0.00013206301082391292
Loss at iteration 1530 : 0.0006618464249186218
Loss at iteration 1540 : 0.00020045280689373612
Loss at iteration 1550 : 0.0005608029896393418
Loss at iteration 1560 : 0.0006912467069923878
Loss at iteration 1570 : 0.0011989637278020382
Loss at iteration 1580 : 0.00018006499158218503
Loss at iteration 1590 : 0.0044668870978057384
Loss at iteration 1600 : 0.0014956255909055471
Loss at iteration 1610 : 0.0032767595257610083
Loss at iteration 1620 : 0.002952537965029478
Loss at iteration 1630 : 9.28304361877963e-05
Loss at iteration 1640 : 0.00024568813387304544
Loss at iteration 1650 : 0.0002557060797698796
Loss at iteration 1660 : 0.00011278984311502427
Loss at iteration 1670 : 0.0013505552196875215
Loss at iteration 1680 : 0.001695331186056137
Loss at iteration 1690 : 0.0005350573919713497
Loss at iteration 1700 : 0.00019042714848183095
Loss at iteration 1710 : 0.0003736575599759817
Loss at iteration 1720 : 0.003179793246090412
Loss at iteration 1730 : 0.0002622011525090784
Loss at iteration 1740 : 0.0006559466710314155
Loss at iteration 1750 : 0.0004404264618642628
The SSIM Value is: 0.9829217305792586
The PSNR Value is: 46.427224781019575
the epoch is: 34
Loss at iteration 10 : 0.0007785693742334843
Loss at iteration 20 : 0.0004214242217130959
Loss at iteration 30 : 8.768367843003944e-05
Loss at iteration 40 : 0.000409812229918316
Loss at iteration 50 : 0.0003325585857965052
Loss at iteration 60 : 0.00011003832332789898
Loss at iteration 70 : 0.0007793540717102587
Loss at iteration 80 : 0.00022057571914047003
Loss at iteration 90 : 0.0006306502036750317
Loss at iteration 100 : 0.0004115232150070369
Loss at iteration 110 : 0.0004616575315594673
Loss at iteration 120 : 7.801593892509118e-05
Loss at iteration 130 : 0.00015596076264046133
Loss at iteration 140 : 0.00016419298481196165
Loss at iteration 150 : 0.00043315935181453824
Loss at iteration 160 : 0.0015660992357879877
Loss at iteration 170 : 0.0028878478333353996
Loss at iteration 180 : 0.00031922126072458923
Loss at iteration 190 : 0.00041114367195405066
Loss at iteration 200 : 0.0027567455545067787
Loss at iteration 210 : 0.00024847208987921476
Loss at iteration 220 : 0.0007471181452274323
Loss at iteration 230 : 0.0010529495775699615
Loss at iteration 240 : 0.0005240737809799612
Loss at iteration 250 : 0.00031393178505823016
Loss at iteration 260 : 0.003927606623619795
Loss at iteration 270 : 0.0003812293871305883
Loss at iteration 280 : 0.0003097384178545326
Loss at iteration 290 : 0.000632990850135684
Loss at iteration 300 : 0.00011776998144341633
Loss at iteration 310 : 0.003189951181411743
Loss at iteration 320 : 0.0034228134900331497
Loss at iteration 330 : 0.00011675678251776844
Loss at iteration 340 : 0.002405622275546193
Loss at iteration 350 : 0.00010779763397295028
Loss at iteration 360 : 0.003833093447610736
Loss at iteration 370 : 0.00028099067276343703
Loss at iteration 380 : 0.0021410807967185974
Loss at iteration 390 : 8.07888136478141e-05
Loss at iteration 400 : 0.00010246103920508176
Loss at iteration 410 : 0.004648057743906975
Loss at iteration 420 : 0.0008271895349025726
Loss at iteration 430 : 7.80419577495195e-05
Loss at iteration 440 : 0.00014697211736347526
Loss at iteration 450 : 0.006445711944252253
Loss at iteration 460 : 0.0006415984826162457
Loss at iteration 470 : 0.0006465789047069848
Loss at iteration 480 : 0.00021890964126214385
Loss at iteration 490 : 0.0026741609908640385
Loss at iteration 500 : 9.641283395467326e-05
Loss at iteration 510 : 0.0003538433229550719
Loss at iteration 520 : 0.002741245087236166
Loss at iteration 530 : 9.670673171058297e-05
Loss at iteration 540 : 0.0008326283423230052
Loss at iteration 550 : 0.0017025514971464872
Loss at iteration 560 : 0.0007434069993905723
Loss at iteration 570 : 0.0003517788427416235
Loss at iteration 580 : 0.00040668173460289836
Loss at iteration 590 : 0.000181371666258201
Loss at iteration 600 : 0.00016983007662929595
Loss at iteration 610 : 0.00014369768905453384
Loss at iteration 620 : 0.002227126620709896
Loss at iteration 630 : 0.00013557777856476605
Loss at iteration 640 : 0.0027427838649600744
Loss at iteration 650 : 0.0004150642780587077
Loss at iteration 660 : 0.004698915872722864
Loss at iteration 670 : 0.00018188821559306234
Loss at iteration 680 : 0.0005335337482392788
Loss at iteration 690 : 0.0015372904017567635
Loss at iteration 700 : 0.0020879243966192007
Loss at iteration 710 : 0.0034527075476944447
Loss at iteration 720 : 0.00021376785298343748
Loss at iteration 730 : 0.0003200456267222762
Loss at iteration 740 : 9.857358236331493e-05
Loss at iteration 750 : 9.265887638321146e-05
Loss at iteration 760 : 0.00015358312521129847
Loss at iteration 770 : 0.0032049668952822685
Loss at iteration 780 : 8.348048868356273e-05
Loss at iteration 790 : 0.0005582927260547876
Loss at iteration 800 : 0.00254188384860754
Loss at iteration 810 : 0.0021312714088708162
Loss at iteration 820 : 0.0017319819889962673
Loss at iteration 830 : 0.0012893679086118937
Loss at iteration 840 : 0.0027598266024142504
Loss at iteration 850 : 0.0022239931859076023
Loss at iteration 860 : 0.0032296127174049616
Loss at iteration 870 : 0.00013879392645321786
Loss at iteration 880 : 0.001946797827258706
Loss at iteration 890 : 0.00010119139915332198
Loss at iteration 900 : 0.0004796379362232983
Loss at iteration 910 : 0.0009990353137254715
Loss at iteration 920 : 0.00038125476567074656
Loss at iteration 930 : 0.005092321895062923
Loss at iteration 940 : 0.000247857125941664
Loss at iteration 950 : 0.0025186091661453247
Loss at iteration 960 : 0.002322822343558073
Loss at iteration 970 : 0.00120201101526618
Loss at iteration 980 : 0.0030037083197385073
Loss at iteration 990 : 0.00012195446470286697
Loss at iteration 1000 : 0.0035160682164132595
Loss at iteration 1010 : 0.0003813330258708447
Loss at iteration 1020 : 0.00020286740618757904
Loss at iteration 1030 : 0.00010549750732025132
Loss at iteration 1040 : 7.063111843308434e-05
Loss at iteration 1050 : 0.0001804940984584391
Loss at iteration 1060 : 0.00015018254634924233
Loss at iteration 1070 : 0.001224118983373046
Loss at iteration 1080 : 0.0042097922414541245
Loss at iteration 1090 : 0.00485153216868639
Loss at iteration 1100 : 0.0006913280813023448
Loss at iteration 1110 : 0.0022677588276565075
Loss at iteration 1120 : 0.003582775592803955
Loss at iteration 1130 : 0.0028565609827637672
Loss at iteration 1140 : 0.00015431988867931068
Loss at iteration 1150 : 0.001043951022438705
Loss at iteration 1160 : 0.0007966761477291584
Loss at iteration 1170 : 0.00036181160248816013
Loss at iteration 1180 : 0.0036425432190299034
Loss at iteration 1190 : 0.0010770284570753574
Loss at iteration 1200 : 0.0006938001606613398
Loss at iteration 1210 : 0.00035198748810216784
Loss at iteration 1220 : 0.0030116946436464787
Loss at iteration 1230 : 0.0006787729798816144
Loss at iteration 1240 : 0.0006143618375062943
Loss at iteration 1250 : 0.0008625517366454005
Loss at iteration 1260 : 0.00017747023957781494
Loss at iteration 1270 : 8.486674050800502e-05
Loss at iteration 1280 : 0.003256850875914097
Loss at iteration 1290 : 0.00130989751778543
Loss at iteration 1300 : 0.001229392597451806
Loss at iteration 1310 : 4.41060183220543e-05
Loss at iteration 1320 : 0.0001545031409477815
Loss at iteration 1330 : 0.00012842539581470191
Loss at iteration 1340 : 0.0028746738098561764
Loss at iteration 1350 : 0.0002965338353533298
Loss at iteration 1360 : 0.00026808062102645636
Loss at iteration 1370 : 0.0014257347211241722
Loss at iteration 1380 : 0.00020954545470885932
Loss at iteration 1390 : 0.00015512315439991653
Loss at iteration 1400 : 0.0030907862819731236
Loss at iteration 1410 : 0.003396938554942608
Loss at iteration 1420 : 0.0012845444725826383
Loss at iteration 1430 : 0.001971163786947727
Loss at iteration 1440 : 0.00616360642015934
Loss at iteration 1450 : 0.00023246268392540514
Loss at iteration 1460 : 8.689701644470915e-05
Loss at iteration 1470 : 0.0004936260520480573
Loss at iteration 1480 : 0.00029577038367278874
Loss at iteration 1490 : 0.002690402325242758
Loss at iteration 1500 : 0.00020903079712297767
Loss at iteration 1510 : 0.00019423211051616818
Loss at iteration 1520 : 0.002013490302488208
Loss at iteration 1530 : 0.00010493788431631401
Loss at iteration 1540 : 0.0001478036429034546
Loss at iteration 1550 : 0.000257375679211691
Loss at iteration 1560 : 0.0001363693008897826
Loss at iteration 1570 : 0.0001357162109343335
Loss at iteration 1580 : 8.914123463910073e-05
Loss at iteration 1590 : 0.0005322163342498243
Loss at iteration 1600 : 0.003039844334125519
Loss at iteration 1610 : 0.00036363780964165926
Loss at iteration 1620 : 0.0006609417614527047
Loss at iteration 1630 : 0.0003096552682109177
Loss at iteration 1640 : 0.0015166483353823423
Loss at iteration 1650 : 0.0003869087668135762
Loss at iteration 1660 : 0.001172214513644576
Loss at iteration 1670 : 0.00020266577485017478
Loss at iteration 1680 : 0.0008556003449484706
Loss at iteration 1690 : 0.0012491574743762612
Loss at iteration 1700 : 0.0001325830235145986
Loss at iteration 1710 : 0.00028110615676268935
Loss at iteration 1720 : 0.0009538098238408566
Loss at iteration 1730 : 5.578061973210424e-05
Loss at iteration 1740 : 0.0010345273185521364
Loss at iteration 1750 : 0.0003517695877235383
The SSIM Value is: 0.9882579720230354
The PSNR Value is: 46.3715348054659
the epoch is: 35
Loss at iteration 10 : 0.00014931887562852353
Loss at iteration 20 : 0.0006101556355133653
Loss at iteration 30 : 0.0025820708833634853
Loss at iteration 40 : 0.0012371302582323551
Loss at iteration 50 : 0.00015550106763839722
Loss at iteration 60 : 0.002164752222597599
Loss at iteration 70 : 0.0001837214222177863
Loss at iteration 80 : 0.00040135910967364907
Loss at iteration 90 : 0.00016995771147776395
Loss at iteration 100 : 0.0006601689383387566
Loss at iteration 110 : 0.0013059601187705994
Loss at iteration 120 : 0.0017777541652321815
Loss at iteration 130 : 0.004527023993432522
Loss at iteration 140 : 0.0033618882298469543
Loss at iteration 150 : 0.0009072998655028641
Loss at iteration 160 : 0.00012195243471069261
Loss at iteration 170 : 0.0007396721048280597
Loss at iteration 180 : 0.004995191935449839
Loss at iteration 190 : 0.0004363861808087677
Loss at iteration 200 : 0.0001829980028560385
Loss at iteration 210 : 0.00020725549256894737
Loss at iteration 220 : 0.0008131492650136352
Loss at iteration 230 : 0.00028809806099161506
Loss at iteration 240 : 0.0004916598554700613
Loss at iteration 250 : 0.003920643124729395
Loss at iteration 260 : 0.003843753831461072
Loss at iteration 270 : 0.0003397649561520666
Loss at iteration 280 : 9.574391151545569e-05
Loss at iteration 290 : 0.0002487330057192594
Loss at iteration 300 : 0.000534068385604769
Loss at iteration 310 : 0.00027289011632092297
Loss at iteration 320 : 0.00020019736257381737
Loss at iteration 330 : 0.00044343428453430533
Loss at iteration 340 : 0.0024845425505191088
Loss at iteration 350 : 0.0007460631895810366
Loss at iteration 360 : 0.00342188635841012
Loss at iteration 370 : 0.0009772209450602531
Loss at iteration 380 : 9.837732068262994e-05
Loss at iteration 390 : 0.0002737402974162251
Loss at iteration 400 : 0.00021913139789830893
Loss at iteration 410 : 0.004323064815253019
Loss at iteration 420 : 0.0012101118918508291
Loss at iteration 430 : 0.00017232587561011314
Loss at iteration 440 : 0.00032937494688667357
Loss at iteration 450 : 0.00020636589033529162
Loss at iteration 460 : 0.00011631558299995959
Loss at iteration 470 : 0.0004405578365549445
Loss at iteration 480 : 0.00025846943026408553
Loss at iteration 490 : 0.0002878790837712586
Loss at iteration 500 : 0.000677743402775377
Loss at iteration 510 : 0.00453356746584177
Loss at iteration 520 : 0.0016716577811166644
Loss at iteration 530 : 0.001954695675522089
Loss at iteration 540 : 0.004222034011036158
Loss at iteration 550 : 0.0004025763482786715
Loss at iteration 560 : 0.0006817802786827087
Loss at iteration 570 : 0.0005922605050727725
Loss at iteration 580 : 0.0009712897590361536
Loss at iteration 590 : 0.002278677187860012
Loss at iteration 600 : 0.00012353406054899096
Loss at iteration 610 : 0.00028735771775245667
Loss at iteration 620 : 0.0001261482248082757
Loss at iteration 630 : 0.0001779219601303339
Loss at iteration 640 : 0.0004114615439902991
Loss at iteration 650 : 0.0007443977519869804
Loss at iteration 660 : 0.0007572690956294537
Loss at iteration 670 : 0.0023121158592402935
Loss at iteration 680 : 0.00021639610349666327
Loss at iteration 690 : 0.0018433158984407783
Loss at iteration 700 : 0.0012230237480252981
Loss at iteration 710 : 0.0010572327300906181
Loss at iteration 720 : 0.0030173780396580696
Loss at iteration 730 : 0.012111219577491283
Loss at iteration 740 : 0.0011956776725128293
Loss at iteration 750 : 0.00016914776642806828
Loss at iteration 760 : 0.00026010681176558137
Loss at iteration 770 : 0.0004450357228051871
Loss at iteration 780 : 0.0016583346296101809
Loss at iteration 790 : 0.002328121569007635
Loss at iteration 800 : 0.00010443211067467928
Loss at iteration 810 : 0.000994460890069604
Loss at iteration 820 : 0.0018585134530439973
Loss at iteration 830 : 0.004051310010254383
Loss at iteration 840 : 0.00045691177365370095
Loss at iteration 850 : 0.0008704642532393336
Loss at iteration 860 : 0.0001706748444121331
Loss at iteration 870 : 0.00018258264753967524
Loss at iteration 880 : 0.002991008572280407
Loss at iteration 890 : 0.005267356522381306
Loss at iteration 900 : 9.731348836794496e-05
Loss at iteration 910 : 0.0008912822813726962
Loss at iteration 920 : 7.953370368340984e-05
Loss at iteration 930 : 0.0004695518291555345
Loss at iteration 940 : 0.0006614024750888348
Loss at iteration 950 : 0.0028744093142449856
Loss at iteration 960 : 0.0002791494771372527
Loss at iteration 970 : 0.0030585131607949734
Loss at iteration 980 : 0.001732161734253168
Loss at iteration 990 : 0.000129627893329598
Loss at iteration 1000 : 0.0014392235316336155
Loss at iteration 1010 : 0.0001655197120271623
Loss at iteration 1020 : 0.0033617056906223297
Loss at iteration 1030 : 0.0001148305309470743
Loss at iteration 1040 : 0.0029848525300621986
Loss at iteration 1050 : 0.000127989609609358
Loss at iteration 1060 : 0.00016947553376667202
Loss at iteration 1070 : 0.00583380414173007
Loss at iteration 1080 : 0.000102578844234813
Loss at iteration 1090 : 6.1488026403822e-05
Loss at iteration 1100 : 0.00015659099153708667
Loss at iteration 1110 : 0.0006596775492653251
Loss at iteration 1120 : 0.0016614615451544523
Loss at iteration 1130 : 0.004339234437793493
Loss at iteration 1140 : 0.00033719089697115123
Loss at iteration 1150 : 0.001968306489288807
Loss at iteration 1160 : 7.634435314685106e-05
Loss at iteration 1170 : 0.00023384021187666804
Loss at iteration 1180 : 0.00020233390387147665
Loss at iteration 1190 : 0.0012953559635207057
Loss at iteration 1200 : 0.0017218135762959719
Loss at iteration 1210 : 0.0013022597413510084
Loss at iteration 1220 : 0.0002773515589069575
Loss at iteration 1230 : 5.6985947594512254e-05
Loss at iteration 1240 : 0.00034690776374191046
Loss at iteration 1250 : 0.0003504599444568157
Loss at iteration 1260 : 0.00017002318054437637
Loss at iteration 1270 : 0.0002432470500934869
Loss at iteration 1280 : 0.002724752528592944
Loss at iteration 1290 : 0.0003586520906537771
Loss at iteration 1300 : 0.0006044920883141458
Loss at iteration 1310 : 0.0019229660974815488
Loss at iteration 1320 : 0.0003369143814779818
Loss at iteration 1330 : 0.0003092964761890471
Loss at iteration 1340 : 0.0006708042928948998
Loss at iteration 1350 : 0.00041361182229593396
Loss at iteration 1360 : 0.0018383092246949673
Loss at iteration 1370 : 0.00019308101036585867
Loss at iteration 1380 : 0.0005027513834647834
Loss at iteration 1390 : 0.0002769281854853034
Loss at iteration 1400 : 0.0016673663631081581
Loss at iteration 1410 : 0.0019541855435818434
Loss at iteration 1420 : 0.001654121559113264
Loss at iteration 1430 : 0.0007039288757368922
Loss at iteration 1440 : 0.0001401651679771021
Loss at iteration 1450 : 0.005738793406635523
Loss at iteration 1460 : 0.00045767007395625114
Loss at iteration 1470 : 0.00027800723910331726
Loss at iteration 1480 : 0.00043855071999132633
Loss at iteration 1490 : 0.00024559471057727933
Loss at iteration 1500 : 0.0005709148244932294
Loss at iteration 1510 : 0.0002045158762484789
Loss at iteration 1520 : 0.0007071912987157702
Loss at iteration 1530 : 0.00016443940694443882
Loss at iteration 1540 : 0.00011251748219365254
Loss at iteration 1550 : 7.52086634747684e-05
Loss at iteration 1560 : 0.0026404373347759247
Loss at iteration 1570 : 0.0004763758333865553
Loss at iteration 1580 : 0.001592008862644434
Loss at iteration 1590 : 0.002207627519965172
Loss at iteration 1600 : 0.0038981507532298565
Loss at iteration 1610 : 0.00017367668624501675
Loss at iteration 1620 : 0.00018427902250550687
Loss at iteration 1630 : 0.0006915187695994973
Loss at iteration 1640 : 0.00024065257457550615
Loss at iteration 1650 : 0.00028350736829452217
Loss at iteration 1660 : 0.0005201424937695265
Loss at iteration 1670 : 0.0010708246845752
Loss at iteration 1680 : 0.0023921935353428125
Loss at iteration 1690 : 0.003160675521939993
Loss at iteration 1700 : 0.001181237050332129
Loss at iteration 1710 : 0.004773714113980532
Loss at iteration 1720 : 0.0007475340971723199
Loss at iteration 1730 : 0.0010114740580320358
Loss at iteration 1740 : 0.0005328630213625729
Loss at iteration 1750 : 0.0013799788430333138
The SSIM Value is: 0.9885734171331717
The PSNR Value is: 46.662733796409576
the epoch is: 36
Loss at iteration 10 : 0.001190660404972732
Loss at iteration 20 : 0.00396979134529829
Loss at iteration 30 : 0.0006276306230574846
Loss at iteration 40 : 0.003373183077201247
Loss at iteration 50 : 0.00011406656994950026
Loss at iteration 60 : 0.0003264513798058033
Loss at iteration 70 : 0.000542757217772305
Loss at iteration 80 : 0.0003201712388545275
Loss at iteration 90 : 0.001835034228861332
Loss at iteration 100 : 0.0002159162104362622
Loss at iteration 110 : 0.00021181433112360537
Loss at iteration 120 : 0.0003649098798632622
Loss at iteration 130 : 0.001257174531929195
Loss at iteration 140 : 0.00010058602492790669
Loss at iteration 150 : 0.0029501186218112707
Loss at iteration 160 : 0.0003561261110007763
Loss at iteration 170 : 0.00033011307823471725
Loss at iteration 180 : 0.0009737283107824624
Loss at iteration 190 : 0.0004656210949178785
Loss at iteration 200 : 0.0010129017755389214
Loss at iteration 210 : 0.0005013746558688581
Loss at iteration 220 : 4.981342135579325e-05
Loss at iteration 230 : 0.0019509932026267052
Loss at iteration 240 : 0.0002944737789221108
Loss at iteration 250 : 0.0005228589288890362
Loss at iteration 260 : 0.00018648529658094049
Loss at iteration 270 : 0.00020273454720154405
Loss at iteration 280 : 0.00018248058040626347
Loss at iteration 290 : 0.0034077479504048824
Loss at iteration 300 : 6.19749043835327e-05
Loss at iteration 310 : 0.002282185247167945
Loss at iteration 320 : 0.0001411087141605094
Loss at iteration 330 : 0.0005937929963693023
Loss at iteration 340 : 0.0027438001707196236
Loss at iteration 350 : 0.00014383313828147948
Loss at iteration 360 : 0.0030289669521152973
Loss at iteration 370 : 0.0006978159653954208
Loss at iteration 380 : 0.0006080060265958309
Loss at iteration 390 : 5.351636718842201e-05
Loss at iteration 400 : 0.0005457522347569466
Loss at iteration 410 : 0.0014224681071937084
Loss at iteration 420 : 0.004419551696628332
Loss at iteration 430 : 0.00024159594613593072
Loss at iteration 440 : 0.0019685085862874985
Loss at iteration 450 : 0.0001135167694883421
Loss at iteration 460 : 0.00026192591758444905
Loss at iteration 470 : 0.0001597478985786438
Loss at iteration 480 : 0.0005454780766740441
Loss at iteration 490 : 0.00040963239734992385
Loss at iteration 500 : 0.00012366317969281226
Loss at iteration 510 : 0.003534500952810049
Loss at iteration 520 : 0.00013654911890625954
Loss at iteration 530 : 0.0021135902497917414
Loss at iteration 540 : 0.0014005890116095543
Loss at iteration 550 : 0.0003209097485523671
Loss at iteration 560 : 0.0021963210310786963
Loss at iteration 570 : 0.0022660712711513042
Loss at iteration 580 : 0.0019623173866420984
Loss at iteration 590 : 0.0003108210803475231
Loss at iteration 600 : 0.0002767063560895622
Loss at iteration 610 : 0.0005754550220444798
Loss at iteration 620 : 0.00021263588860165328
Loss at iteration 630 : 0.0005426965071819723
Loss at iteration 640 : 0.0005019248928874731
Loss at iteration 650 : 0.0008663763292133808
Loss at iteration 660 : 0.0033979283180087805
Loss at iteration 670 : 0.0048903124406933784
Loss at iteration 680 : 0.0050118728540837765
Loss at iteration 690 : 0.00013344701437745243
Loss at iteration 700 : 0.0032379303593188524
Loss at iteration 710 : 0.0003894616093020886
Loss at iteration 720 : 0.0001659209665376693
Loss at iteration 730 : 0.00010985394328599796
Loss at iteration 740 : 0.0006298934458754957
Loss at iteration 750 : 0.0004821400507353246
Loss at iteration 760 : 0.003918370231986046
Loss at iteration 770 : 0.00044942775275558233
Loss at iteration 780 : 0.0005602416931651533
Loss at iteration 790 : 0.00042057715472765267
Loss at iteration 800 : 0.0011837090132758021
Loss at iteration 810 : 0.00016810280794743448
Loss at iteration 820 : 0.00010343888425268233
Loss at iteration 830 : 0.00017407783889211714
Loss at iteration 840 : 0.0016115448670461774
Loss at iteration 850 : 0.0010014423169195652
Loss at iteration 860 : 0.00022569956490769982
Loss at iteration 870 : 0.00027219337061978877
Loss at iteration 880 : 0.00021079111320432276
Loss at iteration 890 : 0.002773670479655266
Loss at iteration 900 : 0.0002296282327733934
Loss at iteration 910 : 0.0006094119744375348
Loss at iteration 920 : 0.00017461921379435807
Loss at iteration 930 : 0.0007007757667452097
Loss at iteration 940 : 0.001565798302181065
Loss at iteration 950 : 0.002218628767877817
Loss at iteration 960 : 0.00018117728177458048
Loss at iteration 970 : 0.00015430474013555795
Loss at iteration 980 : 0.0001213146242662333
Loss at iteration 990 : 0.00013082800433039665
Loss at iteration 1000 : 0.00017904627020470798
Loss at iteration 1010 : 8.653679105918854e-05
Loss at iteration 1020 : 0.00016431717085652053
Loss at iteration 1030 : 0.00024301416124217212
Loss at iteration 1040 : 0.0016596275381743908
Loss at iteration 1050 : 0.0007016408490017056
Loss at iteration 1060 : 9.917483112076297e-05
Loss at iteration 1070 : 0.002803000621497631
Loss at iteration 1080 : 0.00010923150693997741
Loss at iteration 1090 : 0.001142092514783144
Loss at iteration 1100 : 0.0003405309107620269
Loss at iteration 1110 : 0.00010531429143156856
Loss at iteration 1120 : 0.0036945659667253494
Loss at iteration 1130 : 0.000794566236436367
Loss at iteration 1140 : 5.5995809816522524e-05
Loss at iteration 1150 : 0.00042678002500906587
Loss at iteration 1160 : 0.00024155445862561464
Loss at iteration 1170 : 9.335169306723401e-05
Loss at iteration 1180 : 0.0046119075268507
Loss at iteration 1190 : 0.00019428221276029944
Loss at iteration 1200 : 0.00023142824647948146
Loss at iteration 1210 : 0.0001031825813697651
Loss at iteration 1220 : 0.0012508747167885303
Loss at iteration 1230 : 0.0004632810887414962
Loss at iteration 1240 : 0.00012229770072735846
Loss at iteration 1250 : 0.00046470563393086195
Loss at iteration 1260 : 0.001051007304340601
Loss at iteration 1270 : 0.0024514985270798206
Loss at iteration 1280 : 0.00037761410931125283
Loss at iteration 1290 : 0.0025677254889160395
Loss at iteration 1300 : 0.00014551274944096804
Loss at iteration 1310 : 0.0004931137664243579
Loss at iteration 1320 : 0.002959716599434614
Loss at iteration 1330 : 0.0004787765210494399
Loss at iteration 1340 : 0.0003904700861312449
Loss at iteration 1350 : 0.0008784634992480278
Loss at iteration 1360 : 0.00016819190932437778
Loss at iteration 1370 : 0.00056114123435691
Loss at iteration 1380 : 0.00015628416440449655
Loss at iteration 1390 : 0.00011157470726175234
Loss at iteration 1400 : 0.0001828220410970971
Loss at iteration 1410 : 0.0040053436532616615
Loss at iteration 1420 : 0.0009267728310078382
Loss at iteration 1430 : 0.00017548163305036724
Loss at iteration 1440 : 0.0004480968345887959
Loss at iteration 1450 : 0.0009325701394118369
Loss at iteration 1460 : 0.001153786201030016
Loss at iteration 1470 : 0.004617697559297085
Loss at iteration 1480 : 0.0001457845064578578
Loss at iteration 1490 : 0.000771187013015151
Loss at iteration 1500 : 0.0005265043582767248
Loss at iteration 1510 : 0.0001504806277807802
Loss at iteration 1520 : 0.00011820483632618561
Loss at iteration 1530 : 0.0002666895161382854
Loss at iteration 1540 : 0.00030976010020822287
Loss at iteration 1550 : 9.753590711625293e-05
Loss at iteration 1560 : 0.0007172245532274246
Loss at iteration 1570 : 0.0010169482557103038
Loss at iteration 1580 : 0.00014808002742938697
Loss at iteration 1590 : 0.0037909147795289755
Loss at iteration 1600 : 0.0001863293582573533
Loss at iteration 1610 : 0.00291038048453629
Loss at iteration 1620 : 0.0003748717426788062
Loss at iteration 1630 : 0.009606885723769665
Loss at iteration 1640 : 0.0002683044585864991
Loss at iteration 1650 : 0.008300885558128357
Loss at iteration 1660 : 0.0007153478218242526
Loss at iteration 1670 : 0.0014878194779157639
Loss at iteration 1680 : 0.0018737231148406863
Loss at iteration 1690 : 0.00035016980837099254
Loss at iteration 1700 : 4.8118621634785086e-05
Loss at iteration 1710 : 0.0002637733123265207
Loss at iteration 1720 : 0.00032776722218841314
Loss at iteration 1730 : 0.0010607236763462424
Loss at iteration 1740 : 7.219653343781829e-05
Loss at iteration 1750 : 0.0015210674609988928
The SSIM Value is: 0.9869443919952745
The PSNR Value is: 46.65163476246569
the epoch is: 37
Loss at iteration 10 : 0.0007514363387599587
Loss at iteration 20 : 9.448875061934814e-05
Loss at iteration 30 : 0.00016071465506684035
Loss at iteration 40 : 0.003718382678925991
Loss at iteration 50 : 0.0003310001047793776
Loss at iteration 60 : 0.0023162218276411295
Loss at iteration 70 : 0.00013511008000932634
Loss at iteration 80 : 0.0002492878120392561
Loss at iteration 90 : 0.00038358470192179084
Loss at iteration 100 : 0.0001396140141878277
Loss at iteration 110 : 0.007843163795769215
Loss at iteration 120 : 0.00020098326785955578
Loss at iteration 130 : 0.003755575977265835
Loss at iteration 140 : 0.0001798399316612631
Loss at iteration 150 : 0.00033347218413837254
Loss at iteration 160 : 0.0008418549550697207
Loss at iteration 170 : 0.0026189154013991356
Loss at iteration 180 : 0.004426263272762299
Loss at iteration 190 : 0.0001424154470441863
Loss at iteration 200 : 0.000954687362536788
Loss at iteration 210 : 0.0019996431656181812
Loss at iteration 220 : 0.0010262627620249987
Loss at iteration 230 : 0.001241197343915701
Loss at iteration 240 : 0.00022708896722178906
Loss at iteration 250 : 0.00018244743114337325
Loss at iteration 260 : 0.002051310380920768
Loss at iteration 270 : 9.696190682007e-05
Loss at iteration 280 : 0.0027754399925470352
Loss at iteration 290 : 0.00017787073738873005
Loss at iteration 300 : 0.00028742922586388886
Loss at iteration 310 : 0.0001487502595409751
Loss at iteration 320 : 0.00026258424622938037
Loss at iteration 330 : 0.00042652070987969637
Loss at iteration 340 : 0.00017749154358170927
Loss at iteration 350 : 6.529833626700565e-05
Loss at iteration 360 : 0.0012050606310367584
Loss at iteration 370 : 0.00011928847379749641
Loss at iteration 380 : 0.0062301503494381905
Loss at iteration 390 : 0.0006792594795115292
Loss at iteration 400 : 0.0003068085643462837
Loss at iteration 410 : 0.004049979615956545
Loss at iteration 420 : 0.007119255140423775
Loss at iteration 430 : 5.781990694231354e-05
Loss at iteration 440 : 0.00022894184803590178
Loss at iteration 450 : 0.0031394429970532656
Loss at iteration 460 : 0.0002250989928143099
Loss at iteration 470 : 0.0018939796136692166
Loss at iteration 480 : 0.00024914441746659577
Loss at iteration 490 : 0.0013257099781185389
Loss at iteration 500 : 0.002216717228293419
Loss at iteration 510 : 0.0018319784430786967
Loss at iteration 520 : 0.00015468557830899954
Loss at iteration 530 : 9.19090089155361e-05
Loss at iteration 540 : 0.0015772177139297128
Loss at iteration 550 : 0.0015855093952268362
Loss at iteration 560 : 0.00032001265208236873
Loss at iteration 570 : 0.0010770636145025492
Loss at iteration 580 : 0.001356660621240735
Loss at iteration 590 : 0.00017377155018039048
Loss at iteration 600 : 0.00017887182184495032
Loss at iteration 610 : 0.0004819831810891628
Loss at iteration 620 : 4.686527245212346e-05
Loss at iteration 630 : 0.0007465792587026954
Loss at iteration 640 : 0.0020316019654273987
Loss at iteration 650 : 0.001782963634468615
Loss at iteration 660 : 0.00019254934159107506
Loss at iteration 670 : 0.00013553147437050939
Loss at iteration 680 : 0.00023884042457211763
Loss at iteration 690 : 0.0005336106405593455
Loss at iteration 700 : 0.0005609701620414853
Loss at iteration 710 : 0.00010756327537819743
Loss at iteration 720 : 0.0029160398989915848
Loss at iteration 730 : 0.006282126531004906
Loss at iteration 740 : 0.00031764269806444645
Loss at iteration 750 : 0.0034304806031286716
Loss at iteration 760 : 0.0015924368053674698
Loss at iteration 770 : 0.00123015814460814
Loss at iteration 780 : 0.00019863879424519837
Loss at iteration 790 : 0.0001467261608922854
Loss at iteration 800 : 0.00010480644414201379
Loss at iteration 810 : 0.0017344780499115586
Loss at iteration 820 : 0.002821532543748617
Loss at iteration 830 : 0.00015373526548501104
Loss at iteration 840 : 0.0033507172483950853
Loss at iteration 850 : 9.891075023915619e-05
Loss at iteration 860 : 0.0012937627034261823
Loss at iteration 870 : 0.00010334717080695555
Loss at iteration 880 : 5.870021414011717e-05
Loss at iteration 890 : 0.0008237562142312527
Loss at iteration 900 : 0.0001501748338341713
Loss at iteration 910 : 0.0003513674018904567
Loss at iteration 920 : 0.00021920353174209595
Loss at iteration 930 : 0.0023511257022619247
Loss at iteration 940 : 0.000542857451364398
Loss at iteration 950 : 0.00012541802425403148
Loss at iteration 960 : 0.00012892730592284352
Loss at iteration 970 : 0.0007074469467625022
Loss at iteration 980 : 0.00015648409316781908
Loss at iteration 990 : 0.00020269544620532542
Loss at iteration 1000 : 0.002357759280130267
Loss at iteration 1010 : 0.0020108057651668787
Loss at iteration 1020 : 0.004499142523854971
Loss at iteration 1030 : 0.0002532032667659223
Loss at iteration 1040 : 0.00041588774183765054
Loss at iteration 1050 : 0.0002959842677228153
Loss at iteration 1060 : 0.0009837726829573512
Loss at iteration 1070 : 0.0003346795856487006
Loss at iteration 1080 : 0.00041840857011266053
Loss at iteration 1090 : 0.00018454829114489257
Loss at iteration 1100 : 0.0002716016606427729
Loss at iteration 1110 : 0.0037087122909724712
Loss at iteration 1120 : 0.0003085894859395921
Loss at iteration 1130 : 0.0021759713999927044
Loss at iteration 1140 : 8.789171261014417e-05
Loss at iteration 1150 : 0.0005582977901212871
Loss at iteration 1160 : 5.2018905989825726e-05
Loss at iteration 1170 : 0.0030183838680386543
Loss at iteration 1180 : 0.0003175857709720731
Loss at iteration 1190 : 0.003461106214672327
Loss at iteration 1200 : 0.0006211244617588818
Loss at iteration 1210 : 9.32980328798294e-05
Loss at iteration 1220 : 0.0014424368273466825
Loss at iteration 1230 : 0.0026812576688826084
Loss at iteration 1240 : 0.00010571969323791564
Loss at iteration 1250 : 0.00024192128330469131
Loss at iteration 1260 : 0.0005250513786450028
Loss at iteration 1270 : 0.00012633149162866175
Loss at iteration 1280 : 0.0005028062732890248
Loss at iteration 1290 : 0.0007794626289978623
Loss at iteration 1300 : 0.0039321184158325195
Loss at iteration 1310 : 0.000396786374039948
Loss at iteration 1320 : 0.0007059526978991926
Loss at iteration 1330 : 0.0005206107161939144
Loss at iteration 1340 : 0.000874083605594933
Loss at iteration 1350 : 0.0004311717639211565
Loss at iteration 1360 : 0.00042215269058942795
Loss at iteration 1370 : 0.003022490069270134
Loss at iteration 1380 : 0.0004999274387955666
Loss at iteration 1390 : 0.00010694593220250681
Loss at iteration 1400 : 0.00027488547493703663
Loss at iteration 1410 : 0.005157468840479851
Loss at iteration 1420 : 0.0001323302130913362
Loss at iteration 1430 : 0.00014131516218185425
Loss at iteration 1440 : 0.0058213816955685616
Loss at iteration 1450 : 0.00013817100261803716
Loss at iteration 1460 : 0.00032787880627438426
Loss at iteration 1470 : 0.00044998503290116787
Loss at iteration 1480 : 0.0004944774555042386
Loss at iteration 1490 : 0.0004258702974766493
Loss at iteration 1500 : 0.00011948203609790653
Loss at iteration 1510 : 0.001990205841138959
Loss at iteration 1520 : 0.0004202036070637405
Loss at iteration 1530 : 0.0006033207755535841
Loss at iteration 1540 : 0.0022467963863164186
Loss at iteration 1550 : 0.0007385084172710776
Loss at iteration 1560 : 0.005566369276493788
Loss at iteration 1570 : 0.00021851688507013023
Loss at iteration 1580 : 0.00028308521723374724
Loss at iteration 1590 : 0.002026207745075226
Loss at iteration 1600 : 0.0006655801553279161
Loss at iteration 1610 : 0.0004997467622160912
Loss at iteration 1620 : 0.00010553729953244328
Loss at iteration 1630 : 0.0014029581798240542
Loss at iteration 1640 : 0.0012189308181405067
Loss at iteration 1650 : 0.00013178307563066483
Loss at iteration 1660 : 0.0005599840078502893
Loss at iteration 1670 : 0.0025408142246305943
Loss at iteration 1680 : 0.0011262501357123256
Loss at iteration 1690 : 0.001165538327768445
Loss at iteration 1700 : 0.0013173436746001244
Loss at iteration 1710 : 0.00013419902825262398
Loss at iteration 1720 : 0.00024578985176049173
Loss at iteration 1730 : 0.0003891108208335936
Loss at iteration 1740 : 0.0012352822814136744
Loss at iteration 1750 : 0.00186520058196038
The SSIM Value is: 0.9885383153801973
The PSNR Value is: 46.74285984249367
the highest SSIM value is: 46.74285984249367
the epoch is: 38
Loss at iteration 10 : 6.70317022013478e-05
Loss at iteration 20 : 0.000187338562682271
Loss at iteration 30 : 0.0010809481609612703
Loss at iteration 40 : 0.0014527842868119478
Loss at iteration 50 : 0.0002568436320871115
Loss at iteration 60 : 0.0006074969423934817
Loss at iteration 70 : 0.0008701387559995055
Loss at iteration 80 : 0.00014577923866454512
Loss at iteration 90 : 0.002160841366276145
Loss at iteration 100 : 0.00010078652121592313
Loss at iteration 110 : 0.0007004415383562446
Loss at iteration 120 : 0.00018179335165768862
Loss at iteration 130 : 0.00026868077111430466
Loss at iteration 140 : 0.00014252701657824218
Loss at iteration 150 : 0.0012451531365513802
Loss at iteration 160 : 0.0007749179494567215
Loss at iteration 170 : 0.00022190499294083565
Loss at iteration 180 : 0.00032698645372875035
Loss at iteration 190 : 0.005578329320997
Loss at iteration 200 : 0.00010485433449503034
Loss at iteration 210 : 0.00013235455844551325
Loss at iteration 220 : 0.00045767432311549783
Loss at iteration 230 : 0.0001236714015249163
Loss at iteration 240 : 0.00032805794035084546
Loss at iteration 250 : 0.0033638160675764084
Loss at iteration 260 : 0.0013809700030833483
Loss at iteration 270 : 9.06489003682509e-05
Loss at iteration 280 : 0.0026756981387734413
Loss at iteration 290 : 0.0010969311697408557
Loss at iteration 300 : 0.00018652123981155455
Loss at iteration 310 : 0.00153032795060426
Loss at iteration 320 : 0.0003835568786598742
Loss at iteration 330 : 0.0005342093645595014
Loss at iteration 340 : 0.0018776656361296773
Loss at iteration 350 : 0.0001820376346586272
Loss at iteration 360 : 0.0001657040702411905
Loss at iteration 370 : 0.00033146952046081424
Loss at iteration 380 : 0.0028579263016581535
Loss at iteration 390 : 0.0006167731480672956
Loss at iteration 400 : 0.00015205163799691945
Loss at iteration 410 : 0.0003192706499248743
Loss at iteration 420 : 0.0001791573886293918
Loss at iteration 430 : 0.002433772198855877
Loss at iteration 440 : 0.00010026164090959355
Loss at iteration 450 : 0.0009693637257441878
Loss at iteration 460 : 0.0036273631267249584
Loss at iteration 470 : 0.00011601706501096487
Loss at iteration 480 : 0.003383427858352661
Loss at iteration 490 : 0.0003703777911141515
Loss at iteration 500 : 0.00024607169325463474
Loss at iteration 510 : 0.0006866483599878848
Loss at iteration 520 : 0.0004936209879815578
Loss at iteration 530 : 0.004595733247697353
Loss at iteration 540 : 0.0002293657453265041
Loss at iteration 550 : 0.0033271927386522293
Loss at iteration 560 : 0.00017196789849549532
Loss at iteration 570 : 0.00044960365630686283
Loss at iteration 580 : 0.00015308950969483703
Loss at iteration 590 : 0.0005685744108632207
Loss at iteration 600 : 0.00026957516092807055
Loss at iteration 610 : 0.0006130095571279526
Loss at iteration 620 : 0.002449848223477602
Loss at iteration 630 : 0.003725768066942692
Loss at iteration 640 : 0.00038079795194789767
Loss at iteration 650 : 0.0002644032356329262
Loss at iteration 660 : 0.00031579972710460424
Loss at iteration 670 : 0.00039610848762094975
Loss at iteration 680 : 0.00021690456196665764
Loss at iteration 690 : 0.0021640039049088955
Loss at iteration 700 : 0.0008022304391488433
Loss at iteration 710 : 0.005984964780509472
Loss at iteration 720 : 0.00035583737189881504
Loss at iteration 730 : 0.0028803166933357716
Loss at iteration 740 : 0.00038756494177505374
Loss at iteration 750 : 0.0028302553109824657
Loss at iteration 760 : 0.00018532878311816603
Loss at iteration 770 : 0.00044571608304977417
Loss at iteration 780 : 0.00016491924179717898
Loss at iteration 790 : 0.000802614027634263
Loss at iteration 800 : 0.0001926766854012385
Loss at iteration 810 : 0.0005325746606104076
Loss at iteration 820 : 0.0002803877287078649
Loss at iteration 830 : 0.000514065264724195
Loss at iteration 840 : 0.00016345844778697938
Loss at iteration 850 : 0.00020243276958353817
Loss at iteration 860 : 0.0032878464553505182
Loss at iteration 870 : 0.0008520424016751349
Loss at iteration 880 : 0.00011745233496185392
Loss at iteration 890 : 0.0023168730549514294
Loss at iteration 900 : 0.00039980566361919045
Loss at iteration 910 : 0.0029071469325572252
Loss at iteration 920 : 0.005938742775470018
Loss at iteration 930 : 0.00011680265743052587
Loss at iteration 940 : 0.0004982405225746334
Loss at iteration 950 : 0.0022826013155281544
Loss at iteration 960 : 0.0002453792258165777
Loss at iteration 970 : 0.0010125000262632966
Loss at iteration 980 : 0.00045821728417649865
Loss at iteration 990 : 0.00013648055028170347
Loss at iteration 1000 : 0.0002723835641518235
Loss at iteration 1010 : 0.00012111418618587777
Loss at iteration 1020 : 0.0037488294765353203
Loss at iteration 1030 : 0.0001637050008866936
Loss at iteration 1040 : 0.0012591599952429533
Loss at iteration 1050 : 0.0010724584572017193
Loss at iteration 1060 : 0.0009197952458634973
Loss at iteration 1070 : 0.0005693802377209067
Loss at iteration 1080 : 0.0001784129999577999
Loss at iteration 1090 : 0.00025758048286661506
Loss at iteration 1100 : 0.0007307825144380331
Loss at iteration 1110 : 0.0037507181987166405
Loss at iteration 1120 : 0.0006198162445798516
Loss at iteration 1130 : 0.005750538781285286
Loss at iteration 1140 : 0.004045168869197369
Loss at iteration 1150 : 0.004474050365388393
Loss at iteration 1160 : 0.0010887804673984647
Loss at iteration 1170 : 0.0038499925285577774
Loss at iteration 1180 : 0.0015584304928779602
Loss at iteration 1190 : 5.106915341457352e-05
Loss at iteration 1200 : 0.0009224789100699127
Loss at iteration 1210 : 0.001850490691140294
Loss at iteration 1220 : 0.003694497048854828
Loss at iteration 1230 : 0.0010299698915332556
Loss at iteration 1240 : 9.187783871311694e-05
Loss at iteration 1250 : 0.00034393087844364345
Loss at iteration 1260 : 0.0005113193183206022
Loss at iteration 1270 : 0.005813672207295895
Loss at iteration 1280 : 0.0007933032466098666
Loss at iteration 1290 : 0.0002758917398750782
Loss at iteration 1300 : 0.00014614265819545835
Loss at iteration 1310 : 0.0005591614171862602
Loss at iteration 1320 : 0.00015679217176511884
Loss at iteration 1330 : 5.262262129690498e-05
Loss at iteration 1340 : 5.800193684990518e-05
Loss at iteration 1350 : 0.0005228063673712313
Loss at iteration 1360 : 0.0005657695583067834
Loss at iteration 1370 : 0.0068945749662816525
Loss at iteration 1380 : 0.004442548844963312
Loss at iteration 1390 : 0.0014526961604133248
Loss at iteration 1400 : 0.004506808705627918
Loss at iteration 1410 : 0.006368394009768963
Loss at iteration 1420 : 0.0004929053829982877
Loss at iteration 1430 : 0.0004936052719131112
Loss at iteration 1440 : 0.00012797408271580935
Loss at iteration 1450 : 0.00021884273155592382
Loss at iteration 1460 : 0.00010838382149813697
Loss at iteration 1470 : 0.00012986455112695694
Loss at iteration 1480 : 0.00031015207059681416
Loss at iteration 1490 : 0.0007516514742746949
Loss at iteration 1500 : 0.00010504703095648438
Loss at iteration 1510 : 0.00018332665786147118
Loss at iteration 1520 : 0.00020596812828443944
Loss at iteration 1530 : 0.00012152618000982329
Loss at iteration 1540 : 0.0028631160967051983
Loss at iteration 1550 : 0.0003322040429338813
Loss at iteration 1560 : 0.001535993767902255
Loss at iteration 1570 : 0.00036089285276830196
Loss at iteration 1580 : 0.0026928852312266827
Loss at iteration 1590 : 0.00021088482753839344
Loss at iteration 1600 : 0.0030895669478923082
Loss at iteration 1610 : 0.0027554179541766644
Loss at iteration 1620 : 0.0020195599645376205
Loss at iteration 1630 : 0.00014228479994926602
Loss at iteration 1640 : 0.0016020929906517267
Loss at iteration 1650 : 0.0007240462582558393
Loss at iteration 1660 : 0.0003661899536382407
Loss at iteration 1670 : 0.00020809267880395055
Loss at iteration 1680 : 0.0001642303541302681
Loss at iteration 1690 : 0.00020061472605448216
Loss at iteration 1700 : 0.0048897964879870415
Loss at iteration 1710 : 0.0103839710354805
Loss at iteration 1720 : 0.00015249148418661207
Loss at iteration 1730 : 0.00017256036517210305
Loss at iteration 1740 : 0.0007504541426897049
Loss at iteration 1750 : 0.0006929313531145453
The SSIM Value is: 0.9866063899405727
The PSNR Value is: 46.32021706955023
the epoch is: 39
Loss at iteration 10 : 0.00024612434208393097
Loss at iteration 20 : 0.0002650184615049511
Loss at iteration 30 : 0.0005691639962606132
Loss at iteration 40 : 0.005226327106356621
Loss at iteration 50 : 0.0009870774811133742
Loss at iteration 60 : 0.0007786740316078067
Loss at iteration 70 : 0.004213922657072544
Loss at iteration 80 : 0.0006323856068775058
Loss at iteration 90 : 0.0003810862544924021
Loss at iteration 100 : 0.00013095869508106261
Loss at iteration 110 : 0.00215798057615757
Loss at iteration 120 : 0.00098102493211627
Loss at iteration 130 : 0.0043110898695886135
Loss at iteration 140 : 0.00015437549154739827
Loss at iteration 150 : 6.47495617158711e-05
Loss at iteration 160 : 0.00012153721763752401
Loss at iteration 170 : 0.001526201842352748
Loss at iteration 180 : 0.00020105367002543062
Loss at iteration 190 : 0.0005810256698168814
Loss at iteration 200 : 0.0003163520013913512
Loss at iteration 210 : 0.00010074555029859766
Loss at iteration 220 : 0.0002167227939935401
Loss at iteration 230 : 0.002690289169549942
Loss at iteration 240 : 7.480925705749542e-05
Loss at iteration 250 : 0.0023144581355154514
Loss at iteration 260 : 0.0036219912581145763
Loss at iteration 270 : 0.00016283032891806215
Loss at iteration 280 : 0.0003330940380692482
Loss at iteration 290 : 0.0005579408607445657
Loss at iteration 300 : 0.00010578014189377427
Loss at iteration 310 : 0.0036633263807743788
Loss at iteration 320 : 0.0001680454151937738
Loss at iteration 330 : 0.00018950444064103067
Loss at iteration 340 : 0.0002661443722900003
Loss at iteration 350 : 0.0011737160384654999
Loss at iteration 360 : 0.003841336350888014
Loss at iteration 370 : 0.00016872165724635124
Loss at iteration 380 : 0.0016072026919573545
Loss at iteration 390 : 0.0002911257615778595
Loss at iteration 400 : 0.00019144573889207095
Loss at iteration 410 : 0.0010168644366785884
Loss at iteration 420 : 0.00037417240673676133
Loss at iteration 430 : 0.003618604503571987
Loss at iteration 440 : 8.991355571197346e-05
Loss at iteration 450 : 0.00019199843518435955
Loss at iteration 460 : 0.00032712507527321577
Loss at iteration 470 : 0.00013428754755295813
Loss at iteration 480 : 0.0004626133886631578
Loss at iteration 490 : 0.000863279274199158
Loss at iteration 500 : 0.0005886516883037984
Loss at iteration 510 : 0.002076831180602312
Loss at iteration 520 : 0.0003188942209817469
Loss at iteration 530 : 0.00019249742035754025
Loss at iteration 540 : 6.28837660769932e-05
Loss at iteration 550 : 0.00021078014106024057
Loss at iteration 560 : 0.00019531928410287946
Loss at iteration 570 : 0.0001642134302528575
Loss at iteration 580 : 0.0008709407411515713
Loss at iteration 590 : 0.00010869442485272884
Loss at iteration 600 : 0.00015058729331940413
Loss at iteration 610 : 0.0018365213181823492
Loss at iteration 620 : 0.0005743207293562591
Loss at iteration 630 : 0.00013185876014176756
Loss at iteration 640 : 0.0018673803424462676
Loss at iteration 650 : 0.00012290783342905343
Loss at iteration 660 : 0.0017337427707388997
Loss at iteration 670 : 0.004635884426534176
Loss at iteration 680 : 0.00012424336455296725
Loss at iteration 690 : 0.00010402120824437588
Loss at iteration 700 : 0.0001140239619417116
Loss at iteration 710 : 0.001158217084594071
Loss at iteration 720 : 4.2459996620891616e-05
Loss at iteration 730 : 0.0030245983507484198
Loss at iteration 740 : 0.00044217862887308
Loss at iteration 750 : 0.0010645868023857474
Loss at iteration 760 : 0.00021693344751838595
Loss at iteration 770 : 0.00017376584582962096
Loss at iteration 780 : 0.0012818194227293134
Loss at iteration 790 : 9.977364970836788e-05
Loss at iteration 800 : 0.000139286566991359
Loss at iteration 810 : 0.00017675204435363412
Loss at iteration 820 : 0.00027116757701151073
Loss at iteration 830 : 0.003927342593669891
Loss at iteration 840 : 0.0022160010412335396
Loss at iteration 850 : 0.000192441075341776
Loss at iteration 860 : 0.00015463915769942105
Loss at iteration 870 : 0.004054040648043156
Loss at iteration 880 : 0.0006346550071612
Loss at iteration 890 : 0.000500482798088342
Loss at iteration 900 : 0.0005637872964143753
Loss at iteration 910 : 6.999979086685926e-05
Loss at iteration 920 : 9.281773236580193e-05
Loss at iteration 930 : 3.841927900793962e-05
Loss at iteration 940 : 0.0033579394221305847
Loss at iteration 950 : 0.00044238826376385987
Loss at iteration 960 : 0.00020531617337837815
Loss at iteration 970 : 9.73439309746027e-05
Loss at iteration 980 : 0.0025834229309111834
Loss at iteration 990 : 0.002183669013902545
Loss at iteration 1000 : 0.00017519507673569024
Loss at iteration 1010 : 0.003759735729545355
Loss at iteration 1020 : 0.00014102128625381738
Loss at iteration 1030 : 0.0001321469317190349
Loss at iteration 1040 : 0.0004517931374721229
Loss at iteration 1050 : 0.0004601671826094389
Loss at iteration 1060 : 0.0012249883729964495
Loss at iteration 1070 : 0.003943855408579111
Loss at iteration 1080 : 0.00021767245198134333
Loss at iteration 1090 : 0.0003973967977799475
Loss at iteration 1100 : 9.021173173096031e-05
Loss at iteration 1110 : 0.0004058494814671576
Loss at iteration 1120 : 0.0014237891882658005
Loss at iteration 1130 : 0.0003872608649544418
Loss at iteration 1140 : 0.00024860058329068124
Loss at iteration 1150 : 8.164808969013393e-05
Loss at iteration 1160 : 0.0006306340219452977
Loss at iteration 1170 : 0.0007212056079879403
Loss at iteration 1180 : 0.0007155928760766983
Loss at iteration 1190 : 0.0011430811136960983
Loss at iteration 1200 : 0.0024662171490490437
Loss at iteration 1210 : 0.0005720398621633649
Loss at iteration 1220 : 0.00016186048742383718
Loss at iteration 1230 : 0.0013834417331963778
Loss at iteration 1240 : 0.00012259367213118821
Loss at iteration 1250 : 0.00047945004189386964
Loss at iteration 1260 : 0.0004220171831548214
Loss at iteration 1270 : 5.3658539400203153e-05
Loss at iteration 1280 : 0.002809426747262478
Loss at iteration 1290 : 0.00047732016537338495
Loss at iteration 1300 : 7.679292320972309e-05
Loss at iteration 1310 : 0.0005213741096667945
Loss at iteration 1320 : 0.0001499013160355389
Loss at iteration 1330 : 0.00010421606566524133
Loss at iteration 1340 : 0.003710024058818817
Loss at iteration 1350 : 0.0005727992975153029
Loss at iteration 1360 : 0.0013790962984785438
Loss at iteration 1370 : 0.00011738800094462931
Loss at iteration 1380 : 0.001856273040175438
Loss at iteration 1390 : 0.005279483273625374
Loss at iteration 1400 : 0.0008069924078881741
Loss at iteration 1410 : 0.00011878191435243934
Loss at iteration 1420 : 0.00019616169447544962
Loss at iteration 1430 : 0.002011007396504283
Loss at iteration 1440 : 0.000661599391605705
Loss at iteration 1450 : 0.00033256434835493565
Loss at iteration 1460 : 0.00025816471315920353
Loss at iteration 1470 : 0.00012613787839654833
Loss at iteration 1480 : 0.00153487385250628
Loss at iteration 1490 : 0.003534669056534767
Loss at iteration 1500 : 0.003282131627202034
Loss at iteration 1510 : 0.00021857034880667925
Loss at iteration 1520 : 0.00018188105605076998
Loss at iteration 1530 : 0.0026042265817523003
Loss at iteration 1540 : 0.0028444756753742695
Loss at iteration 1550 : 0.001033168169669807
Loss at iteration 1560 : 0.0013857786543667316
Loss at iteration 1570 : 0.0033308551646769047
Loss at iteration 1580 : 0.005163588095456362
Loss at iteration 1590 : 0.00011012562754331157
Loss at iteration 1600 : 0.00023908549337647855
Loss at iteration 1610 : 0.0011858157813549042
Loss at iteration 1620 : 0.0011892484035342932
Loss at iteration 1630 : 0.00017484353156760335
Loss at iteration 1640 : 0.0008573270170018077
Loss at iteration 1650 : 0.0005352214211598039
Loss at iteration 1660 : 0.00011447632277850062
Loss at iteration 1670 : 0.00013598246732726693
Loss at iteration 1680 : 0.0026746487710624933
Loss at iteration 1690 : 0.0015981687465682626
Loss at iteration 1700 : 0.0019354925025254488
Loss at iteration 1710 : 0.003059763927012682
Loss at iteration 1720 : 5.179028812563047e-05
Loss at iteration 1730 : 0.0002522155409678817
Loss at iteration 1740 : 0.0012746193679049611
Loss at iteration 1750 : 0.00023444795806426555
The SSIM Value is: 0.981049699142641
The PSNR Value is: 46.58210064976226
the epoch is: 40
Loss at iteration 10 : 0.005035692825913429
Loss at iteration 20 : 0.00011740659829229116
Loss at iteration 30 : 0.0012558643938973546
Loss at iteration 40 : 0.0011180434376001358
Loss at iteration 50 : 0.003348056459799409
Loss at iteration 60 : 9.354701614938676e-05
Loss at iteration 70 : 0.0027066124603152275
Loss at iteration 80 : 5.779569983133115e-05
Loss at iteration 90 : 0.001123784575611353
Loss at iteration 100 : 0.003481511026620865
Loss at iteration 110 : 0.0027198793832212687
Loss at iteration 120 : 0.00010301537258783355
Loss at iteration 130 : 0.00048609147779643536
Loss at iteration 140 : 0.00022827723296359181
Loss at iteration 150 : 0.00010124721302418038
Loss at iteration 160 : 0.0004080736543983221
Loss at iteration 170 : 0.0002754997694864869
Loss at iteration 180 : 8.945821173256263e-05
Loss at iteration 190 : 0.0006684581167064607
Loss at iteration 200 : 0.0031202398240566254
Loss at iteration 210 : 0.0038643127772957087
Loss at iteration 220 : 0.0004733643145300448
Loss at iteration 230 : 0.00019492347200866789
Loss at iteration 240 : 0.003317312803119421
Loss at iteration 250 : 0.0003197611076757312
Loss at iteration 260 : 7.149662997107953e-05
Loss at iteration 270 : 0.0005902773700654507
Loss at iteration 280 : 0.0027860484551638365
Loss at iteration 290 : 0.0005264835781417787
Loss at iteration 300 : 0.0001551570021547377
Loss at iteration 310 : 0.00011649078805930912
Loss at iteration 320 : 0.00031755887903273106
Loss at iteration 330 : 0.0004385224892757833
Loss at iteration 340 : 0.0008370619034394622
Loss at iteration 350 : 0.0007596360519528389
Loss at iteration 360 : 0.002053849631920457
Loss at iteration 370 : 0.0006733961054123938
Loss at iteration 380 : 0.004827284254133701
Loss at iteration 390 : 0.0009111494873650372
Loss at iteration 400 : 0.002503864234313369
Loss at iteration 410 : 0.0006451091612689197
Loss at iteration 420 : 0.002985222265124321
Loss at iteration 430 : 0.0004063200030941516
Loss at iteration 440 : 0.00018812186317518353
Loss at iteration 450 : 0.0011951869819313288
Loss at iteration 460 : 0.00014504198043141514
Loss at iteration 470 : 0.003391590900719166
Loss at iteration 480 : 0.0006231736624613404
Loss at iteration 490 : 0.0022334083914756775
Loss at iteration 500 : 0.0017586869653314352
Loss at iteration 510 : 0.0007509208517149091
Loss at iteration 520 : 0.00012312633043620735
Loss at iteration 530 : 0.0017089392058551311
Loss at iteration 540 : 0.00013080767530482262
Loss at iteration 550 : 0.0012543534394353628
Loss at iteration 560 : 0.0001630233455216512
Loss at iteration 570 : 0.00016015867004171014
Loss at iteration 580 : 0.0023255525156855583
Loss at iteration 590 : 6.481751915998757e-05
Loss at iteration 600 : 0.00033505994360893965
Loss at iteration 610 : 0.00011321935744490474
Loss at iteration 620 : 0.00013301856233738363
Loss at iteration 630 : 0.0001079915018635802
Loss at iteration 640 : 0.00021948368521407247
Loss at iteration 650 : 0.00037004711339250207
Loss at iteration 660 : 0.0013486272655427456
Loss at iteration 670 : 0.0011599137214943767
Loss at iteration 680 : 0.00015567283844575286
Loss at iteration 690 : 0.0005868111038580537
Loss at iteration 700 : 0.002969908295199275
Loss at iteration 710 : 0.0002643109764903784
Loss at iteration 720 : 0.0016999092185869813
Loss at iteration 730 : 0.0003224714600946754
Loss at iteration 740 : 0.0003302195109426975
Loss at iteration 750 : 0.0001652101200306788
Loss at iteration 760 : 0.0002600677835289389
Loss at iteration 770 : 0.0021980823948979378
Loss at iteration 780 : 0.00017625285545364022
Loss at iteration 790 : 0.0019008053932338953
Loss at iteration 800 : 0.0038244305178523064
Loss at iteration 810 : 0.006132292095571756
Loss at iteration 820 : 6.0317932366160676e-05
Loss at iteration 830 : 0.00021773752814624459
Loss at iteration 840 : 0.002950175665318966
Loss at iteration 850 : 0.00016457645688205957
Loss at iteration 860 : 0.0005145442555658519
Loss at iteration 870 : 0.0001203785213874653
Loss at iteration 880 : 9.645877435104921e-05
Loss at iteration 890 : 4.901732609141618e-05
Loss at iteration 900 : 0.00036275829188525677
Loss at iteration 910 : 0.0012603816576302052
Loss at iteration 920 : 0.002125039231032133
Loss at iteration 930 : 0.0007106972625479102
Loss at iteration 940 : 0.00026785137015394866
Loss at iteration 950 : 0.0038776290602982044
Loss at iteration 960 : 0.00022560422075912356
Loss at iteration 970 : 0.0002735915477387607
Loss at iteration 980 : 0.00011646300845313817
Loss at iteration 990 : 0.00021363268024288118
Loss at iteration 1000 : 0.00043674229527823627
Loss at iteration 1010 : 0.00026961881667375565
Loss at iteration 1020 : 0.0002025187131948769
Loss at iteration 1030 : 0.0011146742617711425
Loss at iteration 1040 : 0.00025375315453857183
Loss at iteration 1050 : 0.0008963841246441007
Loss at iteration 1060 : 0.0037581385113298893
Loss at iteration 1070 : 0.0001095367842935957
Loss at iteration 1080 : 8.064409485086799e-05
Loss at iteration 1090 : 0.0009026369079947472
Loss at iteration 1100 : 0.00027182206395082176
Loss at iteration 1110 : 0.0005397547502070665
Loss at iteration 1120 : 0.00019411109678912908
Loss at iteration 1130 : 0.0006936111021786928
Loss at iteration 1140 : 0.0007018591859377921
Loss at iteration 1150 : 0.0018252319423481822
Loss at iteration 1160 : 0.00011749145050998777
Loss at iteration 1170 : 0.00018454992095939815
Loss at iteration 1180 : 6.909602234372869e-05
Loss at iteration 1190 : 0.0016746323090046644
Loss at iteration 1200 : 0.00010259853297611699
Loss at iteration 1210 : 0.0040790606290102005
Loss at iteration 1220 : 0.001725500333122909
Loss at iteration 1230 : 0.0004263274313416332
Loss at iteration 1240 : 0.00011973555956501514
Loss at iteration 1250 : 0.0004923930973745883
Loss at iteration 1260 : 0.0021478417329490185
Loss at iteration 1270 : 0.0007174088386818767
Loss at iteration 1280 : 0.0005802407977171242
Loss at iteration 1290 : 0.0010063963709399104
Loss at iteration 1300 : 0.0002378181234234944
Loss at iteration 1310 : 0.00016364284965675324
Loss at iteration 1320 : 0.001501074992120266
Loss at iteration 1330 : 0.00147307850420475
Loss at iteration 1340 : 0.0010560848750174046
Loss at iteration 1350 : 0.00015457412519026548
Loss at iteration 1360 : 0.0006198158953338861
Loss at iteration 1370 : 0.0008744500810280442
Loss at iteration 1380 : 0.005473361816257238
Loss at iteration 1390 : 0.00013583264080807567
Loss at iteration 1400 : 0.00016794982366263866
Loss at iteration 1410 : 0.0007578459335491061
Loss at iteration 1420 : 0.00022561982041224837
Loss at iteration 1430 : 0.00015691985026933253
Loss at iteration 1440 : 0.00040362580330111086
Loss at iteration 1450 : 0.0005119428387843072
Loss at iteration 1460 : 0.001753002405166626
Loss at iteration 1470 : 7.61017290642485e-05
Loss at iteration 1480 : 0.0010612880578264594
Loss at iteration 1490 : 8.721493213670328e-05
Loss at iteration 1500 : 0.0004157621879130602
Loss at iteration 1510 : 0.002434362657368183
Loss at iteration 1520 : 0.0005046301521360874
Loss at iteration 1530 : 0.007651920430362225
Loss at iteration 1540 : 0.0002257371525047347
Loss at iteration 1550 : 0.0003508655063342303
Loss at iteration 1560 : 6.409669003915042e-05
Loss at iteration 1570 : 0.0025344439782202244
Loss at iteration 1580 : 0.00039263800135813653
Loss at iteration 1590 : 0.0009452344384044409
Loss at iteration 1600 : 0.01068108156323433
Loss at iteration 1610 : 0.001226535765454173
Loss at iteration 1620 : 0.0038512577302753925
Loss at iteration 1630 : 0.00015192374121397734
Loss at iteration 1640 : 0.000371867063222453
Loss at iteration 1650 : 0.00033135456033051014
Loss at iteration 1660 : 0.0001386068033752963
Loss at iteration 1670 : 0.00014857009227853268
Loss at iteration 1680 : 0.0009027700871229172
Loss at iteration 1690 : 0.0004931142320856452
Loss at iteration 1700 : 0.00024204832152463496
Loss at iteration 1710 : 0.0032861465588212013
Loss at iteration 1720 : 0.0007476312457583845
Loss at iteration 1730 : 0.0005800692597404122
Loss at iteration 1740 : 0.0002960466663353145
Loss at iteration 1750 : 0.00010292527440469712
The SSIM Value is: 0.9888026193112529
The PSNR Value is: 45.97693984834108
the epoch is: 41
Loss at iteration 10 : 0.00038143154233694077
Loss at iteration 20 : 0.002352422568947077
Loss at iteration 30 : 0.0006632698350585997
Loss at iteration 40 : 0.0005445232382044196
Loss at iteration 50 : 0.00017120264237746596
Loss at iteration 60 : 0.006001546513289213
Loss at iteration 70 : 0.00031418411526829004
Loss at iteration 80 : 0.00042064962326548994
Loss at iteration 90 : 0.0009469464421272278
Loss at iteration 100 : 0.00019348447676748037
Loss at iteration 110 : 0.0030614931602030993
Loss at iteration 120 : 0.00021787200239486992
Loss at iteration 130 : 0.0003651974839158356
Loss at iteration 140 : 0.0024401533883064985
Loss at iteration 150 : 0.0004139267257414758
Loss at iteration 160 : 0.00012041907757520676
Loss at iteration 170 : 0.0011889829766005278
Loss at iteration 180 : 0.0001325051998719573
Loss at iteration 190 : 0.002587190130725503
Loss at iteration 200 : 0.0009674411849118769
Loss at iteration 210 : 0.001108214957639575
Loss at iteration 220 : 0.00035981120890937746
Loss at iteration 230 : 0.005866896361112595
Loss at iteration 240 : 0.001059477450326085
Loss at iteration 250 : 0.0005359475035220385
Loss at iteration 260 : 0.00010671068594092503
Loss at iteration 270 : 0.00030526204500347376
Loss at iteration 280 : 0.0017616362310945988
Loss at iteration 290 : 0.001224370440468192
Loss at iteration 300 : 0.0002677813754417002
Loss at iteration 310 : 9.059606964001432e-05
Loss at iteration 320 : 0.0001933290041051805
Loss at iteration 330 : 0.002920872997492552
Loss at iteration 340 : 0.0001287186605622992
Loss at iteration 350 : 0.00017988451872952282
Loss at iteration 360 : 0.0020926552824676037
Loss at iteration 370 : 0.0002093434304697439
Loss at iteration 380 : 0.008427344262599945
Loss at iteration 390 : 3.589588595787063e-05
Loss at iteration 400 : 0.0020559236872941256
Loss at iteration 410 : 0.0005169373471289873
Loss at iteration 420 : 0.0005494848010130227
Loss at iteration 430 : 5.8147568779531866e-05
Loss at iteration 440 : 0.00019548891577869654
Loss at iteration 450 : 0.0002744242665357888
Loss at iteration 460 : 0.0014268751256167889
Loss at iteration 470 : 0.0007161286193877459
Loss at iteration 480 : 0.002339112339541316
Loss at iteration 490 : 0.006152229383587837
Loss at iteration 500 : 0.00019482802599668503
Loss at iteration 510 : 7.143078983062878e-05
Loss at iteration 520 : 8.63015084178187e-05
Loss at iteration 530 : 0.0001860426418716088
Loss at iteration 540 : 0.0013197929365560412
Loss at iteration 550 : 0.00024808989837765694
Loss at iteration 560 : 0.00017813831800594926
Loss at iteration 570 : 0.0030649376567453146
Loss at iteration 580 : 0.0030240430496633053
Loss at iteration 590 : 0.0006737337680533528
Loss at iteration 600 : 0.00020686883362941444
Loss at iteration 610 : 7.662869757041335e-05
Loss at iteration 620 : 0.0004112090973649174
Loss at iteration 630 : 0.00026134372455999255
Loss at iteration 640 : 9.828792099142447e-05
Loss at iteration 650 : 0.0022924530785530806
Loss at iteration 660 : 9.395187953487039e-05
Loss at iteration 670 : 0.0010801800526678562
Loss at iteration 680 : 0.003911599051207304
Loss at iteration 690 : 0.0003539319150149822
Loss at iteration 700 : 0.0043144566006958485
Loss at iteration 710 : 0.003504086984321475
Loss at iteration 720 : 0.00014385877875611186
Loss at iteration 730 : 0.000962037593126297
Loss at iteration 740 : 0.0001098297507269308
Loss at iteration 750 : 0.005688052624464035
Loss at iteration 760 : 0.00017116250819526613
Loss at iteration 770 : 0.0022889140527695417
Loss at iteration 780 : 0.00024171275435946882
Loss at iteration 790 : 0.0007765702903270721
Loss at iteration 800 : 0.0007714068633504212
Loss at iteration 810 : 0.002036947524175048
Loss at iteration 820 : 0.0004757670685648918
Loss at iteration 830 : 0.0002278917672811076
Loss at iteration 840 : 8.567086479160935e-05
Loss at iteration 850 : 0.0003064334159716964
Loss at iteration 860 : 0.0005831421003676951
Loss at iteration 870 : 0.00014169694622978568
Loss at iteration 880 : 7.060985080897808e-05
Loss at iteration 890 : 0.0025596823543310165
Loss at iteration 900 : 0.0010269302874803543
Loss at iteration 910 : 0.0009810930350795388
Loss at iteration 920 : 0.0007370761595666409
Loss at iteration 930 : 0.0005364289390854537
Loss at iteration 940 : 7.858987373765558e-05
Loss at iteration 950 : 0.0007858781609684229
Loss at iteration 960 : 0.0005180775187909603
Loss at iteration 970 : 0.0005427721189334989
Loss at iteration 980 : 0.00031782418955117464
Loss at iteration 990 : 0.00018376730440650135
Loss at iteration 1000 : 0.002782013500109315
Loss at iteration 1010 : 0.00280151329934597
Loss at iteration 1020 : 0.00015677307965233922
Loss at iteration 1030 : 0.000896648271009326
Loss at iteration 1040 : 0.0005391077720560133
Loss at iteration 1050 : 0.0032511744648218155
Loss at iteration 1060 : 0.0005093797808513045
Loss at iteration 1070 : 0.0005326909595169127
Loss at iteration 1080 : 0.0004940155777148902
Loss at iteration 1090 : 0.002114095725119114
Loss at iteration 1100 : 0.00023707699438091367
Loss at iteration 1110 : 0.0001509519206592813
Loss at iteration 1120 : 0.00046689267037436366
Loss at iteration 1130 : 0.0006806047749705613
Loss at iteration 1140 : 0.000518946791999042
Loss at iteration 1150 : 0.0010208470048382878
Loss at iteration 1160 : 0.00015904985775705427
Loss at iteration 1170 : 5.3319192375056446e-05
Loss at iteration 1180 : 0.005668008234351873
Loss at iteration 1190 : 0.0006137940799817443
Loss at iteration 1200 : 0.00019234538194723427
Loss at iteration 1210 : 0.00025818427093327045
Loss at iteration 1220 : 0.004009881988167763
Loss at iteration 1230 : 0.0003407449403312057
Loss at iteration 1240 : 0.0001389094686601311
Loss at iteration 1250 : 0.003001186531037092
Loss at iteration 1260 : 0.0007855064468458295
Loss at iteration 1270 : 0.0001996682840399444
Loss at iteration 1280 : 0.00018410813936498016
Loss at iteration 1290 : 9.584146755514666e-05
Loss at iteration 1300 : 0.0001276458497159183
Loss at iteration 1310 : 9.097559086512774e-05
Loss at iteration 1320 : 0.0003968443488702178
Loss at iteration 1330 : 0.0018674707971513271
Loss at iteration 1340 : 0.00015918881399556994
Loss at iteration 1350 : 0.00010386048961663619
Loss at iteration 1360 : 0.000281939166598022
Loss at iteration 1370 : 0.0003096924920100719
Loss at iteration 1380 : 0.00016985306865535676
Loss at iteration 1390 : 0.004127033520489931
Loss at iteration 1400 : 6.985047366470098e-05
Loss at iteration 1410 : 5.078480899101123e-05
Loss at iteration 1420 : 0.004371953196823597
Loss at iteration 1430 : 0.00033083499874919653
Loss at iteration 1440 : 0.00030864551081322134
Loss at iteration 1450 : 0.003650522092357278
Loss at iteration 1460 : 0.0004673103103414178
Loss at iteration 1470 : 0.004258980043232441
Loss at iteration 1480 : 0.001779840444214642
Loss at iteration 1490 : 7.696988905081525e-05
Loss at iteration 1500 : 0.00029861213988624513
Loss at iteration 1510 : 0.003259685356169939
Loss at iteration 1520 : 0.00010960886720567942
Loss at iteration 1530 : 0.002806218806654215
Loss at iteration 1540 : 0.0001056482142303139
Loss at iteration 1550 : 0.0018051426159217954
Loss at iteration 1560 : 0.0001371989055769518
Loss at iteration 1570 : 0.0006027180352248251
Loss at iteration 1580 : 0.0007642043055966496
Loss at iteration 1590 : 0.0001632876810617745
Loss at iteration 1600 : 0.0009029550710693002
Loss at iteration 1610 : 2.5023680791491643e-05
Loss at iteration 1620 : 0.0005855158087797463
Loss at iteration 1630 : 0.002967938082292676
Loss at iteration 1640 : 0.0004795681743416935
Loss at iteration 1650 : 0.00010797422146424651
Loss at iteration 1660 : 0.00047522762906737626
Loss at iteration 1670 : 0.00020179335842840374
Loss at iteration 1680 : 0.00018235374591313303
Loss at iteration 1690 : 7.436289160978049e-05
Loss at iteration 1700 : 0.0007516128243878484
Loss at iteration 1710 : 0.0004041154752485454
Loss at iteration 1720 : 0.00025493770954199135
Loss at iteration 1730 : 0.0005537197575904429
Loss at iteration 1740 : 0.00026186477043665946
Loss at iteration 1750 : 0.0023148248437792063
The SSIM Value is: 0.989368071902691
The PSNR Value is: 46.50359252896078
the epoch is: 42
Loss at iteration 10 : 0.00026107998564839363
Loss at iteration 20 : 0.0005758993211202323
Loss at iteration 30 : 0.0024699727073311806
Loss at iteration 40 : 0.0006570468540303409
Loss at iteration 50 : 0.006011013872921467
Loss at iteration 60 : 0.0028325195889919996
Loss at iteration 70 : 0.003103643422946334
Loss at iteration 80 : 0.0010076758917421103
Loss at iteration 90 : 0.00018417183309793472
Loss at iteration 100 : 0.0001946649863384664
Loss at iteration 110 : 0.0002788713900372386
Loss at iteration 120 : 0.0008453201735392213
Loss at iteration 130 : 0.0034238616935908794
Loss at iteration 140 : 0.0005586901679635048
Loss at iteration 150 : 0.00022635445930063725
Loss at iteration 160 : 0.0005622353637591004
Loss at iteration 170 : 0.0005518054240383208
Loss at iteration 180 : 0.00015386045561172068
Loss at iteration 190 : 0.0003700433881022036
Loss at iteration 200 : 4.646947854780592e-05
Loss at iteration 210 : 0.00014205582556314766
Loss at iteration 220 : 0.00027538335416466
Loss at iteration 230 : 0.00015244596579577774
Loss at iteration 240 : 0.0004585064889397472
Loss at iteration 250 : 0.000237527463468723
Loss at iteration 260 : 8.456096111331135e-05
Loss at iteration 270 : 0.0019162537064403296
Loss at iteration 280 : 0.00017031910829246044
Loss at iteration 290 : 0.0006334434729069471
Loss at iteration 300 : 0.0006804618751630187
Loss at iteration 310 : 0.00017474323976784945
Loss at iteration 320 : 0.0005336955073289573
Loss at iteration 330 : 0.0007319587748497725
Loss at iteration 340 : 0.0004471187712624669
Loss at iteration 350 : 9.320337267126888e-05
Loss at iteration 360 : 0.0015750254970043898
Loss at iteration 370 : 0.0002611991949379444
Loss at iteration 380 : 0.0031408590730279684
Loss at iteration 390 : 0.000281446409644559
Loss at iteration 400 : 0.0001735356345307082
Loss at iteration 410 : 0.00011333040311001241
Loss at iteration 420 : 0.005373159423470497
Loss at iteration 430 : 0.0004898235201835632
Loss at iteration 440 : 0.0002586900955066085
Loss at iteration 450 : 0.0017626885091885924
Loss at iteration 460 : 0.0006754959467798471
Loss at iteration 470 : 0.0015298147918656468
Loss at iteration 480 : 0.000836071209050715
Loss at iteration 490 : 0.001356832915917039
Loss at iteration 500 : 0.0023296205326914787
Loss at iteration 510 : 0.00012871812214143574
Loss at iteration 520 : 0.00011618466669460759
Loss at iteration 530 : 6.296551873674616e-05
Loss at iteration 540 : 0.0001441262720618397
Loss at iteration 550 : 0.0012082839384675026
Loss at iteration 560 : 0.00020588691404554993
Loss at iteration 570 : 0.00038922857493162155
Loss at iteration 580 : 0.00028530225972644985
Loss at iteration 590 : 0.0008367616683244705
Loss at iteration 600 : 0.00038296106504276395
Loss at iteration 610 : 7.38845847081393e-05
Loss at iteration 620 : 0.0001420108019374311
Loss at iteration 630 : 0.0008216764545068145
Loss at iteration 640 : 0.0002863013942260295
Loss at iteration 650 : 0.0016380366869270802
Loss at iteration 660 : 0.0042019858956336975
Loss at iteration 670 : 0.0016877276357263327
Loss at iteration 680 : 0.00018401486158836633
Loss at iteration 690 : 0.0005867549334652722
Loss at iteration 700 : 0.008985256776213646
Loss at iteration 710 : 0.00014661066234111786
Loss at iteration 720 : 0.002102629514411092
Loss at iteration 730 : 0.003402839880436659
Loss at iteration 740 : 0.0002096251555485651
Loss at iteration 750 : 0.0008910536416806281
Loss at iteration 760 : 0.0002827253774739802
Loss at iteration 770 : 0.0006350679323077202
Loss at iteration 780 : 0.00017389559070579708
Loss at iteration 790 : 0.001993731828406453
Loss at iteration 800 : 0.0003601016360335052
Loss at iteration 810 : 0.0008958292892202735
Loss at iteration 820 : 0.0018478406127542257
Loss at iteration 830 : 0.002129330998286605
Loss at iteration 840 : 0.00017131060303654522
Loss at iteration 850 : 0.00014406107948161662
Loss at iteration 860 : 0.00014311049017123878
Loss at iteration 870 : 0.0005282082129269838
Loss at iteration 880 : 0.0001077445485861972
Loss at iteration 890 : 0.008375683799386024
Loss at iteration 900 : 0.002318901941180229
Loss at iteration 910 : 0.0010560698574408889
Loss at iteration 920 : 0.0004066811525262892
Loss at iteration 930 : 0.00011264278873568401
Loss at iteration 940 : 0.0005301753990352154
Loss at iteration 950 : 0.0007144995033740997
Loss at iteration 960 : 0.0001200147089548409
Loss at iteration 970 : 0.0003043493488803506
Loss at iteration 980 : 0.00017096936062444001
Loss at iteration 990 : 0.00396621273830533
Loss at iteration 1000 : 0.004110740032047033
Loss at iteration 1010 : 0.0002120780700352043
Loss at iteration 1020 : 7.760690641589463e-05
Loss at iteration 1030 : 0.0016087759286165237
Loss at iteration 1040 : 0.00321556581184268
Loss at iteration 1050 : 8.12574871815741e-05
Loss at iteration 1060 : 0.002698746742680669
Loss at iteration 1070 : 0.0006074212142266333
Loss at iteration 1080 : 0.00020046872668899596
Loss at iteration 1090 : 0.0007389523671008646
Loss at iteration 1100 : 0.00018308857397641987
Loss at iteration 1110 : 8.623658504802734e-05
Loss at iteration 1120 : 0.0019630640745162964
Loss at iteration 1130 : 0.0001919710193760693
Loss at iteration 1140 : 0.0007101398659870028
Loss at iteration 1150 : 0.005777236074209213
Loss at iteration 1160 : 0.0003507536603137851
Loss at iteration 1170 : 0.0037054396234452724
Loss at iteration 1180 : 0.0016279295086860657
Loss at iteration 1190 : 0.0057395282201468945
Loss at iteration 1200 : 0.0026771610137075186
Loss at iteration 1210 : 0.0015101468889042735
Loss at iteration 1220 : 0.00012835193774662912
Loss at iteration 1230 : 0.0008345663663931191
Loss at iteration 1240 : 0.00027773925103247166
Loss at iteration 1250 : 0.0002086741733364761
Loss at iteration 1260 : 0.0014377535553649068
Loss at iteration 1270 : 0.0004157362272962928
Loss at iteration 1280 : 0.0003570199478417635
Loss at iteration 1290 : 0.00047013050061650574
Loss at iteration 1300 : 0.00016355758998543024
Loss at iteration 1310 : 0.0008921025437302887
Loss at iteration 1320 : 0.0010478646727278829
Loss at iteration 1330 : 0.0002401329402346164
Loss at iteration 1340 : 0.0013181967660784721
Loss at iteration 1350 : 0.002567132469266653
Loss at iteration 1360 : 0.0002795820473693311
Loss at iteration 1370 : 0.00019615169730968773
Loss at iteration 1380 : 0.0010541141964495182
Loss at iteration 1390 : 0.0019939823541790247
Loss at iteration 1400 : 0.0013477918691933155
Loss at iteration 1410 : 0.00011719323083525524
Loss at iteration 1420 : 0.0010944465175271034
Loss at iteration 1430 : 0.0017945292638614774
Loss at iteration 1440 : 0.0002580659056548029
Loss at iteration 1450 : 0.0003857221454381943
Loss at iteration 1460 : 0.0051459032110869884
Loss at iteration 1470 : 0.0007111959275789559
Loss at iteration 1480 : 0.00024870980996638536
Loss at iteration 1490 : 0.0003676232881844044
Loss at iteration 1500 : 0.000162745505804196
Loss at iteration 1510 : 0.0003439076244831085
Loss at iteration 1520 : 0.00012778813834302127
Loss at iteration 1530 : 0.0019155843183398247
Loss at iteration 1540 : 4.620454637915827e-05
Loss at iteration 1550 : 0.0007981661474332213
Loss at iteration 1560 : 0.000788967008702457
Loss at iteration 1570 : 0.0003004085156135261
Loss at iteration 1580 : 0.0008292145794257522
Loss at iteration 1590 : 0.00026741434703581035
Loss at iteration 1600 : 0.0005198405706323683
Loss at iteration 1610 : 0.0003953821724280715
Loss at iteration 1620 : 7.181731052696705e-05
Loss at iteration 1630 : 0.00020993991347495466
Loss at iteration 1640 : 0.005143595393747091
Loss at iteration 1650 : 0.0038727368228137493
Loss at iteration 1660 : 0.0034812481608241796
Loss at iteration 1670 : 0.0011081141419708729
Loss at iteration 1680 : 0.00459725596010685
Loss at iteration 1690 : 4.439261829247698e-05
Loss at iteration 1700 : 0.0029190557543188334
Loss at iteration 1710 : 0.00022693988285027444
Loss at iteration 1720 : 0.0010382910259068012
Loss at iteration 1730 : 0.0006056370912119746
Loss at iteration 1740 : 0.0004973849281668663
Loss at iteration 1750 : 0.003528597531840205
The SSIM Value is: 0.987185015814945
The PSNR Value is: 46.46000864642307
the epoch is: 43
Loss at iteration 10 : 0.0028734933584928513
Loss at iteration 20 : 0.0001532790483906865
Loss at iteration 30 : 0.00038328004302456975
Loss at iteration 40 : 0.000566140457522124
Loss at iteration 50 : 7.693626685068011e-05
Loss at iteration 60 : 0.0008412880706600845
Loss at iteration 70 : 0.0001024588564177975
Loss at iteration 80 : 0.0037580293137580156
Loss at iteration 90 : 0.0005609688814729452
Loss at iteration 100 : 0.0026780928019434214
Loss at iteration 110 : 0.00011413601168897003
Loss at iteration 120 : 0.001074357656762004
Loss at iteration 130 : 0.00010410483810119331
Loss at iteration 140 : 0.0015513831749558449
Loss at iteration 150 : 0.00043596484465524554
Loss at iteration 160 : 9.682858944870532e-05
Loss at iteration 170 : 0.001688555465079844
Loss at iteration 180 : 0.0001040390707203187
Loss at iteration 190 : 0.003992666490375996
Loss at iteration 200 : 0.00024633208522573113
Loss at iteration 210 : 0.00019736358080990613
Loss at iteration 220 : 0.00021163528435863554
Loss at iteration 230 : 0.0035455513279885054
Loss at iteration 240 : 0.00032850404386408627
Loss at iteration 250 : 6.87953142914921e-05
Loss at iteration 260 : 9.867262269835919e-05
Loss at iteration 270 : 0.004277669358998537
Loss at iteration 280 : 0.0011897211661562324
Loss at iteration 290 : 5.749408228439279e-05
Loss at iteration 300 : 0.0004198252281639725
Loss at iteration 310 : 0.0002767059486359358
Loss at iteration 320 : 0.0001777228753780946
Loss at iteration 330 : 0.00017623395251575857
Loss at iteration 340 : 0.0002074515214189887
Loss at iteration 350 : 0.00011613523383857682
Loss at iteration 360 : 0.0004886136739514768
Loss at iteration 370 : 0.0001705480826785788
Loss at iteration 380 : 0.00013575752382166684
Loss at iteration 390 : 0.0004277311381883919
Loss at iteration 400 : 0.00018426519818603992
Loss at iteration 410 : 0.0002223595802206546
Loss at iteration 420 : 0.0003700209781527519
Loss at iteration 430 : 0.0027666196692734957
Loss at iteration 440 : 9.94117435766384e-05
Loss at iteration 450 : 0.0005917573580518365
Loss at iteration 460 : 9.235647303285077e-05
Loss at iteration 470 : 0.004345017950981855
Loss at iteration 480 : 0.00020770537958014756
Loss at iteration 490 : 0.00018916488625109196
Loss at iteration 500 : 0.000611170893535018
Loss at iteration 510 : 0.00013037430471740663
Loss at iteration 520 : 0.005650044418871403
Loss at iteration 530 : 0.0016760742291808128
Loss at iteration 540 : 0.00020092928025405854
Loss at iteration 550 : 0.00025424070190638304
Loss at iteration 560 : 0.00023179779236670583
Loss at iteration 570 : 0.0013772237580269575
Loss at iteration 580 : 0.0032315016724169254
Loss at iteration 590 : 0.00010204277350567281
Loss at iteration 600 : 0.0010315455729141831
Loss at iteration 610 : 0.00028923602076247334
Loss at iteration 620 : 0.004933815449476242
Loss at iteration 630 : 0.00011412097956053913
Loss at iteration 640 : 0.004185412544757128
Loss at iteration 650 : 0.0014357080217450857
Loss at iteration 660 : 0.0012933588586747646
Loss at iteration 670 : 0.00039274044684134424
Loss at iteration 680 : 0.00010584805568214506
Loss at iteration 690 : 0.00024935006513260305
Loss at iteration 700 : 0.00032203225418925285
Loss at iteration 710 : 0.00013271656644064933
Loss at iteration 720 : 0.0001575844653416425
Loss at iteration 730 : 0.0008953122305683792
Loss at iteration 740 : 0.0002470489125698805
Loss at iteration 750 : 0.00012269268336240202
Loss at iteration 760 : 0.0013688169419765472
Loss at iteration 770 : 0.00010161609679926187
Loss at iteration 780 : 0.00032581915729679167
Loss at iteration 790 : 0.002247959142550826
Loss at iteration 800 : 0.0005613505491055548
Loss at iteration 810 : 0.0037554074078798294
Loss at iteration 820 : 0.0018108895746991038
Loss at iteration 830 : 0.00011788700794568285
Loss at iteration 840 : 5.788848648080602e-05
Loss at iteration 850 : 0.00034540065098553896
Loss at iteration 860 : 0.00014920058310963213
Loss at iteration 870 : 0.0009587950771674514
Loss at iteration 880 : 0.0023115728981792927
Loss at iteration 890 : 0.0014151972718536854
Loss at iteration 900 : 0.0015739003429189324
Loss at iteration 910 : 0.00026839596102945507
Loss at iteration 920 : 0.006250645499676466
Loss at iteration 930 : 0.00010520189243834466
Loss at iteration 940 : 0.0026575352530926466
Loss at iteration 950 : 0.0009854453383013606
Loss at iteration 960 : 0.0006129586836323142
Loss at iteration 970 : 0.0024262857623398304
Loss at iteration 980 : 0.0018040495924651623
Loss at iteration 990 : 0.0006049171206541359
Loss at iteration 1000 : 0.00018727006681729108
Loss at iteration 1010 : 0.004248466342687607
Loss at iteration 1020 : 0.0009201612556353211
Loss at iteration 1030 : 0.0013352045789361
Loss at iteration 1040 : 0.0003047334321308881
Loss at iteration 1050 : 5.442378096631728e-05
Loss at iteration 1060 : 0.0009548915550112724
Loss at iteration 1070 : 8.433466427959502e-05
Loss at iteration 1080 : 0.001174422912299633
Loss at iteration 1090 : 0.001189958187751472
Loss at iteration 1100 : 0.002795533277094364
Loss at iteration 1110 : 0.00019350335060153157
Loss at iteration 1120 : 0.00569604616612196
Loss at iteration 1130 : 0.00012711169256363064
Loss at iteration 1140 : 0.00045871949987486005
Loss at iteration 1150 : 0.0015528795775026083
Loss at iteration 1160 : 0.0020948813762515783
Loss at iteration 1170 : 0.00028939772164449096
Loss at iteration 1180 : 0.0022610854357481003
Loss at iteration 1190 : 0.0002024230343522504
Loss at iteration 1200 : 0.00036320294020697474
Loss at iteration 1210 : 0.002092817798256874
Loss at iteration 1220 : 0.0008495852234773338
Loss at iteration 1230 : 0.0010916210012510419
Loss at iteration 1240 : 0.0008678932208567858
Loss at iteration 1250 : 0.0013699072878807783
Loss at iteration 1260 : 0.00020627013873308897
Loss at iteration 1270 : 0.00017317845777142793
Loss at iteration 1280 : 0.0017337793251499534
Loss at iteration 1290 : 7.296785770449787e-05
Loss at iteration 1300 : 0.0034940780606120825
Loss at iteration 1310 : 0.0004532055463641882
Loss at iteration 1320 : 0.0003845311875920743
Loss at iteration 1330 : 8.874799095792696e-05
Loss at iteration 1340 : 0.0030236374586820602
Loss at iteration 1350 : 5.5469343351433054e-05
Loss at iteration 1360 : 0.0030133354011923075
Loss at iteration 1370 : 0.00530299311503768
Loss at iteration 1380 : 0.00017803421360440552
Loss at iteration 1390 : 0.007668984122574329
Loss at iteration 1400 : 0.0016180436359718442
Loss at iteration 1410 : 0.0015100716846063733
Loss at iteration 1420 : 0.0018020053394138813
Loss at iteration 1430 : 0.0018329564481973648
Loss at iteration 1440 : 0.003327739890664816
Loss at iteration 1450 : 0.0014476729556918144
Loss at iteration 1460 : 0.0007295486284419894
Loss at iteration 1470 : 0.0009586011292412877
Loss at iteration 1480 : 0.0024765869602560997
Loss at iteration 1490 : 0.00010975426994264126
Loss at iteration 1500 : 0.00010691218631109223
Loss at iteration 1510 : 0.00029018695931881666
Loss at iteration 1520 : 0.00473489984869957
Loss at iteration 1530 : 0.00031444235355593264
Loss at iteration 1540 : 0.0010307802585884929
Loss at iteration 1550 : 0.0015873473603278399
Loss at iteration 1560 : 0.0003701833193190396
Loss at iteration 1570 : 0.002877989783883095
Loss at iteration 1580 : 0.00033887417521327734
Loss at iteration 1590 : 0.0027040138375014067
Loss at iteration 1600 : 0.00519986916333437
Loss at iteration 1610 : 0.0001338452857453376
Loss at iteration 1620 : 0.00046048613148741424
Loss at iteration 1630 : 0.000477156339911744
Loss at iteration 1640 : 7.58648311602883e-05
Loss at iteration 1650 : 0.0005107109900563955
Loss at iteration 1660 : 0.001973363570868969
Loss at iteration 1670 : 0.0004549383884295821
Loss at iteration 1680 : 0.0017483981791883707
Loss at iteration 1690 : 0.001216019270941615
Loss at iteration 1700 : 0.00016091324505396187
Loss at iteration 1710 : 0.003677543718367815
Loss at iteration 1720 : 0.00036394374910742044
Loss at iteration 1730 : 0.0003369854821357876
Loss at iteration 1740 : 0.00014614297833759338
Loss at iteration 1750 : 0.00016625977877993137
The SSIM Value is: 0.9849631409550553
The PSNR Value is: 46.232107490169845
the epoch is: 44
Loss at iteration 10 : 0.004207978956401348
Loss at iteration 20 : 0.001009627478197217
Loss at iteration 30 : 0.00022457503655459732
Loss at iteration 40 : 0.0001747468049870804
Loss at iteration 50 : 9.859082638286054e-05
Loss at iteration 60 : 0.00020247952488716692
Loss at iteration 70 : 0.00041159678949043155
Loss at iteration 80 : 0.0006920171435922384
Loss at iteration 90 : 0.00023047070135362446
Loss at iteration 100 : 0.00043423130409792066
Loss at iteration 110 : 0.0006593316793441772
Loss at iteration 120 : 6.722933903802186e-05
Loss at iteration 130 : 0.0018965036142617464
Loss at iteration 140 : 0.0010043150978162885
Loss at iteration 150 : 0.0010859373724088073
Loss at iteration 160 : 0.00016016059089452028
Loss at iteration 170 : 0.00035397347528487444
Loss at iteration 180 : 0.00019680277910083532
Loss at iteration 190 : 0.0015195402083918452
Loss at iteration 200 : 0.00013172693434171379
Loss at iteration 210 : 0.00021327529975678772
Loss at iteration 220 : 0.0005921610863879323
Loss at iteration 230 : 0.0014219610020518303
Loss at iteration 240 : 0.0023198104463517666
Loss at iteration 250 : 0.0004000948974862695
Loss at iteration 260 : 0.0007811394752934575
Loss at iteration 270 : 0.0014109584735706449
Loss at iteration 280 : 0.00032450095750391483
Loss at iteration 290 : 0.00020917912479490042
Loss at iteration 300 : 0.0019575057085603476
Loss at iteration 310 : 0.0016241357661783695
Loss at iteration 320 : 0.00028942347853444517
Loss at iteration 330 : 0.0018330668099224567
Loss at iteration 340 : 0.0004767072678077966
Loss at iteration 350 : 0.00020493805641308427
Loss at iteration 360 : 0.00025750562781468034
Loss at iteration 370 : 0.00011107501632068306
Loss at iteration 380 : 0.0006271223537623882
Loss at iteration 390 : 5.290081389830448e-05
Loss at iteration 400 : 0.0016484914813190699
Loss at iteration 410 : 0.00018606339290272444
Loss at iteration 420 : 0.00016828154912218451
Loss at iteration 430 : 0.00017455374472774565
Loss at iteration 440 : 0.0007144103292375803
Loss at iteration 450 : 0.0028385601472109556
Loss at iteration 460 : 0.00237957201898098
Loss at iteration 470 : 5.1450035243760794e-05
Loss at iteration 480 : 0.001252772519364953
Loss at iteration 490 : 0.00017916133219841868
Loss at iteration 500 : 0.00037512878770940006
Loss at iteration 510 : 0.0012608170509338379
Loss at iteration 520 : 9.26664870348759e-05
Loss at iteration 530 : 0.000425145699409768
Loss at iteration 540 : 0.0014410987496376038
Loss at iteration 550 : 0.00023829327255953103
Loss at iteration 560 : 0.002861243672668934
Loss at iteration 570 : 0.0002042187552433461
Loss at iteration 580 : 0.0004052986914757639
Loss at iteration 590 : 8.108600013656542e-05
Loss at iteration 600 : 0.0007194291683845222
Loss at iteration 610 : 0.00017412868328392506
Loss at iteration 620 : 0.0004225491138640791
Loss at iteration 630 : 0.0001581427059136331
Loss at iteration 640 : 0.0029979946557432413
Loss at iteration 650 : 0.0005436651408672333
Loss at iteration 660 : 0.0008245215867646039
Loss at iteration 670 : 0.00017323534120805562
Loss at iteration 680 : 0.0019364969339221716
Loss at iteration 690 : 9.064651385415345e-05
Loss at iteration 700 : 0.00484465854242444
Loss at iteration 710 : 0.000537061714567244
Loss at iteration 720 : 0.0019325471948832273
Loss at iteration 730 : 0.0004837206215597689
Loss at iteration 740 : 0.0005022879340685904
Loss at iteration 750 : 0.00142054189927876
Loss at iteration 760 : 0.003384638112038374
Loss at iteration 770 : 0.0001225047162733972
Loss at iteration 780 : 0.00046075310092419386
Loss at iteration 790 : 9.628830594010651e-05
Loss at iteration 800 : 0.0009552096016705036
Loss at iteration 810 : 0.0002859178348444402
Loss at iteration 820 : 0.000531800847966224
Loss at iteration 830 : 0.00011307995009701699
Loss at iteration 840 : 0.004633959382772446
Loss at iteration 850 : 0.00020183806191198528
Loss at iteration 860 : 0.003124622395262122
Loss at iteration 870 : 0.002038760343566537
Loss at iteration 880 : 8.805700053926557e-05
Loss at iteration 890 : 0.0003988550743088126
Loss at iteration 900 : 0.00011682890908559784
Loss at iteration 910 : 0.0002329264534637332
Loss at iteration 920 : 0.0012206052197143435
Loss at iteration 930 : 0.00035466800909489393
Loss at iteration 940 : 0.0013757889391854405
Loss at iteration 950 : 8.377504127565771e-05
Loss at iteration 960 : 0.00010619172098813578
Loss at iteration 970 : 0.00301490374840796
Loss at iteration 980 : 0.0019319786224514246
Loss at iteration 990 : 8.586789772380143e-05
Loss at iteration 1000 : 0.000457499991171062
Loss at iteration 1010 : 0.0006693913601338863
Loss at iteration 1020 : 4.277805419405922e-05
Loss at iteration 1030 : 0.002060746308416128
Loss at iteration 1040 : 0.00012567188241519034
Loss at iteration 1050 : 0.0023335651494562626
Loss at iteration 1060 : 0.00026791743584908545
Loss at iteration 1070 : 0.0025363091845065355
Loss at iteration 1080 : 0.005061706993728876
Loss at iteration 1090 : 0.0011011267779394984
Loss at iteration 1100 : 0.00024363206466659904
Loss at iteration 1110 : 0.0001866905513452366
Loss at iteration 1120 : 0.002425230573862791
Loss at iteration 1130 : 0.000149557352415286
Loss at iteration 1140 : 0.0013960376381874084
Loss at iteration 1150 : 0.0003535742871463299
Loss at iteration 1160 : 0.0005627626087516546
Loss at iteration 1170 : 0.003076487220823765
Loss at iteration 1180 : 0.00015011295909062028
Loss at iteration 1190 : 0.0022389511577785015
Loss at iteration 1200 : 0.00022599531803280115
Loss at iteration 1210 : 0.0009333189227618277
Loss at iteration 1220 : 6.015597682562657e-05
Loss at iteration 1230 : 0.00018452022050041705
Loss at iteration 1240 : 0.0044382112100720406
Loss at iteration 1250 : 0.00243477919138968
Loss at iteration 1260 : 0.00017785266391001642
Loss at iteration 1270 : 0.0004322321037761867
Loss at iteration 1280 : 0.0007795181008987129
Loss at iteration 1290 : 0.0029630891513079405
Loss at iteration 1300 : 0.0003550447872839868
Loss at iteration 1310 : 7.757210551062599e-05
Loss at iteration 1320 : 0.0001559602387715131
Loss at iteration 1330 : 0.0011999859707430005
Loss at iteration 1340 : 0.004197617992758751
Loss at iteration 1350 : 0.0025027901865541935
Loss at iteration 1360 : 9.346220758743584e-05
Loss at iteration 1370 : 0.0002940520935226232
Loss at iteration 1380 : 0.00013376174320001155
Loss at iteration 1390 : 0.002683037891983986
Loss at iteration 1400 : 0.0002484886208549142
Loss at iteration 1410 : 0.00012924266047775745
Loss at iteration 1420 : 0.0002571372897364199
Loss at iteration 1430 : 0.0008303181384690106
Loss at iteration 1440 : 0.0001451720600016415
Loss at iteration 1450 : 0.0001439196348655969
Loss at iteration 1460 : 0.0015395566588267684
Loss at iteration 1470 : 0.00011654806439764798
Loss at iteration 1480 : 0.00043015083065256476
Loss at iteration 1490 : 5.123197479406372e-05
Loss at iteration 1500 : 0.004391441587358713
Loss at iteration 1510 : 0.00011456079664640129
Loss at iteration 1520 : 0.0007841687183827162
Loss at iteration 1530 : 0.0004830454126931727
Loss at iteration 1540 : 0.0005072157946415246
Loss at iteration 1550 : 0.0021933293901383877
Loss at iteration 1560 : 0.0008519890252500772
Loss at iteration 1570 : 0.00011811645526904613
Loss at iteration 1580 : 0.0003298856317996979
Loss at iteration 1590 : 0.00029175911913625896
Loss at iteration 1600 : 0.001722274231724441
Loss at iteration 1610 : 0.00018174041179008782
Loss at iteration 1620 : 0.00041715975385159254
Loss at iteration 1630 : 0.00046481762547045946
Loss at iteration 1640 : 0.0012103287735953927
Loss at iteration 1650 : 0.00046089012175798416
Loss at iteration 1660 : 9.485794726060703e-05
Loss at iteration 1670 : 8.13609512988478e-05
Loss at iteration 1680 : 0.00013174540072213858
Loss at iteration 1690 : 0.000637250836007297
Loss at iteration 1700 : 0.0002814565086737275
Loss at iteration 1710 : 0.0031069780234247446
Loss at iteration 1720 : 0.004460449330508709
Loss at iteration 1730 : 0.00021590168762486428
Loss at iteration 1740 : 5.2365521696629e-05
Loss at iteration 1750 : 0.0003301735268905759
The SSIM Value is: 0.98268623092101
The PSNR Value is: 46.46101655203866
the epoch is: 45
Loss at iteration 10 : 0.00011133723455714062
Loss at iteration 20 : 0.0004707153420895338
Loss at iteration 30 : 0.0008877756772562861
Loss at iteration 40 : 0.00010433437273604795
Loss at iteration 50 : 0.00033486823667772114
Loss at iteration 60 : 0.00014209887012839317
Loss at iteration 70 : 0.0004005181835964322
Loss at iteration 80 : 0.00021669678972102702
Loss at iteration 90 : 0.0037032044492661953
Loss at iteration 100 : 0.0001061753137037158
Loss at iteration 110 : 0.001997640822082758
Loss at iteration 120 : 0.00014310794358607382
Loss at iteration 130 : 0.0034984471276402473
Loss at iteration 140 : 0.00062638457166031
Loss at iteration 150 : 0.0008473638445138931
Loss at iteration 160 : 0.00017564301379024982
Loss at iteration 170 : 0.0009151302510872483
Loss at iteration 180 : 9.860350110102445e-05
Loss at iteration 190 : 0.00018287767306901515
Loss at iteration 200 : 0.00020532822236418724
Loss at iteration 210 : 8.19516135379672e-05
Loss at iteration 220 : 0.0004614906501956284
Loss at iteration 230 : 0.0002678510209079832
Loss at iteration 240 : 0.0017608333146199584
Loss at iteration 250 : 0.0013701932039111853
Loss at iteration 260 : 0.0001333418913418427
Loss at iteration 270 : 0.00013799057342112064
Loss at iteration 280 : 0.00037203749525360763
Loss at iteration 290 : 8.383308158954605e-05
Loss at iteration 300 : 0.001586039667017758
Loss at iteration 310 : 9.207322000293061e-05
Loss at iteration 320 : 0.0007285074098035693
Loss at iteration 330 : 0.00012700387742370367
Loss at iteration 340 : 0.00010606191062834114
Loss at iteration 350 : 0.0008996367687359452
Loss at iteration 360 : 0.0012692665914073586
Loss at iteration 370 : 4.376421929919161e-05
Loss at iteration 380 : 0.003346311626955867
Loss at iteration 390 : 0.00020253282855264843
Loss at iteration 400 : 0.0005686533404514194
Loss at iteration 410 : 7.420220936182886e-05
Loss at iteration 420 : 0.00038028100971132517
Loss at iteration 430 : 0.0001700185239315033
Loss at iteration 440 : 0.00015926080232020468
Loss at iteration 450 : 0.0003144106303807348
Loss at iteration 460 : 0.00022830086527392268
Loss at iteration 470 : 0.005463785957545042
Loss at iteration 480 : 0.0002732532157097012
Loss at iteration 490 : 0.0003481846651993692
Loss at iteration 500 : 0.00038037163903936744
Loss at iteration 510 : 0.00018227307009510696
Loss at iteration 520 : 0.00014147824549581856
Loss at iteration 530 : 0.0019709246698766947
Loss at iteration 540 : 0.01058630459010601
Loss at iteration 550 : 9.877683623926714e-05
Loss at iteration 560 : 0.00015513834659941494
Loss at iteration 570 : 0.004445889964699745
Loss at iteration 580 : 6.443419260904193e-05
Loss at iteration 590 : 4.875212471233681e-05
Loss at iteration 600 : 0.0030091763474047184
Loss at iteration 610 : 0.0002423628611722961
Loss at iteration 620 : 0.00011924098362214863
Loss at iteration 630 : 0.0006987039232626557
Loss at iteration 640 : 0.00027086742920801044
Loss at iteration 650 : 0.001404177164658904
Loss at iteration 660 : 0.0024855926167219877
Loss at iteration 670 : 0.0008163779275491834
Loss at iteration 680 : 7.475408347090706e-05
Loss at iteration 690 : 0.0037760711275041103
Loss at iteration 700 : 0.0018742140382528305
Loss at iteration 710 : 0.0005330771091394126
Loss at iteration 720 : 0.0001720464206300676
Loss at iteration 730 : 0.00047447546967305243
Loss at iteration 740 : 0.000502122042234987
Loss at iteration 750 : 0.0002587256603874266
Loss at iteration 760 : 0.00029886822449043393
Loss at iteration 770 : 0.0012811969500035048
Loss at iteration 780 : 0.0003682037640828639
Loss at iteration 790 : 0.00016451514966320246
Loss at iteration 800 : 0.00258475705049932
Loss at iteration 810 : 0.00019230357429478317
Loss at iteration 820 : 0.00030463753500953317
Loss at iteration 830 : 0.0008373441523872316
Loss at iteration 840 : 0.00014856565394438803
Loss at iteration 850 : 0.004501610063016415
Loss at iteration 860 : 7.33477936591953e-05
Loss at iteration 870 : 0.0010945890098810196
Loss at iteration 880 : 0.00011999031266896054
Loss at iteration 890 : 5.874336784472689e-05
Loss at iteration 900 : 0.0001442893990315497
Loss at iteration 910 : 0.0018747083377093077
Loss at iteration 920 : 0.00013371522072702646
Loss at iteration 930 : 9.574051364324987e-05
Loss at iteration 940 : 0.00010774430120363832
Loss at iteration 950 : 0.0007432078127749264
Loss at iteration 960 : 0.0023380564525723457
Loss at iteration 970 : 0.0005776273901574314
Loss at iteration 980 : 8.303798676934093e-05
Loss at iteration 990 : 0.00015292185707949102
Loss at iteration 1000 : 0.0001310621009906754
Loss at iteration 1010 : 0.00021206249948590994
Loss at iteration 1020 : 0.001044899458065629
Loss at iteration 1030 : 0.0015514837577939034
Loss at iteration 1040 : 7.182839181041345e-05
Loss at iteration 1050 : 0.0018522513564676046
Loss at iteration 1060 : 0.0012720554368570447
Loss at iteration 1070 : 0.0005118775297887623
Loss at iteration 1080 : 0.00024599896278232336
Loss at iteration 1090 : 0.0009957426227629185
Loss at iteration 1100 : 0.00017306861991528422
Loss at iteration 1110 : 0.0001282293815165758
Loss at iteration 1120 : 0.0027397803496569395
Loss at iteration 1130 : 0.0027509438805282116
Loss at iteration 1140 : 0.0006965837674215436
Loss at iteration 1150 : 0.0002228274242952466
Loss at iteration 1160 : 0.0005129931960254908
Loss at iteration 1170 : 0.0028597423806786537
Loss at iteration 1180 : 0.002422457793727517
Loss at iteration 1190 : 0.0006537631852552295
Loss at iteration 1200 : 0.0008335351012647152
Loss at iteration 1210 : 0.0036810669116675854
Loss at iteration 1220 : 0.0010065294336527586
Loss at iteration 1230 : 0.00016144746041391045
Loss at iteration 1240 : 0.0037870672531425953
Loss at iteration 1250 : 0.002309085801243782
Loss at iteration 1260 : 0.0001225612504640594
Loss at iteration 1270 : 0.0009325534920208156
Loss at iteration 1280 : 0.0019434911664575338
Loss at iteration 1290 : 0.003736053593456745
Loss at iteration 1300 : 0.0009830037597566843
Loss at iteration 1310 : 0.0011690231040120125
Loss at iteration 1320 : 0.0008697466109879315
Loss at iteration 1330 : 0.0002876023936551064
Loss at iteration 1340 : 0.00041998003143817186
Loss at iteration 1350 : 0.002517062472179532
Loss at iteration 1360 : 0.0016267751343548298
Loss at iteration 1370 : 0.00040257343789562583
Loss at iteration 1380 : 0.003201570361852646
Loss at iteration 1390 : 0.00248385570012033
Loss at iteration 1400 : 0.0015020619612187147
Loss at iteration 1410 : 0.0002642145846039057
Loss at iteration 1420 : 0.0018894780660048127
Loss at iteration 1430 : 0.00013427800149656832
Loss at iteration 1440 : 0.004211987368762493
Loss at iteration 1450 : 0.0005625266931019723
Loss at iteration 1460 : 0.00234796479344368
Loss at iteration 1470 : 0.00010891286365222186
Loss at iteration 1480 : 0.000891059054993093
Loss at iteration 1490 : 0.00047006504610180855
Loss at iteration 1500 : 0.00020710112585220486
Loss at iteration 1510 : 0.0002826208365149796
Loss at iteration 1520 : 0.00026366638485342264
Loss at iteration 1530 : 0.0028633789625018835
Loss at iteration 1540 : 0.00017727894010022283
Loss at iteration 1550 : 0.001187032088637352
Loss at iteration 1560 : 8.2289261627011e-05
Loss at iteration 1570 : 0.00022459955653175712
Loss at iteration 1580 : 0.00043350859778001904
Loss at iteration 1590 : 0.0006530226673930883
Loss at iteration 1600 : 0.0001274782989639789
Loss at iteration 1610 : 0.002832830650731921
Loss at iteration 1620 : 9.253755706595257e-05
Loss at iteration 1630 : 0.0027344003319740295
Loss at iteration 1640 : 0.0003438697603996843
Loss at iteration 1650 : 0.000145743164466694
Loss at iteration 1660 : 0.0001359907619189471
Loss at iteration 1670 : 0.0005415210034698248
Loss at iteration 1680 : 0.0011455591302365065
Loss at iteration 1690 : 0.0012782462872564793
Loss at iteration 1700 : 0.00040359992999583483
Loss at iteration 1710 : 0.00042161234887316823
Loss at iteration 1720 : 0.00020054732158314437
Loss at iteration 1730 : 9.344565478386357e-05
Loss at iteration 1740 : 7.451175042660907e-05
Loss at iteration 1750 : 0.00012833860819227993
The SSIM Value is: 0.9688931374691656
The PSNR Value is: 46.3636796064839
the epoch is: 46
Loss at iteration 10 : 0.0004511954612098634
Loss at iteration 20 : 0.008447741158306599
Loss at iteration 30 : 0.0006222759839147329
Loss at iteration 40 : 0.00037058000452816486
Loss at iteration 50 : 0.0029678582213819027
Loss at iteration 60 : 0.004955081269145012
Loss at iteration 70 : 0.0007057103211991489
Loss at iteration 80 : 0.0003707021242007613
Loss at iteration 90 : 0.001440633786842227
Loss at iteration 100 : 0.0003551342524588108
Loss at iteration 110 : 0.0003518671728670597
Loss at iteration 120 : 0.0008862093091011047
Loss at iteration 130 : 0.0002943068975582719
Loss at iteration 140 : 0.003887402592226863
Loss at iteration 150 : 0.0001605797151569277
Loss at iteration 160 : 5.71829586988315e-05
Loss at iteration 170 : 0.00038997846422716975
Loss at iteration 180 : 9.023607708513737e-05
Loss at iteration 190 : 0.004487277008593082
Loss at iteration 200 : 0.0001983532856684178
Loss at iteration 210 : 0.0001373625418636948
Loss at iteration 220 : 0.00021747479331679642
Loss at iteration 230 : 0.00029871566221117973
Loss at iteration 240 : 0.0001849909167503938
Loss at iteration 250 : 0.004197719041258097
Loss at iteration 260 : 0.000298235536320135
Loss at iteration 270 : 0.00048287896788679063
Loss at iteration 280 : 0.0005398357170633972
Loss at iteration 290 : 0.006064492277801037
Loss at iteration 300 : 0.0009642373188398778
Loss at iteration 310 : 0.000201107221073471
Loss at iteration 320 : 0.00010351107630413026
Loss at iteration 330 : 0.00018614463624544442
Loss at iteration 340 : 0.0007451666169799864
Loss at iteration 350 : 0.0005378212663345039
Loss at iteration 360 : 0.00015069270739331841
Loss at iteration 370 : 0.002356133423745632
Loss at iteration 380 : 0.00023919742670841515
Loss at iteration 390 : 0.0029307412914931774
Loss at iteration 400 : 0.0005902130506001413
Loss at iteration 410 : 7.719815039308742e-05
Loss at iteration 420 : 0.000410425360314548
Loss at iteration 430 : 0.0030971781816333532
Loss at iteration 440 : 0.00012040816363878548
Loss at iteration 450 : 0.0010752752423286438
Loss at iteration 460 : 6.495035631814972e-05
Loss at iteration 470 : 0.0008526487508788705
Loss at iteration 480 : 0.002986855572089553
Loss at iteration 490 : 0.0001640941045479849
Loss at iteration 500 : 0.00015356315998360515
Loss at iteration 510 : 0.00011209170770598575
Loss at iteration 520 : 0.0030035004019737244
Loss at iteration 530 : 5.4385887779062614e-05
Loss at iteration 540 : 0.001885602017864585
Loss at iteration 550 : 0.0017641887534409761
Loss at iteration 560 : 0.00013916523312218487
Loss at iteration 570 : 0.0021399022080004215
Loss at iteration 580 : 7.288699271157384e-05
Loss at iteration 590 : 0.0007732759695500135
Loss at iteration 600 : 0.0027703281957656145
Loss at iteration 610 : 0.003174414625391364
Loss at iteration 620 : 0.0010197561932727695
Loss at iteration 630 : 0.00016777422570157796
Loss at iteration 640 : 0.0002504047588445246
Loss at iteration 650 : 0.00016750583017710596
Loss at iteration 660 : 0.00015511094534303993
Loss at iteration 670 : 0.0002926905290223658
Loss at iteration 680 : 7.946310506667942e-05
Loss at iteration 690 : 0.0004674855445045978
Loss at iteration 700 : 0.0001648175821173936
Loss at iteration 710 : 0.0002961152058560401
Loss at iteration 720 : 0.00047123528202064335
Loss at iteration 730 : 0.004559831693768501
Loss at iteration 740 : 0.00012037971464451402
Loss at iteration 750 : 0.0006697913631796837
Loss at iteration 760 : 0.00016183657862711698
Loss at iteration 770 : 0.0008694134885445237
Loss at iteration 780 : 0.00042169020161964
Loss at iteration 790 : 0.0010461146011948586
Loss at iteration 800 : 0.0027458365075290203
Loss at iteration 810 : 0.0003800556296482682
Loss at iteration 820 : 0.0005340276402421296
Loss at iteration 830 : 0.003826538100838661
Loss at iteration 840 : 0.00012461343430913985
Loss at iteration 850 : 0.00017232223763130605
Loss at iteration 860 : 6.857352855149657e-05
Loss at iteration 870 : 7.094496686477214e-05
Loss at iteration 880 : 9.100006718654186e-05
Loss at iteration 890 : 0.0001896959001896903
Loss at iteration 900 : 0.002015224192291498
Loss at iteration 910 : 0.0003153656143695116
Loss at iteration 920 : 0.0014549198094755411
Loss at iteration 930 : 8.33553058328107e-05
Loss at iteration 940 : 0.00026208985946141183
Loss at iteration 950 : 0.0014465973945334554
Loss at iteration 960 : 0.0003005574399139732
Loss at iteration 970 : 0.001311704283580184
Loss at iteration 980 : 0.0007683843723498285
Loss at iteration 990 : 0.0003640068753156811
Loss at iteration 1000 : 3.650494909379631e-05
Loss at iteration 1010 : 0.0001073283128789626
Loss at iteration 1020 : 0.002120817778632045
Loss at iteration 1030 : 0.008383478969335556
Loss at iteration 1040 : 0.00021117088908795267
Loss at iteration 1050 : 0.0031975600868463516
Loss at iteration 1060 : 0.0006296954234130681
Loss at iteration 1070 : 0.004573567304760218
Loss at iteration 1080 : 0.0002186065976275131
Loss at iteration 1090 : 0.0003933546249754727
Loss at iteration 1100 : 0.0003741091350093484
Loss at iteration 1110 : 0.0007484781672246754
Loss at iteration 1120 : 6.381353159667924e-05
Loss at iteration 1130 : 0.0030535554978996515
Loss at iteration 1140 : 0.0001143207264249213
Loss at iteration 1150 : 0.00042419572127982974
Loss at iteration 1160 : 0.0034463286865502596
Loss at iteration 1170 : 0.0006164879305288196
Loss at iteration 1180 : 0.0013721105642616749
Loss at iteration 1190 : 8.909608004614711e-05
Loss at iteration 1200 : 0.00041773502016440034
Loss at iteration 1210 : 0.0017105016158893704
Loss at iteration 1220 : 0.0007816978031769395
Loss at iteration 1230 : 0.00028968462720513344
Loss at iteration 1240 : 0.00025697765522636473
Loss at iteration 1250 : 0.00025964222732000053
Loss at iteration 1260 : 0.0011194096878170967
Loss at iteration 1270 : 0.0003111028636340052
Loss at iteration 1280 : 7.263420411618426e-05
Loss at iteration 1290 : 0.0001626430603209883
Loss at iteration 1300 : 0.002190957311540842
Loss at iteration 1310 : 0.00014640337030868977
Loss at iteration 1320 : 0.0002246854710392654
Loss at iteration 1330 : 0.002398234326392412
Loss at iteration 1340 : 0.0002481498522683978
Loss at iteration 1350 : 0.0005994830280542374
Loss at iteration 1360 : 0.0006663994863629341
Loss at iteration 1370 : 0.00011812107550213113
Loss at iteration 1380 : 0.0031166577246040106
Loss at iteration 1390 : 0.0001494144817115739
Loss at iteration 1400 : 0.0001112674071919173
Loss at iteration 1410 : 0.0002336892648600042
Loss at iteration 1420 : 0.003746911184862256
Loss at iteration 1430 : 0.0002885345311369747
Loss at iteration 1440 : 0.001546475337818265
Loss at iteration 1450 : 0.00016912532737478614
Loss at iteration 1460 : 0.002353701274842024
Loss at iteration 1470 : 0.0027432481292635202
Loss at iteration 1480 : 0.0015981674659997225
Loss at iteration 1490 : 0.0014220776502043009
Loss at iteration 1500 : 0.004623888060450554
Loss at iteration 1510 : 4.6188259148038924e-05
Loss at iteration 1520 : 0.00012457951379474252
Loss at iteration 1530 : 0.002274161670356989
Loss at iteration 1540 : 0.00019030284602195024
Loss at iteration 1550 : 0.005197313614189625
Loss at iteration 1560 : 0.0012792323250323534
Loss at iteration 1570 : 0.003385794349014759
Loss at iteration 1580 : 0.0003029729996342212
Loss at iteration 1590 : 0.0004120460362173617
Loss at iteration 1600 : 0.0005041209515184164
Loss at iteration 1610 : 0.00016272836364805698
Loss at iteration 1620 : 0.0003296483482699841
Loss at iteration 1630 : 0.0017561737913638353
Loss at iteration 1640 : 0.00011344117228873074
Loss at iteration 1650 : 0.0001715347170829773
Loss at iteration 1660 : 0.003449857234954834
Loss at iteration 1670 : 0.00027204371872358024
Loss at iteration 1680 : 9.336182120023295e-05
Loss at iteration 1690 : 0.000820030109025538
Loss at iteration 1700 : 8.017980144359171e-05
Loss at iteration 1710 : 0.0004918326740153134
Loss at iteration 1720 : 0.0013331014197319746
Loss at iteration 1730 : 0.00021561664470937103
Loss at iteration 1740 : 0.002049990464001894
Loss at iteration 1750 : 0.0005664945347234607
The SSIM Value is: 0.9889961902528083
The PSNR Value is: 46.392568613464086
the epoch is: 47
Loss at iteration 10 : 0.0005457187071442604
Loss at iteration 20 : 0.0008976940298452973
Loss at iteration 30 : 0.0003657130873762071
Loss at iteration 40 : 0.00041530950693413615
Loss at iteration 50 : 0.000418050738517195
Loss at iteration 60 : 0.00020114623475819826
Loss at iteration 70 : 0.002813529223203659
Loss at iteration 80 : 0.0005049454048275948
Loss at iteration 90 : 0.0035319486632943153
Loss at iteration 100 : 0.0005905683501623571
Loss at iteration 110 : 0.00028191422461532056
Loss at iteration 120 : 0.0017563115106895566
Loss at iteration 130 : 0.0038099470548331738
Loss at iteration 140 : 0.0005952363135293126
Loss at iteration 150 : 0.00036626699147745967
Loss at iteration 160 : 0.00014267243386711925
Loss at iteration 170 : 0.005281687714159489
Loss at iteration 180 : 0.005566815845668316
Loss at iteration 190 : 0.00010457456664880738
Loss at iteration 200 : 0.000658435164950788
Loss at iteration 210 : 0.00011293918214505538
Loss at iteration 220 : 0.0009567096712999046
Loss at iteration 230 : 0.013993759639561176
Loss at iteration 240 : 0.0001788575464161113
Loss at iteration 250 : 0.0002473153290338814
Loss at iteration 260 : 0.0006962676998227835
Loss at iteration 270 : 0.0002853374753613025
Loss at iteration 280 : 0.0035566925071179867
Loss at iteration 290 : 0.00013571823365055025
Loss at iteration 300 : 0.0012650979915633798
Loss at iteration 310 : 0.0002125362807419151
Loss at iteration 320 : 0.003255961462855339
Loss at iteration 330 : 0.0003306979197077453
Loss at iteration 340 : 0.00018755850032903254
Loss at iteration 350 : 0.00039534916868433356
Loss at iteration 360 : 0.0004997326759621501
Loss at iteration 370 : 0.00019312599033582956
Loss at iteration 380 : 0.0014322579372674227
Loss at iteration 390 : 9.447074990021065e-05
Loss at iteration 400 : 0.00169865891803056
Loss at iteration 410 : 0.00012090872769476846
Loss at iteration 420 : 0.0007881748024374247
Loss at iteration 430 : 0.0004919826751574874
Loss at iteration 440 : 0.00364864245057106
Loss at iteration 450 : 0.00019282240828033537
Loss at iteration 460 : 0.00012097521539544687
Loss at iteration 470 : 0.00020069850143045187
Loss at iteration 480 : 0.007648398168385029
Loss at iteration 490 : 0.00024826155276969075
Loss at iteration 500 : 0.0005818727659061551
Loss at iteration 510 : 0.0025787148624658585
Loss at iteration 520 : 0.0007768116774968803
Loss at iteration 530 : 0.0034500937908887863
Loss at iteration 540 : 0.000340316619258374
Loss at iteration 550 : 0.0019425745122134686
Loss at iteration 560 : 0.0002717659226618707
Loss at iteration 570 : 0.00012383998546283692
Loss at iteration 580 : 8.843527757562697e-05
Loss at iteration 590 : 0.0005355148459784687
Loss at iteration 600 : 0.0001485461398260668
Loss at iteration 610 : 0.0003288268926553428
Loss at iteration 620 : 9.924182813847438e-05
Loss at iteration 630 : 0.00030397818773053586
Loss at iteration 640 : 0.003252995666116476
Loss at iteration 650 : 0.0003628643462434411
Loss at iteration 660 : 0.0008138547418639064
Loss at iteration 670 : 0.0003618028713390231
Loss at iteration 680 : 0.00044952286407351494
Loss at iteration 690 : 0.00041086639976128936
Loss at iteration 700 : 0.0015950020169839263
Loss at iteration 710 : 0.000524228613357991
Loss at iteration 720 : 9.339967800769955e-05
Loss at iteration 730 : 0.0008246898069046438
Loss at iteration 740 : 0.004323513247072697
Loss at iteration 750 : 0.0047767856158316135
Loss at iteration 760 : 0.0004376261495053768
Loss at iteration 770 : 0.00043647593702189624
Loss at iteration 780 : 0.0003044370678253472
Loss at iteration 790 : 0.0005785460816696286
Loss at iteration 800 : 0.002874468918889761
Loss at iteration 810 : 0.0005063505377620459
Loss at iteration 820 : 0.00019313010852783918
Loss at iteration 830 : 0.00028387177735567093
Loss at iteration 840 : 0.0010756459087133408
Loss at iteration 850 : 0.0004122117243241519
Loss at iteration 860 : 0.00042737709009088576
Loss at iteration 870 : 0.00011033785995095968
Loss at iteration 880 : 0.0004012484278064221
Loss at iteration 890 : 5.5741998949088156e-05
Loss at iteration 900 : 0.004331182688474655
Loss at iteration 910 : 9.38861194299534e-05
Loss at iteration 920 : 0.0007209081668406725
Loss at iteration 930 : 0.0006303671398200095
Loss at iteration 940 : 0.0004247633332852274
Loss at iteration 950 : 0.0005017280345782638
Loss at iteration 960 : 0.0001279575371881947
Loss at iteration 970 : 0.00014912436017766595
Loss at iteration 980 : 0.004818920977413654
Loss at iteration 990 : 0.00023808609694242477
Loss at iteration 1000 : 0.000589513685554266
Loss at iteration 1010 : 0.000493275816552341
Loss at iteration 1020 : 0.00020429547294043005
Loss at iteration 1030 : 0.0031295318622142076
Loss at iteration 1040 : 0.0003511313407216221
Loss at iteration 1050 : 0.0017780447378754616
Loss at iteration 1060 : 0.001270621083676815
Loss at iteration 1070 : 0.005037980154156685
Loss at iteration 1080 : 0.00043581449426710606
Loss at iteration 1090 : 0.00028083164943382144
Loss at iteration 1100 : 0.004015714395791292
Loss at iteration 1110 : 0.0002716010785661638
Loss at iteration 1120 : 0.001050428720191121
Loss at iteration 1130 : 0.00013921110075898468
Loss at iteration 1140 : 7.738269778201357e-05
Loss at iteration 1150 : 0.004534888081252575
Loss at iteration 1160 : 0.0003362662100698799
Loss at iteration 1170 : 8.782275835983455e-05
Loss at iteration 1180 : 0.0008518787217326462
Loss at iteration 1190 : 0.0001275770046049729
Loss at iteration 1200 : 0.00010845529322978109
Loss at iteration 1210 : 0.0013277081307023764
Loss at iteration 1220 : 0.00010834806016646326
Loss at iteration 1230 : 0.006432338617742062
Loss at iteration 1240 : 0.00013885022781323642
Loss at iteration 1250 : 0.0023567331954836845
Loss at iteration 1260 : 0.002985610393807292
Loss at iteration 1270 : 0.0014684537891298532
Loss at iteration 1280 : 0.0010639555985108018
Loss at iteration 1290 : 0.00046238701906986535
Loss at iteration 1300 : 0.002656731056049466
Loss at iteration 1310 : 0.0036651974078267813
Loss at iteration 1320 : 0.002764422446489334
Loss at iteration 1330 : 0.0010263046715408564
Loss at iteration 1340 : 0.00042721614590846
Loss at iteration 1350 : 0.0004530350852292031
Loss at iteration 1360 : 0.00028087347163818777
Loss at iteration 1370 : 0.00357986893504858
Loss at iteration 1380 : 0.0001289779756916687
Loss at iteration 1390 : 0.0006205328973010182
Loss at iteration 1400 : 0.0019151007290929556
Loss at iteration 1410 : 0.0015731980092823505
Loss at iteration 1420 : 0.003516990225762129
Loss at iteration 1430 : 0.0017612128285691142
Loss at iteration 1440 : 0.001196312136016786
Loss at iteration 1450 : 0.003059889655560255
Loss at iteration 1460 : 8.543980220565572e-05
Loss at iteration 1470 : 0.0010639447718858719
Loss at iteration 1480 : 0.003834614995867014
Loss at iteration 1490 : 0.00021486359764821827
Loss at iteration 1500 : 0.00015930115478113294
Loss at iteration 1510 : 0.002435214351862669
Loss at iteration 1520 : 0.00011928168532904238
Loss at iteration 1530 : 0.0012663642410188913
Loss at iteration 1540 : 0.0007339330622926354
Loss at iteration 1550 : 0.001948632881976664
Loss at iteration 1560 : 0.0016366326017305255
Loss at iteration 1570 : 0.0004844485083594918
Loss at iteration 1580 : 0.0001383297931170091
Loss at iteration 1590 : 0.00021602760534733534
Loss at iteration 1600 : 0.0002525083546061069
Loss at iteration 1610 : 0.0003220240760128945
Loss at iteration 1620 : 0.00015913587412796915
Loss at iteration 1630 : 0.0016214079223573208
Loss at iteration 1640 : 0.0001417983294231817
Loss at iteration 1650 : 0.0002663322084117681
Loss at iteration 1660 : 9.457761916564777e-05
Loss at iteration 1670 : 0.00018032667867373675
Loss at iteration 1680 : 0.00020992841746192425
Loss at iteration 1690 : 0.00014265063509810716
Loss at iteration 1700 : 0.0034187284763902426
Loss at iteration 1710 : 0.0014957718085497618
Loss at iteration 1720 : 0.001175622339360416
Loss at iteration 1730 : 0.0003248123684898019
Loss at iteration 1740 : 0.00035936885979026556
Loss at iteration 1750 : 0.0003652169252745807
The SSIM Value is: 0.9808184103424854
The PSNR Value is: 46.5310293987459
the epoch is: 48
Loss at iteration 10 : 9.78841126197949e-05
Loss at iteration 20 : 0.0011717899469658732
Loss at iteration 30 : 0.00020887330174446106
Loss at iteration 40 : 0.000841073167975992
Loss at iteration 50 : 0.0016318343114107847
Loss at iteration 60 : 0.0064598615281283855
Loss at iteration 70 : 0.00020201219012960792
Loss at iteration 80 : 0.00023018315550871193
Loss at iteration 90 : 0.000180907198227942
Loss at iteration 100 : 0.0008935593068599701
Loss at iteration 110 : 0.00045224078348837793
Loss at iteration 120 : 0.0008920406689867377
Loss at iteration 130 : 0.0001258673146367073
Loss at iteration 140 : 6.452589150285348e-05
Loss at iteration 150 : 0.00013884808868169785
Loss at iteration 160 : 0.00017991079948842525
Loss at iteration 170 : 0.00015452405204996467
Loss at iteration 180 : 0.007741441018879414
Loss at iteration 190 : 0.00017558767285663635
Loss at iteration 200 : 0.00010545364784775302
Loss at iteration 210 : 7.023356738500297e-05
Loss at iteration 220 : 0.0007628051098436117
Loss at iteration 230 : 0.00016872858395799994
Loss at iteration 240 : 0.00023340663756243885
Loss at iteration 250 : 0.0002365144609939307
Loss at iteration 260 : 0.00016806843632366508
Loss at iteration 270 : 0.0011515608057379723
Loss at iteration 280 : 0.00018219195771962404
Loss at iteration 290 : 0.00040227494901046157
Loss at iteration 300 : 0.00021764918346889317
Loss at iteration 310 : 0.0006757503724656999
Loss at iteration 320 : 0.003057669848203659
Loss at iteration 330 : 0.000128670028061606
Loss at iteration 340 : 0.00013842276530340314
Loss at iteration 350 : 0.010276442393660545
Loss at iteration 360 : 0.011747660115361214
Loss at iteration 370 : 0.00028182828100398183
Loss at iteration 380 : 0.0007766546914353967
Loss at iteration 390 : 0.0001876634341897443
Loss at iteration 400 : 0.0021172892302274704
Loss at iteration 410 : 0.000272357021458447
Loss at iteration 420 : 0.0004147323779761791
Loss at iteration 430 : 0.00027653740835376084
Loss at iteration 440 : 5.53262434550561e-05
Loss at iteration 450 : 0.00022431748220697045
Loss at iteration 460 : 8.509448525728658e-05
Loss at iteration 470 : 0.0003600613272283226
Loss at iteration 480 : 9.471765952184796e-05
Loss at iteration 490 : 0.0023323586210608482
Loss at iteration 500 : 0.00029148944304324687
Loss at iteration 510 : 6.701617530779913e-05
Loss at iteration 520 : 0.0006299547385424376
Loss at iteration 530 : 8.615487604402006e-05
Loss at iteration 540 : 0.0014700395986437798
Loss at iteration 550 : 0.00010423750063637272
Loss at iteration 560 : 0.0003863256424665451
Loss at iteration 570 : 0.00010420534817967564
Loss at iteration 580 : 0.0002198367437813431
Loss at iteration 590 : 0.0027032929938286543
Loss at iteration 600 : 0.0008453833870589733
Loss at iteration 610 : 0.0003551210684236139
Loss at iteration 620 : 0.00027763060643337667
Loss at iteration 630 : 0.0020860000513494015
Loss at iteration 640 : 0.0016020277980715036
Loss at iteration 650 : 0.0007674754597246647
Loss at iteration 660 : 0.00024205062072724104
Loss at iteration 670 : 0.0004126660933252424
Loss at iteration 680 : 0.00013234102516435087
Loss at iteration 690 : 0.00014664405898656696
Loss at iteration 700 : 0.00030899897683411837
Loss at iteration 710 : 0.0005526048480533063
Loss at iteration 720 : 0.00015599765174556524
Loss at iteration 730 : 0.00018529525550547987
Loss at iteration 740 : 0.002883094595745206
Loss at iteration 750 : 0.002803937066346407
Loss at iteration 760 : 0.0004106631095055491
Loss at iteration 770 : 0.00042072561336681247
Loss at iteration 780 : 0.00029840064235031605
Loss at iteration 790 : 0.002069844864308834
Loss at iteration 800 : 8.418235665885732e-05
Loss at iteration 810 : 0.00016931816935539246
Loss at iteration 820 : 0.0005722487112507224
Loss at iteration 830 : 0.0039639221504330635
Loss at iteration 840 : 6.350646435748786e-05
Loss at iteration 850 : 0.0018111387034878135
Loss at iteration 860 : 0.00014776561874896288
Loss at iteration 870 : 0.0012056223349645734
Loss at iteration 880 : 0.00015489893849007785
Loss at iteration 890 : 0.0016810041852295399
Loss at iteration 900 : 0.004455499351024628
Loss at iteration 910 : 0.002531385514885187
Loss at iteration 920 : 0.0004700824210885912
Loss at iteration 930 : 0.00013914999726694077
Loss at iteration 940 : 0.003477614838629961
Loss at iteration 950 : 0.0005706330994144082
Loss at iteration 960 : 0.0023556805681437254
Loss at iteration 970 : 0.0034779899287968874
Loss at iteration 980 : 0.0016367007046937943
Loss at iteration 990 : 0.0005731991259381175
Loss at iteration 1000 : 0.0001857574679888785
Loss at iteration 1010 : 0.0009617984178476036
Loss at iteration 1020 : 0.0002224429335910827
Loss at iteration 1030 : 0.000532297941390425
Loss at iteration 1040 : 0.0004896043101325631
Loss at iteration 1050 : 0.0018686484545469284
Loss at iteration 1060 : 0.000279830681392923
Loss at iteration 1070 : 0.0012542533222585917
Loss at iteration 1080 : 0.00022351875668391585
Loss at iteration 1090 : 0.00015554696437902749
Loss at iteration 1100 : 0.00014983235450927168
Loss at iteration 1110 : 0.00044887163676321507
Loss at iteration 1120 : 0.0002835830382537097
Loss at iteration 1130 : 0.00011457117216195911
Loss at iteration 1140 : 0.00020551512716338038
Loss at iteration 1150 : 0.00014184744213707745
Loss at iteration 1160 : 0.00014260072202887386
Loss at iteration 1170 : 0.0005736607126891613
Loss at iteration 1180 : 0.0018293268512934446
Loss at iteration 1190 : 0.00010079104686155915
Loss at iteration 1200 : 0.00015613733557984233
Loss at iteration 1210 : 0.0025171590968966484
Loss at iteration 1220 : 0.006154889240860939
Loss at iteration 1230 : 0.0006234078900888562
Loss at iteration 1240 : 0.00028345530154183507
Loss at iteration 1250 : 0.0037339143455028534
Loss at iteration 1260 : 6.871610094094649e-05
Loss at iteration 1270 : 0.0017945623258128762
Loss at iteration 1280 : 3.6468583857640624e-05
Loss at iteration 1290 : 0.0008036589715629816
Loss at iteration 1300 : 0.0008395102340728045
Loss at iteration 1310 : 0.0002984497114084661
Loss at iteration 1320 : 0.002220718190073967
Loss at iteration 1330 : 0.00038652110379189253
Loss at iteration 1340 : 0.000110760418465361
Loss at iteration 1350 : 0.00037991494173184037
Loss at iteration 1360 : 0.0012166542001068592
Loss at iteration 1370 : 0.00012534066627267748
Loss at iteration 1380 : 0.0004031091521028429
Loss at iteration 1390 : 0.00014063433627597988
Loss at iteration 1400 : 0.005249082576483488
Loss at iteration 1410 : 9.956588473869488e-05
Loss at iteration 1420 : 0.0002292838616995141
Loss at iteration 1430 : 0.004284298047423363
Loss at iteration 1440 : 0.0002729985280893743
Loss at iteration 1450 : 0.003008444095030427
Loss at iteration 1460 : 0.0002857775834854692
Loss at iteration 1470 : 9.434307139599696e-05
Loss at iteration 1480 : 0.000471284962259233
Loss at iteration 1490 : 0.0001322219759458676
Loss at iteration 1500 : 0.0030376834329217672
Loss at iteration 1510 : 7.035248563624918e-05
Loss at iteration 1520 : 0.00037560859345830977
Loss at iteration 1530 : 0.0007820760365575552
Loss at iteration 1540 : 0.000766805955208838
Loss at iteration 1550 : 0.00043182968511246145
Loss at iteration 1560 : 0.00025432961410842836
Loss at iteration 1570 : 0.0002765424142125994
Loss at iteration 1580 : 0.0009144500363618135
Loss at iteration 1590 : 0.00011434614134486765
Loss at iteration 1600 : 0.0002279886684846133
Loss at iteration 1610 : 0.000487896497361362
Loss at iteration 1620 : 0.002603319939225912
Loss at iteration 1630 : 9.107780351769179e-05
Loss at iteration 1640 : 9.58901655394584e-05
Loss at iteration 1650 : 0.004004147835075855
Loss at iteration 1660 : 0.0026475766208022833
Loss at iteration 1670 : 0.0051211710087955
Loss at iteration 1680 : 0.0001791447721188888
Loss at iteration 1690 : 0.00039188694790937006
Loss at iteration 1700 : 6.146897794678807e-05
Loss at iteration 1710 : 0.004040791653096676
Loss at iteration 1720 : 0.0007952400483191013
Loss at iteration 1730 : 0.002366054803133011
Loss at iteration 1740 : 8.359320054296404e-05
Loss at iteration 1750 : 0.004411720670759678
The SSIM Value is: 0.9852003305493997
The PSNR Value is: 46.460225920320084
the epoch is: 49
Loss at iteration 10 : 0.00015829471522010863
Loss at iteration 20 : 0.00019705903832800686
Loss at iteration 30 : 0.000118465737614315
Loss at iteration 40 : 0.00030015615629963577
Loss at iteration 50 : 0.0004740725562442094
Loss at iteration 60 : 0.00020801150822080672
Loss at iteration 70 : 6.181002390803769e-05
Loss at iteration 80 : 0.0024062790907919407
Loss at iteration 90 : 0.0006198134506121278
Loss at iteration 100 : 9.6471696451772e-05
Loss at iteration 110 : 0.00022181466920301318
Loss at iteration 120 : 0.000290359283098951
Loss at iteration 130 : 0.0028458533342927694
Loss at iteration 140 : 0.004014466889202595
Loss at iteration 150 : 0.00031594419851899147
Loss at iteration 160 : 0.0013557567726820707
Loss at iteration 170 : 6.816405948484316e-05
Loss at iteration 180 : 0.0019990806467831135
Loss at iteration 190 : 0.0032136233057826757
Loss at iteration 200 : 0.0001508371642557904
Loss at iteration 210 : 0.00010354502592235804
Loss at iteration 220 : 0.000290216994471848
Loss at iteration 230 : 0.0011911583133041859
Loss at iteration 240 : 0.000776894623413682
Loss at iteration 250 : 8.035832433961332e-05
Loss at iteration 260 : 0.0042371973395347595
Loss at iteration 270 : 0.0030392766930162907
Loss at iteration 280 : 0.0006992293056100607
Loss at iteration 290 : 0.0004288728232495487
Loss at iteration 300 : 0.0010995918419212103
Loss at iteration 310 : 0.00026143749710172415
Loss at iteration 320 : 0.002134658396244049
Loss at iteration 330 : 0.00023971698828972876
Loss at iteration 340 : 0.0005228733643889427
Loss at iteration 350 : 0.002578111831098795
Loss at iteration 360 : 0.007040971890091896
Loss at iteration 370 : 0.0002280006738146767
Loss at iteration 380 : 0.001336995861493051
Loss at iteration 390 : 0.001293351873755455
Loss at iteration 400 : 0.0002665118081495166
Loss at iteration 410 : 0.0020275283604860306
Loss at iteration 420 : 0.0006329400930553675
Loss at iteration 430 : 0.00017548745381645858
Loss at iteration 440 : 0.003258683253079653
Loss at iteration 450 : 0.0021332846954464912
Loss at iteration 460 : 0.0002984598686452955
Loss at iteration 470 : 0.001552229281514883
Loss at iteration 480 : 0.0003366741584613919
Loss at iteration 490 : 0.0015880585415288806
Loss at iteration 500 : 0.00045341229997575283
Loss at iteration 510 : 0.00023512367624789476
Loss at iteration 520 : 0.0009290593443438411
Loss at iteration 530 : 0.0003945610369555652
Loss at iteration 540 : 0.00017075453069992363
Loss at iteration 550 : 0.00021772089530713856
Loss at iteration 560 : 0.0005055191577412188
Loss at iteration 570 : 0.0002375139156356454
Loss at iteration 580 : 0.00017749237304087728
Loss at iteration 590 : 0.00010867347737075761
Loss at iteration 600 : 0.0029262106399983168
Loss at iteration 610 : 0.00010469332482898608
Loss at iteration 620 : 0.0011992447543889284
Loss at iteration 630 : 0.0004770458035636693
Loss at iteration 640 : 0.0010907670948654413
Loss at iteration 650 : 0.0003574734437279403
Loss at iteration 660 : 0.002136236522346735
Loss at iteration 670 : 0.0003672348102554679
Loss at iteration 680 : 0.0034590978175401688
Loss at iteration 690 : 0.004544475115835667
Loss at iteration 700 : 0.0009085694327950478
Loss at iteration 710 : 0.00035879964707419276
Loss at iteration 720 : 0.001088856952264905
Loss at iteration 730 : 0.00451665697619319
Loss at iteration 740 : 0.0003484261978883296
Loss at iteration 750 : 0.0018644080264493823
Loss at iteration 760 : 0.0001402588386554271
Loss at iteration 770 : 0.0074980491772294044
Loss at iteration 780 : 0.003462407737970352
Loss at iteration 790 : 0.00027527115889824927
Loss at iteration 800 : 0.002462099539116025
Loss at iteration 810 : 0.0010600953828543425
Loss at iteration 820 : 0.0007131086895242333
Loss at iteration 830 : 9.974504791898653e-05
Loss at iteration 840 : 0.0019230240723118186
Loss at iteration 850 : 0.00012147190136602148
Loss at iteration 860 : 0.0035666553303599358
Loss at iteration 870 : 8.875058847479522e-05
Loss at iteration 880 : 0.003051616484299302
Loss at iteration 890 : 0.00048601580783724785
Loss at iteration 900 : 0.0019061295315623283
Loss at iteration 910 : 0.00011590681970119476
Loss at iteration 920 : 0.00011588523193495348
Loss at iteration 930 : 0.000496577937155962
Loss at iteration 940 : 9.532206604490057e-05
Loss at iteration 950 : 0.00023204938042908907
Loss at iteration 960 : 0.0007990846643224359
Loss at iteration 970 : 0.006306397262960672
Loss at iteration 980 : 0.00023550522746518254
Loss at iteration 990 : 0.0012640217319130898
Loss at iteration 1000 : 0.0022451195400208235
Loss at iteration 1010 : 0.00017336473683826625
Loss at iteration 1020 : 0.00013209135795477778
Loss at iteration 1030 : 0.0004998907679691911
Loss at iteration 1040 : 0.0020125280134379864
Loss at iteration 1050 : 0.0001350665115751326
Loss at iteration 1060 : 0.00022680575784761459
Loss at iteration 1070 : 0.0001848896499723196
Loss at iteration 1080 : 0.00016738686827011406
Loss at iteration 1090 : 0.002917802892625332
Loss at iteration 1100 : 0.0003189530980307609
Loss at iteration 1110 : 0.0037512273993343115
Loss at iteration 1120 : 0.001428909134119749
Loss at iteration 1130 : 0.0005396690685302019
Loss at iteration 1140 : 0.0009473874815739691
Loss at iteration 1150 : 0.0057869721204042435
Loss at iteration 1160 : 0.0003629549755714834
Loss at iteration 1170 : 0.003788558766245842
Loss at iteration 1180 : 0.0005800678045488894
Loss at iteration 1190 : 0.004580646753311157
Loss at iteration 1200 : 0.000370662979548797
Loss at iteration 1210 : 0.00012785755097866058
Loss at iteration 1220 : 0.005654527340084314
Loss at iteration 1230 : 0.0011227255454286933
Loss at iteration 1240 : 9.581563790561631e-05
Loss at iteration 1250 : 0.0002189582446590066
Loss at iteration 1260 : 0.00010203781857853755
Loss at iteration 1270 : 0.00027651930577121675
Loss at iteration 1280 : 0.0019877084996551275
Loss at iteration 1290 : 0.0002983726735692471
Loss at iteration 1300 : 0.0008554321248084307
Loss at iteration 1310 : 0.0014915225328877568
Loss at iteration 1320 : 0.00011858950892928988
Loss at iteration 1330 : 6.862266309326515e-05
Loss at iteration 1340 : 0.00012715118646156043
Loss at iteration 1350 : 0.00021815010404679924
Loss at iteration 1360 : 0.002848525997251272
Loss at iteration 1370 : 0.0002920684346463531
Loss at iteration 1380 : 0.0009889354696497321
Loss at iteration 1390 : 0.00023501846590079367
Loss at iteration 1400 : 0.00019844574853777885
Loss at iteration 1410 : 0.0015986745711416006
Loss at iteration 1420 : 0.00013482380018103868
Loss at iteration 1430 : 6.952707917662337e-05
Loss at iteration 1440 : 0.00466534961014986
Loss at iteration 1450 : 0.000132382643641904
Loss at iteration 1460 : 0.000644558691419661
Loss at iteration 1470 : 0.004723955411463976
Loss at iteration 1480 : 0.00010075559112010524
Loss at iteration 1490 : 0.0005324019584804773
Loss at iteration 1500 : 0.0013590255985036492
Loss at iteration 1510 : 0.0024761678650975227
Loss at iteration 1520 : 0.002038715872913599
Loss at iteration 1530 : 0.0007505160756409168
Loss at iteration 1540 : 0.0015488122589886189
Loss at iteration 1550 : 0.00033426983281970024
Loss at iteration 1560 : 0.0027368771843612194
Loss at iteration 1570 : 0.0005047383601777256
Loss at iteration 1580 : 0.00033208326203748584
Loss at iteration 1590 : 0.0003585216763895005
Loss at iteration 1600 : 0.0008556669345125556
Loss at iteration 1610 : 0.001200672471895814
Loss at iteration 1620 : 0.00043828602065332234
Loss at iteration 1630 : 0.000705621438100934
Loss at iteration 1640 : 0.00016274061636067927
Loss at iteration 1650 : 0.0001515038457000628
Loss at iteration 1660 : 0.0003278230724390596
Loss at iteration 1670 : 0.00017897757061291486
Loss at iteration 1680 : 0.0001020774434437044
Loss at iteration 1690 : 0.0005001527606509626
Loss at iteration 1700 : 0.0014274406712502241
Loss at iteration 1710 : 0.00026002718368545175
Loss at iteration 1720 : 0.00029389269184321165
Loss at iteration 1730 : 0.0006926733767613769
Loss at iteration 1740 : 0.00022694854123983532
Loss at iteration 1750 : 0.00028362422017380595
The SSIM Value is: 0.9867998831597719
The PSNR Value is: 46.35518088739874
the epoch is: 50
Loss at iteration 10 : 0.00022963342780712992
Loss at iteration 20 : 0.0006672927411273122
Loss at iteration 30 : 0.0007255765376612544
Loss at iteration 40 : 0.00021829442994203418
Loss at iteration 50 : 0.002139277756214142
Loss at iteration 60 : 0.000175739754922688
Loss at iteration 70 : 0.0002796732587739825
Loss at iteration 80 : 0.00026679300935938954
Loss at iteration 90 : 0.00013217513333074749
Loss at iteration 100 : 0.00152789696585387
Loss at iteration 110 : 0.0002498021931387484
Loss at iteration 120 : 0.0007813092088326812
Loss at iteration 130 : 0.0001670473866397515
Loss at iteration 140 : 7.192318298621103e-05
Loss at iteration 150 : 0.0028939046896994114
Loss at iteration 160 : 0.0018289850559085608
Loss at iteration 170 : 0.0002364221727475524
Loss at iteration 180 : 0.0019383660983294249
Loss at iteration 190 : 0.0008064446737989783
Loss at iteration 200 : 0.0024549656081944704
Loss at iteration 210 : 0.0002588038332760334
Loss at iteration 220 : 0.000669966684654355
Loss at iteration 230 : 0.0005051213665865362
Loss at iteration 240 : 0.0022004940547049046
Loss at iteration 250 : 0.0028683319687843323
Loss at iteration 260 : 0.0004706078034359962
Loss at iteration 270 : 0.002046113833785057
Loss at iteration 280 : 6.875662802485749e-05
Loss at iteration 290 : 0.0001590288884472102
Loss at iteration 300 : 0.00024121768365148455
Loss at iteration 310 : 0.00018670022836886346
Loss at iteration 320 : 0.00082732317969203
Loss at iteration 330 : 0.000288821232970804
Loss at iteration 340 : 0.0007186500588431954
Loss at iteration 350 : 0.000116566545329988
Loss at iteration 360 : 0.0007222046842798591
Loss at iteration 370 : 0.0007171521428972483
Loss at iteration 380 : 0.00014781822392251343
Loss at iteration 390 : 0.00419898284599185
Loss at iteration 400 : 0.0034956166055053473
Loss at iteration 410 : 0.00024097187269944698
Loss at iteration 420 : 0.00014234791160561144
Loss at iteration 430 : 0.0019486038945615292
Loss at iteration 440 : 0.00011975869711022824
Loss at iteration 450 : 0.00041519576916471124
Loss at iteration 460 : 5.655505083268508e-05
Loss at iteration 470 : 0.0033436520025134087
Loss at iteration 480 : 0.0002906680747400969
Loss at iteration 490 : 0.0001198295212816447
Loss at iteration 500 : 0.0027309947181493044
Loss at iteration 510 : 0.0014014834305271506
Loss at iteration 520 : 0.0001080146903404966
Loss at iteration 530 : 0.0026977285742759705
Loss at iteration 540 : 0.0037343918811529875
Loss at iteration 550 : 0.0011669457890093327
Loss at iteration 560 : 6.597939500352368e-05
Loss at iteration 570 : 0.0012206449173390865
Loss at iteration 580 : 8.726533997105435e-05
Loss at iteration 590 : 0.00079566944623366
Loss at iteration 600 : 0.0016423079650849104
Loss at iteration 610 : 0.00013597545330412686
Loss at iteration 620 : 0.00022957884357310832
Loss at iteration 630 : 0.0004009027616120875
Loss at iteration 640 : 0.00019016982696484774
Loss at iteration 650 : 0.00011938838724745438
Loss at iteration 660 : 0.00010079662024509162
Loss at iteration 670 : 0.0003384800220374018
Loss at iteration 680 : 0.00048163149040192366
Loss at iteration 690 : 0.003932193852961063
Loss at iteration 700 : 0.0001244089799001813
Loss at iteration 710 : 0.0004807477816939354
Loss at iteration 720 : 0.002987397601827979
Loss at iteration 730 : 0.00026193197118118405
Loss at iteration 740 : 0.00019408501975703984
Loss at iteration 750 : 9.121637413045391e-05
Loss at iteration 760 : 0.00018107678624801338
Loss at iteration 770 : 0.0002839996595866978
Loss at iteration 780 : 0.00018370358156971633
Loss at iteration 790 : 9.095586574403569e-05
Loss at iteration 800 : 0.00013614217459689826
Loss at iteration 810 : 7.672682113479823e-05
Loss at iteration 820 : 0.00019278177933301777
Loss at iteration 830 : 0.00021040960564278066
Loss at iteration 840 : 0.000622398336417973
Loss at iteration 850 : 0.0023806937970221043
Loss at iteration 860 : 0.00017639702127780765
Loss at iteration 870 : 6.044844485586509e-05
Loss at iteration 880 : 0.0005271523841656744
Loss at iteration 890 : 0.00045663834316655993
Loss at iteration 900 : 0.0002029698807746172
Loss at iteration 910 : 0.0018871015636250377
Loss at iteration 920 : 0.0013024368090555072
Loss at iteration 930 : 0.0001739104773150757
Loss at iteration 940 : 0.0007280175341293216
Loss at iteration 950 : 8.455244824290276e-05
Loss at iteration 960 : 0.00025659805396571755
Loss at iteration 970 : 0.0001290029613301158
Loss at iteration 980 : 0.002127881394699216
Loss at iteration 990 : 0.0004721623263321817
Loss at iteration 1000 : 0.001303358469158411
Loss at iteration 1010 : 0.000151285610627383
Loss at iteration 1020 : 0.0018689073622226715
Loss at iteration 1030 : 0.0003253609174862504
Loss at iteration 1040 : 0.00016772086382843554
Loss at iteration 1050 : 0.00023508172307629138
Loss at iteration 1060 : 0.00042135652620345354
Loss at iteration 1070 : 7.528950663981959e-05
Loss at iteration 1080 : 0.00015149965474847704
Loss at iteration 1090 : 0.002978770062327385
Loss at iteration 1100 : 0.0009470013901591301
Loss at iteration 1110 : 0.00022869749227538705
Loss at iteration 1120 : 0.0004758732975460589
Loss at iteration 1130 : 0.00011300462938379496
Loss at iteration 1140 : 0.0003083148621954024
Loss at iteration 1150 : 0.00052297004731372
Loss at iteration 1160 : 0.00026623994926922023
Loss at iteration 1170 : 0.00019758885900955647
Loss at iteration 1180 : 0.00011927675950573757
Loss at iteration 1190 : 8.021062967600301e-05
Loss at iteration 1200 : 0.00814652256667614
Loss at iteration 1210 : 0.0006951710674911737
Loss at iteration 1220 : 0.0011095554800704122
Loss at iteration 1230 : 0.00012195983435958624
Loss at iteration 1240 : 0.0032940865494310856
Loss at iteration 1250 : 0.0003607801045291126
Loss at iteration 1260 : 0.0006514123524539173
Loss at iteration 1270 : 0.00030494495877064764
Loss at iteration 1280 : 0.0002174941764678806
Loss at iteration 1290 : 5.6603919802000746e-05
Loss at iteration 1300 : 6.591116107301787e-05
Loss at iteration 1310 : 0.00027717772172763944
Loss at iteration 1320 : 0.00011257869482506067
Loss at iteration 1330 : 0.0003775073273573071
Loss at iteration 1340 : 9.377238166052848e-05
Loss at iteration 1350 : 0.0006050113006494939
Loss at iteration 1360 : 0.0009361320408061147
Loss at iteration 1370 : 0.0026803254149854183
Loss at iteration 1380 : 0.006250310223549604
Loss at iteration 1390 : 0.00048247375525534153
Loss at iteration 1400 : 0.0002254414139315486
Loss at iteration 1410 : 0.001255589071661234
Loss at iteration 1420 : 0.003513102186843753
Loss at iteration 1430 : 0.0005333147128112614
Loss at iteration 1440 : 0.00026911613531410694
Loss at iteration 1450 : 0.0005197292193770409
Loss at iteration 1460 : 0.0001915983302751556
Loss at iteration 1470 : 7.648263999726623e-05
Loss at iteration 1480 : 8.000998786883429e-05
Loss at iteration 1490 : 0.0011956794187426567
Loss at iteration 1500 : 0.000393243768485263
Loss at iteration 1510 : 0.00012542640615720302
Loss at iteration 1520 : 0.00010884727817028761
Loss at iteration 1530 : 0.0021061934530735016
Loss at iteration 1540 : 0.00011242380423936993
Loss at iteration 1550 : 0.00022754471865482628
Loss at iteration 1560 : 9.265737753594294e-05
Loss at iteration 1570 : 0.003131147474050522
Loss at iteration 1580 : 0.00011506662121973932
Loss at iteration 1590 : 0.0001140175954787992
Loss at iteration 1600 : 0.001396728795953095
Loss at iteration 1610 : 0.0007414979627355933
Loss at iteration 1620 : 0.000287123053567484
Loss at iteration 1630 : 0.00024165751528926194
Loss at iteration 1640 : 0.00017956926603801548
Loss at iteration 1650 : 0.00024293793831020594
Loss at iteration 1660 : 0.00016991101438179612
Loss at iteration 1670 : 0.00021877139806747437
Loss at iteration 1680 : 0.0016394038684666157
Loss at iteration 1690 : 0.00039222827763296664
Loss at iteration 1700 : 0.0003186351677868515
Loss at iteration 1710 : 0.0007472453289665282
Loss at iteration 1720 : 0.00020115624647587538
Loss at iteration 1730 : 6.531141843879595e-05
Loss at iteration 1740 : 0.00021133298287168145
Loss at iteration 1750 : 0.0001109400691348128
The SSIM Value is: 0.9783527266217749
The PSNR Value is: 46.57470173772736
the epoch is: 51
Loss at iteration 10 : 0.00048299451009370387
Loss at iteration 20 : 0.00020368100376799703
Loss at iteration 30 : 0.0034152776934206486
Loss at iteration 40 : 0.0034433724358677864
Loss at iteration 50 : 0.0004091694427188486
Loss at iteration 60 : 0.0003704479895532131
Loss at iteration 70 : 0.0004471221473067999
Loss at iteration 80 : 0.00040230227750726044
Loss at iteration 90 : 0.00014285347424447536
Loss at iteration 100 : 0.0064075905829668045
Loss at iteration 110 : 0.0011205493938177824
Loss at iteration 120 : 0.00022179458755999804
Loss at iteration 130 : 0.0013732502702623606
Loss at iteration 140 : 0.00015184114454314113
Loss at iteration 150 : 0.0015958081930875778
Loss at iteration 160 : 0.0002200286544393748
Loss at iteration 170 : 0.00017159880371764302
Loss at iteration 180 : 0.000251269229920581
Loss at iteration 190 : 0.00012236872862558812
Loss at iteration 200 : 0.0034212323371320963
Loss at iteration 210 : 0.0006956389406695962
Loss at iteration 220 : 0.00013569487782660872
Loss at iteration 230 : 0.00012548344966489822
Loss at iteration 240 : 0.001165128080174327
Loss at iteration 250 : 0.0010583450784906745
Loss at iteration 260 : 0.00013458164175972342
Loss at iteration 270 : 0.00013532076263800263
Loss at iteration 280 : 0.003512181807309389
Loss at iteration 290 : 0.00045733735896646976
Loss at iteration 300 : 0.000520544417668134
Loss at iteration 310 : 0.0015013136435300112
Loss at iteration 320 : 0.00030276423785835505
Loss at iteration 330 : 0.0001477621408412233
Loss at iteration 340 : 0.0019532176665961742
Loss at iteration 350 : 0.00022582916426472366
Loss at iteration 360 : 0.0001324412296526134
Loss at iteration 370 : 0.000887976901140064
Loss at iteration 380 : 0.00011100315896328539
Loss at iteration 390 : 0.0020675468258559704
Loss at iteration 400 : 0.006049319636076689
Loss at iteration 410 : 0.0005373768508434296
Loss at iteration 420 : 0.001589293242432177
Loss at iteration 430 : 0.0007129029254429042
Loss at iteration 440 : 5.6181968830060214e-05
Loss at iteration 450 : 0.0007809772505424917
Loss at iteration 460 : 0.0002669401583261788
Loss at iteration 470 : 0.0004970789887011051
Loss at iteration 480 : 0.0008649572264403105
Loss at iteration 490 : 0.0005640772869810462
Loss at iteration 500 : 0.00021590880351141095
Loss at iteration 510 : 0.002941266866400838
Loss at iteration 520 : 0.0001416460727341473
Loss at iteration 530 : 0.0018959013978019357
Loss at iteration 540 : 0.00021606926748063415
Loss at iteration 550 : 0.001535463728941977
Loss at iteration 560 : 0.0001375054707750678
Loss at iteration 570 : 0.00289639993570745
Loss at iteration 580 : 0.00042746527469716966
Loss at iteration 590 : 0.0015143119962885976
Loss at iteration 600 : 8.895887003745884e-05
Loss at iteration 610 : 0.0017278428422287107
Loss at iteration 620 : 0.0001936618355102837
Loss at iteration 630 : 9.045475599123165e-05
Loss at iteration 640 : 0.0019309818744659424
Loss at iteration 650 : 0.00116863870061934
Loss at iteration 660 : 0.0006132096168585122
Loss at iteration 670 : 0.00030704718665219843
Loss at iteration 680 : 0.00024253276933450252
Loss at iteration 690 : 0.006803961470723152
Loss at iteration 700 : 0.0002296924649272114
Loss at iteration 710 : 0.0003526572836562991
Loss at iteration 720 : 0.00027186176157556474
Loss at iteration 730 : 0.0001896960602607578
Loss at iteration 740 : 0.000916128046810627
Loss at iteration 750 : 0.0001966181444004178
Loss at iteration 760 : 0.0003997174499090761
Loss at iteration 770 : 0.00011645307677099481
Loss at iteration 780 : 0.0001656859676586464
Loss at iteration 790 : 0.0015877035912126303
Loss at iteration 800 : 0.0001625042932573706
Loss at iteration 810 : 0.0009124906500801444
Loss at iteration 820 : 0.00022357208945322782
Loss at iteration 830 : 0.0030798090156167746
Loss at iteration 840 : 0.0004772507818415761
Loss at iteration 850 : 7.994838961167261e-05
Loss at iteration 860 : 0.0014145554741844535
Loss at iteration 870 : 0.0002981085854116827
Loss at iteration 880 : 0.00140370090957731
Loss at iteration 890 : 0.00016319286078214645
Loss at iteration 900 : 0.0005415286868810654
Loss at iteration 910 : 7.00171003700234e-05
Loss at iteration 920 : 0.0013351389206945896
Loss at iteration 930 : 0.00014324004587251693
Loss at iteration 940 : 0.00012783531565219164
Loss at iteration 950 : 0.00021357550576794893
Loss at iteration 960 : 7.630109030287713e-05
Loss at iteration 970 : 0.002778831636533141
Loss at iteration 980 : 0.0003188904083799571
Loss at iteration 990 : 0.00027296459302306175
Loss at iteration 1000 : 0.0005654022679664195
Loss at iteration 1010 : 0.0006653370801359415
Loss at iteration 1020 : 0.0007210128824226558
Loss at iteration 1030 : 0.00022837174765300006
Loss at iteration 1040 : 0.0001759208389557898
Loss at iteration 1050 : 0.0002817614295054227
Loss at iteration 1060 : 0.000264510017586872
Loss at iteration 1070 : 0.00013612677867058665
Loss at iteration 1080 : 0.0001380904286634177
Loss at iteration 1090 : 0.0001632030471228063
Loss at iteration 1100 : 0.0011798623017966747
Loss at iteration 1110 : 0.0002545192837715149
Loss at iteration 1120 : 0.0008909227326512337
Loss at iteration 1130 : 0.00013003437197767198
Loss at iteration 1140 : 0.0002444548299536109
Loss at iteration 1150 : 0.00010725202446337789
Loss at iteration 1160 : 0.00046295340871438384
Loss at iteration 1170 : 0.0005119864945299923
Loss at iteration 1180 : 0.00018044134776573628
Loss at iteration 1190 : 0.002835805993527174
Loss at iteration 1200 : 0.002275227103382349
Loss at iteration 1210 : 0.0009109457023441792
Loss at iteration 1220 : 0.0028289740439504385
Loss at iteration 1230 : 0.00017139187548309565
Loss at iteration 1240 : 0.00010818606824614108
Loss at iteration 1250 : 0.0002328114933334291
Loss at iteration 1260 : 0.00012186459935037419
Loss at iteration 1270 : 0.0013218583771958947
Loss at iteration 1280 : 0.00024722114903852344
Loss at iteration 1290 : 0.0050169904716312885
Loss at iteration 1300 : 0.004818652290850878
Loss at iteration 1310 : 0.0006985568325035274
Loss at iteration 1320 : 0.006696833297610283
Loss at iteration 1330 : 0.00024022355501074344
Loss at iteration 1340 : 0.0001997518411371857
Loss at iteration 1350 : 0.00022458407329395413
Loss at iteration 1360 : 0.0025193565525114536
Loss at iteration 1370 : 0.00010359342559240758
Loss at iteration 1380 : 8.835004700813442e-05
Loss at iteration 1390 : 0.00511025357991457
Loss at iteration 1400 : 0.00045778549974784255
Loss at iteration 1410 : 0.0035946283023804426
Loss at iteration 1420 : 0.00030450226040557027
Loss at iteration 1430 : 0.0006698156357742846
Loss at iteration 1440 : 6.881215813336894e-05
Loss at iteration 1450 : 0.00024165777722373605
Loss at iteration 1460 : 0.0018160638865083456
Loss at iteration 1470 : 0.00024109998776111752
Loss at iteration 1480 : 0.0003443041059654206
Loss at iteration 1490 : 0.0005670033860951662
Loss at iteration 1500 : 0.0005419242661446333
Loss at iteration 1510 : 0.00022783293388783932
Loss at iteration 1520 : 0.00015765608986839652
Loss at iteration 1530 : 0.001282330951653421
Loss at iteration 1540 : 6.92867542966269e-05
Loss at iteration 1550 : 0.0003419448039494455
Loss at iteration 1560 : 0.00011088541941717267
Loss at iteration 1570 : 0.00014864871627651155
Loss at iteration 1580 : 0.0008096307283267379
Loss at iteration 1590 : 0.0001624344295123592
Loss at iteration 1600 : 0.00021080300211906433
Loss at iteration 1610 : 0.0017984649166464806
Loss at iteration 1620 : 6.10443894402124e-05
Loss at iteration 1630 : 0.00026034045731648803
Loss at iteration 1640 : 0.0012859447160735726
Loss at iteration 1650 : 0.0018056273693218827
Loss at iteration 1660 : 0.004214177839457989
Loss at iteration 1670 : 0.0004401988408062607
Loss at iteration 1680 : 0.002744589000940323
Loss at iteration 1690 : 0.004431689623743296
Loss at iteration 1700 : 0.0024039086420089006
Loss at iteration 1710 : 7.552378519903868e-05
Loss at iteration 1720 : 0.0001427346287528053
Loss at iteration 1730 : 0.0005807731067761779
Loss at iteration 1740 : 0.0037043250631541014
Loss at iteration 1750 : 0.0012134830467402935
The SSIM Value is: 0.9829165816044493
The PSNR Value is: 46.49993975467094
the epoch is: 52
Loss at iteration 10 : 0.00043912819819524884
Loss at iteration 20 : 7.919982454041019e-05
Loss at iteration 30 : 0.003006621962413192
Loss at iteration 40 : 0.0008623081957921386
Loss at iteration 50 : 0.0007730549550615251
Loss at iteration 60 : 7.26937287254259e-05
Loss at iteration 70 : 0.00011809793068096042
Loss at iteration 80 : 0.0012278971262276173
Loss at iteration 90 : 0.00019341550068929791
Loss at iteration 100 : 0.0014807452680543065
Loss at iteration 110 : 0.0001143064655479975
Loss at iteration 120 : 0.0001722911256365478
Loss at iteration 130 : 0.00038872513687238097
Loss at iteration 140 : 0.0005411173915490508
Loss at iteration 150 : 0.0018771467730402946
Loss at iteration 160 : 0.00016751181101426482
Loss at iteration 170 : 0.0028600692749023438
Loss at iteration 180 : 0.0014085141010582447
Loss at iteration 190 : 0.00027334713377058506
Loss at iteration 200 : 0.0008636326529085636
Loss at iteration 210 : 0.00044033501762896776
Loss at iteration 220 : 0.000617486541159451
Loss at iteration 230 : 0.00011722040653694421
Loss at iteration 240 : 0.0003375044616404921
Loss at iteration 250 : 0.00015437872207257897
Loss at iteration 260 : 0.0006013893871568143
Loss at iteration 270 : 0.00011722309136530384
Loss at iteration 280 : 0.0006973030976951122
Loss at iteration 290 : 0.0011479342356324196
Loss at iteration 300 : 0.0001031901701935567
Loss at iteration 310 : 0.006004467606544495
Loss at iteration 320 : 0.00038631274946965277
Loss at iteration 330 : 0.0003348124446347356
Loss at iteration 340 : 0.0006359525141306221
Loss at iteration 350 : 0.0004121342790313065
Loss at iteration 360 : 0.0027331775054335594
Loss at iteration 370 : 0.00015954827540554106
Loss at iteration 380 : 0.0005647025536745787
Loss at iteration 390 : 0.00016005702491384
Loss at iteration 400 : 0.0032866252586245537
Loss at iteration 410 : 0.00023580709239467978
Loss at iteration 420 : 0.001666238415054977
Loss at iteration 430 : 0.0009900627192109823
Loss at iteration 440 : 9.19845188036561e-05
Loss at iteration 450 : 0.0028546657413244247
Loss at iteration 460 : 0.0003095799474976957
Loss at iteration 470 : 0.0031669277232140303
Loss at iteration 480 : 0.0006348371389321983
Loss at iteration 490 : 0.00020993458747398108
Loss at iteration 500 : 0.0002477829984854907
Loss at iteration 510 : 0.001484910142607987
Loss at iteration 520 : 0.002939903875812888
Loss at iteration 530 : 0.0003947414516005665
Loss at iteration 540 : 0.0020568070467561483
Loss at iteration 550 : 0.0006940768798813224
Loss at iteration 560 : 0.00013446742377709597
Loss at iteration 570 : 0.00047028707922436297
Loss at iteration 580 : 0.00022730983619112521
Loss at iteration 590 : 0.0005595777183771133
Loss at iteration 600 : 0.00035932110040448606
Loss at iteration 610 : 0.00010521805961616337
Loss at iteration 620 : 0.0004868968389928341
Loss at iteration 630 : 0.00016314403910655528
Loss at iteration 640 : 0.00014123135770205408
Loss at iteration 650 : 0.0020766821689903736
Loss at iteration 660 : 0.0005188435316085815
Loss at iteration 670 : 0.004748282488435507
Loss at iteration 680 : 0.002347035799175501
Loss at iteration 690 : 0.00016299383423756808
Loss at iteration 700 : 0.004775957204401493
Loss at iteration 710 : 0.0001231641072081402
Loss at iteration 720 : 0.00015040281869005412
Loss at iteration 730 : 0.00011595834803301841
Loss at iteration 740 : 0.0002304096706211567
Loss at iteration 750 : 0.004325252026319504
Loss at iteration 760 : 0.00011147955956403166
Loss at iteration 770 : 6.200258212629706e-05
Loss at iteration 780 : 0.0025975340977311134
Loss at iteration 790 : 0.00011655835260171443
Loss at iteration 800 : 0.0005331402644515038
Loss at iteration 810 : 0.0028073585126549006
Loss at iteration 820 : 0.0005084335571154952
Loss at iteration 830 : 0.00016148848226293921
Loss at iteration 840 : 0.00037750936462543905
Loss at iteration 850 : 0.004164170008152723
Loss at iteration 860 : 0.004406465217471123
Loss at iteration 870 : 6.865683826617897e-05
Loss at iteration 880 : 0.0002359013305976987
Loss at iteration 890 : 7.759729487588629e-05
Loss at iteration 900 : 0.002909282222390175
Loss at iteration 910 : 0.0001473469310440123
Loss at iteration 920 : 8.455013448838145e-05
Loss at iteration 930 : 0.0010264741722494364
Loss at iteration 940 : 0.00017460001981817186
Loss at iteration 950 : 0.0015223048394545913
Loss at iteration 960 : 0.001579723204486072
Loss at iteration 970 : 0.00025810865918174386
Loss at iteration 980 : 0.0007791726384311914
Loss at iteration 990 : 0.00022466990048997104
Loss at iteration 1000 : 0.0019922489300370216
Loss at iteration 1010 : 0.004675209987908602
Loss at iteration 1020 : 0.00205980590544641
Loss at iteration 1030 : 0.00010097275662701577
Loss at iteration 1040 : 0.002340076956897974
Loss at iteration 1050 : 0.0007305611507035792
Loss at iteration 1060 : 0.0009371591731905937
Loss at iteration 1070 : 0.002775481902062893
Loss at iteration 1080 : 0.0005566749605350196
Loss at iteration 1090 : 0.0013060385826975107
Loss at iteration 1100 : 0.000235800223890692
Loss at iteration 1110 : 0.00027857834356836975
Loss at iteration 1120 : 0.00015383880236186087
Loss at iteration 1130 : 0.0002869997115340084
Loss at iteration 1140 : 0.002925366163253784
Loss at iteration 1150 : 0.00023562024580314755
Loss at iteration 1160 : 0.006044268608093262
Loss at iteration 1170 : 0.0008033859194256365
Loss at iteration 1180 : 0.0012132111005485058
Loss at iteration 1190 : 0.00025980122154578567
Loss at iteration 1200 : 0.0005044061108492315
Loss at iteration 1210 : 0.0017295910511165857
Loss at iteration 1220 : 0.0002614000113680959
Loss at iteration 1230 : 0.0002966260362882167
Loss at iteration 1240 : 0.00026017019990831614
Loss at iteration 1250 : 0.004261164925992489
Loss at iteration 1260 : 4.610889300238341e-05
Loss at iteration 1270 : 0.0014224795158952475
Loss at iteration 1280 : 7.901331991888583e-05
Loss at iteration 1290 : 0.0029935899656265974
Loss at iteration 1300 : 0.0005959636764600873
Loss at iteration 1310 : 0.0039470745250582695
Loss at iteration 1320 : 0.0002745643723756075
Loss at iteration 1330 : 6.0800357459811494e-05
Loss at iteration 1340 : 0.00015136293950490654
Loss at iteration 1350 : 0.001797392382286489
Loss at iteration 1360 : 0.0002693341230042279
Loss at iteration 1370 : 0.0005624342593364418
Loss at iteration 1380 : 0.0001281341683352366
Loss at iteration 1390 : 0.003371210303157568
Loss at iteration 1400 : 0.0001054424064932391
Loss at iteration 1410 : 0.003384446958079934
Loss at iteration 1420 : 0.0008291394915431738
Loss at iteration 1430 : 0.0002996924740727991
Loss at iteration 1440 : 0.00020140441483817995
Loss at iteration 1450 : 0.00013949854474049062
Loss at iteration 1460 : 0.003172448603436351
Loss at iteration 1470 : 0.0022770727518945932
Loss at iteration 1480 : 0.0030533880926668644
Loss at iteration 1490 : 0.0002692455891519785
Loss at iteration 1500 : 0.0003412766382098198
Loss at iteration 1510 : 0.0003409702912904322
Loss at iteration 1520 : 0.0001032446525641717
Loss at iteration 1530 : 0.00011470096069388092
Loss at iteration 1540 : 0.00012106683425372466
Loss at iteration 1550 : 0.00019880366744473577
Loss at iteration 1560 : 0.0005643632612191141
Loss at iteration 1570 : 0.00047770357923582196
Loss at iteration 1580 : 0.00045095052337273955
Loss at iteration 1590 : 0.0013585812412202358
Loss at iteration 1600 : 0.00010122536332346499
Loss at iteration 1610 : 0.00011819342034868896
Loss at iteration 1620 : 0.002865966409444809
Loss at iteration 1630 : 0.0045437938533723354
Loss at iteration 1640 : 0.0009887097403407097
Loss at iteration 1650 : 0.0004010816046502441
Loss at iteration 1660 : 0.00021375220967456698
Loss at iteration 1670 : 0.0004539930378086865
Loss at iteration 1680 : 0.0004415108996909112
Loss at iteration 1690 : 0.0002152096712961793
Loss at iteration 1700 : 0.002107697306200862
Loss at iteration 1710 : 0.0004160194657742977
Loss at iteration 1720 : 0.00020299130119383335
Loss at iteration 1730 : 0.0001573022163938731
Loss at iteration 1740 : 0.00011401047959225252
Loss at iteration 1750 : 0.001035006484016776
The SSIM Value is: 0.9886579212900826
The PSNR Value is: 46.44276215221388
the epoch is: 53
Loss at iteration 10 : 0.0005474818754009902
Loss at iteration 20 : 0.0024428388569504023
Loss at iteration 30 : 0.0002799096400849521
Loss at iteration 40 : 0.0005024541751481593
Loss at iteration 50 : 0.00017883218242786825
Loss at iteration 60 : 0.0024894261732697487
Loss at iteration 70 : 0.00017666176427155733
Loss at iteration 80 : 0.00028473534621298313
Loss at iteration 90 : 6.0129495977889746e-05
Loss at iteration 100 : 0.003907833714038134
Loss at iteration 110 : 0.00013139030488673598
Loss at iteration 120 : 0.0011035322677344084
Loss at iteration 130 : 0.006693659815937281
Loss at iteration 140 : 0.0022036887239664793
Loss at iteration 150 : 0.003840514924377203
Loss at iteration 160 : 0.00010798966832226142
Loss at iteration 170 : 0.0022949057165533304
Loss at iteration 180 : 0.000721211894415319
Loss at iteration 190 : 0.0012451158836483955
Loss at iteration 200 : 0.00012991446419619024
Loss at iteration 210 : 0.0002679007884580642
Loss at iteration 220 : 0.00020380871137604117
Loss at iteration 230 : 0.0013218375388532877
Loss at iteration 240 : 0.0001467295369366184
Loss at iteration 250 : 0.0028860231395810843
Loss at iteration 260 : 0.0005275759613141418
Loss at iteration 270 : 0.0005749620031565428
Loss at iteration 280 : 0.00034202594542875886
Loss at iteration 290 : 0.0006871397490613163
Loss at iteration 300 : 0.0005571337533183396
Loss at iteration 310 : 0.0013947723200544715
Loss at iteration 320 : 0.0009357384406030178
Loss at iteration 330 : 6.0450580349424854e-05
Loss at iteration 340 : 0.0001299733412452042
Loss at iteration 350 : 0.0002942682767752558
Loss at iteration 360 : 0.0009545835200697184
Loss at iteration 370 : 0.00030699491617269814
Loss at iteration 380 : 0.0007279347628355026
Loss at iteration 390 : 0.0006456737755797803
Loss at iteration 400 : 0.0005425772978924215
Loss at iteration 410 : 0.00122148881200701
Loss at iteration 420 : 0.0001003727302304469
Loss at iteration 430 : 7.211783668026328e-05
Loss at iteration 440 : 0.0005450034514069557
Loss at iteration 450 : 0.004117011558264494
Loss at iteration 460 : 0.00023192295338958502
Loss at iteration 470 : 0.0007874965667724609
Loss at iteration 480 : 0.00255323457531631
Loss at iteration 490 : 0.0037333155050873756
Loss at iteration 500 : 0.008419780060648918
Loss at iteration 510 : 0.0009000895079225302
Loss at iteration 520 : 0.00039361458038911223
Loss at iteration 530 : 0.000197017754544504
Loss at iteration 540 : 0.0006606138776987791
Loss at iteration 550 : 0.0010687841568142176
Loss at iteration 560 : 0.000249749340582639
Loss at iteration 570 : 0.0012879109708592296
Loss at iteration 580 : 0.002261572051793337
Loss at iteration 590 : 0.00022136363259050995
Loss at iteration 600 : 0.0002763230004347861
Loss at iteration 610 : 0.0025167041458189487
Loss at iteration 620 : 0.003687809221446514
Loss at iteration 630 : 8.873207116266713e-05
Loss at iteration 640 : 0.0001196390949189663
Loss at iteration 650 : 0.0008894085185602307
Loss at iteration 660 : 0.00031499340548180044
Loss at iteration 670 : 0.0014402028173208237
Loss at iteration 680 : 0.0004689757479354739
Loss at iteration 690 : 8.984738087747246e-05
Loss at iteration 700 : 8.412864553974941e-05
Loss at iteration 710 : 6.665874389000237e-05
Loss at iteration 720 : 0.0002045518485829234
Loss at iteration 730 : 7.076581823639572e-05
Loss at iteration 740 : 0.0002243697817903012
Loss at iteration 750 : 0.0003059442387893796
Loss at iteration 760 : 0.0001618689566385001
Loss at iteration 770 : 0.0001768688962329179
Loss at iteration 780 : 5.9796857385663316e-05
Loss at iteration 790 : 0.00018394387734588236
Loss at iteration 800 : 0.00028313513030298054
Loss at iteration 810 : 0.0018985338974744081
Loss at iteration 820 : 0.00021646908135153353
Loss at iteration 830 : 0.003325662575662136
Loss at iteration 840 : 0.0001359799352940172
Loss at iteration 850 : 0.0007770001539029181
Loss at iteration 860 : 0.007103086449205875
Loss at iteration 870 : 0.0002567210467532277
Loss at iteration 880 : 6.348053284455091e-05
Loss at iteration 890 : 7.987352728378028e-05
Loss at iteration 900 : 0.00015140794857870787
Loss at iteration 910 : 0.00013949898129794747
Loss at iteration 920 : 0.00011158930283272639
Loss at iteration 930 : 0.0036320043727755547
Loss at iteration 940 : 0.00032443823874928057
Loss at iteration 950 : 6.997393938945606e-05
Loss at iteration 960 : 0.00031249813036993146
Loss at iteration 970 : 0.004289362579584122
Loss at iteration 980 : 0.0022543317172676325
Loss at iteration 990 : 0.0040325382724404335
Loss at iteration 1000 : 7.2269540396519e-05
Loss at iteration 1010 : 0.00013167566794436425
Loss at iteration 1020 : 0.00016120026702992618
Loss at iteration 1030 : 0.0005637640133500099
Loss at iteration 1040 : 0.0012464937753975391
Loss at iteration 1050 : 0.0003203317173756659
Loss at iteration 1060 : 0.001054091495461762
Loss at iteration 1070 : 0.002532007172703743
Loss at iteration 1080 : 0.00035780807957053185
Loss at iteration 1090 : 0.0002891050244215876
Loss at iteration 1100 : 0.002078278223052621
Loss at iteration 1110 : 0.0002158515271730721
Loss at iteration 1120 : 0.0006166346720419824
Loss at iteration 1130 : 0.002751461463049054
Loss at iteration 1140 : 0.00012824033910874277
Loss at iteration 1150 : 0.0001362711045658216
Loss at iteration 1160 : 0.0021688013803213835
Loss at iteration 1170 : 0.0032718211878091097
Loss at iteration 1180 : 0.0001787200744729489
Loss at iteration 1190 : 0.00039801097591407597
Loss at iteration 1200 : 0.00018788457964546978
Loss at iteration 1210 : 0.004959439858794212
Loss at iteration 1220 : 0.004175768233835697
Loss at iteration 1230 : 0.0003155031881760806
Loss at iteration 1240 : 8.252434054156765e-05
Loss at iteration 1250 : 0.002805478638038039
Loss at iteration 1260 : 6.341958942357451e-05
Loss at iteration 1270 : 0.000649847264867276
Loss at iteration 1280 : 0.0006262747338041663
Loss at iteration 1290 : 0.0015277942875400186
Loss at iteration 1300 : 0.00020894844783470035
Loss at iteration 1310 : 0.00017403239326085895
Loss at iteration 1320 : 0.0007595979259349406
Loss at iteration 1330 : 0.0009662740048952401
Loss at iteration 1340 : 0.00024113380641210824
Loss at iteration 1350 : 9.410137863596901e-05
Loss at iteration 1360 : 0.0033844185527414083
Loss at iteration 1370 : 0.00023124890867620707
Loss at iteration 1380 : 0.00021734184701927006
Loss at iteration 1390 : 0.00025684156571514904
Loss at iteration 1400 : 0.0008643897017464042
Loss at iteration 1410 : 5.1713635912165046e-05
Loss at iteration 1420 : 0.00011297383753117174
Loss at iteration 1430 : 0.00023925361165311188
Loss at iteration 1440 : 0.00023482281540054828
Loss at iteration 1450 : 0.0005178952706046402
Loss at iteration 1460 : 0.00012245128164067864
Loss at iteration 1470 : 0.002947783563286066
Loss at iteration 1480 : 0.0003791433700826019
Loss at iteration 1490 : 6.675635086139664e-05
Loss at iteration 1500 : 0.0015675303293392062
Loss at iteration 1510 : 0.0030038526747375727
Loss at iteration 1520 : 8.836170309223235e-05
Loss at iteration 1530 : 0.00030252724536694586
Loss at iteration 1540 : 0.0021489481441676617
Loss at iteration 1550 : 0.0050234259106218815
Loss at iteration 1560 : 0.0005657312576659024
Loss at iteration 1570 : 0.0009509663796052337
Loss at iteration 1580 : 0.0024811348412185907
Loss at iteration 1590 : 0.00010362327157054096
Loss at iteration 1600 : 7.748445204924792e-05
Loss at iteration 1610 : 0.0002555761020630598
Loss at iteration 1620 : 0.002979100216180086
Loss at iteration 1630 : 0.000143724144436419
Loss at iteration 1640 : 0.0021475909743458033
Loss at iteration 1650 : 9.474152466282248e-05
Loss at iteration 1660 : 0.00035131239565089345
Loss at iteration 1670 : 0.007254684343934059
Loss at iteration 1680 : 0.00027880954439751804
Loss at iteration 1690 : 0.0001473127049393952
Loss at iteration 1700 : 0.0002831594320014119
Loss at iteration 1710 : 0.002692962996661663
Loss at iteration 1720 : 0.0006410086061805487
Loss at iteration 1730 : 0.0003169103874824941
Loss at iteration 1740 : 0.0004456241149455309
Loss at iteration 1750 : 4.9242094974033535e-05
The SSIM Value is: 0.9836667294281695
The PSNR Value is: 46.32692294183807
the epoch is: 54
Loss at iteration 10 : 0.0003562364145182073
Loss at iteration 20 : 0.002331841504201293
Loss at iteration 30 : 0.0040322779677808285
Loss at iteration 40 : 0.0022468334063887596
Loss at iteration 50 : 9.37475124374032e-05
Loss at iteration 60 : 0.0006936833378858864
Loss at iteration 70 : 0.0037936067674309015
Loss at iteration 80 : 0.000573598372284323
Loss at iteration 90 : 0.0030794567428529263
Loss at iteration 100 : 8.778616029303521e-05
Loss at iteration 110 : 0.00017060455866158009
Loss at iteration 120 : 5.1311399147380143e-05
Loss at iteration 130 : 0.0009901480516418815
Loss at iteration 140 : 0.0001507305132690817
Loss at iteration 150 : 0.00045225280337035656
Loss at iteration 160 : 0.006835144478827715
Loss at iteration 170 : 0.00041204210720025003
Loss at iteration 180 : 7.226922025438398e-05
Loss at iteration 190 : 0.0002621254534460604
Loss at iteration 200 : 0.00013806551578454673
Loss at iteration 210 : 0.0008443309925496578
Loss at iteration 220 : 6.0027297877240926e-05
Loss at iteration 230 : 0.0003841420984826982
Loss at iteration 240 : 0.0001244528975803405
Loss at iteration 250 : 0.0012675096513703465
Loss at iteration 260 : 0.00020080190734006464
Loss at iteration 270 : 0.0007392835104838014
Loss at iteration 280 : 0.0002304649678990245
Loss at iteration 290 : 9.459601278649643e-05
Loss at iteration 300 : 0.0028984113596379757
Loss at iteration 310 : 0.004865971859544516
Loss at iteration 320 : 0.006966022774577141
Loss at iteration 330 : 0.00509572122246027
Loss at iteration 340 : 0.0005093629588373005
Loss at iteration 350 : 0.0033650766126811504
Loss at iteration 360 : 0.0011716920416802168
Loss at iteration 370 : 0.0039131371304392815
Loss at iteration 380 : 0.0026164762675762177
Loss at iteration 390 : 0.0013421152252703905
Loss at iteration 400 : 0.003633670974522829
Loss at iteration 410 : 0.00030805959249846637
Loss at iteration 420 : 0.00013397993461694568
Loss at iteration 430 : 0.0005179281579330564
Loss at iteration 440 : 0.005262306891381741
Loss at iteration 450 : 0.005597386509180069
Loss at iteration 460 : 0.006169551983475685
Loss at iteration 470 : 0.0025682293344289064
Loss at iteration 480 : 0.0005010135937482119
Loss at iteration 490 : 0.00020985683659091592
Loss at iteration 500 : 0.0019090167479589581
Loss at iteration 510 : 0.003375231521204114
Loss at iteration 520 : 0.0015378784155473113
Loss at iteration 530 : 0.002301742322742939
Loss at iteration 540 : 0.0005333866574801505
Loss at iteration 550 : 0.0031417147256433964
Loss at iteration 560 : 0.003945766948163509
Loss at iteration 570 : 0.0004365752683952451
Loss at iteration 580 : 9.067276550922543e-05
Loss at iteration 590 : 0.0001506580738350749
Loss at iteration 600 : 0.000686906510964036
Loss at iteration 610 : 0.001256559044122696
Loss at iteration 620 : 9.920669253915548e-05
Loss at iteration 630 : 9.589440014678985e-05
Loss at iteration 640 : 0.00039286576793529093
Loss at iteration 650 : 0.0001064275493263267
Loss at iteration 660 : 0.00010687827307265252
Loss at iteration 670 : 0.0007368127116933465
Loss at iteration 680 : 0.00015747902216389775
Loss at iteration 690 : 0.0003391467616893351
Loss at iteration 700 : 3.5538876545615494e-05
Loss at iteration 710 : 0.00011325091327307746
Loss at iteration 720 : 0.0027656452730298042
Loss at iteration 730 : 0.00034740145201794803
Loss at iteration 740 : 0.0009258758509531617
Loss at iteration 750 : 0.00017414375906810164
Loss at iteration 760 : 0.0007679591071791947
Loss at iteration 770 : 0.0007808237569406629
Loss at iteration 780 : 0.00044704857282340527
Loss at iteration 790 : 0.0009774693753570318
Loss at iteration 800 : 0.000676768715493381
Loss at iteration 810 : 0.00012409183545969427
Loss at iteration 820 : 0.0016255425289273262
Loss at iteration 830 : 0.002441468881443143
Loss at iteration 840 : 0.0003309849416837096
Loss at iteration 850 : 0.002737953793257475
Loss at iteration 860 : 0.0003163060755468905
Loss at iteration 870 : 0.003896716982126236
Loss at iteration 880 : 0.0015293147880584002
Loss at iteration 890 : 0.005148527678102255
Loss at iteration 900 : 0.0006276293424889445
Loss at iteration 910 : 0.0001330515369772911
Loss at iteration 920 : 0.00043829710921272635
Loss at iteration 930 : 0.0012382151326164603
Loss at iteration 940 : 0.00012006175529677421
Loss at iteration 950 : 0.00013686646707355976
Loss at iteration 960 : 0.0004991148016415536
Loss at iteration 970 : 0.00012437900295481086
Loss at iteration 980 : 0.00014655747509095818
Loss at iteration 990 : 0.0007077057380229235
Loss at iteration 1000 : 0.0029426533728837967
Loss at iteration 1010 : 0.0011370741995051503
Loss at iteration 1020 : 0.0002548394841141999
Loss at iteration 1030 : 0.0058848075568675995
Loss at iteration 1040 : 0.0007610986358486116
Loss at iteration 1050 : 0.00019463809439912438
Loss at iteration 1060 : 0.00047291774535551667
Loss at iteration 1070 : 0.0010991143062710762
Loss at iteration 1080 : 0.0006312370533123612
Loss at iteration 1090 : 0.000547597068361938
Loss at iteration 1100 : 0.0006021301378495991
Loss at iteration 1110 : 0.0005308746476657689
Loss at iteration 1120 : 0.0001763752952683717
Loss at iteration 1130 : 0.00015424180310219526
Loss at iteration 1140 : 0.00011542749416548759
Loss at iteration 1150 : 0.0028686486184597015
Loss at iteration 1160 : 6.571884296135977e-05
Loss at iteration 1170 : 0.0006578924367204309
Loss at iteration 1180 : 0.00014216818090062588
Loss at iteration 1190 : 6.509315426228568e-05
Loss at iteration 1200 : 0.0009057411225512624
Loss at iteration 1210 : 0.0014951679622754455
Loss at iteration 1220 : 0.002001133281737566
Loss at iteration 1230 : 0.00020992473582737148
Loss at iteration 1240 : 0.0008705852669663727
Loss at iteration 1250 : 0.0003133903373964131
Loss at iteration 1260 : 0.00028353690868243575
Loss at iteration 1270 : 0.0003752889751922339
Loss at iteration 1280 : 0.000406680628657341
Loss at iteration 1290 : 0.00013821336324326694
Loss at iteration 1300 : 0.0003063076874241233
Loss at iteration 1310 : 0.0006484674522653222
Loss at iteration 1320 : 0.00021822100097779185
Loss at iteration 1330 : 0.0004061780637130141
Loss at iteration 1340 : 0.00026172486832365394
Loss at iteration 1350 : 0.0004104101099073887
Loss at iteration 1360 : 0.0005836551426909864
Loss at iteration 1370 : 0.000324193766573444
Loss at iteration 1380 : 0.0001344000775134191
Loss at iteration 1390 : 9.168083488475531e-05
Loss at iteration 1400 : 0.00021261387155391276
Loss at iteration 1410 : 0.0015127426013350487
Loss at iteration 1420 : 0.00026293410337530077
Loss at iteration 1430 : 0.0031834463588893414
Loss at iteration 1440 : 8.267527300631627e-05
Loss at iteration 1450 : 0.000820905901491642
Loss at iteration 1460 : 0.0006996179581619799
Loss at iteration 1470 : 0.00021953575196675956
Loss at iteration 1480 : 0.005857676267623901
Loss at iteration 1490 : 0.00018160718900617212
Loss at iteration 1500 : 0.0012868896592408419
Loss at iteration 1510 : 0.00024197061429731548
Loss at iteration 1520 : 9.491721721133217e-05
Loss at iteration 1530 : 0.00017587999172974378
Loss at iteration 1540 : 8.534126391168684e-05
Loss at iteration 1550 : 0.00021702390222344548
Loss at iteration 1560 : 8.510277257300913e-05
Loss at iteration 1570 : 0.00029385369271039963
Loss at iteration 1580 : 0.00017036491772159934
Loss at iteration 1590 : 2.4449193006148562e-05
Loss at iteration 1600 : 0.0018932868260890245
Loss at iteration 1610 : 8.512431668350473e-05
Loss at iteration 1620 : 0.0009298712247982621
Loss at iteration 1630 : 0.004412200301885605
Loss at iteration 1640 : 0.0007574636256322265
Loss at iteration 1650 : 0.0034444378688931465
Loss at iteration 1660 : 0.0012317080982029438
Loss at iteration 1670 : 0.0035984176211059093
Loss at iteration 1680 : 0.0027112397365272045
Loss at iteration 1690 : 6.037135608494282e-05
Loss at iteration 1700 : 0.004055295139551163
Loss at iteration 1710 : 0.002720721997320652
Loss at iteration 1720 : 0.0008066279697231948
Loss at iteration 1730 : 0.001410421566106379
Loss at iteration 1740 : 0.00034448562655597925
Loss at iteration 1750 : 0.0018900129944086075
The SSIM Value is: 0.9877625359837704
The PSNR Value is: 46.2538476263374
the epoch is: 55
Loss at iteration 10 : 0.00021427954197861254
Loss at iteration 20 : 0.0002264091745018959
Loss at iteration 30 : 0.0006235269247554243
Loss at iteration 40 : 0.0036623370833694935
Loss at iteration 50 : 0.0001551326859043911
Loss at iteration 60 : 0.00014100593398325145
Loss at iteration 70 : 0.00018311041640117764
Loss at iteration 80 : 0.00013572501484304667
Loss at iteration 90 : 0.00016156455967575312
Loss at iteration 100 : 0.0075009544380009174
Loss at iteration 110 : 0.00011393215390853584
Loss at iteration 120 : 0.00016943919763434678
Loss at iteration 130 : 0.0008449367014691234
Loss at iteration 140 : 0.0001939880894497037
Loss at iteration 150 : 0.00015433208318427205
Loss at iteration 160 : 0.0004984588595107198
Loss at iteration 170 : 0.0003074151463806629
Loss at iteration 180 : 0.004114601761102676
Loss at iteration 190 : 7.271559297805652e-05
Loss at iteration 200 : 0.00018075897241942585
Loss at iteration 210 : 0.00026873889146372676
Loss at iteration 220 : 0.0003912609536200762
Loss at iteration 230 : 0.0009103497141040862
Loss at iteration 240 : 0.0019129246938973665
Loss at iteration 250 : 0.0005038455128669739
Loss at iteration 260 : 5.002802572562359e-05
Loss at iteration 270 : 0.00031871022656559944
Loss at iteration 280 : 8.981445716926828e-05
Loss at iteration 290 : 0.00019840143795590848
Loss at iteration 300 : 0.005708429962396622
Loss at iteration 310 : 0.00022451451513916254
Loss at iteration 320 : 0.0001323239121120423
Loss at iteration 330 : 0.00018907951016444713
Loss at iteration 340 : 0.004665963817387819
Loss at iteration 350 : 0.0005416179774329066
Loss at iteration 360 : 0.0001379189343424514
Loss at iteration 370 : 0.00020400769426487386
Loss at iteration 380 : 0.001453193835914135
Loss at iteration 390 : 0.0014885093551129103
Loss at iteration 400 : 0.0015080847078934312
Loss at iteration 410 : 0.0004696195828728378
Loss at iteration 420 : 0.0012786276638507843
Loss at iteration 430 : 0.0005156948463991284
Loss at iteration 440 : 0.0010064288508147001
Loss at iteration 450 : 6.707786087645218e-05
Loss at iteration 460 : 8.750209235586226e-05
Loss at iteration 470 : 8.634178811917081e-05
Loss at iteration 480 : 0.00010183192352997139
Loss at iteration 490 : 0.0003244334948249161
Loss at iteration 500 : 9.956212306860834e-05
Loss at iteration 510 : 0.004132462199777365
Loss at iteration 520 : 0.001543272752314806
Loss at iteration 530 : 0.001221950864419341
Loss at iteration 540 : 0.0018273286987096071
Loss at iteration 550 : 0.0002618903818074614
Loss at iteration 560 : 0.0001361616887152195
Loss at iteration 570 : 0.00018789173918776214
Loss at iteration 580 : 6.310307799139991e-05
Loss at iteration 590 : 0.002229207195341587
Loss at iteration 600 : 0.0003534702118486166
Loss at iteration 610 : 0.0005560895660892129
Loss at iteration 620 : 0.00019051968411076814
Loss at iteration 630 : 0.0039667184464633465
Loss at iteration 640 : 0.00010410395043436438
Loss at iteration 650 : 0.0007172629120759666
Loss at iteration 660 : 0.0025811248924583197
Loss at iteration 670 : 0.000627320259809494
Loss at iteration 680 : 0.00029811926651746035
Loss at iteration 690 : 0.0002449406892992556
Loss at iteration 700 : 0.0003652694867923856
Loss at iteration 710 : 0.000252337078563869
Loss at iteration 720 : 0.0002503040013834834
Loss at iteration 730 : 0.0015141970943659544
Loss at iteration 740 : 0.00037055302527733147
Loss at iteration 750 : 0.004646187648177147
Loss at iteration 760 : 0.001631211256608367
Loss at iteration 770 : 9.323281119577587e-05
Loss at iteration 780 : 0.00013186282012611628
Loss at iteration 790 : 0.0010792366228997707
Loss at iteration 800 : 0.0005198175203986466
Loss at iteration 810 : 0.0003858658601529896
Loss at iteration 820 : 0.0008044312126003206
Loss at iteration 830 : 0.00047930009895935655
Loss at iteration 840 : 0.0030568079091608524
Loss at iteration 850 : 9.30633905227296e-05
Loss at iteration 860 : 0.0015597381861880422
Loss at iteration 870 : 0.00011443185212556273
Loss at iteration 880 : 0.0011457354994490743
Loss at iteration 890 : 0.002446461468935013
Loss at iteration 900 : 0.0019247723976150155
Loss at iteration 910 : 0.00046688999282196164
Loss at iteration 920 : 0.00024841781123541296
Loss at iteration 930 : 0.0016787722706794739
Loss at iteration 940 : 0.0006579386536031961
Loss at iteration 950 : 0.00014810566790401936
Loss at iteration 960 : 0.0005331635475158691
Loss at iteration 970 : 0.0011530646588653326
Loss at iteration 980 : 0.0030422371346503496
Loss at iteration 990 : 0.0002269450924359262
Loss at iteration 1000 : 6.813999789301306e-05
Loss at iteration 1010 : 0.0014308937825262547
Loss at iteration 1020 : 0.00024960999144241214
Loss at iteration 1030 : 0.0007779394509270787
Loss at iteration 1040 : 0.0010058722691610456
Loss at iteration 1050 : 0.0004893986624665558
Loss at iteration 1060 : 0.006657236255705357
Loss at iteration 1070 : 0.0025199647061526775
Loss at iteration 1080 : 0.00018607257516123354
Loss at iteration 1090 : 0.00029093879857100546
Loss at iteration 1100 : 0.00013013818534091115
Loss at iteration 1110 : 0.00012068435898981988
Loss at iteration 1120 : 0.0002117917756550014
Loss at iteration 1130 : 4.347075810073875e-05
Loss at iteration 1140 : 0.00015532832185272127
Loss at iteration 1150 : 0.00032788608223199844
Loss at iteration 1160 : 0.0002556055842433125
Loss at iteration 1170 : 0.000107130195829086
Loss at iteration 1180 : 0.003563431091606617
Loss at iteration 1190 : 0.00019851737306453288
Loss at iteration 1200 : 0.001244489336386323
Loss at iteration 1210 : 0.0003902287280652672
Loss at iteration 1220 : 0.0011977546382695436
Loss at iteration 1230 : 0.0010426013031974435
Loss at iteration 1240 : 0.00037545093800872564
Loss at iteration 1250 : 0.004468364175409079
Loss at iteration 1260 : 0.00040188178536482155
Loss at iteration 1270 : 0.00030805490678176284
Loss at iteration 1280 : 0.0003717073705047369
Loss at iteration 1290 : 9.278251673094928e-05
Loss at iteration 1300 : 0.0006528677185997367
Loss at iteration 1310 : 0.0013065882958471775
Loss at iteration 1320 : 0.00022138326312415302
Loss at iteration 1330 : 0.0007077914196997881
Loss at iteration 1340 : 5.1458115194691345e-05
Loss at iteration 1350 : 0.0018123677000403404
Loss at iteration 1360 : 0.00015118156443350017
Loss at iteration 1370 : 0.0003560272161848843
Loss at iteration 1380 : 7.37426380510442e-05
Loss at iteration 1390 : 0.000768269004765898
Loss at iteration 1400 : 0.004477174952626228
Loss at iteration 1410 : 0.0003233939060010016
Loss at iteration 1420 : 0.0023515126667916775
Loss at iteration 1430 : 0.0017653540708124638
Loss at iteration 1440 : 0.000431124004535377
Loss at iteration 1450 : 0.004097708035260439
Loss at iteration 1460 : 0.0005392252351157367
Loss at iteration 1470 : 0.0019406428327783942
Loss at iteration 1480 : 0.0001736320264171809
Loss at iteration 1490 : 0.0002116285904776305
Loss at iteration 1500 : 0.0038700061850249767
Loss at iteration 1510 : 0.0014138828264549375
Loss at iteration 1520 : 0.00011882514809258282
Loss at iteration 1530 : 0.0006311176693998277
Loss at iteration 1540 : 0.00021177651069592685
Loss at iteration 1550 : 0.00012567854719236493
Loss at iteration 1560 : 0.00421306025236845
Loss at iteration 1570 : 0.002962037455290556
Loss at iteration 1580 : 0.00023862964008003473
Loss at iteration 1590 : 0.0042317635379731655
Loss at iteration 1600 : 0.0002029192983172834
Loss at iteration 1610 : 0.00029323314083740115
Loss at iteration 1620 : 0.00020393026352394372
Loss at iteration 1630 : 0.0002536896208766848
Loss at iteration 1640 : 7.203486893558875e-05
Loss at iteration 1650 : 9.169307304546237e-05
Loss at iteration 1660 : 0.002532219048589468
Loss at iteration 1670 : 0.00012394037912599742
Loss at iteration 1680 : 0.0004973386530764401
Loss at iteration 1690 : 0.0005789289716631174
Loss at iteration 1700 : 0.0051063294522464275
Loss at iteration 1710 : 0.00010304142779204994
Loss at iteration 1720 : 0.006191156338900328
Loss at iteration 1730 : 0.0004912955337204039
Loss at iteration 1740 : 0.004167009610682726
Loss at iteration 1750 : 7.392770930891857e-05
The SSIM Value is: 0.9830461311839226
The PSNR Value is: 46.5238585997258
the epoch is: 56
Loss at iteration 10 : 0.0011378508061170578
Loss at iteration 20 : 0.00036731557338498533
Loss at iteration 30 : 0.0008573858649469912
Loss at iteration 40 : 0.00032832406577654183
Loss at iteration 50 : 0.0002829070726875216
Loss at iteration 60 : 0.00034012284595519304
Loss at iteration 70 : 0.00018623174401000142
Loss at iteration 80 : 0.0001456301542930305
Loss at iteration 90 : 0.00039515557000413537
Loss at iteration 100 : 0.0008767588878981769
Loss at iteration 110 : 0.0023510465398430824
Loss at iteration 120 : 0.00015502414316870272
Loss at iteration 130 : 0.0028274785727262497
Loss at iteration 140 : 0.0003288231964688748
Loss at iteration 150 : 8.527966565452516e-05
Loss at iteration 160 : 0.0015210125129669905
Loss at iteration 170 : 9.123269410338253e-05
Loss at iteration 180 : 0.0017311283154413104
Loss at iteration 190 : 0.0003101633337792009
Loss at iteration 200 : 3.813598596025258e-05
Loss at iteration 210 : 0.002706297440454364
Loss at iteration 220 : 0.0008966692257672548
Loss at iteration 230 : 0.0006144515937194228
Loss at iteration 240 : 0.0066194841638207436
Loss at iteration 250 : 0.0006199749186635017
Loss at iteration 260 : 0.00027373299235478044
Loss at iteration 270 : 0.0006778583046980202
Loss at iteration 280 : 0.00023340361076407135
Loss at iteration 290 : 0.0004985254490748048
Loss at iteration 300 : 0.000144859790452756
Loss at iteration 310 : 0.0007049929117783904
Loss at iteration 320 : 0.00020482417312450707
Loss at iteration 330 : 0.00559255899861455
Loss at iteration 340 : 0.00029540073592215776
Loss at iteration 350 : 0.0002934281073976308
Loss at iteration 360 : 6.308993033599108e-05
Loss at iteration 370 : 0.0007659968687221408
Loss at iteration 380 : 0.00044623526628129184
Loss at iteration 390 : 0.0001889326813397929
Loss at iteration 400 : 0.0001248652843059972
Loss at iteration 410 : 0.00041675008833408356
Loss at iteration 420 : 0.001550020882859826
Loss at iteration 430 : 0.0005331929423846304
Loss at iteration 440 : 9.505847992841154e-05
Loss at iteration 450 : 0.0002524397859815508
Loss at iteration 460 : 0.00026584521401673555
Loss at iteration 470 : 0.002262779278680682
Loss at iteration 480 : 0.0005103733856230974
Loss at iteration 490 : 0.0011515612713992596
Loss at iteration 500 : 4.956980046699755e-05
Loss at iteration 510 : 0.003843900514766574
Loss at iteration 520 : 0.00027993801631964743
Loss at iteration 530 : 0.004006612580269575
Loss at iteration 540 : 0.0004904460511170328
Loss at iteration 550 : 0.00031314941588789225
Loss at iteration 560 : 0.00031544495141133666
Loss at iteration 570 : 0.004374267999082804
Loss at iteration 580 : 0.00029590437770821154
Loss at iteration 590 : 0.00014447563444264233
Loss at iteration 600 : 0.0002811530139297247
Loss at iteration 610 : 0.002648985479027033
Loss at iteration 620 : 0.0004345551715232432
Loss at iteration 630 : 0.00017567124450579286
Loss at iteration 640 : 0.0017889232840389013
Loss at iteration 650 : 0.0006777753005735576
Loss at iteration 660 : 0.0001358049048576504
Loss at iteration 670 : 0.0001366690848954022
Loss at iteration 680 : 0.0001545736304251477
Loss at iteration 690 : 0.0015223458176478744
Loss at iteration 700 : 0.00014627935888711363
Loss at iteration 710 : 0.0017042793333530426
Loss at iteration 720 : 9.804886940401047e-05
Loss at iteration 730 : 0.0008225264609791338
Loss at iteration 740 : 7.214861398097128e-05
Loss at iteration 750 : 0.0018830141052603722
Loss at iteration 760 : 0.00014432150055654347
Loss at iteration 770 : 0.0037914214190095663
Loss at iteration 780 : 0.0003586453967727721
Loss at iteration 790 : 0.00022464692301582545
Loss at iteration 800 : 0.0001301569282077253
Loss at iteration 810 : 0.0021209223195910454
Loss at iteration 820 : 0.000133560984977521
Loss at iteration 830 : 0.006277658045291901
Loss at iteration 840 : 0.00021000715787522495
Loss at iteration 850 : 0.00016074968152679503
Loss at iteration 860 : 0.0009332953486591578
Loss at iteration 870 : 0.0001273619564017281
Loss at iteration 880 : 0.0003815035452134907
Loss at iteration 890 : 0.0004334092664066702
Loss at iteration 900 : 4.716185503639281e-05
Loss at iteration 910 : 0.00022306168102659285
Loss at iteration 920 : 0.00014170272334013134
Loss at iteration 930 : 0.004192681051790714
Loss at iteration 940 : 8.422187966061756e-05
Loss at iteration 950 : 0.00011431048187660053
Loss at iteration 960 : 0.0004343166947364807
Loss at iteration 970 : 0.0005471792537719011
Loss at iteration 980 : 0.0002564730530139059
Loss at iteration 990 : 0.0004724302561953664
Loss at iteration 1000 : 0.00031121532083489
Loss at iteration 1010 : 0.00011676522990455851
Loss at iteration 1020 : 0.0009042973397299647
Loss at iteration 1030 : 0.00010802022006828338
Loss at iteration 1040 : 0.0044289338402450085
Loss at iteration 1050 : 0.00026402706862427294
Loss at iteration 1060 : 0.00025172921596094966
Loss at iteration 1070 : 0.003187027759850025
Loss at iteration 1080 : 0.0001050840801326558
Loss at iteration 1090 : 0.0011449112789705396
Loss at iteration 1100 : 0.001491163158789277
Loss at iteration 1110 : 0.00023581896675750613
Loss at iteration 1120 : 5.3852916607866064e-05
Loss at iteration 1130 : 0.00023370207054540515
Loss at iteration 1140 : 0.00011405762779759243
Loss at iteration 1150 : 0.0005282501806505024
Loss at iteration 1160 : 0.00036234877188690007
Loss at iteration 1170 : 0.00014299331814981997
Loss at iteration 1180 : 5.520721242646687e-05
Loss at iteration 1190 : 0.0015740711241960526
Loss at iteration 1200 : 0.0010592505568638444
Loss at iteration 1210 : 0.0003841852303594351
Loss at iteration 1220 : 9.849372145254165e-05
Loss at iteration 1230 : 0.0018189806723967195
Loss at iteration 1240 : 0.00022133074526209384
Loss at iteration 1250 : 0.0005318822804838419
Loss at iteration 1260 : 0.0017180969007313251
Loss at iteration 1270 : 0.001339460490271449
Loss at iteration 1280 : 0.0004760411975439638
Loss at iteration 1290 : 0.002345130778849125
Loss at iteration 1300 : 8.208584040403366e-05
Loss at iteration 1310 : 9.661570948082954e-05
Loss at iteration 1320 : 0.0060368487611413
Loss at iteration 1330 : 0.002918262965977192
Loss at iteration 1340 : 0.000462614290881902
Loss at iteration 1350 : 0.003042025025933981
Loss at iteration 1360 : 0.0014294020365923643
Loss at iteration 1370 : 0.0001311112573603168
Loss at iteration 1380 : 0.0019824220798909664
Loss at iteration 1390 : 0.0004150248714722693
Loss at iteration 1400 : 0.0008528106845915318
Loss at iteration 1410 : 0.0003448280622251332
Loss at iteration 1420 : 0.0009627645486034453
Loss at iteration 1430 : 0.00015506685303989798
Loss at iteration 1440 : 0.00016335747204720974
Loss at iteration 1450 : 0.0015594615833833814
Loss at iteration 1460 : 0.0038658296689391136
Loss at iteration 1470 : 0.0006724769482389092
Loss at iteration 1480 : 0.0030942659359425306
Loss at iteration 1490 : 0.00011291421833448112
Loss at iteration 1500 : 0.0003354845684953034
Loss at iteration 1510 : 0.0005784215172752738
Loss at iteration 1520 : 0.0004256489919498563
Loss at iteration 1530 : 0.001295133144594729
Loss at iteration 1540 : 0.0025134182069450617
Loss at iteration 1550 : 0.0009117085719481111
Loss at iteration 1560 : 0.0030823880806565285
Loss at iteration 1570 : 6.358518294291571e-05
Loss at iteration 1580 : 0.0003525538195390254
Loss at iteration 1590 : 0.003224555402994156
Loss at iteration 1600 : 0.00025882545742206275
Loss at iteration 1610 : 0.0001939740322995931
Loss at iteration 1620 : 0.00017670649685896933
Loss at iteration 1630 : 0.000135880516609177
Loss at iteration 1640 : 0.0010650291806086898
Loss at iteration 1650 : 0.00033267520484514534
Loss at iteration 1660 : 0.0006881699664518237
Loss at iteration 1670 : 0.0038200877606868744
Loss at iteration 1680 : 0.0015572869451716542
Loss at iteration 1690 : 0.00011459294182714075
Loss at iteration 1700 : 3.7785430322401226e-05
Loss at iteration 1710 : 0.00023250101367011666
Loss at iteration 1720 : 0.0012806078884750605
Loss at iteration 1730 : 0.00017739564646035433
Loss at iteration 1740 : 0.00013690436026081443
Loss at iteration 1750 : 0.004568386357277632
The SSIM Value is: 0.9889370578501193
The PSNR Value is: 46.046703357528486
the epoch is: 57
Loss at iteration 10 : 0.003943873569369316
Loss at iteration 20 : 0.00023071102623362094
Loss at iteration 30 : 0.00037535419687628746
Loss at iteration 40 : 0.0005584894679486752
Loss at iteration 50 : 0.0002506207674741745
Loss at iteration 60 : 0.0009211262804456055
Loss at iteration 70 : 0.0006789936451241374
Loss at iteration 80 : 4.62399038951844e-05
Loss at iteration 90 : 9.994937136070803e-05
Loss at iteration 100 : 0.00071973807644099
Loss at iteration 110 : 0.0007148826261982322
Loss at iteration 120 : 0.00033453930518589914
Loss at iteration 130 : 0.0009189009433612227
Loss at iteration 140 : 0.0006328552262857556
Loss at iteration 150 : 0.0004936660407111049
Loss at iteration 160 : 0.0032204599119722843
Loss at iteration 170 : 0.0004407532687764615
Loss at iteration 180 : 0.0024618899915367365
Loss at iteration 190 : 0.006651321426033974
Loss at iteration 200 : 0.00026205391623079777
Loss at iteration 210 : 0.004813734441995621
Loss at iteration 220 : 0.0007153424667194486
Loss at iteration 230 : 0.003727119415998459
Loss at iteration 240 : 0.00010533613385632634
Loss at iteration 250 : 0.0009331017499789596
Loss at iteration 260 : 6.70819281367585e-05
Loss at iteration 270 : 0.0029722964391112328
Loss at iteration 280 : 8.827958663459867e-05
Loss at iteration 290 : 0.0033600807655602694
Loss at iteration 300 : 0.001245038816705346
Loss at iteration 310 : 0.003808381035923958
Loss at iteration 320 : 0.0003822319267783314
Loss at iteration 330 : 6.41751175862737e-05
Loss at iteration 340 : 0.0025939266197383404
Loss at iteration 350 : 0.00019436728325672448
Loss at iteration 360 : 0.00013832967670168728
Loss at iteration 370 : 0.002211272483691573
Loss at iteration 380 : 0.0001477785117458552
Loss at iteration 390 : 0.00021106186613906175
Loss at iteration 400 : 0.0006560679757967591
Loss at iteration 410 : 0.0030430902261286974
Loss at iteration 420 : 6.43049061181955e-05
Loss at iteration 430 : 0.00029707769863307476
Loss at iteration 440 : 0.0005400206428021193
Loss at iteration 450 : 0.00013274705270305276
Loss at iteration 460 : 0.00021054543321952224
Loss at iteration 470 : 0.0015841502463445067
Loss at iteration 480 : 0.002590533345937729
Loss at iteration 490 : 8.376165351364762e-05
Loss at iteration 500 : 0.0002589788055047393
Loss at iteration 510 : 0.00011507637827889994
Loss at iteration 520 : 6.939779268577695e-05
Loss at iteration 530 : 0.0003195325843989849
Loss at iteration 540 : 0.0014305190416052938
Loss at iteration 550 : 0.0001004219739115797
Loss at iteration 560 : 0.003946272190660238
Loss at iteration 570 : 0.0004288661584723741
Loss at iteration 580 : 0.0017450200393795967
Loss at iteration 590 : 0.00010393682168796659
Loss at iteration 600 : 0.0007221739506348968
Loss at iteration 610 : 0.004171039443463087
Loss at iteration 620 : 0.0001535607734695077
Loss at iteration 630 : 0.0001936331536853686
Loss at iteration 640 : 0.002412753878161311
Loss at iteration 650 : 0.003659055335447192
Loss at iteration 660 : 0.0001292964443564415
Loss at iteration 670 : 0.0010869032703340054
Loss at iteration 680 : 0.0014123751316219568
Loss at iteration 690 : 0.00020643393509089947
Loss at iteration 700 : 0.0026786564849317074
Loss at iteration 710 : 0.00025572237791493535
Loss at iteration 720 : 0.000806499389000237
Loss at iteration 730 : 0.0015105450293049216
Loss at iteration 740 : 0.00016538290947210044
Loss at iteration 750 : 0.0002489977050572634
Loss at iteration 760 : 0.00011240530875511467
Loss at iteration 770 : 0.0012502575991675258
Loss at iteration 780 : 0.0005860822275280952
Loss at iteration 790 : 0.0001621408446226269
Loss at iteration 800 : 0.0007493615848943591
Loss at iteration 810 : 9.67863088590093e-05
Loss at iteration 820 : 0.0009970649844035506
Loss at iteration 830 : 0.0001588893064763397
Loss at iteration 840 : 0.0010552641469985247
Loss at iteration 850 : 0.0002183145988965407
Loss at iteration 860 : 6.387395842466503e-05
Loss at iteration 870 : 0.00016759379650466144
Loss at iteration 880 : 5.087556564831175e-05
Loss at iteration 890 : 0.0037654549814760685
Loss at iteration 900 : 0.000565282825846225
Loss at iteration 910 : 0.00019877517479471862
Loss at iteration 920 : 0.00021595491853076965
Loss at iteration 930 : 6.984988431213424e-05
Loss at iteration 940 : 0.00010351710807299241
Loss at iteration 950 : 0.005823144689202309
Loss at iteration 960 : 0.00036030772025696933
Loss at iteration 970 : 0.0012576759327203035
Loss at iteration 980 : 0.005087410099804401
Loss at iteration 990 : 0.004463924560695887
Loss at iteration 1000 : 0.00041297971620224416
Loss at iteration 1010 : 7.103907410055399e-05
Loss at iteration 1020 : 0.000211266364203766
Loss at iteration 1030 : 0.00045654288260266185
Loss at iteration 1040 : 0.0005626764032058418
Loss at iteration 1050 : 0.0037319182883948088
Loss at iteration 1060 : 0.0001474400341976434
Loss at iteration 1070 : 0.0022593114990741014
Loss at iteration 1080 : 6.719520752085373e-05
Loss at iteration 1090 : 0.0005663780029863119
Loss at iteration 1100 : 5.528386463993229e-05
Loss at iteration 1110 : 0.00013088551349937916
Loss at iteration 1120 : 0.00011689939128700644
Loss at iteration 1130 : 0.0003876088303513825
Loss at iteration 1140 : 0.0012395933736115694
Loss at iteration 1150 : 0.00039974384708330035
Loss at iteration 1160 : 0.00014038692461326718
Loss at iteration 1170 : 0.00037098032771609724
Loss at iteration 1180 : 7.431695848936215e-05
Loss at iteration 1190 : 0.002682472113519907
Loss at iteration 1200 : 0.00013020462938584387
Loss at iteration 1210 : 0.0005121668800711632
Loss at iteration 1220 : 0.00022999345674179494
Loss at iteration 1230 : 0.004751542583107948
Loss at iteration 1240 : 0.003717981744557619
Loss at iteration 1250 : 0.004436943680047989
Loss at iteration 1260 : 0.0006588711403310299
Loss at iteration 1270 : 0.0007895518210716546
Loss at iteration 1280 : 0.0016697220271453261
Loss at iteration 1290 : 0.0019316449761390686
Loss at iteration 1300 : 9.450556535739452e-05
Loss at iteration 1310 : 0.0001484725362388417
Loss at iteration 1320 : 0.0002876920043490827
Loss at iteration 1330 : 0.0002423188416287303
Loss at iteration 1340 : 0.0005648594233207405
Loss at iteration 1350 : 0.0044225724413990974
Loss at iteration 1360 : 0.0022207763977348804
Loss at iteration 1370 : 9.630793647374958e-05
Loss at iteration 1380 : 8.505369623890147e-05
Loss at iteration 1390 : 0.00017942697741091251
Loss at iteration 1400 : 4.89133526571095e-05
Loss at iteration 1410 : 0.0005769229610450566
Loss at iteration 1420 : 0.0004628305905498564
Loss at iteration 1430 : 0.0005199280567467213
Loss at iteration 1440 : 0.004824297968298197
Loss at iteration 1450 : 0.0036865021102130413
Loss at iteration 1460 : 0.0015923918690532446
Loss at iteration 1470 : 0.0008333065779879689
Loss at iteration 1480 : 0.0016018918249756098
Loss at iteration 1490 : 0.0011753570288419724
Loss at iteration 1500 : 0.0007281888392753899
Loss at iteration 1510 : 0.0003190978313796222
Loss at iteration 1520 : 0.0003975095460191369
Loss at iteration 1530 : 0.0005275618168525398
Loss at iteration 1540 : 9.604446677258238e-05
Loss at iteration 1550 : 9.378847607877105e-05
Loss at iteration 1560 : 0.0013146622804924846
Loss at iteration 1570 : 0.00395434582605958
Loss at iteration 1580 : 4.245015588821843e-05
Loss at iteration 1590 : 0.0076986136846244335
Loss at iteration 1600 : 0.0004788413061760366
Loss at iteration 1610 : 0.00015350223111454397
Loss at iteration 1620 : 0.00026565074222162366
Loss at iteration 1630 : 0.0008556543616577983
Loss at iteration 1640 : 0.00010947020200546831
Loss at iteration 1650 : 6.599188782274723e-05
Loss at iteration 1660 : 0.00020734337158501148
Loss at iteration 1670 : 6.924636545591056e-05
Loss at iteration 1680 : 0.00033859265386126935
Loss at iteration 1690 : 0.0004167727893218398
Loss at iteration 1700 : 0.0002978873671963811
Loss at iteration 1710 : 0.00010338390711694956
Loss at iteration 1720 : 8.324447844643146e-05
Loss at iteration 1730 : 9.252468589693308e-05
Loss at iteration 1740 : 0.00037230050656944513
Loss at iteration 1750 : 0.0002950797788798809
The SSIM Value is: 0.9838156832734919
The PSNR Value is: 46.23164917613966
the epoch is: 58
Loss at iteration 10 : 0.0007388966623693705
Loss at iteration 20 : 0.00041214440716430545
Loss at iteration 30 : 0.003217762801796198
Loss at iteration 40 : 0.0007585251587443054
Loss at iteration 50 : 0.00039116761763580143
Loss at iteration 60 : 0.0004684628511313349
Loss at iteration 70 : 0.0005755040911026299
Loss at iteration 80 : 0.0021538003347814083
Loss at iteration 90 : 0.0004571476601995528
Loss at iteration 100 : 0.0006901902379468083
Loss at iteration 110 : 0.0003388995537534356
Loss at iteration 120 : 0.0010213165078312159
Loss at iteration 130 : 7.829211972421035e-05
Loss at iteration 140 : 0.00016601005336269736
Loss at iteration 150 : 0.0005875925999134779
Loss at iteration 160 : 0.00016574884648434818
Loss at iteration 170 : 0.0014297314919531345
Loss at iteration 180 : 0.0006629378185607493
Loss at iteration 190 : 0.00015027566405478865
Loss at iteration 200 : 0.0009666249970905483
Loss at iteration 210 : 0.00027601883630268276
Loss at iteration 220 : 0.00015136355068534613
Loss at iteration 230 : 0.00044309109216555953
Loss at iteration 240 : 0.005609631072729826
Loss at iteration 250 : 0.00011521741544129327
Loss at iteration 260 : 0.0018379318062216043
Loss at iteration 270 : 3.988383832620457e-05
Loss at iteration 280 : 0.0025864173658192158
Loss at iteration 290 : 4.7131597966654226e-05
Loss at iteration 300 : 0.00013118688366375864
Loss at iteration 310 : 0.0028608497232198715
Loss at iteration 320 : 0.00027180256438441575
Loss at iteration 330 : 0.0008581246365793049
Loss at iteration 340 : 0.0002999658463522792
Loss at iteration 350 : 0.004078138619661331
Loss at iteration 360 : 0.00010847504017874599
Loss at iteration 370 : 0.001320189330726862
Loss at iteration 380 : 0.0007115518092177808
Loss at iteration 390 : 0.0012465491890907288
Loss at iteration 400 : 0.0008464603452011943
Loss at iteration 410 : 0.00017492801998741925
Loss at iteration 420 : 0.0035997501108795404
Loss at iteration 430 : 0.0014891645405441523
Loss at iteration 440 : 0.0010855955770239234
Loss at iteration 450 : 0.00013833577395416796
Loss at iteration 460 : 0.00017085585568565875
Loss at iteration 470 : 0.0019156394992023706
Loss at iteration 480 : 0.0003253387985751033
Loss at iteration 490 : 0.00015751687169540673
Loss at iteration 500 : 0.0001883906516013667
Loss at iteration 510 : 0.00020895528723485768
Loss at iteration 520 : 0.0006591388373635709
Loss at iteration 530 : 0.0009617793839424849
Loss at iteration 540 : 0.001487761503085494
Loss at iteration 550 : 0.00011033351620426401
Loss at iteration 560 : 0.0005187796195968986
Loss at iteration 570 : 0.0004028230323456228
Loss at iteration 580 : 0.0003267230640631169
Loss at iteration 590 : 0.0012074956903234124
Loss at iteration 600 : 0.0016719880513846874
Loss at iteration 610 : 0.0030392403714358807
Loss at iteration 620 : 0.002150828018784523
Loss at iteration 630 : 0.00031753344228491187
Loss at iteration 640 : 0.0007758014835417271
Loss at iteration 650 : 0.0001411067642038688
Loss at iteration 660 : 0.001195473363623023
Loss at iteration 670 : 0.0004538305220194161
Loss at iteration 680 : 0.00031312316423282027
Loss at iteration 690 : 8.676317520439625e-05
Loss at iteration 700 : 0.002708158455789089
Loss at iteration 710 : 0.00019332086958456784
Loss at iteration 720 : 6.947201472939923e-05
Loss at iteration 730 : 0.0011811464792117476
Loss at iteration 740 : 0.0009055502014234662
Loss at iteration 750 : 0.00025350175565108657
Loss at iteration 760 : 0.000686320592649281
Loss at iteration 770 : 0.0003033597313333303
Loss at iteration 780 : 0.00036976332194171846
Loss at iteration 790 : 0.00015952653484418988
Loss at iteration 800 : 0.00011324807564960793
Loss at iteration 810 : 0.0004948187852278352
Loss at iteration 820 : 5.8026656915899366e-05
Loss at iteration 830 : 0.00035828317049890757
Loss at iteration 840 : 0.0013581563252955675
Loss at iteration 850 : 0.000872414035256952
Loss at iteration 860 : 0.003229103982448578
Loss at iteration 870 : 0.0001859405019786209
Loss at iteration 880 : 0.0008771062712185085
Loss at iteration 890 : 0.0003528188681229949
Loss at iteration 900 : 0.00023063772823661566
Loss at iteration 910 : 8.847584831528366e-05
Loss at iteration 920 : 0.0006607039249502122
Loss at iteration 930 : 0.0010794500121846795
Loss at iteration 940 : 0.00038597307866439223
Loss at iteration 950 : 0.0031046271324157715
Loss at iteration 960 : 0.0020022690296173096
Loss at iteration 970 : 0.0037411171942949295
Loss at iteration 980 : 0.00010222988203167915
Loss at iteration 990 : 0.0005199497099965811
Loss at iteration 1000 : 0.00015170952246990055
Loss at iteration 1010 : 0.0004982867976650596
Loss at iteration 1020 : 0.0016670196782797575
Loss at iteration 1030 : 0.006441510748118162
Loss at iteration 1040 : 8.456864452455193e-05
Loss at iteration 1050 : 0.00040693877963349223
Loss at iteration 1060 : 0.0001802916667656973
Loss at iteration 1070 : 0.0003029645304195583
Loss at iteration 1080 : 0.001881426782347262
Loss at iteration 1090 : 0.001603276003152132
Loss at iteration 1100 : 0.0005153347738087177
Loss at iteration 1110 : 0.00014479536912404
Loss at iteration 1120 : 0.0003271723398938775
Loss at iteration 1130 : 0.00014875628403387964
Loss at iteration 1140 : 0.0018699881620705128
Loss at iteration 1150 : 0.000775983149651438
Loss at iteration 1160 : 0.00010876703163376078
Loss at iteration 1170 : 0.002449560211971402
Loss at iteration 1180 : 0.0004361096944194287
Loss at iteration 1190 : 0.001582740107551217
Loss at iteration 1200 : 0.00048527162289246917
Loss at iteration 1210 : 0.0038994126953184605
Loss at iteration 1220 : 0.0018667364493012428
Loss at iteration 1230 : 0.00029975755023770034
Loss at iteration 1240 : 0.00022075683227740228
Loss at iteration 1250 : 0.0008497872622683644
Loss at iteration 1260 : 5.730916018364951e-05
Loss at iteration 1270 : 0.0015615224838256836
Loss at iteration 1280 : 0.005903645418584347
Loss at iteration 1290 : 0.0006447323248721659
Loss at iteration 1300 : 0.0012586971279233694
Loss at iteration 1310 : 0.0007612149347551167
Loss at iteration 1320 : 0.0004128961300011724
Loss at iteration 1330 : 0.0003340585681144148
Loss at iteration 1340 : 0.0001717017003102228
Loss at iteration 1350 : 0.00010673810174921528
Loss at iteration 1360 : 0.0038239560090005398
Loss at iteration 1370 : 0.0006088318186812103
Loss at iteration 1380 : 0.00018937363347504288
Loss at iteration 1390 : 0.0004795707354787737
Loss at iteration 1400 : 0.0003078844747506082
Loss at iteration 1410 : 0.00011963257566094398
Loss at iteration 1420 : 0.0002122771693393588
Loss at iteration 1430 : 0.003491794690489769
Loss at iteration 1440 : 0.00019055149459745735
Loss at iteration 1450 : 0.0006150531116873026
Loss at iteration 1460 : 0.00024286757980007678
Loss at iteration 1470 : 0.0004556726198643446
Loss at iteration 1480 : 0.0004968924331478775
Loss at iteration 1490 : 0.0003100553876720369
Loss at iteration 1500 : 0.00445125438272953
Loss at iteration 1510 : 0.0008953061187639832
Loss at iteration 1520 : 0.0017171846702694893
Loss at iteration 1530 : 8.360065112356097e-05
Loss at iteration 1540 : 0.008205577731132507
Loss at iteration 1550 : 0.0001280806609429419
Loss at iteration 1560 : 0.0017548074247315526
Loss at iteration 1570 : 0.00017522816779091954
Loss at iteration 1580 : 0.00012317966320551932
Loss at iteration 1590 : 0.00016160916129592806
Loss at iteration 1600 : 0.00018238484335597605
Loss at iteration 1610 : 0.004878624342381954
Loss at iteration 1620 : 0.00025838942383415997
Loss at iteration 1630 : 8.865482959663495e-05
Loss at iteration 1640 : 0.00020645937183871865
Loss at iteration 1650 : 0.0004564422997646034
Loss at iteration 1660 : 0.0008115326054394245
Loss at iteration 1670 : 0.00023026381677482277
Loss at iteration 1680 : 0.0010069097625091672
Loss at iteration 1690 : 0.002495403401553631
Loss at iteration 1700 : 0.0005995507817715406
Loss at iteration 1710 : 0.00017353755538351834
Loss at iteration 1720 : 0.0001790989190340042
Loss at iteration 1730 : 0.0001381175097776577
Loss at iteration 1740 : 0.00013789531658403575
Loss at iteration 1750 : 0.0030402145348489285
The SSIM Value is: 0.9833061441713493
The PSNR Value is: 46.52566781233061
the epoch is: 59
Loss at iteration 10 : 0.0004986014682799578
Loss at iteration 20 : 0.00015735354099888355
Loss at iteration 30 : 0.0015209123957902193
Loss at iteration 40 : 0.00015402452845592052
Loss at iteration 50 : 0.0003050643135793507
Loss at iteration 60 : 0.0006285373819991946
Loss at iteration 70 : 0.0008481626864522696
Loss at iteration 80 : 0.003375046420842409
Loss at iteration 90 : 0.00037367994082160294
Loss at iteration 100 : 0.00025471634580753744
Loss at iteration 110 : 0.0004692747024819255
Loss at iteration 120 : 9.680519724497572e-05
Loss at iteration 130 : 0.0017275430727750063
Loss at iteration 140 : 9.59874305408448e-05
Loss at iteration 150 : 0.00019641857943497598
Loss at iteration 160 : 0.003342526499181986
Loss at iteration 170 : 0.00017476186621934175
Loss at iteration 180 : 0.0004743363824672997
Loss at iteration 190 : 0.0006097254808992147
Loss at iteration 200 : 0.005379087291657925
Loss at iteration 210 : 0.0012316054198890924
Loss at iteration 220 : 0.0003588046529330313
Loss at iteration 230 : 0.0003612960281316191
Loss at iteration 240 : 0.0009896730771288276
Loss at iteration 250 : 0.005341378040611744
Loss at iteration 260 : 9.353276982437819e-05
Loss at iteration 270 : 0.0006486293859779835
Loss at iteration 280 : 0.00019039543985854834
Loss at iteration 290 : 0.00035201775608584285
Loss at iteration 300 : 0.0001137388389906846
Loss at iteration 310 : 0.00033297116169705987
Loss at iteration 320 : 0.0012281382223591208
Loss at iteration 330 : 0.0002817514177877456
Loss at iteration 340 : 0.0005082595162093639
Loss at iteration 350 : 0.0021186168305575848
Loss at iteration 360 : 0.0010590235469862819
Loss at iteration 370 : 0.002623295644298196
Loss at iteration 380 : 0.0003100516623817384
Loss at iteration 390 : 0.003034888533875346
Loss at iteration 400 : 0.00036742346128448844
Loss at iteration 410 : 0.00013359646254684776
Loss at iteration 420 : 0.000825217051897198
Loss at iteration 430 : 8.175391121767461e-05
Loss at iteration 440 : 0.00012507388601079583
Loss at iteration 450 : 0.00038074114127084613
Loss at iteration 460 : 0.00018113190890289843
Loss at iteration 470 : 0.0003687635180540383
Loss at iteration 480 : 0.006770986597985029
Loss at iteration 490 : 0.00021161726908758283
Loss at iteration 500 : 0.000219327601371333
Loss at iteration 510 : 0.0004051416181027889
Loss at iteration 520 : 7.466685929102823e-05
Loss at iteration 530 : 0.0003011356748174876
Loss at iteration 540 : 0.003558945842087269
Loss at iteration 550 : 0.0016878943424671888
Loss at iteration 560 : 0.0003156274906359613
Loss at iteration 570 : 0.0038895104080438614
Loss at iteration 580 : 0.002616486046463251
Loss at iteration 590 : 0.00015948290820233524
Loss at iteration 600 : 0.0004668988985940814
Loss at iteration 610 : 0.0006492051761597395
Loss at iteration 620 : 0.0004901972133666277
Loss at iteration 630 : 0.00045794760808348656
Loss at iteration 640 : 0.0003221461083739996
Loss at iteration 650 : 0.0001287782797589898
Loss at iteration 660 : 0.00036201387410983443
Loss at iteration 670 : 0.00013902594218961895
Loss at iteration 680 : 0.0021922022569924593
Loss at iteration 690 : 0.00019957873155362904
Loss at iteration 700 : 0.0003412140067666769
Loss at iteration 710 : 0.0006483960896730423
Loss at iteration 720 : 0.00014415616169571877
Loss at iteration 730 : 0.00033142202300950885
Loss at iteration 740 : 0.00023479577794205397
Loss at iteration 750 : 0.00448727048933506
Loss at iteration 760 : 0.00018027039186563343
Loss at iteration 770 : 0.0002028246090048924
Loss at iteration 780 : 0.00016569347644690424
Loss at iteration 790 : 0.0004219994880259037
Loss at iteration 800 : 0.0005692818085663021
Loss at iteration 810 : 0.00026238374994136393
Loss at iteration 820 : 0.00018933735555037856
Loss at iteration 830 : 0.0004505353281274438
Loss at iteration 840 : 0.0010574869811534882
Loss at iteration 850 : 0.0021566636860370636
Loss at iteration 860 : 0.0002498731482774019
Loss at iteration 870 : 0.0008351854630745947
Loss at iteration 880 : 0.0009600926423445344
Loss at iteration 890 : 0.0003710938326548785
Loss at iteration 900 : 0.00042040212429128587
Loss at iteration 910 : 0.0006536933360621333
Loss at iteration 920 : 0.0011549690971150994
Loss at iteration 930 : 0.0001664604205871001
Loss at iteration 940 : 0.0023232270032167435
Loss at iteration 950 : 0.00020890483574476093
Loss at iteration 960 : 0.00020284723723307252
Loss at iteration 970 : 0.00016299652634188533
Loss at iteration 980 : 0.0006955930148251355
Loss at iteration 990 : 0.0052671898156404495
Loss at iteration 1000 : 0.0002190446393797174
Loss at iteration 1010 : 0.0016018480528146029
Loss at iteration 1020 : 0.00034515178413130343
Loss at iteration 1030 : 0.0030801782850176096
Loss at iteration 1040 : 0.0009048119536601007
Loss at iteration 1050 : 0.0020266775973141193
Loss at iteration 1060 : 0.000848600931931287
Loss at iteration 1070 : 0.0017048487206920981
Loss at iteration 1080 : 9.825116285355762e-05
Loss at iteration 1090 : 0.0011057404335588217
Loss at iteration 1100 : 0.0007835006108507514
Loss at iteration 1110 : 0.0029993904754519463
Loss at iteration 1120 : 0.0006245803087949753
Loss at iteration 1130 : 0.0039055664092302322
Loss at iteration 1140 : 0.0025133902672678232
Loss at iteration 1150 : 0.003836164716631174
Loss at iteration 1160 : 0.00022327566694002599
Loss at iteration 1170 : 0.00025000935420393944
Loss at iteration 1180 : 0.0003684808034449816
Loss at iteration 1190 : 0.0005009029409848154
Loss at iteration 1200 : 0.0004800704773515463
Loss at iteration 1210 : 0.0033972058445215225
Loss at iteration 1220 : 7.068801642162725e-05
Loss at iteration 1230 : 0.0020998551044613123
Loss at iteration 1240 : 0.0001938023342518136
Loss at iteration 1250 : 4.259854176780209e-05
Loss at iteration 1260 : 0.00022914379951544106
Loss at iteration 1270 : 0.0009128340752795339
Loss at iteration 1280 : 0.00017107425082940608
Loss at iteration 1290 : 9.089075319934636e-05
Loss at iteration 1300 : 0.0004072886658832431
Loss at iteration 1310 : 0.00296034081839025
Loss at iteration 1320 : 0.0001225848391186446
Loss at iteration 1330 : 6.807894533267245e-05
Loss at iteration 1340 : 0.001186708570457995
Loss at iteration 1350 : 0.0018367748707532883
Loss at iteration 1360 : 0.0004102736129425466
Loss at iteration 1370 : 0.0024070078507065773
Loss at iteration 1380 : 0.0002527324541006237
Loss at iteration 1390 : 0.00035872627631761134
Loss at iteration 1400 : 0.005205600522458553
Loss at iteration 1410 : 0.0013038571923971176
Loss at iteration 1420 : 0.0005200722371228039
Loss at iteration 1430 : 0.00027988292276859283
Loss at iteration 1440 : 0.0028201870154589415
Loss at iteration 1450 : 0.00036705841193906963
Loss at iteration 1460 : 0.002609523246064782
Loss at iteration 1470 : 0.00012882761075161397
Loss at iteration 1480 : 0.0011667119106277823
Loss at iteration 1490 : 0.0005274300929158926
Loss at iteration 1500 : 0.0007504866225644946
Loss at iteration 1510 : 0.002464632736518979
Loss at iteration 1520 : 3.8398924516513944e-05
Loss at iteration 1530 : 0.0008235251880250871
Loss at iteration 1540 : 0.0015480179572477937
Loss at iteration 1550 : 0.000247219082666561
Loss at iteration 1560 : 0.0001654066436458379
Loss at iteration 1570 : 0.00016314539243467152
Loss at iteration 1580 : 7.308777276193723e-05
Loss at iteration 1590 : 0.0017219297587871552
Loss at iteration 1600 : 0.0004403378115966916
Loss at iteration 1610 : 0.00015166157390922308
Loss at iteration 1620 : 7.632659981027246e-05
Loss at iteration 1630 : 0.0005886700819246471
Loss at iteration 1640 : 0.00018661291687749326
Loss at iteration 1650 : 0.00036075484240427613
Loss at iteration 1660 : 0.00030013557989150286
Loss at iteration 1670 : 0.0002103504230035469
Loss at iteration 1680 : 0.0007106026750989258
Loss at iteration 1690 : 0.0001856572343967855
Loss at iteration 1700 : 0.00033660224289633334
Loss at iteration 1710 : 0.0010654915822669864
Loss at iteration 1720 : 0.001018363400362432
Loss at iteration 1730 : 0.0004274262464605272
Loss at iteration 1740 : 0.0015504852635785937
Loss at iteration 1750 : 6.845261668786407e-05
The SSIM Value is: 0.985857485937127
The PSNR Value is: 46.46111317983283
the epoch is: 60
Loss at iteration 10 : 0.0008397643687203526
Loss at iteration 20 : 0.00013581621169578284
Loss at iteration 30 : 0.0012071378296241164
Loss at iteration 40 : 0.0002614825207274407
Loss at iteration 50 : 0.0031448467634618282
Loss at iteration 60 : 0.0014858386712148786
Loss at iteration 70 : 0.00024057351402007043
Loss at iteration 80 : 0.00027193143614567816
Loss at iteration 90 : 0.0017786216922104359
Loss at iteration 100 : 0.0001854482397902757
Loss at iteration 110 : 0.00017559003026690334
Loss at iteration 120 : 0.0026677942369133234
Loss at iteration 130 : 0.0034008745569735765
Loss at iteration 140 : 0.00012646938557736576
Loss at iteration 150 : 0.006598326377570629
Loss at iteration 160 : 6.0317932366160676e-05
Loss at iteration 170 : 0.0006000297144055367
Loss at iteration 180 : 0.0003914989356417209
Loss at iteration 190 : 0.0015937571879476309
Loss at iteration 200 : 0.0028901000041514635
Loss at iteration 210 : 0.0011763910297304392
Loss at iteration 220 : 0.001297192182391882
Loss at iteration 230 : 0.002962702652439475
Loss at iteration 240 : 0.005460773594677448
Loss at iteration 250 : 0.0017663746839389205
Loss at iteration 260 : 0.0027008242905139923
Loss at iteration 270 : 0.00014289183309301734
Loss at iteration 280 : 0.00012376664381008595
Loss at iteration 290 : 0.00023101040278561413
Loss at iteration 300 : 0.00010159470548387617
Loss at iteration 310 : 0.00021441892022266984
Loss at iteration 320 : 0.003249459434300661
Loss at iteration 330 : 0.00012648878328036517
Loss at iteration 340 : 0.00045473186764866114
Loss at iteration 350 : 7.596149953315035e-05
Loss at iteration 360 : 0.0007168948650360107
Loss at iteration 370 : 0.000795775034930557
Loss at iteration 380 : 0.0011352277360856533
Loss at iteration 390 : 0.00022679459652863443
Loss at iteration 400 : 0.00017900099919643253
Loss at iteration 410 : 7.611213368363678e-05
Loss at iteration 420 : 0.0012449576752260327
Loss at iteration 430 : 0.0002885511494241655
Loss at iteration 440 : 7.674892549403012e-05
Loss at iteration 450 : 0.00040008145151659846
Loss at iteration 460 : 0.0016380343586206436
Loss at iteration 470 : 0.00031296309316530824
Loss at iteration 480 : 0.00018930714577436447
Loss at iteration 490 : 0.001503692357800901
Loss at iteration 500 : 0.00040320801781490445
Loss at iteration 510 : 0.0010972380405291915
Loss at iteration 520 : 0.006847909651696682
Loss at iteration 530 : 9.641422366257757e-05
Loss at iteration 540 : 0.0021874550729990005
Loss at iteration 550 : 0.0016415719874203205
Loss at iteration 560 : 9.00852755876258e-05
Loss at iteration 570 : 0.006423061713576317
Loss at iteration 580 : 9.353698987979442e-05
Loss at iteration 590 : 0.0002840220113284886
Loss at iteration 600 : 0.004406583961099386
Loss at iteration 610 : 0.001862713135778904
Loss at iteration 620 : 9.139877511188388e-05
Loss at iteration 630 : 0.0007299706339836121
Loss at iteration 640 : 0.0005295546143315732
Loss at iteration 650 : 0.0007398697780445218
Loss at iteration 660 : 0.00035623996518552303
Loss at iteration 670 : 0.00022323671146295965
Loss at iteration 680 : 0.0017347062239423394
Loss at iteration 690 : 0.004108230583369732
Loss at iteration 700 : 0.00012609206896740943
Loss at iteration 710 : 0.0001466766552766785
Loss at iteration 720 : 0.0004151281318627298
Loss at iteration 730 : 0.0019500914495438337
Loss at iteration 740 : 0.003991246223449707
Loss at iteration 750 : 0.002067234832793474
Loss at iteration 760 : 0.000749400001950562
Loss at iteration 770 : 0.0008550751372240484
Loss at iteration 780 : 0.0005692632403224707
Loss at iteration 790 : 0.005173159297555685
Loss at iteration 800 : 0.00031354642123915255
Loss at iteration 810 : 0.00037984305527061224
Loss at iteration 820 : 0.0001153370103565976
Loss at iteration 830 : 0.002301566069945693
Loss at iteration 840 : 0.0012257101479917765
Loss at iteration 850 : 0.0032905784901231527
Loss at iteration 860 : 0.0017850100994110107
Loss at iteration 870 : 3.901266245520674e-05
Loss at iteration 880 : 0.00021270677098073065
Loss at iteration 890 : 0.00029222932062111795
Loss at iteration 900 : 0.0008899320382624865
Loss at iteration 910 : 9.397407848155126e-05
Loss at iteration 920 : 0.0003949982055928558
Loss at iteration 930 : 0.0004283636517357081
Loss at iteration 940 : 0.00014642422320321202
Loss at iteration 950 : 0.00015959018492139876
Loss at iteration 960 : 0.00026396336033940315
Loss at iteration 970 : 0.0025598204229027033
Loss at iteration 980 : 9.321824472863227e-05
Loss at iteration 990 : 0.00022077845642343163
Loss at iteration 1000 : 0.0002548153279349208
Loss at iteration 1010 : 0.00018109814845956862
Loss at iteration 1020 : 0.0005182850873097777
Loss at iteration 1030 : 0.002778721507638693
Loss at iteration 1040 : 0.00028981026844121516
Loss at iteration 1050 : 0.00019191463070455939
Loss at iteration 1060 : 0.004747019149363041
Loss at iteration 1070 : 0.0018976492574438453
Loss at iteration 1080 : 0.0012596595333889127
Loss at iteration 1090 : 0.010415584780275822
Loss at iteration 1100 : 7.418981840601191e-05
Loss at iteration 1110 : 0.0007501908112317324
Loss at iteration 1120 : 0.00029190874192863703
Loss at iteration 1130 : 0.0005183164612390101
Loss at iteration 1140 : 0.0002503096766304225
Loss at iteration 1150 : 0.002766955876722932
Loss at iteration 1160 : 0.0019316021353006363
Loss at iteration 1170 : 0.0013517639599740505
Loss at iteration 1180 : 0.0021206559613347054
Loss at iteration 1190 : 0.00013113321620039642
Loss at iteration 1200 : 0.0026956195943057537
Loss at iteration 1210 : 0.00030080124270170927
Loss at iteration 1220 : 0.0023185426834970713
Loss at iteration 1230 : 0.004711591638624668
Loss at iteration 1240 : 0.00036981169250793755
Loss at iteration 1250 : 0.0008951876661740243
Loss at iteration 1260 : 0.0007082588854245842
Loss at iteration 1270 : 0.0016662284033372998
Loss at iteration 1280 : 6.577889871550724e-05
Loss at iteration 1290 : 0.0053041353821754456
Loss at iteration 1300 : 0.00022730737691745162
Loss at iteration 1310 : 0.00028017532895319164
Loss at iteration 1320 : 6.405214662663639e-05
Loss at iteration 1330 : 0.002575612859800458
Loss at iteration 1340 : 0.0003784594882745296
Loss at iteration 1350 : 0.00012252709711901844
Loss at iteration 1360 : 0.00012257954222150147
Loss at iteration 1370 : 0.0003001524310093373
Loss at iteration 1380 : 0.00019319340935908258
Loss at iteration 1390 : 0.00018272218585480005
Loss at iteration 1400 : 0.0006182413198985159
Loss at iteration 1410 : 0.0020468069706112146
Loss at iteration 1420 : 0.00017351812857668847
Loss at iteration 1430 : 0.0016119155334308743
Loss at iteration 1440 : 6.117801240179688e-05
Loss at iteration 1450 : 0.0009671591687947512
Loss at iteration 1460 : 0.0024751638993620872
Loss at iteration 1470 : 0.004782485775649548
Loss at iteration 1480 : 0.00010863664647331461
Loss at iteration 1490 : 5.950074046268128e-05
Loss at iteration 1500 : 0.00358626083470881
Loss at iteration 1510 : 0.0009148676181212068
Loss at iteration 1520 : 0.00010938625200651586
Loss at iteration 1530 : 0.00016016338486224413
Loss at iteration 1540 : 0.002043047221377492
Loss at iteration 1550 : 0.0017469432204961777
Loss at iteration 1560 : 0.0011765050003305078
Loss at iteration 1570 : 0.00011721360351657495
Loss at iteration 1580 : 0.0001739514118526131
Loss at iteration 1590 : 0.0007354009430855513
Loss at iteration 1600 : 0.00013564559048973024
Loss at iteration 1610 : 0.0001812513655750081
Loss at iteration 1620 : 0.00013946415856480598
Loss at iteration 1630 : 0.00022328869090415537
Loss at iteration 1640 : 0.0016063154907897115
Loss at iteration 1650 : 0.00023720870376564562
Loss at iteration 1660 : 0.00012507881911005825
Loss at iteration 1670 : 0.00013286143075674772
Loss at iteration 1680 : 0.0011652483372017741
Loss at iteration 1690 : 0.00011693288979586214
Loss at iteration 1700 : 0.0003431795921642333
Loss at iteration 1710 : 5.5771710322005674e-05
Loss at iteration 1720 : 0.000561006716452539
Loss at iteration 1730 : 0.0014348458498716354
Loss at iteration 1740 : 5.56485028937459e-05
Loss at iteration 1750 : 0.001264757476747036
The SSIM Value is: 0.9846475879263773
The PSNR Value is: 46.4517790903604
the epoch is: 61
Loss at iteration 10 : 0.0017322672065347433
Loss at iteration 20 : 0.0022207358852028847
Loss at iteration 30 : 0.00023087419685907662
Loss at iteration 40 : 0.0002122744917869568
Loss at iteration 50 : 8.513868669979274e-05
Loss at iteration 60 : 0.0018494074465706944
Loss at iteration 70 : 0.00048088107723742723
Loss at iteration 80 : 0.0010267109610140324
Loss at iteration 90 : 0.002580696251243353
Loss at iteration 100 : 0.00023180636344477534
Loss at iteration 110 : 0.0006864564493298531
Loss at iteration 120 : 0.0009038057178258896
Loss at iteration 130 : 0.0007699074922129512
Loss at iteration 140 : 0.000252330006333068
Loss at iteration 150 : 0.00011173262464581057
Loss at iteration 160 : 0.00048006681026890874
Loss at iteration 170 : 0.000232140242587775
Loss at iteration 180 : 0.006093538366258144
Loss at iteration 190 : 0.00019411847461014986
Loss at iteration 200 : 0.00011958135291934013
Loss at iteration 210 : 0.0037658479996025562
Loss at iteration 220 : 0.00031089887488633394
Loss at iteration 230 : 0.005191260017454624
Loss at iteration 240 : 0.00017827778356149793
Loss at iteration 250 : 0.0001551566820126027
Loss at iteration 260 : 0.0002755668247118592
Loss at iteration 270 : 0.00010857873712666333
Loss at iteration 280 : 4.998984877602197e-05
Loss at iteration 290 : 0.00011234077101107687
Loss at iteration 300 : 0.00012094762496417388
Loss at iteration 310 : 0.0009412115323357284
Loss at iteration 320 : 0.0006374542135745287
Loss at iteration 330 : 0.002102636732161045
Loss at iteration 340 : 0.0015638512559235096
Loss at iteration 350 : 0.0005176168633624911
Loss at iteration 360 : 0.00028999941423535347
Loss at iteration 370 : 0.0027463827282190323
Loss at iteration 380 : 0.0005155042163096368
Loss at iteration 390 : 8.131608774419874e-05
Loss at iteration 400 : 0.00011078387615270913
Loss at iteration 410 : 6.128055247245356e-05
Loss at iteration 420 : 0.0004097727360203862
Loss at iteration 430 : 0.00020048489386681467
Loss at iteration 440 : 0.00012815557420253754
Loss at iteration 450 : 0.00118845677934587
Loss at iteration 460 : 0.00010184765415033326
Loss at iteration 470 : 0.00011177962005604059
Loss at iteration 480 : 0.0002409517765045166
Loss at iteration 490 : 0.001238435972481966
Loss at iteration 500 : 0.0017077330267056823
Loss at iteration 510 : 0.00016679041436873376
Loss at iteration 520 : 0.0010094839381054044
Loss at iteration 530 : 0.0020239632576704025
Loss at iteration 540 : 0.006699501071125269
Loss at iteration 550 : 0.00047408341197296977
Loss at iteration 560 : 6.336743535939604e-05
Loss at iteration 570 : 0.0032970914617180824
Loss at iteration 580 : 0.00015231974248308688
Loss at iteration 590 : 0.0021679848432540894
Loss at iteration 600 : 0.00014327769167721272
Loss at iteration 610 : 0.0003220410435460508
Loss at iteration 620 : 0.00027282105293124914
Loss at iteration 630 : 0.0022971921134740114
Loss at iteration 640 : 7.678792462684214e-05
Loss at iteration 650 : 0.00015694480680394918
Loss at iteration 660 : 9.058316936716437e-05
Loss at iteration 670 : 6.264832336455584e-05
Loss at iteration 680 : 9.63997226790525e-05
Loss at iteration 690 : 0.005893948022276163
Loss at iteration 700 : 0.0005776735488325357
Loss at iteration 710 : 0.0003125276998616755
Loss at iteration 720 : 0.005866453051567078
Loss at iteration 730 : 0.0028007053770124912
Loss at iteration 740 : 0.0017294588033109903
Loss at iteration 750 : 0.0001069027348421514
Loss at iteration 760 : 0.00024652000865899026
Loss at iteration 770 : 7.52833002479747e-05
Loss at iteration 780 : 0.000499697751365602
Loss at iteration 790 : 0.00018214614829048514
Loss at iteration 800 : 0.0018992105033248663
Loss at iteration 810 : 0.0034815596882253885
Loss at iteration 820 : 0.0012757780496031046
Loss at iteration 830 : 0.002373563591390848
Loss at iteration 840 : 0.00018313433974981308
Loss at iteration 850 : 5.5707212595734745e-05
Loss at iteration 860 : 0.0011097101960331202
Loss at iteration 870 : 0.00044982670806348324
Loss at iteration 880 : 0.0005177793209441006
Loss at iteration 890 : 0.002785719698294997
Loss at iteration 900 : 0.00020167820912320167
Loss at iteration 910 : 0.0002855022612493485
Loss at iteration 920 : 0.002859786618500948
Loss at iteration 930 : 0.00011639963486231863
Loss at iteration 940 : 0.0004342657921370119
Loss at iteration 950 : 0.000314280012389645
Loss at iteration 960 : 0.00011484768765512854
Loss at iteration 970 : 0.000364826584700495
Loss at iteration 980 : 0.0013331025838851929
Loss at iteration 990 : 0.00013212054909672588
Loss at iteration 1000 : 0.0003525627253111452
Loss at iteration 1010 : 0.0016125375404953957
Loss at iteration 1020 : 0.0001156399812316522
Loss at iteration 1030 : 9.340587712358683e-05
Loss at iteration 1040 : 0.004458533599972725
Loss at iteration 1050 : 0.0002237392181996256
Loss at iteration 1060 : 0.0001324069162365049
Loss at iteration 1070 : 0.0002242029586341232
Loss at iteration 1080 : 0.0036358009092509747
Loss at iteration 1090 : 0.0018217567121610045
Loss at iteration 1100 : 0.0001588828454259783
Loss at iteration 1110 : 9.142227645497769e-05
Loss at iteration 1120 : 6.535510328831151e-05
Loss at iteration 1130 : 0.003095047315582633
Loss at iteration 1140 : 0.00013721073628403246
Loss at iteration 1150 : 0.0008498373790644109
Loss at iteration 1160 : 0.002246128162369132
Loss at iteration 1170 : 0.0004131873429287225
Loss at iteration 1180 : 0.00022308999905362725
Loss at iteration 1190 : 0.0005259435856714845
Loss at iteration 1200 : 0.00025338513660244644
Loss at iteration 1210 : 0.0009675719775259495
Loss at iteration 1220 : 9.643263183534145e-05
Loss at iteration 1230 : 0.002447890816256404
Loss at iteration 1240 : 0.0001249344350071624
Loss at iteration 1250 : 0.0019828632939606905
Loss at iteration 1260 : 7.322814781218767e-05
Loss at iteration 1270 : 0.00030792082543484867
Loss at iteration 1280 : 0.0007229575421661139
Loss at iteration 1290 : 0.0001611925254110247
Loss at iteration 1300 : 0.007865513674914837
Loss at iteration 1310 : 0.0004021875502076
Loss at iteration 1320 : 0.0001795900461729616
Loss at iteration 1330 : 0.00041543261613696814
Loss at iteration 1340 : 0.0020272918045520782
Loss at iteration 1350 : 0.0005739960470236838
Loss at iteration 1360 : 0.00010459175246069208
Loss at iteration 1370 : 0.0003178874321747571
Loss at iteration 1380 : 0.0001759046281222254
Loss at iteration 1390 : 8.672025433043018e-05
Loss at iteration 1400 : 0.00017703446792438626
Loss at iteration 1410 : 0.00027924985624849796
Loss at iteration 1420 : 0.00010413144627818838
Loss at iteration 1430 : 0.002042285865172744
Loss at iteration 1440 : 0.0006444989703595638
Loss at iteration 1450 : 0.00013097179180476815
Loss at iteration 1460 : 0.00023266093921847641
Loss at iteration 1470 : 0.004220420494675636
Loss at iteration 1480 : 0.00018828119209501892
Loss at iteration 1490 : 0.00012214640446472913
Loss at iteration 1500 : 0.00029259436996653676
Loss at iteration 1510 : 0.0037885750643908978
Loss at iteration 1520 : 0.00032792461570352316
Loss at iteration 1530 : 0.0002275006554555148
Loss at iteration 1540 : 0.000582851585932076
Loss at iteration 1550 : 0.00039350666338577867
Loss at iteration 1560 : 0.00029098865343257785
Loss at iteration 1570 : 0.0006631011492572725
Loss at iteration 1580 : 0.00026683055330067873
Loss at iteration 1590 : 0.00031698262318968773
Loss at iteration 1600 : 0.00024256926553789526
Loss at iteration 1610 : 0.0014287199592217803
Loss at iteration 1620 : 0.0013016695156693459
Loss at iteration 1630 : 0.0002562992158345878
Loss at iteration 1640 : 0.0003045927733182907
Loss at iteration 1650 : 8.556966349715367e-05
Loss at iteration 1660 : 0.004432044457644224
Loss at iteration 1670 : 0.00033030641498044133
Loss at iteration 1680 : 0.00038551315083168447
Loss at iteration 1690 : 6.606009264942259e-05
Loss at iteration 1700 : 0.00022168149007484317
Loss at iteration 1710 : 0.0014978188555687666
Loss at iteration 1720 : 0.00017406752158422023
Loss at iteration 1730 : 0.002670158864930272
Loss at iteration 1740 : 0.0013338433345779777
Loss at iteration 1750 : 0.0011992276413366199
The SSIM Value is: 0.9881700679069049
The PSNR Value is: 45.55712790006058
the epoch is: 62
Loss at iteration 10 : 0.0013821946922689676
Loss at iteration 20 : 0.0008467665174975991
Loss at iteration 30 : 0.004555028397589922
Loss at iteration 40 : 0.0003607419494073838
Loss at iteration 50 : 0.00023533424246124923
Loss at iteration 60 : 0.003469935618340969
Loss at iteration 70 : 0.00012996814621146768
Loss at iteration 80 : 0.00043241551611572504
Loss at iteration 90 : 0.0033480143174529076
Loss at iteration 100 : 0.000902055820915848
Loss at iteration 110 : 0.0036562078166753054
Loss at iteration 120 : 0.000612524978350848
Loss at iteration 130 : 0.0013276091776788235
Loss at iteration 140 : 0.000486321427160874
Loss at iteration 150 : 0.0035871427971869707
Loss at iteration 160 : 0.004644591826945543
Loss at iteration 170 : 0.004889433737844229
Loss at iteration 180 : 7.131336315069348e-05
Loss at iteration 190 : 0.00018505376647226512
Loss at iteration 200 : 0.0015837415121495724
Loss at iteration 210 : 0.000165424746228382
Loss at iteration 220 : 0.002530316123738885
Loss at iteration 230 : 0.00330005562864244
Loss at iteration 240 : 0.002455206587910652
Loss at iteration 250 : 0.0007739338325336576
Loss at iteration 260 : 0.00017240448505617678
Loss at iteration 270 : 0.00016260020493064076
Loss at iteration 280 : 0.003997916355729103
Loss at iteration 290 : 7.331088272621855e-05
Loss at iteration 300 : 0.003214075695723295
Loss at iteration 310 : 0.00019088014960289001
Loss at iteration 320 : 0.0041136667132377625
Loss at iteration 330 : 0.0012095653219148517
Loss at iteration 340 : 6.535670399898663e-05
Loss at iteration 350 : 7.300284778466448e-05
Loss at iteration 360 : 0.0001238776312675327
Loss at iteration 370 : 0.0001350759994238615
Loss at iteration 380 : 0.007786658126860857
Loss at iteration 390 : 0.008445647545158863
Loss at iteration 400 : 9.312106703873724e-05
Loss at iteration 410 : 0.00015133569831959903
Loss at iteration 420 : 0.002563184592872858
Loss at iteration 430 : 0.0007595906499773264
Loss at iteration 440 : 0.0001077649649232626
Loss at iteration 450 : 8.023698319448158e-05
Loss at iteration 460 : 0.00343718146905303
Loss at iteration 470 : 0.0035494528710842133
Loss at iteration 480 : 0.0023404662497341633
Loss at iteration 490 : 3.926412682631053e-05
Loss at iteration 500 : 7.775928679620847e-05
Loss at iteration 510 : 0.0003854453098028898
Loss at iteration 520 : 0.00034976156894117594
Loss at iteration 530 : 0.002155599184334278
Loss at iteration 540 : 0.001552170724608004
Loss at iteration 550 : 8.951623749453574e-05
Loss at iteration 560 : 0.0012587277451530099
Loss at iteration 570 : 0.0003459795843809843
Loss at iteration 580 : 0.00042368145659565926
Loss at iteration 590 : 0.0002942186838481575
Loss at iteration 600 : 0.0003372782957740128
Loss at iteration 610 : 0.00034240385866723955
Loss at iteration 620 : 0.00032556933001615107
Loss at iteration 630 : 0.001131941331550479
Loss at iteration 640 : 0.00020040820527356118
Loss at iteration 650 : 0.0005135966930538416
Loss at iteration 660 : 0.0010387366637587547
Loss at iteration 670 : 0.0005437412182800472
Loss at iteration 680 : 0.002416050061583519
Loss at iteration 690 : 9.057145507540554e-05
Loss at iteration 700 : 0.0008039824897423387
Loss at iteration 710 : 0.0007679229602217674
Loss at iteration 720 : 0.00010561652743490413
Loss at iteration 730 : 0.0003428799391258508
Loss at iteration 740 : 0.0008852632017806172
Loss at iteration 750 : 0.001893539447337389
Loss at iteration 760 : 0.00012701888044830412
Loss at iteration 770 : 0.0030092988163232803
Loss at iteration 780 : 0.0005544986925087869
Loss at iteration 790 : 0.0014995371457189322
Loss at iteration 800 : 0.0005831045564264059
Loss at iteration 810 : 0.000350359856383875
Loss at iteration 820 : 0.002500860020518303
Loss at iteration 830 : 0.0038615684024989605
Loss at iteration 840 : 0.0007639105315320194
Loss at iteration 850 : 0.0005824079271405935
Loss at iteration 860 : 0.0004960017977282405
Loss at iteration 870 : 0.0012692691525444388
Loss at iteration 880 : 0.0011855813208967447
Loss at iteration 890 : 0.0007949057035148144
Loss at iteration 900 : 0.0002159423311240971
Loss at iteration 910 : 0.00022030292893759906
Loss at iteration 920 : 0.0001088013596017845
Loss at iteration 930 : 0.0003879872092511505
Loss at iteration 940 : 0.002391012152656913
Loss at iteration 950 : 0.0005498534301295877
Loss at iteration 960 : 0.000516041531227529
Loss at iteration 970 : 0.005388561170548201
Loss at iteration 980 : 0.0003218080382794142
Loss at iteration 990 : 0.0009388676844537258
Loss at iteration 1000 : 0.0006706065032631159
Loss at iteration 1010 : 0.00244725588709116
Loss at iteration 1020 : 0.0001912547741085291
Loss at iteration 1030 : 0.003715316765010357
Loss at iteration 1040 : 0.0017423981335014105
Loss at iteration 1050 : 0.0005190433003008366
Loss at iteration 1060 : 0.0005372104933485389
Loss at iteration 1070 : 0.000684271682985127
Loss at iteration 1080 : 6.721638783346862e-05
Loss at iteration 1090 : 0.00010283700248692185
Loss at iteration 1100 : 9.053821122506633e-05
Loss at iteration 1110 : 0.0030887017492204905
Loss at iteration 1120 : 0.0003987209056504071
Loss at iteration 1130 : 0.00020175024110358208
Loss at iteration 1140 : 0.005534052383154631
Loss at iteration 1150 : 0.0002810675068758428
Loss at iteration 1160 : 0.0022364510223269463
Loss at iteration 1170 : 0.0008741027559153736
Loss at iteration 1180 : 0.0016594515182077885
Loss at iteration 1190 : 0.00039449852192774415
Loss at iteration 1200 : 0.00016095777391456068
Loss at iteration 1210 : 0.0002079867699649185
Loss at iteration 1220 : 0.0010581156238913536
Loss at iteration 1230 : 0.00011313662980683148
Loss at iteration 1240 : 0.008870304562151432
Loss at iteration 1250 : 0.0013034646399319172
Loss at iteration 1260 : 0.0020915213972330093
Loss at iteration 1270 : 0.00022540861391462386
Loss at iteration 1280 : 0.0003390826750546694
Loss at iteration 1290 : 0.0013417755253612995
Loss at iteration 1300 : 0.0004067297850269824
Loss at iteration 1310 : 0.0016987083945423365
Loss at iteration 1320 : 8.750527922529727e-05
Loss at iteration 1330 : 0.001666997093707323
Loss at iteration 1340 : 0.0022812518291175365
Loss at iteration 1350 : 0.0036726100370287895
Loss at iteration 1360 : 0.0009568927926011384
Loss at iteration 1370 : 0.0003944292548112571
Loss at iteration 1380 : 0.00015725556295365095
Loss at iteration 1390 : 0.00023908492585178465
Loss at iteration 1400 : 0.00013647455489262938
Loss at iteration 1410 : 0.0005928596947342157
Loss at iteration 1420 : 8.947246533352882e-05
Loss at iteration 1430 : 0.005227998830378056
Loss at iteration 1440 : 0.0017192419618368149
Loss at iteration 1450 : 0.0012759417295455933
Loss at iteration 1460 : 0.0044419062323868275
Loss at iteration 1470 : 0.0005900365649722517
Loss at iteration 1480 : 0.00012088960647815838
Loss at iteration 1490 : 0.0007177445222623646
Loss at iteration 1500 : 0.0001290516956942156
Loss at iteration 1510 : 0.0006142188794910908
Loss at iteration 1520 : 0.00010816015128511935
Loss at iteration 1530 : 0.0006897863349877298
Loss at iteration 1540 : 0.0001698275445960462
Loss at iteration 1550 : 0.0025193048641085625
Loss at iteration 1560 : 0.00037877869908697903
Loss at iteration 1570 : 0.002114348579198122
Loss at iteration 1580 : 0.001087746350094676
Loss at iteration 1590 : 0.00020527601009234786
Loss at iteration 1600 : 0.0028984174132347107
Loss at iteration 1610 : 0.0004576809296850115
Loss at iteration 1620 : 6.93158435751684e-05
Loss at iteration 1630 : 0.000131068576592952
Loss at iteration 1640 : 0.0012279304210096598
Loss at iteration 1650 : 0.00014980178093537688
Loss at iteration 1660 : 5.9033467550762e-05
Loss at iteration 1670 : 0.004143153317272663
Loss at iteration 1680 : 0.0005609544459730387
Loss at iteration 1690 : 0.00034340255660936236
Loss at iteration 1700 : 0.0003128612879663706
Loss at iteration 1710 : 0.0006715612835250795
Loss at iteration 1720 : 0.0010895711602643132
Loss at iteration 1730 : 0.0006163307698443532
Loss at iteration 1740 : 0.00018649897538125515
Loss at iteration 1750 : 0.0006548830424435437
The SSIM Value is: 0.9779844289965567
The PSNR Value is: 46.530021045701616
the epoch is: 63
Loss at iteration 10 : 0.0008409281726926565
Loss at iteration 20 : 0.0008967845933511853
Loss at iteration 30 : 0.0031780293211340904
Loss at iteration 40 : 0.004719196353107691
Loss at iteration 50 : 7.241478306241333e-05
Loss at iteration 60 : 0.0006627787370234728
Loss at iteration 70 : 0.00022641793475486338
Loss at iteration 80 : 0.00029178947443142533
Loss at iteration 90 : 0.0001421010965714231
Loss at iteration 100 : 0.00020278045849408954
Loss at iteration 110 : 0.0006905653281137347
Loss at iteration 120 : 0.00020174853852950037
Loss at iteration 130 : 0.0009645497193560004
Loss at iteration 140 : 0.0003322070697322488
Loss at iteration 150 : 0.00012778901145793498
Loss at iteration 160 : 0.0060990070924162865
Loss at iteration 170 : 0.00016458125901408494
Loss at iteration 180 : 0.00012042024172842503
Loss at iteration 190 : 0.0001425224036211148
Loss at iteration 200 : 0.00016799665172584355
Loss at iteration 210 : 0.00011025752610294148
Loss at iteration 220 : 0.004333928227424622
Loss at iteration 230 : 0.0006666596746072173
Loss at iteration 240 : 7.314758840948343e-05
Loss at iteration 250 : 9.158608736470342e-05
Loss at iteration 260 : 0.0005419159424491227
Loss at iteration 270 : 0.00019114816677756608
Loss at iteration 280 : 0.0007141882670111954
Loss at iteration 290 : 0.00015176778833847493
Loss at iteration 300 : 0.003303253324702382
Loss at iteration 310 : 0.00010903338261414319
Loss at iteration 320 : 0.0004846170195378363
Loss at iteration 330 : 0.0037421633023768663
Loss at iteration 340 : 0.0005042861448600888
Loss at iteration 350 : 0.00044006272219121456
Loss at iteration 360 : 0.0028918874450027943
Loss at iteration 370 : 0.00011439919762779027
Loss at iteration 380 : 0.0008111432543955743
Loss at iteration 390 : 0.0011434473562985659
Loss at iteration 400 : 0.0001847025559982285
Loss at iteration 410 : 0.00017298897728323936
Loss at iteration 420 : 0.0018877692054957151
Loss at iteration 430 : 8.526129386154935e-05
Loss at iteration 440 : 0.00020152365323156118
Loss at iteration 450 : 0.0010174319613724947
Loss at iteration 460 : 0.00029577556415461004
Loss at iteration 470 : 0.00014147312322165817
Loss at iteration 480 : 0.002419596305117011
Loss at iteration 490 : 0.000214682673686184
Loss at iteration 500 : 9.812317875912413e-05
Loss at iteration 510 : 0.0006159709882922471
Loss at iteration 520 : 0.00020471024618018419
Loss at iteration 530 : 0.00037096324376761913
Loss at iteration 540 : 0.003971845842897892
Loss at iteration 550 : 0.0005301524652168155
Loss at iteration 560 : 0.0002553485392127186
Loss at iteration 570 : 0.0006964217755012214
Loss at iteration 580 : 0.0007691943319514394
Loss at iteration 590 : 0.0005792122101411223
Loss at iteration 600 : 0.002965128282085061
Loss at iteration 610 : 0.00016320744180120528
Loss at iteration 620 : 0.00023174844682216644
Loss at iteration 630 : 0.0005787296104244888
Loss at iteration 640 : 0.0005025736754760146
Loss at iteration 650 : 0.00020288917585276067
Loss at iteration 660 : 0.0005696722655557096
Loss at iteration 670 : 9.81331177172251e-05
Loss at iteration 680 : 0.000691944092977792
Loss at iteration 690 : 0.00010776086855912581
Loss at iteration 700 : 0.00011360189819242805
Loss at iteration 710 : 0.0005048602470196784
Loss at iteration 720 : 0.0019237473607063293
Loss at iteration 730 : 0.002644594293087721
Loss at iteration 740 : 0.0050007663667202
Loss at iteration 750 : 6.853265222162008e-05
Loss at iteration 760 : 0.0001290435902774334
Loss at iteration 770 : 0.00014098176325205714
Loss at iteration 780 : 0.001709572970867157
Loss at iteration 790 : 0.004150421358644962
Loss at iteration 800 : 0.00629953620955348
Loss at iteration 810 : 0.0021102186292409897
Loss at iteration 820 : 0.00010499553172849119
Loss at iteration 830 : 0.0008686319924890995
Loss at iteration 840 : 0.00017359825142193586
Loss at iteration 850 : 0.009078443050384521
Loss at iteration 860 : 6.462134479079396e-05
Loss at iteration 870 : 0.0002934433287009597
Loss at iteration 880 : 0.0008416456403210759
Loss at iteration 890 : 0.0002597745624370873
Loss at iteration 900 : 0.0007233002688735723
Loss at iteration 910 : 0.00034732173662632704
Loss at iteration 920 : 0.000423833669628948
Loss at iteration 930 : 8.095093653537333e-05
Loss at iteration 940 : 0.00022108308621682227
Loss at iteration 950 : 0.00013664156722370535
Loss at iteration 960 : 0.0009721930837258697
Loss at iteration 970 : 0.0003559089673217386
Loss at iteration 980 : 0.0036619813181459904
Loss at iteration 990 : 0.0002764502423815429
Loss at iteration 1000 : 0.004214677028357983
Loss at iteration 1010 : 0.00018712285964284092
Loss at iteration 1020 : 0.0036708966363221407
Loss at iteration 1030 : 0.0033175917342305183
Loss at iteration 1040 : 0.0003109560057055205
Loss at iteration 1050 : 0.0001332531392108649
Loss at iteration 1060 : 0.0003262571117375046
Loss at iteration 1070 : 0.00042125655454583466
Loss at iteration 1080 : 0.002044086344540119
Loss at iteration 1090 : 0.0003238230710849166
Loss at iteration 1100 : 0.006130523048341274
Loss at iteration 1110 : 0.00020172425138298422
Loss at iteration 1120 : 0.003848566673696041
Loss at iteration 1130 : 0.0005630888626910746
Loss at iteration 1140 : 0.0031342273578047752
Loss at iteration 1150 : 0.0006947859656065702
Loss at iteration 1160 : 0.002269128803163767
Loss at iteration 1170 : 0.0006163952639326453
Loss at iteration 1180 : 5.8764187997439876e-05
Loss at iteration 1190 : 0.006205638404935598
Loss at iteration 1200 : 0.0033696587197482586
Loss at iteration 1210 : 0.0014220759039744735
Loss at iteration 1220 : 0.0019150901352986693
Loss at iteration 1230 : 0.00354613340459764
Loss at iteration 1240 : 0.003680744208395481
Loss at iteration 1250 : 0.0008534049848094583
Loss at iteration 1260 : 0.0034980028867721558
Loss at iteration 1270 : 0.0004633563803508878
Loss at iteration 1280 : 0.0048966072499752045
Loss at iteration 1290 : 0.00021370033209677786
Loss at iteration 1300 : 0.0007622978882864118
Loss at iteration 1310 : 0.00029570914921350777
Loss at iteration 1320 : 0.00116072001401335
Loss at iteration 1330 : 0.0020670529920607805
Loss at iteration 1340 : 0.0003273769107181579
Loss at iteration 1350 : 0.0019694287329912186
Loss at iteration 1360 : 0.00035689573269337416
Loss at iteration 1370 : 0.0015801320550963283
Loss at iteration 1380 : 0.0004265978932380676
Loss at iteration 1390 : 0.0006939860759302974
Loss at iteration 1400 : 0.002824974711984396
Loss at iteration 1410 : 0.0004643782158382237
Loss at iteration 1420 : 0.00021863843721803278
Loss at iteration 1430 : 0.00012564890494104475
Loss at iteration 1440 : 0.00025956102763302624
Loss at iteration 1450 : 0.0012508888030424714
Loss at iteration 1460 : 0.0020363207440823317
Loss at iteration 1470 : 0.0013166810385882854
Loss at iteration 1480 : 0.0004292403464205563
Loss at iteration 1490 : 0.00016826637147460133
Loss at iteration 1500 : 0.00035818153992295265
Loss at iteration 1510 : 0.0005408681463450193
Loss at iteration 1520 : 0.0021572820842266083
Loss at iteration 1530 : 0.0007633987115696073
Loss at iteration 1540 : 0.0027919458225369453
Loss at iteration 1550 : 0.0007765135960653424
Loss at iteration 1560 : 0.001637577428482473
Loss at iteration 1570 : 0.0003603483783081174
Loss at iteration 1580 : 0.0005067243473604321
Loss at iteration 1590 : 0.0026838078629225492
Loss at iteration 1600 : 9.041119483299553e-05
Loss at iteration 1610 : 0.002664934378117323
Loss at iteration 1620 : 0.00030532796517945826
Loss at iteration 1630 : 0.00014513745554722846
Loss at iteration 1640 : 0.00036217900924384594
Loss at iteration 1650 : 0.0033918169792741537
Loss at iteration 1660 : 0.0007587021682411432
Loss at iteration 1670 : 0.0012404409935697913
Loss at iteration 1680 : 0.0001949890865944326
Loss at iteration 1690 : 0.0005242950282990932
Loss at iteration 1700 : 0.0015251473523676395
Loss at iteration 1710 : 0.0005361539078876376
Loss at iteration 1720 : 0.0002922353451140225
Loss at iteration 1730 : 0.004779525566846132
Loss at iteration 1740 : 0.00017210585065186024
Loss at iteration 1750 : 0.0005351315485313535
The SSIM Value is: 0.9825666483147029
The PSNR Value is: 46.57711680240043
the epoch is: 64
Loss at iteration 10 : 0.0014294611755758524
Loss at iteration 20 : 0.0005282338825054467
Loss at iteration 30 : 0.0007595728384330869
Loss at iteration 40 : 0.00010123258107341826
Loss at iteration 50 : 0.00029087564325891435
Loss at iteration 60 : 0.0003155545855406672
Loss at iteration 70 : 0.001407034695148468
Loss at iteration 80 : 0.0002078937104670331
Loss at iteration 90 : 0.0005765116075053811
Loss at iteration 100 : 0.000388367276173085
Loss at iteration 110 : 0.0013557595666497946
Loss at iteration 120 : 7.40107279852964e-05
Loss at iteration 130 : 0.00042735060560517013
Loss at iteration 140 : 0.0005778109189122915
Loss at iteration 150 : 8.617817366030067e-05
Loss at iteration 160 : 0.00022549890854861587
Loss at iteration 170 : 0.000211232720175758
Loss at iteration 180 : 0.00028027762891724706
Loss at iteration 190 : 0.006088780704885721
Loss at iteration 200 : 7.349208317464218e-05
Loss at iteration 210 : 0.00011817509948741645
Loss at iteration 220 : 0.00014085799921303988
Loss at iteration 230 : 0.0004361631872598082
Loss at iteration 240 : 0.0002505121810827404
Loss at iteration 250 : 0.00014823535457253456
Loss at iteration 260 : 0.00018612155690789223
Loss at iteration 270 : 0.00019787259225267917
Loss at iteration 280 : 0.00016837805742397904
Loss at iteration 290 : 0.004824640229344368
Loss at iteration 300 : 0.0001705601462163031
Loss at iteration 310 : 9.411181963514537e-05
Loss at iteration 320 : 0.0003552233974914998
Loss at iteration 330 : 0.0001076985354302451
Loss at iteration 340 : 3.316254878882319e-05
Loss at iteration 350 : 0.0009108698577620089
Loss at iteration 360 : 0.0002273884165333584
Loss at iteration 370 : 0.004327777773141861
Loss at iteration 380 : 0.003271348774433136
Loss at iteration 390 : 0.0001217407188960351
Loss at iteration 400 : 0.00029084147536195815
Loss at iteration 410 : 0.0006697627250105143
Loss at iteration 420 : 0.002755165798589587
Loss at iteration 430 : 0.00010424232459627092
Loss at iteration 440 : 0.0010253251530230045
Loss at iteration 450 : 0.00019365032494533807
Loss at iteration 460 : 0.0008365162648260593
Loss at iteration 470 : 0.002360394923016429
Loss at iteration 480 : 0.0001280533615499735
Loss at iteration 490 : 5.1017086661886424e-05
Loss at iteration 500 : 0.0002165771584259346
Loss at iteration 510 : 0.0006077621364966035
Loss at iteration 520 : 0.0037360815331339836
Loss at iteration 530 : 3.307870065327734e-05
Loss at iteration 540 : 0.004429122898727655
Loss at iteration 550 : 0.0005167797207832336
Loss at iteration 560 : 0.00035440592910163105
Loss at iteration 570 : 0.00032754309359006584
Loss at iteration 580 : 0.0005638694856315851
Loss at iteration 590 : 0.0006259410874918103
Loss at iteration 600 : 0.0002509147161617875
Loss at iteration 610 : 0.0002247414377052337
Loss at iteration 620 : 0.0013457111781463027
Loss at iteration 630 : 0.00034056694130413234
Loss at iteration 640 : 0.0011988356709480286
Loss at iteration 650 : 0.002420002594590187
Loss at iteration 660 : 0.0006934556877240539
Loss at iteration 670 : 0.000583225570153445
Loss at iteration 680 : 0.0006204243982210755
Loss at iteration 690 : 0.0009186548995785415
Loss at iteration 700 : 0.00017964384460356086
Loss at iteration 710 : 6.338154344120994e-05
Loss at iteration 720 : 0.0001295628899242729
Loss at iteration 730 : 0.002390980953350663
Loss at iteration 740 : 0.00021140337048564106
Loss at iteration 750 : 7.397646550089121e-05
Loss at iteration 760 : 0.0003492098185233772
Loss at iteration 770 : 0.0008084675064310431
Loss at iteration 780 : 0.0001240642013726756
Loss at iteration 790 : 0.00029401463689282537
Loss at iteration 800 : 0.0007300203433260322
Loss at iteration 810 : 0.0007072830339893699
Loss at iteration 820 : 0.00013279863924253732
Loss at iteration 830 : 0.002997973235324025
Loss at iteration 840 : 8.764996164245531e-05
Loss at iteration 850 : 0.00036681792698800564
Loss at iteration 860 : 0.000363034923793748
Loss at iteration 870 : 0.000488661287818104
Loss at iteration 880 : 0.0009041138109751046
Loss at iteration 890 : 0.0021687974222004414
Loss at iteration 900 : 0.00039142018067650497
Loss at iteration 910 : 0.0011027297005057335
Loss at iteration 920 : 0.001391738187521696
Loss at iteration 930 : 0.00022583731333725154
Loss at iteration 940 : 0.0004920023493468761
Loss at iteration 950 : 9.883188613457605e-05
Loss at iteration 960 : 0.0007638575625605881
Loss at iteration 970 : 0.0003506967332214117
Loss at iteration 980 : 0.003615285735577345
Loss at iteration 990 : 0.002942057326436043
Loss at iteration 1000 : 0.0009654550231061876
Loss at iteration 1010 : 9.704769763629884e-05
Loss at iteration 1020 : 0.0003436499973759055
Loss at iteration 1030 : 0.0027113943360745907
Loss at iteration 1040 : 0.00015632144641131163
Loss at iteration 1050 : 0.00032698267023079097
Loss at iteration 1060 : 0.0003413147060200572
Loss at iteration 1070 : 0.008976004086434841
Loss at iteration 1080 : 6.819327973062173e-05
Loss at iteration 1090 : 8.263128984253854e-05
Loss at iteration 1100 : 0.00016168091678991914
Loss at iteration 1110 : 0.0002814343897625804
Loss at iteration 1120 : 0.00027784908888861537
Loss at iteration 1130 : 0.0003000778378918767
Loss at iteration 1140 : 0.00012701362720690668
Loss at iteration 1150 : 0.0053156353533267975
Loss at iteration 1160 : 0.00010691221541492268
Loss at iteration 1170 : 0.00013645089347846806
Loss at iteration 1180 : 0.0012190707493573427
Loss at iteration 1190 : 0.0006663906970061362
Loss at iteration 1200 : 0.0010613660560920835
Loss at iteration 1210 : 0.0011298148892819881
Loss at iteration 1220 : 0.005940753035247326
Loss at iteration 1230 : 0.00042801967356354
Loss at iteration 1240 : 0.003719503525644541
Loss at iteration 1250 : 0.000460954790469259
Loss at iteration 1260 : 9.427643817616627e-05
Loss at iteration 1270 : 0.004348880611360073
Loss at iteration 1280 : 0.007145308889448643
Loss at iteration 1290 : 0.00031347048934549093
Loss at iteration 1300 : 0.0002616259444039315
Loss at iteration 1310 : 0.0001340223680017516
Loss at iteration 1320 : 0.00010239897528663278
Loss at iteration 1330 : 0.0015225271927192807
Loss at iteration 1340 : 0.00013355290866456926
Loss at iteration 1350 : 0.00013995259359944612
Loss at iteration 1360 : 0.0002685025683604181
Loss at iteration 1370 : 0.00020956681692041457
Loss at iteration 1380 : 9.40922909649089e-05
Loss at iteration 1390 : 0.00026836933102458715
Loss at iteration 1400 : 5.247359149507247e-05
Loss at iteration 1410 : 0.00037862389581277966
Loss at iteration 1420 : 0.00035113110789097846
Loss at iteration 1430 : 9.45283827604726e-05
Loss at iteration 1440 : 0.00016079354099929333
Loss at iteration 1450 : 0.002655636053532362
Loss at iteration 1460 : 0.00022316821559797972
Loss at iteration 1470 : 4.6634464524686337e-05
Loss at iteration 1480 : 0.0008559506968595088
Loss at iteration 1490 : 0.0033047408796846867
Loss at iteration 1500 : 0.00033796593197621405
Loss at iteration 1510 : 6.656666664639488e-05
Loss at iteration 1520 : 0.00026840606005862355
Loss at iteration 1530 : 0.0001488780544605106
Loss at iteration 1540 : 0.00024022921570576727
Loss at iteration 1550 : 0.00010586282587610185
Loss at iteration 1560 : 0.004087150562554598
Loss at iteration 1570 : 0.0007578037912026048
Loss at iteration 1580 : 0.0006255243206396699
Loss at iteration 1590 : 0.00012652759323827922
Loss at iteration 1600 : 4.1818373574642465e-05
Loss at iteration 1610 : 0.00012030492507619783
Loss at iteration 1620 : 6.523801857838407e-05
Loss at iteration 1630 : 0.001680436311289668
Loss at iteration 1640 : 0.00027751363813877106
Loss at iteration 1650 : 0.0006764421123079956
Loss at iteration 1660 : 0.00036138747236691415
Loss at iteration 1670 : 0.0001462588261347264
Loss at iteration 1680 : 0.0004507016856223345
Loss at iteration 1690 : 0.001661534421145916
Loss at iteration 1700 : 0.00010269076301483437
Loss at iteration 1710 : 0.00038432033034041524
Loss at iteration 1720 : 0.0006222575320862234
Loss at iteration 1730 : 0.0008749075932428241
Loss at iteration 1740 : 0.00013012195995543152
Loss at iteration 1750 : 0.0024325107224285603
The SSIM Value is: 0.9863580370789583
The PSNR Value is: 46.063690500637506
the epoch is: 65
Loss at iteration 10 : 0.0004382785700727254
Loss at iteration 20 : 0.0005683309282176197
Loss at iteration 30 : 0.001266563544049859
Loss at iteration 40 : 0.00043398456182330847
Loss at iteration 50 : 0.0019461710471659899
Loss at iteration 60 : 0.00014470101450569928
Loss at iteration 70 : 0.0008728246320970356
Loss at iteration 80 : 6.070983727113344e-05
Loss at iteration 90 : 0.00045336049515753984
Loss at iteration 100 : 0.002985571511089802
Loss at iteration 110 : 0.0004722787416540086
Loss at iteration 120 : 0.0002273004938615486
Loss at iteration 130 : 0.0002938807010650635
Loss at iteration 140 : 0.004158244002610445
Loss at iteration 150 : 0.0003869496867991984
Loss at iteration 160 : 0.003915829584002495
Loss at iteration 170 : 0.0011668348452076316
Loss at iteration 180 : 0.0007186309667304158
Loss at iteration 190 : 0.0002333225857000798
Loss at iteration 200 : 0.00036001091939397156
Loss at iteration 210 : 0.000560199492610991
Loss at iteration 220 : 0.0002190147206420079
Loss at iteration 230 : 0.002113333670422435
Loss at iteration 240 : 0.0003010147192981094
Loss at iteration 250 : 0.00017588275659363717
Loss at iteration 260 : 8.832825551507995e-05
Loss at iteration 270 : 0.00015545067435596138
Loss at iteration 280 : 7.1782196755521e-05
Loss at iteration 290 : 0.0001953587052412331
Loss at iteration 300 : 0.000357181706931442
Loss at iteration 310 : 0.0019925758242607117
Loss at iteration 320 : 0.0018662628717720509
Loss at iteration 330 : 9.677913476480171e-05
Loss at iteration 340 : 9.22950857784599e-05
Loss at iteration 350 : 0.00013764903997071087
Loss at iteration 360 : 0.00016132737800944597
Loss at iteration 370 : 0.0004229481564834714
Loss at iteration 380 : 0.001116449828259647
Loss at iteration 390 : 0.00025048229144886136
Loss at iteration 400 : 5.6717126426519826e-05
Loss at iteration 410 : 0.00035679026041179895
Loss at iteration 420 : 0.0007620773976668715
Loss at iteration 430 : 0.00012455075921025127
Loss at iteration 440 : 0.0008983585867099464
Loss at iteration 450 : 0.0001729191717458889
Loss at iteration 460 : 0.00020248422515578568
Loss at iteration 470 : 0.002287359908223152
Loss at iteration 480 : 0.00029611456557177007
Loss at iteration 490 : 0.002048117108643055
Loss at iteration 500 : 0.0005206491914577782
Loss at iteration 510 : 0.0002758217160589993
Loss at iteration 520 : 0.0025524545926600695
Loss at iteration 530 : 0.0002627637004479766
Loss at iteration 540 : 0.0003030745720025152
Loss at iteration 550 : 0.0003079198068007827
Loss at iteration 560 : 0.00037386990152299404
Loss at iteration 570 : 0.0010599554516375065
Loss at iteration 580 : 0.004146556835621595
Loss at iteration 590 : 0.001212529488839209
Loss at iteration 600 : 0.0005385418771766126
Loss at iteration 610 : 9.109472739510238e-05
Loss at iteration 620 : 0.003989651799201965
Loss at iteration 630 : 0.0007725426694378257
Loss at iteration 640 : 0.00068344094324857
Loss at iteration 650 : 0.0021495125256478786
Loss at iteration 660 : 0.0007612372282892466
Loss at iteration 670 : 0.00014538731193169951
Loss at iteration 680 : 0.000537825224455446
Loss at iteration 690 : 0.0001221771235577762
Loss at iteration 700 : 0.00044429529225453734
Loss at iteration 710 : 0.00011056294169975445
Loss at iteration 720 : 0.0001994697522604838
Loss at iteration 730 : 0.002147490158677101
Loss at iteration 740 : 0.00022412043472286314
Loss at iteration 750 : 0.0018764975247904658
Loss at iteration 760 : 0.00023339182371273637
Loss at iteration 770 : 0.00011991382052656263
Loss at iteration 780 : 0.00019439026073087007
Loss at iteration 790 : 0.0005120974383316934
Loss at iteration 800 : 0.002132382709532976
Loss at iteration 810 : 0.000716296723112464
Loss at iteration 820 : 0.0002625380293466151
Loss at iteration 830 : 0.004667272791266441
Loss at iteration 840 : 0.0004736350092571229
Loss at iteration 850 : 0.0006114382995292544
Loss at iteration 860 : 0.00039740296779200435
Loss at iteration 870 : 0.0002149136853404343
Loss at iteration 880 : 6.854308594483882e-05
Loss at iteration 890 : 0.0015375278890132904
Loss at iteration 900 : 0.00018748287402559072
Loss at iteration 910 : 0.0009535825229249895
Loss at iteration 920 : 8.206255006371066e-05
Loss at iteration 930 : 0.00017605835455469787
Loss at iteration 940 : 0.00025866847136057913
Loss at iteration 950 : 0.0001693683152552694
Loss at iteration 960 : 0.00010749799548648298
Loss at iteration 970 : 0.000845692993607372
Loss at iteration 980 : 0.00012251608131919056
Loss at iteration 990 : 0.0034741926938295364
Loss at iteration 1000 : 0.0014237213181331754
Loss at iteration 1010 : 0.00015081711171660572
Loss at iteration 1020 : 0.0002508270845282823
Loss at iteration 1030 : 0.004650273360311985
Loss at iteration 1040 : 0.00046280850074253976
Loss at iteration 1050 : 0.002044702647253871
Loss at iteration 1060 : 0.0002303489891346544
Loss at iteration 1070 : 0.0004622460692189634
Loss at iteration 1080 : 0.00013004723587073386
Loss at iteration 1090 : 0.00018749150331132114
Loss at iteration 1100 : 0.002060958184301853
Loss at iteration 1110 : 0.0005529078189283609
Loss at iteration 1120 : 9.817532554734498e-05
Loss at iteration 1130 : 0.0006208611885085702
Loss at iteration 1140 : 0.0014926415169611573
Loss at iteration 1150 : 0.0030295285396277905
Loss at iteration 1160 : 0.0007470041746273637
Loss at iteration 1170 : 0.0010321397567167878
Loss at iteration 1180 : 0.0014124203007668257
Loss at iteration 1190 : 8.190358494175598e-05
Loss at iteration 1200 : 0.0004717819974757731
Loss at iteration 1210 : 0.0022230520844459534
Loss at iteration 1220 : 0.00017353941802866757
Loss at iteration 1230 : 0.0025008353404700756
Loss at iteration 1240 : 0.0038084255065768957
Loss at iteration 1250 : 0.003361394163221121
Loss at iteration 1260 : 8.041279943427071e-05
Loss at iteration 1270 : 0.00046282378025352955
Loss at iteration 1280 : 0.00012776887160725892
Loss at iteration 1290 : 0.0004912605509161949
Loss at iteration 1300 : 0.0021338406950235367
Loss at iteration 1310 : 0.00013951091386843473
Loss at iteration 1320 : 0.00034093111753463745
Loss at iteration 1330 : 0.0004509689169935882
Loss at iteration 1340 : 0.00012041101581417024
Loss at iteration 1350 : 0.00011934254871448502
Loss at iteration 1360 : 0.0005923927528783679
Loss at iteration 1370 : 8.822728705126792e-05
Loss at iteration 1380 : 0.00017017497157212347
Loss at iteration 1390 : 0.003988875541836023
Loss at iteration 1400 : 0.00033348676515743136
Loss at iteration 1410 : 0.002450705273076892
Loss at iteration 1420 : 0.0002865531132556498
Loss at iteration 1430 : 0.0006394572556018829
Loss at iteration 1440 : 0.003951918333768845
Loss at iteration 1450 : 0.00019555602921172976
Loss at iteration 1460 : 0.0017669962253421545
Loss at iteration 1470 : 0.00026404374511912465
Loss at iteration 1480 : 7.85403826739639e-05
Loss at iteration 1490 : 0.002017781836912036
Loss at iteration 1500 : 0.00023394216259475797
Loss at iteration 1510 : 0.0015341599937528372
Loss at iteration 1520 : 4.1862404032144696e-05
Loss at iteration 1530 : 0.0038325125351548195
Loss at iteration 1540 : 0.000303467211779207
Loss at iteration 1550 : 0.00041451846482232213
Loss at iteration 1560 : 0.008303399197757244
Loss at iteration 1570 : 0.0008537177927792072
Loss at iteration 1580 : 0.00014969383482821286
Loss at iteration 1590 : 0.00013625914289150387
Loss at iteration 1600 : 0.002972495974972844
Loss at iteration 1610 : 0.0031109193805605173
Loss at iteration 1620 : 0.0012622856302186847
Loss at iteration 1630 : 0.0009273586329072714
Loss at iteration 1640 : 0.00011376824113540351
Loss at iteration 1650 : 0.000430400890763849
Loss at iteration 1660 : 0.00010957274935208261
Loss at iteration 1670 : 9.28815352381207e-05
Loss at iteration 1680 : 0.0016356336418539286
Loss at iteration 1690 : 0.0004896269529126585
Loss at iteration 1700 : 0.0010741886217147112
Loss at iteration 1710 : 0.00018568833183962852
Loss at iteration 1720 : 0.00023456047347281128
Loss at iteration 1730 : 0.00023662287276238203
Loss at iteration 1740 : 0.00011154050298500806
Loss at iteration 1750 : 0.0009194257436320186
The SSIM Value is: 0.984521280826451
The PSNR Value is: 46.478014244382074
the epoch is: 66
Loss at iteration 10 : 0.000307607464492321
Loss at iteration 20 : 0.0005659002345055342
Loss at iteration 30 : 0.00047758512664586306
Loss at iteration 40 : 0.00036199044552631676
Loss at iteration 50 : 0.002338192891329527
Loss at iteration 60 : 0.00030741377850063145
Loss at iteration 70 : 0.0005560005083680153
Loss at iteration 80 : 0.002980902325361967
Loss at iteration 90 : 0.0001790064270608127
Loss at iteration 100 : 0.0005831713788211346
Loss at iteration 110 : 0.00017563981236889958
Loss at iteration 120 : 0.00045278703328222036
Loss at iteration 130 : 0.0008031644392758608
Loss at iteration 140 : 0.00065436220029369
Loss at iteration 150 : 0.0009351323824375868
Loss at iteration 160 : 0.002595377154648304
Loss at iteration 170 : 0.00030283533851616085
Loss at iteration 180 : 0.00045676005538553
Loss at iteration 190 : 0.0006714460323564708
Loss at iteration 200 : 0.002140879398211837
Loss at iteration 210 : 0.0004336033307481557
Loss at iteration 220 : 0.00013848234084434807
Loss at iteration 230 : 0.004781108349561691
Loss at iteration 240 : 0.0025986838154494762
Loss at iteration 250 : 0.00628327950835228
Loss at iteration 260 : 0.00017611488874536008
Loss at iteration 270 : 0.00010414974531158805
Loss at iteration 280 : 0.0002888719318434596
Loss at iteration 290 : 0.00012075361155439168
Loss at iteration 300 : 0.000592693337239325
Loss at iteration 310 : 0.0006239915965124965
Loss at iteration 320 : 0.0006815619999542832
Loss at iteration 330 : 0.0002767903497442603
Loss at iteration 340 : 0.0012502913596108556
Loss at iteration 350 : 0.00010269858466926962
Loss at iteration 360 : 0.0017870147712528706
Loss at iteration 370 : 4.381797043606639e-05
Loss at iteration 380 : 0.0026023895479738712
Loss at iteration 390 : 8.79606232047081e-05
Loss at iteration 400 : 0.0005237619625404477
Loss at iteration 410 : 0.0005616004345938563
Loss at iteration 420 : 0.002352523384615779
Loss at iteration 430 : 0.00028463301714509726
Loss at iteration 440 : 5.310837150318548e-05
Loss at iteration 450 : 0.000659127370454371
Loss at iteration 460 : 6.453032983699813e-05
Loss at iteration 470 : 0.00030287299887277186
Loss at iteration 480 : 0.0008976972894743085
Loss at iteration 490 : 0.008519718423485756
Loss at iteration 500 : 0.0013487725518643856
Loss at iteration 510 : 0.00169078737962991
Loss at iteration 520 : 0.003627500031143427
Loss at iteration 530 : 0.00018817985255736858
Loss at iteration 540 : 0.0014053033664822578
Loss at iteration 550 : 0.00017505272990092635
Loss at iteration 560 : 0.0002848383446689695
Loss at iteration 570 : 6.600084452657029e-05
Loss at iteration 580 : 0.0020431228913366795
Loss at iteration 590 : 0.0003008351777680218
Loss at iteration 600 : 5.2556431910488755e-05
Loss at iteration 610 : 0.0001702569570625201
Loss at iteration 620 : 0.0009107200312428176
Loss at iteration 630 : 0.0006983130588196218
Loss at iteration 640 : 0.0017083501443266869
Loss at iteration 650 : 0.0001350039674434811
Loss at iteration 660 : 0.0002653774281498045
Loss at iteration 670 : 0.00016324702301062644
Loss at iteration 680 : 0.006370761897414923
Loss at iteration 690 : 0.000280953710898757
Loss at iteration 700 : 0.0021775560453534126
Loss at iteration 710 : 0.00033566015190444887
Loss at iteration 720 : 0.0030512071680277586
Loss at iteration 730 : 0.00042838387889787555
Loss at iteration 740 : 6.635858881054446e-05
Loss at iteration 750 : 0.0006511996616609395
Loss at iteration 760 : 0.00046131203998811543
Loss at iteration 770 : 0.00011972952779615298
Loss at iteration 780 : 0.00010077205661218613
Loss at iteration 790 : 0.000297120917821303
Loss at iteration 800 : 0.00018595048459246755
Loss at iteration 810 : 0.0001967084244824946
Loss at iteration 820 : 0.0014092307537794113
Loss at iteration 830 : 3.4401618904666975e-05
Loss at iteration 840 : 0.00025819000438787043
Loss at iteration 850 : 0.00015386674203909934
Loss at iteration 860 : 0.001409728778526187
Loss at iteration 870 : 0.0001895445166155696
Loss at iteration 880 : 0.0001959118089871481
Loss at iteration 890 : 0.00032256063423119485
Loss at iteration 900 : 0.0050085545517504215
Loss at iteration 910 : 0.0023025318514555693
Loss at iteration 920 : 0.001358249457553029
Loss at iteration 930 : 0.00018959472072310746
Loss at iteration 940 : 9.757424413692206e-05
Loss at iteration 950 : 0.0006144557846710086
Loss at iteration 960 : 0.0008793190354481339
Loss at iteration 970 : 0.008694865740835667
Loss at iteration 980 : 0.0002004773705266416
Loss at iteration 990 : 0.0001837618328863755
Loss at iteration 1000 : 0.001624682336114347
Loss at iteration 1010 : 0.0010264372685924172
Loss at iteration 1020 : 0.0020614678505808115
Loss at iteration 1030 : 7.765994087094441e-05
Loss at iteration 1040 : 0.0008269750978797674
Loss at iteration 1050 : 0.0001309982326347381
Loss at iteration 1060 : 0.00019189529120922089
Loss at iteration 1070 : 0.00042483588913455606
Loss at iteration 1080 : 0.003105407115072012
Loss at iteration 1090 : 0.00011298682511551306
Loss at iteration 1100 : 0.0016702954890206456
Loss at iteration 1110 : 0.00016561325173825026
Loss at iteration 1120 : 0.0010188424494117498
Loss at iteration 1130 : 0.0008400533115491271
Loss at iteration 1140 : 0.00104546919465065
Loss at iteration 1150 : 0.0002014212659560144
Loss at iteration 1160 : 0.002965884516015649
Loss at iteration 1170 : 0.0005508812027983367
Loss at iteration 1180 : 0.00010774790280265734
Loss at iteration 1190 : 0.0007415737491101027
Loss at iteration 1200 : 0.001254607574082911
Loss at iteration 1210 : 0.0001280357682844624
Loss at iteration 1220 : 0.0048426357097923756
Loss at iteration 1230 : 0.00025624706177040935
Loss at iteration 1240 : 0.0001843171485234052
Loss at iteration 1250 : 0.0012423937441781163
Loss at iteration 1260 : 0.002479124115779996
Loss at iteration 1270 : 0.00014961493434384465
Loss at iteration 1280 : 0.0003416177351027727
Loss at iteration 1290 : 0.0004578470252454281
Loss at iteration 1300 : 0.0060378191992640495
Loss at iteration 1310 : 0.00010360448504798114
Loss at iteration 1320 : 0.00015266562695614994
Loss at iteration 1330 : 0.0033343578688800335
Loss at iteration 1340 : 0.0001600677496753633
Loss at iteration 1350 : 0.001623613527044654
Loss at iteration 1360 : 0.00014674167323391885
Loss at iteration 1370 : 0.00017971517809201032
Loss at iteration 1380 : 0.0005596072878688574
Loss at iteration 1390 : 0.0012070348020642996
Loss at iteration 1400 : 0.005354355555027723
Loss at iteration 1410 : 0.0043077426962554455
Loss at iteration 1420 : 0.0003583916986826807
Loss at iteration 1430 : 0.0001990582823054865
Loss at iteration 1440 : 0.0008102911524474621
Loss at iteration 1450 : 7.957799971336499e-05
Loss at iteration 1460 : 0.002487435471266508
Loss at iteration 1470 : 0.0003847031621262431
Loss at iteration 1480 : 0.0008651011157780886
Loss at iteration 1490 : 0.0006597050232812762
Loss at iteration 1500 : 0.002373656490817666
Loss at iteration 1510 : 0.0003780593106057495
Loss at iteration 1520 : 0.00046036706771701574
Loss at iteration 1530 : 0.00035182840656489134
Loss at iteration 1540 : 0.00038471492007374763
Loss at iteration 1550 : 5.2012775995535776e-05
Loss at iteration 1560 : 6.381420098477975e-05
Loss at iteration 1570 : 0.0001301070733461529
Loss at iteration 1580 : 0.00021654916054103523
Loss at iteration 1590 : 9.190924902213737e-05
Loss at iteration 1600 : 0.01179065927863121
Loss at iteration 1610 : 0.0001464374945499003
Loss at iteration 1620 : 0.00032714358530938625
Loss at iteration 1630 : 0.0008589505450800061
Loss at iteration 1640 : 8.155396790243685e-05
Loss at iteration 1650 : 0.0010732245864346623
Loss at iteration 1660 : 0.00042319472413510084
Loss at iteration 1670 : 0.0017006534617394209
Loss at iteration 1680 : 0.0003031474188901484
Loss at iteration 1690 : 0.00025791377993300557
Loss at iteration 1700 : 0.0018357766093686223
Loss at iteration 1710 : 0.0024867078755050898
Loss at iteration 1720 : 0.0018516342388466
Loss at iteration 1730 : 0.00021006650058552623
Loss at iteration 1740 : 0.0003011885564774275
Loss at iteration 1750 : 0.0003982221242040396
The SSIM Value is: 0.9870726715625645
The PSNR Value is: 46.785991561570356
the highest SSIM value is: 46.785991561570356
the epoch is: 67
Loss at iteration 10 : 0.0008681800100021064
Loss at iteration 20 : 0.0003057651047129184
Loss at iteration 30 : 0.00019290186173748225
Loss at iteration 40 : 0.00047371938126161695
Loss at iteration 50 : 0.00016715923266019672
Loss at iteration 60 : 0.0012545149074867368
Loss at iteration 70 : 0.0005615269765257835
Loss at iteration 80 : 0.0005379946087487042
Loss at iteration 90 : 0.0004784242482855916
Loss at iteration 100 : 0.0028720288537442684
Loss at iteration 110 : 0.00027908943593502045
Loss at iteration 120 : 8.072112541412935e-05
Loss at iteration 130 : 0.00010734365787357092
Loss at iteration 140 : 0.0003029653453268111
Loss at iteration 150 : 0.0003590956039261073
Loss at iteration 160 : 0.0005283157806843519
Loss at iteration 170 : 8.821256051305681e-05
Loss at iteration 180 : 0.00010861914051929489
Loss at iteration 190 : 0.00013515213504433632
Loss at iteration 200 : 0.0024014536757022142
Loss at iteration 210 : 0.00032136242953129113
Loss at iteration 220 : 0.0013611310860142112
Loss at iteration 230 : 0.001304789213463664
Loss at iteration 240 : 0.0031760940328240395
Loss at iteration 250 : 0.0012163834180682898
Loss at iteration 260 : 0.0021540476009249687
Loss at iteration 270 : 0.00047669687774032354
Loss at iteration 280 : 0.0006346150767058134
Loss at iteration 290 : 0.0009508365765213966
Loss at iteration 300 : 0.0010930700227618217
Loss at iteration 310 : 0.00011441780952736735
Loss at iteration 320 : 0.00011132154031656682
Loss at iteration 330 : 0.0002900713006965816
Loss at iteration 340 : 0.00043026485946029425
Loss at iteration 350 : 0.0018746426794677973
Loss at iteration 360 : 0.00010762627061922103
Loss at iteration 370 : 0.003001991892233491
Loss at iteration 380 : 0.00029214544338174164
Loss at iteration 390 : 0.0002265878429170698
Loss at iteration 400 : 0.0012157006422057748
Loss at iteration 410 : 0.011991890147328377
Loss at iteration 420 : 0.0031778786797076464
Loss at iteration 430 : 0.0003775330842472613
Loss at iteration 440 : 0.00016718708502594382
Loss at iteration 450 : 0.0002512237406335771
Loss at iteration 460 : 0.005756364203989506
Loss at iteration 470 : 0.00017191970255225897
Loss at iteration 480 : 0.0016636704094707966
Loss at iteration 490 : 0.0005982659058645368
Loss at iteration 500 : 0.00041951268212869763
Loss at iteration 510 : 0.0010725229512900114
Loss at iteration 520 : 0.0001568343723192811
Loss at iteration 530 : 3.305546852061525e-05
Loss at iteration 540 : 0.0011969483457505703
Loss at iteration 550 : 8.728548709768802e-05
Loss at iteration 560 : 0.0036164966877549887
Loss at iteration 570 : 0.0001757274876581505
Loss at iteration 580 : 0.0004505785182118416
Loss at iteration 590 : 0.00019811018137261271
Loss at iteration 600 : 0.0001557151263114065
Loss at iteration 610 : 0.00012976687867194414
Loss at iteration 620 : 0.00016092945588752627
Loss at iteration 630 : 0.0003009496722370386
Loss at iteration 640 : 0.0028933254070580006
Loss at iteration 650 : 0.0005039426614530385
Loss at iteration 660 : 0.00013128465798217803
Loss at iteration 670 : 0.00023078735102899373
Loss at iteration 680 : 0.0032095685601234436
Loss at iteration 690 : 6.155695882625878e-05
Loss at iteration 700 : 0.0004748823994304985
Loss at iteration 710 : 5.2512110414681956e-05
Loss at iteration 720 : 0.00019617547513917089
Loss at iteration 730 : 0.0020238724537193775
Loss at iteration 740 : 6.85388658894226e-05
Loss at iteration 750 : 0.0012834840454161167
Loss at iteration 760 : 0.0005754217272624373
Loss at iteration 770 : 0.00011119521514046937
Loss at iteration 780 : 0.0001934296451508999
Loss at iteration 790 : 0.00039714708691462874
Loss at iteration 800 : 0.0001775746641214937
Loss at iteration 810 : 0.001998813357204199
Loss at iteration 820 : 0.0035827604588121176
Loss at iteration 830 : 0.000504687603097409
Loss at iteration 840 : 0.00036810035817325115
Loss at iteration 850 : 0.0014227763749659061
Loss at iteration 860 : 0.00012803160643670708
Loss at iteration 870 : 0.00027019233675673604
Loss at iteration 880 : 5.5381427955580875e-05
Loss at iteration 890 : 0.00013144980766810477
Loss at iteration 900 : 0.00011028561129933223
Loss at iteration 910 : 0.0007764628971926868
Loss at iteration 920 : 0.0012057311832904816
Loss at iteration 930 : 0.0005394045729190111
Loss at iteration 940 : 0.00025307160103693604
Loss at iteration 950 : 0.0006015736144036055
Loss at iteration 960 : 0.00021086765627842396
Loss at iteration 970 : 9.476006380282342e-05
Loss at iteration 980 : 9.542269981466234e-05
Loss at iteration 990 : 0.00018015368550550193
Loss at iteration 1000 : 0.0009402991272509098
Loss at iteration 1010 : 0.0006738095544278622
Loss at iteration 1020 : 0.006025363691151142
Loss at iteration 1030 : 0.002129672560840845
Loss at iteration 1040 : 0.002862716093659401
Loss at iteration 1050 : 0.00012775450886692852
Loss at iteration 1060 : 0.0006280402885749936
Loss at iteration 1070 : 0.000343620078638196
Loss at iteration 1080 : 0.003891163971275091
Loss at iteration 1090 : 0.0002062296844087541
Loss at iteration 1100 : 0.00281264865770936
Loss at iteration 1110 : 0.00010122679668711498
Loss at iteration 1120 : 0.0004862628993578255
Loss at iteration 1130 : 0.00011361134238541126
Loss at iteration 1140 : 0.0009019389399327338
Loss at iteration 1150 : 0.0007030015112832189
Loss at iteration 1160 : 0.0004937453777529299
Loss at iteration 1170 : 0.00276006362400949
Loss at iteration 1180 : 5.7439523516222835e-05
Loss at iteration 1190 : 9.801865235203877e-05
Loss at iteration 1200 : 0.002568267984315753
Loss at iteration 1210 : 0.0001674606028245762
Loss at iteration 1220 : 0.0004869911936111748
Loss at iteration 1230 : 0.0009165186202153563
Loss at iteration 1240 : 0.00013418556773103774
Loss at iteration 1250 : 0.00011230307427467778
Loss at iteration 1260 : 0.00031082017812877893
Loss at iteration 1270 : 0.0003863552410621196
Loss at iteration 1280 : 0.00040975259616971016
Loss at iteration 1290 : 0.00032367900712415576
Loss at iteration 1300 : 0.0005211857496760786
Loss at iteration 1310 : 0.00011698240268742666
Loss at iteration 1320 : 0.0027109398506581783
Loss at iteration 1330 : 0.00045553239760920405
Loss at iteration 1340 : 0.0004939361242577434
Loss at iteration 1350 : 0.0063553000800311565
Loss at iteration 1360 : 0.0005949557526037097
Loss at iteration 1370 : 7.468075637007132e-05
Loss at iteration 1380 : 0.0010003490606322885
Loss at iteration 1390 : 9.818986291065812e-05
Loss at iteration 1400 : 0.0002715337323024869
Loss at iteration 1410 : 0.0005376648623496294
Loss at iteration 1420 : 0.000291197095066309
Loss at iteration 1430 : 7.482607907149941e-05
Loss at iteration 1440 : 0.0002172119275201112
Loss at iteration 1450 : 0.0002147420309484005
Loss at iteration 1460 : 0.0004815227002836764
Loss at iteration 1470 : 0.0003890573570970446
Loss at iteration 1480 : 0.00010060802742373198
Loss at iteration 1490 : 0.0035033205058425665
Loss at iteration 1500 : 0.0025096090976148844
Loss at iteration 1510 : 0.0012119692983105779
Loss at iteration 1520 : 0.00017738484893925488
Loss at iteration 1530 : 0.004278494045138359
Loss at iteration 1540 : 0.00011109615297755226
Loss at iteration 1550 : 0.0071005867794156075
Loss at iteration 1560 : 0.0016491436399519444
Loss at iteration 1570 : 0.004632593132555485
Loss at iteration 1580 : 0.000501345144584775
Loss at iteration 1590 : 0.0033795477356761694
Loss at iteration 1600 : 0.0029154482763260603
Loss at iteration 1610 : 0.0004836930020246655
Loss at iteration 1620 : 0.00018433887453284115
Loss at iteration 1630 : 0.00010195901995757595
Loss at iteration 1640 : 0.0005545449093915522
Loss at iteration 1650 : 0.00016170725575648248
Loss at iteration 1660 : 0.002551200333982706
Loss at iteration 1670 : 0.002451582346111536
Loss at iteration 1680 : 0.0036400449462234974
Loss at iteration 1690 : 0.0002144526515621692
Loss at iteration 1700 : 0.0007490693242289126
Loss at iteration 1710 : 0.000660229183267802
Loss at iteration 1720 : 0.005264888983219862
Loss at iteration 1730 : 4.926117617287673e-05
Loss at iteration 1740 : 0.0004128344007767737
Loss at iteration 1750 : 7.161391113186255e-05
The SSIM Value is: 0.9854315372290591
The PSNR Value is: 46.73577520815812
the epoch is: 68
Loss at iteration 10 : 0.0025771406944841146
Loss at iteration 20 : 0.00014414623728953302
Loss at iteration 30 : 0.00010628989548422396
Loss at iteration 40 : 0.00012890280049759895
Loss at iteration 50 : 0.0028034686110913754
Loss at iteration 60 : 0.00029614585218951106
Loss at iteration 70 : 0.000198805020772852
Loss at iteration 80 : 0.0014960106927901506
Loss at iteration 90 : 0.002526775933802128
Loss at iteration 100 : 5.4486547014676034e-05
Loss at iteration 110 : 0.0001578368537593633
Loss at iteration 120 : 0.0001317164715146646
Loss at iteration 130 : 0.00010352185199735686
Loss at iteration 140 : 0.0010014246217906475
Loss at iteration 150 : 0.0039175269193947315
Loss at iteration 160 : 0.0003217100165784359
Loss at iteration 170 : 5.028294617659412e-05
Loss at iteration 180 : 0.0001381739421049133
Loss at iteration 190 : 0.003430016804486513
Loss at iteration 200 : 0.001209607464261353
Loss at iteration 210 : 0.0003703596885316074
Loss at iteration 220 : 0.00452467380091548
Loss at iteration 230 : 0.0002013684861594811
Loss at iteration 240 : 0.0001776121207512915
Loss at iteration 250 : 0.0012060949811711907
Loss at iteration 260 : 0.00010073691373690963
Loss at iteration 270 : 0.00010940865468000993
Loss at iteration 280 : 0.00023532880004495382
Loss at iteration 290 : 0.00013159519585315138
Loss at iteration 300 : 0.0003868253552354872
Loss at iteration 310 : 0.0004919175989925861
Loss at iteration 320 : 0.003100777044892311
Loss at iteration 330 : 0.00030514312675222754
Loss at iteration 340 : 5.5440534197259694e-05
Loss at iteration 350 : 0.0001356462889816612
Loss at iteration 360 : 0.002036377089098096
Loss at iteration 370 : 0.00017313072748947889
Loss at iteration 380 : 0.0010479438351467252
Loss at iteration 390 : 0.00047261896543204784
Loss at iteration 400 : 0.000201986069441773
Loss at iteration 410 : 0.000317814527079463
Loss at iteration 420 : 0.0007771393284201622
Loss at iteration 430 : 0.00010886236123042181
Loss at iteration 440 : 0.00014167117478791624
Loss at iteration 450 : 4.03289232053794e-05
Loss at iteration 460 : 0.006330094300210476
Loss at iteration 470 : 0.0022879471071064472
Loss at iteration 480 : 0.00013753089297097176
Loss at iteration 490 : 5.7348133850609884e-05
Loss at iteration 500 : 0.004884301219135523
Loss at iteration 510 : 0.000546809344086796
Loss at iteration 520 : 0.005398128647357225
Loss at iteration 530 : 9.878196578938514e-05
Loss at iteration 540 : 0.00014144252054393291
Loss at iteration 550 : 0.0002572744560893625
Loss at iteration 560 : 0.0001405091752531007
Loss at iteration 570 : 0.00225659878924489
Loss at iteration 580 : 0.0007474601734429598
Loss at iteration 590 : 0.0014358244370669127
Loss at iteration 600 : 0.00012045911716995761
Loss at iteration 610 : 0.00030312733724713326
Loss at iteration 620 : 0.001249645254574716
Loss at iteration 630 : 0.002635735087096691
Loss at iteration 640 : 0.00010036319145001471
Loss at iteration 650 : 0.0001810829562600702
Loss at iteration 660 : 0.0010273652151226997
Loss at iteration 670 : 0.0003815132658928633
Loss at iteration 680 : 0.00019996572518721223
Loss at iteration 690 : 0.0002806356642395258
Loss at iteration 700 : 0.003713090904057026
Loss at iteration 710 : 0.0068695079535245895
Loss at iteration 720 : 0.00010883999493671581
Loss at iteration 730 : 0.0001961188536370173
Loss at iteration 740 : 0.0002763474185485393
Loss at iteration 750 : 0.0009423031006008387
Loss at iteration 760 : 0.0006759088137187064
Loss at iteration 770 : 0.00015870244533289224
Loss at iteration 780 : 0.0032497604843229055
Loss at iteration 790 : 0.0004150813037995249
Loss at iteration 800 : 0.00016046832024585456
Loss at iteration 810 : 0.000493196421302855
Loss at iteration 820 : 0.0033625783398747444
Loss at iteration 830 : 0.00025884099886752665
Loss at iteration 840 : 0.00017450028099119663
Loss at iteration 850 : 0.0001477133046137169
Loss at iteration 860 : 0.0005749173578806221
Loss at iteration 870 : 0.004267442971467972
Loss at iteration 880 : 0.00030821372638456523
Loss at iteration 890 : 0.0012726382119581103
Loss at iteration 900 : 0.0025596118066459894
Loss at iteration 910 : 0.0002449480816721916
Loss at iteration 920 : 0.002237682929262519
Loss at iteration 930 : 0.0008479568059556186
Loss at iteration 940 : 0.00011119586997665465
Loss at iteration 950 : 0.0018509235233068466
Loss at iteration 960 : 0.00048431576578877866
Loss at iteration 970 : 0.0022528590634465218
Loss at iteration 980 : 0.0009354763897135854
Loss at iteration 990 : 9.434920502826571e-05
Loss at iteration 1000 : 0.0029201076831668615
Loss at iteration 1010 : 0.007628313731402159
Loss at iteration 1020 : 0.00018967327196151018
Loss at iteration 1030 : 6.468572973972186e-05
Loss at iteration 1040 : 0.00010694169031921774
Loss at iteration 1050 : 0.0003982589696533978
Loss at iteration 1060 : 0.0001996666833292693
Loss at iteration 1070 : 0.00021828501485288143
Loss at iteration 1080 : 0.00010203660349361598
Loss at iteration 1090 : 0.00013371479872148484
Loss at iteration 1100 : 0.0002644265769049525
Loss at iteration 1110 : 0.003190909046679735
Loss at iteration 1120 : 0.0006520330207422376
Loss at iteration 1130 : 0.0003461233281996101
Loss at iteration 1140 : 0.001565549406222999
Loss at iteration 1150 : 0.003146815812215209
Loss at iteration 1160 : 0.0011143137235194445
Loss at iteration 1170 : 0.0003741187392733991
Loss at iteration 1180 : 0.00025060033658519387
Loss at iteration 1190 : 0.0004626583540812135
Loss at iteration 1200 : 0.0006800713017582893
Loss at iteration 1210 : 0.0010739598656073213
Loss at iteration 1220 : 0.00011570479546207935
Loss at iteration 1230 : 0.0007100135553628206
Loss at iteration 1240 : 0.0005320360651239753
Loss at iteration 1250 : 0.0021502512972801924
Loss at iteration 1260 : 0.001985396258533001
Loss at iteration 1270 : 0.00013896555174142122
Loss at iteration 1280 : 0.00018832051136996597
Loss at iteration 1290 : 0.0005016946815885603
Loss at iteration 1300 : 0.0035252710804343224
Loss at iteration 1310 : 0.0004875835729762912
Loss at iteration 1320 : 0.0001103289396269247
Loss at iteration 1330 : 0.00011347196414135396
Loss at iteration 1340 : 0.00016667605086695403
Loss at iteration 1350 : 0.0033210108522325754
Loss at iteration 1360 : 7.019445911282673e-05
Loss at iteration 1370 : 0.00023047177819535136
Loss at iteration 1380 : 0.002096780575811863
Loss at iteration 1390 : 0.00015715399058535695
Loss at iteration 1400 : 0.0009428036864846945
Loss at iteration 1410 : 0.00020264467457309365
Loss at iteration 1420 : 9.703690011519939e-05
Loss at iteration 1430 : 0.0009023047750815749
Loss at iteration 1440 : 0.0030250507406890392
Loss at iteration 1450 : 0.002907360205426812
Loss at iteration 1460 : 8.996203541755676e-05
Loss at iteration 1470 : 6.979545287322253e-05
Loss at iteration 1480 : 0.00025900531909428537
Loss at iteration 1490 : 0.000377790245693177
Loss at iteration 1500 : 8.894651546142995e-05
Loss at iteration 1510 : 7.053230365272611e-05
Loss at iteration 1520 : 0.00014480462414212525
Loss at iteration 1530 : 0.0025463951751589775
Loss at iteration 1540 : 0.0003452683158684522
Loss at iteration 1550 : 0.006004077382385731
Loss at iteration 1560 : 0.0002964204759337008
Loss at iteration 1570 : 0.00011011491005774587
Loss at iteration 1580 : 0.00039462410495616496
Loss at iteration 1590 : 0.00019467853417154402
Loss at iteration 1600 : 0.00032545271096751094
Loss at iteration 1610 : 0.00033426505979150534
Loss at iteration 1620 : 0.0028380658477544785
Loss at iteration 1630 : 0.0002957159304060042
Loss at iteration 1640 : 0.00020728213712573051
Loss at iteration 1650 : 0.0002432131441310048
Loss at iteration 1660 : 0.00030380269163288176
Loss at iteration 1670 : 0.0011979197151958942
Loss at iteration 1680 : 0.00027655783924274147
Loss at iteration 1690 : 0.00040000869194045663
Loss at iteration 1700 : 0.0007682825671508908
Loss at iteration 1710 : 0.00011974963854299858
Loss at iteration 1720 : 0.00012800429249182343
Loss at iteration 1730 : 0.0017476568464189768
Loss at iteration 1740 : 0.0007942637894302607
Loss at iteration 1750 : 0.0011618474964052439
The SSIM Value is: 0.9834928449555116
The PSNR Value is: 46.66446038804916
the epoch is: 69
Loss at iteration 10 : 0.00016938279441092163
Loss at iteration 20 : 0.00018745684064924717
Loss at iteration 30 : 0.00013117498019710183
Loss at iteration 40 : 0.00022985739633440971
Loss at iteration 50 : 0.00013406004291027784
Loss at iteration 60 : 0.0002935814263764769
Loss at iteration 70 : 0.0006291174795478582
Loss at iteration 80 : 0.003482420928776264
Loss at iteration 90 : 0.0016796189593151212
Loss at iteration 100 : 0.00011669551895465702
Loss at iteration 110 : 0.00150865048635751
Loss at iteration 120 : 9.858296834863722e-05
Loss at iteration 130 : 0.0001361140311928466
Loss at iteration 140 : 0.0013408155646175146
Loss at iteration 150 : 0.0021996647119522095
Loss at iteration 160 : 0.0013590771704912186
Loss at iteration 170 : 9.629714622860774e-05
Loss at iteration 180 : 0.00022333550441544503
Loss at iteration 190 : 0.0002324242959730327
Loss at iteration 200 : 0.003765930887311697
Loss at iteration 210 : 0.0025605594273656607
Loss at iteration 220 : 0.00032680403091944754
Loss at iteration 230 : 0.00016908680845517665
Loss at iteration 240 : 0.000260731962043792
Loss at iteration 250 : 0.0004211464256513864
Loss at iteration 260 : 0.0040092612616717815
Loss at iteration 270 : 0.00010008703247876838
Loss at iteration 280 : 0.0010019908659160137
Loss at iteration 290 : 0.004490169696509838
Loss at iteration 300 : 0.00019013058044947684
Loss at iteration 310 : 0.00043329299660399556
Loss at iteration 320 : 0.0002893615164794028
Loss at iteration 330 : 0.0018969648517668247
Loss at iteration 340 : 0.0012694529723376036
Loss at iteration 350 : 0.00023652665549889207
Loss at iteration 360 : 0.0005183406174182892
Loss at iteration 370 : 0.0004575669881887734
Loss at iteration 380 : 0.00023429948487319052
Loss at iteration 390 : 0.00015929207438603044
Loss at iteration 400 : 8.327254181494936e-05
Loss at iteration 410 : 0.0007531916489824653
Loss at iteration 420 : 0.001011023879982531
Loss at iteration 430 : 0.000879739411175251
Loss at iteration 440 : 0.0035292282700538635
Loss at iteration 450 : 0.003673563478514552
Loss at iteration 460 : 0.000429086503572762
Loss at iteration 470 : 0.0001875012821983546
Loss at iteration 480 : 0.00014039617963135242
Loss at iteration 490 : 0.00022205268032848835
Loss at iteration 500 : 0.0003572572604753077
Loss at iteration 510 : 0.0007007421227172017
Loss at iteration 520 : 0.00026981113478541374
Loss at iteration 530 : 0.0032671517692506313
Loss at iteration 540 : 0.00014487517182715237
Loss at iteration 550 : 0.00020677148131653666
Loss at iteration 560 : 0.000489156402181834
Loss at iteration 570 : 6.363802094710991e-05
Loss at iteration 580 : 0.00010711607319535688
Loss at iteration 590 : 0.00012132875417592004
Loss at iteration 600 : 0.0040317103266716
Loss at iteration 610 : 0.00034685255377553403
Loss at iteration 620 : 0.000284158973954618
Loss at iteration 630 : 0.00024611479602754116
Loss at iteration 640 : 0.00024345760175492615
Loss at iteration 650 : 0.001401514746248722
Loss at iteration 660 : 0.0008643664186820388
Loss at iteration 670 : 0.0005916525260545313
Loss at iteration 680 : 0.0002015666977968067
Loss at iteration 690 : 0.0004193643981125206
Loss at iteration 700 : 0.0030572067480534315
Loss at iteration 710 : 0.00013636819494422525
Loss at iteration 720 : 0.0002946415916085243
Loss at iteration 730 : 0.0003482373140286654
Loss at iteration 740 : 0.0024121874012053013
Loss at iteration 750 : 0.0010343518806621432
Loss at iteration 760 : 0.0001288605126319453
Loss at iteration 770 : 0.0024714027531445026
Loss at iteration 780 : 0.0003909546649083495
Loss at iteration 790 : 0.0003029309445992112
Loss at iteration 800 : 0.0005978366825729609
Loss at iteration 810 : 0.0001488086418248713
Loss at iteration 820 : 0.0014191854279488325
Loss at iteration 830 : 6.335810758173466e-05
Loss at iteration 840 : 0.0003258545184507966
Loss at iteration 850 : 0.000748842372559011
Loss at iteration 860 : 0.0028782091103494167
Loss at iteration 870 : 0.0002405566192464903
Loss at iteration 880 : 0.00015014305245131254
Loss at iteration 890 : 0.0006096179131418467
Loss at iteration 900 : 0.00585172651335597
Loss at iteration 910 : 0.0005747126415371895
Loss at iteration 920 : 0.0014571337960660458
Loss at iteration 930 : 0.00034835946280509233
Loss at iteration 940 : 0.00020107056479901075
Loss at iteration 950 : 0.00056453823344782
Loss at iteration 960 : 0.0010893449652940035
Loss at iteration 970 : 0.002140787895768881
Loss at iteration 980 : 5.830875306855887e-05
Loss at iteration 990 : 0.00020664054318331182
Loss at iteration 1000 : 0.00037406457704491913
Loss at iteration 1010 : 6.922691682120785e-05
Loss at iteration 1020 : 0.0010912353172898293
Loss at iteration 1030 : 0.00032266712514683604
Loss at iteration 1040 : 0.0032047296408563852
Loss at iteration 1050 : 0.00036998873110860586
Loss at iteration 1060 : 0.001673053833656013
Loss at iteration 1070 : 6.576220039278269e-05
Loss at iteration 1080 : 0.0003217831254005432
Loss at iteration 1090 : 0.00013774244871456176
Loss at iteration 1100 : 0.00011331609857734293
Loss at iteration 1110 : 0.00032695321715436876
Loss at iteration 1120 : 0.00019389130466151983
Loss at iteration 1130 : 0.004251385573297739
Loss at iteration 1140 : 0.0002348451962461695
Loss at iteration 1150 : 0.001138223335146904
Loss at iteration 1160 : 0.00015853068907745183
Loss at iteration 1170 : 0.0001713550736894831
Loss at iteration 1180 : 0.0001146421127486974
Loss at iteration 1190 : 0.0011664386838674545
Loss at iteration 1200 : 0.00012000631249975413
Loss at iteration 1210 : 0.0003829427878372371
Loss at iteration 1220 : 9.155004227068275e-05
Loss at iteration 1230 : 0.0001713922101771459
Loss at iteration 1240 : 0.002109765075147152
Loss at iteration 1250 : 0.001092980382964015
Loss at iteration 1260 : 0.0004431756678968668
Loss at iteration 1270 : 0.0001857687602750957
Loss at iteration 1280 : 0.00038298952858895063
Loss at iteration 1290 : 0.0003125355578958988
Loss at iteration 1300 : 0.0030524469912052155
Loss at iteration 1310 : 0.0001349543745163828
Loss at iteration 1320 : 0.00022856841678731143
Loss at iteration 1330 : 0.0006087902584113181
Loss at iteration 1340 : 6.580348417628556e-05
Loss at iteration 1350 : 0.00021952291717752814
Loss at iteration 1360 : 0.002107568085193634
Loss at iteration 1370 : 0.00013916395255364478
Loss at iteration 1380 : 0.00013181626854930073
Loss at iteration 1390 : 0.0002043179119937122
Loss at iteration 1400 : 0.0015202873619273305
Loss at iteration 1410 : 0.003784296102821827
Loss at iteration 1420 : 0.00013680160918738693
Loss at iteration 1430 : 0.00016421446343883872
Loss at iteration 1440 : 0.0016612667823210359
Loss at iteration 1450 : 0.00045882706763222814
Loss at iteration 1460 : 9.1150650405325e-05
Loss at iteration 1470 : 6.882841989863664e-05
Loss at iteration 1480 : 0.00019745345343835652
Loss at iteration 1490 : 0.0008116575190797448
Loss at iteration 1500 : 0.00026704801712185144
Loss at iteration 1510 : 0.00024155143182724714
Loss at iteration 1520 : 0.00010526178812142462
Loss at iteration 1530 : 0.00028763001319020987
Loss at iteration 1540 : 3.279214070062153e-05
Loss at iteration 1550 : 5.828741632285528e-05
Loss at iteration 1560 : 0.00026359930052421987
Loss at iteration 1570 : 0.00013938354095444083
Loss at iteration 1580 : 0.002741175936535001
Loss at iteration 1590 : 0.00017848887364380062
Loss at iteration 1600 : 0.0003216690383851528
Loss at iteration 1610 : 0.000895428005605936
Loss at iteration 1620 : 0.00018495037511456758
Loss at iteration 1630 : 0.0005861802492290735
Loss at iteration 1640 : 0.0009563657222315669
Loss at iteration 1650 : 8.983348379842937e-05
Loss at iteration 1660 : 0.0004912809235975146
Loss at iteration 1670 : 0.00010348568321205676
Loss at iteration 1680 : 0.00024922791635617614
Loss at iteration 1690 : 4.546361378743313e-05
Loss at iteration 1700 : 0.0010380713501945138
Loss at iteration 1710 : 0.0005421143723651767
Loss at iteration 1720 : 0.004037350416183472
Loss at iteration 1730 : 0.00011940569675061852
Loss at iteration 1740 : 0.00018180417828261852
Loss at iteration 1750 : 0.001703432179056108
The SSIM Value is: 0.9851352430650316
The PSNR Value is: 46.5230588996988
the epoch is: 70
Loss at iteration 10 : 0.00012352256453596056
Loss at iteration 20 : 0.00022428999363910407
Loss at iteration 30 : 0.0003620104107540101
Loss at iteration 40 : 0.0003694264160003513
Loss at iteration 50 : 0.00021987702348269522
Loss at iteration 60 : 0.0001758720027282834
Loss at iteration 70 : 0.001074219006113708
Loss at iteration 80 : 0.0017153898952528834
Loss at iteration 90 : 0.0003166641399729997
Loss at iteration 100 : 0.0003865939215756953
Loss at iteration 110 : 0.0007867551757954061
Loss at iteration 120 : 0.0047423760406672955
Loss at iteration 130 : 0.00028442012262530625
Loss at iteration 140 : 0.00015571992844343185
Loss at iteration 150 : 6.148443935671821e-05
Loss at iteration 160 : 0.00011427028221078217
Loss at iteration 170 : 0.0032157159876078367
Loss at iteration 180 : 0.004033532924950123
Loss at iteration 190 : 0.006068907678127289
Loss at iteration 200 : 0.0035067361313849688
Loss at iteration 210 : 0.0007551872986368835
Loss at iteration 220 : 6.54836039757356e-05
Loss at iteration 230 : 0.00024291859881486744
Loss at iteration 240 : 0.005440546199679375
Loss at iteration 250 : 0.0004056276520714164
Loss at iteration 260 : 0.00017574899538885802
Loss at iteration 270 : 0.0032206387259066105
Loss at iteration 280 : 0.0002186987258028239
Loss at iteration 290 : 0.00015203612565528601
Loss at iteration 300 : 0.0018063364550471306
Loss at iteration 310 : 0.008387847803533077
Loss at iteration 320 : 0.0002680312318261713
Loss at iteration 330 : 0.000502257258631289
Loss at iteration 340 : 0.00023615981626790017
Loss at iteration 350 : 0.00017943812417797744
Loss at iteration 360 : 0.0007726508774794638
Loss at iteration 370 : 0.00011974290828220546
Loss at iteration 380 : 0.00014581762661691755
Loss at iteration 390 : 0.0006905070040374994
Loss at iteration 400 : 0.0005561003927141428
Loss at iteration 410 : 0.0003702729009091854
Loss at iteration 420 : 7.606903091073036e-05
Loss at iteration 430 : 0.00028315221425145864
Loss at iteration 440 : 0.0005169035866856575
Loss at iteration 450 : 0.00022052699932828546
Loss at iteration 460 : 0.00017204476171173155
Loss at iteration 470 : 0.0034838898573070765
Loss at iteration 480 : 0.00024215024313889444
Loss at iteration 490 : 0.0004052720032632351
Loss at iteration 500 : 0.00045091353240422904
Loss at iteration 510 : 0.00011985049059148878
Loss at iteration 520 : 0.00037950745900161564
Loss at iteration 530 : 4.8420439270557836e-05
Loss at iteration 540 : 0.0003036217822227627
Loss at iteration 550 : 0.0011050296016037464
Loss at iteration 560 : 0.002418814692646265
Loss at iteration 570 : 0.00044975991477258503
Loss at iteration 580 : 0.0016171709867194295
Loss at iteration 590 : 0.0033253757283091545
Loss at iteration 600 : 0.004915250465273857
Loss at iteration 610 : 0.00024093347019515932
Loss at iteration 620 : 0.0031607334967702627
Loss at iteration 630 : 0.00013837286678608507
Loss at iteration 640 : 0.00023573098587803543
Loss at iteration 650 : 0.0031052161939442158
Loss at iteration 660 : 0.00013684869918506593
Loss at iteration 670 : 9.198440238833427e-05
Loss at iteration 680 : 0.0001910845167003572
Loss at iteration 690 : 0.002763676457107067
Loss at iteration 700 : 0.0004201119882054627
Loss at iteration 710 : 0.00022770671057514846
Loss at iteration 720 : 0.00021963095059618354
Loss at iteration 730 : 0.0006770014297217131
Loss at iteration 740 : 9.171549027087167e-05
Loss at iteration 750 : 0.002147126942873001
Loss at iteration 760 : 0.005299456417560577
Loss at iteration 770 : 0.0002099544508382678
Loss at iteration 780 : 0.0001669433549977839
Loss at iteration 790 : 6.693805335089564e-05
Loss at iteration 800 : 0.00033830886241048574
Loss at iteration 810 : 0.0005303671350702643
Loss at iteration 820 : 0.0009079042356461287
Loss at iteration 830 : 0.00030530482763424516
Loss at iteration 840 : 0.0001593896740814671
Loss at iteration 850 : 0.00023807233083061874
Loss at iteration 860 : 0.0014776801690459251
Loss at iteration 870 : 0.00035297535941936076
Loss at iteration 880 : 0.000409253581892699
Loss at iteration 890 : 0.0013156065251678228
Loss at iteration 900 : 0.0005381498485803604
Loss at iteration 910 : 0.0002920594997704029
Loss at iteration 920 : 0.0014587154146283865
Loss at iteration 930 : 0.00010988194117089733
Loss at iteration 940 : 0.0001915805332828313
Loss at iteration 950 : 0.00024837011005729437
Loss at iteration 960 : 0.00016677362145856023
Loss at iteration 970 : 0.0006374029908329248
Loss at iteration 980 : 0.00043180305510759354
Loss at iteration 990 : 0.0002142584853572771
Loss at iteration 1000 : 8.846946730045602e-05
Loss at iteration 1010 : 5.566053732763976e-05
Loss at iteration 1020 : 0.0005658183945342898
Loss at iteration 1030 : 0.001329318736679852
Loss at iteration 1040 : 0.0005327770486474037
Loss at iteration 1050 : 0.0033562020398676395
Loss at iteration 1060 : 7.509985152864829e-05
Loss at iteration 1070 : 0.00027568364748731256
Loss at iteration 1080 : 0.00028245439170859754
Loss at iteration 1090 : 0.00040984078077599406
Loss at iteration 1100 : 0.0006708960281684995
Loss at iteration 1110 : 0.00019364288891665637
Loss at iteration 1120 : 0.00013148982543498278
Loss at iteration 1130 : 0.0026379043702036142
Loss at iteration 1140 : 0.0004335154080763459
Loss at iteration 1150 : 0.0029944325797259808
Loss at iteration 1160 : 0.001813007052987814
Loss at iteration 1170 : 0.0002746017707977444
Loss at iteration 1180 : 0.0006544367643073201
Loss at iteration 1190 : 0.0031540822237730026
Loss at iteration 1200 : 0.00023452407913282514
Loss at iteration 1210 : 0.0015697922790423036
Loss at iteration 1220 : 0.0011634310940280557
Loss at iteration 1230 : 0.000204872660106048
Loss at iteration 1240 : 0.00047668517800047994
Loss at iteration 1250 : 0.00047963179531507194
Loss at iteration 1260 : 0.0030353255569934845
Loss at iteration 1270 : 0.005534898489713669
Loss at iteration 1280 : 0.00022923684446141124
Loss at iteration 1290 : 0.008468784391880035
Loss at iteration 1300 : 6.178292096592486e-05
Loss at iteration 1310 : 0.00029019289650022984
Loss at iteration 1320 : 0.00016063681687228382
Loss at iteration 1330 : 0.0022573547903448343
Loss at iteration 1340 : 0.00182243378367275
Loss at iteration 1350 : 0.000600881059654057
Loss at iteration 1360 : 0.00036552068195305765
Loss at iteration 1370 : 8.377806807402521e-05
Loss at iteration 1380 : 0.000249114993494004
Loss at iteration 1390 : 0.00042535923421382904
Loss at iteration 1400 : 0.0003199886414222419
Loss at iteration 1410 : 0.0005604324396699667
Loss at iteration 1420 : 0.0032071899622678757
Loss at iteration 1430 : 0.00028770207427442074
Loss at iteration 1440 : 0.0005795439938083291
Loss at iteration 1450 : 0.0001662533322814852
Loss at iteration 1460 : 0.00022279255790635943
Loss at iteration 1470 : 0.0001012257271213457
Loss at iteration 1480 : 0.0006644937675446272
Loss at iteration 1490 : 0.0022826623171567917
Loss at iteration 1500 : 0.00039731309516355395
Loss at iteration 1510 : 0.0003987329255323857
Loss at iteration 1520 : 0.0006992245325818658
Loss at iteration 1530 : 0.0003457124694250524
Loss at iteration 1540 : 0.00020310870604589581
Loss at iteration 1550 : 0.00021348721929825842
Loss at iteration 1560 : 0.00012419995618984103
Loss at iteration 1570 : 0.0013041072525084019
Loss at iteration 1580 : 0.00025289959739893675
Loss at iteration 1590 : 0.0009104605996981263
Loss at iteration 1600 : 0.0002581975422799587
Loss at iteration 1610 : 0.0005074184737168252
Loss at iteration 1620 : 5.552452421397902e-05
Loss at iteration 1630 : 0.0002987164771184325
Loss at iteration 1640 : 0.0002575306862127036
Loss at iteration 1650 : 0.0011874191695824265
Loss at iteration 1660 : 0.0004968942375853658
Loss at iteration 1670 : 0.00021294962789397687
Loss at iteration 1680 : 0.00016273558139801025
Loss at iteration 1690 : 0.0006680497317574918
Loss at iteration 1700 : 0.0007026081439107656
Loss at iteration 1710 : 0.006547744385898113
Loss at iteration 1720 : 0.0001762314495863393
Loss at iteration 1730 : 0.00022442724730353802
Loss at iteration 1740 : 0.0003136223822366446
Loss at iteration 1750 : 0.00010574789484962821
The SSIM Value is: 0.9849994852154266
The PSNR Value is: 46.272164128425366
the epoch is: 71
Loss at iteration 10 : 0.0001993674668483436
Loss at iteration 20 : 0.0005363522213883698
Loss at iteration 30 : 0.0004009511903859675
Loss at iteration 40 : 0.00013346229388844222
Loss at iteration 50 : 0.00028014782583341
Loss at iteration 60 : 0.00042692641727626324
Loss at iteration 70 : 0.00028523130458779633
Loss at iteration 80 : 8.898395026335493e-05
Loss at iteration 90 : 0.0003248513676226139
Loss at iteration 100 : 0.00010174485942116007
Loss at iteration 110 : 0.00018472160445526242
Loss at iteration 120 : 0.001478152466006577
Loss at iteration 130 : 0.0001714703976176679
Loss at iteration 140 : 0.00011077198723796755
Loss at iteration 150 : 0.0018998943269252777
Loss at iteration 160 : 0.0008107817848213017
Loss at iteration 170 : 0.0002729773987084627
Loss at iteration 180 : 0.0003024377510882914
Loss at iteration 190 : 0.0005559994606301188
Loss at iteration 200 : 9.07840731088072e-05
Loss at iteration 210 : 0.000695251626893878
Loss at iteration 220 : 0.0014905876014381647
Loss at iteration 230 : 0.001845417427830398
Loss at iteration 240 : 0.00043749931501224637
Loss at iteration 250 : 0.00028272042982280254
Loss at iteration 260 : 0.003271987196058035
Loss at iteration 270 : 0.0003752212505787611
Loss at iteration 280 : 0.0001700352440821007
Loss at iteration 290 : 0.0032149143517017365
Loss at iteration 300 : 0.002793364692479372
Loss at iteration 310 : 0.00013396503345575184
Loss at iteration 320 : 0.00017974921502172947
Loss at iteration 330 : 0.0001581555261509493
Loss at iteration 340 : 0.01040470227599144
Loss at iteration 350 : 0.00011928233288927004
Loss at iteration 360 : 0.0003752752672880888
Loss at iteration 370 : 0.0006653610616922379
Loss at iteration 380 : 0.0002965348830912262
Loss at iteration 390 : 0.00018056730914395303
Loss at iteration 400 : 0.0015022200532257557
Loss at iteration 410 : 0.0032386137172579765
Loss at iteration 420 : 0.0003619026392698288
Loss at iteration 430 : 0.0003346283338032663
Loss at iteration 440 : 6.096584547776729e-05
Loss at iteration 450 : 0.008066419512033463
Loss at iteration 460 : 0.00012153679563198239
Loss at iteration 470 : 0.00014273721899371594
Loss at iteration 480 : 0.0022473041899502277
Loss at iteration 490 : 0.00026992009952664375
Loss at iteration 500 : 0.002058726269751787
Loss at iteration 510 : 0.0017542110290378332
Loss at iteration 520 : 0.00044067169073969126
Loss at iteration 530 : 0.00040824676398187876
Loss at iteration 540 : 0.00030166131909936666
Loss at iteration 550 : 0.00044383492786437273
Loss at iteration 560 : 0.00018749060109257698
Loss at iteration 570 : 0.00030542712192982435
Loss at iteration 580 : 0.0014910671161487699
Loss at iteration 590 : 0.0003584764781408012
Loss at iteration 600 : 0.0001940838119480759
Loss at iteration 610 : 0.0013149731094017625
Loss at iteration 620 : 0.0012124840868636966
Loss at iteration 630 : 0.0021788401063531637
Loss at iteration 640 : 0.00017800889327190816
Loss at iteration 650 : 0.0003884635807480663
Loss at iteration 660 : 0.0007809585076756775
Loss at iteration 670 : 0.0012212953297421336
Loss at iteration 680 : 0.0007137145730666816
Loss at iteration 690 : 0.0017377970507368445
Loss at iteration 700 : 0.001376184867694974
Loss at iteration 710 : 0.0005850156303495169
Loss at iteration 720 : 0.00033410097239539027
Loss at iteration 730 : 0.00029186083702370524
Loss at iteration 740 : 0.00014286430086940527
Loss at iteration 750 : 0.0022695939987897873
Loss at iteration 760 : 0.00015197184984572232
Loss at iteration 770 : 4.340139639680274e-05
Loss at iteration 780 : 0.0007104803808033466
Loss at iteration 790 : 0.003260432044044137
Loss at iteration 800 : 0.00016952524310909212
Loss at iteration 810 : 5.4869196901563555e-05
Loss at iteration 820 : 0.00046716182259842753
Loss at iteration 830 : 0.00020854989998042583
Loss at iteration 840 : 0.00044715541298501194
Loss at iteration 850 : 0.002541006077080965
Loss at iteration 860 : 0.00011431788880145177
Loss at iteration 870 : 0.0006778665701858699
Loss at iteration 880 : 0.00015250885917339474
Loss at iteration 890 : 0.00020805568783544004
Loss at iteration 900 : 0.0008625739719718695
Loss at iteration 910 : 0.00014848072896711528
Loss at iteration 920 : 7.514016033383086e-05
Loss at iteration 930 : 0.00031212958856485784
Loss at iteration 940 : 0.007272719405591488
Loss at iteration 950 : 0.0009848118061199784
Loss at iteration 960 : 0.004064000677317381
Loss at iteration 970 : 0.002014159457758069
Loss at iteration 980 : 0.0006343519780784845
Loss at iteration 990 : 0.00015057172277010977
Loss at iteration 1000 : 0.0019173503387719393
Loss at iteration 1010 : 0.00027218752074986696
Loss at iteration 1020 : 0.00016677845269441605
Loss at iteration 1030 : 0.0002119369455613196
Loss at iteration 1040 : 0.0001043980082613416
Loss at iteration 1050 : 0.002151523483917117
Loss at iteration 1060 : 0.0006070540985092521
Loss at iteration 1070 : 0.0026037893258035183
Loss at iteration 1080 : 0.0003059601003769785
Loss at iteration 1090 : 0.0002313556324224919
Loss at iteration 1100 : 0.0012875603279098868
Loss at iteration 1110 : 0.0007959756767377257
Loss at iteration 1120 : 0.00018153656856156886
Loss at iteration 1130 : 0.000792452075984329
Loss at iteration 1140 : 0.0002512469363864511
Loss at iteration 1150 : 0.0026537461671978235
Loss at iteration 1160 : 0.004565611481666565
Loss at iteration 1170 : 0.0026455633342266083
Loss at iteration 1180 : 0.0002009761956287548
Loss at iteration 1190 : 0.00022423770860768855
Loss at iteration 1200 : 0.0021695569157600403
Loss at iteration 1210 : 0.0002717844909057021
Loss at iteration 1220 : 0.0007506138645112514
Loss at iteration 1230 : 0.002597109880298376
Loss at iteration 1240 : 0.0030364631675183773
Loss at iteration 1250 : 0.00038296275306493044
Loss at iteration 1260 : 0.0007592343026772141
Loss at iteration 1270 : 0.0003078942245338112
Loss at iteration 1280 : 0.0023839168716222048
Loss at iteration 1290 : 0.00015798289678059518
Loss at iteration 1300 : 0.000896899844519794
Loss at iteration 1310 : 0.0005418785149231553
Loss at iteration 1320 : 0.002025345340371132
Loss at iteration 1330 : 0.00012976913421880454
Loss at iteration 1340 : 0.007025894243270159
Loss at iteration 1350 : 0.0003019344585482031
Loss at iteration 1360 : 0.0015102142933756113
Loss at iteration 1370 : 8.36698745843023e-05
Loss at iteration 1380 : 0.0003297340008430183
Loss at iteration 1390 : 0.0023306780494749546
Loss at iteration 1400 : 0.007351402658969164
Loss at iteration 1410 : 0.00018093915423378348
Loss at iteration 1420 : 0.00016086603864096105
Loss at iteration 1430 : 0.002330570947378874
Loss at iteration 1440 : 8.05046220193617e-05
Loss at iteration 1450 : 0.00010678770195227116
Loss at iteration 1460 : 8.493229688610882e-05
Loss at iteration 1470 : 0.0002898775564972311
Loss at iteration 1480 : 0.0004476085305213928
Loss at iteration 1490 : 0.00047406504745595157
Loss at iteration 1500 : 0.0018699385691434145
Loss at iteration 1510 : 0.003188623581081629
Loss at iteration 1520 : 0.00032504185219295323
Loss at iteration 1530 : 0.0017989028710871935
Loss at iteration 1540 : 0.0022805719636380672
Loss at iteration 1550 : 0.0016393926925957203
Loss at iteration 1560 : 0.0003425175091251731
Loss at iteration 1570 : 0.0036489837802946568
Loss at iteration 1580 : 0.00078785844380036
Loss at iteration 1590 : 9.596606832928956e-05
Loss at iteration 1600 : 0.0012729661539196968
Loss at iteration 1610 : 0.003911201376467943
Loss at iteration 1620 : 8.015661296667531e-05
Loss at iteration 1630 : 0.0005689007812179625
Loss at iteration 1640 : 0.00046662078239023685
Loss at iteration 1650 : 0.0005930938059464097
Loss at iteration 1660 : 0.00019946732209064066
Loss at iteration 1670 : 0.0001206631277455017
Loss at iteration 1680 : 0.0013645637081936002
Loss at iteration 1690 : 0.00015529080701526254
Loss at iteration 1700 : 0.000944982748478651
Loss at iteration 1710 : 0.0026575366500765085
Loss at iteration 1720 : 0.0015366006409749389
Loss at iteration 1730 : 0.00028714112704619765
Loss at iteration 1740 : 0.0005590592045336962
Loss at iteration 1750 : 0.0005947832250967622
The SSIM Value is: 0.9752577166462785
The PSNR Value is: 46.33437218855131
the epoch is: 72
Loss at iteration 10 : 0.0003186256217304617
Loss at iteration 20 : 0.005592223256826401
Loss at iteration 30 : 0.00021380375255830586
Loss at iteration 40 : 0.0002088062174152583
Loss at iteration 50 : 0.00023861866793595254
Loss at iteration 60 : 0.001018591457977891
Loss at iteration 70 : 0.0013558967038989067
Loss at iteration 80 : 9.244508692063391e-05
Loss at iteration 90 : 0.0031578827183693647
Loss at iteration 100 : 0.0031185506377369165
Loss at iteration 110 : 0.0009329479653388262
Loss at iteration 120 : 0.00015667348634451628
Loss at iteration 130 : 0.00019108553533442318
Loss at iteration 140 : 0.00023466254060622305
Loss at iteration 150 : 8.954532677307725e-05
Loss at iteration 160 : 0.000501672679092735
Loss at iteration 170 : 0.003932890482246876
Loss at iteration 180 : 0.0006691050948575139
Loss at iteration 190 : 0.000899269653018564
Loss at iteration 200 : 0.0007983259856700897
Loss at iteration 210 : 0.0013780540321022272
Loss at iteration 220 : 0.0006381893181242049
Loss at iteration 230 : 0.00030388933373615146
Loss at iteration 240 : 0.003181849140673876
Loss at iteration 250 : 0.0006708076689392328
Loss at iteration 260 : 0.00047868251567706466
Loss at iteration 270 : 0.00016515424067620188
Loss at iteration 280 : 0.002458970993757248
Loss at iteration 290 : 0.0007279074052348733
Loss at iteration 300 : 0.00018198156612925231
Loss at iteration 310 : 0.00011033364717150107
Loss at iteration 320 : 0.0016851400723680854
Loss at iteration 330 : 0.0006990684196352959
Loss at iteration 340 : 0.0003830714849755168
Loss at iteration 350 : 0.00024294518516398966
Loss at iteration 360 : 9.363955177832395e-05
Loss at iteration 370 : 0.0006330256583169103
Loss at iteration 380 : 0.0001297628623433411
Loss at iteration 390 : 0.001134830410592258
Loss at iteration 400 : 0.0001343952026218176
Loss at iteration 410 : 0.004702321719378233
Loss at iteration 420 : 9.63059501373209e-05
Loss at iteration 430 : 0.0030886700842529535
Loss at iteration 440 : 0.0010789077496156096
Loss at iteration 450 : 0.00026981873088516295
Loss at iteration 460 : 0.001296016969718039
Loss at iteration 470 : 0.00012995104771107435
Loss at iteration 480 : 0.010595369152724743
Loss at iteration 490 : 0.0002175280242227018
Loss at iteration 500 : 0.001954633742570877
Loss at iteration 510 : 0.00018627647659741342
Loss at iteration 520 : 0.0003548908862285316
Loss at iteration 530 : 0.00040614683530293405
Loss at iteration 540 : 0.00024833783390931785
Loss at iteration 550 : 0.0002169793879147619
Loss at iteration 560 : 0.00024549243971705437
Loss at iteration 570 : 0.0013224015710875392
Loss at iteration 580 : 0.00020800155471079051
Loss at iteration 590 : 0.0004129247390665114
Loss at iteration 600 : 0.0006730890600010753
Loss at iteration 610 : 0.0001432561402907595
Loss at iteration 620 : 0.0003893301181960851
Loss at iteration 630 : 0.00039995386032387614
Loss at iteration 640 : 0.002873143646866083
Loss at iteration 650 : 0.0006624290836043656
Loss at iteration 660 : 0.001986668212339282
Loss at iteration 670 : 0.00013003496860619634
Loss at iteration 680 : 0.0003479667939245701
Loss at iteration 690 : 0.00035942631075158715
Loss at iteration 700 : 7.263701991178095e-05
Loss at iteration 710 : 0.0005675849388353527
Loss at iteration 720 : 0.00045052674249745905
Loss at iteration 730 : 0.006978705059736967
Loss at iteration 740 : 0.0001835699804360047
Loss at iteration 750 : 0.00016901454364415258
Loss at iteration 760 : 0.00011191489466000348
Loss at iteration 770 : 0.00404480891302228
Loss at iteration 780 : 0.001608496531844139
Loss at iteration 790 : 0.0066289943642914295
Loss at iteration 800 : 0.000730760395526886
Loss at iteration 810 : 0.0004728028434328735
Loss at iteration 820 : 0.0017058911034837365
Loss at iteration 830 : 0.00012723002873826772
Loss at iteration 840 : 0.0009933047695085406
Loss at iteration 850 : 0.000620970269665122
Loss at iteration 860 : 0.0003813452203758061
Loss at iteration 870 : 0.00030278059421107173
Loss at iteration 880 : 0.0038298885338008404
Loss at iteration 890 : 0.002695786999538541
Loss at iteration 900 : 0.0005359011702239513
Loss at iteration 910 : 0.00022314026136882603
Loss at iteration 920 : 0.0006411945214495063
Loss at iteration 930 : 0.0004550579469650984
Loss at iteration 940 : 6.285639392444864e-05
Loss at iteration 950 : 0.00026871636509895325
Loss at iteration 960 : 0.0008893314516171813
Loss at iteration 970 : 0.0004072086594533175
Loss at iteration 980 : 0.0001645949960220605
Loss at iteration 990 : 0.0035808351822197437
Loss at iteration 1000 : 0.0006053724209778011
Loss at iteration 1010 : 6.619270425289869e-05
Loss at iteration 1020 : 0.0001672272919677198
Loss at iteration 1030 : 0.001418132334947586
Loss at iteration 1040 : 0.0029288367368280888
Loss at iteration 1050 : 0.00047588051529601216
Loss at iteration 1060 : 0.0006973732961341739
Loss at iteration 1070 : 0.0026653886307030916
Loss at iteration 1080 : 0.0027256738394498825
Loss at iteration 1090 : 9.246935951523483e-05
Loss at iteration 1100 : 0.0001199343751068227
Loss at iteration 1110 : 0.0002390353474766016
Loss at iteration 1120 : 0.0002854310441762209
Loss at iteration 1130 : 0.0005025011487305164
Loss at iteration 1140 : 0.0042088706977665424
Loss at iteration 1150 : 7.281419675564393e-05
Loss at iteration 1160 : 6.724709965055808e-05
Loss at iteration 1170 : 0.0004764152690768242
Loss at iteration 1180 : 0.0012604182120412588
Loss at iteration 1190 : 0.0007739435532130301
Loss at iteration 1200 : 0.00024104198382701725
Loss at iteration 1210 : 0.0013826900394633412
Loss at iteration 1220 : 0.0003558516036719084
Loss at iteration 1230 : 0.0028171828016638756
Loss at iteration 1240 : 8.283283386845142e-05
Loss at iteration 1250 : 0.00027483981102705
Loss at iteration 1260 : 0.0003210253198631108
Loss at iteration 1270 : 0.00030076931579969823
Loss at iteration 1280 : 0.002899788785725832
Loss at iteration 1290 : 4.749643267132342e-05
Loss at iteration 1300 : 0.0004198806709609926
Loss at iteration 1310 : 0.0023423016536980867
Loss at iteration 1320 : 0.0015148178208619356
Loss at iteration 1330 : 0.00016870262334123254
Loss at iteration 1340 : 0.00011137818364659324
Loss at iteration 1350 : 4.775750858243555e-05
Loss at iteration 1360 : 0.00034521479392424226
Loss at iteration 1370 : 0.0003994907019659877
Loss at iteration 1380 : 0.00014872396423015743
Loss at iteration 1390 : 0.0016072862781584263
Loss at iteration 1400 : 0.0017182488227263093
Loss at iteration 1410 : 0.0004804624477401376
Loss at iteration 1420 : 4.75381275464315e-05
Loss at iteration 1430 : 0.00031785276951268315
Loss at iteration 1440 : 0.0011844104155898094
Loss at iteration 1450 : 0.0021079254802316427
Loss at iteration 1460 : 5.4489093599841e-05
Loss at iteration 1470 : 0.00015021217404864728
Loss at iteration 1480 : 0.0035711941309273243
Loss at iteration 1490 : 0.003800956066697836
Loss at iteration 1500 : 0.0035503064282238483
Loss at iteration 1510 : 0.0004997039795853198
Loss at iteration 1520 : 8.409583097090945e-05
Loss at iteration 1530 : 0.0002692089765332639
Loss at iteration 1540 : 0.0002903371932916343
Loss at iteration 1550 : 0.0003353253414388746
Loss at iteration 1560 : 0.00017806596588343382
Loss at iteration 1570 : 0.00025820996961556375
Loss at iteration 1580 : 0.0009026308543980122
Loss at iteration 1590 : 0.00027921010041609406
Loss at iteration 1600 : 5.51471566723194e-05
Loss at iteration 1610 : 0.0001156245416495949
Loss at iteration 1620 : 0.00022581283701583743
Loss at iteration 1630 : 0.0014293298590928316
Loss at iteration 1640 : 0.0001467229303671047
Loss at iteration 1650 : 0.0001197059391415678
Loss at iteration 1660 : 0.00027730182046070695
Loss at iteration 1670 : 0.00034388210042379797
Loss at iteration 1680 : 7.77683308115229e-05
Loss at iteration 1690 : 0.00011297516175545752
Loss at iteration 1700 : 0.0007604627753607929
Loss at iteration 1710 : 0.0016966334078460932
Loss at iteration 1720 : 0.0006310287863016129
Loss at iteration 1730 : 0.003360276808962226
Loss at iteration 1740 : 0.0005889177555218339
Loss at iteration 1750 : 0.00301057449541986
The SSIM Value is: 0.9877006355098691
The PSNR Value is: 46.27179731251385
the epoch is: 73
Loss at iteration 10 : 0.00013493593723978847
Loss at iteration 20 : 0.0018376209773123264
Loss at iteration 30 : 0.0006406887550838292
Loss at iteration 40 : 0.001038440503180027
Loss at iteration 50 : 0.0006945604691281915
Loss at iteration 60 : 0.0017000080551952124
Loss at iteration 70 : 0.0011013377225026488
Loss at iteration 80 : 0.0012977677397429943
Loss at iteration 90 : 0.00016552976740058511
Loss at iteration 100 : 0.0021463113371282816
Loss at iteration 110 : 0.003657109569758177
Loss at iteration 120 : 0.004440142773091793
Loss at iteration 130 : 0.0005093736108392477
Loss at iteration 140 : 0.005745747592300177
Loss at iteration 150 : 9.768726886250079e-05
Loss at iteration 160 : 0.0010529146529734135
Loss at iteration 170 : 0.00036680407356470823
Loss at iteration 180 : 0.0006893689860589802
Loss at iteration 190 : 0.00010460201883688569
Loss at iteration 200 : 0.0022691525518894196
Loss at iteration 210 : 0.0002057600358966738
Loss at iteration 220 : 0.00011424694093875587
Loss at iteration 230 : 0.0027172183617949486
Loss at iteration 240 : 0.0035956220235675573
Loss at iteration 250 : 0.0004692220245487988
Loss at iteration 260 : 0.000988700776360929
Loss at iteration 270 : 0.000939414429012686
Loss at iteration 280 : 0.0050583574920892715
Loss at iteration 290 : 0.0003403785522095859
Loss at iteration 300 : 0.00112110935151577
Loss at iteration 310 : 0.00019417729345150292
Loss at iteration 320 : 0.00013319790014065802
Loss at iteration 330 : 0.0031640068627893925
Loss at iteration 340 : 0.005403339862823486
Loss at iteration 350 : 5.1893741328967735e-05
Loss at iteration 360 : 0.00022301186982076615
Loss at iteration 370 : 0.0003012439701706171
Loss at iteration 380 : 9.404634329257533e-05
Loss at iteration 390 : 0.0026538576930761337
Loss at iteration 400 : 8.99964215932414e-05
Loss at iteration 410 : 0.00021173284039832652
Loss at iteration 420 : 0.0012339644599705935
Loss at iteration 430 : 0.00012242811499163508
Loss at iteration 440 : 0.0002599958097562194
Loss at iteration 450 : 0.0003901544841937721
Loss at iteration 460 : 0.009727481752634048
Loss at iteration 470 : 0.0022560646757483482
Loss at iteration 480 : 0.00016022632189560682
Loss at iteration 490 : 0.0007312282104976475
Loss at iteration 500 : 0.0002533442748244852
Loss at iteration 510 : 0.0002133418747689575
Loss at iteration 520 : 0.0002499332185834646
Loss at iteration 530 : 0.0001298458082601428
Loss at iteration 540 : 0.0002326390240341425
Loss at iteration 550 : 0.0003183985245414078
Loss at iteration 560 : 0.004028329625725746
Loss at iteration 570 : 0.0026036191266030073
Loss at iteration 580 : 0.00033233282738365233
Loss at iteration 590 : 0.0005173207609914243
Loss at iteration 600 : 0.0011912299087271094
Loss at iteration 610 : 0.002527055563405156
Loss at iteration 620 : 0.0013115128967911005
Loss at iteration 630 : 0.0001484438980696723
Loss at iteration 640 : 0.000107544896309264
Loss at iteration 650 : 0.00018829495820682496
Loss at iteration 660 : 0.0011329739354550838
Loss at iteration 670 : 0.0002646859793458134
Loss at iteration 680 : 0.00025949833798222244
Loss at iteration 690 : 0.000871742726303637
Loss at iteration 700 : 0.00010357981227571145
Loss at iteration 710 : 0.0014522360870614648
Loss at iteration 720 : 0.0021864441223442554
Loss at iteration 730 : 0.001628949656151235
Loss at iteration 740 : 0.00033834445639513433
Loss at iteration 750 : 0.0007752216188237071
Loss at iteration 760 : 0.010303184390068054
Loss at iteration 770 : 9.280698577640578e-05
Loss at iteration 780 : 0.00023667006462346762
Loss at iteration 790 : 0.00016666109149809927
Loss at iteration 800 : 0.00033439125400036573
Loss at iteration 810 : 0.00028824975015595555
Loss at iteration 820 : 0.0018613127758726478
Loss at iteration 830 : 0.00017819704953581095
Loss at iteration 840 : 0.0028462756890803576
Loss at iteration 850 : 0.003842183854430914
Loss at iteration 860 : 0.0013023626524955034
Loss at iteration 870 : 0.00012182526552351192
Loss at iteration 880 : 0.0005304726073518395
Loss at iteration 890 : 0.003094122977927327
Loss at iteration 900 : 0.0009409500635229051
Loss at iteration 910 : 0.0012811096385121346
Loss at iteration 920 : 0.001005950733087957
Loss at iteration 930 : 0.0012781675904989243
Loss at iteration 940 : 0.0028952795546501875
Loss at iteration 950 : 5.064239667262882e-05
Loss at iteration 960 : 0.00043404210009612143
Loss at iteration 970 : 0.0007933005108498037
Loss at iteration 980 : 0.0008904292481020093
Loss at iteration 990 : 0.00044121453538537025
Loss at iteration 1000 : 0.0002790264552459121
Loss at iteration 1010 : 0.0002745401579886675
Loss at iteration 1020 : 0.0004307502822484821
Loss at iteration 1030 : 6.641332583967596e-05
Loss at iteration 1040 : 0.0002506139571778476
Loss at iteration 1050 : 0.0014936767984181643
Loss at iteration 1060 : 0.0032944984268397093
Loss at iteration 1070 : 0.00017484882846474648
Loss at iteration 1080 : 0.003333477070555091
Loss at iteration 1090 : 0.0015978978481143713
Loss at iteration 1100 : 0.0006994496798142791
Loss at iteration 1110 : 0.000489929923787713
Loss at iteration 1120 : 0.00024052131630014628
Loss at iteration 1130 : 0.0001114571641664952
Loss at iteration 1140 : 0.00017293900600634515
Loss at iteration 1150 : 0.0004235450178384781
Loss at iteration 1160 : 0.0036815213970839977
Loss at iteration 1170 : 0.004835984669625759
Loss at iteration 1180 : 0.0007009285036474466
Loss at iteration 1190 : 0.00010145059059141204
Loss at iteration 1200 : 0.003896942362189293
Loss at iteration 1210 : 0.0004911000141873956
Loss at iteration 1220 : 0.0014267186634242535
Loss at iteration 1230 : 0.0027781445533037186
Loss at iteration 1240 : 0.00033881317358464
Loss at iteration 1250 : 0.0013858565362170339
Loss at iteration 1260 : 0.002766204299405217
Loss at iteration 1270 : 0.000986903440207243
Loss at iteration 1280 : 0.002683748258277774
Loss at iteration 1290 : 0.0007036840543150902
Loss at iteration 1300 : 0.0002013199555221945
Loss at iteration 1310 : 0.002870674943551421
Loss at iteration 1320 : 0.00010859331814572215
Loss at iteration 1330 : 0.00038247767952270806
Loss at iteration 1340 : 0.003256390569731593
Loss at iteration 1350 : 0.0018692605663090944
Loss at iteration 1360 : 0.00027989415684714913
Loss at iteration 1370 : 0.0004524214018601924
Loss at iteration 1380 : 0.0001505847176304087
Loss at iteration 1390 : 0.00013866352674085647
Loss at iteration 1400 : 0.0008537044050171971
Loss at iteration 1410 : 0.0025768354535102844
Loss at iteration 1420 : 6.410168862203136e-05
Loss at iteration 1430 : 0.0002937588142231107
Loss at iteration 1440 : 0.00019224060815759003
Loss at iteration 1450 : 0.0004318144347053021
Loss at iteration 1460 : 0.00397750036790967
Loss at iteration 1470 : 0.0009391295025125146
Loss at iteration 1480 : 0.0004624514258466661
Loss at iteration 1490 : 0.00022985076066106558
Loss at iteration 1500 : 0.000541853834874928
Loss at iteration 1510 : 0.005144377239048481
Loss at iteration 1520 : 0.00043498072773218155
Loss at iteration 1530 : 0.00034663325641304255
Loss at iteration 1540 : 0.0013512952718883753
Loss at iteration 1550 : 0.00011364321107976139
Loss at iteration 1560 : 0.00011690895189531147
Loss at iteration 1570 : 0.0002933700452558696
Loss at iteration 1580 : 0.0002163316821679473
Loss at iteration 1590 : 0.00011059398821089417
Loss at iteration 1600 : 0.0003205300308763981
Loss at iteration 1610 : 0.00024908618070185184
Loss at iteration 1620 : 0.0001037463589455001
Loss at iteration 1630 : 0.002706838073208928
Loss at iteration 1640 : 0.0018284206744283438
Loss at iteration 1650 : 0.00010815059067681432
Loss at iteration 1660 : 0.0016174297779798508
Loss at iteration 1670 : 0.00017625385953579098
Loss at iteration 1680 : 0.004307490773499012
Loss at iteration 1690 : 0.00031168354325927794
Loss at iteration 1700 : 0.0001353479892713949
Loss at iteration 1710 : 0.0010141127277165651
Loss at iteration 1720 : 0.01247403398156166
Loss at iteration 1730 : 0.00021046119218226522
Loss at iteration 1740 : 0.0002965718158520758
Loss at iteration 1750 : 0.0008147697080858052
The SSIM Value is: 0.9687496625904469
The PSNR Value is: 46.184398004136945
the epoch is: 74
Loss at iteration 10 : 0.0008414524490945041
Loss at iteration 20 : 0.002091735601425171
Loss at iteration 30 : 0.0010166967986151576
Loss at iteration 40 : 0.00043110846308991313
Loss at iteration 50 : 0.0025441832840442657
Loss at iteration 60 : 0.0003072173858527094
Loss at iteration 70 : 7.14345442247577e-05
Loss at iteration 80 : 0.0007213788921944797
Loss at iteration 90 : 0.00036080589052289724
Loss at iteration 100 : 0.00010213381756329909
Loss at iteration 110 : 0.0035493948962539434
Loss at iteration 120 : 0.00022616585192736238
Loss at iteration 130 : 0.0006684187101200223
Loss at iteration 140 : 0.00012016561959171668
Loss at iteration 150 : 0.005006380844861269
Loss at iteration 160 : 0.0005294658476486802
Loss at iteration 170 : 6.391579518094659e-05
Loss at iteration 180 : 0.00042786705307662487
Loss at iteration 190 : 0.0006782817654311657
Loss at iteration 200 : 0.0001879878545878455
Loss at iteration 210 : 0.0008117946563288569
Loss at iteration 220 : 0.00034634029725566506
Loss at iteration 230 : 0.003475271165370941
Loss at iteration 240 : 0.0002345934190088883
Loss at iteration 250 : 8.705347136128694e-05
Loss at iteration 260 : 8.212961256504059e-05
Loss at iteration 270 : 0.000231047160923481
Loss at iteration 280 : 0.000156847556354478
Loss at iteration 290 : 0.00272839586250484
Loss at iteration 300 : 0.0032197178807109594
Loss at iteration 310 : 0.00015398534014821053
Loss at iteration 320 : 0.003225398948416114
Loss at iteration 330 : 0.0006587374955415726
Loss at iteration 340 : 0.00017812594887800515
Loss at iteration 350 : 0.00012493709800764918
Loss at iteration 360 : 0.001219266327098012
Loss at iteration 370 : 9.521293395664543e-05
Loss at iteration 380 : 0.0001704719616100192
Loss at iteration 390 : 0.00021538930013775826
Loss at iteration 400 : 9.005112224258482e-05
Loss at iteration 410 : 0.0020913295447826385
Loss at iteration 420 : 0.001138680730946362
Loss at iteration 430 : 0.0008758269250392914
Loss at iteration 440 : 0.0001303371536778286
Loss at iteration 450 : 0.00010907537944149226
Loss at iteration 460 : 0.0013018114259466529
Loss at iteration 470 : 0.00021369740716181695
Loss at iteration 480 : 0.000615992583334446
Loss at iteration 490 : 0.0024963419418781996
Loss at iteration 500 : 0.000167859805515036
Loss at iteration 510 : 0.002208291320130229
Loss at iteration 520 : 0.0001525195548310876
Loss at iteration 530 : 0.00015892810188233852
Loss at iteration 540 : 0.002201255178079009
Loss at iteration 550 : 0.0006132616545073688
Loss at iteration 560 : 0.0030646477825939655
Loss at iteration 570 : 0.00014849493163637817
Loss at iteration 580 : 0.0023704487830400467
Loss at iteration 590 : 6.588995893253013e-05
Loss at iteration 600 : 0.00034324248554185033
Loss at iteration 610 : 0.0007041774224489927
Loss at iteration 620 : 0.001574242953211069
Loss at iteration 630 : 0.0006463653407990932
Loss at iteration 640 : 0.0038287886418402195
Loss at iteration 650 : 0.0018654398154467344
Loss at iteration 660 : 0.00010416105214972049
Loss at iteration 670 : 0.001320729381404817
Loss at iteration 680 : 0.00036765210097655654
Loss at iteration 690 : 0.0014200706500560045
Loss at iteration 700 : 0.002247779630124569
Loss at iteration 710 : 0.00012687046546489
Loss at iteration 720 : 0.0001252846559509635
Loss at iteration 730 : 0.00013197146472521126
Loss at iteration 740 : 0.0008710367255844176
Loss at iteration 750 : 0.0004187454469501972
Loss at iteration 760 : 0.0024896636605262756
Loss at iteration 770 : 0.0005134083330631256
Loss at iteration 780 : 0.0009202320361509919
Loss at iteration 790 : 0.0013330207439139485
Loss at iteration 800 : 0.00014409712457563728
Loss at iteration 810 : 0.0028291663620620966
Loss at iteration 820 : 0.0004304975154809654
Loss at iteration 830 : 0.004453624598681927
Loss at iteration 840 : 5.39886714250315e-05
Loss at iteration 850 : 0.0003746130096260458
Loss at iteration 860 : 0.00026122372946701944
Loss at iteration 870 : 0.00016081632929854095
Loss at iteration 880 : 0.00020818554912693799
Loss at iteration 890 : 0.0010416534496471286
Loss at iteration 900 : 0.0004281834699213505
Loss at iteration 910 : 0.003008844330906868
Loss at iteration 920 : 0.002915462478995323
Loss at iteration 930 : 0.0005796462646685541
Loss at iteration 940 : 0.002385966246947646
Loss at iteration 950 : 0.00038405030500143766
Loss at iteration 960 : 0.00021785416174679995
Loss at iteration 970 : 0.004164212383329868
Loss at iteration 980 : 0.0004500650684349239
Loss at iteration 990 : 0.002599170897156
Loss at iteration 1000 : 0.00036888732574880123
Loss at iteration 1010 : 0.00031313294311985373
Loss at iteration 1020 : 6.657802441623062e-05
Loss at iteration 1030 : 0.0020291812252253294
Loss at iteration 1040 : 0.0002962618018500507
Loss at iteration 1050 : 0.00030522781889885664
Loss at iteration 1060 : 0.0037243138067424297
Loss at iteration 1070 : 0.00011335688759572804
Loss at iteration 1080 : 0.0002230843820143491
Loss at iteration 1090 : 0.0004498888156376779
Loss at iteration 1100 : 5.334372690413147e-05
Loss at iteration 1110 : 0.00013012398267164826
Loss at iteration 1120 : 0.00011588198685785756
Loss at iteration 1130 : 0.0014609035570174456
Loss at iteration 1140 : 0.00027785368729382753
Loss at iteration 1150 : 0.0002289575495524332
Loss at iteration 1160 : 0.0029807044193148613
Loss at iteration 1170 : 0.0037714990321546793
Loss at iteration 1180 : 0.0006063475157134235
Loss at iteration 1190 : 0.0005847593420185149
Loss at iteration 1200 : 0.0029319236055016518
Loss at iteration 1210 : 0.004108558874577284
Loss at iteration 1220 : 0.00046078237937763333
Loss at iteration 1230 : 0.003261469304561615
Loss at iteration 1240 : 0.0016750339418649673
Loss at iteration 1250 : 0.00010588817531242967
Loss at iteration 1260 : 0.000146529171615839
Loss at iteration 1270 : 7.214660581666976e-05
Loss at iteration 1280 : 0.0022142017260193825
Loss at iteration 1290 : 0.0001564810227137059
Loss at iteration 1300 : 0.003796761389821768
Loss at iteration 1310 : 0.00045005319407209754
Loss at iteration 1320 : 0.0003811791248153895
Loss at iteration 1330 : 0.00022335958783514798
Loss at iteration 1340 : 0.0015403589932247996
Loss at iteration 1350 : 0.00013953822781331837
Loss at iteration 1360 : 0.00011305448424536735
Loss at iteration 1370 : 0.00017880892846733332
Loss at iteration 1380 : 0.000558714906219393
Loss at iteration 1390 : 0.0005540800630114973
Loss at iteration 1400 : 0.0009399338159710169
Loss at iteration 1410 : 0.00198948010802269
Loss at iteration 1420 : 0.0011379702482372522
Loss at iteration 1430 : 0.0003259999502915889
Loss at iteration 1440 : 0.0002094544906867668
Loss at iteration 1450 : 0.0002568144700489938
Loss at iteration 1460 : 9.396878886036575e-05
Loss at iteration 1470 : 9.920153388520703e-05
Loss at iteration 1480 : 0.0018795898649841547
Loss at iteration 1490 : 0.0007175218779593706
Loss at iteration 1500 : 0.0001450696145184338
Loss at iteration 1510 : 0.0011853936593979597
Loss at iteration 1520 : 0.0003978260501753539
Loss at iteration 1530 : 0.0003784784930758178
Loss at iteration 1540 : 0.00014020669914316386
Loss at iteration 1550 : 3.966656367992982e-05
Loss at iteration 1560 : 7.765086047584191e-05
Loss at iteration 1570 : 0.00017531836056150496
Loss at iteration 1580 : 0.000571488169953227
Loss at iteration 1590 : 0.003930337727069855
Loss at iteration 1600 : 0.003539323341101408
Loss at iteration 1610 : 0.0026580451522022486
Loss at iteration 1620 : 6.434062379412353e-05
Loss at iteration 1630 : 0.00011240097228437662
Loss at iteration 1640 : 0.0007194624049589038
Loss at iteration 1650 : 0.0015705949626863003
Loss at iteration 1660 : 0.00010862041381187737
Loss at iteration 1670 : 0.0009061752934940159
Loss at iteration 1680 : 0.006519116461277008
Loss at iteration 1690 : 0.0001397723244735971
Loss at iteration 1700 : 0.00041029101703315973
Loss at iteration 1710 : 0.0016420830506831408
Loss at iteration 1720 : 9.798087558010593e-05
Loss at iteration 1730 : 0.0018615078879520297
Loss at iteration 1740 : 7.776964048389345e-05
Loss at iteration 1750 : 0.0001341687748208642
The SSIM Value is: 0.983638795855812
The PSNR Value is: 46.46479940204368
the epoch is: 75
Loss at iteration 10 : 0.00021831471531186253
Loss at iteration 20 : 0.00013748255150858313
Loss at iteration 30 : 0.006104593630880117
Loss at iteration 40 : 0.001352604478597641
Loss at iteration 50 : 0.00011983612785115838
Loss at iteration 60 : 0.008548139594495296
Loss at iteration 70 : 0.0010647838935256004
Loss at iteration 80 : 0.00031353984377346933
Loss at iteration 90 : 0.001955609070137143
Loss at iteration 100 : 0.00010239111725240946
Loss at iteration 110 : 0.0021323366090655327
Loss at iteration 120 : 0.00032118166564032435
Loss at iteration 130 : 0.00020189976203255355
Loss at iteration 140 : 0.003504503984004259
Loss at iteration 150 : 6.46675907773897e-05
Loss at iteration 160 : 9.013122325995937e-05
Loss at iteration 170 : 0.00013327723718248308
Loss at iteration 180 : 0.0002273624122608453
Loss at iteration 190 : 0.000991240725852549
Loss at iteration 200 : 0.0007534847827628255
Loss at iteration 210 : 0.00489308126270771
Loss at iteration 220 : 0.00014078411913942546
Loss at iteration 230 : 0.009654072113335133
Loss at iteration 240 : 0.0010082805529236794
Loss at iteration 250 : 0.0009967682417482138
Loss at iteration 260 : 0.0017280364409089088
Loss at iteration 270 : 0.0009635646711103618
Loss at iteration 280 : 0.0005257141892798245
Loss at iteration 290 : 0.00023243066971190274
Loss at iteration 300 : 0.001968823606148362
Loss at iteration 310 : 7.430961704812944e-05
Loss at iteration 320 : 0.0008134940871968865
Loss at iteration 330 : 7.707457552896813e-05
Loss at iteration 340 : 0.00026375713059678674
Loss at iteration 350 : 0.0028142521623522043
Loss at iteration 360 : 0.0002534592058509588
Loss at iteration 370 : 0.0015144883655011654
Loss at iteration 380 : 0.0019004016648977995
Loss at iteration 390 : 0.0016765431500971317
Loss at iteration 400 : 0.009443397633731365
Loss at iteration 410 : 0.0005230730166658759
Loss at iteration 420 : 0.0003108755045104772
Loss at iteration 430 : 0.00018044257012661546
Loss at iteration 440 : 0.004202652256935835
Loss at iteration 450 : 6.698843935737386e-05
Loss at iteration 460 : 0.00017737677262630314
Loss at iteration 470 : 0.00017111917259171605
Loss at iteration 480 : 0.0010018717730417848
Loss at iteration 490 : 0.0005261904443614185
Loss at iteration 500 : 0.0001517583295935765
Loss at iteration 510 : 0.00013787392526865005
Loss at iteration 520 : 0.0014825415564700961
Loss at iteration 530 : 0.00013053853763267398
Loss at iteration 540 : 8.003745460882783e-05
Loss at iteration 550 : 0.00010113045573234558
Loss at iteration 560 : 0.0015778008382767439
Loss at iteration 570 : 0.00015867942420300096
Loss at iteration 580 : 0.00018096166604664177
Loss at iteration 590 : 0.0008135372190736234
Loss at iteration 600 : 0.00029937882209196687
Loss at iteration 610 : 0.004454097710549831
Loss at iteration 620 : 0.003570642787963152
Loss at iteration 630 : 0.00026586579042486846
Loss at iteration 640 : 0.0001320141600444913
Loss at iteration 650 : 0.0020223858300596476
Loss at iteration 660 : 0.0004992831964045763
Loss at iteration 670 : 0.0011486035073176026
Loss at iteration 680 : 0.00023332290584221482
Loss at iteration 690 : 0.003036763286218047
Loss at iteration 700 : 7.48225866118446e-05
Loss at iteration 710 : 0.00014176250260788947
Loss at iteration 720 : 0.00036726065445691347
Loss at iteration 730 : 0.00023759753094054759
Loss at iteration 740 : 0.0026928847655653954
Loss at iteration 750 : 0.0004710793145932257
Loss at iteration 760 : 0.00020157956168986857
Loss at iteration 770 : 0.0005588543135672808
Loss at iteration 780 : 0.00022291994537226856
Loss at iteration 790 : 0.0029272735118865967
Loss at iteration 800 : 0.0002540882851462811
Loss at iteration 810 : 0.00017187080811709166
Loss at iteration 820 : 0.00028209720039740205
Loss at iteration 830 : 0.0027217534370720387
Loss at iteration 840 : 0.00015669752610847354
Loss at iteration 850 : 0.00012318613880779594
Loss at iteration 860 : 4.8684680223232135e-05
Loss at iteration 870 : 0.0002762752410490066
Loss at iteration 880 : 0.00015628314577043056
Loss at iteration 890 : 0.0001242752914549783
Loss at iteration 900 : 9.403163858223706e-05
Loss at iteration 910 : 0.00022582222300115973
Loss at iteration 920 : 0.0036932877264916897
Loss at iteration 930 : 0.0003605220699682832
Loss at iteration 940 : 0.0003043419274035841
Loss at iteration 950 : 0.0024097531568259
Loss at iteration 960 : 0.004348362796008587
Loss at iteration 970 : 0.0015670913271605968
Loss at iteration 980 : 5.8750654716277495e-05
Loss at iteration 990 : 4.440311386133544e-05
Loss at iteration 1000 : 0.00028972356813028455
Loss at iteration 1010 : 0.0002234627609141171
Loss at iteration 1020 : 0.0032101189717650414
Loss at iteration 1030 : 0.002687751082703471
Loss at iteration 1040 : 8.500932017341256e-05
Loss at iteration 1050 : 0.000325177883496508
Loss at iteration 1060 : 0.0004373625270090997
Loss at iteration 1070 : 0.00033908768091350794
Loss at iteration 1080 : 0.001377604901790619
Loss at iteration 1090 : 0.00011310030822642148
Loss at iteration 1100 : 0.0013528973795473576
Loss at iteration 1110 : 0.00017654275870881975
Loss at iteration 1120 : 0.0008198569994419813
Loss at iteration 1130 : 0.00033297837944701314
Loss at iteration 1140 : 0.00018795915821101516
Loss at iteration 1150 : 0.0002342933730687946
Loss at iteration 1160 : 0.0001608312886673957
Loss at iteration 1170 : 0.0003220912185497582
Loss at iteration 1180 : 0.0006262764800339937
Loss at iteration 1190 : 0.0004176555958110839
Loss at iteration 1200 : 0.0002689846442081034
Loss at iteration 1210 : 0.00023041412350721657
Loss at iteration 1220 : 0.00043558364268392324
Loss at iteration 1230 : 0.007222118321806192
Loss at iteration 1240 : 0.001965911826118827
Loss at iteration 1250 : 0.00020860767108388245
Loss at iteration 1260 : 0.0050160838291049
Loss at iteration 1270 : 0.0014148509362712502
Loss at iteration 1280 : 0.00018865824677050114
Loss at iteration 1290 : 0.0005303153302520514
Loss at iteration 1300 : 0.000408624968258664
Loss at iteration 1310 : 0.004148036707192659
Loss at iteration 1320 : 0.00019911155686713755
Loss at iteration 1330 : 0.0044385832734405994
Loss at iteration 1340 : 0.000802405527792871
Loss at iteration 1350 : 0.004157401621341705
Loss at iteration 1360 : 0.0002763948868960142
Loss at iteration 1370 : 0.0004348616348579526
Loss at iteration 1380 : 0.00044605479342862964
Loss at iteration 1390 : 0.0001319895964115858
Loss at iteration 1400 : 0.0006237381603568792
Loss at iteration 1410 : 0.00014343217480927706
Loss at iteration 1420 : 0.00018468497728463262
Loss at iteration 1430 : 0.0006864403840154409
Loss at iteration 1440 : 9.243407839676365e-05
Loss at iteration 1450 : 0.000605098670348525
Loss at iteration 1460 : 0.0005258826422505081
Loss at iteration 1470 : 0.0004712690715678036
Loss at iteration 1480 : 0.00017168770136777312
Loss at iteration 1490 : 0.0009364739526063204
Loss at iteration 1500 : 0.00012199148477520794
Loss at iteration 1510 : 0.0038570482283830643
Loss at iteration 1520 : 0.003427275689318776
Loss at iteration 1530 : 0.0010291954968124628
Loss at iteration 1540 : 0.002016662620007992
Loss at iteration 1550 : 0.0005990733625367284
Loss at iteration 1560 : 0.0007525563705712557
Loss at iteration 1570 : 0.0002535031526349485
Loss at iteration 1580 : 0.0006503689219243824
Loss at iteration 1590 : 0.0005495150107890368
Loss at iteration 1600 : 0.0015172386774793267
Loss at iteration 1610 : 0.0003382573486305773
Loss at iteration 1620 : 6.222756201168522e-05
Loss at iteration 1630 : 0.00023788909311406314
Loss at iteration 1640 : 0.0003034476831089705
Loss at iteration 1650 : 0.003823484992608428
Loss at iteration 1660 : 0.001376833999529481
Loss at iteration 1670 : 0.00025619572261348367
Loss at iteration 1680 : 0.0023301206529140472
Loss at iteration 1690 : 0.003945760428905487
Loss at iteration 1700 : 4.922482185065746e-05
Loss at iteration 1710 : 0.00014311826089397073
Loss at iteration 1720 : 0.00020178202248644084
Loss at iteration 1730 : 0.00036679022014141083
Loss at iteration 1740 : 0.00010648519673850387
Loss at iteration 1750 : 0.000236643070820719
The SSIM Value is: 0.9823021543446091
The PSNR Value is: 46.426408074500806
the epoch is: 76
Loss at iteration 10 : 0.0002736060123424977
Loss at iteration 20 : 0.000866193207912147
Loss at iteration 30 : 0.00028623442631214857
Loss at iteration 40 : 6.612925790250301e-05
Loss at iteration 50 : 0.000545744551345706
Loss at iteration 60 : 0.00033539923606440425
Loss at iteration 70 : 0.0007069343118928373
Loss at iteration 80 : 0.00013376546849031
Loss at iteration 90 : 0.0033382405526936054
Loss at iteration 100 : 0.0003960083413403481
Loss at iteration 110 : 0.0012676101177930832
Loss at iteration 120 : 0.00010594727064017206
Loss at iteration 130 : 0.0005591423250734806
Loss at iteration 140 : 0.0018650451675057411
Loss at iteration 150 : 0.0002847653813660145
Loss at iteration 160 : 0.00011212498066015542
Loss at iteration 170 : 0.00022949367121327668
Loss at iteration 180 : 0.0023256076965481043
Loss at iteration 190 : 0.002159679541364312
Loss at iteration 200 : 0.0001340891030849889
Loss at iteration 210 : 0.00011558701226022094
Loss at iteration 220 : 0.00021568666852544993
Loss at iteration 230 : 0.0003811935894191265
Loss at iteration 240 : 0.00021698256023228168
Loss at iteration 250 : 7.647823076695204e-05
Loss at iteration 260 : 0.00023155941744334996
Loss at iteration 270 : 0.00010920866043306887
Loss at iteration 280 : 0.00028961198404431343
Loss at iteration 290 : 0.00010366884816903621
Loss at iteration 300 : 0.00014687837392557412
Loss at iteration 310 : 0.0046865325421094894
Loss at iteration 320 : 0.002094342140480876
Loss at iteration 330 : 0.0004101057129446417
Loss at iteration 340 : 0.00043826946057379246
Loss at iteration 350 : 0.0003186512039974332
Loss at iteration 360 : 0.00013132083404343575
Loss at iteration 370 : 0.00020699226297438145
Loss at iteration 380 : 0.0002900470281019807
Loss at iteration 390 : 0.0007381996256299317
Loss at iteration 400 : 0.00024232003488577902
Loss at iteration 410 : 0.0015363709535449743
Loss at iteration 420 : 0.0005130612989887595
Loss at iteration 430 : 9.842404688242823e-05
Loss at iteration 440 : 0.00040224657277576625
Loss at iteration 450 : 0.000841534580104053
Loss at iteration 460 : 0.0015368959866464138
Loss at iteration 470 : 0.002599908271804452
Loss at iteration 480 : 0.000549906340893358
Loss at iteration 490 : 0.00031882006442174315
Loss at iteration 500 : 0.0004171440377831459
Loss at iteration 510 : 0.002535085892304778
Loss at iteration 520 : 0.001428695279173553
Loss at iteration 530 : 0.0007943491800688207
Loss at iteration 540 : 0.00013770684017799795
Loss at iteration 550 : 0.00014362520596478134
Loss at iteration 560 : 0.0029845775570720434
Loss at iteration 570 : 0.0001678321568761021
Loss at iteration 580 : 0.0003228881978429854
Loss at iteration 590 : 0.0021610993426293135
Loss at iteration 600 : 0.003883780213072896
Loss at iteration 610 : 9.190422861138359e-05
Loss at iteration 620 : 0.0015012146905064583
Loss at iteration 630 : 0.0005094421794638038
Loss at iteration 640 : 0.00020393483282532543
Loss at iteration 650 : 0.00018573272973299026
Loss at iteration 660 : 0.00010741411824710667
Loss at iteration 670 : 0.0014774119481444359
Loss at iteration 680 : 0.0003564202634152025
Loss at iteration 690 : 0.0002127062762156129
Loss at iteration 700 : 0.0003784929576795548
Loss at iteration 710 : 0.0009250066941604018
Loss at iteration 720 : 0.0025555621832609177
Loss at iteration 730 : 0.0013423992786556482
Loss at iteration 740 : 0.0001252276124432683
Loss at iteration 750 : 0.00030509018688462675
Loss at iteration 760 : 0.0001652988576097414
Loss at iteration 770 : 0.0006469867075793445
Loss at iteration 780 : 0.0007989881560206413
Loss at iteration 790 : 0.0020790814887732267
Loss at iteration 800 : 0.0009640564094297588
Loss at iteration 810 : 0.00011166992044309154
Loss at iteration 820 : 0.00017983502766583115
Loss at iteration 830 : 0.00021512901003006846
Loss at iteration 840 : 3.1345018214778975e-05
Loss at iteration 850 : 0.00011558792903088033
Loss at iteration 860 : 0.0006798363756388426
Loss at iteration 870 : 0.00029484080732800066
Loss at iteration 880 : 0.0039949482306838036
Loss at iteration 890 : 0.00016101366782095283
Loss at iteration 900 : 0.0010771355591714382
Loss at iteration 910 : 0.00024651188869029284
Loss at iteration 920 : 0.0003028316132258624
Loss at iteration 930 : 0.00010781736636999995
Loss at iteration 940 : 0.0003548580571077764
Loss at iteration 950 : 0.0013383447658270597
Loss at iteration 960 : 0.0024648585822433233
Loss at iteration 970 : 0.0008788582636043429
Loss at iteration 980 : 0.0018651357386261225
Loss at iteration 990 : 0.00013291981304064393
Loss at iteration 1000 : 0.0008054322679527104
Loss at iteration 1010 : 0.00029745124629698694
Loss at iteration 1020 : 0.0001732404052745551
Loss at iteration 1030 : 0.00010327580821467564
Loss at iteration 1040 : 0.0006288597360253334
Loss at iteration 1050 : 0.000811446865554899
Loss at iteration 1060 : 0.0005724862567149103
Loss at iteration 1070 : 0.00021513254614546895
Loss at iteration 1080 : 0.0012904066825285554
Loss at iteration 1090 : 0.001314579974859953
Loss at iteration 1100 : 7.085542165441439e-05
Loss at iteration 1110 : 0.00030821311520412564
Loss at iteration 1120 : 0.0002614364493638277
Loss at iteration 1130 : 0.001315796747803688
Loss at iteration 1140 : 0.0009001297876238823
Loss at iteration 1150 : 0.0016856761649250984
Loss at iteration 1160 : 0.0028494750149548054
Loss at iteration 1170 : 0.0009963314514607191
Loss at iteration 1180 : 0.0003499891026876867
Loss at iteration 1190 : 9.697582572698593e-05
Loss at iteration 1200 : 0.0005583685706369579
Loss at iteration 1210 : 7.599956006743014e-05
Loss at iteration 1220 : 8.202144817914814e-05
Loss at iteration 1230 : 0.0022512723226100206
Loss at iteration 1240 : 0.0005564700695686042
Loss at iteration 1250 : 0.00225763488560915
Loss at iteration 1260 : 0.005695677828043699
Loss at iteration 1270 : 0.0023724741768091917
Loss at iteration 1280 : 0.0001909394486574456
Loss at iteration 1290 : 7.550011650891975e-05
Loss at iteration 1300 : 0.0008640460437163711
Loss at iteration 1310 : 0.0003297972143627703
Loss at iteration 1320 : 0.0026790660340338945
Loss at iteration 1330 : 0.006945137865841389
Loss at iteration 1340 : 8.963196160038933e-05
Loss at iteration 1350 : 0.00020727768423967063
Loss at iteration 1360 : 0.00017797842156141996
Loss at iteration 1370 : 0.0005879536038264632
Loss at iteration 1380 : 0.000571835320442915
Loss at iteration 1390 : 0.00016340265574399382
Loss at iteration 1400 : 0.0005307155661284924
Loss at iteration 1410 : 0.0011551076313480735
Loss at iteration 1420 : 6.565466901520267e-05
Loss at iteration 1430 : 0.00015178706962615252
Loss at iteration 1440 : 0.0007201835396699607
Loss at iteration 1450 : 0.0007521085208281875
Loss at iteration 1460 : 9.362402488477528e-05
Loss at iteration 1470 : 0.00042506438330747187
Loss at iteration 1480 : 0.002568694530054927
Loss at iteration 1490 : 9.861018043011427e-05
Loss at iteration 1500 : 0.0001317025162279606
Loss at iteration 1510 : 0.004933345131576061
Loss at iteration 1520 : 0.00016151934687513858
Loss at iteration 1530 : 0.00027571883401833475
Loss at iteration 1540 : 0.0009659162606112659
Loss at iteration 1550 : 0.000369365414371714
Loss at iteration 1560 : 0.0016740293940529227
Loss at iteration 1570 : 9.062434401130304e-05
Loss at iteration 1580 : 0.00017469850718043745
Loss at iteration 1590 : 0.00041546171996742487
Loss at iteration 1600 : 0.001814256189391017
Loss at iteration 1610 : 0.0006365628214552999
Loss at iteration 1620 : 5.682151095243171e-05
Loss at iteration 1630 : 0.004977166187018156
Loss at iteration 1640 : 0.002566628623753786
Loss at iteration 1650 : 2.8112948712077923e-05
Loss at iteration 1660 : 0.0003784181026276201
Loss at iteration 1670 : 0.00012741184036713094
Loss at iteration 1680 : 0.001211309339851141
Loss at iteration 1690 : 0.0007888094987720251
Loss at iteration 1700 : 0.00017234249389730394
Loss at iteration 1710 : 0.0009948990773409605
Loss at iteration 1720 : 0.0029253314714878798
Loss at iteration 1730 : 0.0014423723332583904
Loss at iteration 1740 : 0.0026810059789568186
Loss at iteration 1750 : 0.0013901784550398588
The SSIM Value is: 0.9846239580982057
The PSNR Value is: 46.50597993287746
the epoch is: 77
Loss at iteration 10 : 0.0001861925411503762
Loss at iteration 20 : 0.00024322496028617024
Loss at iteration 30 : 0.0011074842186644673
Loss at iteration 40 : 0.0041389474645257
Loss at iteration 50 : 0.0009832660434767604
Loss at iteration 60 : 0.0005720029585063457
Loss at iteration 70 : 0.00021998693409841508
Loss at iteration 80 : 0.00669343676418066
Loss at iteration 90 : 0.00047675383393652737
Loss at iteration 100 : 0.0014917587395757437
Loss at iteration 110 : 0.00039923604344949126
Loss at iteration 120 : 0.0052431495860219
Loss at iteration 130 : 7.262978033395484e-05
Loss at iteration 140 : 0.00016433981363661587
Loss at iteration 150 : 0.00020103107090108097
Loss at iteration 160 : 0.00011591284419409931
Loss at iteration 170 : 0.0002842617395799607
Loss at iteration 180 : 0.0012649174313992262
Loss at iteration 190 : 0.0033128729555755854
Loss at iteration 200 : 0.000778909889049828
Loss at iteration 210 : 0.0006183054647408426
Loss at iteration 220 : 0.0006391361821442842
Loss at iteration 230 : 0.004465193022042513
Loss at iteration 240 : 0.00057701685000211
Loss at iteration 250 : 0.004603352397680283
Loss at iteration 260 : 7.916811591712758e-05
Loss at iteration 270 : 0.00011934453505091369
Loss at iteration 280 : 0.0016237347153946757
Loss at iteration 290 : 0.000147781174746342
Loss at iteration 300 : 0.0003231118607800454
Loss at iteration 310 : 0.0003024879260919988
Loss at iteration 320 : 0.0017983682919293642
Loss at iteration 330 : 0.000341099570505321
Loss at iteration 340 : 0.00010749279317678884
Loss at iteration 350 : 0.00015033797535579652
Loss at iteration 360 : 0.0001759384322213009
Loss at iteration 370 : 0.0012284826952964067
Loss at iteration 380 : 0.00043402647133916616
Loss at iteration 390 : 0.00021450271015055478
Loss at iteration 400 : 0.002845815382897854
Loss at iteration 410 : 0.0002690674737095833
Loss at iteration 420 : 7.337606803048402e-05
Loss at iteration 430 : 0.00019311408686917275
Loss at iteration 440 : 0.005642956122756004
Loss at iteration 450 : 7.370638195425272e-05
Loss at iteration 460 : 0.0006486365455202758
Loss at iteration 470 : 0.0017211658414453268
Loss at iteration 480 : 0.00020722459885291755
Loss at iteration 490 : 5.6481920182704926e-05
Loss at iteration 500 : 0.00023658051213715225
Loss at iteration 510 : 0.0009383952128700912
Loss at iteration 520 : 0.0015667909756302834
Loss at iteration 530 : 0.0032265717163681984
Loss at iteration 540 : 0.00015428022015839815
Loss at iteration 550 : 0.00043880875455215573
Loss at iteration 560 : 0.0009315471397712827
Loss at iteration 570 : 0.00044365518260747194
Loss at iteration 580 : 0.0005159142892807722
Loss at iteration 590 : 0.0004531013546511531
Loss at iteration 600 : 0.001643859432078898
Loss at iteration 610 : 0.0004836080188397318
Loss at iteration 620 : 0.00016941718058660626
Loss at iteration 630 : 5.63415014767088e-05
Loss at iteration 640 : 0.004335924983024597
Loss at iteration 650 : 0.0037530013360083103
Loss at iteration 660 : 0.0004842860216740519
Loss at iteration 670 : 0.0002587592462077737
Loss at iteration 680 : 0.0005293174763210118
Loss at iteration 690 : 0.0003986135998275131
Loss at iteration 700 : 0.0004257740802131593
Loss at iteration 710 : 0.0036062966100871563
Loss at iteration 720 : 0.00018606892263051122
Loss at iteration 730 : 0.0005240520695224404
Loss at iteration 740 : 6.041454616934061e-05
Loss at iteration 750 : 0.0003808218752965331
Loss at iteration 760 : 0.00010998228390235454
Loss at iteration 770 : 0.00026197481201961637
Loss at iteration 780 : 0.0005613646353594959
Loss at iteration 790 : 0.002432161709293723
Loss at iteration 800 : 0.00013102397497277707
Loss at iteration 810 : 0.00022201487445272505
Loss at iteration 820 : 0.00021358582307584584
Loss at iteration 830 : 0.00014042577822692692
Loss at iteration 840 : 0.00017668528016656637
Loss at iteration 850 : 0.0002161989687010646
Loss at iteration 860 : 0.0004242181603331119
Loss at iteration 870 : 0.00022163745597936213
Loss at iteration 880 : 0.0019032647833228111
Loss at iteration 890 : 6.352350465022027e-05
Loss at iteration 900 : 0.00015844617155380547
Loss at iteration 910 : 0.0001094927720259875
Loss at iteration 920 : 0.00043968879617750645
Loss at iteration 930 : 0.00020495255012065172
Loss at iteration 940 : 0.00024647716782055795
Loss at iteration 950 : 0.0014964514411985874
Loss at iteration 960 : 0.0007193361525423825
Loss at iteration 970 : 0.003725355491042137
Loss at iteration 980 : 0.00011583354353206232
Loss at iteration 990 : 0.00032101094257086515
Loss at iteration 1000 : 0.00014315120643004775
Loss at iteration 1010 : 0.0006627078983001411
Loss at iteration 1020 : 0.0023054126650094986
Loss at iteration 1030 : 4.685021485784091e-05
Loss at iteration 1040 : 5.861534009454772e-05
Loss at iteration 1050 : 0.00016871883417479694
Loss at iteration 1060 : 0.0005713133723475039
Loss at iteration 1070 : 0.0030544474720954895
Loss at iteration 1080 : 0.0020996523089706898
Loss at iteration 1090 : 0.0010767658241093159
Loss at iteration 1100 : 0.0006938979495316744
Loss at iteration 1110 : 0.0004354353586677462
Loss at iteration 1120 : 0.0005268794484436512
Loss at iteration 1130 : 0.0008144008461385965
Loss at iteration 1140 : 0.00017355896125081927
Loss at iteration 1150 : 0.0019086331594735384
Loss at iteration 1160 : 0.004106317646801472
Loss at iteration 1170 : 0.001905130222439766
Loss at iteration 1180 : 0.0002775242319330573
Loss at iteration 1190 : 0.0002187921927543357
Loss at iteration 1200 : 7.666681631235406e-05
Loss at iteration 1210 : 0.0004132561443839222
Loss at iteration 1220 : 0.0001932973973453045
Loss at iteration 1230 : 0.0013553296448662877
Loss at iteration 1240 : 0.0003292046603746712
Loss at iteration 1250 : 0.00042359496001154184
Loss at iteration 1260 : 0.0008127290057018399
Loss at iteration 1270 : 0.00017213451792486012
Loss at iteration 1280 : 0.00011138689296785742
Loss at iteration 1290 : 0.004321535117924213
Loss at iteration 1300 : 0.002872824901714921
Loss at iteration 1310 : 0.00022952657309360802
Loss at iteration 1320 : 0.000885218265466392
Loss at iteration 1330 : 0.00042548603960312903
Loss at iteration 1340 : 0.0001392549165757373
Loss at iteration 1350 : 0.00012857347610406578
Loss at iteration 1360 : 0.006997756194323301
Loss at iteration 1370 : 0.00027945375768467784
Loss at iteration 1380 : 0.00023528540623374283
Loss at iteration 1390 : 0.0001552283065393567
Loss at iteration 1400 : 0.00018700459622777998
Loss at iteration 1410 : 0.0002158774877898395
Loss at iteration 1420 : 0.001739094266667962
Loss at iteration 1430 : 0.000689950305968523
Loss at iteration 1440 : 0.0003434470563661307
Loss at iteration 1450 : 0.0006652427837252617
Loss at iteration 1460 : 0.0008285836083814502
Loss at iteration 1470 : 0.00016621340182609856
Loss at iteration 1480 : 0.00021511715021915734
Loss at iteration 1490 : 0.002205249387770891
Loss at iteration 1500 : 0.002861187793314457
Loss at iteration 1510 : 0.00219380808994174
Loss at iteration 1520 : 6.699093501083553e-05
Loss at iteration 1530 : 0.0008242836338467896
Loss at iteration 1540 : 7.141886453609914e-05
Loss at iteration 1550 : 0.0008892020559869707
Loss at iteration 1560 : 0.00031876808498054743
Loss at iteration 1570 : 0.0005371597944758832
Loss at iteration 1580 : 0.003730793483555317
Loss at iteration 1590 : 3.7789483030792326e-05
Loss at iteration 1600 : 0.0038770558312535286
Loss at iteration 1610 : 0.00421177688986063
Loss at iteration 1620 : 0.002348292851820588
Loss at iteration 1630 : 0.00210784375667572
Loss at iteration 1640 : 0.00016419807798229158
Loss at iteration 1650 : 0.00021764225675724447
Loss at iteration 1660 : 0.002383754588663578
Loss at iteration 1670 : 0.00016991827578749508
Loss at iteration 1680 : 0.00031256990041583776
Loss at iteration 1690 : 0.00026953971246257424
Loss at iteration 1700 : 7.8016564657446e-05
Loss at iteration 1710 : 0.00014399395149666816
Loss at iteration 1720 : 0.00035298243165016174
Loss at iteration 1730 : 0.00011550969065865502
Loss at iteration 1740 : 0.0005314309382811189
Loss at iteration 1750 : 0.00032853393349796534
The SSIM Value is: 0.9754682594196387
The PSNR Value is: 46.65646581397708
the epoch is: 78
Loss at iteration 10 : 6.689004658255726e-05
Loss at iteration 20 : 0.0030612866394221783
Loss at iteration 30 : 0.00058552878908813
Loss at iteration 40 : 0.0030577259603887796
Loss at iteration 50 : 0.00014258833834901452
Loss at iteration 60 : 0.00013826426584273577
Loss at iteration 70 : 0.002440421609207988
Loss at iteration 80 : 0.0010479262564331293
Loss at iteration 90 : 0.0008986000320874155
Loss at iteration 100 : 0.0020043160766363144
Loss at iteration 110 : 0.00039261666825041175
Loss at iteration 120 : 9.74704380496405e-05
Loss at iteration 130 : 0.0032168959733098745
Loss at iteration 140 : 0.0003435155958868563
Loss at iteration 150 : 0.0023190383799374104
Loss at iteration 160 : 0.00016637914814054966
Loss at iteration 170 : 0.0005211429670453072
Loss at iteration 180 : 0.00036379037192091346
Loss at iteration 190 : 0.0004627417656593025
Loss at iteration 200 : 0.0002587352937553078
Loss at iteration 210 : 0.0005675050779245794
Loss at iteration 220 : 0.0003537654993124306
Loss at iteration 230 : 0.0004947308334521949
Loss at iteration 240 : 0.00019030515977647156
Loss at iteration 250 : 0.0009102055919356644
Loss at iteration 260 : 0.0009103291085921228
Loss at iteration 270 : 9.602293721400201e-05
Loss at iteration 280 : 0.00011970785999437794
Loss at iteration 290 : 0.0006160114426165819
Loss at iteration 300 : 0.000272198929451406
Loss at iteration 310 : 0.0004190444597043097
Loss at iteration 320 : 0.00022181557142175734
Loss at iteration 330 : 0.00030580867314711213
Loss at iteration 340 : 0.00034011900424957275
Loss at iteration 350 : 0.0004234261577948928
Loss at iteration 360 : 0.00014744888176210225
Loss at iteration 370 : 0.0001067146222339943
Loss at iteration 380 : 0.00010053929145215079
Loss at iteration 390 : 0.00012990296818315983
Loss at iteration 400 : 0.0021973801776766777
Loss at iteration 410 : 0.004100612364709377
Loss at iteration 420 : 0.00010363590263295919
Loss at iteration 430 : 0.003305265447124839
Loss at iteration 440 : 0.0007658099057152867
Loss at iteration 450 : 0.00072141905548051
Loss at iteration 460 : 0.003847892861813307
Loss at iteration 470 : 0.0002176971174776554
Loss at iteration 480 : 0.00032414720044471323
Loss at iteration 490 : 0.0030089071951806545
Loss at iteration 500 : 9.56094081629999e-05
Loss at iteration 510 : 0.003831674112007022
Loss at iteration 520 : 0.0005207950016483665
Loss at iteration 530 : 0.00035098884836770594
Loss at iteration 540 : 9.127629164140671e-05
Loss at iteration 550 : 0.00035025071701966226
Loss at iteration 560 : 0.005245020613074303
Loss at iteration 570 : 0.0002136584371328354
Loss at iteration 580 : 0.0004912423901259899
Loss at iteration 590 : 0.00034330529160797596
Loss at iteration 600 : 0.00030572296236641705
Loss at iteration 610 : 0.0006118968594819307
Loss at iteration 620 : 0.002609165385365486
Loss at iteration 630 : 0.0021203348878771067
Loss at iteration 640 : 0.00018278477364219725
Loss at iteration 650 : 0.00029827537946403027
Loss at iteration 660 : 0.00014345925592351705
Loss at iteration 670 : 0.0005278444150462747
Loss at iteration 680 : 0.0006380722625181079
Loss at iteration 690 : 0.00023944739950820804
Loss at iteration 700 : 0.00036991265369579196
Loss at iteration 710 : 0.001739094266667962
Loss at iteration 720 : 0.0006902970490045846
Loss at iteration 730 : 0.006749303080141544
Loss at iteration 740 : 0.0022617157083004713
Loss at iteration 750 : 0.00012711519957520068
Loss at iteration 760 : 0.0003206784895155579
Loss at iteration 770 : 0.000514467537868768
Loss at iteration 780 : 0.00014978996478021145
Loss at iteration 790 : 0.0007979333167895675
Loss at iteration 800 : 0.00014958700921852142
Loss at iteration 810 : 0.00014542558346875012
Loss at iteration 820 : 0.0032815926242619753
Loss at iteration 830 : 0.00018576909496914595
Loss at iteration 840 : 0.0001796583237592131
Loss at iteration 850 : 0.00010074581950902939
Loss at iteration 860 : 0.000812475336715579
Loss at iteration 870 : 0.0009776577353477478
Loss at iteration 880 : 0.0005999062559567392
Loss at iteration 890 : 0.0002205010678153485
Loss at iteration 900 : 0.00017611673683859408
Loss at iteration 910 : 0.00018660645582713187
Loss at iteration 920 : 0.00029760756297037005
Loss at iteration 930 : 0.000454662018455565
Loss at iteration 940 : 0.0008898329688236117
Loss at iteration 950 : 0.0008996195974759758
Loss at iteration 960 : 0.00019637300283648074
Loss at iteration 970 : 0.002040667925029993
Loss at iteration 980 : 0.0003873489913530648
Loss at iteration 990 : 0.00032637000549584627
Loss at iteration 1000 : 8.155804971465841e-05
Loss at iteration 1010 : 0.000441813055658713
Loss at iteration 1020 : 0.00012801995035260916
Loss at iteration 1030 : 0.006794665940105915
Loss at iteration 1040 : 0.002606579102575779
Loss at iteration 1050 : 0.0010398983722552657
Loss at iteration 1060 : 0.0018388241296634078
Loss at iteration 1070 : 0.00013390384265221655
Loss at iteration 1080 : 0.0011453801998868585
Loss at iteration 1090 : 0.00027514342218637466
Loss at iteration 1100 : 0.00038469929131679237
Loss at iteration 1110 : 0.00046351441415026784
Loss at iteration 1120 : 0.0001349386147921905
Loss at iteration 1130 : 0.0001892441650852561
Loss at iteration 1140 : 0.004031931981444359
Loss at iteration 1150 : 0.0003035190748050809
Loss at iteration 1160 : 0.00012089552183169872
Loss at iteration 1170 : 0.0002662047336343676
Loss at iteration 1180 : 0.0008334196754731238
Loss at iteration 1190 : 0.00011698968592099845
Loss at iteration 1200 : 0.0028386227786540985
Loss at iteration 1210 : 0.002630318282172084
Loss at iteration 1220 : 0.0037161835934966803
Loss at iteration 1230 : 0.0006542807095684111
Loss at iteration 1240 : 6.402639701263979e-05
Loss at iteration 1250 : 0.0008709791582077742
Loss at iteration 1260 : 0.00422258535400033
Loss at iteration 1270 : 6.322380068013445e-05
Loss at iteration 1280 : 0.0008785204263404012
Loss at iteration 1290 : 7.430904224747792e-05
Loss at iteration 1300 : 0.004070604220032692
Loss at iteration 1310 : 0.00011789228301495314
Loss at iteration 1320 : 6.488268991233781e-05
Loss at iteration 1330 : 0.0005082724965177476
Loss at iteration 1340 : 0.00021719087089877576
Loss at iteration 1350 : 0.0003040516749024391
Loss at iteration 1360 : 0.00022455997532233596
Loss at iteration 1370 : 0.0009395556407980621
Loss at iteration 1380 : 0.0009844587184488773
Loss at iteration 1390 : 0.0010660794796422124
Loss at iteration 1400 : 0.000527992146089673
Loss at iteration 1410 : 0.0007161179673857987
Loss at iteration 1420 : 0.00020688715449068695
Loss at iteration 1430 : 0.008922739885747433
Loss at iteration 1440 : 0.0006692862953059375
Loss at iteration 1450 : 0.002675801981240511
Loss at iteration 1460 : 7.17083239578642e-05
Loss at iteration 1470 : 0.0002894418721552938
Loss at iteration 1480 : 0.000551387551240623
Loss at iteration 1490 : 0.00015155145956669003
Loss at iteration 1500 : 0.0015181791968643665
Loss at iteration 1510 : 0.000513642851728946
Loss at iteration 1520 : 0.0005661016330122948
Loss at iteration 1530 : 5.2977447921875864e-05
Loss at iteration 1540 : 0.0001335064007434994
Loss at iteration 1550 : 0.0001093058890546672
Loss at iteration 1560 : 9.288080764235929e-05
Loss at iteration 1570 : 7.657835521968082e-05
Loss at iteration 1580 : 0.0008236659923568368
Loss at iteration 1590 : 0.006832410115748644
Loss at iteration 1600 : 0.0002317071775905788
Loss at iteration 1610 : 0.00420581828802824
Loss at iteration 1620 : 0.00011812233424279839
Loss at iteration 1630 : 0.0009180463384836912
Loss at iteration 1640 : 0.00014460698002949357
Loss at iteration 1650 : 0.001996369566768408
Loss at iteration 1660 : 0.00012637174222618341
Loss at iteration 1670 : 0.0010662402492016554
Loss at iteration 1680 : 0.001760454848408699
Loss at iteration 1690 : 0.00043789573828689754
Loss at iteration 1700 : 0.0006495568086393178
Loss at iteration 1710 : 0.0038004424422979355
Loss at iteration 1720 : 0.003367276396602392
Loss at iteration 1730 : 0.0007594788912683725
Loss at iteration 1740 : 0.0045261993072927
Loss at iteration 1750 : 0.0002723309153225273
The SSIM Value is: 0.9782476178349903
The PSNR Value is: 46.32888177207913
the epoch is: 79
Loss at iteration 10 : 0.000527575146406889
Loss at iteration 20 : 0.00044809142127633095
Loss at iteration 30 : 0.001032048836350441
Loss at iteration 40 : 0.0003294491907581687
Loss at iteration 50 : 0.00034114677691832185
Loss at iteration 60 : 0.0009530481765978038
Loss at iteration 70 : 0.00012929584772791713
Loss at iteration 80 : 0.0010108555434271693
Loss at iteration 90 : 0.0037434170953929424
Loss at iteration 100 : 0.006514000706374645
Loss at iteration 110 : 0.00010353262769058347
Loss at iteration 120 : 0.002117122756317258
Loss at iteration 130 : 0.003002675250172615
Loss at iteration 140 : 0.0015707848360762
Loss at iteration 150 : 4.914152668789029e-05
Loss at iteration 160 : 0.0018682082882151008
Loss at iteration 170 : 0.00024159457825589925
Loss at iteration 180 : 0.0003429887583479285
Loss at iteration 190 : 0.001272974070161581
Loss at iteration 200 : 0.0005477401427924633
Loss at iteration 210 : 0.0001374470884911716
Loss at iteration 220 : 0.0012765220599249005
Loss at iteration 230 : 0.00021059007849544287
Loss at iteration 240 : 0.0002360323560424149
Loss at iteration 250 : 0.0001445980742573738
Loss at iteration 260 : 0.0011382141383364797
Loss at iteration 270 : 0.0014932628255337477
Loss at iteration 280 : 0.0008999004494398832
Loss at iteration 290 : 0.0034201231319457293
Loss at iteration 300 : 0.00027395199867896736
Loss at iteration 310 : 0.00021329348965082318
Loss at iteration 320 : 0.0003541863989084959
Loss at iteration 330 : 0.0007856519659981132
Loss at iteration 340 : 0.0002746481040958315
Loss at iteration 350 : 0.00035064658732153475
Loss at iteration 360 : 0.00020547202439047396
Loss at iteration 370 : 0.00018858863040804863
Loss at iteration 380 : 0.0006566825322806835
Loss at iteration 390 : 0.004777619149535894
Loss at iteration 400 : 0.0030401803087443113
Loss at iteration 410 : 0.001243298640474677
Loss at iteration 420 : 6.405412568710744e-05
Loss at iteration 430 : 0.0007359458832070231
Loss at iteration 440 : 0.0048399693332612514
Loss at iteration 450 : 0.00027353133191354573
Loss at iteration 460 : 0.0015812383498996496
Loss at iteration 470 : 0.0006429990753531456
Loss at iteration 480 : 7.080398791003972e-05
Loss at iteration 490 : 0.0024740523658692837
Loss at iteration 500 : 0.0030515308026224375
Loss at iteration 510 : 0.0007144222618080676
Loss at iteration 520 : 0.00018339217058382928
Loss at iteration 530 : 0.0002436760114505887
Loss at iteration 540 : 0.00010656742961145937
Loss at iteration 550 : 0.00025657066726125777
Loss at iteration 560 : 0.0010504102101549506
Loss at iteration 570 : 0.002228133613243699
Loss at iteration 580 : 0.00014858777285553515
Loss at iteration 590 : 0.0009848909685388207
Loss at iteration 600 : 0.00014362833462655544
Loss at iteration 610 : 0.0004111270827706903
Loss at iteration 620 : 0.001019626623019576
Loss at iteration 630 : 0.00026207129121758044
Loss at iteration 640 : 0.0001881451898952946
Loss at iteration 650 : 0.001787514891475439
Loss at iteration 660 : 8.27688563731499e-05
Loss at iteration 670 : 0.00046012678649276495
Loss at iteration 680 : 0.003114506369456649
Loss at iteration 690 : 0.001340805902145803
Loss at iteration 700 : 5.301627243170515e-05
Loss at iteration 710 : 0.0034031071700155735
Loss at iteration 720 : 0.00021804377320222557
Loss at iteration 730 : 7.425853254972026e-05
Loss at iteration 740 : 0.00039042290882207453
Loss at iteration 750 : 0.00014875232591293752
Loss at iteration 760 : 0.0038147629238665104
Loss at iteration 770 : 0.00045380694791674614
Loss at iteration 780 : 0.00231477664783597
Loss at iteration 790 : 0.00018119113519787788
Loss at iteration 800 : 0.0003341218689456582
Loss at iteration 810 : 0.0003062517789658159
Loss at iteration 820 : 0.00018539968004915863
Loss at iteration 830 : 0.0023784576915204525
Loss at iteration 840 : 0.00027834647335112095
Loss at iteration 850 : 0.0003029756771866232
Loss at iteration 860 : 0.0003782869316637516
Loss at iteration 870 : 0.0004138660151511431
Loss at iteration 880 : 0.0004911888390779495
Loss at iteration 890 : 0.0003931354731321335
Loss at iteration 900 : 0.0050125764682888985
Loss at iteration 910 : 0.00041906285332515836
Loss at iteration 920 : 0.0002041867410298437
Loss at iteration 930 : 0.0013798398431390524
Loss at iteration 940 : 0.0007578125223517418
Loss at iteration 950 : 0.0026399176567792892
Loss at iteration 960 : 0.00014800943608861417
Loss at iteration 970 : 0.002151691587641835
Loss at iteration 980 : 0.004273668862879276
Loss at iteration 990 : 0.002892447169870138
Loss at iteration 1000 : 0.00037538446485996246
Loss at iteration 1010 : 0.0003016228147316724
Loss at iteration 1020 : 0.00011423717660363764
Loss at iteration 1030 : 0.0019501667702570558
Loss at iteration 1040 : 0.0005353884189389646
Loss at iteration 1050 : 0.00031830836087465286
Loss at iteration 1060 : 0.000523012422490865
Loss at iteration 1070 : 0.0038998639211058617
Loss at iteration 1080 : 0.00016669972683303058
Loss at iteration 1090 : 0.0006137185264378786
Loss at iteration 1100 : 0.002874526660889387
Loss at iteration 1110 : 0.0012570105027407408
Loss at iteration 1120 : 0.0008706669323146343
Loss at iteration 1130 : 0.001418672502040863
Loss at iteration 1140 : 0.00023459375370293856
Loss at iteration 1150 : 0.00028997924528084695
Loss at iteration 1160 : 0.00016322250303346664
Loss at iteration 1170 : 0.0006550237303599715
Loss at iteration 1180 : 0.0003631541330832988
Loss at iteration 1190 : 0.00044808859820477664
Loss at iteration 1200 : 0.00015965242346283048
Loss at iteration 1210 : 0.003055378794670105
Loss at iteration 1220 : 0.00168112653773278
Loss at iteration 1230 : 0.002584370318800211
Loss at iteration 1240 : 0.00887579657137394
Loss at iteration 1250 : 0.0001195404474856332
Loss at iteration 1260 : 0.0019783934112638235
Loss at iteration 1270 : 0.0007893452420830727
Loss at iteration 1280 : 0.00012684790999628603
Loss at iteration 1290 : 0.00010044891678262502
Loss at iteration 1300 : 0.0008574527455493808
Loss at iteration 1310 : 0.00024119889712892473
Loss at iteration 1320 : 0.0005864884587936103
Loss at iteration 1330 : 0.00022343220189213753
Loss at iteration 1340 : 0.0005527204484678805
Loss at iteration 1350 : 0.0004093642346560955
Loss at iteration 1360 : 0.00017359583580400795
Loss at iteration 1370 : 0.0013374555855989456
Loss at iteration 1380 : 0.00013495300663635135
Loss at iteration 1390 : 0.00022229983005672693
Loss at iteration 1400 : 0.00027223333017900586
Loss at iteration 1410 : 0.0003117775486316532
Loss at iteration 1420 : 0.00014194424147717655
Loss at iteration 1430 : 0.00025974653544835746
Loss at iteration 1440 : 0.0005783664528280497
Loss at iteration 1450 : 0.0018392186611890793
Loss at iteration 1460 : 0.0020170484203845263
Loss at iteration 1470 : 0.0002673851849976927
Loss at iteration 1480 : 0.0002935215597972274
Loss at iteration 1490 : 0.0008059460087679327
Loss at iteration 1500 : 5.919764225836843e-05
Loss at iteration 1510 : 0.0007160278037190437
Loss at iteration 1520 : 0.0007536585326306522
Loss at iteration 1530 : 0.00011460139648988843
Loss at iteration 1540 : 0.0001820436300477013
Loss at iteration 1550 : 0.000192423933185637
Loss at iteration 1560 : 0.00012769055319949985
Loss at iteration 1570 : 0.0002221942413598299
Loss at iteration 1580 : 0.0003648781275842339
Loss at iteration 1590 : 0.0003400132118258625
Loss at iteration 1600 : 0.00027388264425098896
Loss at iteration 1610 : 0.0010198104428127408
Loss at iteration 1620 : 5.3358933655545115e-05
Loss at iteration 1630 : 0.0024390490725636482
Loss at iteration 1640 : 0.00039316408219747245
Loss at iteration 1650 : 0.00019191585306543857
Loss at iteration 1660 : 0.0007560111116617918
Loss at iteration 1670 : 0.0013490138808265328
Loss at iteration 1680 : 0.00010570513404672965
Loss at iteration 1690 : 0.00023074868659023196
Loss at iteration 1700 : 4.699378405348398e-05
Loss at iteration 1710 : 0.00023104056890588254
Loss at iteration 1720 : 0.00012328033335506916
Loss at iteration 1730 : 0.0003710681339725852
Loss at iteration 1740 : 0.0004114595358259976
Loss at iteration 1750 : 0.0001399093453073874
The SSIM Value is: 0.9758636098076069
The PSNR Value is: 46.38768629040487
the epoch is: 80
Loss at iteration 10 : 7.178689702413976e-05
Loss at iteration 20 : 0.00012387102469801903
Loss at iteration 30 : 0.00010842132905963808
Loss at iteration 40 : 0.00033731391886249185
Loss at iteration 50 : 0.0026961478870362043
Loss at iteration 60 : 0.00013013310672249645
Loss at iteration 70 : 0.00018995169375557452
Loss at iteration 80 : 0.000476569082820788
Loss at iteration 90 : 0.0003162357024848461
Loss at iteration 100 : 0.0005602437886409461
Loss at iteration 110 : 0.0003547016531229019
Loss at iteration 120 : 0.0002687130472622812
Loss at iteration 130 : 0.00046132522402331233
Loss at iteration 140 : 0.0007806154899299145
Loss at iteration 150 : 0.0007177359075285494
Loss at iteration 160 : 0.0027769114822149277
Loss at iteration 170 : 0.0009797030361369252
Loss at iteration 180 : 0.0008540945127606392
Loss at iteration 190 : 0.0004575343045871705
Loss at iteration 200 : 8.304082439281046e-05
Loss at iteration 210 : 0.0034068499226123095
Loss at iteration 220 : 0.00026603788137435913
Loss at iteration 230 : 0.00038078869692981243
Loss at iteration 240 : 0.00013356564159039408
Loss at iteration 250 : 0.0008212043903768063
Loss at iteration 260 : 6.360452243825421e-05
Loss at iteration 270 : 0.0003696937928907573
Loss at iteration 280 : 0.010192418470978737
Loss at iteration 290 : 0.00025656522484496236
Loss at iteration 300 : 0.0002506384043954313
Loss at iteration 310 : 0.000155483212438412
Loss at iteration 320 : 0.00018121942412108183
Loss at iteration 330 : 0.00011660785094136372
Loss at iteration 340 : 0.00028172991005703807
Loss at iteration 350 : 0.0023760232143104076
Loss at iteration 360 : 0.0004152400651946664
Loss at iteration 370 : 0.002397877397015691
Loss at iteration 380 : 0.00024672705330885947
Loss at iteration 390 : 0.002048517344519496
Loss at iteration 400 : 0.003166989190503955
Loss at iteration 410 : 0.001930557074956596
Loss at iteration 420 : 0.002122757490724325
Loss at iteration 430 : 0.00011070694017689675
Loss at iteration 440 : 0.0022674589417874813
Loss at iteration 450 : 0.00019564680405892432
Loss at iteration 460 : 6.377720274031162e-05
Loss at iteration 470 : 7.218903920147568e-05
Loss at iteration 480 : 8.355708268936723e-05
Loss at iteration 490 : 0.00047488519339822233
Loss at iteration 500 : 0.00035516073694452643
Loss at iteration 510 : 4.79687842016574e-05
Loss at iteration 520 : 0.0016869609244167805
Loss at iteration 530 : 0.0003033640969078988
Loss at iteration 540 : 0.00038008266710676253
Loss at iteration 550 : 0.0011129681952297688
Loss at iteration 560 : 0.00014002350508235395
Loss at iteration 570 : 0.0005858300719410181
Loss at iteration 580 : 0.0019358003046363592
Loss at iteration 590 : 0.0005992762162350118
Loss at iteration 600 : 0.004044364672154188
Loss at iteration 610 : 0.0004669962218031287
Loss at iteration 620 : 0.00041455987957306206
Loss at iteration 630 : 0.0010188458254560828
Loss at iteration 640 : 0.0033748832065612078
Loss at iteration 650 : 0.0001728779898257926
Loss at iteration 660 : 0.00022492301650345325
Loss at iteration 670 : 0.00034084581420756876
Loss at iteration 680 : 0.00019406684441491961
Loss at iteration 690 : 0.0018022304866462946
Loss at iteration 700 : 0.0002734344161581248
Loss at iteration 710 : 0.0005671378457918763
Loss at iteration 720 : 0.00020591827342286706
Loss at iteration 730 : 9.710564336273819e-05
Loss at iteration 740 : 0.0008769462583586574
Loss at iteration 750 : 6.157622556202114e-05
Loss at iteration 760 : 0.0027896191459149122
Loss at iteration 770 : 0.0009757919469848275
Loss at iteration 780 : 0.0002634562843013555
Loss at iteration 790 : 0.004451977089047432
Loss at iteration 800 : 0.002422645455226302
Loss at iteration 810 : 0.0001715801772661507
Loss at iteration 820 : 0.0003633536980487406
Loss at iteration 830 : 0.0019365930929780006
Loss at iteration 840 : 8.909866301110014e-05
Loss at iteration 850 : 0.002822963986545801
Loss at iteration 860 : 0.0007460752967745066
Loss at iteration 870 : 0.00013525388203561306
Loss at iteration 880 : 0.0008115987875498831
Loss at iteration 890 : 7.72397470427677e-05
Loss at iteration 900 : 0.0005000715027563274
Loss at iteration 910 : 0.00026731996331363916
Loss at iteration 920 : 0.0002252019476145506
Loss at iteration 930 : 0.0011514852521941066
Loss at iteration 940 : 0.0035289363004267216
Loss at iteration 950 : 0.00031482227495871484
Loss at iteration 960 : 0.0012516085989773273
Loss at iteration 970 : 0.00034020349266938865
Loss at iteration 980 : 0.003957789856940508
Loss at iteration 990 : 0.000543676083907485
Loss at iteration 1000 : 0.001243454753421247
Loss at iteration 1010 : 0.0007415214786306024
Loss at iteration 1020 : 0.00016951019642874599
Loss at iteration 1030 : 0.00021012140496168286
Loss at iteration 1040 : 8.514914225088432e-05
Loss at iteration 1050 : 0.0006043968605808914
Loss at iteration 1060 : 0.0003799242549575865
Loss at iteration 1070 : 5.891770706512034e-05
Loss at iteration 1080 : 0.0006533341365866363
Loss at iteration 1090 : 0.00012716598575934768
Loss at iteration 1100 : 0.0008027415024116635
Loss at iteration 1110 : 0.00024656072491779923
Loss at iteration 1120 : 0.0010560913942754269
Loss at iteration 1130 : 0.005143097601830959
Loss at iteration 1140 : 0.0006407529581338167
Loss at iteration 1150 : 0.00019798979337792844
Loss at iteration 1160 : 0.00016629010497126728
Loss at iteration 1170 : 0.0012364527210593224
Loss at iteration 1180 : 0.00010591791942715645
Loss at iteration 1190 : 0.00044293515384197235
Loss at iteration 1200 : 0.00020142336143180728
Loss at iteration 1210 : 0.00013988357386551797
Loss at iteration 1220 : 0.00037957174936309457
Loss at iteration 1230 : 0.00043814972741529346
Loss at iteration 1240 : 0.001031583407893777
Loss at iteration 1250 : 0.0012359187239781022
Loss at iteration 1260 : 0.00025150494184345007
Loss at iteration 1270 : 0.00010611268226057291
Loss at iteration 1280 : 0.0015048349741846323
Loss at iteration 1290 : 0.0003205106477253139
Loss at iteration 1300 : 0.00010552783351158723
Loss at iteration 1310 : 0.00017437795759178698
Loss at iteration 1320 : 0.0007046141545288265
Loss at iteration 1330 : 0.0003810398920904845
Loss at iteration 1340 : 0.00023764721117913723
Loss at iteration 1350 : 0.000321322149829939
Loss at iteration 1360 : 5.3608906455338e-05
Loss at iteration 1370 : 0.0027331439778208733
Loss at iteration 1380 : 0.0034056969452649355
Loss at iteration 1390 : 8.028934098547325e-05
Loss at iteration 1400 : 0.00031193962786346674
Loss at iteration 1410 : 0.0004654164076782763
Loss at iteration 1420 : 0.002828545169904828
Loss at iteration 1430 : 0.00034165289252996445
Loss at iteration 1440 : 0.0010835151188075542
Loss at iteration 1450 : 0.002062948187813163
Loss at iteration 1460 : 0.0001183990461868234
Loss at iteration 1470 : 0.0002431790198897943
Loss at iteration 1480 : 0.00044888019328936934
Loss at iteration 1490 : 0.003810304682701826
Loss at iteration 1500 : 0.0006094079581089318
Loss at iteration 1510 : 0.001268377061933279
Loss at iteration 1520 : 0.0006651866133324802
Loss at iteration 1530 : 3.424426176934503e-05
Loss at iteration 1540 : 0.0003577651223167777
Loss at iteration 1550 : 6.445985491154715e-05
Loss at iteration 1560 : 0.0001499979553045705
Loss at iteration 1570 : 0.0016356065170839429
Loss at iteration 1580 : 0.00012393119686748832
Loss at iteration 1590 : 0.0001609745086170733
Loss at iteration 1600 : 0.00015190959675237536
Loss at iteration 1610 : 0.00039875286165624857
Loss at iteration 1620 : 0.00011962282587774098
Loss at iteration 1630 : 5.566575055127032e-05
Loss at iteration 1640 : 0.0001646862947382033
Loss at iteration 1650 : 0.00022403935145121068
Loss at iteration 1660 : 0.0026510339230298996
Loss at iteration 1670 : 0.0003265943378210068
Loss at iteration 1680 : 0.0005445332499220967
Loss at iteration 1690 : 0.0005647216457873583
Loss at iteration 1700 : 0.001202625222504139
Loss at iteration 1710 : 0.00019677315140143037
Loss at iteration 1720 : 8.97075588000007e-05
Loss at iteration 1730 : 0.0013947135303169489
Loss at iteration 1740 : 0.0001938919012900442
Loss at iteration 1750 : 0.00023876976047176868
The SSIM Value is: 0.9821408734972782
The PSNR Value is: 46.307904999686755
the epoch is: 81
Loss at iteration 10 : 0.00016659748507663608
Loss at iteration 20 : 0.00013590496382676065
Loss at iteration 30 : 0.00018731153977569193
Loss at iteration 40 : 0.0008035310311242938
Loss at iteration 50 : 0.0019087155815213919
Loss at iteration 60 : 9.185773524222896e-05
Loss at iteration 70 : 0.004025550559163094
Loss at iteration 80 : 0.00018366897711530328
Loss at iteration 90 : 0.0003162785724271089
Loss at iteration 100 : 0.0009874306851997972
Loss at iteration 110 : 0.00010964708053506911
Loss at iteration 120 : 0.0007406204240396619
Loss at iteration 130 : 0.0004535952175501734
Loss at iteration 140 : 0.00021428742911666632
Loss at iteration 150 : 0.00028664415003731847
Loss at iteration 160 : 0.0002623327891342342
Loss at iteration 170 : 0.0004305172769818455
Loss at iteration 180 : 0.0006370681803673506
Loss at iteration 190 : 7.376545545412228e-05
Loss at iteration 200 : 0.0026676806155592203
Loss at iteration 210 : 0.0011777421459555626
Loss at iteration 220 : 0.00012356953811831772
Loss at iteration 230 : 8.694583812030032e-05
Loss at iteration 240 : 0.0025697608944028616
Loss at iteration 250 : 0.00014013456529937685
Loss at iteration 260 : 0.002111760899424553
Loss at iteration 270 : 0.0033772429451346397
Loss at iteration 280 : 0.0007569959852844477
Loss at iteration 290 : 0.0023229606449604034
Loss at iteration 300 : 0.00010729640780482441
Loss at iteration 310 : 0.00030637081363238394
Loss at iteration 320 : 0.00022416410502046347
Loss at iteration 330 : 0.0025321098510175943
Loss at iteration 340 : 0.00011229071242269129
Loss at iteration 350 : 0.00016490912821609527
Loss at iteration 360 : 8.561783761251718e-05
Loss at iteration 370 : 0.0024078686255961657
Loss at iteration 380 : 0.00029182652360759676
Loss at iteration 390 : 0.001334836008027196
Loss at iteration 400 : 0.0001366555516142398
Loss at iteration 410 : 0.0029636514373123646
Loss at iteration 420 : 0.00018677135813049972
Loss at iteration 430 : 0.0008131988579407334
Loss at iteration 440 : 0.0011914677452296019
Loss at iteration 450 : 0.000846404698677361
Loss at iteration 460 : 0.0010489479172974825
Loss at iteration 470 : 0.00023553636856377125
Loss at iteration 480 : 0.0019314114470034838
Loss at iteration 490 : 0.00023383257212117314
Loss at iteration 500 : 0.0007491455180570483
Loss at iteration 510 : 0.0002062120329355821
Loss at iteration 520 : 0.002546881791204214
Loss at iteration 530 : 0.00013357633724808693
Loss at iteration 540 : 0.0012850923230871558
Loss at iteration 550 : 0.0002603505563456565
Loss at iteration 560 : 0.0003513773554004729
Loss at iteration 570 : 0.0001933713792823255
Loss at iteration 580 : 0.00018683103553485125
Loss at iteration 590 : 0.0008677559089846909
Loss at iteration 600 : 0.002286113565787673
Loss at iteration 610 : 0.0035681065637618303
Loss at iteration 620 : 0.00042466737795621157
Loss at iteration 630 : 0.0018694027094170451
Loss at iteration 640 : 0.00042738899355754256
Loss at iteration 650 : 0.00024154045968316495
Loss at iteration 660 : 0.00048338714987039566
Loss at iteration 670 : 0.000594551267568022
Loss at iteration 680 : 0.0006241132505238056
Loss at iteration 690 : 0.0010747377527877688
Loss at iteration 700 : 0.0005077274981886148
Loss at iteration 710 : 0.000972819747403264
Loss at iteration 720 : 0.0002973414375446737
Loss at iteration 730 : 0.00017761625349521637
Loss at iteration 740 : 0.0023545054718852043
Loss at iteration 750 : 0.00069738260935992
Loss at iteration 760 : 0.00091287971008569
Loss at iteration 770 : 0.0009162916103377938
Loss at iteration 780 : 0.0003463065659161657
Loss at iteration 790 : 7.021161582088098e-05
Loss at iteration 800 : 0.0015420098789036274
Loss at iteration 810 : 0.0002853723999578506
Loss at iteration 820 : 0.0003660800866782665
Loss at iteration 830 : 6.935882265679538e-05
Loss at iteration 840 : 0.0027915630489587784
Loss at iteration 850 : 0.0002171127707697451
Loss at iteration 860 : 0.0001444282243028283
Loss at iteration 870 : 0.004594164900481701
Loss at iteration 880 : 0.0001234887749888003
Loss at iteration 890 : 9.727079304866493e-05
Loss at iteration 900 : 0.0003267256252001971
Loss at iteration 910 : 0.00047737275599502027
Loss at iteration 920 : 0.0030061157885938883
Loss at iteration 930 : 0.0007999829831533134
Loss at iteration 940 : 5.183507892070338e-05
Loss at iteration 950 : 0.00191633275244385
Loss at iteration 960 : 0.002580831991508603
Loss at iteration 970 : 0.0031035186257213354
Loss at iteration 980 : 0.00043310350156389177
Loss at iteration 990 : 8.646365313325077e-05
Loss at iteration 1000 : 8.14160011941567e-05
Loss at iteration 1010 : 0.0006292291800491512
Loss at iteration 1020 : 0.003796732984483242
Loss at iteration 1030 : 0.0004645812732633203
Loss at iteration 1040 : 0.003457038663327694
Loss at iteration 1050 : 0.0004843707720283419
Loss at iteration 1060 : 0.0002371318405494094
Loss at iteration 1070 : 0.00017063473933376372
Loss at iteration 1080 : 0.0009294867049902678
Loss at iteration 1090 : 0.000331714516505599
Loss at iteration 1100 : 0.002002812922000885
Loss at iteration 1110 : 0.0001754307741066441
Loss at iteration 1120 : 0.0057238065637648106
Loss at iteration 1130 : 7.459812331944704e-05
Loss at iteration 1140 : 0.0001363327173748985
Loss at iteration 1150 : 0.00011300425103399903
Loss at iteration 1160 : 0.0002794855390675366
Loss at iteration 1170 : 0.00035155672230757773
Loss at iteration 1180 : 0.0006775090005248785
Loss at iteration 1190 : 0.00209068669937551
Loss at iteration 1200 : 0.0003668678109534085
Loss at iteration 1210 : 0.0014607415068894625
Loss at iteration 1220 : 0.00010602147085592151
Loss at iteration 1230 : 0.0004605838912539184
Loss at iteration 1240 : 4.51828382210806e-05
Loss at iteration 1250 : 0.0007375937420874834
Loss at iteration 1260 : 0.000485174881760031
Loss at iteration 1270 : 0.00022183838882483542
Loss at iteration 1280 : 0.00154418486636132
Loss at iteration 1290 : 0.0001747698988765478
Loss at iteration 1300 : 9.308978769695386e-05
Loss at iteration 1310 : 0.00027098937425762415
Loss at iteration 1320 : 0.00032036981428973377
Loss at iteration 1330 : 0.0009014826500788331
Loss at iteration 1340 : 0.00026633572997525334
Loss at iteration 1350 : 0.00011463762348284945
Loss at iteration 1360 : 0.00010870397818507627
Loss at iteration 1370 : 0.0014879372902214527
Loss at iteration 1380 : 0.0004173250636085868
Loss at iteration 1390 : 0.0003920846211258322
Loss at iteration 1400 : 7.844209903851151e-05
Loss at iteration 1410 : 0.0025652393233031034
Loss at iteration 1420 : 0.0013550937874242663
Loss at iteration 1430 : 0.0011392309097573161
Loss at iteration 1440 : 0.0002986696781590581
Loss at iteration 1450 : 0.00015495059778913856
Loss at iteration 1460 : 0.000617050682194531
Loss at iteration 1470 : 0.00013201525143813342
Loss at iteration 1480 : 0.00010659806139301509
Loss at iteration 1490 : 0.00013881694758310914
Loss at iteration 1500 : 0.00026236005942337215
Loss at iteration 1510 : 0.0015214409213513136
Loss at iteration 1520 : 0.005279964301735163
Loss at iteration 1530 : 0.00012529939704108983
Loss at iteration 1540 : 0.00023636725381948054
Loss at iteration 1550 : 7.728314812993631e-05
Loss at iteration 1560 : 0.00021655112504959106
Loss at iteration 1570 : 0.00037800671998411417
Loss at iteration 1580 : 0.0009441532311029732
Loss at iteration 1590 : 0.002898445585742593
Loss at iteration 1600 : 5.64718538953457e-05
Loss at iteration 1610 : 0.0029732107650488615
Loss at iteration 1620 : 0.00018946465570479631
Loss at iteration 1630 : 0.00022931364946998656
Loss at iteration 1640 : 0.00038485031109303236
Loss at iteration 1650 : 0.00028414116241037846
Loss at iteration 1660 : 0.002239836612716317
Loss at iteration 1670 : 0.0022340023424476385
Loss at iteration 1680 : 0.0004231086350046098
Loss at iteration 1690 : 0.0024516757111996412
Loss at iteration 1700 : 0.0007652684580534697
Loss at iteration 1710 : 0.0003592405701056123
Loss at iteration 1720 : 0.006517572328448296
Loss at iteration 1730 : 0.0005136238760314882
Loss at iteration 1740 : 0.001754901371896267
Loss at iteration 1750 : 0.00018944581097457558
The SSIM Value is: 0.9849448394407785
The PSNR Value is: 46.27406300112014
the epoch is: 82
Loss at iteration 10 : 0.0007574891205877066
Loss at iteration 20 : 0.00012092076940461993
Loss at iteration 30 : 0.0011587495682761073
Loss at iteration 40 : 0.0011301676277071238
Loss at iteration 50 : 0.0006288234144449234
Loss at iteration 60 : 0.005935185588896275
Loss at iteration 70 : 0.0035411142744123936
Loss at iteration 80 : 0.0013573123142123222
Loss at iteration 90 : 0.00017127665341831744
Loss at iteration 100 : 0.0003580140764825046
Loss at iteration 110 : 0.002955493051558733
Loss at iteration 120 : 0.0009430702775716782
Loss at iteration 130 : 0.004324440844357014
Loss at iteration 140 : 0.003873676061630249
Loss at iteration 150 : 0.00012797668750863522
Loss at iteration 160 : 0.0014932691119611263
Loss at iteration 170 : 0.0002651868271641433
Loss at iteration 180 : 0.0005226174835115671
Loss at iteration 190 : 0.0004884845111519098
Loss at iteration 200 : 0.001347420155070722
Loss at iteration 210 : 0.00018176012963522226
Loss at iteration 220 : 0.00011444406118243933
Loss at iteration 230 : 0.00018126395298168063
Loss at iteration 240 : 0.00013968776329420507
Loss at iteration 250 : 0.0005150832002982497
Loss at iteration 260 : 0.00033596029970794916
Loss at iteration 270 : 0.002330016577616334
Loss at iteration 280 : 0.00032015074975788593
Loss at iteration 290 : 0.000820286339148879
Loss at iteration 300 : 0.003928434103727341
Loss at iteration 310 : 0.00045181121095083654
Loss at iteration 320 : 0.0009565628133714199
Loss at iteration 330 : 0.0003977533197030425
Loss at iteration 340 : 0.0021286956034600735
Loss at iteration 350 : 0.00014236407878343016
Loss at iteration 360 : 0.00014822895172983408
Loss at iteration 370 : 0.00012384603905957192
Loss at iteration 380 : 0.00024525003391318023
Loss at iteration 390 : 0.0003165035741403699
Loss at iteration 400 : 0.0007604141137562692
Loss at iteration 410 : 9.578866593074054e-05
Loss at iteration 420 : 0.0005177161074243486
Loss at iteration 430 : 0.004521054215729237
Loss at iteration 440 : 0.00012534814595710486
Loss at iteration 450 : 0.001235098927281797
Loss at iteration 460 : 0.0003146140370517969
Loss at iteration 470 : 0.002326312940567732
Loss at iteration 480 : 0.0005535827367566526
Loss at iteration 490 : 0.002577361883595586
Loss at iteration 500 : 0.00031704572029411793
Loss at iteration 510 : 0.0007655599620193243
Loss at iteration 520 : 0.00341547722928226
Loss at iteration 530 : 0.0001810012909118086
Loss at iteration 540 : 0.0010612320620566607
Loss at iteration 550 : 8.731823618290946e-05
Loss at iteration 560 : 0.00014675363490823656
Loss at iteration 570 : 0.0006676501943729818
Loss at iteration 580 : 0.00010649704199749976
Loss at iteration 590 : 0.0006492468528449535
Loss at iteration 600 : 0.00662649841979146
Loss at iteration 610 : 0.0020736870355904102
Loss at iteration 620 : 0.0024940171279013157
Loss at iteration 630 : 0.000364763371180743
Loss at iteration 640 : 0.0005465454305522144
Loss at iteration 650 : 0.00012184195657027885
Loss at iteration 660 : 0.0004362689796835184
Loss at iteration 670 : 0.00025396127603016794
Loss at iteration 680 : 0.002542516216635704
Loss at iteration 690 : 0.0011692307889461517
Loss at iteration 700 : 0.0013877941528335214
Loss at iteration 710 : 0.0013918885961174965
Loss at iteration 720 : 7.370731327682734e-05
Loss at iteration 730 : 0.0010440568439662457
Loss at iteration 740 : 0.003626365214586258
Loss at iteration 750 : 0.0006990865804255009
Loss at iteration 760 : 0.0019863247871398926
Loss at iteration 770 : 0.00015133350098039955
Loss at iteration 780 : 0.00024084644974209368
Loss at iteration 790 : 0.00033238515607081354
Loss at iteration 800 : 0.0004968935390934348
Loss at iteration 810 : 0.00015091386740095913
Loss at iteration 820 : 0.002622156171128154
Loss at iteration 830 : 0.00033243338111788034
Loss at iteration 840 : 0.003069958882406354
Loss at iteration 850 : 0.0033465633168816566
Loss at iteration 860 : 0.0005381038645282388
Loss at iteration 870 : 0.0020967526361346245
Loss at iteration 880 : 0.00010004626528825611
Loss at iteration 890 : 0.0008903624257072806
Loss at iteration 900 : 0.0006868258351460099
Loss at iteration 910 : 0.00025868232478387654
Loss at iteration 920 : 0.00011166007607243955
Loss at iteration 930 : 0.0023103824350982904
Loss at iteration 940 : 0.0004962700768373907
Loss at iteration 950 : 0.0008749497355893254
Loss at iteration 960 : 0.002414229791611433
Loss at iteration 970 : 0.00021762156393378973
Loss at iteration 980 : 0.0001385977229801938
Loss at iteration 990 : 0.00012090760719729587
Loss at iteration 1000 : 0.00031691836193203926
Loss at iteration 1010 : 8.430621528532356e-05
Loss at iteration 1020 : 0.0038309036754071712
Loss at iteration 1030 : 0.0005172144155949354
Loss at iteration 1040 : 0.00027636950835585594
Loss at iteration 1050 : 0.00029996063676662743
Loss at iteration 1060 : 0.00024356209905818105
Loss at iteration 1070 : 0.00031889439560472965
Loss at iteration 1080 : 7.833522249711677e-05
Loss at iteration 1090 : 0.0003414374077692628
Loss at iteration 1100 : 0.0008130821515806019
Loss at iteration 1110 : 0.00020733926794491708
Loss at iteration 1120 : 0.0012046084739267826
Loss at iteration 1130 : 0.00036292331060394645
Loss at iteration 1140 : 0.00012154801515862346
Loss at iteration 1150 : 0.0032965580467134714
Loss at iteration 1160 : 0.0017594293458387256
Loss at iteration 1170 : 0.0011109595652669668
Loss at iteration 1180 : 3.51597809640225e-05
Loss at iteration 1190 : 0.00019369565416127443
Loss at iteration 1200 : 0.000371975009329617
Loss at iteration 1210 : 0.00012786475417669863
Loss at iteration 1220 : 8.660898311063647e-05
Loss at iteration 1230 : 0.0001774363190634176
Loss at iteration 1240 : 0.00011120478302473202
Loss at iteration 1250 : 0.005928700789809227
Loss at iteration 1260 : 0.0002087406610371545
Loss at iteration 1270 : 0.00323794805444777
Loss at iteration 1280 : 0.0016586297424510121
Loss at iteration 1290 : 0.00012146402877988294
Loss at iteration 1300 : 0.00011106632882729173
Loss at iteration 1310 : 0.00030524321482516825
Loss at iteration 1320 : 0.000729953870177269
Loss at iteration 1330 : 0.00028946532984264195
Loss at iteration 1340 : 0.0025075292214751244
Loss at iteration 1350 : 0.0005571246147155762
Loss at iteration 1360 : 0.00030093477107584476
Loss at iteration 1370 : 0.00013783611939288676
Loss at iteration 1380 : 0.000666391511913389
Loss at iteration 1390 : 0.0030502730514854193
Loss at iteration 1400 : 0.0006646473193541169
Loss at iteration 1410 : 0.00028576626209542155
Loss at iteration 1420 : 0.0004981789970770478
Loss at iteration 1430 : 0.0003930859384126961
Loss at iteration 1440 : 0.000745053228456527
Loss at iteration 1450 : 0.0006276547792367637
Loss at iteration 1460 : 0.0003357718524057418
Loss at iteration 1470 : 0.0019172197207808495
Loss at iteration 1480 : 8.641217573313043e-05
Loss at iteration 1490 : 0.00018460636783856899
Loss at iteration 1500 : 0.001928467070683837
Loss at iteration 1510 : 0.00010723576997406781
Loss at iteration 1520 : 0.0003017876879312098
Loss at iteration 1530 : 0.00012657407205551863
Loss at iteration 1540 : 7.352252578129992e-05
Loss at iteration 1550 : 0.00462737213820219
Loss at iteration 1560 : 0.0002996475377585739
Loss at iteration 1570 : 0.00011623942555161193
Loss at iteration 1580 : 0.0007007122621871531
Loss at iteration 1590 : 0.00010871861013583839
Loss at iteration 1600 : 0.000361746788257733
Loss at iteration 1610 : 0.0004371227987576276
Loss at iteration 1620 : 0.003528445027768612
Loss at iteration 1630 : 0.00036430417094379663
Loss at iteration 1640 : 0.0001073053281288594
Loss at iteration 1650 : 0.00025039666797965765
Loss at iteration 1660 : 0.0004801592440344393
Loss at iteration 1670 : 0.000347695779055357
Loss at iteration 1680 : 0.000339728343533352
Loss at iteration 1690 : 0.00019772356608882546
Loss at iteration 1700 : 0.000692248169798404
Loss at iteration 1710 : 0.001147623872384429
Loss at iteration 1720 : 0.0028296581003814936
Loss at iteration 1730 : 0.0009086759528145194
Loss at iteration 1740 : 0.002637842670083046
Loss at iteration 1750 : 0.0038093766197562218
The SSIM Value is: 0.9813433776605497
The PSNR Value is: 46.31902304830005
the epoch is: 83
Loss at iteration 10 : 0.00038173323264345527
Loss at iteration 20 : 0.00047118039219640195
Loss at iteration 30 : 6.237818161025643e-05
Loss at iteration 40 : 3.2149971957551315e-05
Loss at iteration 50 : 0.0005108230980113149
Loss at iteration 60 : 0.0007364754565060139
Loss at iteration 70 : 0.0012877529952675104
Loss at iteration 80 : 0.0004606918664649129
Loss at iteration 90 : 0.0007140776142477989
Loss at iteration 100 : 0.0031001754105091095
Loss at iteration 110 : 0.00022193253971636295
Loss at iteration 120 : 0.0008956420933827758
Loss at iteration 130 : 0.0001209668698720634
Loss at iteration 140 : 0.00033645000075921416
Loss at iteration 150 : 0.002231030026450753
Loss at iteration 160 : 0.000134182526380755
Loss at iteration 170 : 0.0015124944038689137
Loss at iteration 180 : 0.0011014824267476797
Loss at iteration 190 : 0.0008444589329883456
Loss at iteration 200 : 0.0009175562881864607
Loss at iteration 210 : 0.0008627892239019275
Loss at iteration 220 : 0.0048929862678050995
Loss at iteration 230 : 0.003296155948191881
Loss at iteration 240 : 0.00022090127458795905
Loss at iteration 250 : 0.004877876024693251
Loss at iteration 260 : 0.0003884278703480959
Loss at iteration 270 : 0.00014042989641893655
Loss at iteration 280 : 0.00043140898924320936
Loss at iteration 290 : 0.0004608573508448899
Loss at iteration 300 : 0.00025574679602868855
Loss at iteration 310 : 0.001432215329259634
Loss at iteration 320 : 9.660172509029508e-05
Loss at iteration 330 : 0.0002105301828123629
Loss at iteration 340 : 0.00031363993184641004
Loss at iteration 350 : 0.0002007742295973003
Loss at iteration 360 : 0.00011258653830736876
Loss at iteration 370 : 0.0008632843382656574
Loss at iteration 380 : 0.0006210822612047195
Loss at iteration 390 : 0.00019776890985667706
Loss at iteration 400 : 0.001185507164336741
Loss at iteration 410 : 0.00041274254908785224
Loss at iteration 420 : 0.001217678771354258
Loss at iteration 430 : 0.0008612312376499176
Loss at iteration 440 : 0.0021475229877978563
Loss at iteration 450 : 0.0014608028577640653
Loss at iteration 460 : 0.0001580928947078064
Loss at iteration 470 : 0.000805902760475874
Loss at iteration 480 : 0.0038323309272527695
Loss at iteration 490 : 0.002006287919357419
Loss at iteration 500 : 0.0005037690862081945
Loss at iteration 510 : 0.00032172820647247136
Loss at iteration 520 : 0.0005224663182161748
Loss at iteration 530 : 0.0009774124482646585
Loss at iteration 540 : 0.0011207240168005228
Loss at iteration 550 : 0.0002342712541576475
Loss at iteration 560 : 0.0005743339424952865
Loss at iteration 570 : 0.0002114399103447795
Loss at iteration 580 : 0.0033186213113367558
Loss at iteration 590 : 5.9481892094481736e-05
Loss at iteration 600 : 0.0023937353398650885
Loss at iteration 610 : 0.0023785866796970367
Loss at iteration 620 : 0.0001136184437200427
Loss at iteration 630 : 0.001999529544264078
Loss at iteration 640 : 0.0008468013256788254
Loss at iteration 650 : 0.0004975848132744431
Loss at iteration 660 : 8.40194261400029e-05
Loss at iteration 670 : 0.00027648304239846766
Loss at iteration 680 : 0.0007707843906246126
Loss at iteration 690 : 0.00016635505016893148
Loss at iteration 700 : 0.0026476166676729918
Loss at iteration 710 : 0.0003645391552709043
Loss at iteration 720 : 0.0010956916958093643
Loss at iteration 730 : 0.00020814393064938486
Loss at iteration 740 : 0.00014953254139982164
Loss at iteration 750 : 0.0012153050629422069
Loss at iteration 760 : 8.627631177660078e-05
Loss at iteration 770 : 6.80361918057315e-05
Loss at iteration 780 : 0.000185746859642677
Loss at iteration 790 : 0.003849764121696353
Loss at iteration 800 : 0.00250522349961102
Loss at iteration 810 : 0.0002502535644453019
Loss at iteration 820 : 0.0033757954370230436
Loss at iteration 830 : 1.985546259675175e-05
Loss at iteration 840 : 0.0004263829905539751
Loss at iteration 850 : 0.0006025221082381904
Loss at iteration 860 : 0.0022101367358118296
Loss at iteration 870 : 0.007996270433068275
Loss at iteration 880 : 0.0010366231435909867
Loss at iteration 890 : 0.0012679342180490494
Loss at iteration 900 : 0.0006439974531531334
Loss at iteration 910 : 7.521252700826153e-05
Loss at iteration 920 : 0.0011627004714682698
Loss at iteration 930 : 0.0005593709647655487
Loss at iteration 940 : 0.0001715450343908742
Loss at iteration 950 : 0.0002519416157156229
Loss at iteration 960 : 0.0002890062751248479
Loss at iteration 970 : 0.0030470581259578466
Loss at iteration 980 : 0.0003153235884383321
Loss at iteration 990 : 0.0030672536231577396
Loss at iteration 1000 : 0.00032512383768334985
Loss at iteration 1010 : 0.00032512296456843615
Loss at iteration 1020 : 0.0027211201377213
Loss at iteration 1030 : 0.0008721828926354647
Loss at iteration 1040 : 0.00016430887626484036
Loss at iteration 1050 : 0.0026144888252019882
Loss at iteration 1060 : 6.395361560862511e-05
Loss at iteration 1070 : 0.00028430839302018285
Loss at iteration 1080 : 0.0005988100892864168
Loss at iteration 1090 : 7.854753494029865e-05
Loss at iteration 1100 : 0.002126599894836545
Loss at iteration 1110 : 0.00015623279614374042
Loss at iteration 1120 : 8.791971777100116e-05
Loss at iteration 1130 : 0.001446800772100687
Loss at iteration 1140 : 0.0016720055136829615
Loss at iteration 1150 : 0.0048226104117929935
Loss at iteration 1160 : 0.0001594702189322561
Loss at iteration 1170 : 0.00034196811611764133
Loss at iteration 1180 : 0.0003203266824129969
Loss at iteration 1190 : 0.0012487730709835887
Loss at iteration 1200 : 0.00013997180212754756
Loss at iteration 1210 : 0.00022632023319602013
Loss at iteration 1220 : 5.973774750600569e-05
Loss at iteration 1230 : 0.0001329937658738345
Loss at iteration 1240 : 0.00041401234921067953
Loss at iteration 1250 : 0.0001423333742422983
Loss at iteration 1260 : 0.00012644694652408361
Loss at iteration 1270 : 0.005091980565339327
Loss at iteration 1280 : 0.0002611324889585376
Loss at iteration 1290 : 0.00013470488192979246
Loss at iteration 1300 : 0.0019123352831229568
Loss at iteration 1310 : 0.00034089721157215536
Loss at iteration 1320 : 0.0014792204601690173
Loss at iteration 1330 : 0.0001484336971770972
Loss at iteration 1340 : 0.0013586709974333644
Loss at iteration 1350 : 0.00014652323443442583
Loss at iteration 1360 : 7.859145262045786e-05
Loss at iteration 1370 : 0.0004441536730155349
Loss at iteration 1380 : 0.0009176056482829154
Loss at iteration 1390 : 0.00030234840232878923
Loss at iteration 1400 : 0.0003566716914065182
Loss at iteration 1410 : 0.002430792199447751
Loss at iteration 1420 : 0.00026131700724363327
Loss at iteration 1430 : 0.00031847888021729887
Loss at iteration 1440 : 0.00013933383161202073
Loss at iteration 1450 : 0.00042674975702539086
Loss at iteration 1460 : 0.002390921115875244
Loss at iteration 1470 : 0.0004641209961846471
Loss at iteration 1480 : 6.160925840958953e-05
Loss at iteration 1490 : 0.0005837696953676641
Loss at iteration 1500 : 0.001258172793313861
Loss at iteration 1510 : 0.000693829613737762
Loss at iteration 1520 : 0.00018196835299022496
Loss at iteration 1530 : 0.006546771619468927
Loss at iteration 1540 : 0.000878937600646168
Loss at iteration 1550 : 0.00043864850886166096
Loss at iteration 1560 : 0.0001993008772842586
Loss at iteration 1570 : 0.0002725840313360095
Loss at iteration 1580 : 0.00024523650063201785
Loss at iteration 1590 : 0.0010757697746157646
Loss at iteration 1600 : 7.160729728639126e-05
Loss at iteration 1610 : 0.00018212040595244616
Loss at iteration 1620 : 0.0010619420791044831
Loss at iteration 1630 : 0.0004828797827940434
Loss at iteration 1640 : 0.00036634906427934766
Loss at iteration 1650 : 5.403496470535174e-05
Loss at iteration 1660 : 0.00014163227751851082
Loss at iteration 1670 : 0.003158140927553177
Loss at iteration 1680 : 0.0014365363167598844
Loss at iteration 1690 : 0.004427772480994463
Loss at iteration 1700 : 0.00021055991237517446
Loss at iteration 1710 : 0.0010166667634621263
Loss at iteration 1720 : 0.00019724853336811066
Loss at iteration 1730 : 0.00012183639773866162
Loss at iteration 1740 : 0.00014243574696592987
Loss at iteration 1750 : 8.185223850887269e-05
The SSIM Value is: 0.9796860980173565
The PSNR Value is: 46.52981128776651
the epoch is: 84
Loss at iteration 10 : 0.003105326322838664
Loss at iteration 20 : 0.0025711311027407646
Loss at iteration 30 : 0.0007673866930417717
Loss at iteration 40 : 0.0036845135036855936
Loss at iteration 50 : 0.0008773035369813442
Loss at iteration 60 : 0.0001684231247054413
Loss at iteration 70 : 0.0007580790552310646
Loss at iteration 80 : 0.0001090411315090023
Loss at iteration 90 : 0.0022162888199090958
Loss at iteration 100 : 0.003760257735848427
Loss at iteration 110 : 0.002406506100669503
Loss at iteration 120 : 0.0018618351314216852
Loss at iteration 130 : 0.0013189759338274598
Loss at iteration 140 : 0.006309475749731064
Loss at iteration 150 : 0.0006609981064684689
Loss at iteration 160 : 0.0003500268794596195
Loss at iteration 170 : 0.003263950813561678
Loss at iteration 180 : 0.0024296878837049007
Loss at iteration 190 : 0.0006682913517579436
Loss at iteration 200 : 0.00017122116696555167
Loss at iteration 210 : 0.0001759130391292274
Loss at iteration 220 : 0.00039050442865118384
Loss at iteration 230 : 0.0003386475145816803
Loss at iteration 240 : 7.356759306276217e-05
Loss at iteration 250 : 0.0016492558643221855
Loss at iteration 260 : 0.0001398312160745263
Loss at iteration 270 : 0.0024637486785650253
Loss at iteration 280 : 0.00014001925592310727
Loss at iteration 290 : 0.00015506069757975638
Loss at iteration 300 : 0.0002819074725266546
Loss at iteration 310 : 0.0008331924909725785
Loss at iteration 320 : 7.702077709836885e-05
Loss at iteration 330 : 0.0005884486017748713
Loss at iteration 340 : 0.0008466484723612666
Loss at iteration 350 : 0.00017966004088521004
Loss at iteration 360 : 0.00015654026356060058
Loss at iteration 370 : 0.006130639463663101
Loss at iteration 380 : 0.003021869109943509
Loss at iteration 390 : 0.00181157561019063
Loss at iteration 400 : 0.0009162059868685901
Loss at iteration 410 : 0.00018886601901613176
Loss at iteration 420 : 5.947013778495602e-05
Loss at iteration 430 : 0.00025598143110983074
Loss at iteration 440 : 0.00018158418242819607
Loss at iteration 450 : 0.00010382544132880867
Loss at iteration 460 : 0.0022693490609526634
Loss at iteration 470 : 0.002420988865196705
Loss at iteration 480 : 7.505407120333984e-05
Loss at iteration 490 : 0.000701206037774682
Loss at iteration 500 : 0.0003790536429733038
Loss at iteration 510 : 0.0010659471154212952
Loss at iteration 520 : 0.00020416907500475645
Loss at iteration 530 : 0.0002133643429260701
Loss at iteration 540 : 0.0008298566099256277
Loss at iteration 550 : 0.0003266381099820137
Loss at iteration 560 : 0.001021245145238936
Loss at iteration 570 : 0.0014885349664837122
Loss at iteration 580 : 0.010154344141483307
Loss at iteration 590 : 0.00036941925645805895
Loss at iteration 600 : 0.0021144349593669176
Loss at iteration 610 : 0.00010714366362662986
Loss at iteration 620 : 0.000878556165844202
Loss at iteration 630 : 0.006336168851703405
Loss at iteration 640 : 0.00012188656546641141
Loss at iteration 650 : 0.004583319649100304
Loss at iteration 660 : 0.00020950022735632956
Loss at iteration 670 : 0.00010116856719832867
Loss at iteration 680 : 0.00021744320110883564
Loss at iteration 690 : 0.000282705994322896
Loss at iteration 700 : 0.0032347161322832108
Loss at iteration 710 : 0.0003581079072318971
Loss at iteration 720 : 0.0001495503238402307
Loss at iteration 730 : 0.0005579892313107848
Loss at iteration 740 : 0.000440849456936121
Loss at iteration 750 : 0.0020233418326824903
Loss at iteration 760 : 0.0007267347536981106
Loss at iteration 770 : 0.0001670720666879788
Loss at iteration 780 : 0.00035869027487933636
Loss at iteration 790 : 0.0019220479298382998
Loss at iteration 800 : 0.011186128482222557
Loss at iteration 810 : 0.0042900932021439075
Loss at iteration 820 : 0.00015296023047994822
Loss at iteration 830 : 0.0007177879451774061
Loss at iteration 840 : 8.876933134160936e-05
Loss at iteration 850 : 9.204082016367465e-05
Loss at iteration 860 : 0.0022464965004473925
Loss at iteration 870 : 0.00013375112030189484
Loss at iteration 880 : 0.0006587025709450245
Loss at iteration 890 : 0.0022349031642079353
Loss at iteration 900 : 0.0004616927180904895
Loss at iteration 910 : 0.00012281359522603452
Loss at iteration 920 : 0.00012399459956213832
Loss at iteration 930 : 0.00133030884899199
Loss at iteration 940 : 0.00010460893827257678
Loss at iteration 950 : 0.0001684684248175472
Loss at iteration 960 : 0.000395052571548149
Loss at iteration 970 : 0.00015937330317683518
Loss at iteration 980 : 0.0002668725501280278
Loss at iteration 990 : 0.00016454023716505617
Loss at iteration 1000 : 0.002675560535863042
Loss at iteration 1010 : 0.0019000901374965906
Loss at iteration 1020 : 0.0032298006117343903
Loss at iteration 1030 : 0.0005932783242315054
Loss at iteration 1040 : 0.0001209172114613466
Loss at iteration 1050 : 0.0003256032650824636
Loss at iteration 1060 : 0.001690989825874567
Loss at iteration 1070 : 0.00016844937636051327
Loss at iteration 1080 : 0.0009727850556373596
Loss at iteration 1090 : 0.0012741968967020512
Loss at iteration 1100 : 0.001112230820581317
Loss at iteration 1110 : 0.0007794710109010339
Loss at iteration 1120 : 0.0003059714217670262
Loss at iteration 1130 : 0.00025500409537926316
Loss at iteration 1140 : 0.0007695715175941586
Loss at iteration 1150 : 0.0004165687132626772
Loss at iteration 1160 : 0.0003874582180287689
Loss at iteration 1170 : 0.001990059856325388
Loss at iteration 1180 : 0.0001282393204746768
Loss at iteration 1190 : 0.0007248309557326138
Loss at iteration 1200 : 0.0001457786711398512
Loss at iteration 1210 : 5.341541691450402e-05
Loss at iteration 1220 : 0.00011097812239313498
Loss at iteration 1230 : 0.002328938338905573
Loss at iteration 1240 : 0.0008392081945203245
Loss at iteration 1250 : 8.093351789284497e-05
Loss at iteration 1260 : 5.2999152103438973e-05
Loss at iteration 1270 : 0.006637456361204386
Loss at iteration 1280 : 0.0028232198674231768
Loss at iteration 1290 : 0.00011519098188728094
Loss at iteration 1300 : 0.0010136001510545611
Loss at iteration 1310 : 0.0011446004500612617
Loss at iteration 1320 : 6.157551251817495e-05
Loss at iteration 1330 : 0.0012217527255415916
Loss at iteration 1340 : 0.0001135086640715599
Loss at iteration 1350 : 0.0008826849516481161
Loss at iteration 1360 : 0.002715148264542222
Loss at iteration 1370 : 6.966813816688955e-05
Loss at iteration 1380 : 0.0003176477621309459
Loss at iteration 1390 : 0.003190642222762108
Loss at iteration 1400 : 0.00014732731506228447
Loss at iteration 1410 : 0.0002217654255218804
Loss at iteration 1420 : 0.0008046773727983236
Loss at iteration 1430 : 0.0001430245174560696
Loss at iteration 1440 : 0.0003292393812444061
Loss at iteration 1450 : 0.00078394083539024
Loss at iteration 1460 : 0.0011837654747068882
Loss at iteration 1470 : 0.0026490422897040844
Loss at iteration 1480 : 0.00011834773613372818
Loss at iteration 1490 : 0.0007867056410759687
Loss at iteration 1500 : 0.0004071586881764233
Loss at iteration 1510 : 0.004035210702568293
Loss at iteration 1520 : 0.003143196925520897
Loss at iteration 1530 : 0.0015640149358659983
Loss at iteration 1540 : 0.00028400414157658815
Loss at iteration 1550 : 0.0008656807476654649
Loss at iteration 1560 : 0.0003750150790438056
Loss at iteration 1570 : 8.507094025844708e-05
Loss at iteration 1580 : 0.0013799977023154497
Loss at iteration 1590 : 5.924247670918703e-05
Loss at iteration 1600 : 0.00015339009405579418
Loss at iteration 1610 : 4.389863897813484e-05
Loss at iteration 1620 : 0.00020996565581299365
Loss at iteration 1630 : 0.0005822234088554978
Loss at iteration 1640 : 0.0011143502779304981
Loss at iteration 1650 : 0.00039562032907269895
Loss at iteration 1660 : 0.0004641436680685729
Loss at iteration 1670 : 0.00016769187641330063
Loss at iteration 1680 : 0.0020642238669097424
Loss at iteration 1690 : 0.00031069511896930635
Loss at iteration 1700 : 0.0019258928950875998
Loss at iteration 1710 : 0.00029829435516148806
Loss at iteration 1720 : 0.0031087128445506096
Loss at iteration 1730 : 8.247331425081939e-05
Loss at iteration 1740 : 0.002456644084304571
Loss at iteration 1750 : 0.00024166920047719032
The SSIM Value is: 0.9800400628917543
The PSNR Value is: 46.59009066972438
the epoch is: 85
Loss at iteration 10 : 0.0004214151413179934
Loss at iteration 20 : 0.00015740944945719093
Loss at iteration 30 : 0.0003238919307477772
Loss at iteration 40 : 0.0002554389357101172
Loss at iteration 50 : 0.00015610877017024904
Loss at iteration 60 : 0.0004024544032290578
Loss at iteration 70 : 0.0008090019691735506
Loss at iteration 80 : 0.0005577107658609748
Loss at iteration 90 : 0.0007727598422206938
Loss at iteration 100 : 0.000174510627402924
Loss at iteration 110 : 0.00012763318954966962
Loss at iteration 120 : 0.0006966155488044024
Loss at iteration 130 : 0.0005422927206382155
Loss at iteration 140 : 0.0017232175450772047
Loss at iteration 150 : 0.0001123578695114702
Loss at iteration 160 : 0.001892932690680027
Loss at iteration 170 : 0.001317228889092803
Loss at iteration 180 : 0.0018962037283927202
Loss at iteration 190 : 0.0005576646653935313
Loss at iteration 200 : 0.00016871775733307004
Loss at iteration 210 : 0.0030631229747086763
Loss at iteration 220 : 0.003967147786170244
Loss at iteration 230 : 0.0007851251284591854
Loss at iteration 240 : 0.004480636212974787
Loss at iteration 250 : 0.004031171556562185
Loss at iteration 260 : 0.005245650187134743
Loss at iteration 270 : 0.00014048712910152972
Loss at iteration 280 : 0.00024766140268184245
Loss at iteration 290 : 0.0032745967619121075
Loss at iteration 300 : 0.00011125075980089605
Loss at iteration 310 : 0.004666455555707216
Loss at iteration 320 : 0.0005406420677900314
Loss at iteration 330 : 0.0036102363374084234
Loss at iteration 340 : 0.0008810244034975767
Loss at iteration 350 : 0.003593144239857793
Loss at iteration 360 : 0.0003341309493407607
Loss at iteration 370 : 0.0015644439263269305
Loss at iteration 380 : 0.0011998596601188183
Loss at iteration 390 : 0.00015253230230882764
Loss at iteration 400 : 0.0003445266920607537
Loss at iteration 410 : 0.0010084685636684299
Loss at iteration 420 : 0.00036696423194371164
Loss at iteration 430 : 0.0001071902152034454
Loss at iteration 440 : 0.0028770018834620714
Loss at iteration 450 : 0.004927909933030605
Loss at iteration 460 : 0.00014078340609557927
Loss at iteration 470 : 0.00024060512077994645
Loss at iteration 480 : 0.003280473407357931
Loss at iteration 490 : 0.0009342791745439172
Loss at iteration 500 : 0.00048783133388496935
Loss at iteration 510 : 0.00024717222549952567
Loss at iteration 520 : 0.0014331096317619085
Loss at iteration 530 : 0.0006712605245411396
Loss at iteration 540 : 7.79998954385519e-05
Loss at iteration 550 : 0.0005274483701214194
Loss at iteration 560 : 0.00040519601316191256
Loss at iteration 570 : 0.001811620662920177
Loss at iteration 580 : 0.0038322494365274906
Loss at iteration 590 : 0.0010019214823842049
Loss at iteration 600 : 0.0003117104643024504
Loss at iteration 610 : 0.0003927494981326163
Loss at iteration 620 : 0.00019159240764565766
Loss at iteration 630 : 0.0029040933586657047
Loss at iteration 640 : 0.00011740115587599576
Loss at iteration 650 : 0.00786906760185957
Loss at iteration 660 : 0.0007759748259559274
Loss at iteration 670 : 8.236111170845106e-05
Loss at iteration 680 : 0.0034799242857843637
Loss at iteration 690 : 0.0003605126403272152
Loss at iteration 700 : 0.0013096650363877416
Loss at iteration 710 : 0.0010313383536413312
Loss at iteration 720 : 0.0001638588000787422
Loss at iteration 730 : 0.0013099213829264045
Loss at iteration 740 : 6.126804510131478e-05
Loss at iteration 750 : 0.00011161712609464303
Loss at iteration 760 : 0.0003757137747015804
Loss at iteration 770 : 0.0023716881405562162
Loss at iteration 780 : 0.0003065109485760331
Loss at iteration 790 : 0.0023999859113246202
Loss at iteration 800 : 0.00011143762822030112
Loss at iteration 810 : 6.439653225243092e-05
Loss at iteration 820 : 0.00041649065678939223
Loss at iteration 830 : 0.00027978350408375263
Loss at iteration 840 : 0.0002609793737065047
Loss at iteration 850 : 0.0006636159960180521
Loss at iteration 860 : 5.0293212552787736e-05
Loss at iteration 870 : 0.0001724142348393798
Loss at iteration 880 : 4.820505637326278e-05
Loss at iteration 890 : 0.0003483132750261575
Loss at iteration 900 : 0.0014137185644358397
Loss at iteration 910 : 9.41210164455697e-05
Loss at iteration 920 : 0.0075345467776060104
Loss at iteration 930 : 0.0002320518542546779
Loss at iteration 940 : 0.0004661751736421138
Loss at iteration 950 : 0.0017457855865359306
Loss at iteration 960 : 0.0023574582301080227
Loss at iteration 970 : 0.0001669684424996376
Loss at iteration 980 : 0.004034483339637518
Loss at iteration 990 : 6.808996113250032e-05
Loss at iteration 1000 : 0.001438236329704523
Loss at iteration 1010 : 0.0006130310357548296
Loss at iteration 1020 : 0.00038886466063559055
Loss at iteration 1030 : 0.00010326673509553075
Loss at iteration 1040 : 0.0005353277083486319
Loss at iteration 1050 : 0.0039801206439733505
Loss at iteration 1060 : 8.391811570618302e-05
Loss at iteration 1070 : 0.00010209385072812438
Loss at iteration 1080 : 0.0002177292772103101
Loss at iteration 1090 : 0.00020728909294120967
Loss at iteration 1100 : 0.00302333477884531
Loss at iteration 1110 : 0.00025166847626678646
Loss at iteration 1120 : 0.0002957367687486112
Loss at iteration 1130 : 4.335049743531272e-05
Loss at iteration 1140 : 0.0010249846382066607
Loss at iteration 1150 : 0.0033952349331229925
Loss at iteration 1160 : 0.0004000784829258919
Loss at iteration 1170 : 0.0007518756901845336
Loss at iteration 1180 : 0.0021980437450110912
Loss at iteration 1190 : 0.00034533892176114023
Loss at iteration 1200 : 0.004218895919620991
Loss at iteration 1210 : 0.00016597659850958735
Loss at iteration 1220 : 0.00026409319252707064
Loss at iteration 1230 : 0.0005046401638537645
Loss at iteration 1240 : 0.00010645397560438141
Loss at iteration 1250 : 0.00045606523053720593
Loss at iteration 1260 : 0.0001779788435669616
Loss at iteration 1270 : 0.0007102169911377132
Loss at iteration 1280 : 0.00048753165174275637
Loss at iteration 1290 : 0.001940527348779142
Loss at iteration 1300 : 3.747212031157687e-05
Loss at iteration 1310 : 6.313060293905437e-05
Loss at iteration 1320 : 0.0002450535539537668
Loss at iteration 1330 : 0.0001012926222756505
Loss at iteration 1340 : 0.0014185496838763356
Loss at iteration 1350 : 0.00225428375415504
Loss at iteration 1360 : 0.0012777541996911168
Loss at iteration 1370 : 0.00022898796305526048
Loss at iteration 1380 : 0.0005343412631191313
Loss at iteration 1390 : 0.0031089549884200096
Loss at iteration 1400 : 0.001128697069361806
Loss at iteration 1410 : 0.002130422042682767
Loss at iteration 1420 : 0.0013581383973360062
Loss at iteration 1430 : 0.0009269855218008161
Loss at iteration 1440 : 0.0002890696923714131
Loss at iteration 1450 : 0.00015205972886178643
Loss at iteration 1460 : 9.596750169293955e-05
Loss at iteration 1470 : 0.0005855336785316467
Loss at iteration 1480 : 3.182751970598474e-05
Loss at iteration 1490 : 0.000636102631688118
Loss at iteration 1500 : 0.0013179485686123371
Loss at iteration 1510 : 0.00013108285202179104
Loss at iteration 1520 : 0.00012645572132896632
Loss at iteration 1530 : 5.719476757803932e-05
Loss at iteration 1540 : 0.00012580327165778726
Loss at iteration 1550 : 0.00010697468678699806
Loss at iteration 1560 : 0.002188613172620535
Loss at iteration 1570 : 0.00036617479054257274
Loss at iteration 1580 : 0.0042280531488358974
Loss at iteration 1590 : 0.00019458519818726927
Loss at iteration 1600 : 0.00010687206668080762
Loss at iteration 1610 : 0.00035858756746165454
Loss at iteration 1620 : 0.0004294585669413209
Loss at iteration 1630 : 0.0009577135788276792
Loss at iteration 1640 : 0.0014953789068385959
Loss at iteration 1650 : 0.002454474801197648
Loss at iteration 1660 : 0.0019072674913331866
Loss at iteration 1670 : 0.00045228569069877267
Loss at iteration 1680 : 0.00015312367759179324
Loss at iteration 1690 : 0.0035070208832621574
Loss at iteration 1700 : 0.0004944263491779566
Loss at iteration 1710 : 0.0006732767214998603
Loss at iteration 1720 : 0.0005212698597460985
Loss at iteration 1730 : 9.503175533609465e-05
Loss at iteration 1740 : 0.0005817170022055507
Loss at iteration 1750 : 0.0010160207748413086
The SSIM Value is: 0.9837593571467547
The PSNR Value is: 46.23673763779291
the epoch is: 86
Loss at iteration 10 : 0.00029405186069197953
Loss at iteration 20 : 0.00046352006029337645
Loss at iteration 30 : 7.310864748433232e-05
Loss at iteration 40 : 0.00015774498751852661
Loss at iteration 50 : 0.0006618849583901465
Loss at iteration 60 : 0.00032966083381325006
Loss at iteration 70 : 0.00034663709811866283
Loss at iteration 80 : 7.382052717730403e-05
Loss at iteration 90 : 0.0005309391999617219
Loss at iteration 100 : 0.0006656586774624884
Loss at iteration 110 : 0.0042329044081270695
Loss at iteration 120 : 0.0050669885240495205
Loss at iteration 130 : 0.0009239329374395311
Loss at iteration 140 : 0.00016361597226932645
Loss at iteration 150 : 0.0005250765243545175
Loss at iteration 160 : 0.0014918859815225005
Loss at iteration 170 : 0.0002855121565517038
Loss at iteration 180 : 0.0007982631213963032
Loss at iteration 190 : 0.00090292893582955
Loss at iteration 200 : 4.132210960960947e-05
Loss at iteration 210 : 0.0030211012344807386
Loss at iteration 220 : 6.797625246690586e-05
Loss at iteration 230 : 0.00029569450998678803
Loss at iteration 240 : 0.00035467976704239845
Loss at iteration 250 : 0.0017732692649587989
Loss at iteration 260 : 0.0001690221979515627
Loss at iteration 270 : 0.0005098321125842631
Loss at iteration 280 : 0.00021138720330782235
Loss at iteration 290 : 0.00046979147009551525
Loss at iteration 300 : 0.0006226112018339336
Loss at iteration 310 : 0.003120857523754239
Loss at iteration 320 : 0.0002158033021260053
Loss at iteration 330 : 0.00043400333379395306
Loss at iteration 340 : 0.00021228761761449277
Loss at iteration 350 : 0.0011308268876746297
Loss at iteration 360 : 0.00017398566706106067
Loss at iteration 370 : 0.00027208711253479123
Loss at iteration 380 : 6.778510578442365e-05
Loss at iteration 390 : 0.0002126318431692198
Loss at iteration 400 : 0.0002599262516014278
Loss at iteration 410 : 0.00011536627425812185
Loss at iteration 420 : 0.00020764872897416353
Loss at iteration 430 : 0.0008823660900816321
Loss at iteration 440 : 0.0021528482902795076
Loss at iteration 450 : 7.355105481110513e-05
Loss at iteration 460 : 0.004525730386376381
Loss at iteration 470 : 0.00027075360412709415
Loss at iteration 480 : 0.0001251964276889339
Loss at iteration 490 : 0.0003259112418163568
Loss at iteration 500 : 0.0001328291546087712
Loss at iteration 510 : 0.000985192833468318
Loss at iteration 520 : 9.642807708587497e-05
Loss at iteration 530 : 0.0006323100533336401
Loss at iteration 540 : 0.0029973972123116255
Loss at iteration 550 : 0.00587780075147748
Loss at iteration 560 : 0.0033082382287830114
Loss at iteration 570 : 0.0029049054719507694
Loss at iteration 580 : 0.0006232154555618763
Loss at iteration 590 : 0.00482722744345665
Loss at iteration 600 : 0.002679075114428997
Loss at iteration 610 : 0.002009538933634758
Loss at iteration 620 : 0.00032577960519120097
Loss at iteration 630 : 0.0004488375852815807
Loss at iteration 640 : 0.000187403813470155
Loss at iteration 650 : 6.367995229084045e-05
Loss at iteration 660 : 0.0016231461195275187
Loss at iteration 670 : 0.00015051514492370188
Loss at iteration 680 : 0.0003908672952093184
Loss at iteration 690 : 0.0036056891549378633
Loss at iteration 700 : 0.0012268867576494813
Loss at iteration 710 : 0.0042740097269415855
Loss at iteration 720 : 5.922299169469625e-05
Loss at iteration 730 : 0.00014208437642082572
Loss at iteration 740 : 0.0017818603664636612
Loss at iteration 750 : 0.0035269283689558506
Loss at iteration 760 : 0.0002581297012511641
Loss at iteration 770 : 0.0002274267899338156
Loss at iteration 780 : 0.00030004206928424537
Loss at iteration 790 : 0.00028507300885394216
Loss at iteration 800 : 0.0003113127313554287
Loss at iteration 810 : 0.0009849725756794214
Loss at iteration 820 : 0.0005685238866135478
Loss at iteration 830 : 0.00035693030804395676
Loss at iteration 840 : 0.00014823141100350767
Loss at iteration 850 : 0.004169355146586895
Loss at iteration 860 : 0.00011823542445199564
Loss at iteration 870 : 0.0003633644082583487
Loss at iteration 880 : 0.00015039255958981812
Loss at iteration 890 : 0.00032268709037452936
Loss at iteration 900 : 0.002668617758899927
Loss at iteration 910 : 0.00010237591050099581
Loss at iteration 920 : 0.00013840955216437578
Loss at iteration 930 : 0.002284594811499119
Loss at iteration 940 : 0.00016315029643010348
Loss at iteration 950 : 0.00014503933198284358
Loss at iteration 960 : 0.004647832363843918
Loss at iteration 970 : 0.0007662656717002392
Loss at iteration 980 : 0.0010895178420469165
Loss at iteration 990 : 0.003382943570613861
Loss at iteration 1000 : 0.0013356289127841592
Loss at iteration 1010 : 0.0005238389130681753
Loss at iteration 1020 : 0.0001694364327704534
Loss at iteration 1030 : 0.0003926297649741173
Loss at iteration 1040 : 0.00022269293549470603
Loss at iteration 1050 : 0.002014333615079522
Loss at iteration 1060 : 0.0002707125386223197
Loss at iteration 1070 : 0.00018233322771266103
Loss at iteration 1080 : 0.0017430176958441734
Loss at iteration 1090 : 0.0027950461953878403
Loss at iteration 1100 : 9.31416216189973e-05
Loss at iteration 1110 : 0.0002322563377674669
Loss at iteration 1120 : 0.0010312686208635569
Loss at iteration 1130 : 0.0004086571279913187
Loss at iteration 1140 : 0.00017054512863978744
Loss at iteration 1150 : 0.0010088938288390636
Loss at iteration 1160 : 0.0002671430411282927
Loss at iteration 1170 : 0.0007107595447450876
Loss at iteration 1180 : 0.0047084311954677105
Loss at iteration 1190 : 0.00017575552919879556
Loss at iteration 1200 : 0.00029129048925824463
Loss at iteration 1210 : 0.00010915206803474575
Loss at iteration 1220 : 0.0008089877665042877
Loss at iteration 1230 : 0.00017901499813888222
Loss at iteration 1240 : 0.002316199941560626
Loss at iteration 1250 : 0.0001385345822200179
Loss at iteration 1260 : 0.00013414156273938715
Loss at iteration 1270 : 0.004018052481114864
Loss at iteration 1280 : 0.004282228648662567
Loss at iteration 1290 : 0.002492158208042383
Loss at iteration 1300 : 0.0021602113265544176
Loss at iteration 1310 : 0.00029223092133179307
Loss at iteration 1320 : 0.00021520150767173618
Loss at iteration 1330 : 0.0004138704971410334
Loss at iteration 1340 : 0.00011374477617209777
Loss at iteration 1350 : 0.00027074789977632463
Loss at iteration 1360 : 0.0012108130613341928
Loss at iteration 1370 : 0.0025043259374797344
Loss at iteration 1380 : 0.00010643507266649976
Loss at iteration 1390 : 0.0002626038622111082
Loss at iteration 1400 : 0.0025716109666973352
Loss at iteration 1410 : 0.0002501073759049177
Loss at iteration 1420 : 0.0003788481408264488
Loss at iteration 1430 : 0.00011675333371385932
Loss at iteration 1440 : 0.00019313223310746253
Loss at iteration 1450 : 0.0003481436287984252
Loss at iteration 1460 : 9.17097058845684e-05
Loss at iteration 1470 : 9.601365309208632e-05
Loss at iteration 1480 : 0.00017433946777600795
Loss at iteration 1490 : 0.0001590714673511684
Loss at iteration 1500 : 0.0023680373560637236
Loss at iteration 1510 : 0.0004786105128005147
Loss at iteration 1520 : 0.0015218363841995597
Loss at iteration 1530 : 0.0016508272383362055
Loss at iteration 1540 : 0.002675236202776432
Loss at iteration 1550 : 8.69726573000662e-05
Loss at iteration 1560 : 0.0003424813039600849
Loss at iteration 1570 : 0.00019038343452848494
Loss at iteration 1580 : 0.00014172744704410434
Loss at iteration 1590 : 0.00019832052930723876
Loss at iteration 1600 : 0.00023100306862033904
Loss at iteration 1610 : 0.0007205349975265563
Loss at iteration 1620 : 0.00022245744185056537
Loss at iteration 1630 : 0.0028610536828637123
Loss at iteration 1640 : 0.002431971952319145
Loss at iteration 1650 : 0.0011412190506234765
Loss at iteration 1660 : 0.00012007043551420793
Loss at iteration 1670 : 0.0001667987962719053
Loss at iteration 1680 : 0.0010320838773623109
Loss at iteration 1690 : 0.0002997736446559429
Loss at iteration 1700 : 0.002261043293401599
Loss at iteration 1710 : 0.0003159924235660583
Loss at iteration 1720 : 0.00011554767843335867
Loss at iteration 1730 : 0.0008476615766994655
Loss at iteration 1740 : 0.00036206256481818855
Loss at iteration 1750 : 0.0022456622682511806
The SSIM Value is: 0.9846784068099202
The PSNR Value is: 45.64214562529509
the epoch is: 87
Loss at iteration 10 : 0.00040791838546283543
Loss at iteration 20 : 0.00016159043298102915
Loss at iteration 30 : 0.00043407914927229285
Loss at iteration 40 : 9.082560427486897e-05
Loss at iteration 50 : 0.005059017334133387
Loss at iteration 60 : 0.0007925968384370208
Loss at iteration 70 : 0.00014474400086328387
Loss at iteration 80 : 0.00031956523889675736
Loss at iteration 90 : 0.00014022013056091964
Loss at iteration 100 : 0.0037262847181409597
Loss at iteration 110 : 0.0002442362601868808
Loss at iteration 120 : 5.592504021478817e-05
Loss at iteration 130 : 0.00018822202400770038
Loss at iteration 140 : 0.00018517591524869204
Loss at iteration 150 : 0.0022393488325178623
Loss at iteration 160 : 0.0024024590384215117
Loss at iteration 170 : 7.016673043835908e-05
Loss at iteration 180 : 0.0011143888114020228
Loss at iteration 190 : 0.0031506784725934267
Loss at iteration 200 : 0.000686218379996717
Loss at iteration 210 : 0.0025314511731266975
Loss at iteration 220 : 0.00044601457193493843
Loss at iteration 230 : 0.0004092199669685215
Loss at iteration 240 : 0.001517504919320345
Loss at iteration 250 : 0.00012234351015649736
Loss at iteration 260 : 0.0004849317774642259
Loss at iteration 270 : 0.00012796853843610734
Loss at iteration 280 : 4.99026536999736e-05
Loss at iteration 290 : 6.260034570004791e-05
Loss at iteration 300 : 0.000656559772323817
Loss at iteration 310 : 8.259098103735596e-05
Loss at iteration 320 : 0.002417945535853505
Loss at iteration 330 : 7.46820296626538e-05
Loss at iteration 340 : 0.001187300425954163
Loss at iteration 350 : 6.696573109366e-05
Loss at iteration 360 : 0.000292343960609287
Loss at iteration 370 : 0.0007342927856370807
Loss at iteration 380 : 0.00010563319665379822
Loss at iteration 390 : 8.447923755738884e-05
Loss at iteration 400 : 0.00023066421272233129
Loss at iteration 410 : 0.0002307519462192431
Loss at iteration 420 : 0.0002555355604272336
Loss at iteration 430 : 0.0002402006066404283
Loss at iteration 440 : 0.001222772290930152
Loss at iteration 450 : 0.0001908418780658394
Loss at iteration 460 : 0.0018023009179159999
Loss at iteration 470 : 0.0005705569637939334
Loss at iteration 480 : 0.0024224345106631517
Loss at iteration 490 : 0.00022808588983025402
Loss at iteration 500 : 0.001998444087803364
Loss at iteration 510 : 0.0006242395611479878
Loss at iteration 520 : 0.002209258498623967
Loss at iteration 530 : 0.00037598516792058945
Loss at iteration 540 : 0.00041894434252753854
Loss at iteration 550 : 0.0018129516392946243
Loss at iteration 560 : 0.000393140857340768
Loss at iteration 570 : 0.000340920640155673
Loss at iteration 580 : 7.816297875251621e-05
Loss at iteration 590 : 0.0003023144672624767
Loss at iteration 600 : 0.00148158916272223
Loss at iteration 610 : 0.00014335507876239717
Loss at iteration 620 : 0.00823497399687767
Loss at iteration 630 : 0.00025843485491350293
Loss at iteration 640 : 0.00022773025557398796
Loss at iteration 650 : 0.00014040300447959453
Loss at iteration 660 : 0.000793791317846626
Loss at iteration 670 : 0.00012933382822666317
Loss at iteration 680 : 0.001667472766712308
Loss at iteration 690 : 0.0026693171821534634
Loss at iteration 700 : 0.001036650501191616
Loss at iteration 710 : 0.0010694889351725578
Loss at iteration 720 : 0.000267582421656698
Loss at iteration 730 : 0.0002194709231844172
Loss at iteration 740 : 0.0019297897815704346
Loss at iteration 750 : 0.0002607752103358507
Loss at iteration 760 : 0.005509419832378626
Loss at iteration 770 : 0.0005253141862340271
Loss at iteration 780 : 0.0001820010511437431
Loss at iteration 790 : 0.0003316668444313109
Loss at iteration 800 : 0.0006393469520844519
Loss at iteration 810 : 9.54176503000781e-05
Loss at iteration 820 : 0.0008941888809204102
Loss at iteration 830 : 3.242167076678015e-05
Loss at iteration 840 : 0.0003950578684452921
Loss at iteration 850 : 0.00011383653327357024
Loss at iteration 860 : 0.00017849006690084934
Loss at iteration 870 : 0.000415025744587183
Loss at iteration 880 : 0.00012602201604750007
Loss at iteration 890 : 0.002565434668213129
Loss at iteration 900 : 0.0005780440988019109
Loss at iteration 910 : 0.003754417411983013
Loss at iteration 920 : 0.00029837596230208874
Loss at iteration 930 : 0.0021468212362378836
Loss at iteration 940 : 0.0015647390391677618
Loss at iteration 950 : 0.00011407177953515202
Loss at iteration 960 : 0.00012025462638121098
Loss at iteration 970 : 0.0002671937982086092
Loss at iteration 980 : 0.0005517379613593221
Loss at iteration 990 : 0.00013245019363239408
Loss at iteration 1000 : 0.0029624842572957277
Loss at iteration 1010 : 0.0004444313235580921
Loss at iteration 1020 : 0.0006980296457186341
Loss at iteration 1030 : 0.00016446317022200674
Loss at iteration 1040 : 0.0003969603276345879
Loss at iteration 1050 : 0.0030867932364344597
Loss at iteration 1060 : 0.0012758851516991854
Loss at iteration 1070 : 0.0026011222507804632
Loss at iteration 1080 : 0.00020628582569770515
Loss at iteration 1090 : 8.864508708938956e-05
Loss at iteration 1100 : 4.337764039519243e-05
Loss at iteration 1110 : 0.00039511933573521674
Loss at iteration 1120 : 0.0005770022980868816
Loss at iteration 1130 : 0.0016335491091012955
Loss at iteration 1140 : 0.002339521422982216
Loss at iteration 1150 : 0.003371204948052764
Loss at iteration 1160 : 0.00021826921147294343
Loss at iteration 1170 : 0.00041010091081261635
Loss at iteration 1180 : 0.00035564316203817725
Loss at iteration 1190 : 0.00030738074565306306
Loss at iteration 1200 : 0.0001810340181691572
Loss at iteration 1210 : 0.0006289101438596845
Loss at iteration 1220 : 0.00015318390796892345
Loss at iteration 1230 : 0.0025064125657081604
Loss at iteration 1240 : 0.00029038882348686457
Loss at iteration 1250 : 0.0017627967754378915
Loss at iteration 1260 : 0.0004776173736900091
Loss at iteration 1270 : 0.0027322222013026476
Loss at iteration 1280 : 0.000493435887619853
Loss at iteration 1290 : 0.0014803418889641762
Loss at iteration 1300 : 0.00011575438838917762
Loss at iteration 1310 : 0.00010471210407558829
Loss at iteration 1320 : 7.611561159137636e-05
Loss at iteration 1330 : 0.00030202840571291745
Loss at iteration 1340 : 0.00016565766418352723
Loss at iteration 1350 : 0.0012813502689823508
Loss at iteration 1360 : 0.0002659341262187809
Loss at iteration 1370 : 0.002086683176457882
Loss at iteration 1380 : 0.0001915093744173646
Loss at iteration 1390 : 0.0014591299695894122
Loss at iteration 1400 : 0.0003727324365172535
Loss at iteration 1410 : 0.006828946527093649
Loss at iteration 1420 : 0.00010872849816223606
Loss at iteration 1430 : 0.0003808584006037563
Loss at iteration 1440 : 0.0020654299296438694
Loss at iteration 1450 : 0.00017616839613765478
Loss at iteration 1460 : 0.00034664501436054707
Loss at iteration 1470 : 0.0004151086322963238
Loss at iteration 1480 : 0.0025272807106375694
Loss at iteration 1490 : 0.00020017125643789768
Loss at iteration 1500 : 9.01522726053372e-05
Loss at iteration 1510 : 0.0020704269409179688
Loss at iteration 1520 : 0.00012914621038362384
Loss at iteration 1530 : 0.0014569219201803207
Loss at iteration 1540 : 7.986106356838718e-05
Loss at iteration 1550 : 0.00014769029803574085
Loss at iteration 1560 : 0.0005328056286089122
Loss at iteration 1570 : 0.0023360364139080048
Loss at iteration 1580 : 9.806102752918378e-05
Loss at iteration 1590 : 0.001589692779816687
Loss at iteration 1600 : 0.0011884092818945646
Loss at iteration 1610 : 0.00032729835947975516
Loss at iteration 1620 : 0.000435778551036492
Loss at iteration 1630 : 0.00041967519791796803
Loss at iteration 1640 : 0.00016010702529456466
Loss at iteration 1650 : 0.004229462239891291
Loss at iteration 1660 : 0.00024842232232913375
Loss at iteration 1670 : 8.462159166811034e-05
Loss at iteration 1680 : 0.0002490733750164509
Loss at iteration 1690 : 0.0012789705069735646
Loss at iteration 1700 : 0.0003446652553975582
Loss at iteration 1710 : 0.004136623349040747
Loss at iteration 1720 : 0.000614914926700294
Loss at iteration 1730 : 0.001730430405586958
Loss at iteration 1740 : 0.0005997609114274383
Loss at iteration 1750 : 0.00041958183282986283
The SSIM Value is: 0.9879954736925957
The PSNR Value is: 46.63768852964897
the epoch is: 88
Loss at iteration 10 : 0.0013879137113690376
Loss at iteration 20 : 0.00019115861505270004
Loss at iteration 30 : 0.004294122569262981
Loss at iteration 40 : 0.001731178374029696
Loss at iteration 50 : 0.00017680029850453138
Loss at iteration 60 : 0.0017173719825223088
Loss at iteration 70 : 9.894510003505275e-05
Loss at iteration 80 : 9.870647045318037e-05
Loss at iteration 90 : 6.940377352293581e-05
Loss at iteration 100 : 0.0001465822570025921
Loss at iteration 110 : 8.185581100406125e-05
Loss at iteration 120 : 0.0002196434506913647
Loss at iteration 130 : 0.0032115476205945015
Loss at iteration 140 : 0.0007378596346825361
Loss at iteration 150 : 0.0008227183716371655
Loss at iteration 160 : 0.001081105787307024
Loss at iteration 170 : 0.0003821314312517643
Loss at iteration 180 : 0.0010828074300661683
Loss at iteration 190 : 7.384229684248567e-05
Loss at iteration 200 : 0.002156886737793684
Loss at iteration 210 : 0.000496076769195497
Loss at iteration 220 : 0.0006968636880628765
Loss at iteration 230 : 0.00017429032595828176
Loss at iteration 240 : 0.00011747721873689443
Loss at iteration 250 : 0.0003872709348797798
Loss at iteration 260 : 0.00015783551498316228
Loss at iteration 270 : 0.00044678800622932613
Loss at iteration 280 : 0.0012235278263688087
Loss at iteration 290 : 0.0011162144364789128
Loss at iteration 300 : 0.0011793251615017653
Loss at iteration 310 : 0.0012612761929631233
Loss at iteration 320 : 0.0008940745028667152
Loss at iteration 330 : 0.0006300102104432881
Loss at iteration 340 : 0.00010280321293976158
Loss at iteration 350 : 0.0012210626155138016
Loss at iteration 360 : 0.000233431754168123
Loss at iteration 370 : 0.0005096315871924162
Loss at iteration 380 : 0.0009955968707799911
Loss at iteration 390 : 0.00015001863357611
Loss at iteration 400 : 9.630172280594707e-05
Loss at iteration 410 : 0.00019742216682061553
Loss at iteration 420 : 0.0005020599928684533
Loss at iteration 430 : 0.0003139272448606789
Loss at iteration 440 : 8.012945181690156e-05
Loss at iteration 450 : 0.00012311061436776072
Loss at iteration 460 : 0.0004085557593498379
Loss at iteration 470 : 6.912663957336918e-05
Loss at iteration 480 : 0.00011513290519360453
Loss at iteration 490 : 0.00018010845815297216
Loss at iteration 500 : 0.000294512661639601
Loss at iteration 510 : 0.0008331624558195472
Loss at iteration 520 : 0.000597418867982924
Loss at iteration 530 : 0.00015214445011224598
Loss at iteration 540 : 0.0003160813357681036
Loss at iteration 550 : 0.00026803111541084945
Loss at iteration 560 : 0.0006087967194616795
Loss at iteration 570 : 0.001554145710542798
Loss at iteration 580 : 0.002549517899751663
Loss at iteration 590 : 0.00014752248534932733
Loss at iteration 600 : 0.001963726943358779
Loss at iteration 610 : 0.000541986315511167
Loss at iteration 620 : 0.000789073237683624
Loss at iteration 630 : 0.0011464704293757677
Loss at iteration 640 : 0.00024733878672122955
Loss at iteration 650 : 0.0033399094827473164
Loss at iteration 660 : 0.0006631899159401655
Loss at iteration 670 : 2.748402039287612e-05
Loss at iteration 680 : 0.000579455925617367
Loss at iteration 690 : 0.0006177090690471232
Loss at iteration 700 : 0.0007834892603568733
Loss at iteration 710 : 0.00025810804800130427
Loss at iteration 720 : 0.0029958186205476522
Loss at iteration 730 : 0.0014615909894928336
Loss at iteration 740 : 0.0003715534694492817
Loss at iteration 750 : 0.0021082209423184395
Loss at iteration 760 : 0.0014662048779428005
Loss at iteration 770 : 0.0001018942566588521
Loss at iteration 780 : 0.004254952073097229
Loss at iteration 790 : 9.324918210040778e-05
Loss at iteration 800 : 0.000196446490008384
Loss at iteration 810 : 0.00031526503153145313
Loss at iteration 820 : 0.00019088982662651688
Loss at iteration 830 : 0.000832793943118304
Loss at iteration 840 : 0.0038762306794524193
Loss at iteration 850 : 0.001276928698644042
Loss at iteration 860 : 0.004531889222562313
Loss at iteration 870 : 0.0017230052035301924
Loss at iteration 880 : 0.00022082720533944666
Loss at iteration 890 : 0.0019907993264496326
Loss at iteration 900 : 0.0009817469399422407
Loss at iteration 910 : 0.00013473171566147357
Loss at iteration 920 : 0.008973091840744019
Loss at iteration 930 : 0.00010020537592936307
Loss at iteration 940 : 0.0017440158408135176
Loss at iteration 950 : 0.0007257949328050017
Loss at iteration 960 : 0.00016598332149442285
Loss at iteration 970 : 0.0006870174547657371
Loss at iteration 980 : 0.0014416943304240704
Loss at iteration 990 : 0.00022127138799987733
Loss at iteration 1000 : 0.0023791573476046324
Loss at iteration 1010 : 0.0026659222785383463
Loss at iteration 1020 : 0.00019261919078417122
Loss at iteration 1030 : 0.0002863197587430477
Loss at iteration 1040 : 0.0003357628593221307
Loss at iteration 1050 : 0.0004214624350424856
Loss at iteration 1060 : 0.00020268844673410058
Loss at iteration 1070 : 0.00019766887999139726
Loss at iteration 1080 : 0.000483231182442978
Loss at iteration 1090 : 0.0006183445220813155
Loss at iteration 1100 : 0.0016183268744498491
Loss at iteration 1110 : 0.00046907493378967047
Loss at iteration 1120 : 0.00024405989097431302
Loss at iteration 1130 : 0.001075916807167232
Loss at iteration 1140 : 0.0001361081813229248
Loss at iteration 1150 : 0.0006512613035738468
Loss at iteration 1160 : 0.0008646442438475788
Loss at iteration 1170 : 0.0012730831513181329
Loss at iteration 1180 : 0.0003001932054758072
Loss at iteration 1190 : 0.00012235995382070541
Loss at iteration 1200 : 0.004275270272046328
Loss at iteration 1210 : 0.000923690153285861
Loss at iteration 1220 : 0.00039923095027916133
Loss at iteration 1230 : 0.0013030805857852101
Loss at iteration 1240 : 6.881909939693287e-05
Loss at iteration 1250 : 0.00028649784508161247
Loss at iteration 1260 : 0.0002711373963393271
Loss at iteration 1270 : 0.003773573087528348
Loss at iteration 1280 : 0.0009705832344479859
Loss at iteration 1290 : 0.0006505650235339999
Loss at iteration 1300 : 0.00014946659212000668
Loss at iteration 1310 : 0.00017679142183624208
Loss at iteration 1320 : 9.561728802509606e-05
Loss at iteration 1330 : 7.718134293099865e-05
Loss at iteration 1340 : 0.0008546833996661007
Loss at iteration 1350 : 0.0022096559405326843
Loss at iteration 1360 : 0.0008727380773052573
Loss at iteration 1370 : 0.0001425610826117918
Loss at iteration 1380 : 0.0019343688618391752
Loss at iteration 1390 : 0.000503639574162662
Loss at iteration 1400 : 0.003660364542156458
Loss at iteration 1410 : 0.007016743067651987
Loss at iteration 1420 : 0.000906562025193125
Loss at iteration 1430 : 0.00591170322149992
Loss at iteration 1440 : 7.390286918962374e-05
Loss at iteration 1450 : 0.00017039116937667131
Loss at iteration 1460 : 0.0009233241435140371
Loss at iteration 1470 : 0.0005220357561483979
Loss at iteration 1480 : 9.577209129929543e-05
Loss at iteration 1490 : 0.00030980337760411203
Loss at iteration 1500 : 0.0025759197305887938
Loss at iteration 1510 : 0.00010610013850964606
Loss at iteration 1520 : 0.00029475512565113604
Loss at iteration 1530 : 0.001624054042622447
Loss at iteration 1540 : 0.00034264675923623145
Loss at iteration 1550 : 5.533345392905176e-05
Loss at iteration 1560 : 0.0022012668196111917
Loss at iteration 1570 : 0.0002451400796417147
Loss at iteration 1580 : 0.0006292934413067997
Loss at iteration 1590 : 0.00012904235336463898
Loss at iteration 1600 : 0.00018473711679689586
Loss at iteration 1610 : 0.0002880669489968568
Loss at iteration 1620 : 0.001887797610834241
Loss at iteration 1630 : 0.00017431465676054358
Loss at iteration 1640 : 0.00025542653747834265
Loss at iteration 1650 : 0.0026112119667232037
Loss at iteration 1660 : 0.0013742577284574509
Loss at iteration 1670 : 8.326328679686412e-05
Loss at iteration 1680 : 0.0012868678895756602
Loss at iteration 1690 : 0.0025660633109509945
Loss at iteration 1700 : 0.001011442393064499
Loss at iteration 1710 : 0.0004817651060875505
Loss at iteration 1720 : 8.159136632457376e-05
Loss at iteration 1730 : 0.000676547409966588
Loss at iteration 1740 : 0.00010750403453130275
Loss at iteration 1750 : 0.00024289818247780204
The SSIM Value is: 0.9778098105596551
The PSNR Value is: 46.62283121016582
the epoch is: 89
Loss at iteration 10 : 0.0006935374112799764
Loss at iteration 20 : 0.00024614817812107503
Loss at iteration 30 : 0.0003044750774279237
Loss at iteration 40 : 0.00015143332711886615
Loss at iteration 50 : 0.0001160720712505281
Loss at iteration 60 : 0.001144962734542787
Loss at iteration 70 : 0.0004299741704016924
Loss at iteration 80 : 0.0002120189747074619
Loss at iteration 90 : 0.0008973199874162674
Loss at iteration 100 : 2.3800821509212255e-05
Loss at iteration 110 : 7.303413440240547e-05
Loss at iteration 120 : 0.0001054006497724913
Loss at iteration 130 : 0.002010576892644167
Loss at iteration 140 : 0.0014093767385929823
Loss at iteration 150 : 0.00018364452989771962
Loss at iteration 160 : 0.0016209225868806243
Loss at iteration 170 : 0.00013118403148837388
Loss at iteration 180 : 0.0007211248739622533
Loss at iteration 190 : 0.0010035649174824357
Loss at iteration 200 : 0.0003491456154733896
Loss at iteration 210 : 0.0001577984803589061
Loss at iteration 220 : 0.00314518716186285
Loss at iteration 230 : 0.00018472396186552942
Loss at iteration 240 : 0.0003620363131631166
Loss at iteration 250 : 0.0021267603151500225
Loss at iteration 260 : 9.234865137841552e-05
Loss at iteration 270 : 0.0010850246762856841
Loss at iteration 280 : 0.006316391751170158
Loss at iteration 290 : 0.0004605530994012952
Loss at iteration 300 : 0.0004788305377587676
Loss at iteration 310 : 0.00029003253439441323
Loss at iteration 320 : 0.00022074030130170286
Loss at iteration 330 : 0.00025793228996917605
Loss at iteration 340 : 0.00034085442894138396
Loss at iteration 350 : 0.006811066530644894
Loss at iteration 360 : 0.0005539529956877232
Loss at iteration 370 : 0.0003127766540274024
Loss at iteration 380 : 0.0025973906740546227
Loss at iteration 390 : 0.0015398995019495487
Loss at iteration 400 : 0.0038483934476971626
Loss at iteration 410 : 0.0025774086825549603
Loss at iteration 420 : 0.0011371327564120293
Loss at iteration 430 : 0.0001287264167331159
Loss at iteration 440 : 0.0006039324798621237
Loss at iteration 450 : 0.00028326877509243786
Loss at iteration 460 : 0.00026400224305689335
Loss at iteration 470 : 0.004208821803331375
Loss at iteration 480 : 0.00012989374226890504
Loss at iteration 490 : 0.003474521916359663
Loss at iteration 500 : 0.0013781191082671285
Loss at iteration 510 : 0.0034241536632180214
Loss at iteration 520 : 0.00017462833784520626
Loss at iteration 530 : 0.00245079817250371
Loss at iteration 540 : 0.00016078441694844514
Loss at iteration 550 : 0.0006302331457845867
Loss at iteration 560 : 0.0023945767898112535
Loss at iteration 570 : 0.00040697382064536214
Loss at iteration 580 : 0.003928446210920811
Loss at iteration 590 : 0.00018261431250721216
Loss at iteration 600 : 0.000957614800427109
Loss at iteration 610 : 0.0040699332021176815
Loss at iteration 620 : 0.0019259825348854065
Loss at iteration 630 : 0.0009263105457648635
Loss at iteration 640 : 8.779740892350674e-05
Loss at iteration 650 : 0.0010074750753119588
Loss at iteration 660 : 0.00014642096357420087
Loss at iteration 670 : 0.00011447413999121636
Loss at iteration 680 : 0.0025866844225674868
Loss at iteration 690 : 0.0023364985827356577
Loss at iteration 700 : 0.007528440095484257
Loss at iteration 710 : 0.0004596610669977963
Loss at iteration 720 : 0.002687287051230669
Loss at iteration 730 : 0.0017617499688640237
Loss at iteration 740 : 0.0002645759959705174
Loss at iteration 750 : 9.683577809482813e-05
Loss at iteration 760 : 0.0007369698723778129
Loss at iteration 770 : 0.0024826256558299065
Loss at iteration 780 : 6.43591265543364e-05
Loss at iteration 790 : 0.004913675133138895
Loss at iteration 800 : 0.003812394803389907
Loss at iteration 810 : 0.00021498018759302795
Loss at iteration 820 : 0.0003237470518797636
Loss at iteration 830 : 0.0017328428803011775
Loss at iteration 840 : 0.00016278435941785574
Loss at iteration 850 : 3.504062260617502e-05
Loss at iteration 860 : 0.0013401263859122992
Loss at iteration 870 : 0.0010294101666659117
Loss at iteration 880 : 0.002342056483030319
Loss at iteration 890 : 0.00024020284763537347
Loss at iteration 900 : 0.0008447291329503059
Loss at iteration 910 : 0.00019595093908719718
Loss at iteration 920 : 0.00017681992903817445
Loss at iteration 930 : 0.0005757020553573966
Loss at iteration 940 : 0.00031121564097702503
Loss at iteration 950 : 0.0007303312886506319
Loss at iteration 960 : 0.000145621073897928
Loss at iteration 970 : 0.0001063482413883321
Loss at iteration 980 : 0.00022628132137469947
Loss at iteration 990 : 0.002564704045653343
Loss at iteration 1000 : 0.004020214080810547
Loss at iteration 1010 : 0.001809889916330576
Loss at iteration 1020 : 0.00010402673797216266
Loss at iteration 1030 : 0.00022309455380309373
Loss at iteration 1040 : 0.005363236181437969
Loss at iteration 1050 : 0.0019171875901520252
Loss at iteration 1060 : 0.0001555022899992764
Loss at iteration 1070 : 0.00018705939874053001
Loss at iteration 1080 : 0.0031630496960133314
Loss at iteration 1090 : 0.0006624439265578985
Loss at iteration 1100 : 2.7120338927488774e-05
Loss at iteration 1110 : 0.000235329192946665
Loss at iteration 1120 : 0.0006178848561830819
Loss at iteration 1130 : 0.0017938535893335938
Loss at iteration 1140 : 0.0002520237467251718
Loss at iteration 1150 : 0.00037527462700381875
Loss at iteration 1160 : 0.00014657930296380073
Loss at iteration 1170 : 0.004511948209255934
Loss at iteration 1180 : 5.455878272186965e-05
Loss at iteration 1190 : 0.0014725158689543605
Loss at iteration 1200 : 9.225215035257861e-05
Loss at iteration 1210 : 0.0008139970595948398
Loss at iteration 1220 : 0.00044840291957370937
Loss at iteration 1230 : 0.0019805137999355793
Loss at iteration 1240 : 0.0010134089970961213
Loss at iteration 1250 : 0.0009353517089039087
Loss at iteration 1260 : 0.002376645803451538
Loss at iteration 1270 : 0.0002040916442638263
Loss at iteration 1280 : 0.0005446490831673145
Loss at iteration 1290 : 0.00037488044472411275
Loss at iteration 1300 : 0.00021405040752142668
Loss at iteration 1310 : 0.002206044504418969
Loss at iteration 1320 : 0.00015577675367239863
Loss at iteration 1330 : 0.0021377690136432648
Loss at iteration 1340 : 0.0041537354700267315
Loss at iteration 1350 : 0.0002714592556003481
Loss at iteration 1360 : 0.0012440781574696302
Loss at iteration 1370 : 0.0012431575451046228
Loss at iteration 1380 : 0.000462393625639379
Loss at iteration 1390 : 0.0017812005244195461
Loss at iteration 1400 : 0.0020580189302563667
Loss at iteration 1410 : 0.00048768040142022073
Loss at iteration 1420 : 0.0003175758174620569
Loss at iteration 1430 : 0.0005130675854161382
Loss at iteration 1440 : 0.0009234730387106538
Loss at iteration 1450 : 9.278986544813961e-05
Loss at iteration 1460 : 0.00023118917306419462
Loss at iteration 1470 : 0.0049843755550682545
Loss at iteration 1480 : 0.0005579758435487747
Loss at iteration 1490 : 0.0008240756578743458
Loss at iteration 1500 : 0.0008322707144543529
Loss at iteration 1510 : 0.0016360580921173096
Loss at iteration 1520 : 0.0010084747336804867
Loss at iteration 1530 : 5.048893945058808e-05
Loss at iteration 1540 : 0.00045636927825398743
Loss at iteration 1550 : 0.0003728774609044194
Loss at iteration 1560 : 5.998836422804743e-05
Loss at iteration 1570 : 0.0004290840879548341
Loss at iteration 1580 : 0.0021660279016941786
Loss at iteration 1590 : 0.0003211559378542006
Loss at iteration 1600 : 0.002046081470325589
Loss at iteration 1610 : 0.00041216221870854497
Loss at iteration 1620 : 0.0018560158787295222
Loss at iteration 1630 : 0.0003082666953559965
Loss at iteration 1640 : 0.003795618424192071
Loss at iteration 1650 : 0.001114001264795661
Loss at iteration 1660 : 0.0003296450595371425
Loss at iteration 1670 : 0.0014382036169990897
Loss at iteration 1680 : 0.00033354898914694786
Loss at iteration 1690 : 0.00015339956735260785
Loss at iteration 1700 : 5.18995184393134e-05
Loss at iteration 1710 : 0.00019274785881862044
Loss at iteration 1720 : 0.00043036535498686135
Loss at iteration 1730 : 0.00011903214908670634
Loss at iteration 1740 : 0.0003501893952488899
Loss at iteration 1750 : 0.00047524471301585436
The SSIM Value is: 0.9792614856217926
The PSNR Value is: 46.58559073855698
the epoch is: 90
Loss at iteration 10 : 0.000365587358828634
Loss at iteration 20 : 0.0002603020111564547
Loss at iteration 30 : 0.001244135550223291
Loss at iteration 40 : 0.0004258355183992535
Loss at iteration 50 : 0.00042714865412563086
Loss at iteration 60 : 0.00011288217501714826
Loss at iteration 70 : 0.0001577555522089824
Loss at iteration 80 : 0.0003468739159870893
Loss at iteration 90 : 0.0005005159764550626
Loss at iteration 100 : 0.001413743942975998
Loss at iteration 110 : 0.00043200841173529625
Loss at iteration 120 : 0.0005305144004523754
Loss at iteration 130 : 0.0003109180834144354
Loss at iteration 140 : 0.00016133234021253884
Loss at iteration 150 : 0.00024263857631012797
Loss at iteration 160 : 0.0020491129253059626
Loss at iteration 170 : 0.0032410696148872375
Loss at iteration 180 : 0.0004298969288356602
Loss at iteration 190 : 0.0016580659430474043
Loss at iteration 200 : 0.0003351029008626938
Loss at iteration 210 : 0.0001472399744670838
Loss at iteration 220 : 0.0025498538743704557
Loss at iteration 230 : 0.0006411197828128934
Loss at iteration 240 : 0.0006213168962858617
Loss at iteration 250 : 0.003368592821061611
Loss at iteration 260 : 0.0005933286156505346
Loss at iteration 270 : 0.00020641210721805692
Loss at iteration 280 : 5.028292798670009e-05
Loss at iteration 290 : 0.00027135928394272923
Loss at iteration 300 : 0.0020617004483938217
Loss at iteration 310 : 0.0008867756696417928
Loss at iteration 320 : 9.667841368354857e-05
Loss at iteration 330 : 0.01075400784611702
Loss at iteration 340 : 0.00019650640024337918
Loss at iteration 350 : 9.829307964537293e-05
Loss at iteration 360 : 0.00024599896278232336
Loss at iteration 370 : 0.00025414256379008293
Loss at iteration 380 : 0.000926534878090024
Loss at iteration 390 : 0.001027543912641704
Loss at iteration 400 : 6.639275670750067e-05
Loss at iteration 410 : 0.0004292243393138051
Loss at iteration 420 : 0.0003073383413720876
Loss at iteration 430 : 0.00023496628273278475
Loss at iteration 440 : 0.0004312281671445817
Loss at iteration 450 : 0.0003883700992446393
Loss at iteration 460 : 0.00017539574764668941
Loss at iteration 470 : 0.001977519830688834
Loss at iteration 480 : 0.000149883097037673
Loss at iteration 490 : 0.00021139209275133908
Loss at iteration 500 : 0.0007895486196503043
Loss at iteration 510 : 0.0009918475989252329
Loss at iteration 520 : 0.00015342654660344124
Loss at iteration 530 : 0.00023180764401331544
Loss at iteration 540 : 9.076068818103522e-05
Loss at iteration 550 : 0.00040394350071437657
Loss at iteration 560 : 0.00115866307169199
Loss at iteration 570 : 0.0014183552702888846
Loss at iteration 580 : 0.00012928407522849739
Loss at iteration 590 : 0.002047039568424225
Loss at iteration 600 : 0.00012544165656436235
Loss at iteration 610 : 0.00016276798851322383
Loss at iteration 620 : 0.0002839156659319997
Loss at iteration 630 : 0.0007442324422299862
Loss at iteration 640 : 0.00014453852782025933
Loss at iteration 650 : 0.0007119610672816634
Loss at iteration 660 : 0.000433290668297559
Loss at iteration 670 : 0.005243127699941397
Loss at iteration 680 : 0.0006585147930309176
Loss at iteration 690 : 0.003391105914488435
Loss at iteration 700 : 0.0042423647828400135
Loss at iteration 710 : 0.00017844629473984241
Loss at iteration 720 : 0.0017911295872181654
Loss at iteration 730 : 0.00014095011283643544
Loss at iteration 740 : 0.00018729350995272398
Loss at iteration 750 : 5.924896686337888e-05
Loss at iteration 760 : 9.350122127216309e-05
Loss at iteration 770 : 0.000214281419175677
Loss at iteration 780 : 0.00029873233870603144
Loss at iteration 790 : 0.0002750945568550378
Loss at iteration 800 : 0.0003849297936540097
Loss at iteration 810 : 0.003428276162594557
Loss at iteration 820 : 0.0011714780703186989
Loss at iteration 830 : 0.00022809943766333163
Loss at iteration 840 : 0.006089049857109785
Loss at iteration 850 : 0.00012991463881917298
Loss at iteration 860 : 9.907630737870932e-05
Loss at iteration 870 : 0.0002582675660960376
Loss at iteration 880 : 0.0032104034908115864
Loss at iteration 890 : 0.00018856192764360458
Loss at iteration 900 : 0.0005191712989471853
Loss at iteration 910 : 0.0005954605294391513
Loss at iteration 920 : 0.002538675907999277
Loss at iteration 930 : 0.0011583741288632154
Loss at iteration 940 : 0.0057282829657197
Loss at iteration 950 : 0.00017018841754179448
Loss at iteration 960 : 0.0019025236833840609
Loss at iteration 970 : 0.0012449158821254969
Loss at iteration 980 : 0.0035661591682583094
Loss at iteration 990 : 0.0008038231753744185
Loss at iteration 1000 : 0.0030351215973496437
Loss at iteration 1010 : 0.00179261842276901
Loss at iteration 1020 : 0.0024200468324124813
Loss at iteration 1030 : 0.003631892614066601
Loss at iteration 1040 : 0.0011279734317213297
Loss at iteration 1050 : 0.00021317932987585664
Loss at iteration 1060 : 0.00010180885146837682
Loss at iteration 1070 : 9.590265835868195e-05
Loss at iteration 1080 : 0.00015674697351641953
Loss at iteration 1090 : 0.0018789643654599786
Loss at iteration 1100 : 0.0010697103571146727
Loss at iteration 1110 : 0.003439913969486952
Loss at iteration 1120 : 0.007086809724569321
Loss at iteration 1130 : 0.0005153187084943056
Loss at iteration 1140 : 0.0016623294213786721
Loss at iteration 1150 : 0.0003235384065192193
Loss at iteration 1160 : 0.0005036028451286256
Loss at iteration 1170 : 4.600455577019602e-05
Loss at iteration 1180 : 0.0003559335309546441
Loss at iteration 1190 : 0.00034632181632332504
Loss at iteration 1200 : 0.0001809614332159981
Loss at iteration 1210 : 0.00027395112556405365
Loss at iteration 1220 : 0.00015553925186395645
Loss at iteration 1230 : 0.0016979607753455639
Loss at iteration 1240 : 0.00012528324441518635
Loss at iteration 1250 : 0.00046083240886218846
Loss at iteration 1260 : 0.004665131215006113
Loss at iteration 1270 : 0.00010503846715437248
Loss at iteration 1280 : 0.00012725076521746814
Loss at iteration 1290 : 0.0003430854994803667
Loss at iteration 1300 : 6.688747089356184e-05
Loss at iteration 1310 : 8.832989260554314e-05
Loss at iteration 1320 : 0.00011625596380326897
Loss at iteration 1330 : 0.0017281461041420698
Loss at iteration 1340 : 0.00022661472030449659
Loss at iteration 1350 : 0.006475544534623623
Loss at iteration 1360 : 9.9427234090399e-05
Loss at iteration 1370 : 0.0006485064513981342
Loss at iteration 1380 : 0.003143915208056569
Loss at iteration 1390 : 0.0004003790963906795
Loss at iteration 1400 : 0.0005081564304418862
Loss at iteration 1410 : 0.00020636338740587234
Loss at iteration 1420 : 0.001471170922741294
Loss at iteration 1430 : 0.0004092104791197926
Loss at iteration 1440 : 0.0008684259373694658
Loss at iteration 1450 : 0.00019399932352826
Loss at iteration 1460 : 0.0017219395376741886
Loss at iteration 1470 : 0.0004150033346377313
Loss at iteration 1480 : 0.001574107212945819
Loss at iteration 1490 : 8.198245632229373e-05
Loss at iteration 1500 : 0.0006770574836991727
Loss at iteration 1510 : 0.0007611027685925364
Loss at iteration 1520 : 0.008290319703519344
Loss at iteration 1530 : 0.0015089454827830195
Loss at iteration 1540 : 0.0004425938241183758
Loss at iteration 1550 : 9.063943434739485e-05
Loss at iteration 1560 : 0.00018534227274358273
Loss at iteration 1570 : 9.442026203032583e-05
Loss at iteration 1580 : 0.0015444222372025251
Loss at iteration 1590 : 0.0012892029481008649
Loss at iteration 1600 : 0.0001877913309726864
Loss at iteration 1610 : 8.903153502615169e-05
Loss at iteration 1620 : 6.444871542043984e-05
Loss at iteration 1630 : 0.0004237787798047066
Loss at iteration 1640 : 0.0005756295286118984
Loss at iteration 1650 : 0.0001375511783408001
Loss at iteration 1660 : 0.0001376174041070044
Loss at iteration 1670 : 0.008465447463095188
Loss at iteration 1680 : 0.00015826555318199098
Loss at iteration 1690 : 9.830484486883506e-05
Loss at iteration 1700 : 0.0011750842677429318
Loss at iteration 1710 : 9.667582344263792e-05
Loss at iteration 1720 : 0.0021261891815811396
Loss at iteration 1730 : 0.0009092081454582512
Loss at iteration 1740 : 0.0002441795077174902
Loss at iteration 1750 : 0.00020980674889869988
The SSIM Value is: 0.9816164432118117
The PSNR Value is: 46.20482851650221
the epoch is: 91
Loss at iteration 10 : 0.0031629507429897785
Loss at iteration 20 : 0.0004928716807626188
Loss at iteration 30 : 0.0005553801311179996
Loss at iteration 40 : 0.00019652860646601766
Loss at iteration 50 : 0.00034521447378210723
Loss at iteration 60 : 0.0005200619343668222
Loss at iteration 70 : 0.00032801591441966593
Loss at iteration 80 : 0.0010854937136173248
Loss at iteration 90 : 4.694458766607568e-05
Loss at iteration 100 : 0.003304627723991871
Loss at iteration 110 : 0.0049676476046442986
Loss at iteration 120 : 0.00011862177052535117
Loss at iteration 130 : 0.0005976938409730792
Loss at iteration 140 : 9.055290138348937e-05
Loss at iteration 150 : 0.008879235945641994
Loss at iteration 160 : 9.85076476354152e-05
Loss at iteration 170 : 0.00022054550936445594
Loss at iteration 180 : 0.0036904439330101013
Loss at iteration 190 : 0.00017588761693332344
Loss at iteration 200 : 0.0015630240086466074
Loss at iteration 210 : 0.00010054995800601318
Loss at iteration 220 : 4.943837120663375e-05
Loss at iteration 230 : 0.00011296699085505679
Loss at iteration 240 : 9.784717985894531e-05
Loss at iteration 250 : 0.0005183880566619337
Loss at iteration 260 : 0.00046083322376944125
Loss at iteration 270 : 0.0027216938324272633
Loss at iteration 280 : 0.0007731003570370376
Loss at iteration 290 : 0.002270529977977276
Loss at iteration 300 : 0.0009823765140026808
Loss at iteration 310 : 0.0022929972037672997
Loss at iteration 320 : 0.00027739250799641013
Loss at iteration 330 : 0.0002982711012009531
Loss at iteration 340 : 0.0006526001961901784
Loss at iteration 350 : 0.003036695998162031
Loss at iteration 360 : 0.00011902194819413126
Loss at iteration 370 : 0.00012153107672929764
Loss at iteration 380 : 0.0076022157445549965
Loss at iteration 390 : 0.0005500185070559382
Loss at iteration 400 : 0.003547131782397628
Loss at iteration 410 : 0.0009283282561227679
Loss at iteration 420 : 0.0007226138841360807
Loss at iteration 430 : 4.097403143532574e-05
Loss at iteration 440 : 0.0013005784712731838
Loss at iteration 450 : 0.0006470990483649075
Loss at iteration 460 : 0.0002666295040398836
Loss at iteration 470 : 0.00017031315655913204
Loss at iteration 480 : 0.000439355440903455
Loss at iteration 490 : 0.00120683538261801
Loss at iteration 500 : 0.0003460679145064205
Loss at iteration 510 : 0.00010532693704590201
Loss at iteration 520 : 0.00037123370566405356
Loss at iteration 530 : 0.0001997813960770145
Loss at iteration 540 : 0.0012766375439241529
Loss at iteration 550 : 4.179164898232557e-05
Loss at iteration 560 : 0.0002724059158936143
Loss at iteration 570 : 0.0001737526326905936
Loss at iteration 580 : 0.00625432375818491
Loss at iteration 590 : 0.0019332951633259654
Loss at iteration 600 : 0.00046093371929600835
Loss at iteration 610 : 9.161164052784443e-05
Loss at iteration 620 : 0.0018904308089986444
Loss at iteration 630 : 0.003096395405009389
Loss at iteration 640 : 0.00013187012518756092
Loss at iteration 650 : 0.0007126053096726537
Loss at iteration 660 : 0.0031623318791389465
Loss at iteration 670 : 0.003421089379116893
Loss at iteration 680 : 0.0024829693138599396
Loss at iteration 690 : 0.00012464183964766562
Loss at iteration 700 : 0.0001326279016211629
Loss at iteration 710 : 0.003589628729969263
Loss at iteration 720 : 0.0003443119639996439
Loss at iteration 730 : 0.002655069576576352
Loss at iteration 740 : 4.790848834090866e-05
Loss at iteration 750 : 0.00013659108662977815
Loss at iteration 760 : 0.00017225317424163222
Loss at iteration 770 : 0.0005724055226892233
Loss at iteration 780 : 0.001811124151572585
Loss at iteration 790 : 0.0004149608430452645
Loss at iteration 800 : 0.0004635121440514922
Loss at iteration 810 : 0.00019388894725125283
Loss at iteration 820 : 0.002681683748960495
Loss at iteration 830 : 0.0014241772005334496
Loss at iteration 840 : 0.0005510600167326629
Loss at iteration 850 : 0.000321584491757676
Loss at iteration 860 : 0.00015025443281047046
Loss at iteration 870 : 0.0003116313891950995
Loss at iteration 880 : 7.505311805289239e-05
Loss at iteration 890 : 0.0006634729797951877
Loss at iteration 900 : 0.0011985556920990348
Loss at iteration 910 : 0.0024054914247244596
Loss at iteration 920 : 0.0005269874818623066
Loss at iteration 930 : 0.0002559508429840207
Loss at iteration 940 : 0.0002950919442810118
Loss at iteration 950 : 0.0002664659987203777
Loss at iteration 960 : 0.0007432355778291821
Loss at iteration 970 : 0.00013077397306915373
Loss at iteration 980 : 0.0008406870765611529
Loss at iteration 990 : 5.3720970754511654e-05
Loss at iteration 1000 : 0.0011343597434461117
Loss at iteration 1010 : 0.0006293662008829415
Loss at iteration 1020 : 0.0009036961710080504
Loss at iteration 1030 : 0.0004121317178942263
Loss at iteration 1040 : 0.002882398199290037
Loss at iteration 1050 : 0.0007693137740716338
Loss at iteration 1060 : 0.0003197694895789027
Loss at iteration 1070 : 0.0008507990278303623
Loss at iteration 1080 : 5.029054227634333e-05
Loss at iteration 1090 : 0.0034012426622211933
Loss at iteration 1100 : 0.00012112560943933204
Loss at iteration 1110 : 0.0002815744373947382
Loss at iteration 1120 : 0.00350874662399292
Loss at iteration 1130 : 0.00025364698376506567
Loss at iteration 1140 : 0.00045021570986136794
Loss at iteration 1150 : 0.00011875674681505188
Loss at iteration 1160 : 0.000149214974953793
Loss at iteration 1170 : 0.0022668675519526005
Loss at iteration 1180 : 0.00036241585621610284
Loss at iteration 1190 : 0.00033984173205681145
Loss at iteration 1200 : 0.0001414126600138843
Loss at iteration 1210 : 0.00013059428601991385
Loss at iteration 1220 : 0.00011126873141620308
Loss at iteration 1230 : 0.0055932230316102505
Loss at iteration 1240 : 0.0006642399821430445
Loss at iteration 1250 : 0.001569325104355812
Loss at iteration 1260 : 0.000526750460267067
Loss at iteration 1270 : 0.00026035611517727375
Loss at iteration 1280 : 7.578248187201098e-05
Loss at iteration 1290 : 0.00012186971434857696
Loss at iteration 1300 : 0.0024277877528220415
Loss at iteration 1310 : 0.0001460895873606205
Loss at iteration 1320 : 0.0005339483032003045
Loss at iteration 1330 : 0.0007752590463496745
Loss at iteration 1340 : 0.0001337372959824279
Loss at iteration 1350 : 0.00012609476107172668
Loss at iteration 1360 : 0.0014465395361185074
Loss at iteration 1370 : 0.0031719738617539406
Loss at iteration 1380 : 0.0004207627207506448
Loss at iteration 1390 : 0.00023181855794973671
Loss at iteration 1400 : 0.0007420319598168135
Loss at iteration 1410 : 0.0008760148193687201
Loss at iteration 1420 : 4.810207974514924e-05
Loss at iteration 1430 : 0.0010252007050439715
Loss at iteration 1440 : 0.0005529923946596682
Loss at iteration 1450 : 5.374758256948553e-05
Loss at iteration 1460 : 0.0004161571559961885
Loss at iteration 1470 : 0.0002973590453621
Loss at iteration 1480 : 0.0004767592763528228
Loss at iteration 1490 : 0.0001162723929155618
Loss at iteration 1500 : 0.0019065674860030413
Loss at iteration 1510 : 0.0033538609277457
Loss at iteration 1520 : 0.00026600382989272475
Loss at iteration 1530 : 0.00012405561574269086
Loss at iteration 1540 : 0.0012418869882822037
Loss at iteration 1550 : 0.0008720195619389415
Loss at iteration 1560 : 0.0018262984231114388
Loss at iteration 1570 : 0.00025585119146853685
Loss at iteration 1580 : 0.00023499058443121612
Loss at iteration 1590 : 0.00032653380185365677
Loss at iteration 1600 : 0.00010396366997156292
Loss at iteration 1610 : 0.0001285789767280221
Loss at iteration 1620 : 0.00026329938555136323
Loss at iteration 1630 : 0.0012791960034519434
Loss at iteration 1640 : 0.0003278565709479153
Loss at iteration 1650 : 0.00017471291357651353
Loss at iteration 1660 : 0.0025007298681885004
Loss at iteration 1670 : 0.0003179540508426726
Loss at iteration 1680 : 0.00027531717205420136
Loss at iteration 1690 : 0.0010977508500218391
Loss at iteration 1700 : 0.0004008165851701051
Loss at iteration 1710 : 0.0037199018988758326
Loss at iteration 1720 : 0.0007245518499985337
Loss at iteration 1730 : 0.00015592575073242188
Loss at iteration 1740 : 0.00033035577507689595
Loss at iteration 1750 : 0.0005900566466152668
The SSIM Value is: 0.9876195170018116
The PSNR Value is: 46.612776655457616
the epoch is: 92
Loss at iteration 10 : 0.0018292025197297335
Loss at iteration 20 : 0.0011265738867223263
Loss at iteration 30 : 0.00011835184704978019
Loss at iteration 40 : 0.0017519942484796047
Loss at iteration 50 : 0.0002039680548477918
Loss at iteration 60 : 0.00028457731241360307
Loss at iteration 70 : 0.00272197974845767
Loss at iteration 80 : 0.0003618727787397802
Loss at iteration 90 : 0.0010809883242473006
Loss at iteration 100 : 0.0007718330016359687
Loss at iteration 110 : 0.00047547052963636816
Loss at iteration 120 : 8.928118768380955e-05
Loss at iteration 130 : 0.00033689633710309863
Loss at iteration 140 : 0.0008381002116948366
Loss at iteration 150 : 0.00035393558209761977
Loss at iteration 160 : 0.0008042980916798115
Loss at iteration 170 : 0.00010196393122896552
Loss at iteration 180 : 0.007269499357789755
Loss at iteration 190 : 0.0009405752061866224
Loss at iteration 200 : 0.0010151141323149204
Loss at iteration 210 : 0.0001838594034779817
Loss at iteration 220 : 0.007555880583822727
Loss at iteration 230 : 0.002680091420188546
Loss at iteration 240 : 0.00018686760449782014
Loss at iteration 250 : 0.0002232677798019722
Loss at iteration 260 : 0.00014684899360872805
Loss at iteration 270 : 0.0016473423456773162
Loss at iteration 280 : 0.00011245511996094137
Loss at iteration 290 : 0.0006641244981437922
Loss at iteration 300 : 0.0001761479943525046
Loss at iteration 310 : 0.0005371646257117391
Loss at iteration 320 : 0.0005411584861576557
Loss at iteration 330 : 0.000570823613088578
Loss at iteration 340 : 0.0006064942572265863
Loss at iteration 350 : 0.00031472582486458123
Loss at iteration 360 : 0.0004121508973184973
Loss at iteration 370 : 0.004620437044650316
Loss at iteration 380 : 0.00048682972555980086
Loss at iteration 390 : 0.003032383741810918
Loss at iteration 400 : 0.0003634495660662651
Loss at iteration 410 : 0.0001598578382981941
Loss at iteration 420 : 8.103272557491437e-05
Loss at iteration 430 : 0.0006330492906272411
Loss at iteration 440 : 0.0005923638236708939
Loss at iteration 450 : 0.0005509217153303325
Loss at iteration 460 : 0.00012985122157260776
Loss at iteration 470 : 0.0021627042442560196
Loss at iteration 480 : 0.0008273691637441516
Loss at iteration 490 : 0.0021608714014291763
Loss at iteration 500 : 0.00011717825691448525
Loss at iteration 510 : 0.0002737551985774189
Loss at iteration 520 : 0.0015883733285591006
Loss at iteration 530 : 0.0030577564612030983
Loss at iteration 540 : 0.00036597310099750757
Loss at iteration 550 : 0.002183340722694993
Loss at iteration 560 : 0.0015917071141302586
Loss at iteration 570 : 0.0005040831747464836
Loss at iteration 580 : 0.0005465223221108317
Loss at iteration 590 : 0.0004257748369127512
Loss at iteration 600 : 0.00016647789743728936
Loss at iteration 610 : 0.003531674388796091
Loss at iteration 620 : 0.0003561140620149672
Loss at iteration 630 : 0.004050160758197308
Loss at iteration 640 : 0.0007055705646052957
Loss at iteration 650 : 0.0014393455348908901
Loss at iteration 660 : 0.00017604914319235831
Loss at iteration 670 : 0.0032165583688765764
Loss at iteration 680 : 0.0019113606540486217
Loss at iteration 690 : 0.0010433495044708252
Loss at iteration 700 : 8.443455590168014e-05
Loss at iteration 710 : 0.0002960173296742141
Loss at iteration 720 : 0.0036045005545020103
Loss at iteration 730 : 9.649798448663205e-05
Loss at iteration 740 : 0.00016000910545699298
Loss at iteration 750 : 0.0011470632161945105
Loss at iteration 760 : 0.00016518757911399007
Loss at iteration 770 : 0.00022930646082386374
Loss at iteration 780 : 0.00010259917326038703
Loss at iteration 790 : 0.00029697647551074624
Loss at iteration 800 : 0.0001631323975743726
Loss at iteration 810 : 0.00023996998788788915
Loss at iteration 820 : 0.00035072379978373647
Loss at iteration 830 : 0.0007156909559853375
Loss at iteration 840 : 9.239751670975238e-05
Loss at iteration 850 : 0.005722083151340485
Loss at iteration 860 : 0.0006503030890598893
Loss at iteration 870 : 0.00403065700083971
Loss at iteration 880 : 0.0004957680939696729
Loss at iteration 890 : 5.660990427713841e-05
Loss at iteration 900 : 0.0003288817242719233
Loss at iteration 910 : 0.00021540981833823025
Loss at iteration 920 : 0.0007255320088006556
Loss at iteration 930 : 0.0002530484925955534
Loss at iteration 940 : 8.511412306688726e-05
Loss at iteration 950 : 0.00010365305934101343
Loss at iteration 960 : 0.00030286971013993025
Loss at iteration 970 : 0.00017701537581160665
Loss at iteration 980 : 9.597069583833218e-05
Loss at iteration 990 : 0.0007893083384260535
Loss at iteration 1000 : 0.0015166611410677433
Loss at iteration 1010 : 0.0045292992144823074
Loss at iteration 1020 : 0.0011751074343919754
Loss at iteration 1030 : 0.00019360618898645043
Loss at iteration 1040 : 0.0010298809502273798
Loss at iteration 1050 : 0.0005862704711034894
Loss at iteration 1060 : 0.005179090425372124
Loss at iteration 1070 : 0.00012526204227469862
Loss at iteration 1080 : 0.002188822254538536
Loss at iteration 1090 : 0.001722181448712945
Loss at iteration 1100 : 0.0011946028098464012
Loss at iteration 1110 : 0.0003021953161805868
Loss at iteration 1120 : 0.0022775554098188877
Loss at iteration 1130 : 8.8223532657139e-05
Loss at iteration 1140 : 6.974595453357324e-05
Loss at iteration 1150 : 0.00251366151496768
Loss at iteration 1160 : 0.0002906109148170799
Loss at iteration 1170 : 0.0001089798315661028
Loss at iteration 1180 : 0.0027580317109823227
Loss at iteration 1190 : 0.005829075817018747
Loss at iteration 1200 : 0.00021012639626860619
Loss at iteration 1210 : 0.0003069780068472028
Loss at iteration 1220 : 0.001395608764141798
Loss at iteration 1230 : 0.00014242737961467355
Loss at iteration 1240 : 0.00031890301033854485
Loss at iteration 1250 : 0.0006028944626450539
Loss at iteration 1260 : 0.000432189874118194
Loss at iteration 1270 : 0.0005480658728629351
Loss at iteration 1280 : 0.002390457782894373
Loss at iteration 1290 : 0.003891340922564268
Loss at iteration 1300 : 0.00012804780271835625
Loss at iteration 1310 : 0.0029915596824139357
Loss at iteration 1320 : 0.0006455209222622216
Loss at iteration 1330 : 0.0002756047178991139
Loss at iteration 1340 : 0.00018162951164413244
Loss at iteration 1350 : 7.09941959939897e-05
Loss at iteration 1360 : 0.00014052727783564478
Loss at iteration 1370 : 0.00015774962957948446
Loss at iteration 1380 : 0.00044829706894233823
Loss at iteration 1390 : 0.00018508813809603453
Loss at iteration 1400 : 0.0008258019224740565
Loss at iteration 1410 : 0.00010575677151791751
Loss at iteration 1420 : 5.1175939006498083e-05
Loss at iteration 1430 : 0.00027047793264500797
Loss at iteration 1440 : 9.81877456069924e-05
Loss at iteration 1450 : 0.0005100909038446844
Loss at iteration 1460 : 0.00023236445849761367
Loss at iteration 1470 : 0.0004634123179130256
Loss at iteration 1480 : 0.002012715209275484
Loss at iteration 1490 : 0.002447461010888219
Loss at iteration 1500 : 0.00021325322450138628
Loss at iteration 1510 : 0.0004127399006392807
Loss at iteration 1520 : 0.0002967899199575186
Loss at iteration 1530 : 0.0007450227858498693
Loss at iteration 1540 : 0.0005639273440465331
Loss at iteration 1550 : 0.0005383739480748773
Loss at iteration 1560 : 9.088771184906363e-05
Loss at iteration 1570 : 0.0007092043524608016
Loss at iteration 1580 : 0.0004670717171393335
Loss at iteration 1590 : 0.00011373609595466405
Loss at iteration 1600 : 0.001530890935100615
Loss at iteration 1610 : 0.00025764404563233256
Loss at iteration 1620 : 0.00023266163771040738
Loss at iteration 1630 : 0.001263028709217906
Loss at iteration 1640 : 0.0005865234998054802
Loss at iteration 1650 : 0.0008309746626764536
Loss at iteration 1660 : 0.002177807269617915
Loss at iteration 1670 : 0.0002631238312460482
Loss at iteration 1680 : 9.784385474631563e-05
Loss at iteration 1690 : 0.0034661556128412485
Loss at iteration 1700 : 0.0004287887713871896
Loss at iteration 1710 : 0.006153427995741367
Loss at iteration 1720 : 0.00016317599511239678
Loss at iteration 1730 : 0.002546318806707859
Loss at iteration 1740 : 0.0007629776955582201
Loss at iteration 1750 : 0.002004537731409073
The SSIM Value is: 0.9864844308288087
The PSNR Value is: 46.12486315613801
the epoch is: 93
Loss at iteration 10 : 0.0004445779195521027
Loss at iteration 20 : 0.0005642550531774759
Loss at iteration 30 : 0.001374448649585247
Loss at iteration 40 : 0.0009895284892991185
Loss at iteration 50 : 0.00022400222951546311
Loss at iteration 60 : 0.00011987870675511658
Loss at iteration 70 : 0.0002289473923156038
Loss at iteration 80 : 0.001279961783438921
Loss at iteration 90 : 8.377993799513206e-05
Loss at iteration 100 : 0.00045972116640768945
Loss at iteration 110 : 0.00040229540900327265
Loss at iteration 120 : 0.000137422772240825
Loss at iteration 130 : 0.0010649506002664566
Loss at iteration 140 : 0.00012551629333756864
Loss at iteration 150 : 0.000509356614202261
Loss at iteration 160 : 0.0017008851282298565
Loss at iteration 170 : 0.00020827136177103966
Loss at iteration 180 : 0.00035430974094197154
Loss at iteration 190 : 4.19844982388895e-05
Loss at iteration 200 : 0.000885925954207778
Loss at iteration 210 : 0.00028475470026023686
Loss at iteration 220 : 0.00077741191489622
Loss at iteration 230 : 0.0002235816791653633
Loss at iteration 240 : 0.0016371700912714005
Loss at iteration 250 : 0.0005038281669840217
Loss at iteration 260 : 0.0003198760678060353
Loss at iteration 270 : 9.654124005464837e-05
Loss at iteration 280 : 3.498445948935114e-05
Loss at iteration 290 : 0.00047747697681188583
Loss at iteration 300 : 0.004186937119811773
Loss at iteration 310 : 0.0004336788842920214
Loss at iteration 320 : 0.0018277389463037252
Loss at iteration 330 : 0.0017038345104083419
Loss at iteration 340 : 0.0004736957198474556
Loss at iteration 350 : 0.002099362201988697
Loss at iteration 360 : 0.0008645020425319672
Loss at iteration 370 : 0.0019471601117402315
Loss at iteration 380 : 4.516492481343448e-05
Loss at iteration 390 : 0.00024170923279598355
Loss at iteration 400 : 0.0012596286833286285
Loss at iteration 410 : 0.0005218347650952637
Loss at iteration 420 : 0.00013383761688601226
Loss at iteration 430 : 7.058947085170075e-05
Loss at iteration 440 : 0.004325072281062603
Loss at iteration 450 : 0.0021305931732058525
Loss at iteration 460 : 0.000493584549985826
Loss at iteration 470 : 0.00016622300609014928
Loss at iteration 480 : 0.0010411243420094252
Loss at iteration 490 : 7.356926653301343e-05
Loss at iteration 500 : 0.0034763002768158913
Loss at iteration 510 : 0.00042614672565832734
Loss at iteration 520 : 0.004760877229273319
Loss at iteration 530 : 0.0020511841867119074
Loss at iteration 540 : 0.0004662105056922883
Loss at iteration 550 : 0.004358828533440828
Loss at iteration 560 : 0.00042903615394607186
Loss at iteration 570 : 0.0015997830778360367
Loss at iteration 580 : 0.0008140479912981391
Loss at iteration 590 : 0.0013475583400577307
Loss at iteration 600 : 0.0002327917900402099
Loss at iteration 610 : 5.891893306397833e-05
Loss at iteration 620 : 0.00043686863500624895
Loss at iteration 630 : 0.0005063810967840254
Loss at iteration 640 : 0.00028729456244036555
Loss at iteration 650 : 0.004858258180320263
Loss at iteration 660 : 0.002418180461972952
Loss at iteration 670 : 0.00021588648087345064
Loss at iteration 680 : 0.00014150179049465805
Loss at iteration 690 : 0.006842246279120445
Loss at iteration 700 : 6.356013909680769e-05
Loss at iteration 710 : 0.0014827980194240808
Loss at iteration 720 : 0.00018241157522425056
Loss at iteration 730 : 0.0004854887956753373
Loss at iteration 740 : 0.00015667063416913152
Loss at iteration 750 : 0.0002511043567210436
Loss at iteration 760 : 0.0026433251332491636
Loss at iteration 770 : 0.0005880012176930904
Loss at iteration 780 : 0.00026310363318771124
Loss at iteration 790 : 0.002961193909868598
Loss at iteration 800 : 0.0006938517326489091
Loss at iteration 810 : 0.0005962284049019217
Loss at iteration 820 : 0.00047687211190350354
Loss at iteration 830 : 0.0001927997509483248
Loss at iteration 840 : 0.002575722523033619
Loss at iteration 850 : 0.00024126435164362192
Loss at iteration 860 : 0.0004885643720626831
Loss at iteration 870 : 0.0013905753148719668
Loss at iteration 880 : 0.00027072164812125266
Loss at iteration 890 : 0.0032391436398029327
Loss at iteration 900 : 0.00032653985545039177
Loss at iteration 910 : 0.00011240191815886647
Loss at iteration 920 : 0.0042994157411158085
Loss at iteration 930 : 0.003202749416232109
Loss at iteration 940 : 0.0003032259119208902
Loss at iteration 950 : 0.0025754300877451897
Loss at iteration 960 : 0.0020666513592004776
Loss at iteration 970 : 0.00029023311799392104
Loss at iteration 980 : 0.0008777446346357465
Loss at iteration 990 : 0.004470780026167631
Loss at iteration 1000 : 0.0002037256781477481
Loss at iteration 1010 : 0.0005239665042608976
Loss at iteration 1020 : 0.0014078413369134068
Loss at iteration 1030 : 0.0018105503404513001
Loss at iteration 1040 : 0.00035044789547100663
Loss at iteration 1050 : 0.0004972647875547409
Loss at iteration 1060 : 9.049277286976576e-05
Loss at iteration 1070 : 0.000388774904422462
Loss at iteration 1080 : 0.00021746521815657616
Loss at iteration 1090 : 0.002815740881487727
Loss at iteration 1100 : 0.0001285689213545993
Loss at iteration 1110 : 0.0003636053006630391
Loss at iteration 1120 : 0.0005651373649016023
Loss at iteration 1130 : 0.00014258825103752315
Loss at iteration 1140 : 0.0019039260223507881
Loss at iteration 1150 : 0.0013170498423278332
Loss at iteration 1160 : 8.252218685811386e-05
Loss at iteration 1170 : 0.0037180387880653143
Loss at iteration 1180 : 0.00017794471932575107
Loss at iteration 1190 : 0.00021875211677979678
Loss at iteration 1200 : 0.00022449487005360425
Loss at iteration 1210 : 9.500284068053588e-05
Loss at iteration 1220 : 0.0006531873950734735
Loss at iteration 1230 : 0.0010961429215967655
Loss at iteration 1240 : 0.00016697667888365686
Loss at iteration 1250 : 0.0006314730271697044
Loss at iteration 1260 : 0.0020488365553319454
Loss at iteration 1270 : 0.00040743459248915315
Loss at iteration 1280 : 0.0017848147545009851
Loss at iteration 1290 : 0.0005916448426432908
Loss at iteration 1300 : 0.00015068496577441692
Loss at iteration 1310 : 0.0001422673958586529
Loss at iteration 1320 : 0.002657495439052582
Loss at iteration 1330 : 0.0010975878685712814
Loss at iteration 1340 : 0.00011830328003270552
Loss at iteration 1350 : 0.00021828958415426314
Loss at iteration 1360 : 0.000957938376814127
Loss at iteration 1370 : 0.0003093974373769015
Loss at iteration 1380 : 0.004023386165499687
Loss at iteration 1390 : 0.0010012721177190542
Loss at iteration 1400 : 0.0002602747699711472
Loss at iteration 1410 : 4.88660043629352e-05
Loss at iteration 1420 : 0.00856105424463749
Loss at iteration 1430 : 0.0020269975066184998
Loss at iteration 1440 : 4.8157726268982515e-05
Loss at iteration 1450 : 0.002762849209830165
Loss at iteration 1460 : 0.0025082493666559458
Loss at iteration 1470 : 0.005170674994587898
Loss at iteration 1480 : 0.0004142755060456693
Loss at iteration 1490 : 0.00012987734226044267
Loss at iteration 1500 : 0.00041767233051359653
Loss at iteration 1510 : 0.0018512842943891883
Loss at iteration 1520 : 0.00013138094800524414
Loss at iteration 1530 : 0.004059332422912121
Loss at iteration 1540 : 6.274925544857979e-05
Loss at iteration 1550 : 0.0008970685303211212
Loss at iteration 1560 : 0.0003709135053213686
Loss at iteration 1570 : 0.0011763903312385082
Loss at iteration 1580 : 0.00017185973410960287
Loss at iteration 1590 : 0.0004384659114293754
Loss at iteration 1600 : 0.00012101655011065304
Loss at iteration 1610 : 0.0001261816214537248
Loss at iteration 1620 : 0.0004015119920950383
Loss at iteration 1630 : 0.0007974828477017581
Loss at iteration 1640 : 0.0004211912746541202
Loss at iteration 1650 : 0.00014117889804765582
Loss at iteration 1660 : 0.0003639694186858833
Loss at iteration 1670 : 8.860716479830444e-05
Loss at iteration 1680 : 8.304765651701018e-05
Loss at iteration 1690 : 0.00023242458701133728
Loss at iteration 1700 : 0.0009357277886010706
Loss at iteration 1710 : 0.0013321383157745004
Loss at iteration 1720 : 0.0005195374833419919
Loss at iteration 1730 : 0.00021545880008488894
Loss at iteration 1740 : 0.0007086129626259208
Loss at iteration 1750 : 0.00012327196600381285
The SSIM Value is: 0.9777229029176518
The PSNR Value is: 46.15488960459369
the epoch is: 94
Loss at iteration 10 : 6.478326395154e-05
Loss at iteration 20 : 0.00024864531587809324
Loss at iteration 30 : 0.0004689298802986741
Loss at iteration 40 : 0.00013529717398341745
Loss at iteration 50 : 3.997857857029885e-05
Loss at iteration 60 : 0.00030565133783966303
Loss at iteration 70 : 0.00010730121721280739
Loss at iteration 80 : 5.9356701967772096e-05
Loss at iteration 90 : 0.00040278222877532244
Loss at iteration 100 : 0.004939439706504345
Loss at iteration 110 : 0.0002775813336484134
Loss at iteration 120 : 0.00015195565356407315
Loss at iteration 130 : 0.005711328703910112
Loss at iteration 140 : 0.0037247021682560444
Loss at iteration 150 : 0.0024786219000816345
Loss at iteration 160 : 0.00033821447868831456
Loss at iteration 170 : 0.0001247591571882367
Loss at iteration 180 : 0.000983248115517199
Loss at iteration 190 : 0.0006368089816533029
Loss at iteration 200 : 0.0021621601190418005
Loss at iteration 210 : 0.0009446967742405832
Loss at iteration 220 : 0.0007885437225922942
Loss at iteration 230 : 0.0005227811634540558
Loss at iteration 240 : 0.0005740822525694966
Loss at iteration 250 : 0.0010138165671378374
Loss at iteration 260 : 7.471979188267142e-05
Loss at iteration 270 : 0.002334032906219363
Loss at iteration 280 : 0.0006214974564500153
Loss at iteration 290 : 0.004180982708930969
Loss at iteration 300 : 0.001755417208187282
Loss at iteration 310 : 0.0003922093892470002
Loss at iteration 320 : 0.002483716234564781
Loss at iteration 330 : 0.00021863850997760892
Loss at iteration 340 : 0.0039130328223109245
Loss at iteration 350 : 0.00010975907207466662
Loss at iteration 360 : 9.26716165849939e-05
Loss at iteration 370 : 0.00029634518432430923
Loss at iteration 380 : 0.00023830393911339343
Loss at iteration 390 : 0.000574326841160655
Loss at iteration 400 : 0.00310889957472682
Loss at iteration 410 : 0.004194428212940693
Loss at iteration 420 : 0.001326687983237207
Loss at iteration 430 : 0.00037810386857017875
Loss at iteration 440 : 0.00011284345237072557
Loss at iteration 450 : 0.0004302201559767127
Loss at iteration 460 : 0.0030755894258618355
Loss at iteration 470 : 0.00019104438251815736
Loss at iteration 480 : 0.00010098768689204007
Loss at iteration 490 : 0.00044180452823638916
Loss at iteration 500 : 0.00010373878467362374
Loss at iteration 510 : 0.0007956678746268153
Loss at iteration 520 : 0.003925425466150045
Loss at iteration 530 : 0.0018665711395442486
Loss at iteration 540 : 0.00021383637795224786
Loss at iteration 550 : 0.0002522445865906775
Loss at iteration 560 : 0.00016937192413024604
Loss at iteration 570 : 0.0010976186022162437
Loss at iteration 580 : 0.0002515302039682865
Loss at iteration 590 : 0.0011095443041995168
Loss at iteration 600 : 0.005098637659102678
Loss at iteration 610 : 0.003065934171900153
Loss at iteration 620 : 0.003227285807952285
Loss at iteration 630 : 0.0007017601747065783
Loss at iteration 640 : 6.667843263130635e-05
Loss at iteration 650 : 0.000854219077154994
Loss at iteration 660 : 0.00012885757314506918
Loss at iteration 670 : 0.00026191165670752525
Loss at iteration 680 : 0.00033550141961313784
Loss at iteration 690 : 0.0008887920994311571
Loss at iteration 700 : 0.0018736810889095068
Loss at iteration 710 : 0.0005332081927917898
Loss at iteration 720 : 0.00010180307435803115
Loss at iteration 730 : 0.00010321805893909186
Loss at iteration 740 : 9.915317059494555e-05
Loss at iteration 750 : 0.0018656159518286586
Loss at iteration 760 : 0.00014598839334212244
Loss at iteration 770 : 0.00024611884145997465
Loss at iteration 780 : 0.00021971929527353495
Loss at iteration 790 : 0.00012148648966103792
Loss at iteration 800 : 9.12683317437768e-05
Loss at iteration 810 : 0.0008295378647744656
Loss at iteration 820 : 0.0014434397453442216
Loss at iteration 830 : 0.003051698673516512
Loss at iteration 840 : 0.0002965872408822179
Loss at iteration 850 : 0.0009863704908639193
Loss at iteration 860 : 0.0002741917851381004
Loss at iteration 870 : 0.00015508448996115476
Loss at iteration 880 : 0.0005402077222242951
Loss at iteration 890 : 0.00030448578763753176
Loss at iteration 900 : 0.0003447411581873894
Loss at iteration 910 : 0.0009739035158418119
Loss at iteration 920 : 0.0001442302600480616
Loss at iteration 930 : 8.668601367389783e-05
Loss at iteration 940 : 0.00021686029504053295
Loss at iteration 950 : 0.0036763616371899843
Loss at iteration 960 : 7.791524694766849e-05
Loss at iteration 970 : 0.003334029810503125
Loss at iteration 980 : 0.00032863151864148676
Loss at iteration 990 : 0.00032516123610548675
Loss at iteration 1000 : 0.005477575585246086
Loss at iteration 1010 : 0.0012645425740629435
Loss at iteration 1020 : 0.00040347175672650337
Loss at iteration 1030 : 0.0015873173251748085
Loss at iteration 1040 : 0.0024421161506325006
Loss at iteration 1050 : 0.00012155592412455007
Loss at iteration 1060 : 0.0005437626386992633
Loss at iteration 1070 : 8.019812230486423e-05
Loss at iteration 1080 : 0.0016380917513743043
Loss at iteration 1090 : 6.504871998913586e-05
Loss at iteration 1100 : 7.719022687524557e-05
Loss at iteration 1110 : 0.0009320987737737596
Loss at iteration 1120 : 0.0021970062516629696
Loss at iteration 1130 : 0.000204241689061746
Loss at iteration 1140 : 0.0006751891341991723
Loss at iteration 1150 : 0.0003969015961047262
Loss at iteration 1160 : 0.0008591489167883992
Loss at iteration 1170 : 0.0006525043863803148
Loss at iteration 1180 : 0.0008892370387911797
Loss at iteration 1190 : 0.0007665347075089812
Loss at iteration 1200 : 0.00018688126874621958
Loss at iteration 1210 : 9.025481267599389e-05
Loss at iteration 1220 : 0.0002290299307787791
Loss at iteration 1230 : 0.00018926200573332608
Loss at iteration 1240 : 0.0008804653771221638
Loss at iteration 1250 : 0.000992663437500596
Loss at iteration 1260 : 0.0013689817860722542
Loss at iteration 1270 : 0.004137370269745588
Loss at iteration 1280 : 0.00041701016016304493
Loss at iteration 1290 : 0.002139523858204484
Loss at iteration 1300 : 0.00062897230964154
Loss at iteration 1310 : 0.0006527388468384743
Loss at iteration 1320 : 0.0009219369385391474
Loss at iteration 1330 : 0.0022117099724709988
Loss at iteration 1340 : 5.7919620303437114e-05
Loss at iteration 1350 : 0.00298547325655818
Loss at iteration 1360 : 0.01012042723596096
Loss at iteration 1370 : 0.00048553282977081835
Loss at iteration 1380 : 0.001972534693777561
Loss at iteration 1390 : 0.0010861430782824755
Loss at iteration 1400 : 8.892841287888587e-05
Loss at iteration 1410 : 0.0022002242039889097
Loss at iteration 1420 : 0.00013642929843626916
Loss at iteration 1430 : 9.678675996838138e-05
Loss at iteration 1440 : 0.0043291738256812096
Loss at iteration 1450 : 0.00011388998245820403
Loss at iteration 1460 : 0.0025391997769474983
Loss at iteration 1470 : 0.00022285008162725717
Loss at iteration 1480 : 0.00018679903587326407
Loss at iteration 1490 : 0.0001113547186832875
Loss at iteration 1500 : 0.00022463523782789707
Loss at iteration 1510 : 0.0001255699316971004
Loss at iteration 1520 : 0.00018943616305477917
Loss at iteration 1530 : 5.9419136960059404e-05
Loss at iteration 1540 : 9.058714204002172e-05
Loss at iteration 1550 : 0.004137023352086544
Loss at iteration 1560 : 0.0005213957047089934
Loss at iteration 1570 : 0.0016195569187402725
Loss at iteration 1580 : 0.004116798751056194
Loss at iteration 1590 : 0.00016477677854709327
Loss at iteration 1600 : 0.00021827332966495305
Loss at iteration 1610 : 7.365393685176969e-05
Loss at iteration 1620 : 0.0005945260636508465
Loss at iteration 1630 : 0.00018511025700718164
Loss at iteration 1640 : 0.004247857723385096
Loss at iteration 1650 : 0.0019405150087550282
Loss at iteration 1660 : 0.00016011143452487886
Loss at iteration 1670 : 7.039251067908481e-05
Loss at iteration 1680 : 0.001427378854714334
Loss at iteration 1690 : 0.000232574442634359
Loss at iteration 1700 : 0.00019043829524889588
Loss at iteration 1710 : 0.00029362726490944624
Loss at iteration 1720 : 0.0002477939997334033
Loss at iteration 1730 : 0.00046741883852519095
Loss at iteration 1740 : 0.0001381007459713146
Loss at iteration 1750 : 5.38760723429732e-05
The SSIM Value is: 0.9800931680044939
The PSNR Value is: 46.48601575044808
the epoch is: 95
Loss at iteration 10 : 0.00020458111248444766
Loss at iteration 20 : 0.0002544570597819984
Loss at iteration 30 : 0.0010030110133811831
Loss at iteration 40 : 0.0017783741932362318
Loss at iteration 50 : 0.0026870041619986296
Loss at iteration 60 : 0.0005708365351893008
Loss at iteration 70 : 9.394792141392827e-05
Loss at iteration 80 : 0.007347078528255224
Loss at iteration 90 : 0.0005360093782655895
Loss at iteration 100 : 0.0008198523428291082
Loss at iteration 110 : 0.001514400471933186
Loss at iteration 120 : 0.0034704061690717936
Loss at iteration 130 : 0.00017874676268547773
Loss at iteration 140 : 0.00042437727097421885
Loss at iteration 150 : 0.0019390125526115298
Loss at iteration 160 : 0.0004838079621549696
Loss at iteration 170 : 0.00034883758053183556
Loss at iteration 180 : 8.975817036116496e-05
Loss at iteration 190 : 0.00024028174811974168
Loss at iteration 200 : 0.0013804136542603374
Loss at iteration 210 : 0.005366667173802853
Loss at iteration 220 : 0.00241590803489089
Loss at iteration 230 : 0.00010640085383784026
Loss at iteration 240 : 0.0001626125886105001
Loss at iteration 250 : 0.0018102843314409256
Loss at iteration 260 : 0.0032955645583570004
Loss at iteration 270 : 0.0008395547047257423
Loss at iteration 280 : 0.0025820177979767323
Loss at iteration 290 : 0.00014063545677345246
Loss at iteration 300 : 0.0017694751732051373
Loss at iteration 310 : 5.0459158956073225e-05
Loss at iteration 320 : 0.002377844648435712
Loss at iteration 330 : 0.001410529250279069
Loss at iteration 340 : 8.515626541338861e-05
Loss at iteration 350 : 0.0034777012187987566
Loss at iteration 360 : 0.0026509887538850307
Loss at iteration 370 : 0.006991923786699772
Loss at iteration 380 : 0.00011565344902919605
Loss at iteration 390 : 0.0010191083420068026
Loss at iteration 400 : 0.0001512827875558287
Loss at iteration 410 : 0.00010633068450260907
Loss at iteration 420 : 0.00014557389658875763
Loss at iteration 430 : 0.00036568587529473007
Loss at iteration 440 : 0.00011665782949421555
Loss at iteration 450 : 0.0004051669093314558
Loss at iteration 460 : 0.000742694886866957
Loss at iteration 470 : 0.0002319583436474204
Loss at iteration 480 : 0.0018885626923292875
Loss at iteration 490 : 0.0048143272288143635
Loss at iteration 500 : 0.00020266242790967226
Loss at iteration 510 : 0.006763865239918232
Loss at iteration 520 : 0.004633609671145678
Loss at iteration 530 : 0.0023272105026990175
Loss at iteration 540 : 0.00032423509401269257
Loss at iteration 550 : 0.0018011494539678097
Loss at iteration 560 : 0.0022405479103326797
Loss at iteration 570 : 5.616930138785392e-05
Loss at iteration 580 : 0.0004564729752019048
Loss at iteration 590 : 0.00018073184764944017
Loss at iteration 600 : 0.00046648457646369934
Loss at iteration 610 : 0.0022693569771945477
Loss at iteration 620 : 0.00017438849317841232
Loss at iteration 630 : 0.004644331056624651
Loss at iteration 640 : 0.00013476901222020388
Loss at iteration 650 : 0.0004153473419137299
Loss at iteration 660 : 0.0032625014428049326
Loss at iteration 670 : 0.0006010466604493558
Loss at iteration 680 : 0.0003251348971389234
Loss at iteration 690 : 0.0006178385810926557
Loss at iteration 700 : 0.0008127221371978521
Loss at iteration 710 : 0.00011098271352238953
Loss at iteration 720 : 0.0003294752386864275
Loss at iteration 730 : 0.00017050205497071147
Loss at iteration 740 : 0.0008091108174994588
Loss at iteration 750 : 0.0004966505221091211
Loss at iteration 760 : 0.0001851559936767444
Loss at iteration 770 : 0.0009193824953399599
Loss at iteration 780 : 5.6210414186352864e-05
Loss at iteration 790 : 6.109896639827639e-05
Loss at iteration 800 : 0.00298624811694026
Loss at iteration 810 : 0.0024192500859498978
Loss at iteration 820 : 0.0011317331809550524
Loss at iteration 830 : 0.00199545593932271
Loss at iteration 840 : 0.0007074590539559722
Loss at iteration 850 : 0.00014886684948578477
Loss at iteration 860 : 6.728636799380183e-05
Loss at iteration 870 : 0.00019355387485120445
Loss at iteration 880 : 8.61772132338956e-05
Loss at iteration 890 : 0.000893455813638866
Loss at iteration 900 : 0.0012161232298240066
Loss at iteration 910 : 0.003624157514423132
Loss at iteration 920 : 0.0005016268696635962
Loss at iteration 930 : 0.001260944758541882
Loss at iteration 940 : 0.00020642788149416447
Loss at iteration 950 : 0.0004054389428347349
Loss at iteration 960 : 0.0006465546903200448
Loss at iteration 970 : 0.0005471885087899864
Loss at iteration 980 : 0.00019783477182500064
Loss at iteration 990 : 0.0002932902134489268
Loss at iteration 1000 : 0.0008470709435641766
Loss at iteration 1010 : 0.00033516454277560115
Loss at iteration 1020 : 0.001068976242095232
Loss at iteration 1030 : 0.0003182762593496591
Loss at iteration 1040 : 0.001432062592357397
Loss at iteration 1050 : 0.0001081921873264946
Loss at iteration 1060 : 7.25037170923315e-05
Loss at iteration 1070 : 0.00017036327335517853
Loss at iteration 1080 : 0.0014908029697835445
Loss at iteration 1090 : 0.0003458123537711799
Loss at iteration 1100 : 0.0003684861003421247
Loss at iteration 1110 : 0.00012407367466948926
Loss at iteration 1120 : 0.0015457425033673644
Loss at iteration 1130 : 0.0006433262024074793
Loss at iteration 1140 : 0.001065185060724616
Loss at iteration 1150 : 0.0002228442463092506
Loss at iteration 1160 : 0.00011241508764214814
Loss at iteration 1170 : 0.00012571911793202162
Loss at iteration 1180 : 8.378198253922164e-05
Loss at iteration 1190 : 0.00019976921612396836
Loss at iteration 1200 : 0.004075916018337011
Loss at iteration 1210 : 0.0007824101485311985
Loss at iteration 1220 : 0.00022936869936529547
Loss at iteration 1230 : 4.783079930348322e-05
Loss at iteration 1240 : 0.0007322572637349367
Loss at iteration 1250 : 0.00015824291040189564
Loss at iteration 1260 : 0.00037394792889244854
Loss at iteration 1270 : 0.0013969320571050048
Loss at iteration 1280 : 0.00018710270524024963
Loss at iteration 1290 : 0.00012792741472367197
Loss at iteration 1300 : 0.0015790549805387855
Loss at iteration 1310 : 0.00028181931702420115
Loss at iteration 1320 : 0.00036267805262468755
Loss at iteration 1330 : 0.0009478434803895652
Loss at iteration 1340 : 0.0005288432585075498
Loss at iteration 1350 : 0.0010073500452563167
Loss at iteration 1360 : 0.00026519206585362554
Loss at iteration 1370 : 0.00011704661301337183
Loss at iteration 1380 : 0.0004598749219439924
Loss at iteration 1390 : 0.004359433427453041
Loss at iteration 1400 : 0.001450908719561994
Loss at iteration 1410 : 0.00017186012701131403
Loss at iteration 1420 : 0.00024090049555525184
Loss at iteration 1430 : 0.005216571968048811
Loss at iteration 1440 : 6.391100760083646e-05
Loss at iteration 1450 : 0.00016425705689471215
Loss at iteration 1460 : 0.00033424427965655923
Loss at iteration 1470 : 0.0006400184938684106
Loss at iteration 1480 : 0.0007547150598838925
Loss at iteration 1490 : 0.00014105832087807357
Loss at iteration 1500 : 0.0004463666118681431
Loss at iteration 1510 : 0.002989211119711399
Loss at iteration 1520 : 0.002446527360007167
Loss at iteration 1530 : 0.0007754750549793243
Loss at iteration 1540 : 0.00032415182795375586
Loss at iteration 1550 : 0.00022314574744086713
Loss at iteration 1560 : 0.0028735343366861343
Loss at iteration 1570 : 0.0007078048074617982
Loss at iteration 1580 : 0.0005223228945396841
Loss at iteration 1590 : 0.0003009071806445718
Loss at iteration 1600 : 0.0013673993526026607
Loss at iteration 1610 : 0.0049614147283136845
Loss at iteration 1620 : 0.003733955090865493
Loss at iteration 1630 : 0.0004370199458207935
Loss at iteration 1640 : 0.00015139050083234906
Loss at iteration 1650 : 0.00026015189359895885
Loss at iteration 1660 : 0.0032999797258526087
Loss at iteration 1670 : 0.00044203639845363796
Loss at iteration 1680 : 0.005130566190928221
Loss at iteration 1690 : 0.0014784048544242978
Loss at iteration 1700 : 0.00020589886116795242
Loss at iteration 1710 : 6.651452713413164e-05
Loss at iteration 1720 : 0.0001047363257384859
Loss at iteration 1730 : 6.832359940744936e-05
Loss at iteration 1740 : 0.0003236068587284535
Loss at iteration 1750 : 0.000955355993937701
The SSIM Value is: 0.9792969716540517
The PSNR Value is: 46.50893884398339
the epoch is: 96
Loss at iteration 10 : 0.0012158724712207913
Loss at iteration 20 : 0.0009591042180545628
Loss at iteration 30 : 0.002151988912373781
Loss at iteration 40 : 0.00026103315758518875
Loss at iteration 50 : 9.375953231938183e-05
Loss at iteration 60 : 0.00017991726053878665
Loss at iteration 70 : 0.00010928419942501932
Loss at iteration 80 : 0.0002212292602052912
Loss at iteration 90 : 0.0011139237321913242
Loss at iteration 100 : 0.00601179338991642
Loss at iteration 110 : 0.00011906324652954936
Loss at iteration 120 : 6.702039536321536e-05
Loss at iteration 130 : 0.0005383343668654561
Loss at iteration 140 : 0.0007733582169748843
Loss at iteration 150 : 0.0004841827612835914
Loss at iteration 160 : 0.00026486313436180353
Loss at iteration 170 : 0.0002656484139151871
Loss at iteration 180 : 0.004461060278117657
Loss at iteration 190 : 0.0014978426042944193
Loss at iteration 200 : 0.004137285053730011
Loss at iteration 210 : 0.00014560304407496005
Loss at iteration 220 : 0.0006411941139958799
Loss at iteration 230 : 0.00013984518591314554
Loss at iteration 240 : 0.001771091716364026
Loss at iteration 250 : 0.0013245161389932036
Loss at iteration 260 : 0.0017971694469451904
Loss at iteration 270 : 0.0012493330286815763
Loss at iteration 280 : 0.00015330231690313667
Loss at iteration 290 : 0.00034357377444393933
Loss at iteration 300 : 0.000324390857713297
Loss at iteration 310 : 0.0004633315547835082
Loss at iteration 320 : 0.0022386801429092884
Loss at iteration 330 : 0.00021673203445971012
Loss at iteration 340 : 0.008332077413797379
Loss at iteration 350 : 7.115468906704336e-05
Loss at iteration 360 : 0.0002619257429614663
Loss at iteration 370 : 0.00012135258293710649
Loss at iteration 380 : 0.002389146015048027
Loss at iteration 390 : 0.0001626590674277395
Loss at iteration 400 : 0.00016059228801168501
Loss at iteration 410 : 0.0016101355431601405
Loss at iteration 420 : 0.0003156679158564657
Loss at iteration 430 : 4.766462734551169e-05
Loss at iteration 440 : 0.00015292264288291335
Loss at iteration 450 : 6.210307765286416e-05
Loss at iteration 460 : 0.00011557728430489078
Loss at iteration 470 : 0.005564013030380011
Loss at iteration 480 : 0.0003134235448669642
Loss at iteration 490 : 0.000474338186904788
Loss at iteration 500 : 0.00029815896414220333
Loss at iteration 510 : 0.00023675624106545
Loss at iteration 520 : 0.00020804410451091826
Loss at iteration 530 : 0.0001672822836553678
Loss at iteration 540 : 0.00025105252279900014
Loss at iteration 550 : 6.512190884677693e-05
Loss at iteration 560 : 0.0003954405547119677
Loss at iteration 570 : 0.0002474275534041226
Loss at iteration 580 : 0.003194208489730954
Loss at iteration 590 : 0.00032029562862589955
Loss at iteration 600 : 0.0004336040292400867
Loss at iteration 610 : 0.00027331977616995573
Loss at iteration 620 : 0.0012862351723015308
Loss at iteration 630 : 0.0035979067906737328
Loss at iteration 640 : 0.00021291688608471304
Loss at iteration 650 : 0.0004140319360885769
Loss at iteration 660 : 0.00017383364320266992
Loss at iteration 670 : 0.00012274523032829165
Loss at iteration 680 : 0.0006267734570428729
Loss at iteration 690 : 0.00013351098459679633
Loss at iteration 700 : 0.00014699817984364927
Loss at iteration 710 : 0.004948537331074476
Loss at iteration 720 : 8.331982098752633e-05
Loss at iteration 730 : 0.0003353598585817963
Loss at iteration 740 : 0.00011394061584724113
Loss at iteration 750 : 4.591721881297417e-05
Loss at iteration 760 : 0.00010147619468625635
Loss at iteration 770 : 0.002574420999735594
Loss at iteration 780 : 0.0003050004015676677
Loss at iteration 790 : 0.0005248798406682909
Loss at iteration 800 : 0.0005848001455888152
Loss at iteration 810 : 0.0015200290363281965
Loss at iteration 820 : 0.00043821544386446476
Loss at iteration 830 : 0.00012189942935947329
Loss at iteration 840 : 0.00014266041398514062
Loss at iteration 850 : 0.0007035071612335742
Loss at iteration 860 : 0.00048814871115610003
Loss at iteration 870 : 6.233359454199672e-05
Loss at iteration 880 : 0.0003974736901000142
Loss at iteration 890 : 0.00031664539710618556
Loss at iteration 900 : 0.0006857266998849809
Loss at iteration 910 : 0.002406766638159752
Loss at iteration 920 : 0.002398001728579402
Loss at iteration 930 : 0.0002807812998071313
Loss at iteration 940 : 0.0014897927176207304
Loss at iteration 950 : 0.0001473125594202429
Loss at iteration 960 : 0.00023440251243300736
Loss at iteration 970 : 0.00013658174430020154
Loss at iteration 980 : 0.00013501528883352876
Loss at iteration 990 : 0.0008447531145066023
Loss at iteration 1000 : 0.0004314129473641515
Loss at iteration 1010 : 0.0005878498195670545
Loss at iteration 1020 : 0.00018626289966050535
Loss at iteration 1030 : 0.0004417157615534961
Loss at iteration 1040 : 0.0014385225949808955
Loss at iteration 1050 : 7.3217750468757e-05
Loss at iteration 1060 : 0.00042675508302636445
Loss at iteration 1070 : 0.00016722943109925836
Loss at iteration 1080 : 0.0021273531019687653
Loss at iteration 1090 : 0.0008352487930096686
Loss at iteration 1100 : 0.00019470557163003832
Loss at iteration 1110 : 0.00010418269084766507
Loss at iteration 1120 : 0.0016392432153224945
Loss at iteration 1130 : 0.00010603568807709962
Loss at iteration 1140 : 0.00016004865756258368
Loss at iteration 1150 : 0.00038119335658848286
Loss at iteration 1160 : 7.733691018074751e-05
Loss at iteration 1170 : 0.0017729493556544185
Loss at iteration 1180 : 0.0002730356645770371
Loss at iteration 1190 : 0.00016763125313445926
Loss at iteration 1200 : 0.00016814620175864547
Loss at iteration 1210 : 0.0033227980602532625
Loss at iteration 1220 : 0.003334755077958107
Loss at iteration 1230 : 0.0024357931688427925
Loss at iteration 1240 : 0.003139310050755739
Loss at iteration 1250 : 0.000273296725936234
Loss at iteration 1260 : 0.00020981726993341
Loss at iteration 1270 : 0.00015126875950954854
Loss at iteration 1280 : 0.0005042299744673073
Loss at iteration 1290 : 0.004330239724367857
Loss at iteration 1300 : 0.0017309613758698106
Loss at iteration 1310 : 0.0014411131851375103
Loss at iteration 1320 : 0.0004974757903255522
Loss at iteration 1330 : 0.0004664967709686607
Loss at iteration 1340 : 0.0009568231762386858
Loss at iteration 1350 : 7.89163532317616e-05
Loss at iteration 1360 : 0.001317826216109097
Loss at iteration 1370 : 0.0026659194845706224
Loss at iteration 1380 : 0.0012154239229857922
Loss at iteration 1390 : 0.0013499459018930793
Loss at iteration 1400 : 0.00018610191182233393
Loss at iteration 1410 : 0.0011566540924832225
Loss at iteration 1420 : 0.0007129391888156533
Loss at iteration 1430 : 0.00740283215418458
Loss at iteration 1440 : 0.001052633859217167
Loss at iteration 1450 : 0.00020444125402718782
Loss at iteration 1460 : 0.004071109462529421
Loss at iteration 1470 : 0.0032923072576522827
Loss at iteration 1480 : 0.0001991262979572639
Loss at iteration 1490 : 2.1847847165190615e-05
Loss at iteration 1500 : 0.00012283226533327252
Loss at iteration 1510 : 0.003976199775934219
Loss at iteration 1520 : 0.00019559258362278342
Loss at iteration 1530 : 0.0007658026879653335
Loss at iteration 1540 : 0.00011058472591685131
Loss at iteration 1550 : 0.0018034125678241253
Loss at iteration 1560 : 0.002858021529391408
Loss at iteration 1570 : 0.0002443553239572793
Loss at iteration 1580 : 0.0015637369360774755
Loss at iteration 1590 : 0.003770330687984824
Loss at iteration 1600 : 0.0020382737275213003
Loss at iteration 1610 : 0.0003322322154417634
Loss at iteration 1620 : 0.00020859552023466676
Loss at iteration 1630 : 0.0004810318350791931
Loss at iteration 1640 : 0.00021670715068466961
Loss at iteration 1650 : 0.00011367842671461403
Loss at iteration 1660 : 0.00016361243615392596
Loss at iteration 1670 : 0.0008545696618966758
Loss at iteration 1680 : 0.002360429847612977
Loss at iteration 1690 : 0.0015925224870443344
Loss at iteration 1700 : 0.00020270838285796344
Loss at iteration 1710 : 0.0006772399647161365
Loss at iteration 1720 : 0.0002013329358305782
Loss at iteration 1730 : 0.0004469543928280473
Loss at iteration 1740 : 7.710383215453476e-05
Loss at iteration 1750 : 0.00015162237104959786
The SSIM Value is: 0.9828032364141573
The PSNR Value is: 45.658341964436
the epoch is: 97
Loss at iteration 10 : 0.0024622883647680283
Loss at iteration 20 : 0.000667200714815408
Loss at iteration 30 : 0.0001978888758458197
Loss at iteration 40 : 6.238195055630058e-05
Loss at iteration 50 : 0.001948932302184403
Loss at iteration 60 : 0.0007481172797270119
Loss at iteration 70 : 0.00013025842781644315
Loss at iteration 80 : 0.0023534181527793407
Loss at iteration 90 : 0.003582021687179804
Loss at iteration 100 : 0.002613626653328538
Loss at iteration 110 : 0.0006892011733725667
Loss at iteration 120 : 0.0009207860566675663
Loss at iteration 130 : 0.00010629957250785083
Loss at iteration 140 : 0.0002932201896328479
Loss at iteration 150 : 0.00047533103497698903
Loss at iteration 160 : 7.214643119368702e-05
Loss at iteration 170 : 0.0029454126488417387
Loss at iteration 180 : 0.00013681576820090413
Loss at iteration 190 : 0.000914513599127531
Loss at iteration 200 : 0.003297373652458191
Loss at iteration 210 : 0.0034977924078702927
Loss at iteration 220 : 0.0002003131085075438
Loss at iteration 230 : 0.00018132042896468192
Loss at iteration 240 : 7.530601578764617e-05
Loss at iteration 250 : 0.00031192362075671554
Loss at iteration 260 : 0.00022801240265835077
Loss at iteration 270 : 0.00020079026580788195
Loss at iteration 280 : 0.0003392403305042535
Loss at iteration 290 : 0.0007142559625208378
Loss at iteration 300 : 0.0009956995490938425
Loss at iteration 310 : 9.42014085012488e-05
Loss at iteration 320 : 0.005444287322461605
Loss at iteration 330 : 9.350762411486357e-05
Loss at iteration 340 : 0.004008128307759762
Loss at iteration 350 : 0.0003086622746195644
Loss at iteration 360 : 0.00015050798538140953
Loss at iteration 370 : 0.003982176072895527
Loss at iteration 380 : 0.00010324634058633819
Loss at iteration 390 : 0.00011565746535779908
Loss at iteration 400 : 0.00629781000316143
Loss at iteration 410 : 0.00016077232430689037
Loss at iteration 420 : 0.001988687552511692
Loss at iteration 430 : 0.00010604134877212346
Loss at iteration 440 : 0.0006926664500497282
Loss at iteration 450 : 0.00016179835074581206
Loss at iteration 460 : 0.003200158942490816
Loss at iteration 470 : 0.0033639147877693176
Loss at iteration 480 : 0.00159033527597785
Loss at iteration 490 : 0.00719580240547657
Loss at iteration 500 : 0.00017828210548032075
Loss at iteration 510 : 0.004558186046779156
Loss at iteration 520 : 0.0018509352812543511
Loss at iteration 530 : 0.00020889571169391274
Loss at iteration 540 : 0.0021374006755650043
Loss at iteration 550 : 0.00042312819277867675
Loss at iteration 560 : 0.0011956440284848213
Loss at iteration 570 : 0.0006784223369322717
Loss at iteration 580 : 0.0002973902446683496
Loss at iteration 590 : 0.0001944370160344988
Loss at iteration 600 : 0.0011406033299863338
Loss at iteration 610 : 0.0010126031702384353
Loss at iteration 620 : 8.581202564528212e-05
Loss at iteration 630 : 0.006445134989917278
Loss at iteration 640 : 0.0017236873973160982
Loss at iteration 650 : 0.0003478184517007321
Loss at iteration 660 : 0.0004377355217002332
Loss at iteration 670 : 9.8882541351486e-05
Loss at iteration 680 : 9.953092376235873e-05
Loss at iteration 690 : 0.0027264878153800964
Loss at iteration 700 : 0.0006214316235855222
Loss at iteration 710 : 0.0053929719142615795
Loss at iteration 720 : 0.00024315950577147305
Loss at iteration 730 : 0.0003796925884671509
Loss at iteration 740 : 9.813118231249973e-05
Loss at iteration 750 : 0.0005486924201250076
Loss at iteration 760 : 0.0006740447133779526
Loss at iteration 770 : 8.495127985952422e-05
Loss at iteration 780 : 0.00035341817419975996
Loss at iteration 790 : 0.0002118278935085982
Loss at iteration 800 : 0.0040988922119140625
Loss at iteration 810 : 7.1499336627312e-05
Loss at iteration 820 : 0.0001016807509586215
Loss at iteration 830 : 0.0010028734104707837
Loss at iteration 840 : 0.00016074060113169253
Loss at iteration 850 : 0.003918767906725407
Loss at iteration 860 : 4.846128649660386e-05
Loss at iteration 870 : 0.0004783516633324325
Loss at iteration 880 : 0.0004681654099840671
Loss at iteration 890 : 0.0004566674761008471
Loss at iteration 900 : 0.0023369656410068274
Loss at iteration 910 : 0.00021146642393432558
Loss at iteration 920 : 0.0004952219314873219
Loss at iteration 930 : 0.0033120824955403805
Loss at iteration 940 : 0.0002522176073398441
Loss at iteration 950 : 0.0007502700318582356
Loss at iteration 960 : 0.004183000884950161
Loss at iteration 970 : 0.0007378773880191147
Loss at iteration 980 : 0.004916121251881123
Loss at iteration 990 : 0.0007233143551275134
Loss at iteration 1000 : 0.00347623648121953
Loss at iteration 1010 : 0.00012455512478481978
Loss at iteration 1020 : 7.265844033099711e-05
Loss at iteration 1030 : 0.0011427534045651555
Loss at iteration 1040 : 0.0005546287866309285
Loss at iteration 1050 : 0.00016123804380185902
Loss at iteration 1060 : 8.723363862372935e-05
Loss at iteration 1070 : 9.997405140893534e-05
Loss at iteration 1080 : 3.48330577253364e-05
Loss at iteration 1090 : 0.0027678997721523046
Loss at iteration 1100 : 7.674233347643167e-05
Loss at iteration 1110 : 0.00011742657807189971
Loss at iteration 1120 : 0.0001572802575537935
Loss at iteration 1130 : 8.645810157759115e-05
Loss at iteration 1140 : 0.0022961655631661415
Loss at iteration 1150 : 0.0003336658701300621
Loss at iteration 1160 : 0.00022999581415206194
Loss at iteration 1170 : 0.001994606340304017
Loss at iteration 1180 : 0.0002443788980599493
Loss at iteration 1190 : 0.0002304632362211123
Loss at iteration 1200 : 0.00021163831115700305
Loss at iteration 1210 : 0.0008548956830054522
Loss at iteration 1220 : 0.0022668458987027407
Loss at iteration 1230 : 0.0002947432512883097
Loss at iteration 1240 : 0.000744492863304913
Loss at iteration 1250 : 0.0020751270931214094
Loss at iteration 1260 : 0.00034816336119547486
Loss at iteration 1270 : 0.0018519777804613113
Loss at iteration 1280 : 0.000476688175695017
Loss at iteration 1290 : 0.0001833227725001052
Loss at iteration 1300 : 0.0002802826347760856
Loss at iteration 1310 : 0.00018531520618125796
Loss at iteration 1320 : 0.0035357940942049026
Loss at iteration 1330 : 0.0037006682250648737
Loss at iteration 1340 : 0.0014037926448509097
Loss at iteration 1350 : 0.0009570558904670179
Loss at iteration 1360 : 0.001184895052574575
Loss at iteration 1370 : 0.00014012401516083628
Loss at iteration 1380 : 0.0002760578063316643
Loss at iteration 1390 : 0.00018304403056390584
Loss at iteration 1400 : 0.00010418237070553005
Loss at iteration 1410 : 0.0001453246222808957
Loss at iteration 1420 : 0.0012533930130302906
Loss at iteration 1430 : 0.002595465397462249
Loss at iteration 1440 : 0.0018665806856006384
Loss at iteration 1450 : 0.00030059958226047456
Loss at iteration 1460 : 0.0003677440108731389
Loss at iteration 1470 : 0.00010752178059192374
Loss at iteration 1480 : 0.00013181203394196928
Loss at iteration 1490 : 0.0016308373305946589
Loss at iteration 1500 : 9.180405322695151e-05
Loss at iteration 1510 : 0.0004196448135189712
Loss at iteration 1520 : 0.0014020365197211504
Loss at iteration 1530 : 8.844240801408887e-05
Loss at iteration 1540 : 0.00016466919623780996
Loss at iteration 1550 : 0.00013341823068913072
Loss at iteration 1560 : 8.954506483860314e-05
Loss at iteration 1570 : 5.7806399127002805e-05
Loss at iteration 1580 : 8.42236477183178e-05
Loss at iteration 1590 : 0.00010896181629505008
Loss at iteration 1600 : 7.593029295094311e-05
Loss at iteration 1610 : 0.004988550208508968
Loss at iteration 1620 : 0.00021257720072753727
Loss at iteration 1630 : 0.0013153948821127415
Loss at iteration 1640 : 0.0035432097502052784
Loss at iteration 1650 : 0.0006769727915525436
Loss at iteration 1660 : 0.003410233184695244
Loss at iteration 1670 : 0.00021017208928242326
Loss at iteration 1680 : 0.003998550120741129
Loss at iteration 1690 : 0.0002862218825612217
Loss at iteration 1700 : 0.0008627574425190687
Loss at iteration 1710 : 0.000548333628103137
Loss at iteration 1720 : 0.00023984076688066125
Loss at iteration 1730 : 7.020180783001706e-05
Loss at iteration 1740 : 0.0021037617698311806
Loss at iteration 1750 : 0.0015155321452766657
The SSIM Value is: 0.9817306634350496
The PSNR Value is: 46.548375810295475
the epoch is: 98
Loss at iteration 10 : 0.00018439583072904497
Loss at iteration 20 : 0.0016687619499862194
Loss at iteration 30 : 0.0017154819797724485
Loss at iteration 40 : 0.007841651327908039
Loss at iteration 50 : 0.0028946935199201107
Loss at iteration 60 : 0.0021039554849267006
Loss at iteration 70 : 9.409360791323707e-05
Loss at iteration 80 : 5.190563024370931e-05
Loss at iteration 90 : 0.0003746558213606477
Loss at iteration 100 : 3.9613147237105295e-05
Loss at iteration 110 : 7.251511851791292e-05
Loss at iteration 120 : 0.0003784801810979843
Loss at iteration 130 : 0.0003012698725797236
Loss at iteration 140 : 0.0002229478268418461
Loss at iteration 150 : 0.0001326937781414017
Loss at iteration 160 : 0.00014647543139290065
Loss at iteration 170 : 0.0001839221513364464
Loss at iteration 180 : 0.00010012138227466494
Loss at iteration 190 : 0.0003281756944488734
Loss at iteration 200 : 0.0002528989571146667
Loss at iteration 210 : 0.00015939815784804523
Loss at iteration 220 : 0.003322394099086523
Loss at iteration 230 : 8.653219265397638e-05
Loss at iteration 240 : 0.00017701653996482491
Loss at iteration 250 : 0.00021072688105050474
Loss at iteration 260 : 0.00014480527897831053
Loss at iteration 270 : 0.00013896999007556587
Loss at iteration 280 : 0.0004964490071870387
Loss at iteration 290 : 0.00015630951384082437
Loss at iteration 300 : 0.0035533064510673285
Loss at iteration 310 : 0.0015261428197845817
Loss at iteration 320 : 0.0009384442237205803
Loss at iteration 330 : 0.008397988975048065
Loss at iteration 340 : 0.0005308728432282805
Loss at iteration 350 : 0.00910063087940216
Loss at iteration 360 : 0.0006685357075184584
Loss at iteration 370 : 0.0022880430333316326
Loss at iteration 380 : 0.00011490416363812983
Loss at iteration 390 : 0.00019664214050862938
Loss at iteration 400 : 0.004069329705089331
Loss at iteration 410 : 0.0001714680838631466
Loss at iteration 420 : 0.0005572998779825866
Loss at iteration 430 : 0.00010531632869970053
Loss at iteration 440 : 0.0022698433604091406
Loss at iteration 450 : 0.0019452684791758657
Loss at iteration 460 : 5.471000258694403e-05
Loss at iteration 470 : 0.00026283282204531133
Loss at iteration 480 : 6.10955321462825e-05
Loss at iteration 490 : 0.0011003791587427258
Loss at iteration 500 : 0.00023851502919569612
Loss at iteration 510 : 0.004602933302521706
Loss at iteration 520 : 0.003940206952393055
Loss at iteration 530 : 0.0004359935119282454
Loss at iteration 540 : 0.00041920639341697097
Loss at iteration 550 : 3.166644455632195e-05
Loss at iteration 560 : 0.0009335211361758411
Loss at iteration 570 : 0.00020756346930284053
Loss at iteration 580 : 0.0008665698114782572
Loss at iteration 590 : 5.794886965304613e-05
Loss at iteration 600 : 0.0031614890322089195
Loss at iteration 610 : 0.0009328220621682703
Loss at iteration 620 : 0.005027160048484802
Loss at iteration 630 : 0.0007744562462903559
Loss at iteration 640 : 0.00017444032710045576
Loss at iteration 650 : 0.00026410166174173355
Loss at iteration 660 : 0.0015072880778461695
Loss at iteration 670 : 0.0002503869473002851
Loss at iteration 680 : 0.0003042471071239561
Loss at iteration 690 : 0.0002715829759836197
Loss at iteration 700 : 0.0024563251063227654
Loss at iteration 710 : 0.0002462497213855386
Loss at iteration 720 : 0.0008719325414858758
Loss at iteration 730 : 9.238390339305624e-05
Loss at iteration 740 : 0.0010264264419674873
Loss at iteration 750 : 0.00033249356783926487
Loss at iteration 760 : 0.001450837473385036
Loss at iteration 770 : 0.00024900605785660446
Loss at iteration 780 : 0.0013493550941348076
Loss at iteration 790 : 0.00046576844761148095
Loss at iteration 800 : 0.0002928800240624696
Loss at iteration 810 : 0.0008166345069184899
Loss at iteration 820 : 9.98593750409782e-05
Loss at iteration 830 : 8.399443322559819e-05
Loss at iteration 840 : 0.00042682202183641493
Loss at iteration 850 : 0.00033793464535847306
Loss at iteration 860 : 8.983755833469331e-05
Loss at iteration 870 : 0.00022028353123459965
Loss at iteration 880 : 0.0001435242738807574
Loss at iteration 890 : 5.112776852911338e-05
Loss at iteration 900 : 0.0002700208278838545
Loss at iteration 910 : 0.009180673398077488
Loss at iteration 920 : 0.0011552456999197602
Loss at iteration 930 : 0.0009927027858793736
Loss at iteration 940 : 0.0011753758881241083
Loss at iteration 950 : 0.000390154542401433
Loss at iteration 960 : 0.00010386442590970546
Loss at iteration 970 : 0.00025084306253120303
Loss at iteration 980 : 0.0003078789741266519
Loss at iteration 990 : 0.004023502580821514
Loss at iteration 1000 : 0.00035493200994096696
Loss at iteration 1010 : 0.00013726911856792867
Loss at iteration 1020 : 0.0005620945594273508
Loss at iteration 1030 : 0.0009520353632979095
Loss at iteration 1040 : 0.0023277022410184145
Loss at iteration 1050 : 0.00011704050120897591
Loss at iteration 1060 : 0.0032988355960696936
Loss at iteration 1070 : 0.000252043450018391
Loss at iteration 1080 : 0.00018908829952124506
Loss at iteration 1090 : 0.0006175732705742121
Loss at iteration 1100 : 4.5996643166290596e-05
Loss at iteration 1110 : 0.00022339656425174326
Loss at iteration 1120 : 0.0007207825547084212
Loss at iteration 1130 : 0.0002215556160081178
Loss at iteration 1140 : 0.003264434402808547
Loss at iteration 1150 : 0.00017409524298273027
Loss at iteration 1160 : 9.543484338792041e-05
Loss at iteration 1170 : 0.0005400832742452621
Loss at iteration 1180 : 0.0006145586958155036
Loss at iteration 1190 : 0.00020288440282456577
Loss at iteration 1200 : 0.00017833878519013524
Loss at iteration 1210 : 8.502999116899446e-05
Loss at iteration 1220 : 0.00026954192435368896
Loss at iteration 1230 : 0.0008436996140517294
Loss at iteration 1240 : 0.0005244506755843759
Loss at iteration 1250 : 0.0006224523531273007
Loss at iteration 1260 : 0.0025836871936917305
Loss at iteration 1270 : 0.0020761338528245687
Loss at iteration 1280 : 0.0026208367198705673
Loss at iteration 1290 : 0.0031766712199896574
Loss at iteration 1300 : 0.00021269528951961547
Loss at iteration 1310 : 0.002400489989668131
Loss at iteration 1320 : 6.731936446158215e-05
Loss at iteration 1330 : 0.00011814627214334905
Loss at iteration 1340 : 0.0025946081150323153
Loss at iteration 1350 : 0.00019528270058799535
Loss at iteration 1360 : 0.001069533289410174
Loss at iteration 1370 : 0.0009720212547108531
Loss at iteration 1380 : 7.174990605562925e-05
Loss at iteration 1390 : 0.00011683095362968743
Loss at iteration 1400 : 0.00015835429076105356
Loss at iteration 1410 : 4.378924495540559e-05
Loss at iteration 1420 : 0.0003497351426631212
Loss at iteration 1430 : 0.00014043317059986293
Loss at iteration 1440 : 0.0008909094613045454
Loss at iteration 1450 : 0.00014360011846292764
Loss at iteration 1460 : 0.00037189238355495036
Loss at iteration 1470 : 6.923195905983448e-05
Loss at iteration 1480 : 0.0022488608956336975
Loss at iteration 1490 : 0.0008342051296494901
Loss at iteration 1500 : 0.001341146300546825
Loss at iteration 1510 : 0.0031655607745051384
Loss at iteration 1520 : 0.000813406310044229
Loss at iteration 1530 : 0.00019459349277894944
Loss at iteration 1540 : 0.002484549768269062
Loss at iteration 1550 : 0.0002293408033438027
Loss at iteration 1560 : 0.000477760739158839
Loss at iteration 1570 : 0.0007181747350841761
Loss at iteration 1580 : 0.00019534569582901895
Loss at iteration 1590 : 0.0022480711340904236
Loss at iteration 1600 : 7.657677633687854e-05
Loss at iteration 1610 : 0.00013717293040826917
Loss at iteration 1620 : 0.0003989485267084092
Loss at iteration 1630 : 0.0012133332202211022
Loss at iteration 1640 : 0.0006858027772977948
Loss at iteration 1650 : 0.00034273770870640874
Loss at iteration 1660 : 0.0004365109489299357
Loss at iteration 1670 : 0.0031150421127676964
Loss at iteration 1680 : 0.00019556070037651807
Loss at iteration 1690 : 0.00018376587831880897
Loss at iteration 1700 : 0.000498421024531126
Loss at iteration 1710 : 0.002774673979729414
Loss at iteration 1720 : 0.0018825477454811335
Loss at iteration 1730 : 0.00011101437121396884
Loss at iteration 1740 : 0.0005437377258203924
Loss at iteration 1750 : 0.00044571247417479753
The SSIM Value is: 0.9851686937430881
The PSNR Value is: 46.02797243983735
the epoch is: 99
Loss at iteration 10 : 0.003902290016412735
Loss at iteration 20 : 0.0006081534666009247
Loss at iteration 30 : 0.0004695318057201803
Loss at iteration 40 : 7.760830339975655e-05
Loss at iteration 50 : 0.0007478949264623225
Loss at iteration 60 : 0.00018600169278215617
Loss at iteration 70 : 0.001408649142831564
Loss at iteration 80 : 0.0007587046129629016
Loss at iteration 90 : 0.0025632064789533615
Loss at iteration 100 : 0.00017647996719460934
Loss at iteration 110 : 0.0004745794867631048
Loss at iteration 120 : 0.0005322342040017247
Loss at iteration 130 : 0.00046180959907360375
Loss at iteration 140 : 0.00035599846160039306
Loss at iteration 150 : 0.0002534332452341914
Loss at iteration 160 : 0.00017823913367465138
Loss at iteration 170 : 0.0004935325123369694
Loss at iteration 180 : 0.00022515543969348073
Loss at iteration 190 : 0.0007348331855610013
Loss at iteration 200 : 0.002847646363079548
Loss at iteration 210 : 9.24777559703216e-05
Loss at iteration 220 : 0.004771693609654903
Loss at iteration 230 : 0.00020161627617198974
Loss at iteration 240 : 0.003340071765705943
Loss at iteration 250 : 0.00023456559574697167
Loss at iteration 260 : 3.522181941661984e-05
Loss at iteration 270 : 0.002831612480804324
Loss at iteration 280 : 0.0013895740266889334
Loss at iteration 290 : 0.0007119476213119924
Loss at iteration 300 : 0.00015293550677597523
Loss at iteration 310 : 0.00036830175668001175
Loss at iteration 320 : 0.001053630723617971
Loss at iteration 330 : 0.0019407003419473767
Loss at iteration 340 : 8.108825568342581e-05
Loss at iteration 350 : 0.00012972783588338643
Loss at iteration 360 : 0.003452564124017954
Loss at iteration 370 : 0.002949295099824667
Loss at iteration 380 : 0.0028326907195150852
Loss at iteration 390 : 0.00018114381236955523
Loss at iteration 400 : 0.00048330912250094116
Loss at iteration 410 : 0.00016358531138394028
Loss at iteration 420 : 0.0014922905247658491
Loss at iteration 430 : 8.990992500912398e-05
Loss at iteration 440 : 0.0016137557104229927
Loss at iteration 450 : 0.00019926652021240443
Loss at iteration 460 : 0.0009337821393273771
Loss at iteration 470 : 0.00035808529355563223
Loss at iteration 480 : 0.00016680301632732153
Loss at iteration 490 : 6.962598126847297e-05
Loss at iteration 500 : 0.0009439935674890876
Loss at iteration 510 : 0.004793695639818907
Loss at iteration 520 : 6.11357536399737e-05
Loss at iteration 530 : 0.0004343812179286033
Loss at iteration 540 : 0.0005218193400651217
Loss at iteration 550 : 0.00011477609223220497
Loss at iteration 560 : 0.0025423727929592133
Loss at iteration 570 : 0.0008578442502766848
Loss at iteration 580 : 0.002145402366295457
Loss at iteration 590 : 0.0002665792126208544
Loss at iteration 600 : 0.00047517192433588207
Loss at iteration 610 : 0.00010482696234248579
Loss at iteration 620 : 0.00012546966900117695
Loss at iteration 630 : 0.00036941454163752496
Loss at iteration 640 : 0.00036541849840432405
Loss at iteration 650 : 0.0030088317580521107
Loss at iteration 660 : 0.003004013793542981
Loss at iteration 670 : 0.00046946475049480796
Loss at iteration 680 : 0.0002533685474190861
Loss at iteration 690 : 0.00013215442595537752
Loss at iteration 700 : 0.00024020118871703744
Loss at iteration 710 : 0.0001632865605643019
Loss at iteration 720 : 0.00012748407607432455
Loss at iteration 730 : 0.0002671036636456847
Loss at iteration 740 : 8.309751865454018e-05
Loss at iteration 750 : 0.00021033541997894645
Loss at iteration 760 : 8.093592623481527e-05
Loss at iteration 770 : 0.003639958566054702
Loss at iteration 780 : 0.00018099043518304825
Loss at iteration 790 : 0.0032527479343116283
Loss at iteration 800 : 0.0001520377118140459
Loss at iteration 810 : 0.00016852933913469315
Loss at iteration 820 : 8.527169120498002e-05
Loss at iteration 830 : 0.003531309310346842
Loss at iteration 840 : 0.00033606751821935177
Loss at iteration 850 : 0.00011519171675899997
Loss at iteration 860 : 0.000647021341137588
Loss at iteration 870 : 0.00020636332919821143
Loss at iteration 880 : 0.00015948025975376368
Loss at iteration 890 : 0.0002733280707616359
Loss at iteration 900 : 0.000425158126745373
Loss at iteration 910 : 0.0002154361573047936
Loss at iteration 920 : 0.00016967175179161131
Loss at iteration 930 : 0.00011501777044031769
Loss at iteration 940 : 0.00011116929817944765
Loss at iteration 950 : 0.0035277490969747305
Loss at iteration 960 : 0.0004205178120173514
Loss at iteration 970 : 0.0027222048956900835
Loss at iteration 980 : 0.00020432988821994513
Loss at iteration 990 : 9.55407740548253e-05
Loss at iteration 1000 : 0.002453471068292856
Loss at iteration 1010 : 9.933250839821994e-05
Loss at iteration 1020 : 0.0008301918278448284
Loss at iteration 1030 : 0.0001998572697630152
Loss at iteration 1040 : 0.00016554415924474597
Loss at iteration 1050 : 0.00101064657792449
Loss at iteration 1060 : 0.0005764968227595091
Loss at iteration 1070 : 0.0029291592072695494
Loss at iteration 1080 : 0.001328789978288114
Loss at iteration 1090 : 0.0012154856231063604
Loss at iteration 1100 : 0.0007097809575498104
Loss at iteration 1110 : 0.0006502157193608582
Loss at iteration 1120 : 0.00013113237218931317
Loss at iteration 1130 : 0.0011466278228908777
Loss at iteration 1140 : 0.0017195023829117417
Loss at iteration 1150 : 0.0001979860244318843
Loss at iteration 1160 : 0.0001809863024391234
Loss at iteration 1170 : 0.00024794385535642505
Loss at iteration 1180 : 0.0005555038223974407
Loss at iteration 1190 : 0.0001253203663509339
Loss at iteration 1200 : 0.000594867451582104
Loss at iteration 1210 : 0.0004381937033031136
Loss at iteration 1220 : 0.00148290884681046
Loss at iteration 1230 : 0.0030469426419585943
Loss at iteration 1240 : 0.00024869682965800166
Loss at iteration 1250 : 0.0003193793527316302
Loss at iteration 1260 : 0.0010541969677433372
Loss at iteration 1270 : 0.0002644380438141525
Loss at iteration 1280 : 0.0002647395886015147
Loss at iteration 1290 : 0.00016562447126489133
Loss at iteration 1300 : 0.0037186157424002886
Loss at iteration 1310 : 0.0003304592100903392
Loss at iteration 1320 : 0.0012349860044196248
Loss at iteration 1330 : 0.00031923060305416584
Loss at iteration 1340 : 0.00031785681494511664
Loss at iteration 1350 : 3.187731999787502e-05
Loss at iteration 1360 : 0.00311527238227427
Loss at iteration 1370 : 0.0022307843901216984
Loss at iteration 1380 : 0.00044250802602618933
Loss at iteration 1390 : 0.00019641901599243283
Loss at iteration 1400 : 0.00014612992526963353
Loss at iteration 1410 : 0.000495444459374994
Loss at iteration 1420 : 0.00019533070735633373
Loss at iteration 1430 : 9.469386714044958e-05
Loss at iteration 1440 : 0.00248695258051157
Loss at iteration 1450 : 0.0002897285157814622
Loss at iteration 1460 : 0.001610788400284946
Loss at iteration 1470 : 0.0031706453301012516
Loss at iteration 1480 : 6.64238614263013e-05
Loss at iteration 1490 : 0.00025317439576610923
Loss at iteration 1500 : 0.0027834426146000624
Loss at iteration 1510 : 0.0007953636231832206
Loss at iteration 1520 : 0.00015298722428269684
Loss at iteration 1530 : 0.00013606397260446101
Loss at iteration 1540 : 0.0027540484443306923
Loss at iteration 1550 : 0.00036292377626523376
Loss at iteration 1560 : 0.0035159196704626083
Loss at iteration 1570 : 7.635998190380633e-05
Loss at iteration 1580 : 0.003314543515443802
Loss at iteration 1590 : 0.0011047008447349072
Loss at iteration 1600 : 0.0010802862234413624
Loss at iteration 1610 : 0.0001138511870522052
Loss at iteration 1620 : 0.0028334963135421276
Loss at iteration 1630 : 0.0001339705486316234
Loss at iteration 1640 : 0.0035067969001829624
Loss at iteration 1650 : 0.0009792997734621167
Loss at iteration 1660 : 8.734184666536748e-05
Loss at iteration 1670 : 0.00033943759626708925
Loss at iteration 1680 : 0.0020604839082807302
Loss at iteration 1690 : 0.0004964527324773371
Loss at iteration 1700 : 0.00011502265988383442
Loss at iteration 1710 : 0.0024381792172789574
Loss at iteration 1720 : 0.00023979069374036044
Loss at iteration 1730 : 0.0005226240609772503
Loss at iteration 1740 : 0.000487998389871791
Loss at iteration 1750 : 0.0005037806113250554
The SSIM Value is: 0.9822788347494235
The PSNR Value is: 46.399694299907935
the epoch is: 100
Loss at iteration 10 : 0.0009073999826796353
Loss at iteration 20 : 0.0001996768405660987
Loss at iteration 30 : 0.0003423495218157768
Loss at iteration 40 : 0.0008746469393372536
Loss at iteration 50 : 0.0006588438409380615
Loss at iteration 60 : 7.470203854609281e-05
Loss at iteration 70 : 0.00012455084652174264
Loss at iteration 80 : 0.0002514631487429142
Loss at iteration 90 : 0.00017934951756615192
Loss at iteration 100 : 0.0010575141059234738
Loss at iteration 110 : 0.0029569342732429504
Loss at iteration 120 : 0.0014437498757615685
Loss at iteration 130 : 0.0005845829728059471
Loss at iteration 140 : 0.002148539526388049
Loss at iteration 150 : 0.00432656379416585
Loss at iteration 160 : 0.00042442517587915063
Loss at iteration 170 : 6.8804802140221e-05
Loss at iteration 180 : 0.0002939579717349261
Loss at iteration 190 : 0.00013020465848967433
Loss at iteration 200 : 0.001196842873468995
Loss at iteration 210 : 0.00045633784611709416
Loss at iteration 220 : 0.0005240098689682782
Loss at iteration 230 : 0.0017252644756808877
Loss at iteration 240 : 0.00018468129565007985
Loss at iteration 250 : 0.0009345441940240562
Loss at iteration 260 : 0.00011182649177499115
Loss at iteration 270 : 0.0013393994886428118
Loss at iteration 280 : 0.0032352504786103964
Loss at iteration 290 : 0.0033063048031181097
Loss at iteration 300 : 0.00206443527713418
Loss at iteration 310 : 0.0005635156412608922
Loss at iteration 320 : 0.0001756635174388066
Loss at iteration 330 : 0.004726147744804621
Loss at iteration 340 : 8.546633034711704e-05
Loss at iteration 350 : 0.0003352808707859367
Loss at iteration 360 : 0.0012734101619571447
Loss at iteration 370 : 0.0014670479577034712
Loss at iteration 380 : 0.00044290220830589533
Loss at iteration 390 : 0.0019414739217609167
Loss at iteration 400 : 0.003602805780246854
Loss at iteration 410 : 0.00012359375250525773
Loss at iteration 420 : 0.0003375329542905092
Loss at iteration 430 : 0.0023330310359597206
Loss at iteration 440 : 0.00013615693023893982
Loss at iteration 450 : 0.00011251054093008861
Loss at iteration 460 : 9.446532931178808e-05
Loss at iteration 470 : 0.0005202526808716357
Loss at iteration 480 : 0.0023777426686137915
Loss at iteration 490 : 0.001235088799148798
Loss at iteration 500 : 7.686759636271745e-05
Loss at iteration 510 : 0.0008780951611697674
Loss at iteration 520 : 0.0001361180911771953
Loss at iteration 530 : 0.0007046416867524385
Loss at iteration 540 : 0.00015218571934383363
Loss at iteration 550 : 0.0032879577483981848
Loss at iteration 560 : 0.0003809357585851103
Loss at iteration 570 : 9.931087697623298e-05
Loss at iteration 580 : 0.0023264610208570957
Loss at iteration 590 : 0.0011260602623224258
Loss at iteration 600 : 0.0005336839240044355
Loss at iteration 610 : 0.0018380186520516872
Loss at iteration 620 : 0.0003365152224432677
Loss at iteration 630 : 0.00018780975369736552
Loss at iteration 640 : 0.0012066541239619255
Loss at iteration 650 : 0.00011963922588620335
Loss at iteration 660 : 0.0022019799798727036
Loss at iteration 670 : 0.001128201256506145
Loss at iteration 680 : 0.005022039171308279
Loss at iteration 690 : 0.0001689548953436315
Loss at iteration 700 : 0.0018166695954278111
Loss at iteration 710 : 8.290477853734046e-05
Loss at iteration 720 : 0.0010035093873739243
Loss at iteration 730 : 0.0014784155646339059
Loss at iteration 740 : 0.0014967529568821192
Loss at iteration 750 : 0.0004953660536557436
Loss at iteration 760 : 0.0001770272065186873
Loss at iteration 770 : 0.0017049150774255395
Loss at iteration 780 : 0.0006636464968323708
Loss at iteration 790 : 0.00011332201393088326
Loss at iteration 800 : 0.003487872425466776
Loss at iteration 810 : 0.0006936180870980024
Loss at iteration 820 : 0.0030622314661741257
Loss at iteration 830 : 0.00022210192400962114
Loss at iteration 840 : 0.0008011783356778324
Loss at iteration 850 : 0.000184387230547145
Loss at iteration 860 : 0.0008589645731262863
Loss at iteration 870 : 0.0028179259970784187
Loss at iteration 880 : 0.00015422955038957298
Loss at iteration 890 : 0.0013557092752307653
Loss at iteration 900 : 0.0014150174101814628
Loss at iteration 910 : 0.003907875623553991
Loss at iteration 920 : 0.0005668175872415304
Loss at iteration 930 : 7.149847078835592e-05
Loss at iteration 940 : 0.00019359412544872612
Loss at iteration 950 : 0.00098448246717453
Loss at iteration 960 : 7.470365380868316e-05
Loss at iteration 970 : 0.0005293276626616716
Loss at iteration 980 : 9.113612759392709e-05
Loss at iteration 990 : 0.0025084763765335083
Loss at iteration 1000 : 0.002463722135871649
Loss at iteration 1010 : 0.0033055059611797333
Loss at iteration 1020 : 4.904094748781063e-05
Loss at iteration 1030 : 8.612818783149123e-05
Loss at iteration 1040 : 0.004101701080799103
Loss at iteration 1050 : 0.0002512837527319789
Loss at iteration 1060 : 0.003581016091629863
Loss at iteration 1070 : 0.002226770855486393
Loss at iteration 1080 : 0.0017362912185490131
Loss at iteration 1090 : 0.00022627724683843553
Loss at iteration 1100 : 0.001101663801819086
Loss at iteration 1110 : 0.0034561394713819027
Loss at iteration 1120 : 0.00014812173321843147
Loss at iteration 1130 : 0.002842170186340809
Loss at iteration 1140 : 0.0002518305554986
Loss at iteration 1150 : 0.0002730049891397357
Loss at iteration 1160 : 0.001551404595375061
Loss at iteration 1170 : 0.0008197443094104528
Loss at iteration 1180 : 0.00017265029600821435
Loss at iteration 1190 : 0.00014801030920352787
Loss at iteration 1200 : 0.0010371636599302292
Loss at iteration 1210 : 0.0006299396045506
Loss at iteration 1220 : 0.0009170235134661198
Loss at iteration 1230 : 0.00025032248231582344
Loss at iteration 1240 : 0.00011437208013376221
Loss at iteration 1250 : 0.001435206620953977
Loss at iteration 1260 : 0.00016599173250142485
Loss at iteration 1270 : 0.0007241773419082165
Loss at iteration 1280 : 0.0007462176727131009
Loss at iteration 1290 : 0.0007627644808962941
Loss at iteration 1300 : 0.0002578661951702088
Loss at iteration 1310 : 7.584920240333304e-05
Loss at iteration 1320 : 0.00016668361786287278
Loss at iteration 1330 : 0.004250135272741318
Loss at iteration 1340 : 0.002829759381711483
Loss at iteration 1350 : 0.00018863544391933829
Loss at iteration 1360 : 0.00020676440908573568
Loss at iteration 1370 : 0.00021511083468794823
Loss at iteration 1380 : 0.00015628016262780875
Loss at iteration 1390 : 0.00013237682287581265
Loss at iteration 1400 : 0.0003107637749053538
Loss at iteration 1410 : 0.00037613773019984365
Loss at iteration 1420 : 0.00011054710194002837
Loss at iteration 1430 : 0.00037945981603115797
Loss at iteration 1440 : 0.0006377355894073844
Loss at iteration 1450 : 0.0004002282803412527
Loss at iteration 1460 : 0.0004896256141364574
Loss at iteration 1470 : 0.0007629106985405087
Loss at iteration 1480 : 5.827940549352206e-05
Loss at iteration 1490 : 0.0005335606983862817
Loss at iteration 1500 : 0.00019175659690517932
Loss at iteration 1510 : 0.006771802436560392
Loss at iteration 1520 : 0.00449400907382369
Loss at iteration 1530 : 0.0026603189762681723
Loss at iteration 1540 : 0.003860538825392723
Loss at iteration 1550 : 0.00016301248979289085
Loss at iteration 1560 : 0.0023875401820987463
Loss at iteration 1570 : 0.00032904493855312467
Loss at iteration 1580 : 0.00015313737094402313
Loss at iteration 1590 : 0.0033570502419024706
Loss at iteration 1600 : 0.002398835262283683
Loss at iteration 1610 : 0.00010449164983583614
Loss at iteration 1620 : 0.0002374816540395841
Loss at iteration 1630 : 0.002057870617136359
Loss at iteration 1640 : 0.008840173482894897
Loss at iteration 1650 : 0.002457045717164874
Loss at iteration 1660 : 0.0009634669404476881
Loss at iteration 1670 : 0.002502641174942255
Loss at iteration 1680 : 0.0005186952766962349
Loss at iteration 1690 : 0.0001184212596854195
Loss at iteration 1700 : 0.002261029090732336
Loss at iteration 1710 : 6.920415034983307e-05
Loss at iteration 1720 : 0.00036930551868863404
Loss at iteration 1730 : 0.00028271006885915995
Loss at iteration 1740 : 0.0001687280018813908
Loss at iteration 1750 : 0.0002807685232255608
The SSIM Value is: 0.9779867365759375
The PSNR Value is: 46.460908564176854
the epoch is: 101
Loss at iteration 10 : 0.00021769502200186253
Loss at iteration 20 : 0.00024247651163022965
Loss at iteration 30 : 0.00022755573445465416
Loss at iteration 40 : 8.321518544107676e-05
Loss at iteration 50 : 0.003928817808628082
Loss at iteration 60 : 0.00022916749003343284
Loss at iteration 70 : 0.00013737613335251808
Loss at iteration 80 : 0.004983075894415379
Loss at iteration 90 : 0.0018215817399322987
Loss at iteration 100 : 0.0004063266096636653
Loss at iteration 110 : 0.00016976628103293478
Loss at iteration 120 : 0.00014214450493454933
Loss at iteration 130 : 0.0005853717448189855
Loss at iteration 140 : 0.00014791502326261252
Loss at iteration 150 : 0.00014728098176419735
Loss at iteration 160 : 0.0001993654586840421
Loss at iteration 170 : 0.0005604299949482083
Loss at iteration 180 : 0.00012636996689252555
Loss at iteration 190 : 0.004735778551548719
Loss at iteration 200 : 0.0002450832980684936
Loss at iteration 210 : 0.00017718445451464504
Loss at iteration 220 : 0.0001741221349220723
Loss at iteration 230 : 0.0005908170714974403
Loss at iteration 240 : 0.00036928479676134884
Loss at iteration 250 : 0.0004777944996021688
Loss at iteration 260 : 0.00048092653742060065
Loss at iteration 270 : 0.003478599712252617
Loss at iteration 280 : 0.0026103779673576355
Loss at iteration 290 : 0.0010896942112594843
Loss at iteration 300 : 5.0143895350629464e-05
Loss at iteration 310 : 0.0014533607754856348
Loss at iteration 320 : 0.0027701284270733595
Loss at iteration 330 : 0.0005342146614566445
Loss at iteration 340 : 9.855229291133583e-05
Loss at iteration 350 : 0.00131353794131428
Loss at iteration 360 : 0.00010356478742323816
Loss at iteration 370 : 0.0012260406510904431
Loss at iteration 380 : 0.00010500694043003023
Loss at iteration 390 : 5.929049802944064e-05
Loss at iteration 400 : 0.0001701100409263745
Loss at iteration 410 : 0.0001720780855976045
Loss at iteration 420 : 0.0025315582752227783
Loss at iteration 430 : 0.004913785494863987
Loss at iteration 440 : 0.0010825184872373939
Loss at iteration 450 : 0.0003571331035345793
Loss at iteration 460 : 0.00035632180515676737
Loss at iteration 470 : 0.0006766087026335299
Loss at iteration 480 : 0.0008326568058691919
Loss at iteration 490 : 0.0011375925969332457
Loss at iteration 500 : 0.0005453979829326272
Loss at iteration 510 : 0.0006902901805005968
Loss at iteration 520 : 0.00023877102648839355
Loss at iteration 530 : 0.0005136723630130291
Loss at iteration 540 : 0.00024987413780763745
Loss at iteration 550 : 0.0036069839261472225
Loss at iteration 560 : 0.003600664436817169
Loss at iteration 570 : 8.671493560541421e-05
Loss at iteration 580 : 0.000260841625276953
Loss at iteration 590 : 0.0041295005939900875
Loss at iteration 600 : 7.21366232028231e-05
Loss at iteration 610 : 8.53368328534998e-05
Loss at iteration 620 : 0.002756851725280285
Loss at iteration 630 : 0.00044171203626319766
Loss at iteration 640 : 0.00012644840171560645
Loss at iteration 650 : 0.0013861190527677536
Loss at iteration 660 : 0.00023336023150477558
Loss at iteration 670 : 0.0006017869454808533
Loss at iteration 680 : 0.0033677201718091965
Loss at iteration 690 : 0.0012536970898509026
Loss at iteration 700 : 0.0004388162342365831
Loss at iteration 710 : 0.0004252095823176205
Loss at iteration 720 : 0.00039858880336396396
Loss at iteration 730 : 0.00024317289353348315
Loss at iteration 740 : 0.0004125829436816275
Loss at iteration 750 : 0.00010444450890645385
Loss at iteration 760 : 0.00021310398005880415
Loss at iteration 770 : 0.0014850718434900045
Loss at iteration 780 : 0.0006777413655072451
Loss at iteration 790 : 0.006607214920222759
Loss at iteration 800 : 9.532368130749092e-05
Loss at iteration 810 : 0.0002180802694056183
Loss at iteration 820 : 0.001072445185855031
Loss at iteration 830 : 0.00037058687303215265
Loss at iteration 840 : 0.0006679219659417868
Loss at iteration 850 : 0.0005080460105091333
Loss at iteration 860 : 0.00016095221508294344
Loss at iteration 870 : 0.0002839791704900563
Loss at iteration 880 : 0.0001250180066563189
Loss at iteration 890 : 0.00019494813750497997
Loss at iteration 900 : 0.0030363779515028
Loss at iteration 910 : 0.00010568177094683051
Loss at iteration 920 : 0.00013225643488112837
Loss at iteration 930 : 0.0001414119906257838
Loss at iteration 940 : 0.001877248054370284
Loss at iteration 950 : 0.0001532826863694936
Loss at iteration 960 : 0.00010053419100586325
Loss at iteration 970 : 0.00023769000836182386
Loss at iteration 980 : 0.0004849496763199568
Loss at iteration 990 : 0.00018260671640746295
Loss at iteration 1000 : 2.854453668987844e-05
Loss at iteration 1010 : 4.835928120883182e-05
Loss at iteration 1020 : 0.0007171271136030555
Loss at iteration 1030 : 0.00014476070646196604
Loss at iteration 1040 : 0.002807506825774908
Loss at iteration 1050 : 0.00016956233594100922
Loss at iteration 1060 : 0.004010461736470461
Loss at iteration 1070 : 0.00036032762727700174
Loss at iteration 1080 : 0.0020635598339140415
Loss at iteration 1090 : 0.0008441320969723165
Loss at iteration 1100 : 0.0007882962236180902
Loss at iteration 1110 : 0.0007451136480085552
Loss at iteration 1120 : 0.00025540226488374174
Loss at iteration 1130 : 0.0026749884709715843
Loss at iteration 1140 : 0.00013618622324429452
Loss at iteration 1150 : 0.00015797141531948
Loss at iteration 1160 : 0.00010987129644490778
Loss at iteration 1170 : 0.0035163150168955326
Loss at iteration 1180 : 0.0009788073366507888
Loss at iteration 1190 : 0.0001792715338524431
Loss at iteration 1200 : 4.035462188767269e-05
Loss at iteration 1210 : 0.00010301015572622418
Loss at iteration 1220 : 0.001760145416483283
Loss at iteration 1230 : 0.00010742597805801779
Loss at iteration 1240 : 0.0001439881307305768
Loss at iteration 1250 : 0.0001487678091507405
Loss at iteration 1260 : 0.0012830335181206465
Loss at iteration 1270 : 0.002135061426088214
Loss at iteration 1280 : 0.0008290273835882545
Loss at iteration 1290 : 0.00011465474381111562
Loss at iteration 1300 : 0.000590285868383944
Loss at iteration 1310 : 0.0016428767703473568
Loss at iteration 1320 : 0.002320179482921958
Loss at iteration 1330 : 5.479241008288227e-05
Loss at iteration 1340 : 0.00012003225856460631
Loss at iteration 1350 : 0.003830844070762396
Loss at iteration 1360 : 0.0001883242221083492
Loss at iteration 1370 : 0.00018584707868285477
Loss at iteration 1380 : 0.00018643095972947776
Loss at iteration 1390 : 0.0003985441871918738
Loss at iteration 1400 : 8.468475425615907e-05
Loss at iteration 1410 : 0.00013112019223626703
Loss at iteration 1420 : 0.0004440075717866421
Loss at iteration 1430 : 0.00018110458040609956
Loss at iteration 1440 : 0.00017162581207230687
Loss at iteration 1450 : 0.0002226128417532891
Loss at iteration 1460 : 0.0002700533077586442
Loss at iteration 1470 : 0.00012907898053526878
Loss at iteration 1480 : 0.000672221533022821
Loss at iteration 1490 : 0.001206125714816153
Loss at iteration 1500 : 0.0001663979492150247
Loss at iteration 1510 : 0.00018074898980557919
Loss at iteration 1520 : 0.0011158399283885956
Loss at iteration 1530 : 0.004474909510463476
Loss at iteration 1540 : 0.0030123216565698385
Loss at iteration 1550 : 0.00013320795551408082
Loss at iteration 1560 : 0.0007315450347959995
Loss at iteration 1570 : 0.0008451917674392462
Loss at iteration 1580 : 4.4132539187557995e-05
Loss at iteration 1590 : 0.0003034781548194587
Loss at iteration 1600 : 0.00423487089574337
Loss at iteration 1610 : 0.00016515635070391
Loss at iteration 1620 : 0.0007661068812012672
Loss at iteration 1630 : 0.0011237889993935823
Loss at iteration 1640 : 9.656965994508937e-05
Loss at iteration 1650 : 0.0006828138139098883
Loss at iteration 1660 : 8.69671130203642e-05
Loss at iteration 1670 : 0.00024372554617002606
Loss at iteration 1680 : 0.000891129020601511
Loss at iteration 1690 : 0.001598479924723506
Loss at iteration 1700 : 0.006200013682246208
Loss at iteration 1710 : 0.0021466491743922234
Loss at iteration 1720 : 0.00021974714763928205
Loss at iteration 1730 : 0.0005209051887504756
Loss at iteration 1740 : 0.0014885750133544207
Loss at iteration 1750 : 0.00010435791773488745
The SSIM Value is: 0.9689448753511328
The PSNR Value is: 46.26295724524275
the epoch is: 102
Loss at iteration 10 : 0.0004912551958113909
Loss at iteration 20 : 0.0007973717292770743
Loss at iteration 30 : 0.0001099606670322828
Loss at iteration 40 : 0.0007814972777850926
Loss at iteration 50 : 0.00023746484657749534
Loss at iteration 60 : 0.00014742492930963635
Loss at iteration 70 : 0.0009335142094641924
Loss at iteration 80 : 0.0003208956040907651
Loss at iteration 90 : 0.0003476761921774596
Loss at iteration 100 : 0.00015438860282301903
Loss at iteration 110 : 0.0003992895653937012
Loss at iteration 120 : 0.0005321403732523322
Loss at iteration 130 : 0.00018556488794274628
Loss at iteration 140 : 0.0006000768626108766
Loss at iteration 150 : 0.0017158153932541609
Loss at iteration 160 : 0.0038192300125956535
Loss at iteration 170 : 0.00025067038950510323
Loss at iteration 180 : 0.00028181850211694837
Loss at iteration 190 : 0.0001798511075321585
Loss at iteration 200 : 7.883333455538377e-05
Loss at iteration 210 : 7.118493522284552e-05
Loss at iteration 220 : 0.0011457196669653058
Loss at iteration 230 : 0.0004962526727467775
Loss at iteration 240 : 0.00038836809108033776
Loss at iteration 250 : 0.0011617275886237621
Loss at iteration 260 : 0.00048737943870946765
Loss at iteration 270 : 0.00023049203446134925
Loss at iteration 280 : 0.00011927471496164799
Loss at iteration 290 : 0.00024589840904809535
Loss at iteration 300 : 0.00021819554967805743
Loss at iteration 310 : 7.359154551522806e-05
Loss at iteration 320 : 0.00018068295321427286
Loss at iteration 330 : 0.000502440903801471
Loss at iteration 340 : 0.003315156092867255
Loss at iteration 350 : 0.00020258230506442487
Loss at iteration 360 : 0.00021095352713018656
Loss at iteration 370 : 9.901686280500144e-05
Loss at iteration 380 : 0.0013137615751475096
Loss at iteration 390 : 0.00016458783647976816
Loss at iteration 400 : 9.608036634745076e-05
Loss at iteration 410 : 0.00012548183440230787
Loss at iteration 420 : 0.0004706162726506591
Loss at iteration 430 : 0.003387839999049902
Loss at iteration 440 : 0.0014071475015953183
Loss at iteration 450 : 0.0006130391848273575
Loss at iteration 460 : 0.00030101899756118655
Loss at iteration 470 : 0.0003822034050244838
Loss at iteration 480 : 0.00014450433081947267
Loss at iteration 490 : 0.00020400999346747994
Loss at iteration 500 : 0.0031957514584064484
Loss at iteration 510 : 4.1061153751797974e-05
Loss at iteration 520 : 0.0018122695619240403
Loss at iteration 530 : 0.0007999823428690434
Loss at iteration 540 : 0.00021525128977373242
Loss at iteration 550 : 0.00039226331864483654
Loss at iteration 560 : 0.0024850117042660713
Loss at iteration 570 : 0.0003271160530857742
Loss at iteration 580 : 0.000734784291125834
Loss at iteration 590 : 0.00031521692289970815
Loss at iteration 600 : 0.00013088533887639642
Loss at iteration 610 : 0.0011750037083402276
Loss at iteration 620 : 0.00482330983504653
Loss at iteration 630 : 0.0004688685876317322
Loss at iteration 640 : 0.0008056923397816718
Loss at iteration 650 : 0.00022257360978983343
Loss at iteration 660 : 0.0004747849015984684
Loss at iteration 670 : 4.3283765990054235e-05
Loss at iteration 680 : 0.00085564045002684
Loss at iteration 690 : 0.00041183471330441535
Loss at iteration 700 : 0.002480742521584034
Loss at iteration 710 : 0.00035311782266944647
Loss at iteration 720 : 0.00047635240480303764
Loss at iteration 730 : 0.0021020681597292423
Loss at iteration 740 : 0.0003842422738671303
Loss at iteration 750 : 0.0006460571894422174
Loss at iteration 760 : 7.047603139653802e-05
Loss at iteration 770 : 0.0031085689552128315
Loss at iteration 780 : 0.00022752612130716443
Loss at iteration 790 : 0.00024226386449299753
Loss at iteration 800 : 0.00030396407237276435
Loss at iteration 810 : 0.0002323935041204095
Loss at iteration 820 : 0.0025323727168142796
Loss at iteration 830 : 0.00246244459412992
Loss at iteration 840 : 0.0013396375579759479
Loss at iteration 850 : 0.000157297239638865
Loss at iteration 860 : 0.00047569238813593984
Loss at iteration 870 : 0.0001416944433003664
Loss at iteration 880 : 0.0010659551480785012
Loss at iteration 890 : 0.0007174190832301974
Loss at iteration 900 : 0.0015458042034879327
Loss at iteration 910 : 0.00014612307131756097
Loss at iteration 920 : 0.0022666382137686014
Loss at iteration 930 : 0.005853092763572931
Loss at iteration 940 : 0.00012872279330622405
Loss at iteration 950 : 0.003214272204786539
Loss at iteration 960 : 0.0009514143457636237
Loss at iteration 970 : 0.0002322638756595552
Loss at iteration 980 : 0.0007453890284523368
Loss at iteration 990 : 0.0004885230446234345
Loss at iteration 1000 : 0.00030878870165906847
Loss at iteration 1010 : 0.0005687495577149093
Loss at iteration 1020 : 0.0003197355254087597
Loss at iteration 1030 : 0.00010321437730453908
Loss at iteration 1040 : 6.380456761689857e-05
Loss at iteration 1050 : 0.0004011986020486802
Loss at iteration 1060 : 0.00211512902751565
Loss at iteration 1070 : 0.0003428936470299959
Loss at iteration 1080 : 0.0001519574725534767
Loss at iteration 1090 : 0.00046682223910465837
Loss at iteration 1100 : 0.00014618145360145718
Loss at iteration 1110 : 0.0017772074788808823
Loss at iteration 1120 : 0.0056646838784217834
Loss at iteration 1130 : 0.003096016589552164
Loss at iteration 1140 : 0.00034555423189885914
Loss at iteration 1150 : 0.0020589898340404034
Loss at iteration 1160 : 0.0004500525537878275
Loss at iteration 1170 : 0.0001567056169733405
Loss at iteration 1180 : 0.00010917524923570454
Loss at iteration 1190 : 0.0016740945866331458
Loss at iteration 1200 : 0.00012571160914376378
Loss at iteration 1210 : 0.00021078895952086896
Loss at iteration 1220 : 6.468207720899954e-05
Loss at iteration 1230 : 0.00018669405835680664
Loss at iteration 1240 : 8.8530607172288e-05
Loss at iteration 1250 : 0.007127509452402592
Loss at iteration 1260 : 0.0012536367867141962
Loss at iteration 1270 : 0.002328701550140977
Loss at iteration 1280 : 8.465853170491755e-05
Loss at iteration 1290 : 0.0009826845489442348
Loss at iteration 1300 : 0.00012627866817638278
Loss at iteration 1310 : 0.00033854221692308784
Loss at iteration 1320 : 0.0005255253054201603
Loss at iteration 1330 : 0.00015311191964428872
Loss at iteration 1340 : 0.00010521268268348649
Loss at iteration 1350 : 0.00044221157440915704
Loss at iteration 1360 : 0.0012389536714181304
Loss at iteration 1370 : 0.0004150703316554427
Loss at iteration 1380 : 0.00015532641555182636
Loss at iteration 1390 : 0.00014411569281946868
Loss at iteration 1400 : 0.0006203700322657824
Loss at iteration 1410 : 0.00044250389328226447
Loss at iteration 1420 : 0.0002478704845998436
Loss at iteration 1430 : 0.0001448428665753454
Loss at iteration 1440 : 0.0016955154715105891
Loss at iteration 1450 : 0.00025342509616166353
Loss at iteration 1460 : 0.00041845321538858116
Loss at iteration 1470 : 0.000323752494296059
Loss at iteration 1480 : 0.0037493398413062096
Loss at iteration 1490 : 0.0006147452513687313
Loss at iteration 1500 : 0.00018144752539228648
Loss at iteration 1510 : 0.0012856912799179554
Loss at iteration 1520 : 0.00013461393245961517
Loss at iteration 1530 : 0.0015907138586044312
Loss at iteration 1540 : 0.000810437195468694
Loss at iteration 1550 : 0.00025602462119422853
Loss at iteration 1560 : 0.00015356110816355795
Loss at iteration 1570 : 0.003000121098011732
Loss at iteration 1580 : 0.00016844950732775033
Loss at iteration 1590 : 0.0007574607152491808
Loss at iteration 1600 : 0.0004956569755449891
Loss at iteration 1610 : 0.001180115039460361
Loss at iteration 1620 : 0.0001555324561195448
Loss at iteration 1630 : 0.0006831101491115987
Loss at iteration 1640 : 0.0036208657547831535
Loss at iteration 1650 : 0.0007411955739371479
Loss at iteration 1660 : 0.00021360332902986556
Loss at iteration 1670 : 0.002919867867603898
Loss at iteration 1680 : 8.829915896058083e-05
Loss at iteration 1690 : 0.00016211923502851278
Loss at iteration 1700 : 0.00024298718199133873
Loss at iteration 1710 : 0.003498267149552703
Loss at iteration 1720 : 8.258871821453795e-05
Loss at iteration 1730 : 0.002563171787187457
Loss at iteration 1740 : 4.9113037675851956e-05
Loss at iteration 1750 : 0.0014654608676210046
The SSIM Value is: 0.984545841484868
The PSNR Value is: 46.402139541861246
the epoch is: 103
Loss at iteration 10 : 0.0010532652959227562
Loss at iteration 20 : 0.0002100183191942051
Loss at iteration 30 : 0.00034327214234508574
Loss at iteration 40 : 0.00186136644333601
Loss at iteration 50 : 0.002218647161498666
Loss at iteration 60 : 0.00017132828361354768
Loss at iteration 70 : 0.0002453617053106427
Loss at iteration 80 : 0.0016410619718953967
Loss at iteration 90 : 0.0004708660126198083
Loss at iteration 100 : 0.0006508526857942343
Loss at iteration 110 : 0.002004339825361967
Loss at iteration 120 : 0.001702487119473517
Loss at iteration 130 : 0.00036155490670353174
Loss at iteration 140 : 0.007375888992100954
Loss at iteration 150 : 0.006356513127684593
Loss at iteration 160 : 0.0002677228767424822
Loss at iteration 170 : 9.366904123453423e-05
Loss at iteration 180 : 0.0006513248081319034
Loss at iteration 190 : 0.004497966263443232
Loss at iteration 200 : 0.0001297236594837159
Loss at iteration 210 : 8.273308776551858e-05
Loss at iteration 220 : 0.0002971335197798908
Loss at iteration 230 : 8.732874994166195e-05
Loss at iteration 240 : 0.0010522378142923117
Loss at iteration 250 : 9.347411833005026e-05
Loss at iteration 260 : 9.417482215212658e-05
Loss at iteration 270 : 7.087245467118919e-05
Loss at iteration 280 : 0.0002519040135666728
Loss at iteration 290 : 9.20113961910829e-05
Loss at iteration 300 : 0.00012465883628465235
Loss at iteration 310 : 0.0003990124096162617
Loss at iteration 320 : 0.0015893775271251798
Loss at iteration 330 : 0.00027098978171125054
Loss at iteration 340 : 0.0001336207496933639
Loss at iteration 350 : 0.0016670834738761187
Loss at iteration 360 : 0.0004939691862091422
Loss at iteration 370 : 0.003514708485454321
Loss at iteration 380 : 0.003405987750738859
Loss at iteration 390 : 9.162345668300986e-05
Loss at iteration 400 : 0.00012406412861309946
Loss at iteration 410 : 0.0002807825803756714
Loss at iteration 420 : 0.0003819627163466066
Loss at iteration 430 : 0.00017223090981133282
Loss at iteration 440 : 0.0007363396580331028
Loss at iteration 450 : 0.0001795287535060197
Loss at iteration 460 : 0.003019979689270258
Loss at iteration 470 : 0.0027159631717950106
Loss at iteration 480 : 0.000289351271931082
Loss at iteration 490 : 0.0002596205158624798
Loss at iteration 500 : 0.0004718155541922897
Loss at iteration 510 : 0.0003206956316716969
Loss at iteration 520 : 0.0007521678926423192
Loss at iteration 530 : 0.00010473097790963948
Loss at iteration 540 : 0.0001980590750463307
Loss at iteration 550 : 0.00035774888237938285
Loss at iteration 560 : 0.0002788543060887605
Loss at iteration 570 : 0.00010939939966192469
Loss at iteration 580 : 0.0002506094169802964
Loss at iteration 590 : 0.00016185220738407224
Loss at iteration 600 : 0.0011379198404029012
Loss at iteration 610 : 0.00021368970919866115
Loss at iteration 620 : 0.000531192694325
Loss at iteration 630 : 0.00010217035742243752
Loss at iteration 640 : 0.0020318885799497366
Loss at iteration 650 : 0.006370927207171917
Loss at iteration 660 : 0.00032616767566651106
Loss at iteration 670 : 0.0005345502868294716
Loss at iteration 680 : 0.0010480380151420832
Loss at iteration 690 : 0.00039237222517840564
Loss at iteration 700 : 0.0018430561758577824
Loss at iteration 710 : 0.00010599145025480539
Loss at iteration 720 : 8.070739568211138e-05
Loss at iteration 730 : 0.006664358079433441
Loss at iteration 740 : 0.0013983158860355616
Loss at iteration 750 : 0.0004091252340003848
Loss at iteration 760 : 0.0003807927714660764
Loss at iteration 770 : 0.00014420159277506173
Loss at iteration 780 : 7.648137398064137e-05
Loss at iteration 790 : 0.00020266577485017478
Loss at iteration 800 : 0.0001953672617673874
Loss at iteration 810 : 0.0004977912176400423
Loss at iteration 820 : 0.00016354622493963689
Loss at iteration 830 : 0.006109202280640602
Loss at iteration 840 : 0.0018277163617312908
Loss at iteration 850 : 0.0005622805911116302
Loss at iteration 860 : 0.0003105091454926878
Loss at iteration 870 : 0.00013127163401804864
Loss at iteration 880 : 0.00015473448729608208
Loss at iteration 890 : 0.0017847191775217652
Loss at iteration 900 : 0.0020165699534118176
Loss at iteration 910 : 0.004630812909454107
Loss at iteration 920 : 0.00024145566567312926
Loss at iteration 930 : 0.00024241283244919032
Loss at iteration 940 : 0.001706316601485014
Loss at iteration 950 : 0.0005255909636616707
Loss at iteration 960 : 0.0030262211803346872
Loss at iteration 970 : 0.00017513307102490216
Loss at iteration 980 : 0.0006709439912810922
Loss at iteration 990 : 0.0014710444957017899
Loss at iteration 1000 : 0.002957866759970784
Loss at iteration 1010 : 0.0003475128614809364
Loss at iteration 1020 : 0.0003591118147596717
Loss at iteration 1030 : 0.0005283184582367539
Loss at iteration 1040 : 0.003339448943734169
Loss at iteration 1050 : 0.0015361682744696736
Loss at iteration 1060 : 0.0005259603494778275
Loss at iteration 1070 : 0.00019916817836929113
Loss at iteration 1080 : 0.0010924352100118995
Loss at iteration 1090 : 0.002370250876992941
Loss at iteration 1100 : 0.0001718201529001817
Loss at iteration 1110 : 0.0007128067081794143
Loss at iteration 1120 : 0.00026268872898072004
Loss at iteration 1130 : 0.001079506822861731
Loss at iteration 1140 : 0.0028222640976309776
Loss at iteration 1150 : 0.00014662370085716248
Loss at iteration 1160 : 0.00026810902636498213
Loss at iteration 1170 : 0.0002493307983968407
Loss at iteration 1180 : 0.0026701607275754213
Loss at iteration 1190 : 0.0012675952166318893
Loss at iteration 1200 : 0.00024408854369539768
Loss at iteration 1210 : 0.00011278128658886999
Loss at iteration 1220 : 0.0002583288005553186
Loss at iteration 1230 : 0.004425888881087303
Loss at iteration 1240 : 0.00024321259115822613
Loss at iteration 1250 : 0.0002413889451418072
Loss at iteration 1260 : 0.00010840185859706253
Loss at iteration 1270 : 4.501858347794041e-05
Loss at iteration 1280 : 0.0010375268757343292
Loss at iteration 1290 : 0.0013051512651145458
Loss at iteration 1300 : 0.00014220751472748816
Loss at iteration 1310 : 0.0006798336980864406
Loss at iteration 1320 : 0.00013737543486058712
Loss at iteration 1330 : 0.000488585326820612
Loss at iteration 1340 : 0.0029660803265869617
Loss at iteration 1350 : 0.0054148901253938675
Loss at iteration 1360 : 7.685433956794441e-05
Loss at iteration 1370 : 5.035992217017338e-05
Loss at iteration 1380 : 0.0008192254463210702
Loss at iteration 1390 : 0.0036952272057533264
Loss at iteration 1400 : 0.00014003156684339046
Loss at iteration 1410 : 0.00010649978503352031
Loss at iteration 1420 : 0.0019468213431537151
Loss at iteration 1430 : 0.0005543484003283083
Loss at iteration 1440 : 0.0002075416559819132
Loss at iteration 1450 : 0.00021343120897654444
Loss at iteration 1460 : 0.00011844573600683361
Loss at iteration 1470 : 0.0017472074832767248
Loss at iteration 1480 : 0.002782325027510524
Loss at iteration 1490 : 0.0003470606170594692
Loss at iteration 1500 : 0.00022205166169442236
Loss at iteration 1510 : 0.0007826356450095773
Loss at iteration 1520 : 0.00023798536858521402
Loss at iteration 1530 : 0.00016225530998781323
Loss at iteration 1540 : 0.00043430383084341884
Loss at iteration 1550 : 0.00011394339526304975
Loss at iteration 1560 : 8.875325147528201e-05
Loss at iteration 1570 : 0.0005682547343894839
Loss at iteration 1580 : 0.0034632892347872257
Loss at iteration 1590 : 0.00014911478501744568
Loss at iteration 1600 : 0.002327925758436322
Loss at iteration 1610 : 0.0029430952854454517
Loss at iteration 1620 : 0.0005795746110379696
Loss at iteration 1630 : 0.0010148215806111693
Loss at iteration 1640 : 0.0007735783001407981
Loss at iteration 1650 : 0.0007776714628562331
Loss at iteration 1660 : 8.054864156292751e-05
Loss at iteration 1670 : 0.00200666137970984
Loss at iteration 1680 : 0.003735124133527279
Loss at iteration 1690 : 0.00034842119202949107
Loss at iteration 1700 : 7.67773890402168e-05
Loss at iteration 1710 : 0.0005463590496219695
Loss at iteration 1720 : 0.0008845982956700027
Loss at iteration 1730 : 0.0005112195503897965
Loss at iteration 1740 : 0.005718515254557133
Loss at iteration 1750 : 0.0066953967325389385
The SSIM Value is: 0.9855038212522012
The PSNR Value is: 46.22277023298625
the epoch is: 104
Loss at iteration 10 : 0.00016954260354395956
Loss at iteration 20 : 0.0020088329911231995
Loss at iteration 30 : 4.312539749662392e-05
Loss at iteration 40 : 0.002832042519003153
Loss at iteration 50 : 0.0006116593722254038
Loss at iteration 60 : 0.00032864868990145624
Loss at iteration 70 : 0.00182162516284734
Loss at iteration 80 : 0.0034220339730381966
Loss at iteration 90 : 0.000401865690946579
Loss at iteration 100 : 0.0035857222974300385
Loss at iteration 110 : 0.00014997708785813302
Loss at iteration 120 : 0.00018749349692370743
Loss at iteration 130 : 0.006491301115602255
Loss at iteration 140 : 0.00036541419103741646
Loss at iteration 150 : 0.0001094682447728701
Loss at iteration 160 : 5.2988893003202975e-05
Loss at iteration 170 : 0.0008868523873388767
Loss at iteration 180 : 0.0013820305466651917
Loss at iteration 190 : 0.0017160127172246575
Loss at iteration 200 : 0.00012959179002791643
Loss at iteration 210 : 0.0021419196855276823
Loss at iteration 220 : 0.0005225893692113459
Loss at iteration 230 : 0.00014107950846664608
Loss at iteration 240 : 0.005825384519994259
Loss at iteration 250 : 0.0002658641606103629
Loss at iteration 260 : 0.000696740229614079
Loss at iteration 270 : 0.0008213146938942373
Loss at iteration 280 : 0.002794134896248579
Loss at iteration 290 : 0.0033488848712295294
Loss at iteration 300 : 0.00017248722724616528
Loss at iteration 310 : 0.0003174381563439965
Loss at iteration 320 : 0.0007132227765396237
Loss at iteration 330 : 0.0002384004183113575
Loss at iteration 340 : 0.0002846645948011428
Loss at iteration 350 : 0.00019312679069116712
Loss at iteration 360 : 0.0015618882607668638
Loss at iteration 370 : 0.001091466867364943
Loss at iteration 380 : 0.0001304070756305009
Loss at iteration 390 : 0.00029183164588175714
Loss at iteration 400 : 0.0006319930544123054
Loss at iteration 410 : 0.0006916283164173365
Loss at iteration 420 : 0.0001443897926947102
Loss at iteration 430 : 0.00039404284325428307
Loss at iteration 440 : 0.00020326313097029924
Loss at iteration 450 : 0.003168167546391487
Loss at iteration 460 : 0.00019763116142712533
Loss at iteration 470 : 0.00022716207604389638
Loss at iteration 480 : 0.00022578181233257055
Loss at iteration 490 : 0.0026683094911277294
Loss at iteration 500 : 0.0005414627376012504
Loss at iteration 510 : 0.0009702026145532727
Loss at iteration 520 : 6.939173908904195e-05
Loss at iteration 530 : 0.003407757729291916
Loss at iteration 540 : 8.838288340484723e-05
Loss at iteration 550 : 0.0005697963060811162
Loss at iteration 560 : 0.0016353530809283257
Loss at iteration 570 : 0.00020471903553698212
Loss at iteration 580 : 0.00012698108912445605
Loss at iteration 590 : 0.0007368099759332836
Loss at iteration 600 : 0.0005754544399678707
Loss at iteration 610 : 0.00029265510966069996
Loss at iteration 620 : 0.0019292772049084306
Loss at iteration 630 : 0.002193272113800049
Loss at iteration 640 : 0.0005200908053666353
Loss at iteration 650 : 0.00029571185586974025
Loss at iteration 660 : 0.00018802168779075146
Loss at iteration 670 : 7.840318721719086e-05
Loss at iteration 680 : 0.0005802800878882408
Loss at iteration 690 : 0.00017297189333476126
Loss at iteration 700 : 5.061531555838883e-05
Loss at iteration 710 : 9.538686572341248e-05
Loss at iteration 720 : 0.0038232477381825447
Loss at iteration 730 : 0.0025458233430981636
Loss at iteration 740 : 0.0010886876843869686
Loss at iteration 750 : 0.002485482022166252
Loss at iteration 760 : 0.00035066550481133163
Loss at iteration 770 : 0.00013213627971708775
Loss at iteration 780 : 0.0028349938802421093
Loss at iteration 790 : 0.00642367685213685
Loss at iteration 800 : 0.0019192715408280492
Loss at iteration 810 : 0.00011324345541652292
Loss at iteration 820 : 0.0001464248780393973
Loss at iteration 830 : 0.002288681222125888
Loss at iteration 840 : 0.00013233769277576357
Loss at iteration 850 : 0.000634009251371026
Loss at iteration 860 : 7.075244502630085e-05
Loss at iteration 870 : 0.00020285649225115776
Loss at iteration 880 : 0.00016528379637748003
Loss at iteration 890 : 0.0009211748838424683
Loss at iteration 900 : 0.0031586429104208946
Loss at iteration 910 : 7.807606743881479e-05
Loss at iteration 920 : 0.003817963879555464
Loss at iteration 930 : 0.0030330459121614695
Loss at iteration 940 : 4.546656055026688e-05
Loss at iteration 950 : 0.00031780972494743764
Loss at iteration 960 : 0.0004972273600287735
Loss at iteration 970 : 0.00011399529466871172
Loss at iteration 980 : 0.0010344618931412697
Loss at iteration 990 : 0.005889753345400095
Loss at iteration 1000 : 0.0002165807381970808
Loss at iteration 1010 : 0.0007536946795880795
Loss at iteration 1020 : 0.0034140627831220627
Loss at iteration 1030 : 0.0008475134382024407
Loss at iteration 1040 : 0.0004829480894841254
Loss at iteration 1050 : 0.0001045909448293969
Loss at iteration 1060 : 0.00014030543388798833
Loss at iteration 1070 : 0.0005985013558529317
Loss at iteration 1080 : 0.0005479975370690227
Loss at iteration 1090 : 0.0002315557503607124
Loss at iteration 1100 : 0.0004237309331074357
Loss at iteration 1110 : 0.0013085231184959412
Loss at iteration 1120 : 9.937675349647179e-05
Loss at iteration 1130 : 0.0014614140382036567
Loss at iteration 1140 : 0.00026445079129189253
Loss at iteration 1150 : 0.000293977209366858
Loss at iteration 1160 : 0.0016391169046983123
Loss at iteration 1170 : 0.00016628974117338657
Loss at iteration 1180 : 0.0010719613637775183
Loss at iteration 1190 : 0.0011270972900092602
Loss at iteration 1200 : 0.00011348970292601734
Loss at iteration 1210 : 0.0001010518753901124
Loss at iteration 1220 : 0.0002822109963744879
Loss at iteration 1230 : 0.0003369227924849838
Loss at iteration 1240 : 0.0007243975414894521
Loss at iteration 1250 : 0.001903733005747199
Loss at iteration 1260 : 8.018673543119803e-05
Loss at iteration 1270 : 0.00034406845225021243
Loss at iteration 1280 : 0.00018550829554442316
Loss at iteration 1290 : 0.00015629678091499954
Loss at iteration 1300 : 0.00013630067405756563
Loss at iteration 1310 : 0.00035020324867218733
Loss at iteration 1320 : 0.0003216789336875081
Loss at iteration 1330 : 0.00013535149628296494
Loss at iteration 1340 : 0.0022843789774924517
Loss at iteration 1350 : 0.00019346008775755763
Loss at iteration 1360 : 0.0002549458004068583
Loss at iteration 1370 : 0.00022845808416604996
Loss at iteration 1380 : 0.00168670027051121
Loss at iteration 1390 : 0.0006278309738263488
Loss at iteration 1400 : 0.0017942170379683375
Loss at iteration 1410 : 0.0003702151880133897
Loss at iteration 1420 : 0.0003867258201353252
Loss at iteration 1430 : 0.0033949222415685654
Loss at iteration 1440 : 0.0027496374677866697
Loss at iteration 1450 : 0.000641348771750927
Loss at iteration 1460 : 4.220067785354331e-05
Loss at iteration 1470 : 0.00022936835011933
Loss at iteration 1480 : 0.0005992684164084494
Loss at iteration 1490 : 0.00013814057456329465
Loss at iteration 1500 : 0.0021752032916992903
Loss at iteration 1510 : 0.00022594806796405464
Loss at iteration 1520 : 0.003497747704386711
Loss at iteration 1530 : 0.0021270993165671825
Loss at iteration 1540 : 0.00043318848474882543
Loss at iteration 1550 : 0.000409321510232985
Loss at iteration 1560 : 0.0070362696424126625
Loss at iteration 1570 : 0.0005486884037964046
Loss at iteration 1580 : 0.00024319968360941857
Loss at iteration 1590 : 7.597589865326881e-05
Loss at iteration 1600 : 0.0011345769744366407
Loss at iteration 1610 : 0.0032597449608147144
Loss at iteration 1620 : 0.0017362723592668772
Loss at iteration 1630 : 0.00019417489238549024
Loss at iteration 1640 : 0.0019209996098652482
Loss at iteration 1650 : 0.0025569014251232147
Loss at iteration 1660 : 0.00016312704246956855
Loss at iteration 1670 : 0.00022338380222208798
Loss at iteration 1680 : 0.0012583050411194563
Loss at iteration 1690 : 0.0023621695581823587
Loss at iteration 1700 : 0.0021369571331888437
Loss at iteration 1710 : 0.000518647488206625
Loss at iteration 1720 : 0.0023575108498334885
Loss at iteration 1730 : 0.00010619206295814365
Loss at iteration 1740 : 6.272727478062734e-05
Loss at iteration 1750 : 0.00010886982636293396
The SSIM Value is: 0.9879216521584515
The PSNR Value is: 46.521853461664676
the epoch is: 105
Loss at iteration 10 : 0.00041849820991046727
Loss at iteration 20 : 0.0008761935750953853
Loss at iteration 30 : 0.0013351324014365673
Loss at iteration 40 : 0.0013225252041593194
Loss at iteration 50 : 0.0002744279336184263
Loss at iteration 60 : 0.00011391335283406079
Loss at iteration 70 : 6.94342379574664e-05
Loss at iteration 80 : 0.0002701906778384
Loss at iteration 90 : 0.006729363463819027
Loss at iteration 100 : 0.00067582365591079
Loss at iteration 110 : 0.0033253435976803303
Loss at iteration 120 : 0.00021883890440221876
Loss at iteration 130 : 0.00012383861758280545
Loss at iteration 140 : 0.0001580300449859351
Loss at iteration 150 : 0.00018064430332742631
Loss at iteration 160 : 0.0005250441026873887
Loss at iteration 170 : 0.004278819542378187
Loss at iteration 180 : 0.0010009427787736058
Loss at iteration 190 : 0.006292757112532854
Loss at iteration 200 : 0.003914705477654934
Loss at iteration 210 : 0.0013580078957602382
Loss at iteration 220 : 0.0017442521639168262
Loss at iteration 230 : 0.00010887300595641136
Loss at iteration 240 : 0.00015173142310231924
Loss at iteration 250 : 0.0001217034732690081
Loss at iteration 260 : 0.0006420391146093607
Loss at iteration 270 : 0.00014549438492394984
Loss at iteration 280 : 0.00011977783287875354
Loss at iteration 290 : 0.00022352550877258182
Loss at iteration 300 : 0.0032852254807949066
Loss at iteration 310 : 6.853196100564674e-05
Loss at iteration 320 : 0.000552246521692723
Loss at iteration 330 : 0.0009518091683275998
Loss at iteration 340 : 0.003626710269600153
Loss at iteration 350 : 0.00016482382488902658
Loss at iteration 360 : 0.0003071021055802703
Loss at iteration 370 : 0.00033059512497857213
Loss at iteration 380 : 0.001245043589733541
Loss at iteration 390 : 8.637814607936889e-05
Loss at iteration 400 : 0.0004427559324540198
Loss at iteration 410 : 0.0005113586666993797
Loss at iteration 420 : 0.00012673402670770884
Loss at iteration 430 : 0.000774357991758734
Loss at iteration 440 : 0.00021903759625274688
Loss at iteration 450 : 0.0003249357105232775
Loss at iteration 460 : 0.0008776133181527257
Loss at iteration 470 : 0.00036732025910168886
Loss at iteration 480 : 0.0002306806418346241
Loss at iteration 490 : 6.558372115250677e-05
Loss at iteration 500 : 0.0002488623431418091
Loss at iteration 510 : 0.00019737411639653146
Loss at iteration 520 : 0.00015295595221687108
Loss at iteration 530 : 0.00022699913824908435
Loss at iteration 540 : 0.0001440987252863124
Loss at iteration 550 : 4.0250270103570074e-05
Loss at iteration 560 : 0.0007992368191480637
Loss at iteration 570 : 0.00020522880367934704
Loss at iteration 580 : 0.002395461779087782
Loss at iteration 590 : 0.00021393841598182917
Loss at iteration 600 : 0.0005447770236060023
Loss at iteration 610 : 0.0001602361589903012
Loss at iteration 620 : 0.00042870367178693414
Loss at iteration 630 : 0.003631257452070713
Loss at iteration 640 : 0.002440206240862608
Loss at iteration 650 : 0.0022594176698476076
Loss at iteration 660 : 0.0008435125928372145
Loss at iteration 670 : 0.001887243939563632
Loss at iteration 680 : 0.0017282560002058744
Loss at iteration 690 : 0.000298679166007787
Loss at iteration 700 : 0.0003634801250882447
Loss at iteration 710 : 0.0011087425518780947
Loss at iteration 720 : 0.00027123192558065057
Loss at iteration 730 : 8.736881136428565e-05
Loss at iteration 740 : 0.00042924380977638066
Loss at iteration 750 : 0.0008407302666455507
Loss at iteration 760 : 0.0003246343112550676
Loss at iteration 770 : 0.0002021577238338068
Loss at iteration 780 : 0.00015922862803563476
Loss at iteration 790 : 0.0003278132062405348
Loss at iteration 800 : 0.0019579522777348757
Loss at iteration 810 : 0.000345899083185941
Loss at iteration 820 : 9.179003245662898e-05
Loss at iteration 830 : 0.00013088196283206344
Loss at iteration 840 : 0.000530682853423059
Loss at iteration 850 : 0.00018620042828842998
Loss at iteration 860 : 0.0009942672913894057
Loss at iteration 870 : 0.00014027731958776712
Loss at iteration 880 : 0.00045447441516444087
Loss at iteration 890 : 7.69739635870792e-05
Loss at iteration 900 : 0.0002754836459644139
Loss at iteration 910 : 0.0013435641303658485
Loss at iteration 920 : 0.0007402835763059556
Loss at iteration 930 : 0.0007420782931149006
Loss at iteration 940 : 0.0003679046640172601
Loss at iteration 950 : 0.0026178834959864616
Loss at iteration 960 : 0.002728586085140705
Loss at iteration 970 : 0.00032108076266013086
Loss at iteration 980 : 0.00015897481353022158
Loss at iteration 990 : 0.0009396421955898404
Loss at iteration 1000 : 0.00011608465138124302
Loss at iteration 1010 : 0.00017447464051656425
Loss at iteration 1020 : 0.00024132145335897803
Loss at iteration 1030 : 5.2369734476087615e-05
Loss at iteration 1040 : 0.0005371763836592436
Loss at iteration 1050 : 0.002884361194446683
Loss at iteration 1060 : 9.931321255862713e-05
Loss at iteration 1070 : 0.0028614639304578304
Loss at iteration 1080 : 0.00032679986907169223
Loss at iteration 1090 : 0.000361199548933655
Loss at iteration 1100 : 0.0001270284119527787
Loss at iteration 1110 : 0.004656617064028978
Loss at iteration 1120 : 0.0002142441226169467
Loss at iteration 1130 : 0.00033798947697505355
Loss at iteration 1140 : 0.00014208258653525263
Loss at iteration 1150 : 0.0016258565010502934
Loss at iteration 1160 : 0.0004173820198047906
Loss at iteration 1170 : 0.0025462398771196604
Loss at iteration 1180 : 0.0001021251009660773
Loss at iteration 1190 : 0.0005078527610749006
Loss at iteration 1200 : 0.00017969062901102006
Loss at iteration 1210 : 0.00029918079962953925
Loss at iteration 1220 : 0.003412133315578103
Loss at iteration 1230 : 0.0023805927485227585
Loss at iteration 1240 : 0.0015328829176723957
Loss at iteration 1250 : 0.006778632756322622
Loss at iteration 1260 : 0.0036726135294884443
Loss at iteration 1270 : 0.0007819279562681913
Loss at iteration 1280 : 0.0033747656270861626
Loss at iteration 1290 : 0.0003538975724950433
Loss at iteration 1300 : 0.0002537196269258857
Loss at iteration 1310 : 0.00019523433002177626
Loss at iteration 1320 : 0.00011467600415926427
Loss at iteration 1330 : 0.0001318079448537901
Loss at iteration 1340 : 0.0006360586266964674
Loss at iteration 1350 : 0.0001998207881115377
Loss at iteration 1360 : 0.0002354720199946314
Loss at iteration 1370 : 0.00036887405440211296
Loss at iteration 1380 : 0.00019412057008594275
Loss at iteration 1390 : 0.0002482209529262036
Loss at iteration 1400 : 0.00022813482792116702
Loss at iteration 1410 : 0.002638451522216201
Loss at iteration 1420 : 0.0005883127450942993
Loss at iteration 1430 : 0.0006425448227673769
Loss at iteration 1440 : 0.004841475747525692
Loss at iteration 1450 : 0.00011939430987695232
Loss at iteration 1460 : 0.0003143778012599796
Loss at iteration 1470 : 0.00028683748678304255
Loss at iteration 1480 : 0.001342535251751542
Loss at iteration 1490 : 0.00068286107853055
Loss at iteration 1500 : 0.00026126025477424264
Loss at iteration 1510 : 0.00026942352997139096
Loss at iteration 1520 : 0.0002518396941013634
Loss at iteration 1530 : 0.00021169177489355206
Loss at iteration 1540 : 0.0005817032651975751
Loss at iteration 1550 : 0.004178908187896013
Loss at iteration 1560 : 0.00040541187627241015
Loss at iteration 1570 : 6.812182255089283e-05
Loss at iteration 1580 : 0.00017622805899009109
Loss at iteration 1590 : 0.0021362192928791046
Loss at iteration 1600 : 0.002751346444711089
Loss at iteration 1610 : 0.0002959996636491269
Loss at iteration 1620 : 0.0004995216149836779
Loss at iteration 1630 : 0.00015965614875312895
Loss at iteration 1640 : 0.00559906754642725
Loss at iteration 1650 : 0.0002218543377239257
Loss at iteration 1660 : 0.00029315214487724006
Loss at iteration 1670 : 0.00041235401295125484
Loss at iteration 1680 : 0.0002976844261866063
Loss at iteration 1690 : 0.00010818881855811924
Loss at iteration 1700 : 0.0005202063475735486
Loss at iteration 1710 : 0.002765953540802002
Loss at iteration 1720 : 0.0020562168210744858
Loss at iteration 1730 : 0.0008079468971118331
Loss at iteration 1740 : 0.0016187919536605477
Loss at iteration 1750 : 7.424304203595966e-05
The SSIM Value is: 0.9843756023482604
The PSNR Value is: 46.439942219183834
the epoch is: 106
Loss at iteration 10 : 0.0006694511976093054
Loss at iteration 20 : 0.00047245973837561905
Loss at iteration 30 : 0.0005649663507938385
Loss at iteration 40 : 0.004179826471954584
Loss at iteration 50 : 0.0006430747453123331
Loss at iteration 60 : 0.0008722632192075253
Loss at iteration 70 : 0.0002949757326859981
Loss at iteration 80 : 0.00028575683245435357
Loss at iteration 90 : 0.00021441990975290537
Loss at iteration 100 : 0.00022264738800004125
Loss at iteration 110 : 0.00024839871912263334
Loss at iteration 120 : 0.0014528044266626239
Loss at iteration 130 : 0.0035030576400458813
Loss at iteration 140 : 0.0016005404759198427
Loss at iteration 150 : 0.0005641159950755537
Loss at iteration 160 : 3.142712375847623e-05
Loss at iteration 170 : 0.00016326345212291926
Loss at iteration 180 : 0.00024199564359150827
Loss at iteration 190 : 0.003081362694501877
Loss at iteration 200 : 0.0001360135938739404
Loss at iteration 210 : 0.0024485134053975344
Loss at iteration 220 : 0.005567529238760471
Loss at iteration 230 : 0.0021283025853335857
Loss at iteration 240 : 0.000298317929264158
Loss at iteration 250 : 0.00017314040451310575
Loss at iteration 260 : 0.00029647565679624677
Loss at iteration 270 : 9.289871377404779e-05
Loss at iteration 280 : 0.000179352326085791
Loss at iteration 290 : 0.00019599497318267822
Loss at iteration 300 : 0.00014165070024318993
Loss at iteration 310 : 0.0002560583525337279
Loss at iteration 320 : 0.00021119964367244393
Loss at iteration 330 : 0.00364832766354084
Loss at iteration 340 : 0.00021819808171130717
Loss at iteration 350 : 0.00015913535025902092
Loss at iteration 360 : 0.00014814009773544967
Loss at iteration 370 : 0.00022364742471836507
Loss at iteration 380 : 0.00010215963993687183
Loss at iteration 390 : 0.0023246589116752148
Loss at iteration 400 : 0.00428383331745863
Loss at iteration 410 : 0.00020141743880230933
Loss at iteration 420 : 0.0023793280124664307
Loss at iteration 430 : 0.00046274965279735625
Loss at iteration 440 : 7.817185542080551e-05
Loss at iteration 450 : 0.0004516914195846766
Loss at iteration 460 : 8.740431803744286e-05
Loss at iteration 470 : 7.944137178128585e-05
Loss at iteration 480 : 0.0025439017917960882
Loss at iteration 490 : 0.0005141353467479348
Loss at iteration 500 : 0.0035549760796129704
Loss at iteration 510 : 0.0002720204065553844
Loss at iteration 520 : 0.0006624123780056834
Loss at iteration 530 : 0.000139472060254775
Loss at iteration 540 : 5.460112515720539e-05
Loss at iteration 550 : 0.00011262201587669551
Loss at iteration 560 : 0.00020410152501426637
Loss at iteration 570 : 5.225931090535596e-05
Loss at iteration 580 : 0.00018181189079768956
Loss at iteration 590 : 0.00010109796858159825
Loss at iteration 600 : 0.00018201355123892426
Loss at iteration 610 : 0.00020198177662678063
Loss at iteration 620 : 0.0005387359415180981
Loss at iteration 630 : 0.00010140357335330918
Loss at iteration 640 : 0.0034347809851169586
Loss at iteration 650 : 0.0001530702575109899
Loss at iteration 660 : 0.0009074948029592633
Loss at iteration 670 : 0.00013297924306243658
Loss at iteration 680 : 0.002499423688277602
Loss at iteration 690 : 0.0004098395293112844
Loss at iteration 700 : 0.00041190587216988206
Loss at iteration 710 : 0.00016278681869152933
Loss at iteration 720 : 0.0003371457278262824
Loss at iteration 730 : 0.0003284270060248673
Loss at iteration 740 : 0.0004516851040534675
Loss at iteration 750 : 0.0011919345706701279
Loss at iteration 760 : 0.0020970359910279512
Loss at iteration 770 : 0.00015860411804169416
Loss at iteration 780 : 0.0065529667772352695
Loss at iteration 790 : 0.0003118634922429919
Loss at iteration 800 : 0.002326240297406912
Loss at iteration 810 : 0.0019928161054849625
Loss at iteration 820 : 0.0005149969947524369
Loss at iteration 830 : 0.0008230383973568678
Loss at iteration 840 : 0.0003561164194252342
Loss at iteration 850 : 0.00016045190568547696
Loss at iteration 860 : 0.00014522738638333976
Loss at iteration 870 : 0.0005073969368822873
Loss at iteration 880 : 0.0008877297514118254
Loss at iteration 890 : 0.0032038120552897453
Loss at iteration 900 : 0.00016176269855350256
Loss at iteration 910 : 0.0015170639380812645
Loss at iteration 920 : 0.000517555745318532
Loss at iteration 930 : 0.0008327824180014431
Loss at iteration 940 : 0.00016118038911372423
Loss at iteration 950 : 0.002260096138343215
Loss at iteration 960 : 0.00021081179147586226
Loss at iteration 970 : 0.0004156419017817825
Loss at iteration 980 : 0.0001329801743850112
Loss at iteration 990 : 0.00048308863188140094
Loss at iteration 1000 : 0.0029873147141188383
Loss at iteration 1010 : 0.004960513208061457
Loss at iteration 1020 : 0.0003201206272933632
Loss at iteration 1030 : 0.0005039538373239338
Loss at iteration 1040 : 0.00013691329513676465
Loss at iteration 1050 : 0.0020724693313241005
Loss at iteration 1060 : 0.00011748651741072536
Loss at iteration 1070 : 0.0001861999771790579
Loss at iteration 1080 : 0.001317509450018406
Loss at iteration 1090 : 0.0015724239638075233
Loss at iteration 1100 : 0.002115896437317133
Loss at iteration 1110 : 0.0005830783629789948
Loss at iteration 1120 : 0.005833134055137634
Loss at iteration 1130 : 7.839018508093432e-05
Loss at iteration 1140 : 0.0002827489224728197
Loss at iteration 1150 : 0.00014194936375133693
Loss at iteration 1160 : 0.00012269891158211976
Loss at iteration 1170 : 0.0015986048383638263
Loss at iteration 1180 : 0.0031103738583624363
Loss at iteration 1190 : 8.708398672752082e-05
Loss at iteration 1200 : 0.0025859843008220196
Loss at iteration 1210 : 0.0002594668185338378
Loss at iteration 1220 : 8.976911340141669e-05
Loss at iteration 1230 : 0.002101535676047206
Loss at iteration 1240 : 0.0007228848990052938
Loss at iteration 1250 : 0.0002216351276729256
Loss at iteration 1260 : 0.00048131204675883055
Loss at iteration 1270 : 0.002174168359488249
Loss at iteration 1280 : 0.0037956228479743004
Loss at iteration 1290 : 0.00035998449311591685
Loss at iteration 1300 : 0.00044280453585088253
Loss at iteration 1310 : 0.0003214540774933994
Loss at iteration 1320 : 0.00033817451912909746
Loss at iteration 1330 : 0.0018952907994389534
Loss at iteration 1340 : 0.002594918478280306
Loss at iteration 1350 : 5.9266152675263584e-05
Loss at iteration 1360 : 0.00011516420636326075
Loss at iteration 1370 : 0.0004698126867879182
Loss at iteration 1380 : 9.524207416689023e-05
Loss at iteration 1390 : 0.002833189442753792
Loss at iteration 1400 : 0.00015703379176557064
Loss at iteration 1410 : 0.00036009884206578135
Loss at iteration 1420 : 0.0012063917238265276
Loss at iteration 1430 : 0.00017385267710778862
Loss at iteration 1440 : 0.00029425640241242945
Loss at iteration 1450 : 0.001331497565843165
Loss at iteration 1460 : 0.0004341320018284023
Loss at iteration 1470 : 0.001263282960280776
Loss at iteration 1480 : 0.0018672957085072994
Loss at iteration 1490 : 0.0002055032819043845
Loss at iteration 1500 : 0.0002252002595923841
Loss at iteration 1510 : 0.0003597575705498457
Loss at iteration 1520 : 0.00010728667984949425
Loss at iteration 1530 : 0.0008202100871130824
Loss at iteration 1540 : 0.002530713565647602
Loss at iteration 1550 : 0.00019407055515330285
Loss at iteration 1560 : 0.00014932539488654584
Loss at iteration 1570 : 0.004859783686697483
Loss at iteration 1580 : 0.002439638366922736
Loss at iteration 1590 : 0.0021667792461812496
Loss at iteration 1600 : 0.0007294070674106479
Loss at iteration 1610 : 0.003141788300126791
Loss at iteration 1620 : 0.0009151157573796809
Loss at iteration 1630 : 0.00019121074001304805
Loss at iteration 1640 : 0.0004825678188353777
Loss at iteration 1650 : 0.0015507085481658578
Loss at iteration 1660 : 0.0007961142691783607
Loss at iteration 1670 : 0.00014177363482303917
Loss at iteration 1680 : 0.0003027596103493124
Loss at iteration 1690 : 0.0002421718672849238
Loss at iteration 1700 : 0.00013452323037199676
Loss at iteration 1710 : 0.00028909946558997035
Loss at iteration 1720 : 0.00023565307492390275
Loss at iteration 1730 : 0.001239802804775536
Loss at iteration 1740 : 0.0005355059402063489
Loss at iteration 1750 : 0.00041614071233198047
The SSIM Value is: 0.9835285405230417
The PSNR Value is: 46.514466972603145
the epoch is: 107
Loss at iteration 10 : 0.0001417363528162241
Loss at iteration 20 : 0.00040648423600941896
Loss at iteration 30 : 0.00034904625499621034
Loss at iteration 40 : 0.0036845190916210413
Loss at iteration 50 : 0.0003483111795503646
Loss at iteration 60 : 0.00010585406562313437
Loss at iteration 70 : 0.001018111128360033
Loss at iteration 80 : 0.0005638835718855262
Loss at iteration 90 : 0.00269263400696218
Loss at iteration 100 : 0.0015408212784677744
Loss at iteration 110 : 0.0003388596815057099
Loss at iteration 120 : 0.00019698028336279094
Loss at iteration 130 : 0.0003321841941215098
Loss at iteration 140 : 0.0009012154769152403
Loss at iteration 150 : 0.004191510379314423
Loss at iteration 160 : 0.0009873033268377185
Loss at iteration 170 : 0.00020218209829181433
Loss at iteration 180 : 0.0002767895348370075
Loss at iteration 190 : 0.0005052651977166533
Loss at iteration 200 : 0.004378270357847214
Loss at iteration 210 : 0.0002537630789447576
Loss at iteration 220 : 0.00021907687187194824
Loss at iteration 230 : 0.0002152492816094309
Loss at iteration 240 : 9.496013080934063e-05
Loss at iteration 250 : 0.00010670696792658418
Loss at iteration 260 : 0.0002541950671002269
Loss at iteration 270 : 0.0006611972348764539
Loss at iteration 280 : 0.00020836107432842255
Loss at iteration 290 : 0.0006328540039248765
Loss at iteration 300 : 0.00028384136385284364
Loss at iteration 310 : 5.056998270447366e-05
Loss at iteration 320 : 0.0005945309530943632
Loss at iteration 330 : 0.00042334364843554795
Loss at iteration 340 : 0.00032870692666620016
Loss at iteration 350 : 0.00040107552194967866
Loss at iteration 360 : 0.0004715546383522451
Loss at iteration 370 : 0.0002485248551238328
Loss at iteration 380 : 0.00015263157547451556
Loss at iteration 390 : 0.0005991713260300457
Loss at iteration 400 : 0.0002284095826325938
Loss at iteration 410 : 0.00028814555844292045
Loss at iteration 420 : 0.00013600099191535264
Loss at iteration 430 : 0.001002805307507515
Loss at iteration 440 : 0.007994634099304676
Loss at iteration 450 : 0.0001774712436599657
Loss at iteration 460 : 0.00011883061961270869
Loss at iteration 470 : 0.0003987018426414579
Loss at iteration 480 : 0.0002987523621413857
Loss at iteration 490 : 0.0004637561796698719
Loss at iteration 500 : 0.005342874210327864
Loss at iteration 510 : 0.002941494109109044
Loss at iteration 520 : 0.00034336847602389753
Loss at iteration 530 : 0.0002614760596770793
Loss at iteration 540 : 0.005202375818043947
Loss at iteration 550 : 0.0005436852225102484
Loss at iteration 560 : 0.0004426947270985693
Loss at iteration 570 : 8.90812007128261e-05
Loss at iteration 580 : 0.0007077157497406006
Loss at iteration 590 : 0.00017981049313675612
Loss at iteration 600 : 0.00033962310408242047
Loss at iteration 610 : 6.100569953559898e-05
Loss at iteration 620 : 0.000102892896393314
Loss at iteration 630 : 0.004422152880579233
Loss at iteration 640 : 0.0007059796480461955
Loss at iteration 650 : 0.0002478749956935644
Loss at iteration 660 : 0.00022502745559904724
Loss at iteration 670 : 8.466518193017691e-05
Loss at iteration 680 : 0.0023281974717974663
Loss at iteration 690 : 0.0006679623038507998
Loss at iteration 700 : 0.0041038342751562595
Loss at iteration 710 : 0.0001059469286701642
Loss at iteration 720 : 0.00030847068410366774
Loss at iteration 730 : 0.00035719614243134856
Loss at iteration 740 : 0.00011563855514395982
Loss at iteration 750 : 0.001084471819922328
Loss at iteration 760 : 0.000496577238664031
Loss at iteration 770 : 0.004175337962806225
Loss at iteration 780 : 7.897543400758877e-05
Loss at iteration 790 : 9.49511886574328e-05
Loss at iteration 800 : 0.0008581965230405331
Loss at iteration 810 : 0.00022551792790181935
Loss at iteration 820 : 0.00024631619453430176
Loss at iteration 830 : 8.596655970904976e-05
Loss at iteration 840 : 0.0018078208668157458
Loss at iteration 850 : 8.982772123999894e-05
Loss at iteration 860 : 0.00012972175318282098
Loss at iteration 870 : 0.00034401746233925223
Loss at iteration 880 : 0.0001554533955641091
Loss at iteration 890 : 0.0005476317601278424
Loss at iteration 900 : 0.0015558014856651425
Loss at iteration 910 : 0.000513622013386339
Loss at iteration 920 : 0.0074745542369782925
Loss at iteration 930 : 0.0002829691511578858
Loss at iteration 940 : 0.001692869351245463
Loss at iteration 950 : 0.0007525585824623704
Loss at iteration 960 : 0.0002848307485692203
Loss at iteration 970 : 6.104233034420758e-05
Loss at iteration 980 : 0.004071488045156002
Loss at iteration 990 : 0.0017748386599123478
Loss at iteration 1000 : 0.003347819671034813
Loss at iteration 1010 : 0.0003807201574090868
Loss at iteration 1020 : 9.799143299460411e-05
Loss at iteration 1030 : 0.0005764061352238059
Loss at iteration 1040 : 0.002583898138254881
Loss at iteration 1050 : 0.00033079960849136114
Loss at iteration 1060 : 0.00011843189713545144
Loss at iteration 1070 : 0.0004550043377093971
Loss at iteration 1080 : 3.8373844290617853e-05
Loss at iteration 1090 : 0.0002757633337751031
Loss at iteration 1100 : 0.0072171674109995365
Loss at iteration 1110 : 0.0022595797199755907
Loss at iteration 1120 : 0.0009036400588229299
Loss at iteration 1130 : 0.0005516150267794728
Loss at iteration 1140 : 0.004428637679666281
Loss at iteration 1150 : 0.00027621720801107585
Loss at iteration 1160 : 0.00017431580636184663
Loss at iteration 1170 : 0.0003452857490628958
Loss at iteration 1180 : 0.0015735395718365908
Loss at iteration 1190 : 0.0012908830540254712
Loss at iteration 1200 : 0.0010068160481750965
Loss at iteration 1210 : 0.0003400676650926471
Loss at iteration 1220 : 0.00017600040882825851
Loss at iteration 1230 : 0.0008278820896521211
Loss at iteration 1240 : 0.001424999674782157
Loss at iteration 1250 : 0.0002585226611699909
Loss at iteration 1260 : 0.0001447324175387621
Loss at iteration 1270 : 0.0013821156462654471
Loss at iteration 1280 : 0.003335891291499138
Loss at iteration 1290 : 0.003147420007735491
Loss at iteration 1300 : 0.00014910769823472947
Loss at iteration 1310 : 0.0030023795552551746
Loss at iteration 1320 : 0.0001002522258204408
Loss at iteration 1330 : 0.0009492848184891045
Loss at iteration 1340 : 0.0003831566427834332
Loss at iteration 1350 : 0.0003324798890389502
Loss at iteration 1360 : 0.0015642717480659485
Loss at iteration 1370 : 9.389650949742645e-05
Loss at iteration 1380 : 0.0004244704614393413
Loss at iteration 1390 : 0.0006265765405260026
Loss at iteration 1400 : 0.0014552655629813671
Loss at iteration 1410 : 0.0013490805868059397
Loss at iteration 1420 : 0.0038780122995376587
Loss at iteration 1430 : 0.005967169534415007
Loss at iteration 1440 : 0.0027875788509845734
Loss at iteration 1450 : 0.0012503924081102014
Loss at iteration 1460 : 0.00023920295643620193
Loss at iteration 1470 : 0.0007135830819606781
Loss at iteration 1480 : 0.0006391496281139553
Loss at iteration 1490 : 0.0002613918040879071
Loss at iteration 1500 : 0.0004612422490026802
Loss at iteration 1510 : 0.0004430954286362976
Loss at iteration 1520 : 0.00010139941150555387
Loss at iteration 1530 : 0.0030185854993760586
Loss at iteration 1540 : 0.000363010389264673
Loss at iteration 1550 : 0.00032870814902707934
Loss at iteration 1560 : 0.0008032856276258826
Loss at iteration 1570 : 0.004912546370178461
Loss at iteration 1580 : 0.00035622002906166017
Loss at iteration 1590 : 0.0008627320639789104
Loss at iteration 1600 : 0.00010903729707933962
Loss at iteration 1610 : 0.001054876483976841
Loss at iteration 1620 : 0.0020094765350222588
Loss at iteration 1630 : 0.00019030217663384974
Loss at iteration 1640 : 0.0004523815878201276
Loss at iteration 1650 : 0.0056037018075585365
Loss at iteration 1660 : 0.0024559260345995426
Loss at iteration 1670 : 0.001143640256486833
Loss at iteration 1680 : 0.00017771270358934999
Loss at iteration 1690 : 0.00010219329124083742
Loss at iteration 1700 : 4.5781904191244394e-05
Loss at iteration 1710 : 0.0009302707621827722
Loss at iteration 1720 : 0.0007456233142875135
Loss at iteration 1730 : 0.0005615361733362079
Loss at iteration 1740 : 0.0006932675023563206
Loss at iteration 1750 : 0.00022214157797861844
The SSIM Value is: 0.9803570249007136
The PSNR Value is: 46.495007359508904
the epoch is: 108
Loss at iteration 10 : 0.0007637626258656383
Loss at iteration 20 : 0.00014280476898420602
Loss at iteration 30 : 0.00012579937174450606
Loss at iteration 40 : 0.0008896997314877808
Loss at iteration 50 : 0.0023911716416478157
Loss at iteration 60 : 0.00017593143275007606
Loss at iteration 70 : 0.00013288389891386032
Loss at iteration 80 : 0.001751535921357572
Loss at iteration 90 : 0.0005384603864513338
Loss at iteration 100 : 0.00016325565229635686
Loss at iteration 110 : 5.778031481895596e-05
Loss at iteration 120 : 0.0001607897283975035
Loss at iteration 130 : 0.003278381424024701
Loss at iteration 140 : 0.002020162995904684
Loss at iteration 150 : 0.0008802118245512247
Loss at iteration 160 : 0.002324494067579508
Loss at iteration 170 : 0.00011358378105796874
Loss at iteration 180 : 0.00013782232417725027
Loss at iteration 190 : 0.0023213133681565523
Loss at iteration 200 : 5.0789760280167684e-05
Loss at iteration 210 : 0.00043438305146992207
Loss at iteration 220 : 0.0003398953704163432
Loss at iteration 230 : 0.00029059109510853887
Loss at iteration 240 : 0.000650476198643446
Loss at iteration 250 : 0.0001073408784577623
Loss at iteration 260 : 0.00043223623652011156
Loss at iteration 270 : 0.0034062995109707117
Loss at iteration 280 : 0.0003566447994671762
Loss at iteration 290 : 0.0030690839048475027
Loss at iteration 300 : 0.0002665871870703995
Loss at iteration 310 : 0.0009937076829373837
Loss at iteration 320 : 0.000524410221260041
Loss at iteration 330 : 8.623631583759561e-05
Loss at iteration 340 : 0.0001932113809743896
Loss at iteration 350 : 0.0002083387807942927
Loss at iteration 360 : 0.0001517480704933405
Loss at iteration 370 : 0.0005154490354470909
Loss at iteration 380 : 7.039825868560001e-05
Loss at iteration 390 : 0.00043089757673442364
Loss at iteration 400 : 0.002071133116260171
Loss at iteration 410 : 0.001957009080797434
Loss at iteration 420 : 0.002639205427840352
Loss at iteration 430 : 0.0002189657825510949
Loss at iteration 440 : 0.00022180439555086195
Loss at iteration 450 : 0.00012908670760225505
Loss at iteration 460 : 0.005029691383242607
Loss at iteration 470 : 0.0005271537811495364
Loss at iteration 480 : 0.002890301402658224
Loss at iteration 490 : 0.0011657488066703081
Loss at iteration 500 : 0.0007462200010195374
Loss at iteration 510 : 0.00011270868708379567
Loss at iteration 520 : 0.0026931236498057842
Loss at iteration 530 : 0.0004931756411679089
Loss at iteration 540 : 0.002827635733410716
Loss at iteration 550 : 0.0003037556307390332
Loss at iteration 560 : 0.001402197522111237
Loss at iteration 570 : 0.001687716576270759
Loss at iteration 580 : 0.0013623104896396399
Loss at iteration 590 : 0.00019688170868903399
Loss at iteration 600 : 0.0002938519464805722
Loss at iteration 610 : 0.00014704825298395008
Loss at iteration 620 : 0.009486165829002857
Loss at iteration 630 : 0.002412874484434724
Loss at iteration 640 : 0.00014742399798706174
Loss at iteration 650 : 0.0006076506106182933
Loss at iteration 660 : 0.0006686669075861573
Loss at iteration 670 : 0.00012712128227576613
Loss at iteration 680 : 0.0027491552755236626
Loss at iteration 690 : 0.00016345585754606873
Loss at iteration 700 : 0.0008240422466769814
Loss at iteration 710 : 5.231717659626156e-05
Loss at iteration 720 : 0.000660173362120986
Loss at iteration 730 : 0.0001814946299418807
Loss at iteration 740 : 0.00247219973243773
Loss at iteration 750 : 0.000266926916083321
Loss at iteration 760 : 0.0034938976168632507
Loss at iteration 770 : 0.0011364166857674718
Loss at iteration 780 : 0.000509896781295538
Loss at iteration 790 : 0.00019905061344616115
Loss at iteration 800 : 0.006306825205683708
Loss at iteration 810 : 0.00019317619444336742
Loss at iteration 820 : 0.0003428768250159919
Loss at iteration 830 : 0.0017516396474093199
Loss at iteration 840 : 0.0006180625641718507
Loss at iteration 850 : 0.00010897489846684039
Loss at iteration 860 : 0.0007881842320784926
Loss at iteration 870 : 0.00014484018902294338
Loss at iteration 880 : 7.687291508773342e-05
Loss at iteration 890 : 0.0005223380867391825
Loss at iteration 900 : 0.0025393981486558914
Loss at iteration 910 : 7.618548261234537e-05
Loss at iteration 920 : 0.00024932288215495646
Loss at iteration 930 : 4.3781175918411463e-05
Loss at iteration 940 : 0.003496471093967557
Loss at iteration 950 : 0.001593911089003086
Loss at iteration 960 : 0.00016954028978943825
Loss at iteration 970 : 0.0010141974780708551
Loss at iteration 980 : 0.0016569072613492608
Loss at iteration 990 : 5.9896941820625216e-05
Loss at iteration 1000 : 0.00011568093032110482
Loss at iteration 1010 : 0.0007839308818802238
Loss at iteration 1020 : 0.00017479941016063094
Loss at iteration 1030 : 0.0007503083324991167
Loss at iteration 1040 : 0.0012462176382541656
Loss at iteration 1050 : 0.00017674220725893974
Loss at iteration 1060 : 0.00021100087906233966
Loss at iteration 1070 : 0.0004885800299234688
Loss at iteration 1080 : 0.0029091702308505774
Loss at iteration 1090 : 0.00028301277779974043
Loss at iteration 1100 : 0.0002705658844206482
Loss at iteration 1110 : 0.00020951488113496453
Loss at iteration 1120 : 0.004707608371973038
Loss at iteration 1130 : 0.00011390855797799304
Loss at iteration 1140 : 0.0007702792063355446
Loss at iteration 1150 : 0.0008695803117007017
Loss at iteration 1160 : 0.0001892252912512049
Loss at iteration 1170 : 0.00014743409701623023
Loss at iteration 1180 : 0.0020273420959711075
Loss at iteration 1190 : 0.0004131798632442951
Loss at iteration 1200 : 0.003914386499673128
Loss at iteration 1210 : 0.0006580150220543146
Loss at iteration 1220 : 0.003038539318367839
Loss at iteration 1230 : 0.0008487961022183299
Loss at iteration 1240 : 0.0006268203142099082
Loss at iteration 1250 : 0.0003027213679160923
Loss at iteration 1260 : 0.0003944112977478653
Loss at iteration 1270 : 0.0003898865543305874
Loss at iteration 1280 : 0.0019119451753795147
Loss at iteration 1290 : 0.00017803881200961769
Loss at iteration 1300 : 0.0028457301668822765
Loss at iteration 1310 : 0.00024344227858819067
Loss at iteration 1320 : 0.0007109578000381589
Loss at iteration 1330 : 0.00020572435460053384
Loss at iteration 1340 : 0.0002151917724404484
Loss at iteration 1350 : 0.00022299611009657383
Loss at iteration 1360 : 0.0019209894817322493
Loss at iteration 1370 : 0.00016950453573372215
Loss at iteration 1380 : 0.00017209051293320954
Loss at iteration 1390 : 9.158585453405976e-05
Loss at iteration 1400 : 7.181787805166095e-05
Loss at iteration 1410 : 3.080032911384478e-05
Loss at iteration 1420 : 0.00023818822228349745
Loss at iteration 1430 : 0.0028877188451588154
Loss at iteration 1440 : 0.0005938159883953631
Loss at iteration 1450 : 0.001569840358570218
Loss at iteration 1460 : 0.0001357132277917117
Loss at iteration 1470 : 0.0023345244117081165
Loss at iteration 1480 : 0.001388931181281805
Loss at iteration 1490 : 7.696773536736146e-05
Loss at iteration 1500 : 0.0002742621873039752
Loss at iteration 1510 : 8.986922330223024e-05
Loss at iteration 1520 : 4.900209023617208e-05
Loss at iteration 1530 : 0.001612069201655686
Loss at iteration 1540 : 0.00018656883912626654
Loss at iteration 1550 : 0.00012405612505972385
Loss at iteration 1560 : 0.0002240834292024374
Loss at iteration 1570 : 0.00016374870028812438
Loss at iteration 1580 : 0.0001250644272658974
Loss at iteration 1590 : 0.0004132436588406563
Loss at iteration 1600 : 0.00014144314627628773
Loss at iteration 1610 : 0.0004340236191637814
Loss at iteration 1620 : 0.004294571466743946
Loss at iteration 1630 : 0.0013518205378204584
Loss at iteration 1640 : 9.555699944030493e-05
Loss at iteration 1650 : 0.0006262105889618397
Loss at iteration 1660 : 0.00018824428843799978
Loss at iteration 1670 : 0.0003484941553324461
Loss at iteration 1680 : 0.00022061183699406683
Loss at iteration 1690 : 0.00024297040363308042
Loss at iteration 1700 : 0.0036258259788155556
Loss at iteration 1710 : 0.00027285117539577186
Loss at iteration 1720 : 0.00010710902279242873
Loss at iteration 1730 : 0.0037269301246851683
Loss at iteration 1740 : 0.0016183649422600865
Loss at iteration 1750 : 0.0009706512209959328
The SSIM Value is: 0.9828682347541339
The PSNR Value is: 46.58488795200633
the epoch is: 109
Loss at iteration 10 : 0.0010380549356341362
Loss at iteration 20 : 0.002478615380823612
Loss at iteration 30 : 0.001606523641385138
Loss at iteration 40 : 0.0002497788518667221
Loss at iteration 50 : 0.002025393070653081
Loss at iteration 60 : 0.0007246067398227751
Loss at iteration 70 : 0.00010905876843025908
Loss at iteration 80 : 0.000250147539190948
Loss at iteration 90 : 0.00020223832689225674
Loss at iteration 100 : 0.00013666276936419308
Loss at iteration 110 : 0.0056090462021529675
Loss at iteration 120 : 0.009036483243107796
Loss at iteration 130 : 0.00022640074894297868
Loss at iteration 140 : 0.00016552938905078918
Loss at iteration 150 : 0.00016420180327259004
Loss at iteration 160 : 0.00014234991976991296
Loss at iteration 170 : 0.0017066647997125983
Loss at iteration 180 : 0.0004052158910781145
Loss at iteration 190 : 0.00048653376870788634
Loss at iteration 200 : 0.00013203035632614046
Loss at iteration 210 : 5.0854967412305996e-05
Loss at iteration 220 : 5.205197521718219e-05
Loss at iteration 230 : 0.0008747786050662398
Loss at iteration 240 : 8.841023372951895e-05
Loss at iteration 250 : 0.001104826107621193
Loss at iteration 260 : 0.00022047912352718413
Loss at iteration 270 : 0.00014619523426517844
Loss at iteration 280 : 0.00036192889092490077
Loss at iteration 290 : 0.0006644558743573725
Loss at iteration 300 : 0.0010904899099841714
Loss at iteration 310 : 0.0001904980163089931
Loss at iteration 320 : 0.0021146785002201796
Loss at iteration 330 : 0.0010468725813552737
Loss at iteration 340 : 0.00021423684665933251
Loss at iteration 350 : 0.00010019565524999052
Loss at iteration 360 : 0.0007493461016565561
Loss at iteration 370 : 0.0026964107528328896
Loss at iteration 380 : 0.0003233607276342809
Loss at iteration 390 : 0.0007323895115405321
Loss at iteration 400 : 0.003954591695219278
Loss at iteration 410 : 0.0020078038796782494
Loss at iteration 420 : 0.0019462569616734982
Loss at iteration 430 : 0.0008301740745082498
Loss at iteration 440 : 0.0014743604697287083
Loss at iteration 450 : 0.0054913414642214775
Loss at iteration 460 : 0.0022469735704362392
Loss at iteration 470 : 0.0006395507953129709
Loss at iteration 480 : 0.0006157825700938702
Loss at iteration 490 : 0.0007958622882142663
Loss at iteration 500 : 0.0004279372515156865
Loss at iteration 510 : 0.0007101952796801925
Loss at iteration 520 : 0.0002429969608783722
Loss at iteration 530 : 0.00257375231012702
Loss at iteration 540 : 0.0015406138263642788
Loss at iteration 550 : 0.00012545273057185113
Loss at iteration 560 : 0.0031891297549009323
Loss at iteration 570 : 0.00016600295202806592
Loss at iteration 580 : 0.00010201889381278306
Loss at iteration 590 : 0.000178089554538019
Loss at iteration 600 : 7.47009544284083e-05
Loss at iteration 610 : 0.00033294761669822037
Loss at iteration 620 : 0.0005041046533733606
Loss at iteration 630 : 0.00043694593477994204
Loss at iteration 640 : 0.00016617256915196776
Loss at iteration 650 : 3.3547767088748515e-05
Loss at iteration 660 : 0.0003618063637986779
Loss at iteration 670 : 0.0004540358786471188
Loss at iteration 680 : 9.20184247661382e-05
Loss at iteration 690 : 0.00047421656199730933
Loss at iteration 700 : 0.00017084699356928468
Loss at iteration 710 : 0.00011618623830145225
Loss at iteration 720 : 0.0007618952076882124
Loss at iteration 730 : 0.005692809820175171
Loss at iteration 740 : 0.0012685039546340704
Loss at iteration 750 : 5.2414154197322205e-05
Loss at iteration 760 : 0.0002295018930453807
Loss at iteration 770 : 0.0003033944813068956
Loss at iteration 780 : 0.003628616686910391
Loss at iteration 790 : 0.004443292506039143
Loss at iteration 800 : 5.2719362429343164e-05
Loss at iteration 810 : 0.00010558390931691974
Loss at iteration 820 : 0.0002597616985440254
Loss at iteration 830 : 0.00020189740462228656
Loss at iteration 840 : 0.0006547286175191402
Loss at iteration 850 : 0.0010691488860175014
Loss at iteration 860 : 0.0008727075764909387
Loss at iteration 870 : 0.0034951174166053534
Loss at iteration 880 : 0.0006682344246655703
Loss at iteration 890 : 0.005190120078623295
Loss at iteration 900 : 0.00019291795615572482
Loss at iteration 910 : 0.00011694449494825676
Loss at iteration 920 : 0.0027259942144155502
Loss at iteration 930 : 0.0001896336325444281
Loss at iteration 940 : 0.0003182219807058573
Loss at iteration 950 : 0.0006656036130152643
Loss at iteration 960 : 0.00021304520487319678
Loss at iteration 970 : 0.003627836238592863
Loss at iteration 980 : 0.0034850400406867266
Loss at iteration 990 : 0.0008894903003238142
Loss at iteration 1000 : 0.00030866742599755526
Loss at iteration 1010 : 0.00017730552644934505
Loss at iteration 1020 : 0.0004383052000775933
Loss at iteration 1030 : 0.00011058542440878227
Loss at iteration 1040 : 6.743760604877025e-05
Loss at iteration 1050 : 0.0001059607311617583
Loss at iteration 1060 : 0.000141127486131154
Loss at iteration 1070 : 0.0003743702545762062
Loss at iteration 1080 : 0.00026962527772411704
Loss at iteration 1090 : 0.0001510055735707283
Loss at iteration 1100 : 0.00013975935871712863
Loss at iteration 1110 : 0.00153124809730798
Loss at iteration 1120 : 0.0006884114118292928
Loss at iteration 1130 : 0.0017252594698220491
Loss at iteration 1140 : 0.0022950395941734314
Loss at iteration 1150 : 0.0002697824384085834
Loss at iteration 1160 : 0.0007537184283137321
Loss at iteration 1170 : 0.0003516677825246006
Loss at iteration 1180 : 0.00013357131683733314
Loss at iteration 1190 : 0.00035990000469610095
Loss at iteration 1200 : 0.0025162252131849527
Loss at iteration 1210 : 0.007068961393088102
Loss at iteration 1220 : 0.0013403900666162372
Loss at iteration 1230 : 0.0005679532769136131
Loss at iteration 1240 : 2.062211569864303e-05
Loss at iteration 1250 : 0.0020441918168216944
Loss at iteration 1260 : 0.00017231761012226343
Loss at iteration 1270 : 0.003446375485509634
Loss at iteration 1280 : 0.0005517943645827472
Loss at iteration 1290 : 0.00023434162721969187
Loss at iteration 1300 : 0.0005098373512737453
Loss at iteration 1310 : 0.0003035446861758828
Loss at iteration 1320 : 0.005427751690149307
Loss at iteration 1330 : 0.0014418390346691012
Loss at iteration 1340 : 0.00018334196647629142
Loss at iteration 1350 : 0.0012886116746813059
Loss at iteration 1360 : 0.0018072602106258273
Loss at iteration 1370 : 0.0002969896304421127
Loss at iteration 1380 : 0.00024401358678005636
Loss at iteration 1390 : 0.00019821047317236662
Loss at iteration 1400 : 0.0024837919045239687
Loss at iteration 1410 : 0.0013258045073598623
Loss at iteration 1420 : 0.0006278548971749842
Loss at iteration 1430 : 0.0029834953602403402
Loss at iteration 1440 : 0.001094328355975449
Loss at iteration 1450 : 0.0019637146033346653
Loss at iteration 1460 : 4.024631198262796e-05
Loss at iteration 1470 : 0.0006627198890782893
Loss at iteration 1480 : 0.0015922158490866423
Loss at iteration 1490 : 0.0002826864365488291
Loss at iteration 1500 : 0.00014304430806078017
Loss at iteration 1510 : 0.000487529207020998
Loss at iteration 1520 : 0.0038865713868290186
Loss at iteration 1530 : 0.0002977025287691504
Loss at iteration 1540 : 0.00031841546297073364
Loss at iteration 1550 : 0.00029268075013533235
Loss at iteration 1560 : 0.0032060849480330944
Loss at iteration 1570 : 0.00038961617974564433
Loss at iteration 1580 : 0.0003391471691429615
Loss at iteration 1590 : 0.001162329688668251
Loss at iteration 1600 : 0.0002543226582929492
Loss at iteration 1610 : 0.0025659967213869095
Loss at iteration 1620 : 0.00015789770986884832
Loss at iteration 1630 : 0.0020547800231724977
Loss at iteration 1640 : 9.739660163177177e-05
Loss at iteration 1650 : 0.0011624253820627928
Loss at iteration 1660 : 0.0013212270569056273
Loss at iteration 1670 : 0.00046095685684122145
Loss at iteration 1680 : 0.0001434489240637049
Loss at iteration 1690 : 0.0009866644395515323
Loss at iteration 1700 : 0.0011742791393771768
Loss at iteration 1710 : 0.00017561999266035855
Loss at iteration 1720 : 0.0001592380867805332
Loss at iteration 1730 : 0.0007367582875303924
Loss at iteration 1740 : 0.00020541923004202545
Loss at iteration 1750 : 0.0002763425000011921
The SSIM Value is: 0.984198059279488
The PSNR Value is: 45.91587885465916
the epoch is: 110
Loss at iteration 10 : 0.00026347400853410363
Loss at iteration 20 : 0.0008057313971221447
Loss at iteration 30 : 0.0006337672821246088
Loss at iteration 40 : 0.00020751550619024783
Loss at iteration 50 : 0.0001548918808111921
Loss at iteration 60 : 0.0003642427618615329
Loss at iteration 70 : 0.004068741109222174
Loss at iteration 80 : 0.0003654530446510762
Loss at iteration 90 : 0.00021961855236440897
Loss at iteration 100 : 0.00042830666643567383
Loss at iteration 110 : 0.004189265891909599
Loss at iteration 120 : 0.0005197543068788946
Loss at iteration 130 : 0.0012287955032661557
Loss at iteration 140 : 0.00030959039577282965
Loss at iteration 150 : 0.002893295371904969
Loss at iteration 160 : 9.857949044089764e-05
Loss at iteration 170 : 0.00267620338127017
Loss at iteration 180 : 0.0025122773367911577
Loss at iteration 190 : 0.0003410058852750808
Loss at iteration 200 : 0.00027751881862059236
Loss at iteration 210 : 0.0005120310815982521
Loss at iteration 220 : 0.0006196137983351946
Loss at iteration 230 : 0.0004604891873896122
Loss at iteration 240 : 0.0009752332116477191
Loss at iteration 250 : 0.0007580792298540473
Loss at iteration 260 : 0.0001704269234323874
Loss at iteration 270 : 0.0002624953049235046
Loss at iteration 280 : 0.00030638897442258894
Loss at iteration 290 : 0.0008610612130723894
Loss at iteration 300 : 0.0002953869989141822
Loss at iteration 310 : 0.0009217194747179747
Loss at iteration 320 : 0.004592566285282373
Loss at iteration 330 : 0.0032198054250329733
Loss at iteration 340 : 0.00044811266707256436
Loss at iteration 350 : 0.0005394452018663287
Loss at iteration 360 : 0.00017106541781686246
Loss at iteration 370 : 7.109405123628676e-05
Loss at iteration 380 : 0.0015763913979753852
Loss at iteration 390 : 0.0003778153331950307
Loss at iteration 400 : 0.00017308503447566181
Loss at iteration 410 : 0.0003562237834557891
Loss at iteration 420 : 0.0038471962325274944
Loss at iteration 430 : 0.0009484326583333313
Loss at iteration 440 : 9.106135257752612e-05
Loss at iteration 450 : 0.00015415201778523624
Loss at iteration 460 : 0.0005180768785066903
Loss at iteration 470 : 0.0033512506633996964
Loss at iteration 480 : 0.00027277204208076
Loss at iteration 490 : 0.0006328448071144521
Loss at iteration 500 : 0.0033549342770129442
Loss at iteration 510 : 0.0007592531037516892
Loss at iteration 520 : 0.00040429941145703197
Loss at iteration 530 : 5.420980232884176e-05
Loss at iteration 540 : 0.0026840607170015574
Loss at iteration 550 : 0.000345391861628741
Loss at iteration 560 : 0.000832844409160316
Loss at iteration 570 : 0.0002389890723861754
Loss at iteration 580 : 0.0002134682727046311
Loss at iteration 590 : 0.005511992145329714
Loss at iteration 600 : 0.0010118326172232628
Loss at iteration 610 : 0.00023903830151539296
Loss at iteration 620 : 0.0004724492318928242
Loss at iteration 630 : 6.20923747192137e-05
Loss at iteration 640 : 8.62568776938133e-05
Loss at iteration 650 : 0.0016804281622171402
Loss at iteration 660 : 0.00231083738617599
Loss at iteration 670 : 0.0004632967757061124
Loss at iteration 680 : 0.0016252418281510472
Loss at iteration 690 : 0.0001628250174690038
Loss at iteration 700 : 0.0014776948373764753
Loss at iteration 710 : 0.0006259649526327848
Loss at iteration 720 : 0.00016313162632286549
Loss at iteration 730 : 0.0009456549305468798
Loss at iteration 740 : 0.0025264336727559566
Loss at iteration 750 : 0.0004649205948226154
Loss at iteration 760 : 6.0027334257029e-05
Loss at iteration 770 : 0.0008379752980545163
Loss at iteration 780 : 0.0007532211020588875
Loss at iteration 790 : 0.004518800415098667
Loss at iteration 800 : 0.00032254611141979694
Loss at iteration 810 : 0.003686880925670266
Loss at iteration 820 : 0.003082399722188711
Loss at iteration 830 : 0.0007318094721995294
Loss at iteration 840 : 0.0004266019386705011
Loss at iteration 850 : 0.00019241549307480454
Loss at iteration 860 : 0.0004537467611953616
Loss at iteration 870 : 0.00012643708032555878
Loss at iteration 880 : 0.0005774247110821307
Loss at iteration 890 : 0.0003493645344860852
Loss at iteration 900 : 0.00019162586249876767
Loss at iteration 910 : 0.00014589124475605786
Loss at iteration 920 : 0.00035024661337956786
Loss at iteration 930 : 0.001732826349325478
Loss at iteration 940 : 0.0001719833235256374
Loss at iteration 950 : 0.00013722128642257303
Loss at iteration 960 : 0.0011884727282449603
Loss at iteration 970 : 0.0009301153477281332
Loss at iteration 980 : 0.004808914847671986
Loss at iteration 990 : 0.005515964701771736
Loss at iteration 1000 : 9.883419261313975e-05
Loss at iteration 1010 : 0.00015315963537432253
Loss at iteration 1020 : 6.242441304493695e-05
Loss at iteration 1030 : 0.00017845431284513324
Loss at iteration 1040 : 0.0002796997723635286
Loss at iteration 1050 : 0.00014233568799681962
Loss at iteration 1060 : 0.0007076528272591531
Loss at iteration 1070 : 0.00010121501691173762
Loss at iteration 1080 : 0.0006436469266191125
Loss at iteration 1090 : 0.00034215982304885983
Loss at iteration 1100 : 0.001354551175609231
Loss at iteration 1110 : 9.366690210299566e-05
Loss at iteration 1120 : 0.002074026968330145
Loss at iteration 1130 : 0.000388267042580992
Loss at iteration 1140 : 0.00027876076637767255
Loss at iteration 1150 : 6.736301293130964e-05
Loss at iteration 1160 : 0.00032808457035571337
Loss at iteration 1170 : 0.00020229397341609
Loss at iteration 1180 : 0.00019415239512454718
Loss at iteration 1190 : 0.00014186689804773778
Loss at iteration 1200 : 0.00011942484707105905
Loss at iteration 1210 : 0.0004840244073420763
Loss at iteration 1220 : 0.002688442124053836
Loss at iteration 1230 : 0.00010707920591812581
Loss at iteration 1240 : 0.0011580507270991802
Loss at iteration 1250 : 0.0001111202291212976
Loss at iteration 1260 : 0.00011892192560480908
Loss at iteration 1270 : 8.801960939308628e-05
Loss at iteration 1280 : 0.00013099088391754776
Loss at iteration 1290 : 0.00010192901390837505
Loss at iteration 1300 : 0.00010229945473838598
Loss at iteration 1310 : 0.00020619836868718266
Loss at iteration 1320 : 0.001819825847633183
Loss at iteration 1330 : 0.00011347299005137756
Loss at iteration 1340 : 0.0014269099337980151
Loss at iteration 1350 : 0.00010729085624916479
Loss at iteration 1360 : 0.00045080750714987516
Loss at iteration 1370 : 0.0003204493841622025
Loss at iteration 1380 : 0.0033924460876733065
Loss at iteration 1390 : 7.94929001131095e-05
Loss at iteration 1400 : 0.000491953338496387
Loss at iteration 1410 : 0.0002482160634826869
Loss at iteration 1420 : 0.0028492165729403496
Loss at iteration 1430 : 0.003990519791841507
Loss at iteration 1440 : 0.00022005074424669147
Loss at iteration 1450 : 0.00019284023437649012
Loss at iteration 1460 : 0.003184370929375291
Loss at iteration 1470 : 0.003694647690281272
Loss at iteration 1480 : 0.0005458648083731532
Loss at iteration 1490 : 0.00022808974608778954
Loss at iteration 1500 : 0.002009585266932845
Loss at iteration 1510 : 0.0003744355635717511
Loss at iteration 1520 : 0.0004544261610135436
Loss at iteration 1530 : 0.002839625347405672
Loss at iteration 1540 : 0.0005853151669725776
Loss at iteration 1550 : 0.00011830018775071949
Loss at iteration 1560 : 0.0008166588959284127
Loss at iteration 1570 : 0.00013352166570257396
Loss at iteration 1580 : 0.006147227715700865
Loss at iteration 1590 : 0.0028217604849487543
Loss at iteration 1600 : 0.0001761059247655794
Loss at iteration 1610 : 0.0002988050691783428
Loss at iteration 1620 : 7.134721818147227e-05
Loss at iteration 1630 : 0.00011497062223497778
Loss at iteration 1640 : 0.0006676333723589778
Loss at iteration 1650 : 0.0021754226181656122
Loss at iteration 1660 : 0.00015822055866010487
Loss at iteration 1670 : 0.00017741286137606949
Loss at iteration 1680 : 0.0003604142111726105
Loss at iteration 1690 : 0.0003325121651869267
Loss at iteration 1700 : 0.00031540868803858757
Loss at iteration 1710 : 0.0012681109365075827
Loss at iteration 1720 : 0.00018151225231122226
Loss at iteration 1730 : 7.355106208706275e-05
Loss at iteration 1740 : 0.002958223456516862
Loss at iteration 1750 : 0.00018127073417417705
The SSIM Value is: 0.982107642726226
The PSNR Value is: 46.52448148769429
the epoch is: 111
Loss at iteration 10 : 0.001096673309803009
Loss at iteration 20 : 0.001822223304770887
Loss at iteration 30 : 0.0018801451660692692
Loss at iteration 40 : 0.0005473221535794437
Loss at iteration 50 : 9.114770364249125e-05
Loss at iteration 60 : 0.00042296259198337793
Loss at iteration 70 : 0.0001952626626007259
Loss at iteration 80 : 0.00011286917288089171
Loss at iteration 90 : 0.0002410507295280695
Loss at iteration 100 : 0.00024023382866289467
Loss at iteration 110 : 0.00030467784381471574
Loss at iteration 120 : 0.0003427661140449345
Loss at iteration 130 : 0.002380401361733675
Loss at iteration 140 : 0.0004091458104085177
Loss at iteration 150 : 0.0004746917402371764
Loss at iteration 160 : 0.001160336541943252
Loss at iteration 170 : 0.002343646949157119
Loss at iteration 180 : 0.00019579631043598056
Loss at iteration 190 : 5.490765761351213e-05
Loss at iteration 200 : 0.00042407214641571045
Loss at iteration 210 : 0.00011662677570711821
Loss at iteration 220 : 0.00017264476628042758
Loss at iteration 230 : 0.00022159997024573386
Loss at iteration 240 : 0.0005597727140411735
Loss at iteration 250 : 0.002530997386202216
Loss at iteration 260 : 0.0006207147962413728
Loss at iteration 270 : 0.0025601000525057316
Loss at iteration 280 : 0.0009444759343750775
Loss at iteration 290 : 0.00015219548367895186
Loss at iteration 300 : 0.00028580354410223663
Loss at iteration 310 : 0.0008261811453849077
Loss at iteration 320 : 0.0023285835050046444
Loss at iteration 330 : 0.001207639928907156
Loss at iteration 340 : 0.00024955678964033723
Loss at iteration 350 : 0.0012114738347008824
Loss at iteration 360 : 0.00014620268484577537
Loss at iteration 370 : 3.987548188888468e-05
Loss at iteration 380 : 0.00043276080396026373
Loss at iteration 390 : 0.0027412327472120523
Loss at iteration 400 : 0.001619085785932839
Loss at iteration 410 : 0.005485631991177797
Loss at iteration 420 : 0.0003161051427014172
Loss at iteration 430 : 9.116884029936045e-05
Loss at iteration 440 : 0.0007544871186837554
Loss at iteration 450 : 0.00033696735044941306
Loss at iteration 460 : 0.00016267098544631153
Loss at iteration 470 : 0.0002008882147492841
Loss at iteration 480 : 0.0005902902339585125
Loss at iteration 490 : 0.00034621282247826457
Loss at iteration 500 : 0.00023748402600176632
Loss at iteration 510 : 0.00014655155246146023
Loss at iteration 520 : 0.0003817107935901731
Loss at iteration 530 : 0.00036573654506355524
Loss at iteration 540 : 9.452685480937362e-05
Loss at iteration 550 : 0.000496622291393578
Loss at iteration 560 : 0.0003295040805824101
Loss at iteration 570 : 7.641856063855812e-05
Loss at iteration 580 : 0.0001307008642470464
Loss at iteration 590 : 0.0036955871619284153
Loss at iteration 600 : 5.4214175179367885e-05
Loss at iteration 610 : 0.0008796673500910401
Loss at iteration 620 : 0.0025453846901655197
Loss at iteration 630 : 0.0025046339724212885
Loss at iteration 640 : 0.0005007661529816687
Loss at iteration 650 : 0.00039639550959691405
Loss at iteration 660 : 0.00035448174457997084
Loss at iteration 670 : 0.00013914957526139915
Loss at iteration 680 : 0.00010757443669717759
Loss at iteration 690 : 0.0002679946774151176
Loss at iteration 700 : 0.0003010478976648301
Loss at iteration 710 : 0.0001664721203269437
Loss at iteration 720 : 0.00013337127165868878
Loss at iteration 730 : 0.00010725807078415528
Loss at iteration 740 : 0.003978128079324961
Loss at iteration 750 : 0.00046266388380900025
Loss at iteration 760 : 0.002615684410557151
Loss at iteration 770 : 0.004657589830458164
Loss at iteration 780 : 0.0009092089021578431
Loss at iteration 790 : 0.00019849998352583498
Loss at iteration 800 : 0.0013057992327958345
Loss at iteration 810 : 0.0027828505262732506
Loss at iteration 820 : 0.0026330575346946716
Loss at iteration 830 : 0.0025206059217453003
Loss at iteration 840 : 0.0003503150073811412
Loss at iteration 850 : 0.0019060008926317096
Loss at iteration 860 : 0.00042119831778109074
Loss at iteration 870 : 0.00040382571751251817
Loss at iteration 880 : 0.004600603133440018
Loss at iteration 890 : 0.0038651281502097845
Loss at iteration 900 : 0.0004751933447550982
Loss at iteration 910 : 0.0003888669307343662
Loss at iteration 920 : 0.0001323404721915722
Loss at iteration 930 : 0.00023316542501561344
Loss at iteration 940 : 0.0001706352486507967
Loss at iteration 950 : 0.004814389161765575
Loss at iteration 960 : 0.00019244279246777296
Loss at iteration 970 : 0.0001500047801528126
Loss at iteration 980 : 0.002904383698478341
Loss at iteration 990 : 0.0005386929260566831
Loss at iteration 1000 : 9.696769848233089e-05
Loss at iteration 1010 : 0.000328195805195719
Loss at iteration 1020 : 0.00011315919982735068
Loss at iteration 1030 : 0.0002796237822622061
Loss at iteration 1040 : 0.0011346936225891113
Loss at iteration 1050 : 0.00040303185232914984
Loss at iteration 1060 : 0.005528036039322615
Loss at iteration 1070 : 0.00013903857325203717
Loss at iteration 1080 : 0.00037427604547701776
Loss at iteration 1090 : 0.0027349486481398344
Loss at iteration 1100 : 0.0008173622190952301
Loss at iteration 1110 : 0.0010082918452098966
Loss at iteration 1120 : 0.0001726832560962066
Loss at iteration 1130 : 0.00030390528263524175
Loss at iteration 1140 : 0.00015442559379152954
Loss at iteration 1150 : 0.00010512004519114271
Loss at iteration 1160 : 0.0003776921657845378
Loss at iteration 1170 : 0.0003364065778441727
Loss at iteration 1180 : 0.0002790721191558987
Loss at iteration 1190 : 0.0005578297423198819
Loss at iteration 1200 : 0.00019439296738710254
Loss at iteration 1210 : 0.0010597355430945754
Loss at iteration 1220 : 0.002086035907268524
Loss at iteration 1230 : 0.002604937646538019
Loss at iteration 1240 : 0.0019665579311549664
Loss at iteration 1250 : 0.0009379740804433823
Loss at iteration 1260 : 0.00024629198014736176
Loss at iteration 1270 : 0.0009975713910534978
Loss at iteration 1280 : 0.00015737267676740885
Loss at iteration 1290 : 0.00014172728697303683
Loss at iteration 1300 : 0.00012953358236700296
Loss at iteration 1310 : 0.0023691013921052217
Loss at iteration 1320 : 0.00025652191834524274
Loss at iteration 1330 : 0.0002631980169098824
Loss at iteration 1340 : 0.0012725277338176966
Loss at iteration 1350 : 0.00010816346184583381
Loss at iteration 1360 : 0.0004662616993300617
Loss at iteration 1370 : 0.002738052047789097
Loss at iteration 1380 : 6.390242924680933e-05
Loss at iteration 1390 : 5.6847435189411044e-05
Loss at iteration 1400 : 0.0002551070647314191
Loss at iteration 1410 : 0.00018864944286178797
Loss at iteration 1420 : 0.0026362878270447254
Loss at iteration 1430 : 0.000250808778218925
Loss at iteration 1440 : 0.0012965230271220207
Loss at iteration 1450 : 0.006614950019866228
Loss at iteration 1460 : 0.000887320376932621
Loss at iteration 1470 : 0.0017873519100248814
Loss at iteration 1480 : 0.0029494839254766703
Loss at iteration 1490 : 0.000601216044742614
Loss at iteration 1500 : 0.00285588251426816
Loss at iteration 1510 : 0.0051977671682834625
Loss at iteration 1520 : 0.0004959797952324152
Loss at iteration 1530 : 0.00022115807223599404
Loss at iteration 1540 : 0.00023184869496617466
Loss at iteration 1550 : 0.00012914114631712437
Loss at iteration 1560 : 6.600288907065988e-05
Loss at iteration 1570 : 0.002582767279818654
Loss at iteration 1580 : 0.00010657659731805325
Loss at iteration 1590 : 0.00010236627713311464
Loss at iteration 1600 : 0.00049693847540766
Loss at iteration 1610 : 0.00010317045962437987
Loss at iteration 1620 : 0.0001827677624532953
Loss at iteration 1630 : 0.0001750412629917264
Loss at iteration 1640 : 0.0011681860778480768
Loss at iteration 1650 : 0.0002918991376645863
Loss at iteration 1660 : 0.0003676596097648144
Loss at iteration 1670 : 0.0005054787034168839
Loss at iteration 1680 : 4.532474122243002e-05
Loss at iteration 1690 : 0.00010031144483946264
Loss at iteration 1700 : 0.0002170744410250336
Loss at iteration 1710 : 0.0017145771998912096
Loss at iteration 1720 : 0.00038280696026049554
Loss at iteration 1730 : 0.0002638022124301642
Loss at iteration 1740 : 0.0003425386385060847
Loss at iteration 1750 : 0.0002932671632152051
The SSIM Value is: 0.9854783820160685
The PSNR Value is: 46.042931376049694
the epoch is: 112
Loss at iteration 10 : 0.0005873065092600882
Loss at iteration 20 : 0.0009736993815749884
Loss at iteration 30 : 0.002042119624093175
Loss at iteration 40 : 0.0004388826200738549
Loss at iteration 50 : 0.00019254157086834311
Loss at iteration 60 : 0.00040874892147257924
Loss at iteration 70 : 9.138455789070576e-05
Loss at iteration 80 : 9.87037128652446e-05
Loss at iteration 90 : 0.00020576623501256108
Loss at iteration 100 : 5.913930363021791e-05
Loss at iteration 110 : 0.0040835109539330006
Loss at iteration 120 : 0.0008264248026534915
Loss at iteration 130 : 0.00048767559928819537
Loss at iteration 140 : 0.0005957591929472983
Loss at iteration 150 : 0.0007071146974340081
Loss at iteration 160 : 0.00020669680088758469
Loss at iteration 170 : 0.001316330162808299
Loss at iteration 180 : 0.0030607618391513824
Loss at iteration 190 : 0.0001435986632714048
Loss at iteration 200 : 0.00047141138929873705
Loss at iteration 210 : 0.0016093680169433355
Loss at iteration 220 : 0.002398954937234521
Loss at iteration 230 : 0.00010919890337390825
Loss at iteration 240 : 0.004313897341489792
Loss at iteration 250 : 0.0006377691170200706
Loss at iteration 260 : 0.0022618903312832117
Loss at iteration 270 : 0.0002760861534625292
Loss at iteration 280 : 0.0009156156447716057
Loss at iteration 290 : 0.0031719421967864037
Loss at iteration 300 : 0.0004955905023962259
Loss at iteration 310 : 0.00032544881105422974
Loss at iteration 320 : 0.002308274619281292
Loss at iteration 330 : 0.00012844328011851758
Loss at iteration 340 : 0.0020470470190048218
Loss at iteration 350 : 0.0005608818028122187
Loss at iteration 360 : 0.0017828363925218582
Loss at iteration 370 : 0.0037991153076291084
Loss at iteration 380 : 9.701529052108526e-05
Loss at iteration 390 : 0.0002358789643039927
Loss at iteration 400 : 0.003892822191119194
Loss at iteration 410 : 0.003450088668614626
Loss at iteration 420 : 0.0004447170067578554
Loss at iteration 430 : 4.871868804912083e-05
Loss at iteration 440 : 0.0002698828175198287
Loss at iteration 450 : 0.0035296722780913115
Loss at iteration 460 : 0.0016303707379847765
Loss at iteration 470 : 0.0018654342275112867
Loss at iteration 480 : 0.0049403514713048935
Loss at iteration 490 : 0.00041230133501812816
Loss at iteration 500 : 0.0006747483275830746
Loss at iteration 510 : 0.000349000416463241
Loss at iteration 520 : 0.00010056105384137481
Loss at iteration 530 : 0.00020303075143601745
Loss at iteration 540 : 0.004897532053291798
Loss at iteration 550 : 0.0004220718692522496
Loss at iteration 560 : 0.0002790176949929446
Loss at iteration 570 : 0.00022028968669474125
Loss at iteration 580 : 0.00020027323625981808
Loss at iteration 590 : 0.002535718958824873
Loss at iteration 600 : 0.0050469134002923965
Loss at iteration 610 : 0.0025870141107589006
Loss at iteration 620 : 0.00011224004992982373
Loss at iteration 630 : 0.00031155796023085713
Loss at iteration 640 : 0.002393214963376522
Loss at iteration 650 : 0.00010396423749625683
Loss at iteration 660 : 0.003208546433597803
Loss at iteration 670 : 0.002179526723921299
Loss at iteration 680 : 0.00031558089540340006
Loss at iteration 690 : 0.0003497413417790085
Loss at iteration 700 : 0.0006206822581589222
Loss at iteration 710 : 0.00028654959169216454
Loss at iteration 720 : 0.003058787900954485
Loss at iteration 730 : 0.000137006223667413
Loss at iteration 740 : 0.00096222257707268
Loss at iteration 750 : 0.000131920853164047
Loss at iteration 760 : 0.0027777370996773243
Loss at iteration 770 : 0.0001832030975492671
Loss at iteration 780 : 0.005374274216592312
Loss at iteration 790 : 0.00025992345763370395
Loss at iteration 800 : 0.003450811840593815
Loss at iteration 810 : 0.0013030042173340917
Loss at iteration 820 : 0.00041484879329800606
Loss at iteration 830 : 8.158678247127682e-05
Loss at iteration 840 : 0.0004508736892603338
Loss at iteration 850 : 0.00016672346100676805
Loss at iteration 860 : 0.00016311176295857877
Loss at iteration 870 : 0.004299954976886511
Loss at iteration 880 : 0.0004504059616010636
Loss at iteration 890 : 0.0018375159706920385
Loss at iteration 900 : 0.0001312539679929614
Loss at iteration 910 : 0.00038667977787554264
Loss at iteration 920 : 0.0001969948352780193
Loss at iteration 930 : 0.00030572459218092263
Loss at iteration 940 : 0.00526978587731719
Loss at iteration 950 : 0.00463827745988965
Loss at iteration 960 : 0.00035479170037433505
Loss at iteration 970 : 0.0002076063392451033
Loss at iteration 980 : 0.00013337690324988216
Loss at iteration 990 : 9.761936962604523e-05
Loss at iteration 1000 : 0.00015281471132766455
Loss at iteration 1010 : 0.0006648947601206601
Loss at iteration 1020 : 0.0009768957970663905
Loss at iteration 1030 : 0.0004520007350947708
Loss at iteration 1040 : 0.00012796444934792817
Loss at iteration 1050 : 0.0015371250919997692
Loss at iteration 1060 : 0.0004893934237770736
Loss at iteration 1070 : 0.00029735558200627565
Loss at iteration 1080 : 0.00342510431073606
Loss at iteration 1090 : 0.0020934392232447863
Loss at iteration 1100 : 0.00015631660062354058
Loss at iteration 1110 : 0.0001236415992025286
Loss at iteration 1120 : 0.0002804304240271449
Loss at iteration 1130 : 0.001880995579995215
Loss at iteration 1140 : 0.00015311881725210696
Loss at iteration 1150 : 0.00018754240591078997
Loss at iteration 1160 : 0.00016326765762642026
Loss at iteration 1170 : 0.0001919476198963821
Loss at iteration 1180 : 0.00011875767086166888
Loss at iteration 1190 : 0.0003371673228684813
Loss at iteration 1200 : 0.00014898841618560255
Loss at iteration 1210 : 0.0013040241319686174
Loss at iteration 1220 : 0.0033702703658491373
Loss at iteration 1230 : 0.0032777786254882812
Loss at iteration 1240 : 0.0017417131457477808
Loss at iteration 1250 : 0.004112770780920982
Loss at iteration 1260 : 0.0011860675876960158
Loss at iteration 1270 : 4.42550954176113e-05
Loss at iteration 1280 : 0.0008189784130081534
Loss at iteration 1290 : 0.001323777949437499
Loss at iteration 1300 : 0.003366007935255766
Loss at iteration 1310 : 0.00030263871303759515
Loss at iteration 1320 : 0.00029480402008630335
Loss at iteration 1330 : 0.00018037085828837007
Loss at iteration 1340 : 0.0022020696196705103
Loss at iteration 1350 : 0.00044586422154679894
Loss at iteration 1360 : 0.00046367812319658697
Loss at iteration 1370 : 0.002723331330344081
Loss at iteration 1380 : 0.0011030591558665037
Loss at iteration 1390 : 0.000491422601044178
Loss at iteration 1400 : 0.00014989005285315216
Loss at iteration 1410 : 0.0006042165914550424
Loss at iteration 1420 : 0.0010572291212156415
Loss at iteration 1430 : 0.0001305867190239951
Loss at iteration 1440 : 0.000845972157549113
Loss at iteration 1450 : 0.00047800911124795675
Loss at iteration 1460 : 0.00016973513993434608
Loss at iteration 1470 : 0.0006216352921910584
Loss at iteration 1480 : 0.00040990827255882323
Loss at iteration 1490 : 8.725744555704296e-05
Loss at iteration 1500 : 0.0003630684514064342
Loss at iteration 1510 : 0.0002878716622944921
Loss at iteration 1520 : 0.0008164431783370674
Loss at iteration 1530 : 0.0024416856467723846
Loss at iteration 1540 : 0.00013973463501315564
Loss at iteration 1550 : 0.00012615266314242035
Loss at iteration 1560 : 8.72898890520446e-05
Loss at iteration 1570 : 0.001648294972255826
Loss at iteration 1580 : 0.0001220880076289177
Loss at iteration 1590 : 0.00026184358284808695
Loss at iteration 1600 : 0.005131642334163189
Loss at iteration 1610 : 0.0002072738716378808
Loss at iteration 1620 : 0.0045823026448488235
Loss at iteration 1630 : 6.535786087624729e-05
Loss at iteration 1640 : 0.00011930651817237958
Loss at iteration 1650 : 0.003461829386651516
Loss at iteration 1660 : 0.00029003695817664266
Loss at iteration 1670 : 0.001631291233934462
Loss at iteration 1680 : 0.002370844827964902
Loss at iteration 1690 : 0.0009219684870913625
Loss at iteration 1700 : 0.00012041321315336972
Loss at iteration 1710 : 0.00011828262358903885
Loss at iteration 1720 : 0.00019439765310380608
Loss at iteration 1730 : 0.000383385136956349
Loss at iteration 1740 : 0.002615163801237941
Loss at iteration 1750 : 0.005724132992327213
The SSIM Value is: 0.975809550364112
The PSNR Value is: 46.385181469014036
the epoch is: 113
Loss at iteration 10 : 0.003950880374759436
Loss at iteration 20 : 0.0007669220212846994
Loss at iteration 30 : 0.00023152539506554604
Loss at iteration 40 : 9.578442404745147e-05
Loss at iteration 50 : 9.659316128818318e-05
Loss at iteration 60 : 0.00017355689487885684
Loss at iteration 70 : 7.2208495112136e-05
Loss at iteration 80 : 9.69400571193546e-05
Loss at iteration 90 : 0.00024562550242990255
Loss at iteration 100 : 4.517951310845092e-05
Loss at iteration 110 : 0.0006984805804677308
Loss at iteration 120 : 0.0011915870709344745
Loss at iteration 130 : 0.00197285832837224
Loss at iteration 140 : 0.00032939587254077196
Loss at iteration 150 : 0.0002706032828427851
Loss at iteration 160 : 0.0005169358337298036
Loss at iteration 170 : 0.0004448599647730589
Loss at iteration 180 : 6.358546670526266e-05
Loss at iteration 190 : 0.0003784976142924279
Loss at iteration 200 : 0.0006573095452040434
Loss at iteration 210 : 0.00012331065954640508
Loss at iteration 220 : 0.0005084591102786362
Loss at iteration 230 : 0.00035420682979747653
Loss at iteration 240 : 0.00014206444029696286
Loss at iteration 250 : 0.0010814775014296174
Loss at iteration 260 : 0.0022414452396333218
Loss at iteration 270 : 0.00033619391615502536
Loss at iteration 280 : 0.0033134811092168093
Loss at iteration 290 : 0.00014215489500202239
Loss at iteration 300 : 0.0004686710308305919
Loss at iteration 310 : 0.00014734290016349405
Loss at iteration 320 : 0.004203871823847294
Loss at iteration 330 : 0.0014755836455151439
Loss at iteration 340 : 0.0007698304834775627
Loss at iteration 350 : 0.0006752207991667092
Loss at iteration 360 : 0.00016650540055707097
Loss at iteration 370 : 0.0001237719552591443
Loss at iteration 380 : 0.00019906331726815552
Loss at iteration 390 : 0.000774934480432421
Loss at iteration 400 : 0.0002161466545658186
Loss at iteration 410 : 0.0034011632669717073
Loss at iteration 420 : 0.0018944955663755536
Loss at iteration 430 : 0.0001815370051190257
Loss at iteration 440 : 0.00028791098156943917
Loss at iteration 450 : 0.0007027556421235204
Loss at iteration 460 : 6.034019679646008e-05
Loss at iteration 470 : 0.00042679868056438863
Loss at iteration 480 : 0.0004869949771091342
Loss at iteration 490 : 0.00076521304436028
Loss at iteration 500 : 0.002533928956836462
Loss at iteration 510 : 0.00018032178923022002
Loss at iteration 520 : 0.001147608389146626
Loss at iteration 530 : 8.075892401393503e-05
Loss at iteration 540 : 0.0001235522940987721
Loss at iteration 550 : 0.0008047555456869304
Loss at iteration 560 : 0.00013504319940693676
Loss at iteration 570 : 0.00258085154928267
Loss at iteration 580 : 9.643677913118154e-05
Loss at iteration 590 : 0.00043774431105703115
Loss at iteration 600 : 0.00024341446987818927
Loss at iteration 610 : 0.0004746009362861514
Loss at iteration 620 : 0.002858445979654789
Loss at iteration 630 : 0.0001461653009755537
Loss at iteration 640 : 0.000569504511076957
Loss at iteration 650 : 0.0001856019807746634
Loss at iteration 660 : 0.0002632457762956619
Loss at iteration 670 : 0.0005948980688117445
Loss at iteration 680 : 0.0034696292132139206
Loss at iteration 690 : 0.0006352188647724688
Loss at iteration 700 : 0.0024068064521998167
Loss at iteration 710 : 0.0008888334850780666
Loss at iteration 720 : 0.00014463614206761122
Loss at iteration 730 : 0.0001397746236762032
Loss at iteration 740 : 0.000308051094179973
Loss at iteration 750 : 0.0005926421727053821
Loss at iteration 760 : 4.98340668855235e-05
Loss at iteration 770 : 0.00046299074892885983
Loss at iteration 780 : 0.002440664917230606
Loss at iteration 790 : 0.00028869378729723394
Loss at iteration 800 : 0.00017067157023120672
Loss at iteration 810 : 0.0005605305195786059
Loss at iteration 820 : 0.00012636734754778445
Loss at iteration 830 : 0.00015424855519086123
Loss at iteration 840 : 0.003025264944881201
Loss at iteration 850 : 0.001194584066979587
Loss at iteration 860 : 0.00010098807251779363
Loss at iteration 870 : 0.0005642325850203633
Loss at iteration 880 : 0.00033673644065856934
Loss at iteration 890 : 0.00017483369447290897
Loss at iteration 900 : 0.00037325764424167573
Loss at iteration 910 : 0.00010368476796429604
Loss at iteration 920 : 0.00010248705802951008
Loss at iteration 930 : 0.0007512092124670744
Loss at iteration 940 : 0.00014433678006753325
Loss at iteration 950 : 0.00026886037085205317
Loss at iteration 960 : 0.000609586073551327
Loss at iteration 970 : 0.0013520534848794341
Loss at iteration 980 : 0.00015303082182072103
Loss at iteration 990 : 0.00016302871517837048
Loss at iteration 1000 : 0.00023898787912912667
Loss at iteration 1010 : 0.0004430312546901405
Loss at iteration 1020 : 0.00023090242757461965
Loss at iteration 1030 : 0.003934510517865419
Loss at iteration 1040 : 0.00012331883772276342
Loss at iteration 1050 : 0.0035630480851978064
Loss at iteration 1060 : 0.00014472444308921695
Loss at iteration 1070 : 0.0008750625420361757
Loss at iteration 1080 : 0.00029377866303548217
Loss at iteration 1090 : 0.003525321837514639
Loss at iteration 1100 : 0.00014918686065357178
Loss at iteration 1110 : 0.0006127237575128675
Loss at iteration 1120 : 0.0033690689597278833
Loss at iteration 1130 : 0.00018113550322595984
Loss at iteration 1140 : 0.000622291408944875
Loss at iteration 1150 : 0.00011339131015120074
Loss at iteration 1160 : 0.0021475839894264936
Loss at iteration 1170 : 0.0017575020901858807
Loss at iteration 1180 : 6.619821942877024e-05
Loss at iteration 1190 : 8.947165770223364e-05
Loss at iteration 1200 : 0.0001268093619728461
Loss at iteration 1210 : 0.0006263100658543408
Loss at iteration 1220 : 0.00016370901721529663
Loss at iteration 1230 : 7.939111674204469e-05
Loss at iteration 1240 : 0.00016728554328437895
Loss at iteration 1250 : 0.0003706970892380923
Loss at iteration 1260 : 0.002734686015173793
Loss at iteration 1270 : 0.0008726652013137937
Loss at iteration 1280 : 0.00027002993738278747
Loss at iteration 1290 : 0.0006274019833654165
Loss at iteration 1300 : 7.445976370945573e-05
Loss at iteration 1310 : 0.0002934541553258896
Loss at iteration 1320 : 0.007096237502992153
Loss at iteration 1330 : 0.00033617758890613914
Loss at iteration 1340 : 7.882928184699267e-05
Loss at iteration 1350 : 0.0004679511475842446
Loss at iteration 1360 : 9.547053196001798e-05
Loss at iteration 1370 : 0.0011991644278168678
Loss at iteration 1380 : 7.48502352507785e-05
Loss at iteration 1390 : 0.00028707447927445173
Loss at iteration 1400 : 0.00011917881784029305
Loss at iteration 1410 : 0.000246191571932286
Loss at iteration 1420 : 0.00012531349784694612
Loss at iteration 1430 : 0.00044861272908747196
Loss at iteration 1440 : 0.0016129205469042063
Loss at iteration 1450 : 0.0014501159312203526
Loss at iteration 1460 : 0.00017530510376673192
Loss at iteration 1470 : 0.0003867694758810103
Loss at iteration 1480 : 0.0001453988516004756
Loss at iteration 1490 : 0.0024313637986779213
Loss at iteration 1500 : 0.0015672828303650022
Loss at iteration 1510 : 6.435293471440673e-05
Loss at iteration 1520 : 0.0033949464559555054
Loss at iteration 1530 : 0.0001651880593271926
Loss at iteration 1540 : 0.0005633343243971467
Loss at iteration 1550 : 6.697740172967315e-05
Loss at iteration 1560 : 0.004630507901310921
Loss at iteration 1570 : 0.0027680140919983387
Loss at iteration 1580 : 0.003006798680871725
Loss at iteration 1590 : 0.0007002728525549173
Loss at iteration 1600 : 0.0002351852599531412
Loss at iteration 1610 : 0.00019937432080041617
Loss at iteration 1620 : 0.003481560852378607
Loss at iteration 1630 : 0.00011871073365909979
Loss at iteration 1640 : 0.00024078374553937465
Loss at iteration 1650 : 0.0020631880033761263
Loss at iteration 1660 : 0.00020692069665528834
Loss at iteration 1670 : 0.0038632084615528584
Loss at iteration 1680 : 0.00022921829076949507
Loss at iteration 1690 : 0.002446427009999752
Loss at iteration 1700 : 6.309009768301621e-05
Loss at iteration 1710 : 0.00037919660098850727
Loss at iteration 1720 : 0.00011877885117428377
Loss at iteration 1730 : 0.0002208652877015993
Loss at iteration 1740 : 0.0001954037870746106
Loss at iteration 1750 : 0.003841361263766885
The SSIM Value is: 0.9707884948027816
The PSNR Value is: 46.27509891829302
the epoch is: 114
Loss at iteration 10 : 0.00016384097398258746
Loss at iteration 20 : 0.0006356111261993647
Loss at iteration 30 : 0.0009925831109285355
Loss at iteration 40 : 0.006857587024569511
Loss at iteration 50 : 7.193109922809526e-05
Loss at iteration 60 : 0.0007766087655909359
Loss at iteration 70 : 5.6862096244003624e-05
Loss at iteration 80 : 0.00020050181774422526
Loss at iteration 90 : 0.0015613201539963484
Loss at iteration 100 : 0.0002328595583094284
Loss at iteration 110 : 0.003172706812620163
Loss at iteration 120 : 0.004058019258081913
Loss at iteration 130 : 0.002155347727239132
Loss at iteration 140 : 0.0004524225078057498
Loss at iteration 150 : 0.0013263161526992917
Loss at iteration 160 : 0.00022193760378286242
Loss at iteration 170 : 0.00038156629307195544
Loss at iteration 180 : 0.0002870046882890165
Loss at iteration 190 : 0.0006637104088440537
Loss at iteration 200 : 0.0002204200136475265
Loss at iteration 210 : 0.000544953509233892
Loss at iteration 220 : 0.0014969699550420046
Loss at iteration 230 : 0.00021849392214789987
Loss at iteration 240 : 0.0003028383944183588
Loss at iteration 250 : 0.0001260228018509224
Loss at iteration 260 : 0.00013235289952717721
Loss at iteration 270 : 0.0020812000147998333
Loss at iteration 280 : 0.00017773665604181588
Loss at iteration 290 : 0.0006350255571305752
Loss at iteration 300 : 0.0022823233157396317
Loss at iteration 310 : 0.0004052364965900779
Loss at iteration 320 : 0.0009064690093509853
Loss at iteration 330 : 0.001989505486562848
Loss at iteration 340 : 0.0003603959921747446
Loss at iteration 350 : 0.0008402859675697982
Loss at iteration 360 : 0.00040091993287205696
Loss at iteration 370 : 0.006159834563732147
Loss at iteration 380 : 0.00068049062974751
Loss at iteration 390 : 0.0003830020723398775
Loss at iteration 400 : 0.00024319597287103534
Loss at iteration 410 : 0.0011033245828002691
Loss at iteration 420 : 0.002976533491164446
Loss at iteration 430 : 0.00036460894625633955
Loss at iteration 440 : 0.0004308274365030229
Loss at iteration 450 : 0.0026362210046499968
Loss at iteration 460 : 0.00017275985737796873
Loss at iteration 470 : 0.0014045683201402426
Loss at iteration 480 : 5.78026520088315e-05
Loss at iteration 490 : 0.0017990351188927889
Loss at iteration 500 : 0.00015249532589223236
Loss at iteration 510 : 0.001417666207998991
Loss at iteration 520 : 0.0037443982437253
Loss at iteration 530 : 0.0011052358895540237
Loss at iteration 540 : 0.00022167008137330413
Loss at iteration 550 : 4.200253533781506e-05
Loss at iteration 560 : 0.0001374431449221447
Loss at iteration 570 : 0.0020532282069325447
Loss at iteration 580 : 0.0030305800028145313
Loss at iteration 590 : 9.805775334825739e-05
Loss at iteration 600 : 5.708550816052593e-05
Loss at iteration 610 : 0.0001046512697939761
Loss at iteration 620 : 0.00013651733752340078
Loss at iteration 630 : 0.00046094562276266515
Loss at iteration 640 : 0.0006167354877106845
Loss at iteration 650 : 8.506703306920826e-05
Loss at iteration 660 : 0.0006533201085403562
Loss at iteration 670 : 0.0001843716308940202
Loss at iteration 680 : 0.00017776648746803403
Loss at iteration 690 : 0.002648015506565571
Loss at iteration 700 : 0.00025302194990217686
Loss at iteration 710 : 0.000282093184068799
Loss at iteration 720 : 0.0002381795202381909
Loss at iteration 730 : 9.089041850529611e-05
Loss at iteration 740 : 0.002053673379123211
Loss at iteration 750 : 0.00021579825261142105
Loss at iteration 760 : 0.0008657696307636797
Loss at iteration 770 : 0.00010050589480670169
Loss at iteration 780 : 8.62626766320318e-05
Loss at iteration 790 : 0.0006234022439457476
Loss at iteration 800 : 0.00028160586953163147
Loss at iteration 810 : 0.0005145894247107208
Loss at iteration 820 : 0.002093422692269087
Loss at iteration 830 : 0.0007478780462406576
Loss at iteration 840 : 0.00010476015449967235
Loss at iteration 850 : 0.0009543633786961436
Loss at iteration 860 : 0.0001825907384045422
Loss at iteration 870 : 0.0004134192713536322
Loss at iteration 880 : 0.0007855528965592384
Loss at iteration 890 : 6.200945063028485e-05
Loss at iteration 900 : 0.003981070127338171
Loss at iteration 910 : 0.00012724139378406107
Loss at iteration 920 : 0.00017418820061720908
Loss at iteration 930 : 0.00012039137072861195
Loss at iteration 940 : 0.00011608093336690217
Loss at iteration 950 : 0.00038202383439056575
Loss at iteration 960 : 0.00014687188377138227
Loss at iteration 970 : 9.550918184686452e-05
Loss at iteration 980 : 9.102856711251661e-05
Loss at iteration 990 : 0.0017965291626751423
Loss at iteration 1000 : 0.00022521166829392314
Loss at iteration 1010 : 0.00016378815053030849
Loss at iteration 1020 : 0.0006844336166977882
Loss at iteration 1030 : 0.00010596865467960015
Loss at iteration 1040 : 0.0009956056019291282
Loss at iteration 1050 : 0.0009665231918916106
Loss at iteration 1060 : 0.0031419566366821527
Loss at iteration 1070 : 0.0006413893424905837
Loss at iteration 1080 : 0.0072441077791154385
Loss at iteration 1090 : 5.900819814996794e-05
Loss at iteration 1100 : 6.600261986022815e-05
Loss at iteration 1110 : 0.00012338632950559258
Loss at iteration 1120 : 0.002749260514974594
Loss at iteration 1130 : 0.00040520832408219576
Loss at iteration 1140 : 0.0008604493923485279
Loss at iteration 1150 : 0.003635621163994074
Loss at iteration 1160 : 0.00016619624511804432
Loss at iteration 1170 : 0.00040411335066892207
Loss at iteration 1180 : 0.003351380815729499
Loss at iteration 1190 : 0.00019689733744598925
Loss at iteration 1200 : 0.00012649976997636259
Loss at iteration 1210 : 0.00018826460291165859
Loss at iteration 1220 : 0.00034256113576702774
Loss at iteration 1230 : 0.0003247917047701776
Loss at iteration 1240 : 0.0022491798736155033
Loss at iteration 1250 : 0.0029773791320621967
Loss at iteration 1260 : 0.0006393109797500074
Loss at iteration 1270 : 0.0015863218577578664
Loss at iteration 1280 : 0.002236726926639676
Loss at iteration 1290 : 0.0005885999416932464
Loss at iteration 1300 : 0.0005351420259103179
Loss at iteration 1310 : 0.0018038307316601276
Loss at iteration 1320 : 0.0018772450275719166
Loss at iteration 1330 : 0.00017592830408830196
Loss at iteration 1340 : 0.0002061409322777763
Loss at iteration 1350 : 0.0004363741900306195
Loss at iteration 1360 : 0.00022957473993301392
Loss at iteration 1370 : 0.0001494419266236946
Loss at iteration 1380 : 0.00011665264901239425
Loss at iteration 1390 : 0.006749081891030073
Loss at iteration 1400 : 0.00014666872448287904
Loss at iteration 1410 : 0.0010040949564427137
Loss at iteration 1420 : 0.002185128629207611
Loss at iteration 1430 : 0.00013330054935067892
Loss at iteration 1440 : 0.00013100725482217968
Loss at iteration 1450 : 0.00010814669076353312
Loss at iteration 1460 : 0.0030004242435097694
Loss at iteration 1470 : 0.0012694260803982615
Loss at iteration 1480 : 0.00027583373594097793
Loss at iteration 1490 : 0.0020347675308585167
Loss at iteration 1500 : 0.0002847157302312553
Loss at iteration 1510 : 0.00019432100816629827
Loss at iteration 1520 : 0.0008264982025139034
Loss at iteration 1530 : 0.000522816029842943
Loss at iteration 1540 : 0.0003526478831190616
Loss at iteration 1550 : 0.00011351432476658374
Loss at iteration 1560 : 0.00014377459592651576
Loss at iteration 1570 : 0.0005861474201083183
Loss at iteration 1580 : 0.00032128478051163256
Loss at iteration 1590 : 0.001903753262013197
Loss at iteration 1600 : 0.007341342978179455
Loss at iteration 1610 : 0.0017350871348753572
Loss at iteration 1620 : 0.00043811119394376874
Loss at iteration 1630 : 0.006561832036823034
Loss at iteration 1640 : 0.00012411759234964848
Loss at iteration 1650 : 0.000296832004096359
Loss at iteration 1660 : 0.0060449764132499695
Loss at iteration 1670 : 0.00017364822269883007
Loss at iteration 1680 : 0.00026385398814454675
Loss at iteration 1690 : 0.00019281895947642624
Loss at iteration 1700 : 0.0006867247866466641
Loss at iteration 1710 : 0.0003332928172312677
Loss at iteration 1720 : 0.0002716207236517221
Loss at iteration 1730 : 0.00012219848576933146
Loss at iteration 1740 : 7.608382293256e-05
Loss at iteration 1750 : 0.00234780739992857
The SSIM Value is: 0.9851929993093802
The PSNR Value is: 46.73138199818817
the epoch is: 115
Loss at iteration 10 : 7.18974115443416e-05
Loss at iteration 20 : 0.00043045877828262746
Loss at iteration 30 : 0.0036308870185166597
Loss at iteration 40 : 0.0020515811629593372
Loss at iteration 50 : 0.003467343281954527
Loss at iteration 60 : 0.000448965176474303
Loss at iteration 70 : 0.00015625065134372562
Loss at iteration 80 : 0.00015536826686002314
Loss at iteration 90 : 0.001925549004226923
Loss at iteration 100 : 0.0023526009172201157
Loss at iteration 110 : 9.248563583241776e-05
Loss at iteration 120 : 0.0005390237784013152
Loss at iteration 130 : 0.00038712500827386975
Loss at iteration 140 : 0.00025362588348798454
Loss at iteration 150 : 0.0020354336593300104
Loss at iteration 160 : 0.0003692274622153491
Loss at iteration 170 : 0.0002807342680171132
Loss at iteration 180 : 3.056460263906047e-05
Loss at iteration 190 : 0.00015791680198162794
Loss at iteration 200 : 0.0003137077437713742
Loss at iteration 210 : 0.0009555895230732858
Loss at iteration 220 : 0.000494329899083823
Loss at iteration 230 : 0.0002092522627208382
Loss at iteration 240 : 0.00048434961354359984
Loss at iteration 250 : 0.0020508538000285625
Loss at iteration 260 : 0.0002671646070666611
Loss at iteration 270 : 0.0021712593734264374
Loss at iteration 280 : 0.0007606880972161889
Loss at iteration 290 : 0.0008173241512849927
Loss at iteration 300 : 0.0024839919060468674
Loss at iteration 310 : 0.0008641515159979463
Loss at iteration 320 : 0.00045466836309060454
Loss at iteration 330 : 0.0025883065536618233
Loss at iteration 340 : 0.00010094956815009937
Loss at iteration 350 : 0.00012079734005965292
Loss at iteration 360 : 0.0012571808183565736
Loss at iteration 370 : 0.0014579587150365114
Loss at iteration 380 : 0.00034736868110485375
Loss at iteration 390 : 0.0004306946648284793
Loss at iteration 400 : 0.00019681703997775912
Loss at iteration 410 : 0.0007879257900640368
Loss at iteration 420 : 0.0004508616984821856
Loss at iteration 430 : 0.00015747337602078915
Loss at iteration 440 : 0.0005369000718928874
Loss at iteration 450 : 0.0015719285001978278
Loss at iteration 460 : 0.0002413848997093737
Loss at iteration 470 : 0.00045571455848403275
Loss at iteration 480 : 0.002337342593818903
Loss at iteration 490 : 0.0001809107488952577
Loss at iteration 500 : 0.0028511949349194765
Loss at iteration 510 : 0.0003432804951444268
Loss at iteration 520 : 0.003435405669733882
Loss at iteration 530 : 0.0008659235900267959
Loss at iteration 540 : 7.123033719835803e-05
Loss at iteration 550 : 0.0002486873709131032
Loss at iteration 560 : 0.00034340249840170145
Loss at iteration 570 : 0.0009515696438029408
Loss at iteration 580 : 9.59870740189217e-05
Loss at iteration 590 : 0.0031802630983293056
Loss at iteration 600 : 0.0002585809270385653
Loss at iteration 610 : 0.0010374997509643435
Loss at iteration 620 : 0.00023472181055694818
Loss at iteration 630 : 0.0004885635571554303
Loss at iteration 640 : 0.0005214043194428086
Loss at iteration 650 : 0.004434753675013781
Loss at iteration 660 : 0.003104635514318943
Loss at iteration 670 : 0.00018563895719125867
Loss at iteration 680 : 0.0007586134597659111
Loss at iteration 690 : 0.00019205074931960553
Loss at iteration 700 : 5.778922059107572e-05
Loss at iteration 710 : 0.0029073578771203756
Loss at iteration 720 : 0.00022187780996318907
Loss at iteration 730 : 0.000311596057144925
Loss at iteration 740 : 0.00012696190970018506
Loss at iteration 750 : 0.0001742503372952342
Loss at iteration 760 : 0.0009502301691100001
Loss at iteration 770 : 0.0001633202627999708
Loss at iteration 780 : 0.00021641157218255103
Loss at iteration 790 : 0.0030901983845978975
Loss at iteration 800 : 0.0001842426718212664
Loss at iteration 810 : 0.00035776535514742136
Loss at iteration 820 : 0.0008573363302275538
Loss at iteration 830 : 0.0027977603022009134
Loss at iteration 840 : 0.003026999067515135
Loss at iteration 850 : 7.106350676622242e-05
Loss at iteration 860 : 0.00022074530716054142
Loss at iteration 870 : 0.0001834950380725786
Loss at iteration 880 : 0.0003636288456618786
Loss at iteration 890 : 0.0018677396001294255
Loss at iteration 900 : 0.0011296117445454001
Loss at iteration 910 : 0.001026910264045
Loss at iteration 920 : 0.0001364255149383098
Loss at iteration 930 : 0.0034489568788558245
Loss at iteration 940 : 0.00015929705114103854
Loss at iteration 950 : 0.00017757735622581095
Loss at iteration 960 : 0.00015428895130753517
Loss at iteration 970 : 0.0005749536212533712
Loss at iteration 980 : 0.0001939332578331232
Loss at iteration 990 : 0.0006328315939754248
Loss at iteration 1000 : 3.774798460653983e-05
Loss at iteration 1010 : 9.376188245369121e-05
Loss at iteration 1020 : 0.0005384032265283167
Loss at iteration 1030 : 0.0007973764440976083
Loss at iteration 1040 : 0.0021883079316467047
Loss at iteration 1050 : 0.0014431439340114594
Loss at iteration 1060 : 0.00028379890136420727
Loss at iteration 1070 : 0.0012122186599299312
Loss at iteration 1080 : 0.00048283219803124666
Loss at iteration 1090 : 0.001296826871111989
Loss at iteration 1100 : 0.00047140655806288123
Loss at iteration 1110 : 0.0006155981682240963
Loss at iteration 1120 : 8.451236499240622e-05
Loss at iteration 1130 : 0.00258898688480258
Loss at iteration 1140 : 0.005220333114266396
Loss at iteration 1150 : 0.00020221149316057563
Loss at iteration 1160 : 0.0005428928416222334
Loss at iteration 1170 : 0.00019654603966046125
Loss at iteration 1180 : 0.00639703031629324
Loss at iteration 1190 : 0.0011003115214407444
Loss at iteration 1200 : 0.00016372134268749505
Loss at iteration 1210 : 0.00014010476297698915
Loss at iteration 1220 : 0.006325618829578161
Loss at iteration 1230 : 0.00039596066926606
Loss at iteration 1240 : 0.006026582792401314
Loss at iteration 1250 : 0.00047314228140749037
Loss at iteration 1260 : 0.0001345902419416234
Loss at iteration 1270 : 0.0002111881331074983
Loss at iteration 1280 : 0.00013189364108256996
Loss at iteration 1290 : 5.26153453392908e-05
Loss at iteration 1300 : 6.767248851247132e-05
Loss at iteration 1310 : 0.00024347400176338851
Loss at iteration 1320 : 0.00010209931497229263
Loss at iteration 1330 : 0.00012749042070936412
Loss at iteration 1340 : 0.00016964692622423172
Loss at iteration 1350 : 0.00022884785721544176
Loss at iteration 1360 : 0.001543200807645917
Loss at iteration 1370 : 0.0005360398790799081
Loss at iteration 1380 : 0.00010483826918061823
Loss at iteration 1390 : 0.0001809945679269731
Loss at iteration 1400 : 8.195783448172733e-05
Loss at iteration 1410 : 0.00029621721478179097
Loss at iteration 1420 : 0.00169425702188164
Loss at iteration 1430 : 0.0001453057338949293
Loss at iteration 1440 : 0.0010995519114658237
Loss at iteration 1450 : 6.137905438663438e-05
Loss at iteration 1460 : 0.002886399859562516
Loss at iteration 1470 : 0.00044567996519617736
Loss at iteration 1480 : 0.00014438663492910564
Loss at iteration 1490 : 0.0028760763816535473
Loss at iteration 1500 : 0.00025498619652353227
Loss at iteration 1510 : 0.0005404454423114657
Loss at iteration 1520 : 0.0002620674204081297
Loss at iteration 1530 : 0.0017490850295871496
Loss at iteration 1540 : 0.00021591037511825562
Loss at iteration 1550 : 0.00031427713111042976
Loss at iteration 1560 : 0.0005525592714548111
Loss at iteration 1570 : 0.0044333720579743385
Loss at iteration 1580 : 0.0017602998996153474
Loss at iteration 1590 : 0.0014720726758241653
Loss at iteration 1600 : 0.0047947741113603115
Loss at iteration 1610 : 0.0022352971136569977
Loss at iteration 1620 : 0.0019505394157022238
Loss at iteration 1630 : 0.0025080544874072075
Loss at iteration 1640 : 0.0004679271369241178
Loss at iteration 1650 : 0.0020279036834836006
Loss at iteration 1660 : 0.0005841315723955631
Loss at iteration 1670 : 0.00018233832088299096
Loss at iteration 1680 : 0.0004482737567741424
Loss at iteration 1690 : 0.002225093077868223
Loss at iteration 1700 : 0.00018594416906125844
Loss at iteration 1710 : 0.00012368451280053705
Loss at iteration 1720 : 0.0003331043117213994
Loss at iteration 1730 : 0.0027790300082415342
Loss at iteration 1740 : 0.00013040263729635626
Loss at iteration 1750 : 0.001084416639059782
The SSIM Value is: 0.9816179828234181
The PSNR Value is: 46.4892185984204
the epoch is: 116
Loss at iteration 10 : 0.000835707935038954
Loss at iteration 20 : 0.0009127836674451828
Loss at iteration 30 : 0.00019784487085416913
Loss at iteration 40 : 0.003833549562841654
Loss at iteration 50 : 0.00026107655139639974
Loss at iteration 60 : 0.00013406682410277426
Loss at iteration 70 : 7.039305637590587e-05
Loss at iteration 80 : 0.001044852426275611
Loss at iteration 90 : 0.00027047525509260595
Loss at iteration 100 : 0.0040282560512423515
Loss at iteration 110 : 0.0017860452644526958
Loss at iteration 120 : 0.003049117513000965
Loss at iteration 130 : 7.965893018990755e-05
Loss at iteration 140 : 0.0003780975821428001
Loss at iteration 150 : 0.0012507829815149307
Loss at iteration 160 : 7.986487617017701e-05
Loss at iteration 170 : 0.0001405254879500717
Loss at iteration 180 : 0.0005612028762698174
Loss at iteration 190 : 0.00022800196893513203
Loss at iteration 200 : 0.0002036064979620278
Loss at iteration 210 : 0.0015156037406995893
Loss at iteration 220 : 0.0002594533725641668
Loss at iteration 230 : 0.004028692375868559
Loss at iteration 240 : 0.00038608553586527705
Loss at iteration 250 : 0.00031765346648171544
Loss at iteration 260 : 0.00034060751204378903
Loss at iteration 270 : 0.00026469677686691284
Loss at iteration 280 : 0.00010109340655617416
Loss at iteration 290 : 9.625886741559952e-05
Loss at iteration 300 : 0.00034584960667416453
Loss at iteration 310 : 0.00025370443472638726
Loss at iteration 320 : 0.0004828759701922536
Loss at iteration 330 : 0.0002098249242408201
Loss at iteration 340 : 0.002545086434110999
Loss at iteration 350 : 0.0008796793408691883
Loss at iteration 360 : 0.0017936029471457005
Loss at iteration 370 : 0.00022174591140355915
Loss at iteration 380 : 0.0001860454212874174
Loss at iteration 390 : 0.000997775699943304
Loss at iteration 400 : 6.86798884999007e-05
Loss at iteration 410 : 0.0015280486550182104
Loss at iteration 420 : 9.360797412227839e-05
Loss at iteration 430 : 0.0032035955227911472
Loss at iteration 440 : 6.91525056026876e-05
Loss at iteration 450 : 0.0032056979835033417
Loss at iteration 460 : 0.000723276927601546
Loss at iteration 470 : 0.0021305358968675137
Loss at iteration 480 : 0.000620426784735173
Loss at iteration 490 : 6.792521890019998e-05
Loss at iteration 500 : 7.419090252369642e-05
Loss at iteration 510 : 0.0007612917106598616
Loss at iteration 520 : 0.00018322697724215686
Loss at iteration 530 : 0.0002914214273914695
Loss at iteration 540 : 0.0028965971432626247
Loss at iteration 550 : 0.0003640986396931112
Loss at iteration 560 : 0.0014599328860640526
Loss at iteration 570 : 0.001172493677586317
Loss at iteration 580 : 0.00031213852344080806
Loss at iteration 590 : 0.0002093724615406245
Loss at iteration 600 : 0.00012729469744954258
Loss at iteration 610 : 0.004186023958027363
Loss at iteration 620 : 0.0002211046958109364
Loss at iteration 630 : 0.00010465022205607966
Loss at iteration 640 : 0.0008811631705611944
Loss at iteration 650 : 0.0006219808710739017
Loss at iteration 660 : 0.000565483933314681
Loss at iteration 670 : 0.0006521279574371874
Loss at iteration 680 : 0.0006403328734450042
Loss at iteration 690 : 0.0003438772400841117
Loss at iteration 700 : 0.003081051865592599
Loss at iteration 710 : 0.00038159266114234924
Loss at iteration 720 : 0.0008171852678060532
Loss at iteration 730 : 0.000163326520123519
Loss at iteration 740 : 9.541233885101974e-05
Loss at iteration 750 : 5.82852735533379e-05
Loss at iteration 760 : 0.0003251583257224411
Loss at iteration 770 : 0.0013772477395832539
Loss at iteration 780 : 0.0009533737320452929
Loss at iteration 790 : 0.0011540435953065753
Loss at iteration 800 : 6.712353206239641e-05
Loss at iteration 810 : 0.010045697912573814
Loss at iteration 820 : 0.0006378025282174349
Loss at iteration 830 : 8.45960748847574e-05
Loss at iteration 840 : 0.0008360323263332248
Loss at iteration 850 : 0.00018436195387039334
Loss at iteration 860 : 0.002708679996430874
Loss at iteration 870 : 0.00033071101643145084
Loss at iteration 880 : 0.003471024800091982
Loss at iteration 890 : 0.0009935470297932625
Loss at iteration 900 : 0.0002476245863363147
Loss at iteration 910 : 0.0021892443764954805
Loss at iteration 920 : 0.00017860955267678946
Loss at iteration 930 : 9.65748040471226e-05
Loss at iteration 940 : 0.00020113299251534045
Loss at iteration 950 : 0.00018197970348410308
Loss at iteration 960 : 0.0001090554942493327
Loss at iteration 970 : 0.0013667973689734936
Loss at iteration 980 : 0.0003228846180718392
Loss at iteration 990 : 0.00014387760893441737
Loss at iteration 1000 : 0.00013032265997026116
Loss at iteration 1010 : 0.002443644218146801
Loss at iteration 1020 : 0.0007974867476150393
Loss at iteration 1030 : 0.0003570281551219523
Loss at iteration 1040 : 0.003274134360253811
Loss at iteration 1050 : 0.0001925579854287207
Loss at iteration 1060 : 0.0001463293592678383
Loss at iteration 1070 : 0.0006852914812043309
Loss at iteration 1080 : 0.0005874009802937508
Loss at iteration 1090 : 0.0005385736585594714
Loss at iteration 1100 : 0.00018761996761895716
Loss at iteration 1110 : 0.0014962407294660807
Loss at iteration 1120 : 0.0033091572113335133
Loss at iteration 1130 : 6.454045796999708e-05
Loss at iteration 1140 : 0.006563880480825901
Loss at iteration 1150 : 0.001060969429090619
Loss at iteration 1160 : 0.0012823357246816158
Loss at iteration 1170 : 0.0005860762903466821
Loss at iteration 1180 : 0.0013493512524291873
Loss at iteration 1190 : 0.00012744471314363182
Loss at iteration 1200 : 0.000398463656893
Loss at iteration 1210 : 0.003364080097526312
Loss at iteration 1220 : 0.007091057952493429
Loss at iteration 1230 : 0.005423684138804674
Loss at iteration 1240 : 0.000168551632668823
Loss at iteration 1250 : 0.002839584369212389
Loss at iteration 1260 : 0.0002074808580800891
Loss at iteration 1270 : 0.00014487635053228587
Loss at iteration 1280 : 7.55293367546983e-05
Loss at iteration 1290 : 0.001909262384288013
Loss at iteration 1300 : 0.0001259034324903041
Loss at iteration 1310 : 0.00021676014875993133
Loss at iteration 1320 : 0.00020450522424653172
Loss at iteration 1330 : 0.00012615825107786804
Loss at iteration 1340 : 0.007628357503563166
Loss at iteration 1350 : 0.003541807644069195
Loss at iteration 1360 : 0.00010943172674160451
Loss at iteration 1370 : 0.004406404681503773
Loss at iteration 1380 : 0.00033198518212884665
Loss at iteration 1390 : 0.000294820754788816
Loss at iteration 1400 : 0.00264368811622262
Loss at iteration 1410 : 0.0002353274030610919
Loss at iteration 1420 : 0.00018087337957695127
Loss at iteration 1430 : 0.0004925832618027925
Loss at iteration 1440 : 0.0011907177977263927
Loss at iteration 1450 : 0.00036266318056732416
Loss at iteration 1460 : 0.00029598138644360006
Loss at iteration 1470 : 0.002696420531719923
Loss at iteration 1480 : 0.00203603389672935
Loss at iteration 1490 : 0.002849229611456394
Loss at iteration 1500 : 0.00027978167054243386
Loss at iteration 1510 : 5.946712553850375e-05
Loss at iteration 1520 : 8.481859549647197e-05
Loss at iteration 1530 : 0.0028000392485409975
Loss at iteration 1540 : 9.63302081800066e-05
Loss at iteration 1550 : 0.00011533686483744532
Loss at iteration 1560 : 0.0025953962467610836
Loss at iteration 1570 : 0.0004031884018331766
Loss at iteration 1580 : 0.0020238044671714306
Loss at iteration 1590 : 0.00021341003593988717
Loss at iteration 1600 : 0.0001994425692828372
Loss at iteration 1610 : 0.0001214477961184457
Loss at iteration 1620 : 0.00033994874684140086
Loss at iteration 1630 : 0.0002343048545299098
Loss at iteration 1640 : 0.0009772679768502712
Loss at iteration 1650 : 0.00014399737119674683
Loss at iteration 1660 : 0.0004492579319048673
Loss at iteration 1670 : 0.00022915606677997857
Loss at iteration 1680 : 0.0029629324562847614
Loss at iteration 1690 : 0.0004529537109192461
Loss at iteration 1700 : 0.00014993632794357836
Loss at iteration 1710 : 0.0050317975692451
Loss at iteration 1720 : 0.00046567502431571484
Loss at iteration 1730 : 0.0022414159029722214
Loss at iteration 1740 : 0.00011817413906101137
Loss at iteration 1750 : 0.003499763086438179
The SSIM Value is: 0.9859128926556541
The PSNR Value is: 46.100717958374695
the epoch is: 117
Loss at iteration 10 : 0.0006979054305702448
Loss at iteration 20 : 9.131478145718575e-05
Loss at iteration 30 : 0.00015901459846645594
Loss at iteration 40 : 0.00012106340727768838
Loss at iteration 50 : 0.00015245295071508735
Loss at iteration 60 : 0.0011415818007662892
Loss at iteration 70 : 0.003403562121093273
Loss at iteration 80 : 0.00029476318741217256
Loss at iteration 90 : 0.005596595350652933
Loss at iteration 100 : 0.0003733272315002978
Loss at iteration 110 : 0.0001673743681749329
Loss at iteration 120 : 0.002237962558865547
Loss at iteration 130 : 0.0009387654135935009
Loss at iteration 140 : 0.0002973944356199354
Loss at iteration 150 : 0.0003264788829255849
Loss at iteration 160 : 0.003515351563692093
Loss at iteration 170 : 8.291791164083406e-05
Loss at iteration 180 : 0.0008779948111623526
Loss at iteration 190 : 0.0036163951735943556
Loss at iteration 200 : 0.00014585061580874026
Loss at iteration 210 : 0.00021871041099075228
Loss at iteration 220 : 0.00012584748037625104
Loss at iteration 230 : 0.0005210078088566661
Loss at iteration 240 : 0.0002695773437153548
Loss at iteration 250 : 0.0055511873215436935
Loss at iteration 260 : 0.00026801665080711246
Loss at iteration 270 : 0.00013383361510932446
Loss at iteration 280 : 0.0009150281548500061
Loss at iteration 290 : 0.0001525283878436312
Loss at iteration 300 : 0.00025997875491157174
Loss at iteration 310 : 0.002354766707867384
Loss at iteration 320 : 4.9009489885065705e-05
Loss at iteration 330 : 0.0007688010227866471
Loss at iteration 340 : 0.0036484901793301105
Loss at iteration 350 : 0.0006166219245642424
Loss at iteration 360 : 0.0005797195481136441
Loss at iteration 370 : 0.00036440580151975155
Loss at iteration 380 : 0.0018585511716082692
Loss at iteration 390 : 4.656692544813268e-05
Loss at iteration 400 : 0.00023547295131720603
Loss at iteration 410 : 0.0012059458531439304
Loss at iteration 420 : 0.002641150960698724
Loss at iteration 430 : 0.004189423751085997
Loss at iteration 440 : 0.003046941477805376
Loss at iteration 450 : 0.00224883365444839
Loss at iteration 460 : 0.000326197303365916
Loss at iteration 470 : 0.000898779253475368
Loss at iteration 480 : 0.0009557578596286476
Loss at iteration 490 : 0.00035662527079693973
Loss at iteration 500 : 0.0015489659272134304
Loss at iteration 510 : 7.37311493139714e-05
Loss at iteration 520 : 0.001290412270464003
Loss at iteration 530 : 0.00013076105096843094
Loss at iteration 540 : 0.0027005397714674473
Loss at iteration 550 : 0.00045668441453017294
Loss at iteration 560 : 0.0006958772428333759
Loss at iteration 570 : 0.002383571118116379
Loss at iteration 580 : 9.932360262610018e-05
Loss at iteration 590 : 7.466968963854015e-05
Loss at iteration 600 : 0.0002932437928393483
Loss at iteration 610 : 0.0019456320442259312
Loss at iteration 620 : 0.002111871028319001
Loss at iteration 630 : 0.00014537226525135338
Loss at iteration 640 : 0.001838030992075801
Loss at iteration 650 : 0.00012063090980518609
Loss at iteration 660 : 0.0002612441312521696
Loss at iteration 670 : 0.0001180262042907998
Loss at iteration 680 : 0.0013038055039942265
Loss at iteration 690 : 0.000277424551313743
Loss at iteration 700 : 0.000509472971316427
Loss at iteration 710 : 0.0006739245727658272
Loss at iteration 720 : 0.0017602532170712948
Loss at iteration 730 : 0.0008446109131909907
Loss at iteration 740 : 0.0011791841825470328
Loss at iteration 750 : 7.536017074016854e-05
Loss at iteration 760 : 8.877195068635046e-05
Loss at iteration 770 : 0.0023514600470662117
Loss at iteration 780 : 0.0001817703596316278
Loss at iteration 790 : 0.0006333986530080438
Loss at iteration 800 : 0.0006514720153063536
Loss at iteration 810 : 0.0004532637249212712
Loss at iteration 820 : 0.0006972677074372768
Loss at iteration 830 : 0.00010481313802301884
Loss at iteration 840 : 0.00037267126026563346
Loss at iteration 850 : 0.003070325590670109
Loss at iteration 860 : 0.00026389246340841055
Loss at iteration 870 : 0.000604346685577184
Loss at iteration 880 : 8.130916103255004e-05
Loss at iteration 890 : 6.283468246692792e-05
Loss at iteration 900 : 0.0014389132848009467
Loss at iteration 910 : 0.00016879578470252454
Loss at iteration 920 : 9.471619705436751e-05
Loss at iteration 930 : 0.00011086327867815271
Loss at iteration 940 : 0.004289307631552219
Loss at iteration 950 : 0.0008028281736187637
Loss at iteration 960 : 0.0009142415365204215
Loss at iteration 970 : 0.002142033539712429
Loss at iteration 980 : 0.00023333029821515083
Loss at iteration 990 : 9.963069896912202e-05
Loss at iteration 1000 : 0.0004244735464453697
Loss at iteration 1010 : 0.0011262512998655438
Loss at iteration 1020 : 0.002575556980445981
Loss at iteration 1030 : 0.0002299547486472875
Loss at iteration 1040 : 0.00019304122542962432
Loss at iteration 1050 : 0.00016903139476198703
Loss at iteration 1060 : 0.001131861237809062
Loss at iteration 1070 : 0.004267462529242039
Loss at iteration 1080 : 7.655269291717559e-05
Loss at iteration 1090 : 0.0018532141111791134
Loss at iteration 1100 : 0.0017272498225793242
Loss at iteration 1110 : 0.0001768857764545828
Loss at iteration 1120 : 0.0014069403987377882
Loss at iteration 1130 : 0.0038338599260896444
Loss at iteration 1140 : 0.002079288475215435
Loss at iteration 1150 : 0.003309402847662568
Loss at iteration 1160 : 0.00043305399594828486
Loss at iteration 1170 : 0.002371793380007148
Loss at iteration 1180 : 0.00015161422197706997
Loss at iteration 1190 : 0.0005521891289390624
Loss at iteration 1200 : 0.00023774988949298859
Loss at iteration 1210 : 0.0010488718980923295
Loss at iteration 1220 : 0.0023393293377012014
Loss at iteration 1230 : 7.340965385083109e-05
Loss at iteration 1240 : 0.0002572454686742276
Loss at iteration 1250 : 0.0012621115893125534
Loss at iteration 1260 : 7.869937689974904e-05
Loss at iteration 1270 : 0.0002962519647553563
Loss at iteration 1280 : 0.000967270927503705
Loss at iteration 1290 : 0.00010309753997717053
Loss at iteration 1300 : 0.0006559989415109158
Loss at iteration 1310 : 0.0003002715820912272
Loss at iteration 1320 : 0.0008246023207902908
Loss at iteration 1330 : 6.730092718498781e-05
Loss at iteration 1340 : 0.003068177029490471
Loss at iteration 1350 : 0.000513435632456094
Loss at iteration 1360 : 0.00040834100218489766
Loss at iteration 1370 : 0.0006144793005660176
Loss at iteration 1380 : 0.0002751547144725919
Loss at iteration 1390 : 0.0006779122049920261
Loss at iteration 1400 : 0.0004031554562970996
Loss at iteration 1410 : 0.0002769844140857458
Loss at iteration 1420 : 0.0001851738488767296
Loss at iteration 1430 : 0.005964209325611591
Loss at iteration 1440 : 0.00024500113795511425
Loss at iteration 1450 : 0.0009849797934293747
Loss at iteration 1460 : 0.0005745441885665059
Loss at iteration 1470 : 0.0010611447505652905
Loss at iteration 1480 : 0.0005454898346215487
Loss at iteration 1490 : 0.00042180862510576844
Loss at iteration 1500 : 0.0002269557153340429
Loss at iteration 1510 : 0.003126348601654172
Loss at iteration 1520 : 0.000141895841807127
Loss at iteration 1530 : 0.00012277955829631537
Loss at iteration 1540 : 0.0002943851286545396
Loss at iteration 1550 : 8.251670078607276e-05
Loss at iteration 1560 : 0.001100071589462459
Loss at iteration 1570 : 0.00016881794726941735
Loss at iteration 1580 : 0.00042108044726774096
Loss at iteration 1590 : 0.0004080305225215852
Loss at iteration 1600 : 0.0017909316811710596
Loss at iteration 1610 : 0.0004331158706918359
Loss at iteration 1620 : 4.567833821056411e-05
Loss at iteration 1630 : 0.0011871876195073128
Loss at iteration 1640 : 0.00018467416521161795
Loss at iteration 1650 : 6.828132609371096e-05
Loss at iteration 1660 : 0.00022007472580298781
Loss at iteration 1670 : 0.0007133077597245574
Loss at iteration 1680 : 0.0033520227298140526
Loss at iteration 1690 : 0.00025970549904741347
Loss at iteration 1700 : 0.00011698855814756826
Loss at iteration 1710 : 0.00015320177772082388
Loss at iteration 1720 : 0.0002607810602057725
Loss at iteration 1730 : 0.0005377151537686586
Loss at iteration 1740 : 0.00047712569357827306
Loss at iteration 1750 : 0.0006038106512278318
The SSIM Value is: 0.9850154881435343
The PSNR Value is: 45.664063396958
the epoch is: 118
Loss at iteration 10 : 0.0008206224301829934
Loss at iteration 20 : 9.325637074653059e-05
Loss at iteration 30 : 0.003295884933322668
Loss at iteration 40 : 0.00047640412230975926
Loss at iteration 50 : 0.00020696080173365772
Loss at iteration 60 : 0.00017604007734917104
Loss at iteration 70 : 0.0005732036661356688
Loss at iteration 80 : 5.737271931138821e-05
Loss at iteration 90 : 0.0006582911591976881
Loss at iteration 100 : 0.0001782119070412591
Loss at iteration 110 : 0.00011001928942278028
Loss at iteration 120 : 0.0021214366424828768
Loss at iteration 130 : 0.00034146709367632866
Loss at iteration 140 : 0.0014093301724642515
Loss at iteration 150 : 0.0012421885039657354
Loss at iteration 160 : 0.00039756979094818234
Loss at iteration 170 : 0.00428271247074008
Loss at iteration 180 : 0.00012796089868061244
Loss at iteration 190 : 0.00023250520462170243
Loss at iteration 200 : 0.00015223462833091617
Loss at iteration 210 : 0.002330973045900464
Loss at iteration 220 : 0.00027546161436475813
Loss at iteration 230 : 0.0036756570916622877
Loss at iteration 240 : 8.657976286485791e-05
Loss at iteration 250 : 0.0005264420760795474
Loss at iteration 260 : 0.0008721235790289938
Loss at iteration 270 : 0.0033955464605242014
Loss at iteration 280 : 0.00012077939754817635
Loss at iteration 290 : 0.00012807500024791807
Loss at iteration 300 : 0.0005892494227737188
Loss at iteration 310 : 0.0011948311002925038
Loss at iteration 320 : 0.0007659567636437714
Loss at iteration 330 : 0.0001893126463983208
Loss at iteration 340 : 0.0005981296417303383
Loss at iteration 350 : 0.0012120162136852741
Loss at iteration 360 : 0.00016952367150224745
Loss at iteration 370 : 0.00017374490562360734
Loss at iteration 380 : 0.005142545327544212
Loss at iteration 390 : 0.00015054205141495913
Loss at iteration 400 : 0.00015053908282425255
Loss at iteration 410 : 0.0015821598935872316
Loss at iteration 420 : 0.0004596324870362878
Loss at iteration 430 : 0.0005233143456280231
Loss at iteration 440 : 0.0006016913102939725
Loss at iteration 450 : 0.00045423739356920123
Loss at iteration 460 : 0.0003568742540664971
Loss at iteration 470 : 0.00436887051910162
Loss at iteration 480 : 0.0014671587850898504
Loss at iteration 490 : 0.0006121800979599357
Loss at iteration 500 : 0.009508457966148853
Loss at iteration 510 : 0.0009582193451933563
Loss at iteration 520 : 0.00012835770030505955
Loss at iteration 530 : 0.005001205950975418
Loss at iteration 540 : 0.00011112188803963363
Loss at iteration 550 : 0.0009102849289774895
Loss at iteration 560 : 0.0004979701479896903
Loss at iteration 570 : 0.0034664517734199762
Loss at iteration 580 : 0.00023696545395068824
Loss at iteration 590 : 0.001554071088321507
Loss at iteration 600 : 0.00397061463445425
Loss at iteration 610 : 0.00012187484389869496
Loss at iteration 620 : 0.0005053238710388541
Loss at iteration 630 : 0.00532930064946413
Loss at iteration 640 : 9.563610365148634e-05
Loss at iteration 650 : 0.0002886126167140901
Loss at iteration 660 : 0.00012976232392247766
Loss at iteration 670 : 0.0006652417359873652
Loss at iteration 680 : 0.0026392030995339155
Loss at iteration 690 : 0.00045481682172976434
Loss at iteration 700 : 0.00039262452628463507
Loss at iteration 710 : 0.0001964311086339876
Loss at iteration 720 : 0.0002444877754896879
Loss at iteration 730 : 0.0006137312739156187
Loss at iteration 740 : 0.0003412952646613121
Loss at iteration 750 : 0.0004909666022285819
Loss at iteration 760 : 0.000981294782832265
Loss at iteration 770 : 0.0003811080823652446
Loss at iteration 780 : 0.0005618182476609945
Loss at iteration 790 : 0.00044798373710364103
Loss at iteration 800 : 0.00010935393220279366
Loss at iteration 810 : 0.00032096041832119226
Loss at iteration 820 : 6.502788164652884e-05
Loss at iteration 830 : 0.00018901124713011086
Loss at iteration 840 : 0.001699385466054082
Loss at iteration 850 : 0.0001115031773224473
Loss at iteration 860 : 0.00023104601132217795
Loss at iteration 870 : 0.00016228295862674713
Loss at iteration 880 : 0.00017760874470695853
Loss at iteration 890 : 0.0012273204047232866
Loss at iteration 900 : 9.440902067581192e-05
Loss at iteration 910 : 8.697043085703626e-05
Loss at iteration 920 : 0.0002532907819841057
Loss at iteration 930 : 0.001335845678113401
Loss at iteration 940 : 0.0013476377353072166
Loss at iteration 950 : 0.002262706635519862
Loss at iteration 960 : 0.0014283170457929373
Loss at iteration 970 : 0.00020979129476472735
Loss at iteration 980 : 0.0011205300688743591
Loss at iteration 990 : 0.00041008932748809457
Loss at iteration 1000 : 0.001317491289228201
Loss at iteration 1010 : 0.00019742573203984648
Loss at iteration 1020 : 0.0012784816790372133
Loss at iteration 1030 : 0.0006355849327519536
Loss at iteration 1040 : 0.0002841535024344921
Loss at iteration 1050 : 0.004333797842264175
Loss at iteration 1060 : 0.0006541694747284055
Loss at iteration 1070 : 0.00010460009798407555
Loss at iteration 1080 : 0.00020116071391385049
Loss at iteration 1090 : 0.00013966625556349754
Loss at iteration 1100 : 5.23763446835801e-05
Loss at iteration 1110 : 0.00010825295612448826
Loss at iteration 1120 : 0.0014293496496975422
Loss at iteration 1130 : 0.0010207208106294274
Loss at iteration 1140 : 0.0006314041092991829
Loss at iteration 1150 : 0.0005536136450245976
Loss at iteration 1160 : 0.005155913066118956
Loss at iteration 1170 : 0.0002557765692472458
Loss at iteration 1180 : 0.0003432100638747215
Loss at iteration 1190 : 0.0012177727185189724
Loss at iteration 1200 : 0.00026366490055806935
Loss at iteration 1210 : 0.0032040304504334927
Loss at iteration 1220 : 0.0005409540026448667
Loss at iteration 1230 : 0.0003971383557654917
Loss at iteration 1240 : 0.0013951651053503156
Loss at iteration 1250 : 0.0003321266849525273
Loss at iteration 1260 : 7.292650116141886e-05
Loss at iteration 1270 : 0.000582462758757174
Loss at iteration 1280 : 5.5056632845662534e-05
Loss at iteration 1290 : 0.0016429319512099028
Loss at iteration 1300 : 0.0017451834864914417
Loss at iteration 1310 : 0.001528857508674264
Loss at iteration 1320 : 0.0002494275104254484
Loss at iteration 1330 : 0.00579108577221632
Loss at iteration 1340 : 0.0003657700144685805
Loss at iteration 1350 : 9.091536776395515e-05
Loss at iteration 1360 : 0.004227052442729473
Loss at iteration 1370 : 8.512609201716259e-05
Loss at iteration 1380 : 0.0006011321675032377
Loss at iteration 1390 : 0.004514575470238924
Loss at iteration 1400 : 0.0008994190720841289
Loss at iteration 1410 : 0.0006008266936987638
Loss at iteration 1420 : 0.001602215925231576
Loss at iteration 1430 : 0.0031931179109960794
Loss at iteration 1440 : 0.0008012372418306768
Loss at iteration 1450 : 6.338016828522086e-05
Loss at iteration 1460 : 0.0009432719089090824
Loss at iteration 1470 : 0.0002503502764739096
Loss at iteration 1480 : 0.0008384512038901448
Loss at iteration 1490 : 0.00017085862054955214
Loss at iteration 1500 : 0.002663342747837305
Loss at iteration 1510 : 0.00021166200167499483
Loss at iteration 1520 : 0.0003743307897821069
Loss at iteration 1530 : 0.00016672033234499395
Loss at iteration 1540 : 0.000681141042150557
Loss at iteration 1550 : 0.00032521079992875457
Loss at iteration 1560 : 8.68181959958747e-05
Loss at iteration 1570 : 0.0016533227171748877
Loss at iteration 1580 : 0.003708199830725789
Loss at iteration 1590 : 0.0006797638488933444
Loss at iteration 1600 : 7.553538307547569e-05
Loss at iteration 1610 : 0.00026663023163564503
Loss at iteration 1620 : 0.0008068918832577765
Loss at iteration 1630 : 0.0005888519226573408
Loss at iteration 1640 : 0.002904218155890703
Loss at iteration 1650 : 0.0002635133860167116
Loss at iteration 1660 : 0.0013890063855797052
Loss at iteration 1670 : 9.582604980096221e-05
Loss at iteration 1680 : 0.0005978838307783008
Loss at iteration 1690 : 0.0007570324814878404
Loss at iteration 1700 : 0.0004095193580724299
Loss at iteration 1710 : 0.00012094325938960537
Loss at iteration 1720 : 0.0003034771652892232
Loss at iteration 1730 : 0.0001628200407139957
Loss at iteration 1740 : 0.0032263367902487516
Loss at iteration 1750 : 0.0019351225346326828
The SSIM Value is: 0.9696965498546146
The PSNR Value is: 45.58114654482199
the epoch is: 119
Loss at iteration 10 : 0.0002310052514076233
Loss at iteration 20 : 0.0018776990473270416
Loss at iteration 30 : 0.00034460873575881124
Loss at iteration 40 : 0.0018360416870564222
Loss at iteration 50 : 3.849325003102422e-05
Loss at iteration 60 : 0.00012926857743877918
Loss at iteration 70 : 0.00022770896612200886
Loss at iteration 80 : 0.0002150370564777404
Loss at iteration 90 : 0.00013658081297762692
Loss at iteration 100 : 0.00029172649374231696
Loss at iteration 110 : 0.0002470846811775118
Loss at iteration 120 : 0.00017855718033388257
Loss at iteration 130 : 0.0014076429652050138
Loss at iteration 140 : 0.001646817778237164
Loss at iteration 150 : 0.003932654857635498
Loss at iteration 160 : 0.0005451673059724271
Loss at iteration 170 : 0.0002922198618762195
Loss at iteration 180 : 0.00018002493015956134
Loss at iteration 190 : 0.00026615941897034645
Loss at iteration 200 : 0.003128000535070896
Loss at iteration 210 : 0.000574174802750349
Loss at iteration 220 : 0.0006319507956504822
Loss at iteration 230 : 9.894534014165401e-05
Loss at iteration 240 : 6.726022547809407e-05
Loss at iteration 250 : 0.00011895182979060337
Loss at iteration 260 : 0.00017279337043873966
Loss at iteration 270 : 0.0029197598341852427
Loss at iteration 280 : 6.865910836495459e-05
Loss at iteration 290 : 0.001376803731545806
Loss at iteration 300 : 0.005894244648516178
Loss at iteration 310 : 0.00019252307538408786
Loss at iteration 320 : 0.001343705807812512
Loss at iteration 330 : 0.00041772957774810493
Loss at iteration 340 : 7.061728683765978e-05
Loss at iteration 350 : 0.0022560972720384598
Loss at iteration 360 : 8.860618254402652e-05
Loss at iteration 370 : 0.002427914645522833
Loss at iteration 380 : 0.00017258043226320297
Loss at iteration 390 : 0.0002952382492367178
Loss at iteration 400 : 0.0013109265128150582
Loss at iteration 410 : 0.0012196124298498034
Loss at iteration 420 : 0.0003724782436620444
Loss at iteration 430 : 0.0006944225169718266
Loss at iteration 440 : 0.0005560022545978427
Loss at iteration 450 : 7.359393930528313e-05
Loss at iteration 460 : 8.904679998522624e-05
Loss at iteration 470 : 0.00026563636492937803
Loss at iteration 480 : 0.0007500412175431848
Loss at iteration 490 : 0.0002498755347914994
Loss at iteration 500 : 0.00017056637443602085
Loss at iteration 510 : 0.0013354058610275388
Loss at iteration 520 : 0.00028855845448561013
Loss at iteration 530 : 7.127661228878424e-05
Loss at iteration 540 : 0.0011764720547944307
Loss at iteration 550 : 0.0002567429037299007
Loss at iteration 560 : 0.0029799079056829214
Loss at iteration 570 : 0.00012987144873477519
Loss at iteration 580 : 0.0002368168206885457
Loss at iteration 590 : 0.0002883962879423052
Loss at iteration 600 : 0.0017625832697376609
Loss at iteration 610 : 0.0001617440429981798
Loss at iteration 620 : 0.0002006431168410927
Loss at iteration 630 : 9.393158688908443e-05
Loss at iteration 640 : 0.002157983835786581
Loss at iteration 650 : 0.001278191339224577
Loss at iteration 660 : 0.00011356059985700995
Loss at iteration 670 : 0.00026930891908705235
Loss at iteration 680 : 0.0019393772818148136
Loss at iteration 690 : 0.000689620734192431
Loss at iteration 700 : 0.00034756711102090776
Loss at iteration 710 : 0.00014066355652175844
Loss at iteration 720 : 9.761687397258356e-05
Loss at iteration 730 : 0.00016222165140789002
Loss at iteration 740 : 0.00025486506638117135
Loss at iteration 750 : 0.0008783612865954638
Loss at iteration 760 : 0.0002106021565850824
Loss at iteration 770 : 0.0025243028067052364
Loss at iteration 780 : 0.00021775586355943233
Loss at iteration 790 : 0.0012442514998838305
Loss at iteration 800 : 0.0022542085498571396
Loss at iteration 810 : 0.00018255476607009768
Loss at iteration 820 : 0.003760199062526226
Loss at iteration 830 : 0.00016901514027267694
Loss at iteration 840 : 0.0005290888948366046
Loss at iteration 850 : 0.0007535771001130342
Loss at iteration 860 : 0.0005673033301718533
Loss at iteration 870 : 0.0009143155766651034
Loss at iteration 880 : 0.009067146107554436
Loss at iteration 890 : 0.0005427038413472474
Loss at iteration 900 : 0.0003322869015391916
Loss at iteration 910 : 0.00013211551413405687
Loss at iteration 920 : 0.0039227427914738655
Loss at iteration 930 : 0.00021538093278650194
Loss at iteration 940 : 0.001439821207895875
Loss at iteration 950 : 0.00022093381267040968
Loss at iteration 960 : 0.0028710446786135435
Loss at iteration 970 : 0.0024996879510581493
Loss at iteration 980 : 0.00034900911850854754
Loss at iteration 990 : 0.00017244303307961673
Loss at iteration 1000 : 0.00043378525879234076
Loss at iteration 1010 : 0.00018515661940909922
Loss at iteration 1020 : 0.0010283691808581352
Loss at iteration 1030 : 0.005054057575762272
Loss at iteration 1040 : 0.00027642297209240496
Loss at iteration 1050 : 0.0004559661610983312
Loss at iteration 1060 : 0.002145754173398018
Loss at iteration 1070 : 0.005197632592171431
Loss at iteration 1080 : 0.00021223953808657825
Loss at iteration 1090 : 0.0024833562783896923
Loss at iteration 1100 : 5.3893971198704094e-05
Loss at iteration 1110 : 7.592287147417665e-05
Loss at iteration 1120 : 0.00014348771946970373
Loss at iteration 1130 : 0.00012139477621531114
Loss at iteration 1140 : 0.0001552405155962333
Loss at iteration 1150 : 0.002762205433100462
Loss at iteration 1160 : 0.0004993965849280357
Loss at iteration 1170 : 0.00229840911924839
Loss at iteration 1180 : 7.318836287595332e-05
Loss at iteration 1190 : 0.0002948117326013744
Loss at iteration 1200 : 0.0014424615073949099
Loss at iteration 1210 : 0.0036243044305592775
Loss at iteration 1220 : 0.00026130047626793385
Loss at iteration 1230 : 0.004060443956404924
Loss at iteration 1240 : 0.00015542343317065388
Loss at iteration 1250 : 0.0004577019717544317
Loss at iteration 1260 : 0.0018229890847578645
Loss at iteration 1270 : 0.0022129486314952374
Loss at iteration 1280 : 0.00031921896152198315
Loss at iteration 1290 : 0.0007467595860362053
Loss at iteration 1300 : 0.0001700204738881439
Loss at iteration 1310 : 0.0001634783111512661
Loss at iteration 1320 : 0.0004049037816002965
Loss at iteration 1330 : 0.0005851842579431832
Loss at iteration 1340 : 0.00010612452024361119
Loss at iteration 1350 : 0.00012484757462516427
Loss at iteration 1360 : 0.0006765020079910755
Loss at iteration 1370 : 0.001900254748761654
Loss at iteration 1380 : 0.00015000073472037911
Loss at iteration 1390 : 0.0002587773196864873
Loss at iteration 1400 : 0.00039076153188943863
Loss at iteration 1410 : 0.00045584607869386673
Loss at iteration 1420 : 0.00360915157943964
Loss at iteration 1430 : 0.0019203370902687311
Loss at iteration 1440 : 0.0008298547472804785
Loss at iteration 1450 : 0.0006723738042637706
Loss at iteration 1460 : 0.0034002186730504036
Loss at iteration 1470 : 0.0002456478541716933
Loss at iteration 1480 : 0.0009110818500630558
Loss at iteration 1490 : 0.0024688374251127243
Loss at iteration 1500 : 0.00021029889467172325
Loss at iteration 1510 : 8.343603258254007e-05
Loss at iteration 1520 : 0.0009776260703802109
Loss at iteration 1530 : 0.0001471740542910993
Loss at iteration 1540 : 0.0005538430996239185
Loss at iteration 1550 : 0.00012263220560271293
Loss at iteration 1560 : 9.852162474999204e-05
Loss at iteration 1570 : 0.0015027393819764256
Loss at iteration 1580 : 0.00010336414561606944
Loss at iteration 1590 : 0.0005364975077100098
Loss at iteration 1600 : 0.0016674203798174858
Loss at iteration 1610 : 0.005611206404864788
Loss at iteration 1620 : 0.0004638491082005203
Loss at iteration 1630 : 0.0018517000135034323
Loss at iteration 1640 : 0.0002776109613478184
Loss at iteration 1650 : 0.0026265927590429783
Loss at iteration 1660 : 0.00021826414740644395
Loss at iteration 1670 : 0.0029189852066338062
Loss at iteration 1680 : 0.0002944072475656867
Loss at iteration 1690 : 0.00017139040573965758
Loss at iteration 1700 : 0.0002678166201803833
Loss at iteration 1710 : 0.00016578398935962468
Loss at iteration 1720 : 0.0012642033398151398
Loss at iteration 1730 : 0.00131507299374789
Loss at iteration 1740 : 0.0001947490673046559
Loss at iteration 1750 : 0.0003286033752374351
The SSIM Value is: 0.9863444724272001
The PSNR Value is: 45.90659702821975
the epoch is: 120
Loss at iteration 10 : 0.002154682297259569
Loss at iteration 20 : 0.0009182952344417572
Loss at iteration 30 : 0.00014381774235516787
Loss at iteration 40 : 0.003260933794081211
Loss at iteration 50 : 0.00016409083036705852
Loss at iteration 60 : 0.0012565958313643932
Loss at iteration 70 : 8.968635665951297e-05
Loss at iteration 80 : 0.0005055470392107964
Loss at iteration 90 : 0.0004337789723649621
Loss at iteration 100 : 0.0002045453729806468
Loss at iteration 110 : 0.0024255975149571896
Loss at iteration 120 : 0.0046132635325193405
Loss at iteration 130 : 7.643748540431261e-05
Loss at iteration 140 : 0.0006113268900662661
Loss at iteration 150 : 0.005111494101583958
Loss at iteration 160 : 0.00018913031090050936
Loss at iteration 170 : 9.739875531522557e-05
Loss at iteration 180 : 0.004763743374496698
Loss at iteration 190 : 0.00013381114695221186
Loss at iteration 200 : 0.00040736646042205393
Loss at iteration 210 : 0.00014494550123345107
Loss at iteration 220 : 0.00020736157603096217
Loss at iteration 230 : 0.0016783392056822777
Loss at iteration 240 : 0.00023226888151839375
Loss at iteration 250 : 0.00011937525414396077
Loss at iteration 260 : 0.00011691553663695231
Loss at iteration 270 : 0.0021288509014993906
Loss at iteration 280 : 0.00015827023889869452
Loss at iteration 290 : 0.001644322881475091
Loss at iteration 300 : 0.0003172011929564178
Loss at iteration 310 : 7.586101128254086e-05
Loss at iteration 320 : 8.506822632625699e-05
Loss at iteration 330 : 0.0034129612613469362
Loss at iteration 340 : 0.00010139114601770416
Loss at iteration 350 : 0.00025327029288746417
Loss at iteration 360 : 0.00020838712225668132
Loss at iteration 370 : 0.0001832981506595388
Loss at iteration 380 : 0.0030302987433969975
Loss at iteration 390 : 0.00015354956849478185
Loss at iteration 400 : 0.00115161610301584
Loss at iteration 410 : 0.00011977215763181448
Loss at iteration 420 : 0.00017835164908319712
Loss at iteration 430 : 0.0003803883446380496
Loss at iteration 440 : 0.0005834717303514481
Loss at iteration 450 : 0.0005891646142117679
Loss at iteration 460 : 0.0009015988325700164
Loss at iteration 470 : 0.00017109629698097706
Loss at iteration 480 : 0.0005818282952532172
Loss at iteration 490 : 0.00027180250617675483
Loss at iteration 500 : 0.0069863274693489075
Loss at iteration 510 : 0.00013890092668589205
Loss at iteration 520 : 0.0009209701092913747
Loss at iteration 530 : 0.00021978982840664685
Loss at iteration 540 : 6.564366049133241e-05
Loss at iteration 550 : 0.00020563311409205198
Loss at iteration 560 : 0.00012611770944204181
Loss at iteration 570 : 0.001364059280604124
Loss at iteration 580 : 0.0014753028517588973
Loss at iteration 590 : 0.0006063196924515069
Loss at iteration 600 : 0.0009582405909895897
Loss at iteration 610 : 0.00033763734973035753
Loss at iteration 620 : 0.00208057789131999
Loss at iteration 630 : 3.4088167012669146e-05
Loss at iteration 640 : 0.0003073161351494491
Loss at iteration 650 : 0.00014112883945927024
Loss at iteration 660 : 0.00029884109972044826
Loss at iteration 670 : 0.0005685960641130805
Loss at iteration 680 : 0.00026833469746634364
Loss at iteration 690 : 0.0009602081263437867
Loss at iteration 700 : 0.0037711667828261852
Loss at iteration 710 : 0.0004669891786761582
Loss at iteration 720 : 0.0027469643391668797
Loss at iteration 730 : 9.353868517791852e-05
Loss at iteration 740 : 0.0003425224858801812
Loss at iteration 750 : 0.00465505663305521
Loss at iteration 760 : 0.000874434073921293
Loss at iteration 770 : 0.0002652291441336274
Loss at iteration 780 : 0.000686215702444315
Loss at iteration 790 : 0.00042807665886357427
Loss at iteration 800 : 0.00011458345397841185
Loss at iteration 810 : 0.00045527389738708735
Loss at iteration 820 : 0.00027279858477413654
Loss at iteration 830 : 0.00010522101365495473
Loss at iteration 840 : 0.00039538240525871515
Loss at iteration 850 : 0.005564928986132145
Loss at iteration 860 : 0.0005544640589505434
Loss at iteration 870 : 0.0005818734643980861
Loss at iteration 880 : 0.0001870396372396499
Loss at iteration 890 : 0.0017311957199126482
Loss at iteration 900 : 5.97616053710226e-05
Loss at iteration 910 : 0.0031617842614650726
Loss at iteration 920 : 0.0022863808553665876
Loss at iteration 930 : 0.007358885370194912
Loss at iteration 940 : 0.0008617671555839479
Loss at iteration 950 : 0.0009933615801855922
Loss at iteration 960 : 0.0012085888301953673
Loss at iteration 970 : 0.0008171694353222847
Loss at iteration 980 : 0.0026336766313761473
Loss at iteration 990 : 0.0006563570932485163
Loss at iteration 1000 : 0.00028565339744091034
Loss at iteration 1010 : 0.0001669460762059316
Loss at iteration 1020 : 0.00017902854597195983
Loss at iteration 1030 : 0.0004510061990004033
Loss at iteration 1040 : 0.00048806422273628414
Loss at iteration 1050 : 0.0015981707256287336
Loss at iteration 1060 : 0.00024474484962411225
Loss at iteration 1070 : 0.003258819691836834
Loss at iteration 1080 : 7.980244845384732e-05
Loss at iteration 1090 : 9.909489745041355e-05
Loss at iteration 1100 : 0.00045483410940505564
Loss at iteration 1110 : 0.0010287344921380281
Loss at iteration 1120 : 0.0014380437787622213
Loss at iteration 1130 : 9.040827717399225e-05
Loss at iteration 1140 : 0.0035969337914139032
Loss at iteration 1150 : 0.003041674615815282
Loss at iteration 1160 : 0.000300370913464576
Loss at iteration 1170 : 0.002440284937620163
Loss at iteration 1180 : 7.800004095770419e-05
Loss at iteration 1190 : 0.00017235387349501252
Loss at iteration 1200 : 0.00014314583677332848
Loss at iteration 1210 : 0.00031297083478420973
Loss at iteration 1220 : 0.0005580524448305368
Loss at iteration 1230 : 0.00012848660117015243
Loss at iteration 1240 : 0.0002881590335164219
Loss at iteration 1250 : 0.00019724802405107766
Loss at iteration 1260 : 0.00014059414388611913
Loss at iteration 1270 : 0.0019293786026537418
Loss at iteration 1280 : 0.0037176974583417177
Loss at iteration 1290 : 0.00023893102479632944
Loss at iteration 1300 : 0.0010199618991464376
Loss at iteration 1310 : 0.0005732967983931303
Loss at iteration 1320 : 0.0021913861855864525
Loss at iteration 1330 : 0.0008416958153247833
Loss at iteration 1340 : 0.00020975354709662497
Loss at iteration 1350 : 0.00016775866970419884
Loss at iteration 1360 : 0.0009006247855722904
Loss at iteration 1370 : 0.003768657799810171
Loss at iteration 1380 : 0.00017888462753035128
Loss at iteration 1390 : 0.0001865960657596588
Loss at iteration 1400 : 0.00016167813737411052
Loss at iteration 1410 : 0.0019403818296268582
Loss at iteration 1420 : 0.0004797589499503374
Loss at iteration 1430 : 0.0005102705908939242
Loss at iteration 1440 : 0.00024209124967455864
Loss at iteration 1450 : 0.00019041477935388684
Loss at iteration 1460 : 0.0019298915285617113
Loss at iteration 1470 : 0.0001568214502185583
Loss at iteration 1480 : 0.00045011506881564856
Loss at iteration 1490 : 0.00010289350029779598
Loss at iteration 1500 : 2.0876890630461276e-05
Loss at iteration 1510 : 0.00071339076384902
Loss at iteration 1520 : 0.001978876069188118
Loss at iteration 1530 : 9.025022882269695e-05
Loss at iteration 1540 : 0.0003214688622392714
Loss at iteration 1550 : 0.00045358180068433285
Loss at iteration 1560 : 0.0002111905487254262
Loss at iteration 1570 : 0.00010490717249922454
Loss at iteration 1580 : 9.600629709893838e-05
Loss at iteration 1590 : 0.0003713104233611375
Loss at iteration 1600 : 0.00022775825345888734
Loss at iteration 1610 : 0.002921181730926037
Loss at iteration 1620 : 0.0016275359084829688
Loss at iteration 1630 : 0.0006560615729540586
Loss at iteration 1640 : 0.002475159242749214
Loss at iteration 1650 : 0.0001655626983847469
Loss at iteration 1660 : 0.004826463758945465
Loss at iteration 1670 : 0.00046877586282789707
Loss at iteration 1680 : 0.003273965325206518
Loss at iteration 1690 : 0.002261423971503973
Loss at iteration 1700 : 0.003348782891407609
Loss at iteration 1710 : 0.0002374722680542618
Loss at iteration 1720 : 0.00014645988994743675
Loss at iteration 1730 : 0.00017428037244826555
Loss at iteration 1740 : 0.0009558854508213699
Loss at iteration 1750 : 0.0006955893477424979
The SSIM Value is: 0.9830782908437535
The PSNR Value is: 46.519738100698866
the epoch is: 121
Loss at iteration 10 : 0.00014050354366190732
Loss at iteration 20 : 8.623106259619817e-05
Loss at iteration 30 : 0.0005735780578106642
Loss at iteration 40 : 0.0010421775514259934
Loss at iteration 50 : 0.00016602357209194452
Loss at iteration 60 : 0.0037293878849595785
Loss at iteration 70 : 0.0036549419164657593
Loss at iteration 80 : 0.00038679916178807616
Loss at iteration 90 : 0.0015714758774265647
Loss at iteration 100 : 0.009381449781358242
Loss at iteration 110 : 0.00025108325644396245
Loss at iteration 120 : 0.0010713324882090092
Loss at iteration 130 : 0.0006939208833500743
Loss at iteration 140 : 0.0004547392309177667
Loss at iteration 150 : 0.002394120441749692
Loss at iteration 160 : 0.0021920253057032824
Loss at iteration 170 : 0.00013035355368629098
Loss at iteration 180 : 0.00019598596554715186
Loss at iteration 190 : 0.00023868188145570457
Loss at iteration 200 : 0.00021752514294348657
Loss at iteration 210 : 0.000352482806192711
Loss at iteration 220 : 0.0014830923173576593
Loss at iteration 230 : 0.00016252484056167305
Loss at iteration 240 : 0.002269231015816331
Loss at iteration 250 : 0.0014695916324853897
Loss at iteration 260 : 7.147243741201237e-05
Loss at iteration 270 : 0.0020349002443253994
Loss at iteration 280 : 9.256585326511413e-05
Loss at iteration 290 : 0.003286719089373946
Loss at iteration 300 : 0.0022069718688726425
Loss at iteration 310 : 0.00012340770626906306
Loss at iteration 320 : 0.00031504477374255657
Loss at iteration 330 : 0.0003385246673133224
Loss at iteration 340 : 0.0005008737789466977
Loss at iteration 350 : 0.0003135940642096102
Loss at iteration 360 : 0.0025260101538151503
Loss at iteration 370 : 7.191451732069254e-05
Loss at iteration 380 : 0.0028393070679157972
Loss at iteration 390 : 0.0001123991678468883
Loss at iteration 400 : 9.518714068690315e-05
Loss at iteration 410 : 0.0006812536157667637
Loss at iteration 420 : 0.0005674210260622203
Loss at iteration 430 : 0.00014727780944667757
Loss at iteration 440 : 0.00024180932086892426
Loss at iteration 450 : 0.0009155608713626862
Loss at iteration 460 : 0.001797680975869298
Loss at iteration 470 : 0.0003589543921407312
Loss at iteration 480 : 0.00012260426592547446
Loss at iteration 490 : 0.0024029193446040154
Loss at iteration 500 : 0.00031879564630798995
Loss at iteration 510 : 9.504740592092276e-05
Loss at iteration 520 : 7.871714478824288e-05
Loss at iteration 530 : 0.0003354084910824895
Loss at iteration 540 : 0.006994930095970631
Loss at iteration 550 : 0.00014061536057852209
Loss at iteration 560 : 0.0017944058636203408
Loss at iteration 570 : 0.00016868802777025849
Loss at iteration 580 : 0.003337936010211706
Loss at iteration 590 : 0.0033017247915267944
Loss at iteration 600 : 0.0005990508943796158
Loss at iteration 610 : 6.552245031343773e-05
Loss at iteration 620 : 8.21537323645316e-05
Loss at iteration 630 : 0.00017854718316812068
Loss at iteration 640 : 0.004194268491119146
Loss at iteration 650 : 0.0005025003338232636
Loss at iteration 660 : 0.0002742287761066109
Loss at iteration 670 : 0.004124192520976067
Loss at iteration 680 : 9.514189150650054e-05
Loss at iteration 690 : 0.0005023262929171324
Loss at iteration 700 : 0.0008764982922002673
Loss at iteration 710 : 0.00025067460956051946
Loss at iteration 720 : 0.00012563879135996103
Loss at iteration 730 : 0.0006789801991544664
Loss at iteration 740 : 0.00030820301617495716
Loss at iteration 750 : 0.00026026874547824264
Loss at iteration 760 : 0.0010811628308147192
Loss at iteration 770 : 0.0009057073039002717
Loss at iteration 780 : 0.0025792443193495274
Loss at iteration 790 : 0.0002234054118162021
Loss at iteration 800 : 0.00012989185051992536
Loss at iteration 810 : 0.002000286942347884
Loss at iteration 820 : 0.0026359453331679106
Loss at iteration 830 : 0.0018506613560020924
Loss at iteration 840 : 0.00012184980732854456
Loss at iteration 850 : 0.00019446351507212967
Loss at iteration 860 : 5.0952614401467144e-05
Loss at iteration 870 : 0.0023684795014560223
Loss at iteration 880 : 7.143357652239501e-05
Loss at iteration 890 : 0.0023094224743545055
Loss at iteration 900 : 0.0004317826242186129
Loss at iteration 910 : 0.0008654260891489685
Loss at iteration 920 : 0.00043097324669361115
Loss at iteration 930 : 0.00034801376750692725
Loss at iteration 940 : 0.0008605002658441663
Loss at iteration 950 : 0.0029567559249699116
Loss at iteration 960 : 0.00014294104767031968
Loss at iteration 970 : 0.00047495256876572967
Loss at iteration 980 : 0.000527972006238997
Loss at iteration 990 : 0.0021904795430600643
Loss at iteration 1000 : 0.00022418095613829792
Loss at iteration 1010 : 0.0017541853012517095
Loss at iteration 1020 : 0.0023711896501481533
Loss at iteration 1030 : 7.212683703983203e-05
Loss at iteration 1040 : 0.003642719704657793
Loss at iteration 1050 : 0.00014144387387204915
Loss at iteration 1060 : 0.0013335775583982468
Loss at iteration 1070 : 0.00017366507381666452
Loss at iteration 1080 : 0.0005083605647087097
Loss at iteration 1090 : 0.003498727921396494
Loss at iteration 1100 : 0.0001601426483830437
Loss at iteration 1110 : 0.0038329982198774815
Loss at iteration 1120 : 8.410828013438731e-05
Loss at iteration 1130 : 0.00019080516358371824
Loss at iteration 1140 : 0.001117131905630231
Loss at iteration 1150 : 0.003371291793882847
Loss at iteration 1160 : 0.006508818827569485
Loss at iteration 1170 : 0.00026999058900400996
Loss at iteration 1180 : 0.000259315682342276
Loss at iteration 1190 : 0.000170439641806297
Loss at iteration 1200 : 0.0004000422777608037
Loss at iteration 1210 : 0.003089755307883024
Loss at iteration 1220 : 0.0005099237314425409
Loss at iteration 1230 : 0.0001055656248354353
Loss at iteration 1240 : 7.040576019790024e-05
Loss at iteration 1250 : 0.00022046137019060552
Loss at iteration 1260 : 6.515245331684127e-05
Loss at iteration 1270 : 4.895453093922697e-05
Loss at iteration 1280 : 0.0007687861216254532
Loss at iteration 1290 : 0.00047741117305122316
Loss at iteration 1300 : 0.00031351111829280853
Loss at iteration 1310 : 0.00020810007117688656
Loss at iteration 1320 : 0.0001657685497775674
Loss at iteration 1330 : 0.005109657067805529
Loss at iteration 1340 : 0.00035133492201566696
Loss at iteration 1350 : 0.002440736861899495
Loss at iteration 1360 : 5.453780613606796e-05
Loss at iteration 1370 : 0.002862309105694294
Loss at iteration 1380 : 0.00020480318926274776
Loss at iteration 1390 : 0.0014605270698666573
Loss at iteration 1400 : 0.0029187086038291454
Loss at iteration 1410 : 0.00023224404139909893
Loss at iteration 1420 : 0.0011612314265221357
Loss at iteration 1430 : 7.674522930756211e-05
Loss at iteration 1440 : 0.00022767347400076687
Loss at iteration 1450 : 0.00030600817990489304
Loss at iteration 1460 : 0.0003238274366594851
Loss at iteration 1470 : 0.0001831854460760951
Loss at iteration 1480 : 0.0005291114212013781
Loss at iteration 1490 : 0.00020990503253415227
Loss at iteration 1500 : 0.00028682081028819084
Loss at iteration 1510 : 0.00021864892914891243
Loss at iteration 1520 : 0.002735322341322899
Loss at iteration 1530 : 0.001425824360921979
Loss at iteration 1540 : 0.0008096472593024373
Loss at iteration 1550 : 0.001515109557658434
Loss at iteration 1560 : 0.0004926021792925894
Loss at iteration 1570 : 0.0007062433869577944
Loss at iteration 1580 : 9.238782513421029e-05
Loss at iteration 1590 : 0.0031581076327711344
Loss at iteration 1600 : 0.0002933697833213955
Loss at iteration 1610 : 0.0002963146544061601
Loss at iteration 1620 : 0.0006059609004296362
Loss at iteration 1630 : 0.0002617013524286449
Loss at iteration 1640 : 0.0005720080807805061
Loss at iteration 1650 : 0.000319000449962914
Loss at iteration 1660 : 0.00021636011661030352
Loss at iteration 1670 : 0.00397214712575078
Loss at iteration 1680 : 0.00018798196106217802
Loss at iteration 1690 : 0.0001750088413245976
Loss at iteration 1700 : 0.00017685978673398495
Loss at iteration 1710 : 0.0006974323187023401
Loss at iteration 1720 : 0.000203433824935928
Loss at iteration 1730 : 0.0021214578300714493
Loss at iteration 1740 : 0.0007847368833608925
Loss at iteration 1750 : 0.0001252452057087794
The SSIM Value is: 0.9863266255624494
The PSNR Value is: 46.27678145396027
the epoch is: 122
Loss at iteration 10 : 0.002681983634829521
Loss at iteration 20 : 0.0005465665017254651
Loss at iteration 30 : 0.0005161116714589298
Loss at iteration 40 : 0.00015303508553188294
Loss at iteration 50 : 0.00029943761182948947
Loss at iteration 60 : 0.0008472795598208904
Loss at iteration 70 : 0.0004542448732536286
Loss at iteration 80 : 2.8645716156461276e-05
Loss at iteration 90 : 0.004223950672894716
Loss at iteration 100 : 0.00022415097919292748
Loss at iteration 110 : 0.00023074776981957257
Loss at iteration 120 : 0.0002922323765233159
Loss at iteration 130 : 0.001536759315058589
Loss at iteration 140 : 0.0005171647644601762
Loss at iteration 150 : 0.0007119554211385548
Loss at iteration 160 : 0.0002887625596486032
Loss at iteration 170 : 0.000283390108961612
Loss at iteration 180 : 0.0003105381620116532
Loss at iteration 190 : 0.0015649809502065182
Loss at iteration 200 : 0.0007586330757476389
Loss at iteration 210 : 0.0030654347501695156
Loss at iteration 220 : 0.0004676935204770416
Loss at iteration 230 : 0.0007052607834339142
Loss at iteration 240 : 0.0004290093493182212
Loss at iteration 250 : 0.004908239468932152
Loss at iteration 260 : 8.571024955017492e-05
Loss at iteration 270 : 0.00039973657112568617
Loss at iteration 280 : 0.0011147905606776476
Loss at iteration 290 : 0.0002786130935419351
Loss at iteration 300 : 0.0002604701730888337
Loss at iteration 310 : 0.00022364802134688944
Loss at iteration 320 : 0.00018686524708755314
Loss at iteration 330 : 0.00040677550714462996
Loss at iteration 340 : 0.0004488130216486752
Loss at iteration 350 : 0.0001734867983032018
Loss at iteration 360 : 0.0004472449654713273
Loss at iteration 370 : 9.274494368582964e-05
Loss at iteration 380 : 9.269210568163544e-05
Loss at iteration 390 : 0.003184056840837002
Loss at iteration 400 : 0.0010252712527289987
Loss at iteration 410 : 0.0032590115442872047
Loss at iteration 420 : 0.00010644476424204186
Loss at iteration 430 : 0.000260858767433092
Loss at iteration 440 : 0.00020234959083609283
Loss at iteration 450 : 0.0008275400032289326
Loss at iteration 460 : 0.005445336923003197
Loss at iteration 470 : 0.002609924180433154
Loss at iteration 480 : 0.004909127485007048
Loss at iteration 490 : 0.00015317215002141893
Loss at iteration 500 : 0.0007585742278024554
Loss at iteration 510 : 7.505622488679364e-05
Loss at iteration 520 : 0.00013033361756242812
Loss at iteration 530 : 0.00034452794352546334
Loss at iteration 540 : 0.0044210501946508884
Loss at iteration 550 : 0.0017051630420610309
Loss at iteration 560 : 0.0002099105913657695
Loss at iteration 570 : 3.076824577874504e-05
Loss at iteration 580 : 6.62720703985542e-05
Loss at iteration 590 : 7.358275615843013e-05
Loss at iteration 600 : 0.0004369678790681064
Loss at iteration 610 : 8.444531704299152e-05
Loss at iteration 620 : 0.0030242223292589188
Loss at iteration 630 : 0.0003862057637888938
Loss at iteration 640 : 0.0001357995643047616
Loss at iteration 650 : 0.0004542627139016986
Loss at iteration 660 : 0.0003238402132410556
Loss at iteration 670 : 0.00045457767555490136
Loss at iteration 680 : 3.671475133160129e-05
Loss at iteration 690 : 0.0025741527788341045
Loss at iteration 700 : 0.0009373691864311695
Loss at iteration 710 : 0.001929786056280136
Loss at iteration 720 : 9.783727000467479e-05
Loss at iteration 730 : 0.0021881817374378443
Loss at iteration 740 : 0.0007343471515923738
Loss at iteration 750 : 0.000783094554208219
Loss at iteration 760 : 0.005622592754662037
Loss at iteration 770 : 0.00010286130418535322
Loss at iteration 780 : 0.00022734068625140935
Loss at iteration 790 : 0.0006110145477578044
Loss at iteration 800 : 7.798793376423419e-05
Loss at iteration 810 : 0.0005687749362550676
Loss at iteration 820 : 0.0017856531776487827
Loss at iteration 830 : 0.002438264898955822
Loss at iteration 840 : 0.0004742446180898696
Loss at iteration 850 : 0.0004301724839024246
Loss at iteration 860 : 0.00023167533800005913
Loss at iteration 870 : 0.00018035198445431888
Loss at iteration 880 : 4.334957338869572e-05
Loss at iteration 890 : 0.00018329333397559822
Loss at iteration 900 : 0.001683241338469088
Loss at iteration 910 : 0.0010464431252330542
Loss at iteration 920 : 0.00015890462964307517
Loss at iteration 930 : 0.000522805203218013
Loss at iteration 940 : 0.0005263612838461995
Loss at iteration 950 : 0.0009071957319974899
Loss at iteration 960 : 0.0030357087962329388
Loss at iteration 970 : 0.0013196133077144623
Loss at iteration 980 : 0.00012899241119157523
Loss at iteration 990 : 9.658880298957229e-05
Loss at iteration 1000 : 0.00036065062158741057
Loss at iteration 1010 : 0.0024846685118973255
Loss at iteration 1020 : 0.0008151325164362788
Loss at iteration 1030 : 0.0011705756187438965
Loss at iteration 1040 : 0.00034696486545726657
Loss at iteration 1050 : 0.0002811726008076221
Loss at iteration 1060 : 0.0003043279575649649
Loss at iteration 1070 : 0.00010258228576276451
Loss at iteration 1080 : 0.001292089931666851
Loss at iteration 1090 : 0.002169577870517969
Loss at iteration 1100 : 0.00030219892505556345
Loss at iteration 1110 : 0.00018544688646215945
Loss at iteration 1120 : 0.004457869566977024
Loss at iteration 1130 : 0.0010084164096042514
Loss at iteration 1140 : 0.0010722355218604207
Loss at iteration 1150 : 0.006487452890723944
Loss at iteration 1160 : 9.179890912491828e-05
Loss at iteration 1170 : 0.00011156710388604552
Loss at iteration 1180 : 0.0003479981969576329
Loss at iteration 1190 : 8.076659287326038e-05
Loss at iteration 1200 : 0.00031970810960046947
Loss at iteration 1210 : 0.0009513482800684869
Loss at iteration 1220 : 0.0001123541733250022
Loss at iteration 1230 : 0.0011640690499916673
Loss at iteration 1240 : 0.0002950491034425795
Loss at iteration 1250 : 0.0004695081734098494
Loss at iteration 1260 : 0.00492405379191041
Loss at iteration 1270 : 0.00020194193348288536
Loss at iteration 1280 : 0.0024604201316833496
Loss at iteration 1290 : 0.00014379635103978217
Loss at iteration 1300 : 0.001402157824486494
Loss at iteration 1310 : 7.400987669825554e-05
Loss at iteration 1320 : 0.0001900748029584065
Loss at iteration 1330 : 0.00010277858382323757
Loss at iteration 1340 : 0.0002713529102038592
Loss at iteration 1350 : 0.004583492875099182
Loss at iteration 1360 : 9.961500472854823e-05
Loss at iteration 1370 : 0.0009980180766433477
Loss at iteration 1380 : 0.0015928430948406458
Loss at iteration 1390 : 0.00011209566582692787
Loss at iteration 1400 : 0.00023703654005657881
Loss at iteration 1410 : 0.0023911409080028534
Loss at iteration 1420 : 0.0017398919444531202
Loss at iteration 1430 : 0.00020406945259310305
Loss at iteration 1440 : 0.0011079874821007252
Loss at iteration 1450 : 0.0008119565900415182
Loss at iteration 1460 : 0.0013207764131948352
Loss at iteration 1470 : 0.00014883330732118338
Loss at iteration 1480 : 0.0027482006698846817
Loss at iteration 1490 : 7.819282473064959e-05
Loss at iteration 1500 : 0.00037316675297915936
Loss at iteration 1510 : 0.001594302011653781
Loss at iteration 1520 : 0.0009602591162547469
Loss at iteration 1530 : 0.0008074977085925639
Loss at iteration 1540 : 0.0003482885949779302
Loss at iteration 1550 : 0.0002430676540825516
Loss at iteration 1560 : 0.00023626544862054288
Loss at iteration 1570 : 0.00015126774087548256
Loss at iteration 1580 : 0.003433732781559229
Loss at iteration 1590 : 0.0002460489922668785
Loss at iteration 1600 : 0.00027636607410386205
Loss at iteration 1610 : 0.0007056479225866497
Loss at iteration 1620 : 0.00027968501672148705
Loss at iteration 1630 : 0.004340781830251217
Loss at iteration 1640 : 0.00020157812105026096
Loss at iteration 1650 : 7.583534170407802e-05
Loss at iteration 1660 : 0.00023822455841582268
Loss at iteration 1670 : 6.752151239197701e-05
Loss at iteration 1680 : 0.004212318453937769
Loss at iteration 1690 : 0.00023261159367393702
Loss at iteration 1700 : 0.0046239327639341354
Loss at iteration 1710 : 0.00022119675122667104
Loss at iteration 1720 : 0.0005670596146956086
Loss at iteration 1730 : 0.0004563232068903744
Loss at iteration 1740 : 0.00012874676031060517
Loss at iteration 1750 : 0.0002000006497837603
The SSIM Value is: 0.9859832336198916
The PSNR Value is: 46.31651653592282
the epoch is: 123
Loss at iteration 10 : 0.00225311191752553
Loss at iteration 20 : 0.0004677499528042972
Loss at iteration 30 : 0.0009863474406301975
Loss at iteration 40 : 0.00611626822501421
Loss at iteration 50 : 0.0068013351410627365
Loss at iteration 60 : 0.00037459086161106825
Loss at iteration 70 : 0.002575174206867814
Loss at iteration 80 : 0.0028282571583986282
Loss at iteration 90 : 0.0033187824301421642
Loss at iteration 100 : 0.001711502205580473
Loss at iteration 110 : 0.00017817341722548008
Loss at iteration 120 : 0.00030863654683344066
Loss at iteration 130 : 0.0018921131268143654
Loss at iteration 140 : 0.0010309694334864616
Loss at iteration 150 : 0.00038020958891138434
Loss at iteration 160 : 0.0004207429592497647
Loss at iteration 170 : 5.258242163108662e-05
Loss at iteration 180 : 0.000379921228159219
Loss at iteration 190 : 0.002722326200455427
Loss at iteration 200 : 0.0020527068991214037
Loss at iteration 210 : 0.0007614006754010916
Loss at iteration 220 : 0.00021324378030840307
Loss at iteration 230 : 0.0006976696313358843
Loss at iteration 240 : 0.00036166771315038204
Loss at iteration 250 : 0.0006169621483422816
Loss at iteration 260 : 0.003997522406280041
Loss at iteration 270 : 0.0002899966493714601
Loss at iteration 280 : 0.0004074994067195803
Loss at iteration 290 : 0.00017450489394832402
Loss at iteration 300 : 0.0004763876204378903
Loss at iteration 310 : 0.00013416299771051854
Loss at iteration 320 : 0.001356289954856038
Loss at iteration 330 : 0.0003331159823574126
Loss at iteration 340 : 0.00037011579843237996
Loss at iteration 350 : 0.00039746053516864777
Loss at iteration 360 : 0.00024554404080845416
Loss at iteration 370 : 0.0003488266374915838
Loss at iteration 380 : 0.0007845510262995958
Loss at iteration 390 : 0.000693168374709785
Loss at iteration 400 : 0.00013914750888943672
Loss at iteration 410 : 0.0004773943219333887
Loss at iteration 420 : 0.0006030257791280746
Loss at iteration 430 : 0.0002915971854235977
Loss at iteration 440 : 0.002699157688766718
Loss at iteration 450 : 0.005362749099731445
Loss at iteration 460 : 0.001291133463382721
Loss at iteration 470 : 0.00010633237980073318
Loss at iteration 480 : 0.0002800186048261821
Loss at iteration 490 : 0.0014252536930143833
Loss at iteration 500 : 6.719935481669381e-05
Loss at iteration 510 : 0.00021073828975204378
Loss at iteration 520 : 0.0029539659153670073
Loss at iteration 530 : 0.004996119067072868
Loss at iteration 540 : 0.00010407947411295027
Loss at iteration 550 : 4.235039159539156e-05
Loss at iteration 560 : 0.0008045250433497131
Loss at iteration 570 : 0.0002026966103585437
Loss at iteration 580 : 0.001633193576708436
Loss at iteration 590 : 0.00022041410556994379
Loss at iteration 600 : 0.000271627854090184
Loss at iteration 610 : 0.002715612994506955
Loss at iteration 620 : 0.00015895019168965518
Loss at iteration 630 : 0.0006225518300198019
Loss at iteration 640 : 0.0005760119529440999
Loss at iteration 650 : 7.619756070198491e-05
Loss at iteration 660 : 0.00011043376434827223
Loss at iteration 670 : 0.000204077223315835
Loss at iteration 680 : 6.510387902380899e-05
Loss at iteration 690 : 0.00017258884327020496
Loss at iteration 700 : 0.0002307796967215836
Loss at iteration 710 : 0.00017247782670892775
Loss at iteration 720 : 0.00044102189713157713
Loss at iteration 730 : 0.0002680219477042556
Loss at iteration 740 : 0.0008934850338846445
Loss at iteration 750 : 0.0003403548034839332
Loss at iteration 760 : 0.0017184203024953604
Loss at iteration 770 : 0.00039687412208877504
Loss at iteration 780 : 0.0007738997810520232
Loss at iteration 790 : 0.0001162740372819826
Loss at iteration 800 : 0.0028822533786296844
Loss at iteration 810 : 0.00010769701475510374
Loss at iteration 820 : 0.0006924313493072987
Loss at iteration 830 : 0.0003868249768856913
Loss at iteration 840 : 0.0020281276665627956
Loss at iteration 850 : 0.00011997076217085123
Loss at iteration 860 : 0.0009743309346958995
Loss at iteration 870 : 0.0012635741150006652
Loss at iteration 880 : 0.0005543644074350595
Loss at iteration 890 : 0.004434894770383835
Loss at iteration 900 : 0.0015318933874368668
Loss at iteration 910 : 7.583454862469807e-05
Loss at iteration 920 : 0.0032302059698849916
Loss at iteration 930 : 0.00023588289332110435
Loss at iteration 940 : 0.00012180402700323611
Loss at iteration 950 : 0.0036914986558258533
Loss at iteration 960 : 0.0001643849682295695
Loss at iteration 970 : 0.0003115853469353169
Loss at iteration 980 : 0.00020279384625609964
Loss at iteration 990 : 0.0004298014100641012
Loss at iteration 1000 : 7.670940249226987e-05
Loss at iteration 1010 : 0.00046216335613280535
Loss at iteration 1020 : 0.005762668792158365
Loss at iteration 1030 : 0.0002614540862850845
Loss at iteration 1040 : 3.673265018733218e-05
Loss at iteration 1050 : 0.000826990813948214
Loss at iteration 1060 : 0.0002447620499879122
Loss at iteration 1070 : 0.0002230024110758677
Loss at iteration 1080 : 0.003112061880528927
Loss at iteration 1090 : 0.0002448390005156398
Loss at iteration 1100 : 0.0001226166932610795
Loss at iteration 1110 : 0.0023525215219706297
Loss at iteration 1120 : 0.0002699121832847595
Loss at iteration 1130 : 0.0005802127998322248
Loss at iteration 1140 : 0.00011956664093304425
Loss at iteration 1150 : 0.00013198310625739396
Loss at iteration 1160 : 0.00018338041263632476
Loss at iteration 1170 : 0.0001720441214274615
Loss at iteration 1180 : 9.851632785284892e-05
Loss at iteration 1190 : 0.0002796101616695523
Loss at iteration 1200 : 0.0032225854229182005
Loss at iteration 1210 : 0.0005050367908552289
Loss at iteration 1220 : 0.001572884269990027
Loss at iteration 1230 : 6.839341222075745e-05
Loss at iteration 1240 : 0.000263703492237255
Loss at iteration 1250 : 0.0038177194073796272
Loss at iteration 1260 : 0.00010972130985464901
Loss at iteration 1270 : 0.00017883094551507384
Loss at iteration 1280 : 0.0005898916278965771
Loss at iteration 1290 : 5.646722638630308e-05
Loss at iteration 1300 : 8.982951112557203e-05
Loss at iteration 1310 : 0.00012084834452252835
Loss at iteration 1320 : 0.0006823351723141968
Loss at iteration 1330 : 7.951362931635231e-05
Loss at iteration 1340 : 0.00013263690925668925
Loss at iteration 1350 : 0.00036081287544220686
Loss at iteration 1360 : 0.0007220433908514678
Loss at iteration 1370 : 0.00022195155906956643
Loss at iteration 1380 : 0.00034503586357459426
Loss at iteration 1390 : 0.00015477463603019714
Loss at iteration 1400 : 0.00015376225928775966
Loss at iteration 1410 : 0.0009467822965234518
Loss at iteration 1420 : 0.0004994645132683218
Loss at iteration 1430 : 0.00023666233755648136
Loss at iteration 1440 : 0.000647322740405798
Loss at iteration 1450 : 0.0007828617235645652
Loss at iteration 1460 : 0.0008070891490206122
Loss at iteration 1470 : 0.00015438688569702208
Loss at iteration 1480 : 0.00015277891361620277
Loss at iteration 1490 : 0.00010421701881568879
Loss at iteration 1500 : 0.0008550422498956323
Loss at iteration 1510 : 0.00022674971842207015
Loss at iteration 1520 : 8.334408630616963e-05
Loss at iteration 1530 : 0.0009747539297677577
Loss at iteration 1540 : 0.0020657216664403677
Loss at iteration 1550 : 0.000746392470318824
Loss at iteration 1560 : 0.0017201161244884133
Loss at iteration 1570 : 0.0024829786270856857
Loss at iteration 1580 : 0.0002101468271575868
Loss at iteration 1590 : 0.0028117490001022816
Loss at iteration 1600 : 0.0053306021727621555
Loss at iteration 1610 : 0.000286484370008111
Loss at iteration 1620 : 0.0012159221805632114
Loss at iteration 1630 : 0.003136938437819481
Loss at iteration 1640 : 0.00020482555555645376
Loss at iteration 1650 : 0.000320275139529258
Loss at iteration 1660 : 0.0002572047524154186
Loss at iteration 1670 : 0.00024077793932519853
Loss at iteration 1680 : 0.0006774580106139183
Loss at iteration 1690 : 5.8214893215335906e-05
Loss at iteration 1700 : 0.0013349363580346107
Loss at iteration 1710 : 0.00028009433299303055
Loss at iteration 1720 : 0.0005535149248316884
Loss at iteration 1730 : 0.0002518088440410793
Loss at iteration 1740 : 0.00013544029206968844
Loss at iteration 1750 : 0.0001755299890646711
The SSIM Value is: 0.981838984767771
The PSNR Value is: 46.52229969091878
the epoch is: 124
Loss at iteration 10 : 0.00020455683988984674
Loss at iteration 20 : 0.001043432392179966
Loss at iteration 30 : 0.0004350196977611631
Loss at iteration 40 : 0.00027385109569877386
Loss at iteration 50 : 0.0015060739824548364
Loss at iteration 60 : 0.00020086890435777605
Loss at iteration 70 : 0.001979568973183632
Loss at iteration 80 : 0.0006639030762016773
Loss at iteration 90 : 0.00233101868070662
Loss at iteration 100 : 0.002532612532377243
Loss at iteration 110 : 0.0001054418899002485
Loss at iteration 120 : 0.0011492181802168489
Loss at iteration 130 : 0.0004125345149077475
Loss at iteration 140 : 0.000856938015203923
Loss at iteration 150 : 0.003285340964794159
Loss at iteration 160 : 0.0002918709651567042
Loss at iteration 170 : 0.0002247207157779485
Loss at iteration 180 : 0.0008301292546093464
Loss at iteration 190 : 0.0007374040433205664
Loss at iteration 200 : 0.0007033043657429516
Loss at iteration 210 : 0.00011213994002901018
Loss at iteration 220 : 0.0006996921729296446
Loss at iteration 230 : 0.0007021726341918111
Loss at iteration 240 : 0.00010154271876672283
Loss at iteration 250 : 0.0012031791266053915
Loss at iteration 260 : 0.0005185883492231369
Loss at iteration 270 : 0.00011979226110270247
Loss at iteration 280 : 0.0016252705827355385
Loss at iteration 290 : 0.00012175156734883785
Loss at iteration 300 : 0.0003440585860516876
Loss at iteration 310 : 0.0025174706242978573
Loss at iteration 320 : 0.0002452133339829743
Loss at iteration 330 : 0.0038585711736232042
Loss at iteration 340 : 0.00012136275472585112
Loss at iteration 350 : 0.0005016439827159047
Loss at iteration 360 : 0.00016295615932904184
Loss at iteration 370 : 0.0010543589014559984
Loss at iteration 380 : 0.00015831351629458368
Loss at iteration 390 : 0.002337539568543434
Loss at iteration 400 : 0.00015053959214128554
Loss at iteration 410 : 0.0011830893345177174
Loss at iteration 420 : 7.023061334621161e-05
Loss at iteration 430 : 0.0003008311032317579
Loss at iteration 440 : 0.002112247981131077
Loss at iteration 450 : 0.00035268740612082183
Loss at iteration 460 : 0.0001900148781714961
Loss at iteration 470 : 0.0005713613354600966
Loss at iteration 480 : 0.00013476144522428513
Loss at iteration 490 : 0.00029419444035738707
Loss at iteration 500 : 0.00012414008961059153
Loss at iteration 510 : 0.0002582950983196497
Loss at iteration 520 : 0.00016080951900221407
Loss at iteration 530 : 0.000294273195322603
Loss at iteration 540 : 0.0022683655843138695
Loss at iteration 550 : 0.00016245852748397738
Loss at iteration 560 : 0.00044463382801041007
Loss at iteration 570 : 0.0005517419194802642
Loss at iteration 580 : 0.0008972431533038616
Loss at iteration 590 : 0.00014903236296959221
Loss at iteration 600 : 0.0009090208914130926
Loss at iteration 610 : 0.00011654145055217668
Loss at iteration 620 : 0.001400149310939014
Loss at iteration 630 : 0.00015670276479795575
Loss at iteration 640 : 0.00016353993851225823
Loss at iteration 650 : 0.0002762735530268401
Loss at iteration 660 : 0.0003001229197252542
Loss at iteration 670 : 0.00042900265543721616
Loss at iteration 680 : 0.0007179398089647293
Loss at iteration 690 : 0.0002061855047941208
Loss at iteration 700 : 0.00012530607637017965
Loss at iteration 710 : 0.0024746914859861135
Loss at iteration 720 : 0.0011854453478008509
Loss at iteration 730 : 0.0006819958798587322
Loss at iteration 740 : 0.0005938399117439985
Loss at iteration 750 : 0.00011580272257560864
Loss at iteration 760 : 0.0006182529032230377
Loss at iteration 770 : 0.00019801908638328314
Loss at iteration 780 : 0.0005167732597328722
Loss at iteration 790 : 0.0004610612813849002
Loss at iteration 800 : 0.0032222250010818243
Loss at iteration 810 : 0.00015549248200841248
Loss at iteration 820 : 0.005311371758580208
Loss at iteration 830 : 0.00045611910172738135
Loss at iteration 840 : 0.00026943880948238075
Loss at iteration 850 : 0.00032786489464342594
Loss at iteration 860 : 8.82195308804512e-05
Loss at iteration 870 : 0.0006629979470744729
Loss at iteration 880 : 0.00010510750144021586
Loss at iteration 890 : 0.0003854398673865944
Loss at iteration 900 : 8.055823855102062e-05
Loss at iteration 910 : 0.0001564826088724658
Loss at iteration 920 : 0.0003456103731878102
Loss at iteration 930 : 0.0001886418176582083
Loss at iteration 940 : 0.0008503705612383783
Loss at iteration 950 : 0.00018946276395581663
Loss at iteration 960 : 0.00040710013126954436
Loss at iteration 970 : 0.0009655061876401305
Loss at iteration 980 : 0.00017405259131919593
Loss at iteration 990 : 0.00011138649279018864
Loss at iteration 1000 : 0.00011908017040695995
Loss at iteration 1010 : 0.00029532494954764843
Loss at iteration 1020 : 0.0003800020203925669
Loss at iteration 1030 : 0.000359384692274034
Loss at iteration 1040 : 0.0038214202504605055
Loss at iteration 1050 : 0.00022650216124020517
Loss at iteration 1060 : 0.000478107831440866
Loss at iteration 1070 : 0.0013127838028594851
Loss at iteration 1080 : 0.0004372642724774778
Loss at iteration 1090 : 0.0001247616164619103
Loss at iteration 1100 : 0.0009576010634191334
Loss at iteration 1110 : 0.000291281146928668
Loss at iteration 1120 : 0.003161710686981678
Loss at iteration 1130 : 0.00042033728095702827
Loss at iteration 1140 : 0.005391879938542843
Loss at iteration 1150 : 9.0180998085998e-05
Loss at iteration 1160 : 0.00046945089707151055
Loss at iteration 1170 : 0.00025750978966243565
Loss at iteration 1180 : 0.0003390689380466938
Loss at iteration 1190 : 7.963994721649215e-05
Loss at iteration 1200 : 0.0002993391244672239
Loss at iteration 1210 : 0.00026692039682529867
Loss at iteration 1220 : 0.00024991147802211344
Loss at iteration 1230 : 7.64764190535061e-05
Loss at iteration 1240 : 0.0006034349789842963
Loss at iteration 1250 : 0.00018613006977830082
Loss at iteration 1260 : 0.00027828870224766433
Loss at iteration 1270 : 0.004360252991318703
Loss at iteration 1280 : 0.00025279130204580724
Loss at iteration 1290 : 0.002870385069400072
Loss at iteration 1300 : 0.0025461907498538494
Loss at iteration 1310 : 0.001800832455046475
Loss at iteration 1320 : 0.0003944922355003655
Loss at iteration 1330 : 0.001009922125376761
Loss at iteration 1340 : 0.0006268518045544624
Loss at iteration 1350 : 0.0007449387921951711
Loss at iteration 1360 : 0.00016817779396660626
Loss at iteration 1370 : 0.00130825350061059
Loss at iteration 1380 : 0.00121296476572752
Loss at iteration 1390 : 9.630447311792523e-05
Loss at iteration 1400 : 0.00024940966977737844
Loss at iteration 1410 : 0.0011982396245002747
Loss at iteration 1420 : 0.0007334451656788588
Loss at iteration 1430 : 0.0003593282890506089
Loss at iteration 1440 : 0.00015530850214418024
Loss at iteration 1450 : 0.003202425315976143
Loss at iteration 1460 : 0.0011533228680491447
Loss at iteration 1470 : 0.00011426561104599386
Loss at iteration 1480 : 6.697257776977494e-05
Loss at iteration 1490 : 0.0027093086391687393
Loss at iteration 1500 : 0.0045859068632125854
Loss at iteration 1510 : 0.0004723774909507483
Loss at iteration 1520 : 9.414389205630869e-05
Loss at iteration 1530 : 0.0001720951113384217
Loss at iteration 1540 : 0.00020545575534924865
Loss at iteration 1550 : 0.00019351366790942848
Loss at iteration 1560 : 0.0009443368762731552
Loss at iteration 1570 : 0.00014049772289581597
Loss at iteration 1580 : 0.0006051261443644762
Loss at iteration 1590 : 6.765366561012343e-05
Loss at iteration 1600 : 0.0004908944247290492
Loss at iteration 1610 : 0.00037252798210829496
Loss at iteration 1620 : 0.0015454988460987806
Loss at iteration 1630 : 0.001102842390537262
Loss at iteration 1640 : 6.423362356144935e-05
Loss at iteration 1650 : 0.00017727678641676903
Loss at iteration 1660 : 0.00025359101709909737
Loss at iteration 1670 : 0.0006850290228612721
Loss at iteration 1680 : 0.0034037712030112743
Loss at iteration 1690 : 0.004041110165417194
Loss at iteration 1700 : 0.003793172538280487
Loss at iteration 1710 : 0.001147368224337697
Loss at iteration 1720 : 0.0017601727740839124
Loss at iteration 1730 : 7.146806456148624e-05
Loss at iteration 1740 : 0.0014127297326922417
Loss at iteration 1750 : 0.004504065960645676
The SSIM Value is: 0.9861574616726274
The PSNR Value is: 46.24276108678742
the epoch is: 125
Loss at iteration 10 : 0.0003488887450657785
Loss at iteration 20 : 0.00019047979731112719
Loss at iteration 30 : 7.178998203016818e-05
Loss at iteration 40 : 0.00030633341521024704
Loss at iteration 50 : 0.0006867853226140141
Loss at iteration 60 : 8.1292622780893e-05
Loss at iteration 70 : 0.0001082496892195195
Loss at iteration 80 : 0.0031344452872872353
Loss at iteration 90 : 0.00021177521557547152
Loss at iteration 100 : 0.00031817221315577626
Loss at iteration 110 : 0.0006701871752738953
Loss at iteration 120 : 0.0009599860641174018
Loss at iteration 130 : 0.004071431700140238
Loss at iteration 140 : 0.0003166334645356983
Loss at iteration 150 : 0.0017652071546763182
Loss at iteration 160 : 0.0052665043622255325
Loss at iteration 170 : 0.0006226126570254564
Loss at iteration 180 : 0.0004320400767028332
Loss at iteration 190 : 0.0003001037403009832
Loss at iteration 200 : 0.00016602790856268257
Loss at iteration 210 : 0.0005383967654779553
Loss at iteration 220 : 0.00030553468968719244
Loss at iteration 230 : 0.0005936885718256235
Loss at iteration 240 : 0.0005612988024950027
Loss at iteration 250 : 0.00045240059262141585
Loss at iteration 260 : 0.0036968591157346964
Loss at iteration 270 : 0.00036471907515078783
Loss at iteration 280 : 8.491934568155557e-05
Loss at iteration 290 : 0.0003797409008257091
Loss at iteration 300 : 0.0005526038585230708
Loss at iteration 310 : 0.001983304973691702
Loss at iteration 320 : 0.00014931893383618444
Loss at iteration 330 : 0.00021679377823602408
Loss at iteration 340 : 9.497749852016568e-05
Loss at iteration 350 : 0.0006450595683418214
Loss at iteration 360 : 0.00025591952726244926
Loss at iteration 370 : 0.00011174937390023842
Loss at iteration 380 : 0.0002080590056721121
Loss at iteration 390 : 0.0004456833703443408
Loss at iteration 400 : 0.0008946623420342803
Loss at iteration 410 : 0.000975780887529254
Loss at iteration 420 : 0.0019225124269723892
Loss at iteration 430 : 0.0009618705371394753
Loss at iteration 440 : 0.00018326743156649172
Loss at iteration 450 : 0.0019335970282554626
Loss at iteration 460 : 0.00021844517323188484
Loss at iteration 470 : 0.00028606358682736754
Loss at iteration 480 : 0.004340403713285923
Loss at iteration 490 : 0.0008800869109109044
Loss at iteration 500 : 0.0008698280435055494
Loss at iteration 510 : 0.0002241192851215601
Loss at iteration 520 : 0.0008569357451051474
Loss at iteration 530 : 8.009413431864232e-05
Loss at iteration 540 : 0.000613172072917223
Loss at iteration 550 : 8.68723655003123e-05
Loss at iteration 560 : 0.0009403066942468286
Loss at iteration 570 : 0.0014559583505615592
Loss at iteration 580 : 0.0001519041252322495
Loss at iteration 590 : 0.00041693542152643204
Loss at iteration 600 : 0.0003819543053396046
Loss at iteration 610 : 0.0019707875326275826
Loss at iteration 620 : 0.0014269017847254872
Loss at iteration 630 : 0.0006535893771797419
Loss at iteration 640 : 0.0014588037738576531
Loss at iteration 650 : 0.0022301075514405966
Loss at iteration 660 : 0.00013751917867921293
Loss at iteration 670 : 0.00047734344843775034
Loss at iteration 680 : 0.00018089680816046894
Loss at iteration 690 : 0.0006549705867655575
Loss at iteration 700 : 0.00017578681581653655
Loss at iteration 710 : 0.0015493545215576887
Loss at iteration 720 : 0.0005294288857840002
Loss at iteration 730 : 0.00010130294685950503
Loss at iteration 740 : 0.0012493063695728779
Loss at iteration 750 : 0.00017615618708077818
Loss at iteration 760 : 0.00017771654529497027
Loss at iteration 770 : 0.0002114259114023298
Loss at iteration 780 : 7.982375245774165e-05
Loss at iteration 790 : 0.00013745797332376242
Loss at iteration 800 : 0.002503011142835021
Loss at iteration 810 : 0.002569428877905011
Loss at iteration 820 : 0.00010845069482456893
Loss at iteration 830 : 4.5845321437809616e-05
Loss at iteration 840 : 0.00010109686991199851
Loss at iteration 850 : 0.001397784799337387
Loss at iteration 860 : 0.00401276396587491
Loss at iteration 870 : 0.00011179322609677911
Loss at iteration 880 : 0.0021607696544378996
Loss at iteration 890 : 0.0008721923804841936
Loss at iteration 900 : 0.0002202857140218839
Loss at iteration 910 : 0.0008166827028617263
Loss at iteration 920 : 0.0002789052086882293
Loss at iteration 930 : 0.003018046263605356
Loss at iteration 940 : 0.0012288178550079465
Loss at iteration 950 : 0.00046287733130156994
Loss at iteration 960 : 0.00010399155871709809
Loss at iteration 970 : 0.0023531210608780384
Loss at iteration 980 : 0.0001922043302329257
Loss at iteration 990 : 0.0004384074127301574
Loss at iteration 1000 : 0.00042240836773999035
Loss at iteration 1010 : 6.66049963911064e-05
Loss at iteration 1020 : 0.0004906937829218805
Loss at iteration 1030 : 0.00010591367026790977
Loss at iteration 1040 : 4.8136811528820544e-05
Loss at iteration 1050 : 5.380533548304811e-05
Loss at iteration 1060 : 0.00022529307170771062
Loss at iteration 1070 : 9.354895155411214e-05
Loss at iteration 1080 : 0.00014707577065564692
Loss at iteration 1090 : 0.006354536861181259
Loss at iteration 1100 : 0.00014732689305674285
Loss at iteration 1110 : 0.0007632474880665541
Loss at iteration 1120 : 0.0012771965702995658
Loss at iteration 1130 : 0.0015110911335796118
Loss at iteration 1140 : 0.0038351076655089855
Loss at iteration 1150 : 9.955350105883554e-05
Loss at iteration 1160 : 0.00028506957460194826
Loss at iteration 1170 : 0.0001656955137150362
Loss at iteration 1180 : 0.0005515432567335665
Loss at iteration 1190 : 0.0021564054768532515
Loss at iteration 1200 : 0.0015645063249394298
Loss at iteration 1210 : 0.00012730607704725116
Loss at iteration 1220 : 0.00021394119539763778
Loss at iteration 1230 : 0.0002192715764977038
Loss at iteration 1240 : 0.0006425746250897646
Loss at iteration 1250 : 0.0009682634263299406
Loss at iteration 1260 : 0.003437178675085306
Loss at iteration 1270 : 0.0003349724574945867
Loss at iteration 1280 : 0.00011014423944288865
Loss at iteration 1290 : 0.00024091987870633602
Loss at iteration 1300 : 0.000720708747394383
Loss at iteration 1310 : 0.00018800633552018553
Loss at iteration 1320 : 0.0006336101214401424
Loss at iteration 1330 : 0.00021687120897695422
Loss at iteration 1340 : 7.465629460057244e-05
Loss at iteration 1350 : 0.00028003897750750184
Loss at iteration 1360 : 0.0038837427273392677
Loss at iteration 1370 : 0.0009367135353386402
Loss at iteration 1380 : 0.0001526053383713588
Loss at iteration 1390 : 0.002721806289628148
Loss at iteration 1400 : 4.287717820261605e-05
Loss at iteration 1410 : 0.0006024419562891126
Loss at iteration 1420 : 0.0001148181690950878
Loss at iteration 1430 : 5.0561582611408085e-05
Loss at iteration 1440 : 0.0011931337649002671
Loss at iteration 1450 : 0.0020706963259726763
Loss at iteration 1460 : 0.0004199399263598025
Loss at iteration 1470 : 0.0002213228290202096
Loss at iteration 1480 : 0.0024076486006379128
Loss at iteration 1490 : 0.0024528070352971554
Loss at iteration 1500 : 0.00033279755734838545
Loss at iteration 1510 : 0.0007100594229996204
Loss at iteration 1520 : 0.0004341385210864246
Loss at iteration 1530 : 0.00013465322263073176
Loss at iteration 1540 : 0.00015605913358740509
Loss at iteration 1550 : 0.0020684392657130957
Loss at iteration 1560 : 0.0007128792349249125
Loss at iteration 1570 : 0.0016308760968968272
Loss at iteration 1580 : 0.0028343219310045242
Loss at iteration 1590 : 0.00032309090602211654
Loss at iteration 1600 : 0.0022369581274688244
Loss at iteration 1610 : 0.0002676255244296044
Loss at iteration 1620 : 0.0033466569148004055
Loss at iteration 1630 : 0.0003435802645981312
Loss at iteration 1640 : 0.0015514648985117674
Loss at iteration 1650 : 0.0007241658167913556
Loss at iteration 1660 : 0.000358375022187829
Loss at iteration 1670 : 0.008618926629424095
Loss at iteration 1680 : 0.0004317753482609987
Loss at iteration 1690 : 0.0012041485169902444
Loss at iteration 1700 : 0.00021599067258648574
Loss at iteration 1710 : 0.000437678158050403
Loss at iteration 1720 : 0.00012555974535644054
Loss at iteration 1730 : 0.0027961141895502806
Loss at iteration 1740 : 0.00011658415314741433
Loss at iteration 1750 : 0.00022090869606472552
The SSIM Value is: 0.9855497075072469
The PSNR Value is: 46.60364961834206
the epoch is: 126
Loss at iteration 10 : 0.0013847301015630364
Loss at iteration 20 : 0.00015776226064190269
Loss at iteration 30 : 0.00017219135770574212
Loss at iteration 40 : 0.000862226530443877
Loss at iteration 50 : 0.00040841641020961106
Loss at iteration 60 : 0.00013510613644029945
Loss at iteration 70 : 0.0013829160016030073
Loss at iteration 80 : 0.00013926585961598903
Loss at iteration 90 : 0.0003730151802301407
Loss at iteration 100 : 0.004444509278982878
Loss at iteration 110 : 0.00020701330504380167
Loss at iteration 120 : 0.0025329366326332092
Loss at iteration 130 : 0.00024199896142818034
Loss at iteration 140 : 0.001424352522008121
Loss at iteration 150 : 0.00016146758571267128
Loss at iteration 160 : 0.0011830426519736648
Loss at iteration 170 : 0.001112476922571659
Loss at iteration 180 : 0.0007318391581065953
Loss at iteration 190 : 0.00029164343141019344
Loss at iteration 200 : 0.000365321320714429
Loss at iteration 210 : 0.0004657927784137428
Loss at iteration 220 : 0.00017383706290274858
Loss at iteration 230 : 0.0010063301306217909
Loss at iteration 240 : 0.0003444580943323672
Loss at iteration 250 : 0.0004770896630361676
Loss at iteration 260 : 0.0034718504175543785
Loss at iteration 270 : 0.0019674987997859716
Loss at iteration 280 : 0.000157054397277534
Loss at iteration 290 : 0.0027335602790117264
Loss at iteration 300 : 0.0006211428553797305
Loss at iteration 310 : 0.0005594828980974853
Loss at iteration 320 : 0.0004930755821987987
Loss at iteration 330 : 0.0012852833606302738
Loss at iteration 340 : 0.00030506454640999436
Loss at iteration 350 : 0.0001272793160751462
Loss at iteration 360 : 0.004158870317041874
Loss at iteration 370 : 0.00024118670262396336
Loss at iteration 380 : 0.000957369920797646
Loss at iteration 390 : 0.0007444577058777213
Loss at iteration 400 : 0.003864455968141556
Loss at iteration 410 : 0.001978951273486018
Loss at iteration 420 : 0.0038938228972256184
Loss at iteration 430 : 0.0007720762514509261
Loss at iteration 440 : 0.0016508873086422682
Loss at iteration 450 : 0.00019245181465521455
Loss at iteration 460 : 0.0022919639013707638
Loss at iteration 470 : 0.0001732073724269867
Loss at iteration 480 : 0.00047067407285794616
Loss at iteration 490 : 0.00024798649246804416
Loss at iteration 500 : 0.0001695820683380589
Loss at iteration 510 : 0.00018864762387238443
Loss at iteration 520 : 0.0049727302975952625
Loss at iteration 530 : 0.00041842387872748077
Loss at iteration 540 : 0.00040086073568090796
Loss at iteration 550 : 0.0026427903212606907
Loss at iteration 560 : 0.0025189900770783424
Loss at iteration 570 : 0.002767469733953476
Loss at iteration 580 : 0.00022268117754720151
Loss at iteration 590 : 0.0018052954692393541
Loss at iteration 600 : 9.151220001513138e-05
Loss at iteration 610 : 0.000445043871877715
Loss at iteration 620 : 0.004260714165866375
Loss at iteration 630 : 0.0003687988792080432
Loss at iteration 640 : 8.59875581227243e-05
Loss at iteration 650 : 0.0029437514021992683
Loss at iteration 660 : 0.0003757753293029964
Loss at iteration 670 : 0.0002380332734901458
Loss at iteration 680 : 0.0005215817363932729
Loss at iteration 690 : 0.0002946595777757466
Loss at iteration 700 : 0.00013887538807466626
Loss at iteration 710 : 0.0014845577534288168
Loss at iteration 720 : 0.00013586178829427809
Loss at iteration 730 : 0.0017726571531966329
Loss at iteration 740 : 0.0008155811810865998
Loss at iteration 750 : 6.148067768663168e-05
Loss at iteration 760 : 0.0005398748908191919
Loss at iteration 770 : 0.00037625301047228277
Loss at iteration 780 : 0.0013891732087358832
Loss at iteration 790 : 9.617866453481838e-05
Loss at iteration 800 : 0.0001815219147829339
Loss at iteration 810 : 0.0006564364302903414
Loss at iteration 820 : 0.00010863184434128925
Loss at iteration 830 : 0.0002978226402774453
Loss at iteration 840 : 0.0003428134077694267
Loss at iteration 850 : 0.0003693400358315557
Loss at iteration 860 : 0.0003232844464946538
Loss at iteration 870 : 0.0020113917998969555
Loss at iteration 880 : 0.0006072863470762968
Loss at iteration 890 : 0.003675746265798807
Loss at iteration 900 : 0.0005978437256999314
Loss at iteration 910 : 0.0019058806356042624
Loss at iteration 920 : 0.0005564432358369231
Loss at iteration 930 : 0.00015652235015295446
Loss at iteration 940 : 0.00038296624552458525
Loss at iteration 950 : 0.0017281071050092578
Loss at iteration 960 : 0.001719874795526266
Loss at iteration 970 : 0.0013254274381324649
Loss at iteration 980 : 0.00021936857956461608
Loss at iteration 990 : 0.0004601798136718571
Loss at iteration 1000 : 0.0003226223634555936
Loss at iteration 1010 : 0.00012230318679939955
Loss at iteration 1020 : 3.7543934013228863e-05
Loss at iteration 1030 : 0.003368356730788946
Loss at iteration 1040 : 0.00012162126949988306
Loss at iteration 1050 : 0.00021777689107693732
Loss at iteration 1060 : 0.0016217449447140098
Loss at iteration 1070 : 0.0004276506952010095
Loss at iteration 1080 : 0.002193898893892765
Loss at iteration 1090 : 0.002526715397834778
Loss at iteration 1100 : 0.00013172172475606203
Loss at iteration 1110 : 0.00033626859658397734
Loss at iteration 1120 : 0.0018676409963518381
Loss at iteration 1130 : 0.00010213698988081887
Loss at iteration 1140 : 0.00570463202893734
Loss at iteration 1150 : 0.004011438228189945
Loss at iteration 1160 : 0.002815764397382736
Loss at iteration 1170 : 0.0010726336622610688
Loss at iteration 1180 : 0.00043963815551251173
Loss at iteration 1190 : 0.0005819061771035194
Loss at iteration 1200 : 0.002478772308677435
Loss at iteration 1210 : 0.0025598364882171154
Loss at iteration 1220 : 7.288122287718579e-05
Loss at iteration 1230 : 0.00022216940124053508
Loss at iteration 1240 : 0.0015046459157019854
Loss at iteration 1250 : 0.00043107266537845135
Loss at iteration 1260 : 0.0006844524759799242
Loss at iteration 1270 : 0.002127560321241617
Loss at iteration 1280 : 5.1884508138755336e-05
Loss at iteration 1290 : 0.001160196727141738
Loss at iteration 1300 : 0.0003092911501880735
Loss at iteration 1310 : 0.0015608792891725898
Loss at iteration 1320 : 0.0008488116436637938
Loss at iteration 1330 : 0.0029054584447294474
Loss at iteration 1340 : 0.002113494323566556
Loss at iteration 1350 : 0.0016665218863636255
Loss at iteration 1360 : 0.005784063134342432
Loss at iteration 1370 : 0.00020898329967167228
Loss at iteration 1380 : 0.0009918427094817162
Loss at iteration 1390 : 0.0018980151508003473
Loss at iteration 1400 : 0.00010824541095644236
Loss at iteration 1410 : 0.0007942528463900089
Loss at iteration 1420 : 0.00019123672973364592
Loss at iteration 1430 : 0.00045603496255353093
Loss at iteration 1440 : 0.001013670233078301
Loss at iteration 1450 : 0.0020159808918833733
Loss at iteration 1460 : 0.00026498513761907816
Loss at iteration 1470 : 0.00037443049950525165
Loss at iteration 1480 : 0.0008539786795154214
Loss at iteration 1490 : 0.0015292601892724633
Loss at iteration 1500 : 0.0011140070855617523
Loss at iteration 1510 : 0.000940253958106041
Loss at iteration 1520 : 0.000204956391826272
Loss at iteration 1530 : 0.0005206788191571832
Loss at iteration 1540 : 0.0009427771437913179
Loss at iteration 1550 : 0.0016545223770663142
Loss at iteration 1560 : 0.004748467355966568
Loss at iteration 1570 : 4.979994992027059e-05
Loss at iteration 1580 : 0.0002715623122639954
Loss at iteration 1590 : 5.215494820731692e-05
Loss at iteration 1600 : 9.467449126532301e-05
Loss at iteration 1610 : 0.00032793235732242465
Loss at iteration 1620 : 0.0008748109685257077
Loss at iteration 1630 : 0.004462176933884621
Loss at iteration 1640 : 0.0021117154974490404
Loss at iteration 1650 : 0.0007893915753811598
Loss at iteration 1660 : 4.021413406007923e-05
Loss at iteration 1670 : 0.0009077030117623508
Loss at iteration 1680 : 0.0004878663457930088
Loss at iteration 1690 : 0.0002638019504956901
Loss at iteration 1700 : 0.00028476325678639114
Loss at iteration 1710 : 0.00015675881877541542
Loss at iteration 1720 : 6.4662512158975e-05
Loss at iteration 1730 : 0.0008124796440824866
Loss at iteration 1740 : 0.0009633572772145271
Loss at iteration 1750 : 0.0006354001816362143
The SSIM Value is: 0.9855266595464446
The PSNR Value is: 46.71871668651766
the epoch is: 127
Loss at iteration 10 : 0.0002444643178023398
Loss at iteration 20 : 0.00033550875377841294
Loss at iteration 30 : 0.0001909266720758751
Loss at iteration 40 : 6.0382219089660794e-05
Loss at iteration 50 : 0.004588453099131584
Loss at iteration 60 : 9.032031812239438e-05
Loss at iteration 70 : 0.0011396748013794422
Loss at iteration 80 : 0.00035323892370797694
Loss at iteration 90 : 0.0021596408914774656
Loss at iteration 100 : 9.27107612369582e-05
Loss at iteration 110 : 0.00022503243235405535
Loss at iteration 120 : 0.0012655723839998245
Loss at iteration 130 : 7.069401908665895e-05
Loss at iteration 140 : 0.00024715863401070237
Loss at iteration 150 : 0.0009620238561183214
Loss at iteration 160 : 0.0005562445148825645
Loss at iteration 170 : 6.825649325037375e-05
Loss at iteration 180 : 0.0004273196973372251
Loss at iteration 190 : 0.002195393666625023
Loss at iteration 200 : 0.0002747827966231853
Loss at iteration 210 : 0.0004198929527774453
Loss at iteration 220 : 0.00011496182560222223
Loss at iteration 230 : 0.002083068946376443
Loss at iteration 240 : 0.00424845889210701
Loss at iteration 250 : 0.00024582393234595656
Loss at iteration 260 : 0.0005116980755701661
Loss at iteration 270 : 0.003758761566132307
Loss at iteration 280 : 8.556530519854277e-05
Loss at iteration 290 : 0.0024713596794754267
Loss at iteration 300 : 0.0023092483170330524
Loss at iteration 310 : 0.00019328793860040605
Loss at iteration 320 : 0.00021365525026340038
Loss at iteration 330 : 0.00031628028955310583
Loss at iteration 340 : 0.0003429563366807997
Loss at iteration 350 : 0.002002132125198841
Loss at iteration 360 : 0.004211180377751589
Loss at iteration 370 : 0.0010146033018827438
Loss at iteration 380 : 0.0018765936838462949
Loss at iteration 390 : 0.0003185347013641149
Loss at iteration 400 : 0.0009322884725406766
Loss at iteration 410 : 0.00460975244641304
Loss at iteration 420 : 9.977855370379984e-05
Loss at iteration 430 : 4.132787580601871e-05
Loss at iteration 440 : 6.826943717896938e-05
Loss at iteration 450 : 0.0005770160350948572
Loss at iteration 460 : 0.0001376594736939296
Loss at iteration 470 : 0.0003082184703089297
Loss at iteration 480 : 0.00012927957868669182
Loss at iteration 490 : 0.0029606507159769535
Loss at iteration 500 : 0.00033673076541163027
Loss at iteration 510 : 0.0001995157217606902
Loss at iteration 520 : 0.00017777347238734365
Loss at iteration 530 : 0.00068176124477759
Loss at iteration 540 : 0.0018127725925296545
Loss at iteration 550 : 0.00029445503605529666
Loss at iteration 560 : 0.00034737467649392784
Loss at iteration 570 : 0.00020662978931795806
Loss at iteration 580 : 0.00015271420124918222
Loss at iteration 590 : 6.019866486894898e-05
Loss at iteration 600 : 0.00011261557665420696
Loss at iteration 610 : 0.002383309416472912
Loss at iteration 620 : 0.00012666422117035836
Loss at iteration 630 : 0.00027644564397633076
Loss at iteration 640 : 5.733798025175929e-05
Loss at iteration 650 : 0.0013240058906376362
Loss at iteration 660 : 0.0023471908643841743
Loss at iteration 670 : 0.0001744883629726246
Loss at iteration 680 : 0.0005838752840645611
Loss at iteration 690 : 0.00010970896983053535
Loss at iteration 700 : 0.00070715113542974
Loss at iteration 710 : 5.2252449677325785e-05
Loss at iteration 720 : 9.476981358602643e-05
Loss at iteration 730 : 0.0002556098625063896
Loss at iteration 740 : 0.0022570695728063583
Loss at iteration 750 : 0.0005903974524699152
Loss at iteration 760 : 0.0002102211001329124
Loss at iteration 770 : 0.00011393625754863024
Loss at iteration 780 : 0.000734277768060565
Loss at iteration 790 : 0.00023579580010846257
Loss at iteration 800 : 0.00017680788005236536
Loss at iteration 810 : 6.835794920334592e-05
Loss at iteration 820 : 0.0008052918128669262
Loss at iteration 830 : 0.00071531324647367
Loss at iteration 840 : 4.4314445403870195e-05
Loss at iteration 850 : 0.000104650913272053
Loss at iteration 860 : 0.002354320138692856
Loss at iteration 870 : 0.0001423207577317953
Loss at iteration 880 : 0.00020920185488648713
Loss at iteration 890 : 0.0003556621668394655
Loss at iteration 900 : 0.0005804633256047964
Loss at iteration 910 : 0.003169463248923421
Loss at iteration 920 : 0.00026535478536970913
Loss at iteration 930 : 7.445264054695144e-05
Loss at iteration 940 : 0.00016078520275186747
Loss at iteration 950 : 0.0005154465325176716
Loss at iteration 960 : 0.0006183276418596506
Loss at iteration 970 : 0.0007256887620314956
Loss at iteration 980 : 0.000336155469994992
Loss at iteration 990 : 0.0008443809347227216
Loss at iteration 1000 : 0.0002923074353020638
Loss at iteration 1010 : 4.987740612705238e-05
Loss at iteration 1020 : 0.002880684332922101
Loss at iteration 1030 : 0.0001519129436928779
Loss at iteration 1040 : 0.000894595927093178
Loss at iteration 1050 : 0.0002128928026650101
Loss at iteration 1060 : 0.0039044106379151344
Loss at iteration 1070 : 0.0003568860120140016
Loss at iteration 1080 : 0.00023745496582705528
Loss at iteration 1090 : 9.405949094798416e-05
Loss at iteration 1100 : 0.00014460599049925804
Loss at iteration 1110 : 0.0005779024213552475
Loss at iteration 1120 : 0.00015735432680230588
Loss at iteration 1130 : 0.0004822493065148592
Loss at iteration 1140 : 0.00013169794692657888
Loss at iteration 1150 : 0.004536407999694347
Loss at iteration 1160 : 0.00010199713869951665
Loss at iteration 1170 : 9.876811964204535e-05
Loss at iteration 1180 : 0.0007346112979575992
Loss at iteration 1190 : 0.0017879779916256666
Loss at iteration 1200 : 0.00041433051228523254
Loss at iteration 1210 : 0.00014317675959318876
Loss at iteration 1220 : 0.0025957936886698008
Loss at iteration 1230 : 0.0010188828455284238
Loss at iteration 1240 : 0.00018605825607664883
Loss at iteration 1250 : 0.0025307070463895798
Loss at iteration 1260 : 5.7042125263251364e-05
Loss at iteration 1270 : 0.00012947294453624636
Loss at iteration 1280 : 0.002821107394993305
Loss at iteration 1290 : 0.00057928980095312
Loss at iteration 1300 : 0.00022268615430220962
Loss at iteration 1310 : 0.002835604129359126
Loss at iteration 1320 : 0.0005152045050635934
Loss at iteration 1330 : 0.00303041934967041
Loss at iteration 1340 : 0.0005018042866140604
Loss at iteration 1350 : 4.880905180471018e-05
Loss at iteration 1360 : 0.00028327282052487135
Loss at iteration 1370 : 0.0002937964745797217
Loss at iteration 1380 : 0.00043162854854017496
Loss at iteration 1390 : 0.0004058179329149425
Loss at iteration 1400 : 0.0003280149830970913
Loss at iteration 1410 : 0.0029084670823067427
Loss at iteration 1420 : 5.658800728269853e-05
Loss at iteration 1430 : 0.00031446124194189906
Loss at iteration 1440 : 0.0021044667810201645
Loss at iteration 1450 : 0.0035411803983151913
Loss at iteration 1460 : 0.0007428114186041057
Loss at iteration 1470 : 0.007211415562778711
Loss at iteration 1480 : 0.00010780072625493631
Loss at iteration 1490 : 0.001709033502265811
Loss at iteration 1500 : 9.554444113746285e-05
Loss at iteration 1510 : 0.00023876214982010424
Loss at iteration 1520 : 0.000284836016362533
Loss at iteration 1530 : 0.002441100310534239
Loss at iteration 1540 : 0.00010362360626459122
Loss at iteration 1550 : 0.0013015219010412693
Loss at iteration 1560 : 0.0008082204731181264
Loss at iteration 1570 : 0.0001660671114223078
Loss at iteration 1580 : 7.903442747192457e-05
Loss at iteration 1590 : 0.0007062378572300076
Loss at iteration 1600 : 0.0005461135297082365
Loss at iteration 1610 : 0.0010009328834712505
Loss at iteration 1620 : 0.0003358190879225731
Loss at iteration 1630 : 0.0002417586511000991
Loss at iteration 1640 : 0.0003551690315362066
Loss at iteration 1650 : 0.00015024507592897862
Loss at iteration 1660 : 0.0002508409961592406
Loss at iteration 1670 : 0.0004796491703018546
Loss at iteration 1680 : 7.05964193912223e-05
Loss at iteration 1690 : 0.00038872420554980636
Loss at iteration 1700 : 0.0003035272238776088
Loss at iteration 1710 : 0.0005853594047948718
Loss at iteration 1720 : 0.00035460537765175104
Loss at iteration 1730 : 6.534482236020267e-05
Loss at iteration 1740 : 7.358998846029863e-05
Loss at iteration 1750 : 0.00010973901225952432
The SSIM Value is: 0.9838698788623977
The PSNR Value is: 46.66172553159067
the epoch is: 128
Loss at iteration 10 : 0.0004439202311914414
Loss at iteration 20 : 0.0022328472696244717
Loss at iteration 30 : 0.00024203545763157308
Loss at iteration 40 : 0.0005919697578065097
Loss at iteration 50 : 0.0023190949577838182
Loss at iteration 60 : 0.001217248965986073
Loss at iteration 70 : 0.0003187358961440623
Loss at iteration 80 : 9.07007633941248e-05
Loss at iteration 90 : 0.0001882270153146237
Loss at iteration 100 : 6.704495172016323e-05
Loss at iteration 110 : 4.912633812637068e-05
Loss at iteration 120 : 0.00010040687629953027
Loss at iteration 130 : 0.0008524045115336776
Loss at iteration 140 : 0.0001490786817157641
Loss at iteration 150 : 0.0029358710162341595
Loss at iteration 160 : 0.0004662320134229958
Loss at iteration 170 : 0.004467815160751343
Loss at iteration 180 : 0.0019174261251464486
Loss at iteration 190 : 0.0002018559753196314
Loss at iteration 200 : 8.049879397731274e-05
Loss at iteration 210 : 0.00037485602661035955
Loss at iteration 220 : 0.0005297558382153511
Loss at iteration 230 : 0.0002568311174400151
Loss at iteration 240 : 0.0024916939437389374
Loss at iteration 250 : 0.00010227354505332187
Loss at iteration 260 : 7.13536428520456e-05
Loss at iteration 270 : 0.0025351757649332285
Loss at iteration 280 : 0.0010906143579632044
Loss at iteration 290 : 0.002970106666907668
Loss at iteration 300 : 0.0003781573614105582
Loss at iteration 310 : 8.638399594929069e-05
Loss at iteration 320 : 0.0002199150767410174
Loss at iteration 330 : 0.0013447608798742294
Loss at iteration 340 : 0.00026366309612058103
Loss at iteration 350 : 0.0010378080187365413
Loss at iteration 360 : 0.00010443778592161834
Loss at iteration 370 : 0.00042010913603007793
Loss at iteration 380 : 0.002316628582775593
Loss at iteration 390 : 0.00024927983758971095
Loss at iteration 400 : 0.00027610163670033216
Loss at iteration 410 : 0.0009968085214495659
Loss at iteration 420 : 0.00013464776566252112
Loss at iteration 430 : 0.0004564341506920755
Loss at iteration 440 : 0.0004468903935048729
Loss at iteration 450 : 0.0029625529423356056
Loss at iteration 460 : 0.0019488311372697353
Loss at iteration 470 : 0.0001384352071909234
Loss at iteration 480 : 0.0031172737944871187
Loss at iteration 490 : 0.00012477801647037268
Loss at iteration 500 : 0.00018728880968410522
Loss at iteration 510 : 0.0011335265589877963
Loss at iteration 520 : 0.0001727190101519227
Loss at iteration 530 : 0.00011306337546557188
Loss at iteration 540 : 8.331928256666288e-05
Loss at iteration 550 : 0.0006034731632098556
Loss at iteration 560 : 0.00143925822339952
Loss at iteration 570 : 0.0007445293013006449
Loss at iteration 580 : 0.00017755359294824302
Loss at iteration 590 : 0.00012541722389869392
Loss at iteration 600 : 8.050876203924417e-05
Loss at iteration 610 : 0.00012222396617289633
Loss at iteration 620 : 0.00028437667060643435
Loss at iteration 630 : 0.0004879511834587902
Loss at iteration 640 : 0.0009422444272786379
Loss at iteration 650 : 0.004437596071511507
Loss at iteration 660 : 0.00019845465430989861
Loss at iteration 670 : 0.0002050513430731371
Loss at iteration 680 : 0.0013652433408424258
Loss at iteration 690 : 0.00037588580744341016
Loss at iteration 700 : 0.0006631948053836823
Loss at iteration 710 : 0.00011155441461596638
Loss at iteration 720 : 0.00021545850904658437
Loss at iteration 730 : 9.629067790228873e-05
Loss at iteration 740 : 0.0005111789214424789
Loss at iteration 750 : 0.002987481188029051
Loss at iteration 760 : 0.006822146475315094
Loss at iteration 770 : 0.00033273312146775424
Loss at iteration 780 : 0.001480408594943583
Loss at iteration 790 : 0.00022329241619445384
Loss at iteration 800 : 4.538695066003129e-05
Loss at iteration 810 : 0.001615916844457388
Loss at iteration 820 : 0.0008345660753548145
Loss at iteration 830 : 0.00018700704094953835
Loss at iteration 840 : 5.0987502618227154e-05
Loss at iteration 850 : 0.001173812197521329
Loss at iteration 860 : 0.00020073373161721975
Loss at iteration 870 : 0.0006677218480035663
Loss at iteration 880 : 0.0001264597085537389
Loss at iteration 890 : 0.00042695054435171187
Loss at iteration 900 : 0.003217089921236038
Loss at iteration 910 : 0.00016695790691301227
Loss at iteration 920 : 0.00012427772162482142
Loss at iteration 930 : 0.00015664305828977376
Loss at iteration 940 : 0.0002506487653590739
Loss at iteration 950 : 0.0016448801616206765
Loss at iteration 960 : 0.0022690738551318645
Loss at iteration 970 : 0.0003022323071490973
Loss at iteration 980 : 0.0002420497330604121
Loss at iteration 990 : 0.00014888237637933344
Loss at iteration 1000 : 0.0012290277518332005
Loss at iteration 1010 : 0.0009049387881532311
Loss at iteration 1020 : 0.0004989688750356436
Loss at iteration 1030 : 0.0005770135321654379
Loss at iteration 1040 : 0.00043824093881994486
Loss at iteration 1050 : 8.537814574083313e-05
Loss at iteration 1060 : 0.000655895215459168
Loss at iteration 1070 : 0.00012768476153723896
Loss at iteration 1080 : 0.00048679811879992485
Loss at iteration 1090 : 0.0033669876866042614
Loss at iteration 1100 : 0.001983057474717498
Loss at iteration 1110 : 0.00022466687369160354
Loss at iteration 1120 : 0.00020226489868946373
Loss at iteration 1130 : 0.00023090376635082066
Loss at iteration 1140 : 0.006335216574370861
Loss at iteration 1150 : 6.120215402916074e-05
Loss at iteration 1160 : 0.0021721264347434044
Loss at iteration 1170 : 0.00013254974328447133
Loss at iteration 1180 : 0.0029860942158848047
Loss at iteration 1190 : 3.6013316275784746e-05
Loss at iteration 1200 : 0.001698059611953795
Loss at iteration 1210 : 0.00012872843944933265
Loss at iteration 1220 : 0.00024130484962370247
Loss at iteration 1230 : 0.0035579975228756666
Loss at iteration 1240 : 0.00032461766386404634
Loss at iteration 1250 : 0.00044732383685186505
Loss at iteration 1260 : 0.0002670474932529032
Loss at iteration 1270 : 0.0003301360411569476
Loss at iteration 1280 : 0.00012279397924430668
Loss at iteration 1290 : 0.0004839855246245861
Loss at iteration 1300 : 0.0017395296599715948
Loss at iteration 1310 : 0.0013648546300828457
Loss at iteration 1320 : 0.00011939073010580614
Loss at iteration 1330 : 0.00013309479982126504
Loss at iteration 1340 : 0.00037201697705313563
Loss at iteration 1350 : 0.0038270719815045595
Loss at iteration 1360 : 0.000245415314566344
Loss at iteration 1370 : 0.0006198015762493014
Loss at iteration 1380 : 0.00028596914489753544
Loss at iteration 1390 : 0.0002259331231471151
Loss at iteration 1400 : 0.0009359742398373783
Loss at iteration 1410 : 0.002024225890636444
Loss at iteration 1420 : 0.0003645712276920676
Loss at iteration 1430 : 0.00013835956633556634
Loss at iteration 1440 : 8.821949450066313e-05
Loss at iteration 1450 : 0.0023240381851792336
Loss at iteration 1460 : 0.0001525868137832731
Loss at iteration 1470 : 0.0020015875343233347
Loss at iteration 1480 : 0.0003156827879138291
Loss at iteration 1490 : 5.215913552092388e-05
Loss at iteration 1500 : 0.0001390798861393705
Loss at iteration 1510 : 0.00015363770944532007
Loss at iteration 1520 : 0.00026572219212539494
Loss at iteration 1530 : 0.0005978651461191475
Loss at iteration 1540 : 0.0017422790406271815
Loss at iteration 1550 : 0.00022826832719147205
Loss at iteration 1560 : 0.00021740139345638454
Loss at iteration 1570 : 0.00014039123198017478
Loss at iteration 1580 : 7.429275137837976e-05
Loss at iteration 1590 : 0.00011577697296161205
Loss at iteration 1600 : 0.0004947356064803898
Loss at iteration 1610 : 0.00016083355876617134
Loss at iteration 1620 : 0.001469818176701665
Loss at iteration 1630 : 0.0011204006150364876
Loss at iteration 1640 : 0.0010395656572654843
Loss at iteration 1650 : 0.0011444168630987406
Loss at iteration 1660 : 0.001620283117517829
Loss at iteration 1670 : 6.819171539973468e-05
Loss at iteration 1680 : 0.0002626466448418796
Loss at iteration 1690 : 0.0002429498272249475
Loss at iteration 1700 : 9.17275610845536e-05
Loss at iteration 1710 : 0.004726340062916279
Loss at iteration 1720 : 0.003223767736926675
Loss at iteration 1730 : 0.0009002802544273436
Loss at iteration 1740 : 0.0012381006963551044
Loss at iteration 1750 : 0.0016371841775253415
The SSIM Value is: 0.9872545702341895
The PSNR Value is: 46.788215864072285
the highest SSIM value is: 46.788215864072285
the epoch is: 129
Loss at iteration 10 : 3.3015119697665796e-05
Loss at iteration 20 : 0.0001721276348689571
Loss at iteration 30 : 0.00022437376901507378
Loss at iteration 40 : 0.00016778637655079365
Loss at iteration 50 : 0.000201699513127096
Loss at iteration 60 : 0.00012255081674084067
Loss at iteration 70 : 0.001824858132749796
Loss at iteration 80 : 0.0013644617283716798
Loss at iteration 90 : 0.0003431106451898813
Loss at iteration 100 : 0.00026569212786853313
Loss at iteration 110 : 0.0009451687801629305
Loss at iteration 120 : 0.00022049996186979115
Loss at iteration 130 : 0.0004950838629156351
Loss at iteration 140 : 0.0003306925646029413
Loss at iteration 150 : 0.0005709804827347398
Loss at iteration 160 : 0.0007041338249109685
Loss at iteration 170 : 0.00016024908109102398
Loss at iteration 180 : 4.371177055872977e-05
Loss at iteration 190 : 0.00045663208584301174
Loss at iteration 200 : 0.0019797119311988354
Loss at iteration 210 : 0.00012887203774880618
Loss at iteration 220 : 0.00023676594719290733
Loss at iteration 230 : 0.00013292397488839924
Loss at iteration 240 : 0.000268947595031932
Loss at iteration 250 : 0.00016664799477439374
Loss at iteration 260 : 0.0002612409880384803
Loss at iteration 270 : 0.00015073947724886239
Loss at iteration 280 : 0.002072198549285531
Loss at iteration 290 : 0.0016700060805305839
Loss at iteration 300 : 0.0006619362975470722
Loss at iteration 310 : 0.0002982612932100892
Loss at iteration 320 : 0.00011485770664876327
Loss at iteration 330 : 0.0018187719397246838
Loss at iteration 340 : 0.00039894809015095234
Loss at iteration 350 : 0.0031489774119108915
Loss at iteration 360 : 0.00017059905803762376
Loss at iteration 370 : 0.00012920176959596574
Loss at iteration 380 : 7.759847358101979e-05
Loss at iteration 390 : 7.40042160032317e-05
Loss at iteration 400 : 0.0001241810678038746
Loss at iteration 410 : 7.780751184327528e-05
Loss at iteration 420 : 0.0018479820573702455
Loss at iteration 430 : 0.00019000525935553014
Loss at iteration 440 : 0.0033624342177063227
Loss at iteration 450 : 0.0002277600870002061
Loss at iteration 460 : 0.0018311812309548259
Loss at iteration 470 : 0.0013423238415271044
Loss at iteration 480 : 7.141358219087124e-05
Loss at iteration 490 : 0.003203638596460223
Loss at iteration 500 : 0.0002257335581816733
Loss at iteration 510 : 7.062677468638867e-05
Loss at iteration 520 : 0.0041941688396036625
Loss at iteration 530 : 0.00026167946634814143
Loss at iteration 540 : 0.0009761385736055672
Loss at iteration 550 : 0.00239371694624424
Loss at iteration 560 : 0.0003072783874813467
Loss at iteration 570 : 0.0004538832581602037
Loss at iteration 580 : 0.0005183815374039114
Loss at iteration 590 : 0.00015827442985028028
Loss at iteration 600 : 0.00031846071942709386
Loss at iteration 610 : 8.735951996641234e-05
Loss at iteration 620 : 0.0007787552895024419
Loss at iteration 630 : 0.00011195575643796474
Loss at iteration 640 : 0.0009907272178679705
Loss at iteration 650 : 0.000169198407093063
Loss at iteration 660 : 0.00023541154223494232
Loss at iteration 670 : 0.00019650498870760202
Loss at iteration 680 : 0.00015750247985124588
Loss at iteration 690 : 9.294430492445827e-05
Loss at iteration 700 : 0.0001612440391909331
Loss at iteration 710 : 8.552116923965514e-05
Loss at iteration 720 : 0.002870962955057621
Loss at iteration 730 : 0.0003510740352794528
Loss at iteration 740 : 0.0004183951241429895
Loss at iteration 750 : 0.00031476339790970087
Loss at iteration 760 : 0.0015002924483269453
Loss at iteration 770 : 0.0004683127626776695
Loss at iteration 780 : 0.008888263255357742
Loss at iteration 790 : 0.00047236535465344787
Loss at iteration 800 : 0.00044703768799081445
Loss at iteration 810 : 0.00024096749257296324
Loss at iteration 820 : 0.000517265172675252
Loss at iteration 830 : 0.00010024200309999287
Loss at iteration 840 : 0.005503119435161352
Loss at iteration 850 : 0.0009406284079886973
Loss at iteration 860 : 0.0019528864650055766
Loss at iteration 870 : 0.0008069112664088607
Loss at iteration 880 : 0.0005286065861582756
Loss at iteration 890 : 0.00035503588151186705
Loss at iteration 900 : 0.0004704269231297076
Loss at iteration 910 : 0.001065970165655017
Loss at iteration 920 : 0.0014297007583081722
Loss at iteration 930 : 0.00018968054791912436
Loss at iteration 940 : 0.001589289866387844
Loss at iteration 950 : 0.0007270061178132892
Loss at iteration 960 : 0.0002953569928649813
Loss at iteration 970 : 0.0002886472793761641
Loss at iteration 980 : 0.0005073141655884683
Loss at iteration 990 : 0.00026121240807697177
Loss at iteration 1000 : 0.0001561280369060114
Loss at iteration 1010 : 0.0002715603040996939
Loss at iteration 1020 : 0.000534969090949744
Loss at iteration 1030 : 0.0026588947512209415
Loss at iteration 1040 : 0.0001319369621342048
Loss at iteration 1050 : 0.0011911881156265736
Loss at iteration 1060 : 0.0017648092471063137
Loss at iteration 1070 : 0.0006613401346839964
Loss at iteration 1080 : 0.00019418157171458006
Loss at iteration 1090 : 0.00019884260836988688
Loss at iteration 1100 : 0.00036777748027816415
Loss at iteration 1110 : 7.489432755392045e-05
Loss at iteration 1120 : 0.000192136038094759
Loss at iteration 1130 : 0.0002906318986788392
Loss at iteration 1140 : 0.0025419467128813267
Loss at iteration 1150 : 0.00014126673340797424
Loss at iteration 1160 : 0.000601405743509531
Loss at iteration 1170 : 8.44734677230008e-05
Loss at iteration 1180 : 0.0015918596182018518
Loss at iteration 1190 : 0.0028462945483624935
Loss at iteration 1200 : 6.957918230909854e-05
Loss at iteration 1210 : 0.00019671302288770676
Loss at iteration 1220 : 0.0002780148934107274
Loss at iteration 1230 : 6.354338984237984e-05
Loss at iteration 1240 : 0.00025058467872440815
Loss at iteration 1250 : 0.0003287126310169697
Loss at iteration 1260 : 0.0001355229178443551
Loss at iteration 1270 : 0.0016817334108054638
Loss at iteration 1280 : 0.00044104200787842274
Loss at iteration 1290 : 0.0010871049016714096
Loss at iteration 1300 : 0.0005003557307645679
Loss at iteration 1310 : 0.001354630570858717
Loss at iteration 1320 : 8.045225695241243e-05
Loss at iteration 1330 : 0.0030953623354434967
Loss at iteration 1340 : 0.0002550364297349006
Loss at iteration 1350 : 5.775843601441011e-05
Loss at iteration 1360 : 0.0022479200270026922
Loss at iteration 1370 : 0.00036059398553334177
Loss at iteration 1380 : 0.0004142776015214622
Loss at iteration 1390 : 0.002303710673004389
Loss at iteration 1400 : 0.0004428671090863645
Loss at iteration 1410 : 0.0004353572439868003
Loss at iteration 1420 : 0.0014968483010306954
Loss at iteration 1430 : 0.003683927236124873
Loss at iteration 1440 : 0.000295913137961179
Loss at iteration 1450 : 0.00031035509891808033
Loss at iteration 1460 : 0.002612182404845953
Loss at iteration 1470 : 0.00046490266686305404
Loss at iteration 1480 : 7.548763824161142e-05
Loss at iteration 1490 : 0.00014762151113245636
Loss at iteration 1500 : 0.0005181383457966149
Loss at iteration 1510 : 0.0012894244864583015
Loss at iteration 1520 : 0.0003173551522195339
Loss at iteration 1530 : 0.00013011883129365742
Loss at iteration 1540 : 0.00192716671153903
Loss at iteration 1550 : 0.0002820069785229862
Loss at iteration 1560 : 0.00014672860561404377
Loss at iteration 1570 : 0.0001550684537505731
Loss at iteration 1580 : 6.633441080339253e-05
Loss at iteration 1590 : 0.0034696534276008606
Loss at iteration 1600 : 0.003585535567253828
Loss at iteration 1610 : 0.00011010151501977816
Loss at iteration 1620 : 0.004150701221078634
Loss at iteration 1630 : 0.000986938364803791
Loss at iteration 1640 : 0.0024550503585487604
Loss at iteration 1650 : 0.0036171653773635626
Loss at iteration 1660 : 0.0015450625214725733
Loss at iteration 1670 : 5.510447226697579e-05
Loss at iteration 1680 : 0.0003255096962675452
Loss at iteration 1690 : 0.0034809643402695656
Loss at iteration 1700 : 0.00022982801601756364
Loss at iteration 1710 : 0.003421703353524208
Loss at iteration 1720 : 6.19073398411274e-05
Loss at iteration 1730 : 9.512571705272421e-05
Loss at iteration 1740 : 3.960312460549176e-05
Loss at iteration 1750 : 0.00024077930720523
The SSIM Value is: 0.9864747043748259
The PSNR Value is: 46.75008765611354
the epoch is: 130
Loss at iteration 10 : 0.0004214089713059366
Loss at iteration 20 : 0.002876613289117813
Loss at iteration 30 : 0.003248229157179594
Loss at iteration 40 : 0.0009223070810548961
Loss at iteration 50 : 0.0007950327708385885
Loss at iteration 60 : 0.000343025109032169
Loss at iteration 70 : 0.00824542436748743
Loss at iteration 80 : 0.004862826317548752
Loss at iteration 90 : 0.0010065212845802307
Loss at iteration 100 : 0.00020282098557800055
Loss at iteration 110 : 0.0004149337764829397
Loss at iteration 120 : 0.0007513094460591674
Loss at iteration 130 : 0.0004786299541592598
Loss at iteration 140 : 0.00039257717435248196
Loss at iteration 150 : 0.00034380954457446933
Loss at iteration 160 : 0.00011759167682612315
Loss at iteration 170 : 0.0003119909961242229
Loss at iteration 180 : 0.001947155804373324
Loss at iteration 190 : 0.00036722247023135424
Loss at iteration 200 : 0.00716688297688961
Loss at iteration 210 : 0.00068296940298751
Loss at iteration 220 : 0.00037364207673817873
Loss at iteration 230 : 8.518029062543064e-05
Loss at iteration 240 : 0.000199702859390527
Loss at iteration 250 : 0.0003270209126640111
Loss at iteration 260 : 0.0037668482400476933
Loss at iteration 270 : 0.000297390331979841
Loss at iteration 280 : 0.00022153023746795952
Loss at iteration 290 : 5.97925900365226e-05
Loss at iteration 300 : 0.0009137520682998002
Loss at iteration 310 : 0.001064589712768793
Loss at iteration 320 : 0.00019166135462000966
Loss at iteration 330 : 0.00034436321584507823
Loss at iteration 340 : 0.00021891447249799967
Loss at iteration 350 : 0.0007636342197656631
Loss at iteration 360 : 0.00010571779421297833
Loss at iteration 370 : 4.0433988033328205e-05
Loss at iteration 380 : 0.0001600170653546229
Loss at iteration 390 : 0.0027488425839692354
Loss at iteration 400 : 0.0002620824670884758
Loss at iteration 410 : 0.004193698987364769
Loss at iteration 420 : 0.0003266784769948572
Loss at iteration 430 : 0.00014807021943852305
Loss at iteration 440 : 0.0001514922914793715
Loss at iteration 450 : 0.00015020347200334072
Loss at iteration 460 : 6.911723903613165e-05
Loss at iteration 470 : 0.0031388606876134872
Loss at iteration 480 : 0.0013139047659933567
Loss at iteration 490 : 7.561329402960837e-05
Loss at iteration 500 : 0.0016448375536128879
Loss at iteration 510 : 0.002131772693246603
Loss at iteration 520 : 0.00034815806429833174
Loss at iteration 530 : 0.00039135056431405246
Loss at iteration 540 : 0.00014297867892310023
Loss at iteration 550 : 0.0007968865102156997
Loss at iteration 560 : 0.00012131685070926324
Loss at iteration 570 : 8.780921052675694e-05
Loss at iteration 580 : 0.003762771375477314
Loss at iteration 590 : 0.00019683191203512251
Loss at iteration 600 : 0.00028859369922429323
Loss at iteration 610 : 0.0010743560269474983
Loss at iteration 620 : 0.0028152482118457556
Loss at iteration 630 : 0.00017843573004938662
Loss at iteration 640 : 0.003486654255539179
Loss at iteration 650 : 0.00018064017058350146
Loss at iteration 660 : 0.0009749337332323194
Loss at iteration 670 : 0.0001925829565152526
Loss at iteration 680 : 0.0008192150853574276
Loss at iteration 690 : 0.0005789389833807945
Loss at iteration 700 : 0.0017629698850214481
Loss at iteration 710 : 0.00010980094521073624
Loss at iteration 720 : 0.000642866943962872
Loss at iteration 730 : 0.00013851864787284285
Loss at iteration 740 : 0.00015150441322475672
Loss at iteration 750 : 0.001995217055082321
Loss at iteration 760 : 0.002448883606120944
Loss at iteration 770 : 0.004129302687942982
Loss at iteration 780 : 8.296287705888972e-05
Loss at iteration 790 : 0.0006883038440719247
Loss at iteration 800 : 0.0009464572067372501
Loss at iteration 810 : 0.0002023411070695147
Loss at iteration 820 : 0.00014085174188949168
Loss at iteration 830 : 0.00042633345583453774
Loss at iteration 840 : 8.259288733825088e-05
Loss at iteration 850 : 8.85255285538733e-05
Loss at iteration 860 : 0.0008473454508930445
Loss at iteration 870 : 0.00015355563664343208
Loss at iteration 880 : 7.237840327434242e-05
Loss at iteration 890 : 0.00024853702052496374
Loss at iteration 900 : 0.0004670650523621589
Loss at iteration 910 : 0.00038122819387353957
Loss at iteration 920 : 0.00017785871750675142
Loss at iteration 930 : 0.0007518491474911571
Loss at iteration 940 : 0.0016971128061413765
Loss at iteration 950 : 0.0005093423533253372
Loss at iteration 960 : 0.000390783476177603
Loss at iteration 970 : 0.0004229475453030318
Loss at iteration 980 : 0.0002568633353803307
Loss at iteration 990 : 9.114490239880979e-05
Loss at iteration 1000 : 0.0009467093623243272
Loss at iteration 1010 : 0.00013289475464262068
Loss at iteration 1020 : 0.0004108488210476935
Loss at iteration 1030 : 0.00047895486932247877
Loss at iteration 1040 : 0.0006606472888961434
Loss at iteration 1050 : 0.00011674071720335633
Loss at iteration 1060 : 0.0008238665759563446
Loss at iteration 1070 : 0.0009811989730224013
Loss at iteration 1080 : 9.799930558074266e-05
Loss at iteration 1090 : 0.00010344923794036731
Loss at iteration 1100 : 0.004144551232457161
Loss at iteration 1110 : 0.0023396587930619717
Loss at iteration 1120 : 0.0004002844507340342
Loss at iteration 1130 : 0.0005766169051639736
Loss at iteration 1140 : 0.0004361828905530274
Loss at iteration 1150 : 0.0010666392045095563
Loss at iteration 1160 : 0.0008600346627645195
Loss at iteration 1170 : 0.0013707487378269434
Loss at iteration 1180 : 0.00122573203407228
Loss at iteration 1190 : 0.0011890491005033255
Loss at iteration 1200 : 6.855114042991772e-05
Loss at iteration 1210 : 0.001031222054734826
Loss at iteration 1220 : 0.0005916956579312682
Loss at iteration 1230 : 0.000781307346187532
Loss at iteration 1240 : 5.285466613713652e-05
Loss at iteration 1250 : 0.002456155139952898
Loss at iteration 1260 : 0.003236423246562481
Loss at iteration 1270 : 0.00022495744633488357
Loss at iteration 1280 : 0.002062498824670911
Loss at iteration 1290 : 0.00011607840860961005
Loss at iteration 1300 : 8.427505963481963e-05
Loss at iteration 1310 : 0.003946961835026741
Loss at iteration 1320 : 0.00077390595106408
Loss at iteration 1330 : 0.0002259724133182317
Loss at iteration 1340 : 0.0006189934210851789
Loss at iteration 1350 : 0.00204043323174119
Loss at iteration 1360 : 0.0002449519815854728
Loss at iteration 1370 : 0.004560502711683512
Loss at iteration 1380 : 0.0001445842208340764
Loss at iteration 1390 : 0.003912771120667458
Loss at iteration 1400 : 0.0017162002623081207
Loss at iteration 1410 : 0.00232622679322958
Loss at iteration 1420 : 0.00037923880154266953
Loss at iteration 1430 : 0.002835734747350216
Loss at iteration 1440 : 0.00010082272638101131
Loss at iteration 1450 : 8.706454536877573e-05
Loss at iteration 1460 : 5.837949720444158e-05
Loss at iteration 1470 : 0.002138655399903655
Loss at iteration 1480 : 0.0004488358972594142
Loss at iteration 1490 : 0.001065390883013606
Loss at iteration 1500 : 0.00011087942402809858
Loss at iteration 1510 : 0.0008365646353922784
Loss at iteration 1520 : 0.0010846053482964635
Loss at iteration 1530 : 4.152082692598924e-05
Loss at iteration 1540 : 0.0003304096171632409
Loss at iteration 1550 : 0.0005720530170947313
Loss at iteration 1560 : 9.375646186526865e-05
Loss at iteration 1570 : 0.003663336858153343
Loss at iteration 1580 : 6.716590723954141e-05
Loss at iteration 1590 : 0.00012748496374115348
Loss at iteration 1600 : 0.0025922150816768408
Loss at iteration 1610 : 0.0007670592167414725
Loss at iteration 1620 : 0.0005258703604340553
Loss at iteration 1630 : 0.000404406018787995
Loss at iteration 1640 : 4.397763404995203e-05
Loss at iteration 1650 : 0.00025013391859829426
Loss at iteration 1660 : 0.003391692880541086
Loss at iteration 1670 : 0.0001962545793503523
Loss at iteration 1680 : 0.00016828547813929617
Loss at iteration 1690 : 0.0002444228739477694
Loss at iteration 1700 : 0.0012110824463889003
Loss at iteration 1710 : 0.0002709039254114032
Loss at iteration 1720 : 0.00023066998983267695
Loss at iteration 1730 : 0.0014867553254589438
Loss at iteration 1740 : 0.00012777972733601928
Loss at iteration 1750 : 0.000351306633092463
The SSIM Value is: 0.985030651223817
The PSNR Value is: 46.61895479924878
the epoch is: 131
Loss at iteration 10 : 0.00034316012170165777
Loss at iteration 20 : 0.00012531253742054105
Loss at iteration 30 : 0.0011710624676197767
Loss at iteration 40 : 0.00034571648575365543
Loss at iteration 50 : 4.7653476940467954e-05
Loss at iteration 60 : 0.0003697671345435083
Loss at iteration 70 : 0.00013379000301938504
Loss at iteration 80 : 0.00020067408331669867
Loss at iteration 90 : 0.0006023989990353584
Loss at iteration 100 : 0.0010745902545750141
Loss at iteration 110 : 0.00011836967314593494
Loss at iteration 120 : 0.0004648756585083902
Loss at iteration 130 : 0.00335861137136817
Loss at iteration 140 : 0.0031837671995162964
Loss at iteration 150 : 0.00035902069066651165
Loss at iteration 160 : 0.000186319142812863
Loss at iteration 170 : 0.0007276950054802
Loss at iteration 180 : 0.0037785375025123358
Loss at iteration 190 : 0.003169615752995014
Loss at iteration 200 : 0.00010476703027961776
Loss at iteration 210 : 0.0015357541851699352
Loss at iteration 220 : 0.00013141866656951606
Loss at iteration 230 : 0.00014638098946306854
Loss at iteration 240 : 0.00011627086496446282
Loss at iteration 250 : 0.0017218017019331455
Loss at iteration 260 : 0.0004073545860592276
Loss at iteration 270 : 0.00019675455405376852
Loss at iteration 280 : 0.0009030649671331048
Loss at iteration 290 : 0.000519847497344017
Loss at iteration 300 : 0.0006406311294995248
Loss at iteration 310 : 0.0005216195713728666
Loss at iteration 320 : 0.00010515321628190577
Loss at iteration 330 : 0.0003112964623142034
Loss at iteration 340 : 0.00031628497526980937
Loss at iteration 350 : 0.00020759417384397238
Loss at iteration 360 : 0.00036760634975507855
Loss at iteration 370 : 0.0011820890940725803
Loss at iteration 380 : 0.0015142301563173532
Loss at iteration 390 : 0.0014238250441849232
Loss at iteration 400 : 0.0085969939827919
Loss at iteration 410 : 5.28325981576927e-05
Loss at iteration 420 : 0.00022277815151028335
Loss at iteration 430 : 0.0026420140638947487
Loss at iteration 440 : 0.005101587623357773
Loss at iteration 450 : 0.0033144578337669373
Loss at iteration 460 : 0.00037115681334398687
Loss at iteration 470 : 0.0005992823280394077
Loss at iteration 480 : 0.00030098907882347703
Loss at iteration 490 : 5.6692286307225004e-05
Loss at iteration 500 : 0.007431802339851856
Loss at iteration 510 : 0.0020622252486646175
Loss at iteration 520 : 0.00015922446618787944
Loss at iteration 530 : 0.000542248017154634
Loss at iteration 540 : 0.0011259154416620731
Loss at iteration 550 : 0.0019130881410092115
Loss at iteration 560 : 0.006782961077988148
Loss at iteration 570 : 0.0001472204166930169
Loss at iteration 580 : 0.000286400638287887
Loss at iteration 590 : 0.0024762353859841824
Loss at iteration 600 : 0.004194175358861685
Loss at iteration 610 : 0.004100640770047903
Loss at iteration 620 : 0.0027378564700484276
Loss at iteration 630 : 0.0018736092606559396
Loss at iteration 640 : 0.000512533588334918
Loss at iteration 650 : 0.00024254458548966795
Loss at iteration 660 : 0.0005819968064315617
Loss at iteration 670 : 0.0004232962673995644
Loss at iteration 680 : 0.0026470075827091932
Loss at iteration 690 : 0.00021598412422463298
Loss at iteration 700 : 0.00016896218585316092
Loss at iteration 710 : 0.0019521904177963734
Loss at iteration 720 : 0.0001373307895846665
Loss at iteration 730 : 7.32556582079269e-05
Loss at iteration 740 : 0.0005030388128943741
Loss at iteration 750 : 0.0001962146779987961
Loss at iteration 760 : 0.00014345113595481962
Loss at iteration 770 : 0.0023265895433723927
Loss at iteration 780 : 0.0037529829423874617
Loss at iteration 790 : 0.002497236942872405
Loss at iteration 800 : 8.686094224685803e-05
Loss at iteration 810 : 0.00019365872140042484
Loss at iteration 820 : 0.001724997186101973
Loss at iteration 830 : 8.82015228853561e-05
Loss at iteration 840 : 0.0021869910415261984
Loss at iteration 850 : 0.00012580963084474206
Loss at iteration 860 : 0.00013341389421839267
Loss at iteration 870 : 0.00046232741442508996
Loss at iteration 880 : 0.00015895452816039324
Loss at iteration 890 : 0.00016988693096209317
Loss at iteration 900 : 0.00014843638928141445
Loss at iteration 910 : 0.0002634081174619496
Loss at iteration 920 : 9.281285747420043e-05
Loss at iteration 930 : 0.0002335046010557562
Loss at iteration 940 : 0.00013210221368353814
Loss at iteration 950 : 3.466345151537098e-05
Loss at iteration 960 : 0.0003830452333204448
Loss at iteration 970 : 0.00019166468700859696
Loss at iteration 980 : 0.0027013616636395454
Loss at iteration 990 : 0.00012275934568606317
Loss at iteration 1000 : 0.0004081311053596437
Loss at iteration 1010 : 0.00018206793174613267
Loss at iteration 1020 : 0.00014488183660432696
Loss at iteration 1030 : 0.0002595375117380172
Loss at iteration 1040 : 5.6287768529728055e-05
Loss at iteration 1050 : 0.001967192627489567
Loss at iteration 1060 : 9.320005483459681e-05
Loss at iteration 1070 : 0.0020564869046211243
Loss at iteration 1080 : 0.00015130024985410273
Loss at iteration 1090 : 0.0024763206019997597
Loss at iteration 1100 : 0.0001232808717759326
Loss at iteration 1110 : 0.0002150594664271921
Loss at iteration 1120 : 0.0005608866922557354
Loss at iteration 1130 : 0.0015220573404803872
Loss at iteration 1140 : 0.00027637596940621734
Loss at iteration 1150 : 0.00017989357002079487
Loss at iteration 1160 : 0.00018230831483379006
Loss at iteration 1170 : 0.0002085130545310676
Loss at iteration 1180 : 0.00022689244360662997
Loss at iteration 1190 : 0.0006039705476723611
Loss at iteration 1200 : 0.00010827663936652243
Loss at iteration 1210 : 0.0016438195016235113
Loss at iteration 1220 : 0.001027750549837947
Loss at iteration 1230 : 7.931554137030616e-05
Loss at iteration 1240 : 0.0007779378211125731
Loss at iteration 1250 : 8.930251351557672e-05
Loss at iteration 1260 : 0.00015313968469854444
Loss at iteration 1270 : 0.0025228848680853844
Loss at iteration 1280 : 0.002669542096555233
Loss at iteration 1290 : 0.0002941364364232868
Loss at iteration 1300 : 0.005384018644690514
Loss at iteration 1310 : 0.0004949207650497556
Loss at iteration 1320 : 0.00015756244829390198
Loss at iteration 1330 : 9.781932749319822e-05
Loss at iteration 1340 : 0.00016768065688665956
Loss at iteration 1350 : 0.00036895403172820807
Loss at iteration 1360 : 0.002427150961011648
Loss at iteration 1370 : 0.0002401433594059199
Loss at iteration 1380 : 0.00012378787505440414
Loss at iteration 1390 : 0.002188124693930149
Loss at iteration 1400 : 0.0027857432141900063
Loss at iteration 1410 : 7.447285315720364e-05
Loss at iteration 1420 : 0.000966292223893106
Loss at iteration 1430 : 0.0005331917200237513
Loss at iteration 1440 : 0.00013116339687258005
Loss at iteration 1450 : 0.0019685926381498575
Loss at iteration 1460 : 0.003539164550602436
Loss at iteration 1470 : 0.0003714812046382576
Loss at iteration 1480 : 0.00037411428638733923
Loss at iteration 1490 : 0.00032626924803480506
Loss at iteration 1500 : 0.00037531740963459015
Loss at iteration 1510 : 0.007090824656188488
Loss at iteration 1520 : 0.00011013206676580012
Loss at iteration 1530 : 0.0002160501026082784
Loss at iteration 1540 : 0.0011116520036011934
Loss at iteration 1550 : 5.984957533655688e-05
Loss at iteration 1560 : 0.002246495569124818
Loss at iteration 1570 : 0.00035160212428309023
Loss at iteration 1580 : 0.0008667084621265531
Loss at iteration 1590 : 0.00019900126790162176
Loss at iteration 1600 : 9.351367043564096e-05
Loss at iteration 1610 : 0.00010609559831209481
Loss at iteration 1620 : 0.0030028733890503645
Loss at iteration 1630 : 0.001512056915089488
Loss at iteration 1640 : 0.0022616980131715536
Loss at iteration 1650 : 0.0003483103064354509
Loss at iteration 1660 : 0.0004163064295426011
Loss at iteration 1670 : 0.00013130638399161398
Loss at iteration 1680 : 0.00013400931493379176
Loss at iteration 1690 : 0.0005795470206066966
Loss at iteration 1700 : 0.000242440466536209
Loss at iteration 1710 : 0.00033534906106069684
Loss at iteration 1720 : 0.003659381764009595
Loss at iteration 1730 : 0.00010391624527983367
Loss at iteration 1740 : 0.00018136898870579898
Loss at iteration 1750 : 0.00017487420700490475
The SSIM Value is: 0.9841185699212919
The PSNR Value is: 46.39203493605626
the epoch is: 132
Loss at iteration 10 : 0.002918096724897623
Loss at iteration 20 : 0.0012853348162025213
Loss at iteration 30 : 0.0002021314576268196
Loss at iteration 40 : 0.007255296688526869
Loss at iteration 50 : 0.0014273987617343664
Loss at iteration 60 : 0.00030138701549731195
Loss at iteration 70 : 0.0001866557140601799
Loss at iteration 80 : 0.0003519413876347244
Loss at iteration 90 : 0.0025729273911565542
Loss at iteration 100 : 0.000254479527939111
Loss at iteration 110 : 0.0002901897532865405
Loss at iteration 120 : 0.0026900158263742924
Loss at iteration 130 : 0.00039439951069653034
Loss at iteration 140 : 0.0003511665272526443
Loss at iteration 150 : 0.0005243205814622343
Loss at iteration 160 : 0.0014124695444479585
Loss at iteration 170 : 0.0017685949569568038
Loss at iteration 180 : 0.000199318106751889
Loss at iteration 190 : 0.0012945892522111535
Loss at iteration 200 : 0.0001278171839658171
Loss at iteration 210 : 5.906113074161112e-05
Loss at iteration 220 : 0.002642339328303933
Loss at iteration 230 : 0.0004867338575422764
Loss at iteration 240 : 0.0006762477569282055
Loss at iteration 250 : 0.00016740334103815258
Loss at iteration 260 : 0.003928760532289743
Loss at iteration 270 : 0.00020074882195331156
Loss at iteration 280 : 0.00011593360977713019
Loss at iteration 290 : 0.0002358477795496583
Loss at iteration 300 : 0.003402876900509
Loss at iteration 310 : 0.0005284947110339999
Loss at iteration 320 : 0.00010592838953016326
Loss at iteration 330 : 0.002548007760196924
Loss at iteration 340 : 0.003828211920335889
Loss at iteration 350 : 0.0017365210223942995
Loss at iteration 360 : 0.0021654306910932064
Loss at iteration 370 : 6.762997509213164e-05
Loss at iteration 380 : 0.0009154251893050969
Loss at iteration 390 : 6.810133345425129e-05
Loss at iteration 400 : 0.00023660145234316587
Loss at iteration 410 : 0.0036583654582500458
Loss at iteration 420 : 0.003508515888825059
Loss at iteration 430 : 0.00015519699081778526
Loss at iteration 440 : 0.0002832014870364219
Loss at iteration 450 : 3.9558344724355265e-05
Loss at iteration 460 : 9.355926158605143e-05
Loss at iteration 470 : 0.00014782752259634435
Loss at iteration 480 : 0.00015891807561274618
Loss at iteration 490 : 0.00036267060204409063
Loss at iteration 500 : 0.00475695263594389
Loss at iteration 510 : 0.00011562892177607864
Loss at iteration 520 : 0.0009252774761989713
Loss at iteration 530 : 0.0003500139282550663
Loss at iteration 540 : 0.00034242638503201306
Loss at iteration 550 : 0.0003754664503503591
Loss at iteration 560 : 0.0015907009365037084
Loss at iteration 570 : 0.00010662246495485306
Loss at iteration 580 : 0.00012811896158382297
Loss at iteration 590 : 0.00018240798090118915
Loss at iteration 600 : 0.0023367907851934433
Loss at iteration 610 : 0.0005862483521923423
Loss at iteration 620 : 0.00012607715325430036
Loss at iteration 630 : 0.0025549198035150766
Loss at iteration 640 : 0.00024666800163686275
Loss at iteration 650 : 0.0004119159420952201
Loss at iteration 660 : 0.00036983678000979125
Loss at iteration 670 : 0.0020631682127714157
Loss at iteration 680 : 0.0026887101121246815
Loss at iteration 690 : 0.0031483592465519905
Loss at iteration 700 : 0.002480258233845234
Loss at iteration 710 : 0.0009843807201832533
Loss at iteration 720 : 0.0003321451658848673
Loss at iteration 730 : 0.0011432055616751313
Loss at iteration 740 : 0.0007805178174749017
Loss at iteration 750 : 0.002334252931177616
Loss at iteration 760 : 3.9199363527586684e-05
Loss at iteration 770 : 0.00011449463636381552
Loss at iteration 780 : 0.0017490740865468979
Loss at iteration 790 : 0.00016864995996002108
Loss at iteration 800 : 0.00013027385284658521
Loss at iteration 810 : 0.004521876573562622
Loss at iteration 820 : 0.00039752578595653176
Loss at iteration 830 : 0.0002788804704323411
Loss at iteration 840 : 0.0001331430539721623
Loss at iteration 850 : 0.0002287738025188446
Loss at iteration 860 : 0.00028636251226998866
Loss at iteration 870 : 0.0001673770311754197
Loss at iteration 880 : 0.0005948434118181467
Loss at iteration 890 : 0.00010538053174968809
Loss at iteration 900 : 0.00021293530880939215
Loss at iteration 910 : 0.00048551004147157073
Loss at iteration 920 : 0.00024739987566135824
Loss at iteration 930 : 5.185862028156407e-05
Loss at iteration 940 : 0.0007526042172685266
Loss at iteration 950 : 0.00010824004129972309
Loss at iteration 960 : 0.0001374737184960395
Loss at iteration 970 : 5.483658969751559e-05
Loss at iteration 980 : 0.000410786597058177
Loss at iteration 990 : 0.002190051134675741
Loss at iteration 1000 : 3.7231307942420244e-05
Loss at iteration 1010 : 0.0011311069829389453
Loss at iteration 1020 : 0.0031007055658847094
Loss at iteration 1030 : 0.005607444327324629
Loss at iteration 1040 : 0.004030177369713783
Loss at iteration 1050 : 7.564213592559099e-05
Loss at iteration 1060 : 0.0012554990826174617
Loss at iteration 1070 : 0.00039468929753638804
Loss at iteration 1080 : 0.0001455640740459785
Loss at iteration 1090 : 0.00011990561324637383
Loss at iteration 1100 : 0.0040119718760252
Loss at iteration 1110 : 0.00027690434944815934
Loss at iteration 1120 : 0.0027470914646983147
Loss at iteration 1130 : 9.584571671439335e-05
Loss at iteration 1140 : 0.00017844815738499165
Loss at iteration 1150 : 0.0001905948156490922
Loss at iteration 1160 : 0.00013971561565995216
Loss at iteration 1170 : 0.00028917286545038223
Loss at iteration 1180 : 0.00013542882516048849
Loss at iteration 1190 : 0.0003064270713366568
Loss at iteration 1200 : 0.00016437900194432586
Loss at iteration 1210 : 0.00032157631358131766
Loss at iteration 1220 : 0.00026521101244725287
Loss at iteration 1230 : 0.00022903349599801004
Loss at iteration 1240 : 0.00441357959061861
Loss at iteration 1250 : 0.00015039586287457496
Loss at iteration 1260 : 0.003229759866371751
Loss at iteration 1270 : 0.00029743011691607535
Loss at iteration 1280 : 0.0007764560868963599
Loss at iteration 1290 : 6.43411694909446e-05
Loss at iteration 1300 : 0.00019013909331988543
Loss at iteration 1310 : 0.006188652478158474
Loss at iteration 1320 : 0.00021395846852101386
Loss at iteration 1330 : 0.0010105607798323035
Loss at iteration 1340 : 0.00011882633407367393
Loss at iteration 1350 : 0.0007663003052584827
Loss at iteration 1360 : 0.00043770240154117346
Loss at iteration 1370 : 0.0032882613595575094
Loss at iteration 1380 : 0.000307647162117064
Loss at iteration 1390 : 0.0007632572087459266
Loss at iteration 1400 : 0.004265411291271448
Loss at iteration 1410 : 0.0002821457455866039
Loss at iteration 1420 : 0.001592849032022059
Loss at iteration 1430 : 0.0031195981428027153
Loss at iteration 1440 : 0.0016925493255257607
Loss at iteration 1450 : 0.0020789317786693573
Loss at iteration 1460 : 0.004163362085819244
Loss at iteration 1470 : 0.00023721164325252175
Loss at iteration 1480 : 0.0006690526497550309
Loss at iteration 1490 : 0.0010386265348643064
Loss at iteration 1500 : 0.002203734591603279
Loss at iteration 1510 : 0.0002739028714131564
Loss at iteration 1520 : 0.0014945329166948795
Loss at iteration 1530 : 0.0010608491720631719
Loss at iteration 1540 : 0.0023221236187964678
Loss at iteration 1550 : 0.00017055014905054122
Loss at iteration 1560 : 0.0004012065473943949
Loss at iteration 1570 : 0.0006537768058478832
Loss at iteration 1580 : 0.0003494212287478149
Loss at iteration 1590 : 0.00023070134920999408
Loss at iteration 1600 : 0.00014527251187246293
Loss at iteration 1610 : 0.004282230511307716
Loss at iteration 1620 : 9.647308615967631e-05
Loss at iteration 1630 : 0.00011819535575341433
Loss at iteration 1640 : 0.0021144933998584747
Loss at iteration 1650 : 0.0004396691801957786
Loss at iteration 1660 : 0.0002607557689771056
Loss at iteration 1670 : 0.00017308429232798517
Loss at iteration 1680 : 0.005381952505558729
Loss at iteration 1690 : 0.00011456479842308909
Loss at iteration 1700 : 0.006245981436222792
Loss at iteration 1710 : 0.00033699849154800177
Loss at iteration 1720 : 0.0002248004311695695
Loss at iteration 1730 : 0.00013719845446757972
Loss at iteration 1740 : 0.0009657603222876787
Loss at iteration 1750 : 0.0002620013547129929
The SSIM Value is: 0.9850020799867907
The PSNR Value is: 46.487320192059755
the epoch is: 133
Loss at iteration 10 : 0.0022348915226757526
Loss at iteration 20 : 0.0003169967094436288
Loss at iteration 30 : 0.0008039123495109379
Loss at iteration 40 : 0.002430096035823226
Loss at iteration 50 : 0.0008064010180532932
Loss at iteration 60 : 0.0001765758206602186
Loss at iteration 70 : 0.00015606556553393602
Loss at iteration 80 : 0.0002261058980366215
Loss at iteration 90 : 0.00027779510128311813
Loss at iteration 100 : 0.00044357922160997987
Loss at iteration 110 : 0.0005140310386195779
Loss at iteration 120 : 0.003385497722774744
Loss at iteration 130 : 0.00016844351193867624
Loss at iteration 140 : 0.00040757720125839114
Loss at iteration 150 : 0.0002386165433563292
Loss at iteration 160 : 0.0001586338330525905
Loss at iteration 170 : 0.00029626660398207605
Loss at iteration 180 : 0.0003616087487898767
Loss at iteration 190 : 0.006375598721206188
Loss at iteration 200 : 0.00011197085405001417
Loss at iteration 210 : 0.000989788444712758
Loss at iteration 220 : 0.00025236833607777953
Loss at iteration 230 : 0.00022594546317122877
Loss at iteration 240 : 0.00010117790952790529
Loss at iteration 250 : 0.00015377184899989516
Loss at iteration 260 : 0.0004048652481287718
Loss at iteration 270 : 0.00024199768085964024
Loss at iteration 280 : 0.0010362116154283285
Loss at iteration 290 : 8.337358303833753e-05
Loss at iteration 300 : 0.002950228750705719
Loss at iteration 310 : 3.366676901350729e-05
Loss at iteration 320 : 0.00017821147048380226
Loss at iteration 330 : 0.00023999976110644639
Loss at iteration 340 : 0.0004622105916496366
Loss at iteration 350 : 0.0003170746495015919
Loss at iteration 360 : 3.9431368350051343e-05
Loss at iteration 370 : 7.263649604283273e-05
Loss at iteration 380 : 0.00023224070901051164
Loss at iteration 390 : 0.00024640734773129225
Loss at iteration 400 : 0.00021277213818393648
Loss at iteration 410 : 0.00040023052133619785
Loss at iteration 420 : 8.934967627283186e-05
Loss at iteration 430 : 0.000493750732857734
Loss at iteration 440 : 0.0004209357430227101
Loss at iteration 450 : 0.00014147243928164244
Loss at iteration 460 : 0.00014201093290466815
Loss at iteration 470 : 0.00018603702483233064
Loss at iteration 480 : 0.0002939829137176275
Loss at iteration 490 : 0.00043460747110657394
Loss at iteration 500 : 0.0020373680163174868
Loss at iteration 510 : 0.00015980548050720245
Loss at iteration 520 : 0.00012901377340313047
Loss at iteration 530 : 0.0007431649137288332
Loss at iteration 540 : 0.0015745627461001277
Loss at iteration 550 : 0.0003673556202556938
Loss at iteration 560 : 0.00033350661396980286
Loss at iteration 570 : 0.006995250470936298
Loss at iteration 580 : 0.0006661650841124356
Loss at iteration 590 : 0.0006248271092772484
Loss at iteration 600 : 0.00018328908481635153
Loss at iteration 610 : 0.0032437052577733994
Loss at iteration 620 : 0.000164085126016289
Loss at iteration 630 : 0.00011936450755456463
Loss at iteration 640 : 0.0005673372070305049
Loss at iteration 650 : 0.00015679183707106858
Loss at iteration 660 : 0.0004223352298140526
Loss at iteration 670 : 3.764195571420714e-05
Loss at iteration 680 : 0.00033010137849487364
Loss at iteration 690 : 8.570477075409144e-05
Loss at iteration 700 : 0.0005391204031184316
Loss at iteration 710 : 0.00010337441926822066
Loss at iteration 720 : 0.0033000607509166002
Loss at iteration 730 : 0.00013253538054414093
Loss at iteration 740 : 0.003240294987335801
Loss at iteration 750 : 0.002630311530083418
Loss at iteration 760 : 0.0010620967950671911
Loss at iteration 770 : 0.000927599670831114
Loss at iteration 780 : 0.0011634067632257938
Loss at iteration 790 : 0.0002321857464266941
Loss at iteration 800 : 0.0008052951307035983
Loss at iteration 810 : 0.00016054109437391162
Loss at iteration 820 : 0.00019260708359070122
Loss at iteration 830 : 0.0009283747640438378
Loss at iteration 840 : 0.0015119852032512426
Loss at iteration 850 : 0.0002047553425654769
Loss at iteration 860 : 9.982432675315067e-05
Loss at iteration 870 : 0.0005924423458054662
Loss at iteration 880 : 0.00023240529117174447
Loss at iteration 890 : 0.0008391042938455939
Loss at iteration 900 : 0.00013342982856556773
Loss at iteration 910 : 0.00023053583572618663
Loss at iteration 920 : 0.0019273522775620222
Loss at iteration 930 : 0.00035911964369006455
Loss at iteration 940 : 0.0010605036513879895
Loss at iteration 950 : 0.00018088117940351367
Loss at iteration 960 : 0.0036534660030156374
Loss at iteration 970 : 0.00028264778666198254
Loss at iteration 980 : 0.0003820873680524528
Loss at iteration 990 : 7.890728738857433e-05
Loss at iteration 1000 : 0.00013419485185295343
Loss at iteration 1010 : 0.0001466500252718106
Loss at iteration 1020 : 0.00017315660079475492
Loss at iteration 1030 : 0.002810362260788679
Loss at iteration 1040 : 0.00019572211022023112
Loss at iteration 1050 : 0.0003704962437041104
Loss at iteration 1060 : 0.0006322424742393196
Loss at iteration 1070 : 0.0005820866790600121
Loss at iteration 1080 : 0.00033773467293940485
Loss at iteration 1090 : 0.002067260444164276
Loss at iteration 1100 : 0.0003286141436547041
Loss at iteration 1110 : 0.0008735053124837577
Loss at iteration 1120 : 0.0006671547889709473
Loss at iteration 1130 : 0.00020481680985540152
Loss at iteration 1140 : 0.00037773745134472847
Loss at iteration 1150 : 0.0005908342427574098
Loss at iteration 1160 : 0.005637743975967169
Loss at iteration 1170 : 0.00041128857992589474
Loss at iteration 1180 : 0.0004320167063269764
Loss at iteration 1190 : 0.003546925960108638
Loss at iteration 1200 : 0.0003268092405050993
Loss at iteration 1210 : 0.0002075007214443758
Loss at iteration 1220 : 0.0011248351074755192
Loss at iteration 1230 : 0.0021780976094305515
Loss at iteration 1240 : 0.000223616196308285
Loss at iteration 1250 : 0.000992446206510067
Loss at iteration 1260 : 0.0008398287463933229
Loss at iteration 1270 : 0.00024095411936286837
Loss at iteration 1280 : 0.0002653267001733184
Loss at iteration 1290 : 0.00011950948101002723
Loss at iteration 1300 : 0.001055024447850883
Loss at iteration 1310 : 0.0006550286198034883
Loss at iteration 1320 : 0.0009617726318538189
Loss at iteration 1330 : 5.129196506459266e-05
Loss at iteration 1340 : 0.0003162976063322276
Loss at iteration 1350 : 6.409177876776084e-05
Loss at iteration 1360 : 0.00015971777611412108
Loss at iteration 1370 : 5.549436173168942e-05
Loss at iteration 1380 : 0.00014128544717095792
Loss at iteration 1390 : 0.002636968856677413
Loss at iteration 1400 : 0.0036088107153773308
Loss at iteration 1410 : 0.00018402691057417542
Loss at iteration 1420 : 6.573004793608561e-05
Loss at iteration 1430 : 0.0005223004845902324
Loss at iteration 1440 : 9.737386426422745e-05
Loss at iteration 1450 : 6.615514575969428e-05
Loss at iteration 1460 : 8.845312549965456e-05
Loss at iteration 1470 : 0.00036829058080911636
Loss at iteration 1480 : 0.00013773517275694758
Loss at iteration 1490 : 0.0016088312258943915
Loss at iteration 1500 : 0.0004561962850857526
Loss at iteration 1510 : 0.00036232906859368086
Loss at iteration 1520 : 0.0003133714199066162
Loss at iteration 1530 : 0.001423484180122614
Loss at iteration 1540 : 5.545446401811205e-05
Loss at iteration 1550 : 0.0006556208245456219
Loss at iteration 1560 : 0.0002464533899910748
Loss at iteration 1570 : 0.003948384430259466
Loss at iteration 1580 : 0.0028624834958463907
Loss at iteration 1590 : 0.0022555948235094547
Loss at iteration 1600 : 0.00025021814508363605
Loss at iteration 1610 : 0.00024040283460635692
Loss at iteration 1620 : 0.0002837105421349406
Loss at iteration 1630 : 0.0013398779556155205
Loss at iteration 1640 : 0.00019198149675503373
Loss at iteration 1650 : 0.0010300904978066683
Loss at iteration 1660 : 0.00012894358951598406
Loss at iteration 1670 : 0.00016123322711791843
Loss at iteration 1680 : 0.000945190608035773
Loss at iteration 1690 : 0.0001442442589905113
Loss at iteration 1700 : 0.0012411054922267795
Loss at iteration 1710 : 0.004545130766928196
Loss at iteration 1720 : 9.539988241158426e-05
Loss at iteration 1730 : 0.0006738230586051941
Loss at iteration 1740 : 0.00010614890925353393
Loss at iteration 1750 : 0.00022096764587331563
The SSIM Value is: 0.9883816043973495
The PSNR Value is: 46.51069040340474
the epoch is: 134
Loss at iteration 10 : 0.00016036561282817274
Loss at iteration 20 : 0.0025497388560324907
Loss at iteration 30 : 9.387161844642833e-05
Loss at iteration 40 : 7.184695277828723e-05
Loss at iteration 50 : 0.0002996475959662348
Loss at iteration 60 : 9.034677350427955e-05
Loss at iteration 70 : 0.0002785215328913182
Loss at iteration 80 : 0.0018755686469376087
Loss at iteration 90 : 0.0003170472919009626
Loss at iteration 100 : 0.00011731034464901313
Loss at iteration 110 : 0.0004532161692623049
Loss at iteration 120 : 8.528870966983959e-05
Loss at iteration 130 : 0.000310487492242828
Loss at iteration 140 : 0.00021317906794138253
Loss at iteration 150 : 0.0002995384857058525
Loss at iteration 160 : 0.0020899176597595215
Loss at iteration 170 : 0.0014776702737435699
Loss at iteration 180 : 0.0001834532740758732
Loss at iteration 190 : 0.0020905029959976673
Loss at iteration 200 : 0.0015384049620479345
Loss at iteration 210 : 0.00032827083487063646
Loss at iteration 220 : 0.001015692250803113
Loss at iteration 230 : 0.0002367070846958086
Loss at iteration 240 : 0.0005516321398317814
Loss at iteration 250 : 6.922336615389213e-05
Loss at iteration 260 : 0.00012832286302000284
Loss at iteration 270 : 0.002466305624693632
Loss at iteration 280 : 0.0016196384094655514
Loss at iteration 290 : 7.029234257061034e-05
Loss at iteration 300 : 0.00012766689178533852
Loss at iteration 310 : 0.0002117843832820654
Loss at iteration 320 : 0.003013148671016097
Loss at iteration 330 : 9.480254811933264e-05
Loss at iteration 340 : 0.0002534828963689506
Loss at iteration 350 : 0.0032166687306016684
Loss at iteration 360 : 0.0023602372966706753
Loss at iteration 370 : 9.493085963185877e-05
Loss at iteration 380 : 0.00029321774491108954
Loss at iteration 390 : 0.0013443423667922616
Loss at iteration 400 : 0.0022246656008064747
Loss at iteration 410 : 0.0002994792303070426
Loss at iteration 420 : 0.0002995504473801702
Loss at iteration 430 : 0.0003797576355282217
Loss at iteration 440 : 0.004474978893995285
Loss at iteration 450 : 0.0011242812033742666
Loss at iteration 460 : 0.001604150515049696
Loss at iteration 470 : 0.0018643426010385156
Loss at iteration 480 : 0.0019385148771107197
Loss at iteration 490 : 0.00048415339551866055
Loss at iteration 500 : 0.00022906740196049213
Loss at iteration 510 : 0.005805117078125477
Loss at iteration 520 : 0.002570046577602625
Loss at iteration 530 : 0.0021626120433211327
Loss at iteration 540 : 9.639863856136799e-05
Loss at iteration 550 : 0.001085785566829145
Loss at iteration 560 : 0.0023722518235445023
Loss at iteration 570 : 9.686278644949198e-05
Loss at iteration 580 : 0.0013688822509720922
Loss at iteration 590 : 0.0007382851908914745
Loss at iteration 600 : 0.00017412497254554182
Loss at iteration 610 : 0.002771018771454692
Loss at iteration 620 : 5.397250788519159e-05
Loss at iteration 630 : 0.0001023897057166323
Loss at iteration 640 : 0.0013253072975203395
Loss at iteration 650 : 0.0003597842005547136
Loss at iteration 660 : 0.00036703934893012047
Loss at iteration 670 : 0.0001778745063347742
Loss at iteration 680 : 0.00024235609453171492
Loss at iteration 690 : 0.0030796690843999386
Loss at iteration 700 : 6.985285290284082e-05
Loss at iteration 710 : 0.00106510566547513
Loss at iteration 720 : 0.00013978887000121176
Loss at iteration 730 : 0.0016622752882540226
Loss at iteration 740 : 0.000270677002845332
Loss at iteration 750 : 0.00014607577759306878
Loss at iteration 760 : 0.0038776258006691933
Loss at iteration 770 : 0.0003488989605102688
Loss at iteration 780 : 0.00044572039041668177
Loss at iteration 790 : 8.889254240784794e-05
Loss at iteration 800 : 4.939189966535196e-05
Loss at iteration 810 : 0.00012474566756282002
Loss at iteration 820 : 0.00021041663421783596
Loss at iteration 830 : 0.0001731842930894345
Loss at iteration 840 : 0.00014303003263194114
Loss at iteration 850 : 0.00028833496617153287
Loss at iteration 860 : 5.691696424037218e-05
Loss at iteration 870 : 0.0002683863276615739
Loss at iteration 880 : 0.00015035507385618985
Loss at iteration 890 : 0.0008270272519439459
Loss at iteration 900 : 8.552436338504776e-05
Loss at iteration 910 : 0.001901419018395245
Loss at iteration 920 : 0.002273315330967307
Loss at iteration 930 : 0.00010246099554933608
Loss at iteration 940 : 0.00029384714434854686
Loss at iteration 950 : 8.4332401456777e-05
Loss at iteration 960 : 0.0002643158659338951
Loss at iteration 970 : 0.00034126409445889294
Loss at iteration 980 : 0.0009958812734112144
Loss at iteration 990 : 0.00011316969175823033
Loss at iteration 1000 : 0.00025343455490656197
Loss at iteration 1010 : 0.00010742845188360661
Loss at iteration 1020 : 5.8582321798894554e-05
Loss at iteration 1030 : 0.0001337567955488339
Loss at iteration 1040 : 5.369275459088385e-05
Loss at iteration 1050 : 0.0017949886387214065
Loss at iteration 1060 : 0.00030393374618142843
Loss at iteration 1070 : 0.0009230299619957805
Loss at iteration 1080 : 0.00011637533316388726
Loss at iteration 1090 : 0.0002862654800992459
Loss at iteration 1100 : 0.00013195911014918238
Loss at iteration 1110 : 0.0007105693221092224
Loss at iteration 1120 : 7.104279939085245e-05
Loss at iteration 1130 : 0.0009851929498836398
Loss at iteration 1140 : 0.00037038547452539206
Loss at iteration 1150 : 3.694654151331633e-05
Loss at iteration 1160 : 0.00043962147901766
Loss at iteration 1170 : 0.00094743596855551
Loss at iteration 1180 : 0.00022205468849278986
Loss at iteration 1190 : 8.68264542077668e-05
Loss at iteration 1200 : 0.00010366159403929487
Loss at iteration 1210 : 6.923537148395553e-05
Loss at iteration 1220 : 0.002088163746520877
Loss at iteration 1230 : 0.0026273331604897976
Loss at iteration 1240 : 0.00024203812063205987
Loss at iteration 1250 : 0.0024531891103833914
Loss at iteration 1260 : 0.005515637807548046
Loss at iteration 1270 : 0.0005817316705361009
Loss at iteration 1280 : 0.0005819356883876026
Loss at iteration 1290 : 0.0005090941558592021
Loss at iteration 1300 : 0.0002885988506022841
Loss at iteration 1310 : 0.003052577842026949
Loss at iteration 1320 : 3.4071781556122005e-05
Loss at iteration 1330 : 7.127189746825024e-05
Loss at iteration 1340 : 0.006829593330621719
Loss at iteration 1350 : 0.0002181773743359372
Loss at iteration 1360 : 0.003467004047706723
Loss at iteration 1370 : 0.0005428785807453096
Loss at iteration 1380 : 0.0008747145184315741
Loss at iteration 1390 : 0.00017906392167788
Loss at iteration 1400 : 0.0005809335852973163
Loss at iteration 1410 : 0.0019201545510441065
Loss at iteration 1420 : 0.00012230481661390513
Loss at iteration 1430 : 0.00021225032105576247
Loss at iteration 1440 : 0.00012518437870312482
Loss at iteration 1450 : 0.00023675394186284393
Loss at iteration 1460 : 0.003851089393720031
Loss at iteration 1470 : 0.0008072804193943739
Loss at iteration 1480 : 0.0015928569482639432
Loss at iteration 1490 : 0.00027607675292529166
Loss at iteration 1500 : 0.0005375175387598574
Loss at iteration 1510 : 0.00015113747213035822
Loss at iteration 1520 : 0.002937135985121131
Loss at iteration 1530 : 0.0004348341899458319
Loss at iteration 1540 : 0.0007626431761309505
Loss at iteration 1550 : 0.00014666968490928411
Loss at iteration 1560 : 0.0010728879133239388
Loss at iteration 1570 : 0.0001081801310647279
Loss at iteration 1580 : 0.0001528640277683735
Loss at iteration 1590 : 0.0001847939274739474
Loss at iteration 1600 : 0.002206571400165558
Loss at iteration 1610 : 0.00026298503507860005
Loss at iteration 1620 : 0.00023569754557684064
Loss at iteration 1630 : 0.00269797770306468
Loss at iteration 1640 : 0.00012954902194906026
Loss at iteration 1650 : 8.953022916102782e-05
Loss at iteration 1660 : 5.633241016766988e-05
Loss at iteration 1670 : 0.00012972450349479914
Loss at iteration 1680 : 0.00023754872381687164
Loss at iteration 1690 : 0.00019609623996075243
Loss at iteration 1700 : 9.074027184396982e-05
Loss at iteration 1710 : 0.0004877389292232692
Loss at iteration 1720 : 0.0002150246873497963
Loss at iteration 1730 : 0.0007724073366262019
Loss at iteration 1740 : 0.000709572690539062
Loss at iteration 1750 : 0.0013013072311878204
The SSIM Value is: 0.9875050578348437
The PSNR Value is: 46.63834311783577
the epoch is: 135
Loss at iteration 10 : 0.0002779195492621511
Loss at iteration 20 : 0.0025774678215384483
Loss at iteration 30 : 0.0006144276703707874
Loss at iteration 40 : 0.0002186077181249857
Loss at iteration 50 : 0.0003891349188052118
Loss at iteration 60 : 0.0001644357544137165
Loss at iteration 70 : 0.00010195524373557419
Loss at iteration 80 : 0.00022436976723838598
Loss at iteration 90 : 0.0010097525082528591
Loss at iteration 100 : 7.938710768939927e-05
Loss at iteration 110 : 0.00014253691188059747
Loss at iteration 120 : 0.0033008658792823553
Loss at iteration 130 : 0.00028511867276392877
Loss at iteration 140 : 0.0011111744679510593
Loss at iteration 150 : 0.0007054124143905938
Loss at iteration 160 : 0.0002022813423536718
Loss at iteration 170 : 0.0001384975330438465
Loss at iteration 180 : 0.003130071796476841
Loss at iteration 190 : 0.00016131230222526938
Loss at iteration 200 : 9.507920185569674e-05
Loss at iteration 210 : 0.00558813801035285
Loss at iteration 220 : 8.565835742047057e-05
Loss at iteration 230 : 0.00011786479444708675
Loss at iteration 240 : 0.0036128442734479904
Loss at iteration 250 : 0.00012963828339707106
Loss at iteration 260 : 0.0037481538020074368
Loss at iteration 270 : 0.0001506629487266764
Loss at iteration 280 : 0.004895028658211231
Loss at iteration 290 : 4.4106669520260766e-05
Loss at iteration 300 : 0.0009166272939182818
Loss at iteration 310 : 0.002778035821393132
Loss at iteration 320 : 0.0004215224471408874
Loss at iteration 330 : 0.00016758298443164676
Loss at iteration 340 : 0.00046681813546456397
Loss at iteration 350 : 0.00028694578213617206
Loss at iteration 360 : 6.631212454522029e-05
Loss at iteration 370 : 0.00014997813559602946
Loss at iteration 380 : 0.00018209095287602395
Loss at iteration 390 : 0.0005300514749251306
Loss at iteration 400 : 0.008311256766319275
Loss at iteration 410 : 0.0026660095900297165
Loss at iteration 420 : 0.0038183806464076042
Loss at iteration 430 : 0.0005393055616877973
Loss at iteration 440 : 0.0001952734455699101
Loss at iteration 450 : 0.00017077088705264032
Loss at iteration 460 : 0.0010829982347786427
Loss at iteration 470 : 0.0003050222294405103
Loss at iteration 480 : 0.0047300755977630615
Loss at iteration 490 : 0.0005392683669924736
Loss at iteration 500 : 0.000314206350594759
Loss at iteration 510 : 0.0002478382957633585
Loss at iteration 520 : 6.686671258648857e-05
Loss at iteration 530 : 0.0007677885005250573
Loss at iteration 540 : 0.0012073373654857278
Loss at iteration 550 : 0.0002545487368479371
Loss at iteration 560 : 0.00020111832418479025
Loss at iteration 570 : 0.00020535866497084498
Loss at iteration 580 : 0.00045438058441504836
Loss at iteration 590 : 0.000657601747661829
Loss at iteration 600 : 0.0017805853858590126
Loss at iteration 610 : 0.0017106089508160949
Loss at iteration 620 : 0.0005110943457111716
Loss at iteration 630 : 0.004217404872179031
Loss at iteration 640 : 0.001416124403476715
Loss at iteration 650 : 0.002741600386798382
Loss at iteration 660 : 0.0028640571981668472
Loss at iteration 670 : 8.516204252373427e-05
Loss at iteration 680 : 0.002759738825261593
Loss at iteration 690 : 0.00013902342470828444
Loss at iteration 700 : 0.0010701651917770505
Loss at iteration 710 : 7.294275565072894e-05
Loss at iteration 720 : 0.00013382801262196153
Loss at iteration 730 : 0.0003343646239954978
Loss at iteration 740 : 0.0016645870637148619
Loss at iteration 750 : 0.0002752379223238677
Loss at iteration 760 : 0.0021556455176323652
Loss at iteration 770 : 0.0032830159179866314
Loss at iteration 780 : 0.00014941862900741398
Loss at iteration 790 : 0.0011579657439142466
Loss at iteration 800 : 0.00021205053781159222
Loss at iteration 810 : 0.0001744505570968613
Loss at iteration 820 : 0.000977640855126083
Loss at iteration 830 : 7.691032078582793e-05
Loss at iteration 840 : 0.00080728845205158
Loss at iteration 850 : 0.001398154883645475
Loss at iteration 860 : 0.00010155947529710829
Loss at iteration 870 : 0.00028515138546936214
Loss at iteration 880 : 0.0004087613197043538
Loss at iteration 890 : 0.0005798108759336174
Loss at iteration 900 : 0.0009266813285648823
Loss at iteration 910 : 0.0010475850431248546
Loss at iteration 920 : 0.00010543166717980057
Loss at iteration 930 : 0.0036464512813836336
Loss at iteration 940 : 0.003790518268942833
Loss at iteration 950 : 7.140562956919894e-05
Loss at iteration 960 : 0.0001575890346430242
Loss at iteration 970 : 0.00013532183947972953
Loss at iteration 980 : 9.913607937050983e-05
Loss at iteration 990 : 0.0016970232827588916
Loss at iteration 1000 : 0.002232682891190052
Loss at iteration 1010 : 0.0008593489183112979
Loss at iteration 1020 : 0.000579263549298048
Loss at iteration 1030 : 0.00023488941951654851
Loss at iteration 1040 : 0.0067710550501942635
Loss at iteration 1050 : 0.002524853218346834
Loss at iteration 1060 : 0.0010851813713088632
Loss at iteration 1070 : 0.00030535226687788963
Loss at iteration 1080 : 0.00048540052375756204
Loss at iteration 1090 : 0.00013673241483047605
Loss at iteration 1100 : 0.0006949363159947097
Loss at iteration 1110 : 0.002316680969670415
Loss at iteration 1120 : 0.001340832095593214
Loss at iteration 1130 : 0.00027535230037756264
Loss at iteration 1140 : 0.0024787033908069134
Loss at iteration 1150 : 0.0008045253343880177
Loss at iteration 1160 : 0.0008204983896575868
Loss at iteration 1170 : 0.0003120597975794226
Loss at iteration 1180 : 0.003606642596423626
Loss at iteration 1190 : 0.00038242427399381995
Loss at iteration 1200 : 0.00037559709744527936
Loss at iteration 1210 : 0.00016804687038529664
Loss at iteration 1220 : 0.00018819005344994366
Loss at iteration 1230 : 0.00019856214930769056
Loss at iteration 1240 : 0.0007054118905216455
Loss at iteration 1250 : 0.0019845329225063324
Loss at iteration 1260 : 0.0003371291095390916
Loss at iteration 1270 : 0.0006338158855214715
Loss at iteration 1280 : 0.0049055712297558784
Loss at iteration 1290 : 0.0013456344604492188
Loss at iteration 1300 : 8.030336903175339e-05
Loss at iteration 1310 : 0.0001266613689949736
Loss at iteration 1320 : 0.001571865170262754
Loss at iteration 1330 : 8.989500202005729e-05
Loss at iteration 1340 : 0.00036759921931661665
Loss at iteration 1350 : 0.00044836700544692576
Loss at iteration 1360 : 8.276593871414661e-05
Loss at iteration 1370 : 0.0008371436852030456
Loss at iteration 1380 : 0.0021786729339510202
Loss at iteration 1390 : 0.0001091235171770677
Loss at iteration 1400 : 0.00046257281792350113
Loss at iteration 1410 : 0.0027539210859686136
Loss at iteration 1420 : 0.0002560334396548569
Loss at iteration 1430 : 9.860620048129931e-05
Loss at iteration 1440 : 0.00010286446922691539
Loss at iteration 1450 : 0.0001911712170112878
Loss at iteration 1460 : 0.0017907873261719942
Loss at iteration 1470 : 0.00044806787627749145
Loss at iteration 1480 : 0.0005993434460833669
Loss at iteration 1490 : 0.002187756123021245
Loss at iteration 1500 : 0.0019134263275191188
Loss at iteration 1510 : 7.093766907928512e-05
Loss at iteration 1520 : 0.0025042337365448475
Loss at iteration 1530 : 0.00015348210581578314
Loss at iteration 1540 : 8.324986265506595e-05
Loss at iteration 1550 : 8.217638969654217e-05
Loss at iteration 1560 : 0.0006527157966047525
Loss at iteration 1570 : 0.00011177528358530253
Loss at iteration 1580 : 9.27456421777606e-05
Loss at iteration 1590 : 0.000273607816779986
Loss at iteration 1600 : 4.5766289986204356e-05
Loss at iteration 1610 : 0.0011929553002119064
Loss at iteration 1620 : 0.0003184365341439843
Loss at iteration 1630 : 0.0005139224813319743
Loss at iteration 1640 : 0.0004753231769427657
Loss at iteration 1650 : 0.00016315311950165778
Loss at iteration 1660 : 0.0013270181370899081
Loss at iteration 1670 : 0.0001579449890414253
Loss at iteration 1680 : 0.00016155137564055622
Loss at iteration 1690 : 5.130638601258397e-05
Loss at iteration 1700 : 0.004928953014314175
Loss at iteration 1710 : 0.0001081751033780165
Loss at iteration 1720 : 0.0003096745640505105
Loss at iteration 1730 : 0.00047474796883761883
Loss at iteration 1740 : 0.0015990941319614649
Loss at iteration 1750 : 5.8816425735130906e-05
The SSIM Value is: 0.9866300842310364
The PSNR Value is: 46.517179480733326
the epoch is: 136
Loss at iteration 10 : 0.0034129968844354153
Loss at iteration 20 : 0.000560652872081846
Loss at iteration 30 : 0.00018751173047348857
Loss at iteration 40 : 0.0009273563046008348
Loss at iteration 50 : 8.029047603486106e-05
Loss at iteration 60 : 0.0002953636576421559
Loss at iteration 70 : 0.0010156402131542563
Loss at iteration 80 : 0.0007105952245183289
Loss at iteration 90 : 0.0005430530873127282
Loss at iteration 100 : 0.0001112958270823583
Loss at iteration 110 : 0.0032176743261516094
Loss at iteration 120 : 0.00051018939120695
Loss at iteration 130 : 0.00019828254880849272
Loss at iteration 140 : 0.002967838430777192
Loss at iteration 150 : 0.00034355922252871096
Loss at iteration 160 : 8.346710092155263e-05
Loss at iteration 170 : 0.00025281053967773914
Loss at iteration 180 : 0.003132506739348173
Loss at iteration 190 : 0.0001253570953849703
Loss at iteration 200 : 0.0016410165699198842
Loss at iteration 210 : 0.0014720610342919827
Loss at iteration 220 : 0.0009763345587998629
Loss at iteration 230 : 0.0002259625180158764
Loss at iteration 240 : 0.00025565645773895085
Loss at iteration 250 : 0.000263189896941185
Loss at iteration 260 : 0.0005742888897657394
Loss at iteration 270 : 0.00039681256748735905
Loss at iteration 280 : 0.0047827549278736115
Loss at iteration 290 : 0.0001889887498691678
Loss at iteration 300 : 6.715004565194249e-05
Loss at iteration 310 : 0.00011727430683095008
Loss at iteration 320 : 0.0014706600923091173
Loss at iteration 330 : 0.001188419759273529
Loss at iteration 340 : 0.00017489376477897167
Loss at iteration 350 : 0.0002286480157636106
Loss at iteration 360 : 0.000378690252546221
Loss at iteration 370 : 0.00015089868975337595
Loss at iteration 380 : 0.005498022772371769
Loss at iteration 390 : 0.0003988390089944005
Loss at iteration 400 : 0.002412151312455535
Loss at iteration 410 : 0.0001336565474048257
Loss at iteration 420 : 0.00019953680748585612
Loss at iteration 430 : 0.0019008198287338018
Loss at iteration 440 : 0.0004390282556414604
Loss at iteration 450 : 0.00038454640889540315
Loss at iteration 460 : 0.0030011029448360205
Loss at iteration 470 : 8.36402177810669e-05
Loss at iteration 480 : 0.0003544442297425121
Loss at iteration 490 : 8.093279029708356e-05
Loss at iteration 500 : 0.0004923067172057927
Loss at iteration 510 : 0.00031757820397615433
Loss at iteration 520 : 9.945989586412907e-05
Loss at iteration 530 : 0.0006185982492752373
Loss at iteration 540 : 0.0032151322811841965
Loss at iteration 550 : 0.0005132429068908095
Loss at iteration 560 : 0.005023160018026829
Loss at iteration 570 : 0.0002628093643579632
Loss at iteration 580 : 2.793345629470423e-05
Loss at iteration 590 : 0.0030785496346652508
Loss at iteration 600 : 0.000309730094159022
Loss at iteration 610 : 0.0001360817113891244
Loss at iteration 620 : 0.0003523961640894413
Loss at iteration 630 : 0.0027326871640980244
Loss at iteration 640 : 6.208210106706247e-05
Loss at iteration 650 : 0.003193858079612255
Loss at iteration 660 : 0.0028602341189980507
Loss at iteration 670 : 0.0001029714330798015
Loss at iteration 680 : 0.0006840206333436072
Loss at iteration 690 : 9.66960215009749e-05
Loss at iteration 700 : 0.0017659348668530583
Loss at iteration 710 : 0.0005697380984202027
Loss at iteration 720 : 0.00031546084210276604
Loss at iteration 730 : 0.001777114812284708
Loss at iteration 740 : 0.00016869409591890872
Loss at iteration 750 : 0.0001829235116019845
Loss at iteration 760 : 0.00011312255082884803
Loss at iteration 770 : 8.92256066435948e-05
Loss at iteration 780 : 0.0006886260234750807
Loss at iteration 790 : 0.00010821338219102472
Loss at iteration 800 : 0.00010081737855216488
Loss at iteration 810 : 0.00036635942524299026
Loss at iteration 820 : 0.0007771029486320913
Loss at iteration 830 : 0.0008082762360572815
Loss at iteration 840 : 0.003277041483670473
Loss at iteration 850 : 0.00016596814384683967
Loss at iteration 860 : 0.0008033122285269201
Loss at iteration 870 : 7.639286923222244e-05
Loss at iteration 880 : 0.00010496597678866237
Loss at iteration 890 : 2.974514245579485e-05
Loss at iteration 900 : 0.003854600479826331
Loss at iteration 910 : 0.0003220997750759125
Loss at iteration 920 : 0.0013426386285573244
Loss at iteration 930 : 0.00015293771866708994
Loss at iteration 940 : 0.0008371019503101707
Loss at iteration 950 : 0.0013895060401409864
Loss at iteration 960 : 0.00020215583208482713
Loss at iteration 970 : 0.0001157813603640534
Loss at iteration 980 : 4.220577466185205e-05
Loss at iteration 990 : 0.0019136860501021147
Loss at iteration 1000 : 0.0034676911309361458
Loss at iteration 1010 : 0.006616981700062752
Loss at iteration 1020 : 0.0003462705062702298
Loss at iteration 1030 : 0.0025308195035904646
Loss at iteration 1040 : 0.00019406602950766683
Loss at iteration 1050 : 0.0004283061425667256
Loss at iteration 1060 : 0.0001381094043608755
Loss at iteration 1070 : 0.0001919833302963525
Loss at iteration 1080 : 0.0010922563960775733
Loss at iteration 1090 : 0.00027731689624488354
Loss at iteration 1100 : 0.00023495890491176397
Loss at iteration 1110 : 0.002635101554915309
Loss at iteration 1120 : 0.0004822534683626145
Loss at iteration 1130 : 0.00014433286560233682
Loss at iteration 1140 : 0.0011311371345072985
Loss at iteration 1150 : 0.00036019718390889466
Loss at iteration 1160 : 0.0003667455748654902
Loss at iteration 1170 : 0.000815509061794728
Loss at iteration 1180 : 0.0012616546591743827
Loss at iteration 1190 : 0.00012816619710065424
Loss at iteration 1200 : 0.0004841077607125044
Loss at iteration 1210 : 6.90225133439526e-05
Loss at iteration 1220 : 0.0004094077739864588
Loss at iteration 1230 : 0.0002971671347040683
Loss at iteration 1240 : 0.000102672100183554
Loss at iteration 1250 : 7.360791641985998e-05
Loss at iteration 1260 : 0.00015610663103871047
Loss at iteration 1270 : 0.0019767864141613245
Loss at iteration 1280 : 0.0002261684276163578
Loss at iteration 1290 : 0.00033215037547051907
Loss at iteration 1300 : 0.00015228387201204896
Loss at iteration 1310 : 0.0029433169402182102
Loss at iteration 1320 : 0.0004675242817029357
Loss at iteration 1330 : 0.0003825467429123819
Loss at iteration 1340 : 0.0009072782704606652
Loss at iteration 1350 : 0.001088468823581934
Loss at iteration 1360 : 0.00037458716542460024
Loss at iteration 1370 : 0.00046747783198952675
Loss at iteration 1380 : 0.0019090166315436363
Loss at iteration 1390 : 0.0038022527005523443
Loss at iteration 1400 : 0.00031137786572799087
Loss at iteration 1410 : 0.001498701749369502
Loss at iteration 1420 : 0.0006304144044406712
Loss at iteration 1430 : 9.603191574569792e-05
Loss at iteration 1440 : 0.0021269437856972218
Loss at iteration 1450 : 0.0018706650007516146
Loss at iteration 1460 : 0.00020869041327387094
Loss at iteration 1470 : 0.00692669115960598
Loss at iteration 1480 : 0.0022579028736799955
Loss at iteration 1490 : 0.003540144534781575
Loss at iteration 1500 : 4.408932727528736e-05
Loss at iteration 1510 : 0.003478158498182893
Loss at iteration 1520 : 0.0023772786371409893
Loss at iteration 1530 : 7.152080070227385e-05
Loss at iteration 1540 : 0.0014106243615970016
Loss at iteration 1550 : 0.0007459964836016297
Loss at iteration 1560 : 0.0002490482875145972
Loss at iteration 1570 : 0.00017463238327763975
Loss at iteration 1580 : 0.0001974046608665958
Loss at iteration 1590 : 0.0003244801773689687
Loss at iteration 1600 : 0.0001807952648960054
Loss at iteration 1610 : 0.0010851831175386906
Loss at iteration 1620 : 0.0009463088936172426
Loss at iteration 1630 : 0.0036134133115410805
Loss at iteration 1640 : 0.00017072586342692375
Loss at iteration 1650 : 0.00014503931743092835
Loss at iteration 1660 : 0.00042452506022527814
Loss at iteration 1670 : 0.0001449967676308006
Loss at iteration 1680 : 0.0025912588462233543
Loss at iteration 1690 : 5.514161239261739e-05
Loss at iteration 1700 : 0.0011886314023286104
Loss at iteration 1710 : 0.00041657124529592693
Loss at iteration 1720 : 0.0013764528557658195
Loss at iteration 1730 : 0.0028650988824665546
Loss at iteration 1740 : 0.0005457960651256144
Loss at iteration 1750 : 0.0008208055514842272
The SSIM Value is: 0.985967101635912
The PSNR Value is: 46.59731235798235
the epoch is: 137
Loss at iteration 10 : 0.00031000684248283505
Loss at iteration 20 : 7.638846727786586e-05
Loss at iteration 30 : 0.00021414605726022273
Loss at iteration 40 : 0.0003414456150494516
Loss at iteration 50 : 0.0002691396221052855
Loss at iteration 60 : 0.00019420115859247744
Loss at iteration 70 : 0.0005853191250935197
Loss at iteration 80 : 0.0006770649924874306
Loss at iteration 90 : 0.002830131910741329
Loss at iteration 100 : 0.00547063210979104
Loss at iteration 110 : 0.0007645419100299478
Loss at iteration 120 : 0.0023713023401796818
Loss at iteration 130 : 0.002576491329818964
Loss at iteration 140 : 0.0010575554333627224
Loss at iteration 150 : 0.00032499866210855544
Loss at iteration 160 : 8.884145063348114e-05
Loss at iteration 170 : 0.00011625726619968191
Loss at iteration 180 : 0.00016723386943340302
Loss at iteration 190 : 0.00024306337581947446
Loss at iteration 200 : 0.00014670001110062003
Loss at iteration 210 : 0.0025873598642647266
Loss at iteration 220 : 0.00016515603056177497
Loss at iteration 230 : 0.00015903348685242236
Loss at iteration 240 : 0.0028127129189670086
Loss at iteration 250 : 0.000508872966747731
Loss at iteration 260 : 0.0001588372397236526
Loss at iteration 270 : 0.0008444779086858034
Loss at iteration 280 : 8.562135917600244e-05
Loss at iteration 290 : 5.5379125114995986e-05
Loss at iteration 300 : 0.0002327075053472072
Loss at iteration 310 : 0.00017469999147579074
Loss at iteration 320 : 0.00016277621034532785
Loss at iteration 330 : 0.0021060709841549397
Loss at iteration 340 : 0.0008149227360263467
Loss at iteration 350 : 0.0026546684093773365
Loss at iteration 360 : 0.001280949218198657
Loss at iteration 370 : 7.607896259287372e-05
Loss at iteration 380 : 4.6503533667419106e-05
Loss at iteration 390 : 0.0019457526504993439
Loss at iteration 400 : 0.0001246654719579965
Loss at iteration 410 : 0.0009487136267125607
Loss at iteration 420 : 7.636244117747992e-05
Loss at iteration 430 : 0.0012573904823511839
Loss at iteration 440 : 0.0001361844188068062
Loss at iteration 450 : 0.0087632667273283
Loss at iteration 460 : 0.0010710533242672682
Loss at iteration 470 : 0.00044194015208631754
Loss at iteration 480 : 0.0031156884506344795
Loss at iteration 490 : 9.286438580602407e-05
Loss at iteration 500 : 0.0008751625427976251
Loss at iteration 510 : 0.0005420963861979544
Loss at iteration 520 : 8.805007382761687e-05
Loss at iteration 530 : 0.00021754857152700424
Loss at iteration 540 : 0.005006053484976292
Loss at iteration 550 : 0.00019455354777164757
Loss at iteration 560 : 4.6778695832472295e-05
Loss at iteration 570 : 0.0005638194270431995
Loss at iteration 580 : 0.00016515761672053486
Loss at iteration 590 : 0.0004052399890497327
Loss at iteration 600 : 8.919798710849136e-05
Loss at iteration 610 : 0.00024814915377646685
Loss at iteration 620 : 0.00012718382640741765
Loss at iteration 630 : 0.002894240664318204
Loss at iteration 640 : 0.003501112572848797
Loss at iteration 650 : 0.00019951282592955977
Loss at iteration 660 : 0.0001295857218792662
Loss at iteration 670 : 5.7348130212631077e-05
Loss at iteration 680 : 0.0012624942464753985
Loss at iteration 690 : 0.00034895114367827773
Loss at iteration 700 : 0.002804485382512212
Loss at iteration 710 : 0.00021699418721254915
Loss at iteration 720 : 0.00027465278981253505
Loss at iteration 730 : 0.00010449951514601707
Loss at iteration 740 : 0.0005502573330886662
Loss at iteration 750 : 0.0004678480327129364
Loss at iteration 760 : 0.000140443560667336
Loss at iteration 770 : 0.0008084190776571631
Loss at iteration 780 : 0.00015053708921186626
Loss at iteration 790 : 0.0013691314961761236
Loss at iteration 800 : 0.0006089130183681846
Loss at iteration 810 : 8.254280692199245e-05
Loss at iteration 820 : 0.00032243941677734256
Loss at iteration 830 : 0.00013871681585442275
Loss at iteration 840 : 0.0035237143747508526
Loss at iteration 850 : 0.00029731832910329103
Loss at iteration 860 : 0.00014936212392058223
Loss at iteration 870 : 0.0004512321320362389
Loss at iteration 880 : 0.0013948882697150111
Loss at iteration 890 : 0.0010752154048532248
Loss at iteration 900 : 0.0002622836618684232
Loss at iteration 910 : 0.0018789529567584395
Loss at iteration 920 : 0.0006784466095268726
Loss at iteration 930 : 0.0001652012870181352
Loss at iteration 940 : 0.0015695176552981138
Loss at iteration 950 : 0.0004883008077740669
Loss at iteration 960 : 0.0016888459213078022
Loss at iteration 970 : 0.00023024340043775737
Loss at iteration 980 : 0.00015299662481993437
Loss at iteration 990 : 0.000278855295618996
Loss at iteration 1000 : 0.0011667170329019427
Loss at iteration 1010 : 0.0003174155717715621
Loss at iteration 1020 : 0.0008004929986782372
Loss at iteration 1030 : 0.0005477897357195616
Loss at iteration 1040 : 0.00010197537631029263
Loss at iteration 1050 : 0.00010450282570673153
Loss at iteration 1060 : 0.0006615120219066739
Loss at iteration 1070 : 0.0011546576861292124
Loss at iteration 1080 : 0.0005679996684193611
Loss at iteration 1090 : 0.000515467778313905
Loss at iteration 1100 : 0.00046429503709077835
Loss at iteration 1110 : 0.0006569183897227049
Loss at iteration 1120 : 0.004192787688225508
Loss at iteration 1130 : 0.005087820813059807
Loss at iteration 1140 : 0.0003593029105104506
Loss at iteration 1150 : 0.002463784534484148
Loss at iteration 1160 : 8.034571510506794e-05
Loss at iteration 1170 : 0.00047543278196826577
Loss at iteration 1180 : 0.00013801649038214236
Loss at iteration 1190 : 0.0010157435899600387
Loss at iteration 1200 : 0.001757193123921752
Loss at iteration 1210 : 0.005013579502701759
Loss at iteration 1220 : 0.008220288902521133
Loss at iteration 1230 : 6.614410813199356e-05
Loss at iteration 1240 : 0.00021555299463216215
Loss at iteration 1250 : 0.00024046815815381706
Loss at iteration 1260 : 0.00745457224547863
Loss at iteration 1270 : 0.001133048557676375
Loss at iteration 1280 : 8.96081401151605e-05
Loss at iteration 1290 : 0.0016240952536463737
Loss at iteration 1300 : 9.778750245459378e-05
Loss at iteration 1310 : 0.000224056449951604
Loss at iteration 1320 : 0.0004227968165650964
Loss at iteration 1330 : 0.0007745536277070642
Loss at iteration 1340 : 0.0003798612451646477
Loss at iteration 1350 : 0.0008792903972789645
Loss at iteration 1360 : 0.00012957394937984645
Loss at iteration 1370 : 0.0005214183474890888
Loss at iteration 1380 : 0.007186803966760635
Loss at iteration 1390 : 0.0021919291466474533
Loss at iteration 1400 : 0.00016041184426285326
Loss at iteration 1410 : 0.0021565116476267576
Loss at iteration 1420 : 6.762803968740627e-05
Loss at iteration 1430 : 0.0003558075404725969
Loss at iteration 1440 : 0.0005974008236080408
Loss at iteration 1450 : 0.0006911613745614886
Loss at iteration 1460 : 0.001872659893706441
Loss at iteration 1470 : 0.0028066684026271105
Loss at iteration 1480 : 0.00018409418407827616
Loss at iteration 1490 : 7.854231080273166e-05
Loss at iteration 1500 : 8.743767102714628e-05
Loss at iteration 1510 : 0.0008489088504575193
Loss at iteration 1520 : 0.004099090117961168
Loss at iteration 1530 : 0.00010884820221690461
Loss at iteration 1540 : 0.0009812596254050732
Loss at iteration 1550 : 0.0002044017892330885
Loss at iteration 1560 : 0.0005391975864768028
Loss at iteration 1570 : 9.770640463102609e-05
Loss at iteration 1580 : 0.0007633154164068401
Loss at iteration 1590 : 0.0003129987744614482
Loss at iteration 1600 : 9.879219578579068e-05
Loss at iteration 1610 : 0.0003001689910888672
Loss at iteration 1620 : 6.532978295581415e-05
Loss at iteration 1630 : 0.0003970763355027884
Loss at iteration 1640 : 7.43084674468264e-05
Loss at iteration 1650 : 0.00013825250789523125
Loss at iteration 1660 : 0.00045860628597438335
Loss at iteration 1670 : 0.000822057481855154
Loss at iteration 1680 : 8.076194353634492e-05
Loss at iteration 1690 : 0.002132344525307417
Loss at iteration 1700 : 6.733727059327066e-05
Loss at iteration 1710 : 0.000163641496328637
Loss at iteration 1720 : 0.0025674914941191673
Loss at iteration 1730 : 0.006799711845815182
Loss at iteration 1740 : 0.0007250768830999732
Loss at iteration 1750 : 0.00024083619064185768
The SSIM Value is: 0.9867082834243774
The PSNR Value is: 46.42023972372652
the epoch is: 138
Loss at iteration 10 : 0.00023039773805066943
Loss at iteration 20 : 0.0003937902220059186
Loss at iteration 30 : 0.0017233941471204162
Loss at iteration 40 : 0.0003970683610532433
Loss at iteration 50 : 0.00017490555183030665
Loss at iteration 60 : 0.0003150867123622447
Loss at iteration 70 : 0.0016051754355430603
Loss at iteration 80 : 0.0001385555078741163
Loss at iteration 90 : 0.0002254693681607023
Loss at iteration 100 : 0.00011944858124479651
Loss at iteration 110 : 0.00014949534670449793
Loss at iteration 120 : 0.00045532811782322824
Loss at iteration 130 : 0.002939626108855009
Loss at iteration 140 : 0.005995949264615774
Loss at iteration 150 : 0.00016854680143296719
Loss at iteration 160 : 0.0028926145751029253
Loss at iteration 170 : 3.305702193756588e-05
Loss at iteration 180 : 0.00014165091852191836
Loss at iteration 190 : 0.00016863881319295615
Loss at iteration 200 : 0.002524616662412882
Loss at iteration 210 : 0.003479491686448455
Loss at iteration 220 : 0.00015086607891134918
Loss at iteration 230 : 0.0023659728467464447
Loss at iteration 240 : 0.0008714871946722269
Loss at iteration 250 : 0.00022519243066199124
Loss at iteration 260 : 0.0011445736745372415
Loss at iteration 270 : 0.00010387277143308893
Loss at iteration 280 : 0.00013725511962547898
Loss at iteration 290 : 0.0004605822323355824
Loss at iteration 300 : 0.0026918970979750156
Loss at iteration 310 : 0.00016379938460886478
Loss at iteration 320 : 0.0024427049793303013
Loss at iteration 330 : 0.004332058597356081
Loss at iteration 340 : 0.0007141084643080831
Loss at iteration 350 : 0.0004122593381907791
Loss at iteration 360 : 0.00024234816373791546
Loss at iteration 370 : 0.0005205717752687633
Loss at iteration 380 : 0.0004047393158543855
Loss at iteration 390 : 0.0003836977994069457
Loss at iteration 400 : 6.54918621876277e-05
Loss at iteration 410 : 5.059836257714778e-05
Loss at iteration 420 : 0.0004908929113298655
Loss at iteration 430 : 0.0010714642703533173
Loss at iteration 440 : 0.00016204576240852475
Loss at iteration 450 : 5.213265831116587e-05
Loss at iteration 460 : 0.0009750382741913199
Loss at iteration 470 : 0.002572006545960903
Loss at iteration 480 : 8.954167424235493e-05
Loss at iteration 490 : 0.00011916831863345578
Loss at iteration 500 : 0.004002995789051056
Loss at iteration 510 : 0.00010134344483958557
Loss at iteration 520 : 0.00038042469532229006
Loss at iteration 530 : 8.379395148949698e-05
Loss at iteration 540 : 0.00025283731520175934
Loss at iteration 550 : 0.00025060484767891467
Loss at iteration 560 : 0.001271936227567494
Loss at iteration 570 : 0.00023895507911220193
Loss at iteration 580 : 9.68886015471071e-05
Loss at iteration 590 : 0.0007221559644676745
Loss at iteration 600 : 0.001474900171160698
Loss at iteration 610 : 8.798867202131078e-05
Loss at iteration 620 : 0.0005003935075365007
Loss at iteration 630 : 0.002307166578248143
Loss at iteration 640 : 0.0005470971809700131
Loss at iteration 650 : 0.0002581523440312594
Loss at iteration 660 : 0.0007498826598748565
Loss at iteration 670 : 0.0007461006753146648
Loss at iteration 680 : 0.000376064155716449
Loss at iteration 690 : 0.00043699186062440276
Loss at iteration 700 : 0.00021805442520417273
Loss at iteration 710 : 0.0005936278030276299
Loss at iteration 720 : 0.00011470547906355932
Loss at iteration 730 : 0.0012356333900243044
Loss at iteration 740 : 0.0006889743963256478
Loss at iteration 750 : 0.00012509740190580487
Loss at iteration 760 : 7.890007691457868e-05
Loss at iteration 770 : 0.0010691666975617409
Loss at iteration 780 : 0.0007089214632287621
Loss at iteration 790 : 0.00022089824778959155
Loss at iteration 800 : 0.0005652017425745726
Loss at iteration 810 : 0.0003175107412971556
Loss at iteration 820 : 0.003621714888140559
Loss at iteration 830 : 0.00011284294305369258
Loss at iteration 840 : 0.0005996493855491281
Loss at iteration 850 : 8.610982331447303e-05
Loss at iteration 860 : 0.00022353407985065132
Loss at iteration 870 : 0.00014725173241458833
Loss at iteration 880 : 0.0001710606156848371
Loss at iteration 890 : 8.334496669704095e-05
Loss at iteration 900 : 0.0007185308495536447
Loss at iteration 910 : 0.000586492067668587
Loss at iteration 920 : 0.00034235359635204077
Loss at iteration 930 : 0.00019116155453957617
Loss at iteration 940 : 0.00013230842887423933
Loss at iteration 950 : 0.0005942517891526222
Loss at iteration 960 : 9.144862269749865e-05
Loss at iteration 970 : 0.0010055527091026306
Loss at iteration 980 : 0.00035431573633104563
Loss at iteration 990 : 0.0004945232649333775
Loss at iteration 1000 : 0.0019966750405728817
Loss at iteration 1010 : 0.0003745341382455081
Loss at iteration 1020 : 0.00012744325795210898
Loss at iteration 1030 : 0.0009641017531976104
Loss at iteration 1040 : 9.458836575504392e-05
Loss at iteration 1050 : 8.517762762494385e-05
Loss at iteration 1060 : 0.00048427353613078594
Loss at iteration 1070 : 0.005291907116770744
Loss at iteration 1080 : 8.627747592981905e-05
Loss at iteration 1090 : 0.0004404797509778291
Loss at iteration 1100 : 0.00024794653290882707
Loss at iteration 1110 : 0.0019185203127563
Loss at iteration 1120 : 0.000245927571086213
Loss at iteration 1130 : 0.00031941031920723617
Loss at iteration 1140 : 0.00013198268425185233
Loss at iteration 1150 : 0.0007659830735065043
Loss at iteration 1160 : 0.003993856254965067
Loss at iteration 1170 : 0.0012543447082862258
Loss at iteration 1180 : 0.00013584710541181266
Loss at iteration 1190 : 0.0002531542268116027
Loss at iteration 1200 : 0.0005689848330803216
Loss at iteration 1210 : 0.008070779964327812
Loss at iteration 1220 : 0.0012778373202309012
Loss at iteration 1230 : 5.0196718802908435e-05
Loss at iteration 1240 : 0.00043986429227516055
Loss at iteration 1250 : 0.0006427683401852846
Loss at iteration 1260 : 0.0032717734575271606
Loss at iteration 1270 : 0.00034141138894483447
Loss at iteration 1280 : 0.00015848205657675862
Loss at iteration 1290 : 0.0028725722804665565
Loss at iteration 1300 : 0.0026531796902418137
Loss at iteration 1310 : 7.880391785874963e-05
Loss at iteration 1320 : 8.176068513421342e-05
Loss at iteration 1330 : 0.00015866347530391067
Loss at iteration 1340 : 0.0003469725197646767
Loss at iteration 1350 : 0.0006575821898877621
Loss at iteration 1360 : 0.00033597328001633286
Loss at iteration 1370 : 0.0008228082442656159
Loss at iteration 1380 : 0.0005786166293546557
Loss at iteration 1390 : 0.00028937170282006264
Loss at iteration 1400 : 0.0005095672095194459
Loss at iteration 1410 : 0.0004903977969661355
Loss at iteration 1420 : 0.00015192916907835752
Loss at iteration 1430 : 0.0011799358762800694
Loss at iteration 1440 : 0.0001804955245461315
Loss at iteration 1450 : 0.004078834783285856
Loss at iteration 1460 : 0.0011465580901131034
Loss at iteration 1470 : 0.00017902464605867863
Loss at iteration 1480 : 0.00012061662710038945
Loss at iteration 1490 : 0.004136825446039438
Loss at iteration 1500 : 0.0007124615367501974
Loss at iteration 1510 : 0.0024735592305660248
Loss at iteration 1520 : 0.00012682181841228157
Loss at iteration 1530 : 0.00020750668772961944
Loss at iteration 1540 : 3.932275285478681e-05
Loss at iteration 1550 : 0.0005889214226044714
Loss at iteration 1560 : 0.001797819510102272
Loss at iteration 1570 : 0.0022090415004640818
Loss at iteration 1580 : 0.0006310691242106259
Loss at iteration 1590 : 0.0002686113875824958
Loss at iteration 1600 : 9.53833368839696e-05
Loss at iteration 1610 : 0.008381312713027
Loss at iteration 1620 : 0.0050484295934438705
Loss at iteration 1630 : 0.0020169068593531847
Loss at iteration 1640 : 6.118523015175015e-05
Loss at iteration 1650 : 0.001303915516473353
Loss at iteration 1660 : 0.0008743251673877239
Loss at iteration 1670 : 0.0039293947629630566
Loss at iteration 1680 : 0.0006997664459049702
Loss at iteration 1690 : 0.0003058001457247883
Loss at iteration 1700 : 0.0015516879502683878
Loss at iteration 1710 : 0.00010595935600576922
Loss at iteration 1720 : 0.0004517901688814163
Loss at iteration 1730 : 0.0013742665760219097
Loss at iteration 1740 : 0.00014629215002059937
Loss at iteration 1750 : 5.472075645229779e-05
The SSIM Value is: 0.9784609882185638
The PSNR Value is: 46.16206611935788
the epoch is: 139
Loss at iteration 10 : 0.00021451579232234508
Loss at iteration 20 : 0.00037914488348178566
Loss at iteration 30 : 0.00033438135869801044
Loss at iteration 40 : 0.00047825451474636793
Loss at iteration 50 : 0.00022544308740179986
Loss at iteration 60 : 0.00027398287784308195
Loss at iteration 70 : 0.0012240258511155844
Loss at iteration 80 : 6.67926506139338e-05
Loss at iteration 90 : 0.0033820082899183035
Loss at iteration 100 : 0.002109201392158866
Loss at iteration 110 : 0.0002677322772797197
Loss at iteration 120 : 0.0009782384149730206
Loss at iteration 130 : 0.003762839362025261
Loss at iteration 140 : 6.441378354793414e-05
Loss at iteration 150 : 0.00020936888176947832
Loss at iteration 160 : 7.749912037979811e-05
Loss at iteration 170 : 0.0006239734357222915
Loss at iteration 180 : 0.0026063183322548866
Loss at iteration 190 : 0.0014451371971517801
Loss at iteration 200 : 0.00044190589687786996
Loss at iteration 210 : 0.00019429324311204255
Loss at iteration 220 : 0.0001339159207418561
Loss at iteration 230 : 0.0015003923326730728
Loss at iteration 240 : 0.0026800143532454967
Loss at iteration 250 : 0.00012004108430119231
Loss at iteration 260 : 8.381498628295958e-05
Loss at iteration 270 : 0.00010678872058633715
Loss at iteration 280 : 0.00027440168196335435
Loss at iteration 290 : 0.00028754136292263865
Loss at iteration 300 : 0.000594073033425957
Loss at iteration 310 : 0.00011654289119178429
Loss at iteration 320 : 0.0037794786039739847
Loss at iteration 330 : 0.003150440752506256
Loss at iteration 340 : 0.0001636789966141805
Loss at iteration 350 : 0.0002853134647011757
Loss at iteration 360 : 0.0020285153295844793
Loss at iteration 370 : 0.0036939713172614574
Loss at iteration 380 : 0.0022462704218924046
Loss at iteration 390 : 0.0005324636586010456
Loss at iteration 400 : 0.0030705039389431477
Loss at iteration 410 : 0.00038932886673137546
Loss at iteration 420 : 0.002285553840920329
Loss at iteration 430 : 9.045192564371973e-05
Loss at iteration 440 : 0.00018390851619187742
Loss at iteration 450 : 0.0036742896772921085
Loss at iteration 460 : 0.00019970950961578637
Loss at iteration 470 : 0.00013513470184989274
Loss at iteration 480 : 6.213214510353282e-05
Loss at iteration 490 : 0.00023192646040115505
Loss at iteration 500 : 0.00014893771731294692
Loss at iteration 510 : 0.000341384467901662
Loss at iteration 520 : 0.0005755360471084714
Loss at iteration 530 : 0.004170665983110666
Loss at iteration 540 : 0.00020147986651863903
Loss at iteration 550 : 0.0007164977723732591
Loss at iteration 560 : 0.00034318154212087393
Loss at iteration 570 : 0.003818826051428914
Loss at iteration 580 : 0.0017125187441706657
Loss at iteration 590 : 0.00025958591140806675
Loss at iteration 600 : 0.0036170671228319407
Loss at iteration 610 : 0.003693869337439537
Loss at iteration 620 : 0.0031472486443817616
Loss at iteration 630 : 0.004112611524760723
Loss at iteration 640 : 0.005017002113163471
Loss at iteration 650 : 6.828571349615231e-05
Loss at iteration 660 : 0.002102141734212637
Loss at iteration 670 : 0.0005745328962802887
Loss at iteration 680 : 0.0007593700429424644
Loss at iteration 690 : 0.0003675459884107113
Loss at iteration 700 : 2.7752921596402302e-05
Loss at iteration 710 : 0.00013768248027190566
Loss at iteration 720 : 0.0006974539719521999
Loss at iteration 730 : 0.00042620341992005706
Loss at iteration 740 : 0.00012104485358577222
Loss at iteration 750 : 0.00018826017912942916
Loss at iteration 760 : 0.00042889820178970695
Loss at iteration 770 : 0.00021469336934387684
Loss at iteration 780 : 0.002608242677524686
Loss at iteration 790 : 0.0009860752616077662
Loss at iteration 800 : 7.663582073291764e-05
Loss at iteration 810 : 0.00014417422062251717
Loss at iteration 820 : 0.004805859178304672
Loss at iteration 830 : 0.004701726604253054
Loss at iteration 840 : 0.0007848446257412434
Loss at iteration 850 : 0.0001943202514667064
Loss at iteration 860 : 0.0016200386453419924
Loss at iteration 870 : 0.000991372624412179
Loss at iteration 880 : 0.0013434705324470997
Loss at iteration 890 : 0.00012923574831802398
Loss at iteration 900 : 0.0004494912864174694
Loss at iteration 910 : 0.00029098644154146314
Loss at iteration 920 : 0.00013036164455115795
Loss at iteration 930 : 0.0013405387289822102
Loss at iteration 940 : 0.0052529750391840935
Loss at iteration 950 : 0.0003916139539796859
Loss at iteration 960 : 0.00012792523193638772
Loss at iteration 970 : 9.225906251231208e-05
Loss at iteration 980 : 0.0005128899938426912
Loss at iteration 990 : 0.002693945774808526
Loss at iteration 1000 : 7.237905083457008e-05
Loss at iteration 1010 : 0.00017264105554204434
Loss at iteration 1020 : 0.0003792653151322156
Loss at iteration 1030 : 0.0005516040837392211
Loss at iteration 1040 : 0.007945774123072624
Loss at iteration 1050 : 0.00012459575373213738
Loss at iteration 1060 : 0.002042601350694895
Loss at iteration 1070 : 0.00449267216026783
Loss at iteration 1080 : 0.0005223213229328394
Loss at iteration 1090 : 0.0001478864869568497
Loss at iteration 1100 : 0.0030346668791025877
Loss at iteration 1110 : 0.00015297312347684056
Loss at iteration 1120 : 8.314717706525698e-05
Loss at iteration 1130 : 0.0005205850466154516
Loss at iteration 1140 : 0.00011240781168453395
Loss at iteration 1150 : 8.063219138421118e-05
Loss at iteration 1160 : 0.002385632134974003
Loss at iteration 1170 : 0.0009857630357146263
Loss at iteration 1180 : 0.004457068629562855
Loss at iteration 1190 : 0.0018532994436100125
Loss at iteration 1200 : 0.00019147006969433278
Loss at iteration 1210 : 0.0018951419042423368
Loss at iteration 1220 : 0.00030029419576749206
Loss at iteration 1230 : 0.00044237595284357667
Loss at iteration 1240 : 0.0005980449495837092
Loss at iteration 1250 : 0.0017577229300513864
Loss at iteration 1260 : 0.00045494225923903286
Loss at iteration 1270 : 0.00017407000996172428
Loss at iteration 1280 : 0.00012698654609266669
Loss at iteration 1290 : 0.0011085910955443978
Loss at iteration 1300 : 0.0016651591286063194
Loss at iteration 1310 : 0.00021084895706735551
Loss at iteration 1320 : 0.00020607472106348723
Loss at iteration 1330 : 0.0021183383651077747
Loss at iteration 1340 : 0.0012423261068761349
Loss at iteration 1350 : 0.000443797092884779
Loss at iteration 1360 : 0.0013520825887098908
Loss at iteration 1370 : 0.002282248344272375
Loss at iteration 1380 : 5.254883581073955e-05
Loss at iteration 1390 : 0.0003397635882720351
Loss at iteration 1400 : 0.0001890356361400336
Loss at iteration 1410 : 0.0006513674161396921
Loss at iteration 1420 : 0.0003240159130655229
Loss at iteration 1430 : 0.006813157349824905
Loss at iteration 1440 : 0.00011581076250877231
Loss at iteration 1450 : 0.00012459937715902925
Loss at iteration 1460 : 0.0011551943607628345
Loss at iteration 1470 : 0.0012356529477983713
Loss at iteration 1480 : 0.0001636280067032203
Loss at iteration 1490 : 0.00033467073808424175
Loss at iteration 1500 : 0.002204215619713068
Loss at iteration 1510 : 0.0005904692225158215
Loss at iteration 1520 : 0.00042098347330465913
Loss at iteration 1530 : 0.005404556170105934
Loss at iteration 1540 : 0.0003792473580688238
Loss at iteration 1550 : 0.0003433219972066581
Loss at iteration 1560 : 0.0002899663813877851
Loss at iteration 1570 : 0.003721831366419792
Loss at iteration 1580 : 0.0028278420213609934
Loss at iteration 1590 : 7.235781959025189e-05
Loss at iteration 1600 : 0.0005583896418102086
Loss at iteration 1610 : 0.004036488477140665
Loss at iteration 1620 : 0.00011309568071737885
Loss at iteration 1630 : 0.001080920803360641
Loss at iteration 1640 : 9.582027269061655e-05
Loss at iteration 1650 : 0.00019476577290333807
Loss at iteration 1660 : 0.0035656471736729145
Loss at iteration 1670 : 0.0002010206808336079
Loss at iteration 1680 : 0.0021175527945160866
Loss at iteration 1690 : 0.000218847650103271
Loss at iteration 1700 : 0.00011427482240833342
Loss at iteration 1710 : 0.000252947531407699
Loss at iteration 1720 : 0.0037881755270063877
Loss at iteration 1730 : 0.0007650814368389547
Loss at iteration 1740 : 0.0006922597531229258
Loss at iteration 1750 : 0.0007222002022899687
The SSIM Value is: 0.9892902596143899
The PSNR Value is: 46.56213962874224
the epoch is: 140
Loss at iteration 10 : 7.046762038953602e-05
Loss at iteration 20 : 0.00012626402894966304
Loss at iteration 30 : 0.0024292543530464172
Loss at iteration 40 : 0.0001503011881140992
Loss at iteration 50 : 0.00020409550052136183
Loss at iteration 60 : 0.0007345361518673599
Loss at iteration 70 : 0.003855147399008274
Loss at iteration 80 : 0.0026961322873830795
Loss at iteration 90 : 0.0007943041855469346
Loss at iteration 100 : 0.0007897003670223057
Loss at iteration 110 : 0.000474092666991055
Loss at iteration 120 : 0.00013115255569573492
Loss at iteration 130 : 0.009489479474723339
Loss at iteration 140 : 0.00033523759339004755
Loss at iteration 150 : 0.0035266221966594458
Loss at iteration 160 : 8.001198875717819e-05
Loss at iteration 170 : 9.700318332761526e-05
Loss at iteration 180 : 0.00021881380234844983
Loss at iteration 190 : 0.0003908529761247337
Loss at iteration 200 : 8.284470095532015e-05
Loss at iteration 210 : 0.0002849229204002768
Loss at iteration 220 : 0.000310458242893219
Loss at iteration 230 : 0.0004885825328528881
Loss at iteration 240 : 0.00013786955969408154
Loss at iteration 250 : 0.0010792359244078398
Loss at iteration 260 : 0.00018642301438376307
Loss at iteration 270 : 0.0004965108237229288
Loss at iteration 280 : 0.0003867250052280724
Loss at iteration 290 : 0.00020065631542820483
Loss at iteration 300 : 0.00015704332327004522
Loss at iteration 310 : 0.0002644426131155342
Loss at iteration 320 : 0.00025752175133675337
Loss at iteration 330 : 7.082276715664193e-05
Loss at iteration 340 : 0.0012975622666999698
Loss at iteration 350 : 0.00029461385565809906
Loss at iteration 360 : 0.0013957255287095904
Loss at iteration 370 : 0.007348265498876572
Loss at iteration 380 : 0.00022266477753873914
Loss at iteration 390 : 0.00011857019853778183
Loss at iteration 400 : 0.00332717620767653
Loss at iteration 410 : 0.00036688579712063074
Loss at iteration 420 : 0.0002536236133892089
Loss at iteration 430 : 0.00419854000210762
Loss at iteration 440 : 0.00015168714162427932
Loss at iteration 450 : 6.826907338108867e-05
Loss at iteration 460 : 0.00011113437358289957
Loss at iteration 470 : 0.0001018946131807752
Loss at iteration 480 : 0.0001771440583979711
Loss at iteration 490 : 0.0008352592121809721
Loss at iteration 500 : 0.00030056401737965643
Loss at iteration 510 : 0.00035280699376016855
Loss at iteration 520 : 0.001737444312311709
Loss at iteration 530 : 6.909092917339876e-05
Loss at iteration 540 : 0.0022631646133959293
Loss at iteration 550 : 0.00023631125804968178
Loss at iteration 560 : 9.588735701981932e-05
Loss at iteration 570 : 0.000662545149680227
Loss at iteration 580 : 0.0005513765499927104
Loss at iteration 590 : 0.0011913885828107595
Loss at iteration 600 : 0.0032789111137390137
Loss at iteration 610 : 0.00010695078526623547
Loss at iteration 620 : 0.0003125294460915029
Loss at iteration 630 : 0.0004202671116217971
Loss at iteration 640 : 0.00045851696631871164
Loss at iteration 650 : 0.00040222113602794707
Loss at iteration 660 : 0.0035264401230961084
Loss at iteration 670 : 0.0065839821472764015
Loss at iteration 680 : 0.00011848863505292684
Loss at iteration 690 : 0.0017503186827525496
Loss at iteration 700 : 0.001946720527485013
Loss at iteration 710 : 0.0013314696261659265
Loss at iteration 720 : 0.0016060946509242058
Loss at iteration 730 : 0.00020773291180375963
Loss at iteration 740 : 0.0017018148209899664
Loss at iteration 750 : 0.00013902266800869256
Loss at iteration 760 : 0.0001445329253328964
Loss at iteration 770 : 0.0005457332590594888
Loss at iteration 780 : 0.0004146636638324708
Loss at iteration 790 : 0.001635843887925148
Loss at iteration 800 : 0.00014189175271894783
Loss at iteration 810 : 0.00012314043124206364
Loss at iteration 820 : 0.0001592809712747112
Loss at iteration 830 : 0.0002332037256564945
Loss at iteration 840 : 0.0048892139457166195
Loss at iteration 850 : 0.00021631846902891994
Loss at iteration 860 : 0.0003652488230727613
Loss at iteration 870 : 9.250409493688494e-05
Loss at iteration 880 : 0.0005889605381526053
Loss at iteration 890 : 0.00012251726002432406
Loss at iteration 900 : 0.00027001622947864234
Loss at iteration 910 : 0.002283127047121525
Loss at iteration 920 : 0.00014112023927737027
Loss at iteration 930 : 0.00037401574081741273
Loss at iteration 940 : 0.00054266577353701
Loss at iteration 950 : 0.00015987393271643668
Loss at iteration 960 : 0.001287344261072576
Loss at iteration 970 : 0.0009149606339633465
Loss at iteration 980 : 0.0003328635939396918
Loss at iteration 990 : 0.0005997815169394016
Loss at iteration 1000 : 0.003605774836614728
Loss at iteration 1010 : 0.0007360744057223201
Loss at iteration 1020 : 0.002115331357344985
Loss at iteration 1030 : 0.0031740819104015827
Loss at iteration 1040 : 0.00024835270596668124
Loss at iteration 1050 : 6.349563773255795e-05
Loss at iteration 1060 : 0.0006197583279572427
Loss at iteration 1070 : 8.373533637495711e-05
Loss at iteration 1080 : 0.00023213063832372427
Loss at iteration 1090 : 5.606707418337464e-05
Loss at iteration 1100 : 5.103177682030946e-05
Loss at iteration 1110 : 0.0005852198228240013
Loss at iteration 1120 : 0.0008740219054743648
Loss at iteration 1130 : 0.00013969678548164666
Loss at iteration 1140 : 0.002092470182105899
Loss at iteration 1150 : 0.0006213515298441052
Loss at iteration 1160 : 0.0004714050446636975
Loss at iteration 1170 : 0.0008108888287097216
Loss at iteration 1180 : 0.0003015664988197386
Loss at iteration 1190 : 0.00014953326899558306
Loss at iteration 1200 : 0.0005229349480941892
Loss at iteration 1210 : 0.00019972164591308683
Loss at iteration 1220 : 0.0017969728214666247
Loss at iteration 1230 : 0.0007173438789322972
Loss at iteration 1240 : 0.0001868299877969548
Loss at iteration 1250 : 0.0002341940999031067
Loss at iteration 1260 : 0.00019633279589470476
Loss at iteration 1270 : 0.00013813251280225813
Loss at iteration 1280 : 0.00045840037637390196
Loss at iteration 1290 : 0.0005611197557300329
Loss at iteration 1300 : 0.000553768128156662
Loss at iteration 1310 : 0.00042169028893113136
Loss at iteration 1320 : 0.0006905627669766545
Loss at iteration 1330 : 0.00011127709876745939
Loss at iteration 1340 : 0.006592491175979376
Loss at iteration 1350 : 0.0001874431036412716
Loss at iteration 1360 : 0.002735862974077463
Loss at iteration 1370 : 0.00012552994303405285
Loss at iteration 1380 : 0.0027207890525460243
Loss at iteration 1390 : 0.005101058632135391
Loss at iteration 1400 : 0.00020968777243979275
Loss at iteration 1410 : 0.000574922829400748
Loss at iteration 1420 : 0.0003236302291043103
Loss at iteration 1430 : 0.0025548995472490788
Loss at iteration 1440 : 0.00032228921190835536
Loss at iteration 1450 : 0.0001375934516545385
Loss at iteration 1460 : 0.0009446271578781307
Loss at iteration 1470 : 6.9739980972372e-05
Loss at iteration 1480 : 0.0003632801817730069
Loss at iteration 1490 : 0.0001067604825948365
Loss at iteration 1500 : 0.0011562681756913662
Loss at iteration 1510 : 0.0002506015880499035
Loss at iteration 1520 : 0.00014245553757064044
Loss at iteration 1530 : 0.0004816661821678281
Loss at iteration 1540 : 8.131130016408861e-05
Loss at iteration 1550 : 0.00038929766742512584
Loss at iteration 1560 : 0.0026346021331846714
Loss at iteration 1570 : 0.002027665264904499
Loss at iteration 1580 : 0.0001963376416824758
Loss at iteration 1590 : 0.0006019803695380688
Loss at iteration 1600 : 0.00034913112176582217
Loss at iteration 1610 : 0.002850383287295699
Loss at iteration 1620 : 0.0014701740583404899
Loss at iteration 1630 : 0.0008898262167349458
Loss at iteration 1640 : 0.0001938318891916424
Loss at iteration 1650 : 9.729505836730823e-05
Loss at iteration 1660 : 0.0005079084075987339
Loss at iteration 1670 : 0.0003611429128795862
Loss at iteration 1680 : 9.676155605120584e-05
Loss at iteration 1690 : 0.00013202580157667398
Loss at iteration 1700 : 9.231413423549384e-05
Loss at iteration 1710 : 0.00014224783808458596
Loss at iteration 1720 : 6.717533688060939e-05
Loss at iteration 1730 : 0.001668334472924471
Loss at iteration 1740 : 0.0013114657485857606
Loss at iteration 1750 : 0.00011918575910385698
The SSIM Value is: 0.9861397705151647
The PSNR Value is: 46.54415165905385
the epoch is: 141
Loss at iteration 10 : 0.00011281087790848687
Loss at iteration 20 : 0.004284867085516453
Loss at iteration 30 : 0.0002905123110394925
Loss at iteration 40 : 0.00048729468835517764
Loss at iteration 50 : 0.0010893115540966392
Loss at iteration 60 : 0.002535370411351323
Loss at iteration 70 : 0.0026616454124450684
Loss at iteration 80 : 0.005254603922367096
Loss at iteration 90 : 0.00019601591338869184
Loss at iteration 100 : 0.00031728038447909057
Loss at iteration 110 : 0.006950909271836281
Loss at iteration 120 : 0.00032829144038259983
Loss at iteration 130 : 0.006711479276418686
Loss at iteration 140 : 0.00040187983540818095
Loss at iteration 150 : 0.0038888968992978334
Loss at iteration 160 : 0.0017529877368360758
Loss at iteration 170 : 0.0025502177886664867
Loss at iteration 180 : 0.00034143991069868207
Loss at iteration 190 : 0.00015295486082322896
Loss at iteration 200 : 0.00032876263139769435
Loss at iteration 210 : 0.00023191171931102872
Loss at iteration 220 : 0.000195888671441935
Loss at iteration 230 : 0.00025344864116050303
Loss at iteration 240 : 0.0005478066741488874
Loss at iteration 250 : 0.0013176993234083056
Loss at iteration 260 : 0.0010305449832230806
Loss at iteration 270 : 0.0005566162872128189
Loss at iteration 280 : 0.0033246774692088366
Loss at iteration 290 : 0.00028614868642762303
Loss at iteration 300 : 0.0034577976912260056
Loss at iteration 310 : 0.0008378760539926589
Loss at iteration 320 : 0.000518797489348799
Loss at iteration 330 : 9.859379497356713e-05
Loss at iteration 340 : 0.0009004519088193774
Loss at iteration 350 : 0.0003678305947687477
Loss at iteration 360 : 0.0019282448338344693
Loss at iteration 370 : 0.00043464545160532
Loss at iteration 380 : 0.00014395515609066933
Loss at iteration 390 : 0.0013260738924145699
Loss at iteration 400 : 0.0003421006549615413
Loss at iteration 410 : 0.002901975065469742
Loss at iteration 420 : 0.0002138157287845388
Loss at iteration 430 : 3.617633774410933e-05
Loss at iteration 440 : 0.003065266413614154
Loss at iteration 450 : 0.004145913757383823
Loss at iteration 460 : 0.0022261282429099083
Loss at iteration 470 : 0.0007877678726799786
Loss at iteration 480 : 0.0028572860173881054
Loss at iteration 490 : 0.00017904426204040647
Loss at iteration 500 : 0.0002525889431126416
Loss at iteration 510 : 0.00015891570365056396
Loss at iteration 520 : 0.0006390906637534499
Loss at iteration 530 : 0.0002970368950627744
Loss at iteration 540 : 0.002947597997263074
Loss at iteration 550 : 0.005663576070219278
Loss at iteration 560 : 9.360362309962511e-05
Loss at iteration 570 : 0.0029415537137538195
Loss at iteration 580 : 0.00011745255324058235
Loss at iteration 590 : 0.0007879144395701587
Loss at iteration 600 : 9.945621422957629e-05
Loss at iteration 610 : 6.447872874559835e-05
Loss at iteration 620 : 0.0011518225073814392
Loss at iteration 630 : 0.00020965805742889643
Loss at iteration 640 : 0.00026207647169940174
Loss at iteration 650 : 0.0029642977751791477
Loss at iteration 660 : 4.515140244620852e-05
Loss at iteration 670 : 0.0025040071923285723
Loss at iteration 680 : 0.00017716287402436137
Loss at iteration 690 : 0.002540991175919771
Loss at iteration 700 : 0.001371112884953618
Loss at iteration 710 : 0.0017126686871051788
Loss at iteration 720 : 8.002300455700606e-05
Loss at iteration 730 : 6.52550152153708e-05
Loss at iteration 740 : 0.0005981626454740763
Loss at iteration 750 : 0.00013785090413875878
Loss at iteration 760 : 0.0004002096247859299
Loss at iteration 770 : 7.069275307003409e-05
Loss at iteration 780 : 0.00017322439816780388
Loss at iteration 790 : 0.0029784957878291607
Loss at iteration 800 : 0.0002209184312960133
Loss at iteration 810 : 7.887190440669656e-05
Loss at iteration 820 : 0.00017832510638982058
Loss at iteration 830 : 0.0001276362600037828
Loss at iteration 840 : 0.0002390966546954587
Loss at iteration 850 : 0.000531670288182795
Loss at iteration 860 : 0.0019589648582041264
Loss at iteration 870 : 0.0016601074021309614
Loss at iteration 880 : 0.00014170745271258056
Loss at iteration 890 : 0.00013363792095333338
Loss at iteration 900 : 0.00043441326124593616
Loss at iteration 910 : 0.0015142906922847033
Loss at iteration 920 : 0.000464314769487828
Loss at iteration 930 : 0.00017643789760768414
Loss at iteration 940 : 0.0010583647526800632
Loss at iteration 950 : 0.0004346148925833404
Loss at iteration 960 : 0.00025512126740068197
Loss at iteration 970 : 0.00020857280469499528
Loss at iteration 980 : 0.00016206243890337646
Loss at iteration 990 : 0.00012000963761238381
Loss at iteration 1000 : 0.005422921851277351
Loss at iteration 1010 : 0.002718577394261956
Loss at iteration 1020 : 0.000546205963473767
Loss at iteration 1030 : 0.00035915058106184006
Loss at iteration 1040 : 0.0027323802933096886
Loss at iteration 1050 : 0.002449059160426259
Loss at iteration 1060 : 0.000744961726013571
Loss at iteration 1070 : 0.00020108827447984368
Loss at iteration 1080 : 0.0006478169816546142
Loss at iteration 1090 : 0.0003870923537760973
Loss at iteration 1100 : 0.0004758412833325565
Loss at iteration 1110 : 0.0004742815508507192
Loss at iteration 1120 : 0.004085784777998924
Loss at iteration 1130 : 0.0006646411493420601
Loss at iteration 1140 : 0.0026729509700089693
Loss at iteration 1150 : 0.002055911812931299
Loss at iteration 1160 : 0.00025237275986000896
Loss at iteration 1170 : 0.0025887296069413424
Loss at iteration 1180 : 8.530375635018572e-05
Loss at iteration 1190 : 0.003238400211557746
Loss at iteration 1200 : 0.001811444410122931
Loss at iteration 1210 : 0.007059767376631498
Loss at iteration 1220 : 0.0008663844782859087
Loss at iteration 1230 : 6.823535659350455e-05
Loss at iteration 1240 : 0.0005745832459069788
Loss at iteration 1250 : 0.003919518552720547
Loss at iteration 1260 : 0.0003368011093698442
Loss at iteration 1270 : 0.002812794176861644
Loss at iteration 1280 : 0.0007051347638480365
Loss at iteration 1290 : 0.0001356073044007644
Loss at iteration 1300 : 0.00012164055078756064
Loss at iteration 1310 : 0.0002786790137179196
Loss at iteration 1320 : 0.0006255448097363114
Loss at iteration 1330 : 0.00041668565245345235
Loss at iteration 1340 : 6.245018448680639e-05
Loss at iteration 1350 : 0.00011421594535931945
Loss at iteration 1360 : 0.00019670635811053216
Loss at iteration 1370 : 0.00017876304627861828
Loss at iteration 1380 : 0.003221044084057212
Loss at iteration 1390 : 0.00018666929099708796
Loss at iteration 1400 : 0.00013052672147750854
Loss at iteration 1410 : 0.001470423536375165
Loss at iteration 1420 : 0.00139577966183424
Loss at iteration 1430 : 0.0013279854319989681
Loss at iteration 1440 : 0.00012264164979569614
Loss at iteration 1450 : 0.0034765638411045074
Loss at iteration 1460 : 8.814891043584794e-05
Loss at iteration 1470 : 0.006482979748398066
Loss at iteration 1480 : 0.00041885138489305973
Loss at iteration 1490 : 0.00018516182899475098
Loss at iteration 1500 : 0.0004455178859643638
Loss at iteration 1510 : 9.775507351150736e-05
Loss at iteration 1520 : 0.00025268548051826656
Loss at iteration 1530 : 4.550784797174856e-05
Loss at iteration 1540 : 0.0007258861442096531
Loss at iteration 1550 : 0.0018564413767307997
Loss at iteration 1560 : 0.00011585141328396276
Loss at iteration 1570 : 0.0017827018164098263
Loss at iteration 1580 : 0.004032776691019535
Loss at iteration 1590 : 0.002066215965896845
Loss at iteration 1600 : 0.00048311316641047597
Loss at iteration 1610 : 0.0001890490239020437
Loss at iteration 1620 : 0.0007422780618071556
Loss at iteration 1630 : 0.00034159424831159413
Loss at iteration 1640 : 7.360719610005617e-05
Loss at iteration 1650 : 0.00029096592334099114
Loss at iteration 1660 : 0.0013210095930844545
Loss at iteration 1670 : 0.0001490949362050742
Loss at iteration 1680 : 0.0016439276514574885
Loss at iteration 1690 : 0.000180643008206971
Loss at iteration 1700 : 0.003905172925442457
Loss at iteration 1710 : 0.0014435544144362211
Loss at iteration 1720 : 0.00040895797428674996
Loss at iteration 1730 : 0.0007748538628220558
Loss at iteration 1740 : 0.00016832654364407063
Loss at iteration 1750 : 0.002453584922477603
The SSIM Value is: 0.9872061702123297
The PSNR Value is: 46.83424029371287
the highest SSIM value is: 46.83424029371287
the epoch is: 142
Loss at iteration 10 : 0.00010003570059780031
Loss at iteration 20 : 0.00038562307599931955
Loss at iteration 30 : 0.0004886699025519192
Loss at iteration 40 : 0.00013326610496733338
Loss at iteration 50 : 0.0002357825287617743
Loss at iteration 60 : 0.00043702268158085644
Loss at iteration 70 : 0.00016136406338773668
Loss at iteration 80 : 0.0013782328460365534
Loss at iteration 90 : 0.00293544284068048
Loss at iteration 100 : 0.0002635678101796657
Loss at iteration 110 : 0.0003139961918350309
Loss at iteration 120 : 0.00010978950740536675
Loss at iteration 130 : 0.0015771313337609172
Loss at iteration 140 : 0.0003520793397910893
Loss at iteration 150 : 0.00037155678728595376
Loss at iteration 160 : 0.0025665396824479103
Loss at iteration 170 : 9.518473234493285e-05
Loss at iteration 180 : 0.0004927378613501787
Loss at iteration 190 : 0.00014180892321746796
Loss at iteration 200 : 0.0005811512819491327
Loss at iteration 210 : 0.00038463500095531344
Loss at iteration 220 : 0.00011584128515096381
Loss at iteration 230 : 0.0005600254517048597
Loss at iteration 240 : 0.0013111906591802835
Loss at iteration 250 : 0.003970531281083822
Loss at iteration 260 : 0.0003290062304586172
Loss at iteration 270 : 0.0006076417630538344
Loss at iteration 280 : 0.0017616201657801867
Loss at iteration 290 : 0.00017053844931069762
Loss at iteration 300 : 0.0007464936934411526
Loss at iteration 310 : 0.00590092595666647
Loss at iteration 320 : 0.0004424121871124953
Loss at iteration 330 : 0.0008442233083769679
Loss at iteration 340 : 7.390004611806944e-05
Loss at iteration 350 : 0.00013661215780302882
Loss at iteration 360 : 0.0037996345199644566
Loss at iteration 370 : 0.00046117647434584796
Loss at iteration 380 : 0.00034733006032183766
Loss at iteration 390 : 0.0002558195556048304
Loss at iteration 400 : 0.002559235319495201
Loss at iteration 410 : 8.27148396638222e-05
Loss at iteration 420 : 0.00017699904856272042
Loss at iteration 430 : 0.0030138990841805935
Loss at iteration 440 : 0.0011235290439799428
Loss at iteration 450 : 0.0004450228007044643
Loss at iteration 460 : 0.0007173259509727359
Loss at iteration 470 : 0.00013664596190210432
Loss at iteration 480 : 0.0029700472950935364
Loss at iteration 490 : 0.000526625313796103
Loss at iteration 500 : 0.0009461783338338137
Loss at iteration 510 : 0.0011327310930937529
Loss at iteration 520 : 0.0004394740972202271
Loss at iteration 530 : 0.00013071871944703162
Loss at iteration 540 : 9.61484620347619e-05
Loss at iteration 550 : 0.0005765393143519759
Loss at iteration 560 : 0.0026330016553401947
Loss at iteration 570 : 0.00016283444711007178
Loss at iteration 580 : 0.0005365147371776402
Loss at iteration 590 : 0.0006013246602378786
Loss at iteration 600 : 0.00018289998115506023
Loss at iteration 610 : 0.0003971808182541281
Loss at iteration 620 : 0.0016821683384478092
Loss at iteration 630 : 0.00010414714051876217
Loss at iteration 640 : 0.0002601580345071852
Loss at iteration 650 : 0.00043599747004918754
Loss at iteration 660 : 0.003394238417968154
Loss at iteration 670 : 0.002134524518623948
Loss at iteration 680 : 0.00042431391193531454
Loss at iteration 690 : 0.0001305557379964739
Loss at iteration 700 : 0.005004453472793102
Loss at iteration 710 : 0.00022841495228931308
Loss at iteration 720 : 0.0003459647996351123
Loss at iteration 730 : 0.0005880186799913645
Loss at iteration 740 : 0.0001373926643282175
Loss at iteration 750 : 0.00026361140771768987
Loss at iteration 760 : 0.0004700010467786342
Loss at iteration 770 : 0.00010733936505857855
Loss at iteration 780 : 0.0003040329902432859
Loss at iteration 790 : 0.0006101069157011807
Loss at iteration 800 : 0.000721093500033021
Loss at iteration 810 : 9.065635094884783e-05
Loss at iteration 820 : 0.002767861820757389
Loss at iteration 830 : 6.875270628370345e-05
Loss at iteration 840 : 0.00017847746494226158
Loss at iteration 850 : 0.00039625720819458365
Loss at iteration 860 : 0.0006296882638707757
Loss at iteration 870 : 7.009500404819846e-05
Loss at iteration 880 : 0.0020783902145922184
Loss at iteration 890 : 0.00012262232485227287
Loss at iteration 900 : 0.00019272032659500837
Loss at iteration 910 : 0.003751196898519993
Loss at iteration 920 : 0.00035114469937980175
Loss at iteration 930 : 0.0015120458556339145
Loss at iteration 940 : 0.002133822301402688
Loss at iteration 950 : 0.00010655450751073658
Loss at iteration 960 : 0.00025050516705960035
Loss at iteration 970 : 0.00017247165669687092
Loss at iteration 980 : 0.00030036139651201665
Loss at iteration 990 : 0.00022792279196437448
Loss at iteration 1000 : 0.0024346238933503628
Loss at iteration 1010 : 0.0005396248307079077
Loss at iteration 1020 : 0.00010743041639216244
Loss at iteration 1030 : 7.596854266012087e-05
Loss at iteration 1040 : 0.0017703925259411335
Loss at iteration 1050 : 0.0010929300915449858
Loss at iteration 1060 : 0.0004727683844976127
Loss at iteration 1070 : 0.00014631336671300232
Loss at iteration 1080 : 0.005634072702378035
Loss at iteration 1090 : 0.0058437734842300415
Loss at iteration 1100 : 0.001194963464513421
Loss at iteration 1110 : 0.00033701749634929
Loss at iteration 1120 : 0.0018778599333018064
Loss at iteration 1130 : 0.0008682311745360494
Loss at iteration 1140 : 0.00012273815809749067
Loss at iteration 1150 : 0.00019630468159448355
Loss at iteration 1160 : 0.0008763172663748264
Loss at iteration 1170 : 6.188829866005108e-05
Loss at iteration 1180 : 0.0009003864252008498
Loss at iteration 1190 : 0.0022056710440665483
Loss at iteration 1200 : 0.0007024200749583542
Loss at iteration 1210 : 9.788593888515607e-05
Loss at iteration 1220 : 0.00015472275845240802
Loss at iteration 1230 : 0.003591755870729685
Loss at iteration 1240 : 0.003501173807308078
Loss at iteration 1250 : 0.00037980792694725096
Loss at iteration 1260 : 4.2016527004307136e-05
Loss at iteration 1270 : 0.00010519979696255177
Loss at iteration 1280 : 0.007846176624298096
Loss at iteration 1290 : 0.0009918115101754665
Loss at iteration 1300 : 0.000382494181394577
Loss at iteration 1310 : 0.00014135618403088301
Loss at iteration 1320 : 0.000147487226058729
Loss at iteration 1330 : 0.0007913814624771476
Loss at iteration 1340 : 0.0010489706182852387
Loss at iteration 1350 : 0.0009638144401833415
Loss at iteration 1360 : 0.004299170337617397
Loss at iteration 1370 : 0.00017326153465546668
Loss at iteration 1380 : 8.818117930786684e-05
Loss at iteration 1390 : 5.246017826721072e-05
Loss at iteration 1400 : 0.0002822835522238165
Loss at iteration 1410 : 0.00028975680470466614
Loss at iteration 1420 : 0.00092186318943277
Loss at iteration 1430 : 0.0002543740556575358
Loss at iteration 1440 : 0.00018755948985926807
Loss at iteration 1450 : 0.0013082455843687057
Loss at iteration 1460 : 0.000566834700293839
Loss at iteration 1470 : 5.090505874250084e-05
Loss at iteration 1480 : 0.00037762499414384365
Loss at iteration 1490 : 6.268761353567243e-05
Loss at iteration 1500 : 0.00042473251232877374
Loss at iteration 1510 : 0.0017832485027611256
Loss at iteration 1520 : 0.00014009998994879425
Loss at iteration 1530 : 0.0003227067063562572
Loss at iteration 1540 : 0.0003569834225345403
Loss at iteration 1550 : 0.0005411101155914366
Loss at iteration 1560 : 7.557091885246336e-05
Loss at iteration 1570 : 0.004031838849186897
Loss at iteration 1580 : 0.0002407647843938321
Loss at iteration 1590 : 0.00448859017342329
Loss at iteration 1600 : 0.00042527663754299283
Loss at iteration 1610 : 0.00035567773738875985
Loss at iteration 1620 : 0.00011178151180502027
Loss at iteration 1630 : 0.0027655628509819508
Loss at iteration 1640 : 0.00022662346600554883
Loss at iteration 1650 : 0.00011118210386484861
Loss at iteration 1660 : 0.00031129291164688766
Loss at iteration 1670 : 0.0022541522048413754
Loss at iteration 1680 : 0.0002814296749420464
Loss at iteration 1690 : 0.001957349479198456
Loss at iteration 1700 : 0.00011826171248685569
Loss at iteration 1710 : 0.00021379641839303076
Loss at iteration 1720 : 7.021633791737258e-05
Loss at iteration 1730 : 0.000604906992521137
Loss at iteration 1740 : 0.00021835029474459589
Loss at iteration 1750 : 0.000936551601625979
The SSIM Value is: 0.9811491349195068
The PSNR Value is: 46.43483264645816
the epoch is: 143
Loss at iteration 10 : 0.0012275438057258725
Loss at iteration 20 : 5.748778494307771e-05
Loss at iteration 30 : 0.00014660076703876257
Loss at iteration 40 : 0.00016966063412837684
Loss at iteration 50 : 0.0010402984917163849
Loss at iteration 60 : 0.0006074131233617663
Loss at iteration 70 : 0.0009464872418902814
Loss at iteration 80 : 0.000603728462010622
Loss at iteration 90 : 0.00045058398973196745
Loss at iteration 100 : 0.00018500641454011202
Loss at iteration 110 : 0.0002212255640188232
Loss at iteration 120 : 0.00032912901951931417
Loss at iteration 130 : 0.0003404323651921004
Loss at iteration 140 : 0.000520314322784543
Loss at iteration 150 : 0.0011657517170533538
Loss at iteration 160 : 0.00014452841423917562
Loss at iteration 170 : 0.00020520991529338062
Loss at iteration 180 : 0.00041643797885626554
Loss at iteration 190 : 0.002997651696205139
Loss at iteration 200 : 0.0001856762683019042
Loss at iteration 210 : 0.00023701941245235503
Loss at iteration 220 : 0.001492036273702979
Loss at iteration 230 : 0.000262065208517015
Loss at iteration 240 : 0.00015173615247476846
Loss at iteration 250 : 9.956079156836495e-05
Loss at iteration 260 : 0.002755868947133422
Loss at iteration 270 : 0.0004159333766438067
Loss at iteration 280 : 0.00014952316996641457
Loss at iteration 290 : 0.0007861790945753455
Loss at iteration 300 : 0.0004769395454786718
Loss at iteration 310 : 0.00043769285548478365
Loss at iteration 320 : 0.0036636728327721357
Loss at iteration 330 : 0.00010844085045391694
Loss at iteration 340 : 0.0005303838988766074
Loss at iteration 350 : 0.001602236763574183
Loss at iteration 360 : 0.002801582682877779
Loss at iteration 370 : 0.0002674564311746508
Loss at iteration 380 : 0.00030556373530998826
Loss at iteration 390 : 0.00029445922700688243
Loss at iteration 400 : 0.0007236006204038858
Loss at iteration 410 : 0.0002170219086110592
Loss at iteration 420 : 0.0006288402946665883
Loss at iteration 430 : 0.00010344017937313765
Loss at iteration 440 : 0.00021677360928151757
Loss at iteration 450 : 0.00046771130291745067
Loss at iteration 460 : 9.511793905403465e-05
Loss at iteration 470 : 0.0061226096004247665
Loss at iteration 480 : 0.008619267493486404
Loss at iteration 490 : 0.0007339316653087735
Loss at iteration 500 : 0.0063584656454622746
Loss at iteration 510 : 0.0008551805512979627
Loss at iteration 520 : 0.0002537893014959991
Loss at iteration 530 : 0.00036541925510391593
Loss at iteration 540 : 0.00010148136789212003
Loss at iteration 550 : 0.001214455347508192
Loss at iteration 560 : 0.0028159362263977528
Loss at iteration 570 : 0.0025112570729106665
Loss at iteration 580 : 0.00014865369303151965
Loss at iteration 590 : 0.00018224932136945426
Loss at iteration 600 : 0.003783825086429715
Loss at iteration 610 : 0.0015500521985813975
Loss at iteration 620 : 0.005041247699409723
Loss at iteration 630 : 0.002026027301326394
Loss at iteration 640 : 0.0007244202424772084
Loss at iteration 650 : 0.0019772015511989594
Loss at iteration 660 : 0.001402461901307106
Loss at iteration 670 : 0.002199800219386816
Loss at iteration 680 : 8.717065793462098e-05
Loss at iteration 690 : 0.0006356921512633562
Loss at iteration 700 : 0.00018916997942142189
Loss at iteration 710 : 0.0001309658691752702
Loss at iteration 720 : 3.483981345198117e-05
Loss at iteration 730 : 0.00318311620503664
Loss at iteration 740 : 0.00010325467155780643
Loss at iteration 750 : 0.0009891430381685495
Loss at iteration 760 : 0.000972962356172502
Loss at iteration 770 : 0.00015499230357818305
Loss at iteration 780 : 9.494835103396326e-05
Loss at iteration 790 : 0.000460529001429677
Loss at iteration 800 : 0.0001695703249424696
Loss at iteration 810 : 0.000227574331802316
Loss at iteration 820 : 0.00028474951977841556
Loss at iteration 830 : 0.00010921947978204116
Loss at iteration 840 : 0.00027952162781730294
Loss at iteration 850 : 0.0005596614792011678
Loss at iteration 860 : 0.00022245892614591867
Loss at iteration 870 : 0.00010033702710643411
Loss at iteration 880 : 0.0029832376167178154
Loss at iteration 890 : 0.00011402974632801488
Loss at iteration 900 : 0.0022106000687927008
Loss at iteration 910 : 0.00023920275270938873
Loss at iteration 920 : 0.00013937108451500535
Loss at iteration 930 : 0.000100663339253515
Loss at iteration 940 : 0.0019942820072174072
Loss at iteration 950 : 0.0002471920452080667
Loss at iteration 960 : 0.0009208811679854989
Loss at iteration 970 : 0.00033357267966493964
Loss at iteration 980 : 0.00014061789261177182
Loss at iteration 990 : 0.00024495067191310227
Loss at iteration 1000 : 0.0022514660377055407
Loss at iteration 1010 : 0.002026959788054228
Loss at iteration 1020 : 0.0003847450134344399
Loss at iteration 1030 : 0.00019151972082909197
Loss at iteration 1040 : 0.00016493373550474644
Loss at iteration 1050 : 0.0004036175669170916
Loss at iteration 1060 : 0.0004372396506369114
Loss at iteration 1070 : 0.0011660257587209344
Loss at iteration 1080 : 0.001914008753374219
Loss at iteration 1090 : 0.00011798363266279921
Loss at iteration 1100 : 0.0002169363433495164
Loss at iteration 1110 : 0.0008170305518433452
Loss at iteration 1120 : 0.004169294610619545
Loss at iteration 1130 : 0.001627335324883461
Loss at iteration 1140 : 0.0034221941605210304
Loss at iteration 1150 : 0.000869615119881928
Loss at iteration 1160 : 0.00026432686718180776
Loss at iteration 1170 : 0.0002103472943417728
Loss at iteration 1180 : 0.0009447485208511353
Loss at iteration 1190 : 0.00020245747873559594
Loss at iteration 1200 : 0.0018130351090803742
Loss at iteration 1210 : 0.00014041358372196555
Loss at iteration 1220 : 0.0009891821537166834
Loss at iteration 1230 : 0.00011392205487936735
Loss at iteration 1240 : 9.57394004217349e-05
Loss at iteration 1250 : 0.005148818716406822
Loss at iteration 1260 : 0.0005393673782236874
Loss at iteration 1270 : 0.0024089838843792677
Loss at iteration 1280 : 0.00023710746609140188
Loss at iteration 1290 : 0.0002081663260469213
Loss at iteration 1300 : 8.606389747001231e-05
Loss at iteration 1310 : 0.0016424063360318542
Loss at iteration 1320 : 0.0022083965595811605
Loss at iteration 1330 : 0.0006962213665246964
Loss at iteration 1340 : 0.00028503371868282557
Loss at iteration 1350 : 0.0019947169348597527
Loss at iteration 1360 : 0.00017368921544402838
Loss at iteration 1370 : 0.00036053231451660395
Loss at iteration 1380 : 0.0006055739358998835
Loss at iteration 1390 : 8.910023461794481e-05
Loss at iteration 1400 : 0.002615059958770871
Loss at iteration 1410 : 0.00020668611978180707
Loss at iteration 1420 : 0.0002925333974417299
Loss at iteration 1430 : 0.0004042930086143315
Loss at iteration 1440 : 0.00012108471855754033
Loss at iteration 1450 : 0.00010954264143947512
Loss at iteration 1460 : 0.0012373747304081917
Loss at iteration 1470 : 0.0005093810032121837
Loss at iteration 1480 : 9.817023237701505e-05
Loss at iteration 1490 : 0.0007025736849755049
Loss at iteration 1500 : 0.0004233574727550149
Loss at iteration 1510 : 0.00015047439956106246
Loss at iteration 1520 : 0.0002479524118825793
Loss at iteration 1530 : 0.0008952264906838536
Loss at iteration 1540 : 0.0007715548272244632
Loss at iteration 1550 : 0.0002990439534187317
Loss at iteration 1560 : 0.00031963310902938247
Loss at iteration 1570 : 0.00207523419521749
Loss at iteration 1580 : 0.0001289464271394536
Loss at iteration 1590 : 0.0048133619129657745
Loss at iteration 1600 : 0.0003147634561173618
Loss at iteration 1610 : 0.0003478337894193828
Loss at iteration 1620 : 0.0007243354339152575
Loss at iteration 1630 : 8.477186929667369e-05
Loss at iteration 1640 : 0.0038962890394032
Loss at iteration 1650 : 0.0010119472863152623
Loss at iteration 1660 : 9.778044477570802e-05
Loss at iteration 1670 : 0.0025421602185815573
Loss at iteration 1680 : 0.007910370826721191
Loss at iteration 1690 : 7.959052891237661e-05
Loss at iteration 1700 : 0.0016624073032289743
Loss at iteration 1710 : 0.0012342467671260238
Loss at iteration 1720 : 0.0032970246393233538
Loss at iteration 1730 : 0.0011659187730401754
Loss at iteration 1740 : 0.00020677255815826356
Loss at iteration 1750 : 0.00014350430865306407
The SSIM Value is: 0.9804512518355499
The PSNR Value is: 46.62970854427321
the epoch is: 144
Loss at iteration 10 : 0.00019130820874124765
Loss at iteration 20 : 0.0027247730176895857
Loss at iteration 30 : 0.0001540149823995307
Loss at iteration 40 : 0.00043142077629454434
Loss at iteration 50 : 0.00021359670790843666
Loss at iteration 60 : 0.001917943824082613
Loss at iteration 70 : 0.0030063255690038204
Loss at iteration 80 : 0.0006475115660578012
Loss at iteration 90 : 0.00046109186951071024
Loss at iteration 100 : 9.79047836153768e-05
Loss at iteration 110 : 9.230435534846038e-05
Loss at iteration 120 : 0.0006318673258647323
Loss at iteration 130 : 0.00039595598354935646
Loss at iteration 140 : 0.0003197647456545383
Loss at iteration 150 : 7.74002619436942e-05
Loss at iteration 160 : 0.00020398020569700748
Loss at iteration 170 : 0.00030729343416169286
Loss at iteration 180 : 0.0047264061868190765
Loss at iteration 190 : 0.001634123269468546
Loss at iteration 200 : 0.00019938143668696284
Loss at iteration 210 : 0.0005759949563071132
Loss at iteration 220 : 0.0033644309733062983
Loss at iteration 230 : 0.003910390194505453
Loss at iteration 240 : 0.0006741321994923055
Loss at iteration 250 : 0.0002005838177865371
Loss at iteration 260 : 0.00019642540428321809
Loss at iteration 270 : 4.763463221024722e-05
Loss at iteration 280 : 0.0005182740860618651
Loss at iteration 290 : 0.0002730859850998968
Loss at iteration 300 : 0.003231110516935587
Loss at iteration 310 : 3.9304650272242725e-05
Loss at iteration 320 : 0.00030251621501520276
Loss at iteration 330 : 0.00018745001580100507
Loss at iteration 340 : 0.003949225880205631
Loss at iteration 350 : 0.00010829155507963151
Loss at iteration 360 : 0.0009709470323286951
Loss at iteration 370 : 0.0004984790575690567
Loss at iteration 380 : 0.0010705891763791442
Loss at iteration 390 : 0.004078247584402561
Loss at iteration 400 : 0.0031706071458756924
Loss at iteration 410 : 0.00016224074352066964
Loss at iteration 420 : 0.003142436733469367
Loss at iteration 430 : 0.00012815938680432737
Loss at iteration 440 : 0.000482228584587574
Loss at iteration 450 : 6.308600131887943e-05
Loss at iteration 460 : 0.0011576799442991614
Loss at iteration 470 : 0.0004951262380927801
Loss at iteration 480 : 0.0001639118418097496
Loss at iteration 490 : 0.0011346563696861267
Loss at iteration 500 : 6.583135109394789e-05
Loss at iteration 510 : 0.0005204088520258665
Loss at iteration 520 : 0.000494159001391381
Loss at iteration 530 : 0.0026346114464104176
Loss at iteration 540 : 0.0012033170787617564
Loss at iteration 550 : 0.0013573258183896542
Loss at iteration 560 : 0.0021386740263551474
Loss at iteration 570 : 6.787799065932631e-05
Loss at iteration 580 : 0.00013818952720612288
Loss at iteration 590 : 0.00019601287203840911
Loss at iteration 600 : 0.00015258885105140507
Loss at iteration 610 : 0.005861096549779177
Loss at iteration 620 : 8.01238275016658e-05
Loss at iteration 630 : 0.0003710305318236351
Loss at iteration 640 : 0.0001925794203998521
Loss at iteration 650 : 0.0023048098664730787
Loss at iteration 660 : 0.0005863991100341082
Loss at iteration 670 : 0.00029353416175581515
Loss at iteration 680 : 0.006565104238688946
Loss at iteration 690 : 0.0021641526836901903
Loss at iteration 700 : 0.0006872382364235818
Loss at iteration 710 : 0.00014059391105547547
Loss at iteration 720 : 0.001951535465195775
Loss at iteration 730 : 0.0011193203972652555
Loss at iteration 740 : 0.0016678286483511329
Loss at iteration 750 : 0.002749064937233925
Loss at iteration 760 : 0.00030777184292674065
Loss at iteration 770 : 5.867498111911118e-05
Loss at iteration 780 : 0.0008056521182879806
Loss at iteration 790 : 0.000640435959212482
Loss at iteration 800 : 0.0034757035318762064
Loss at iteration 810 : 0.002463033888489008
Loss at iteration 820 : 0.0011026968713849783
Loss at iteration 830 : 0.0009733336046338081
Loss at iteration 840 : 0.00022938809706829488
Loss at iteration 850 : 0.005773059092462063
Loss at iteration 860 : 0.0006454449612647295
Loss at iteration 870 : 0.0032309144735336304
Loss at iteration 880 : 0.00043381028808653355
Loss at iteration 890 : 5.920914190937765e-05
Loss at iteration 900 : 0.00023547204909846187
Loss at iteration 910 : 0.00011697378795361146
Loss at iteration 920 : 0.00021055042452644557
Loss at iteration 930 : 0.0008847459102980793
Loss at iteration 940 : 0.0009670588769949973
Loss at iteration 950 : 0.00022842289763502777
Loss at iteration 960 : 0.0013251514174044132
Loss at iteration 970 : 0.00046444282634183764
Loss at iteration 980 : 0.0001975549675989896
Loss at iteration 990 : 6.841023423476145e-05
Loss at iteration 1000 : 0.00014858265058137476
Loss at iteration 1010 : 7.518297934439033e-05
Loss at iteration 1020 : 0.0009765410795807838
Loss at iteration 1030 : 7.506347901653498e-05
Loss at iteration 1040 : 7.968577119754627e-05
Loss at iteration 1050 : 0.0012485218467190862
Loss at iteration 1060 : 0.003351951017975807
Loss at iteration 1070 : 0.003403814509510994
Loss at iteration 1080 : 0.0013568432768806815
Loss at iteration 1090 : 0.0006383683066815138
Loss at iteration 1100 : 0.0035227437037974596
Loss at iteration 1110 : 0.004103964194655418
Loss at iteration 1120 : 0.004462660290300846
Loss at iteration 1130 : 5.670747486874461e-05
Loss at iteration 1140 : 0.00041923654498532414
Loss at iteration 1150 : 0.00013684359146282077
Loss at iteration 1160 : 0.0008158632554113865
Loss at iteration 1170 : 0.0026409009005874395
Loss at iteration 1180 : 0.00031075641163624823
Loss at iteration 1190 : 0.0029460499063134193
Loss at iteration 1200 : 0.00042639239109121263
Loss at iteration 1210 : 0.0004353393742348999
Loss at iteration 1220 : 0.0014198825228959322
Loss at iteration 1230 : 0.0002353499294258654
Loss at iteration 1240 : 0.00015956585411913693
Loss at iteration 1250 : 0.0001836614974308759
Loss at iteration 1260 : 8.113460353342816e-05
Loss at iteration 1270 : 0.00035994069185107946
Loss at iteration 1280 : 0.0004704318998847157
Loss at iteration 1290 : 0.00023076109937392175
Loss at iteration 1300 : 0.003863483900204301
Loss at iteration 1310 : 0.00012345088180154562
Loss at iteration 1320 : 0.0015303216641768813
Loss at iteration 1330 : 3.937857400160283e-05
Loss at iteration 1340 : 5.396758206188679e-05
Loss at iteration 1350 : 0.0009609833941794932
Loss at iteration 1360 : 0.0005428500007838011
Loss at iteration 1370 : 0.00035666083567775786
Loss at iteration 1380 : 0.0014741435879841447
Loss at iteration 1390 : 0.0040588825941085815
Loss at iteration 1400 : 0.00026989163598045707
Loss at iteration 1410 : 0.00012823796714656055
Loss at iteration 1420 : 0.0007159782107919455
Loss at iteration 1430 : 0.001373092643916607
Loss at iteration 1440 : 0.00033588887890800834
Loss at iteration 1450 : 0.00030808692099526525
Loss at iteration 1460 : 0.0004452602588571608
Loss at iteration 1470 : 0.0035717461723834276
Loss at iteration 1480 : 0.00011469835590105504
Loss at iteration 1490 : 0.00296764075756073
Loss at iteration 1500 : 0.00010369917436037213
Loss at iteration 1510 : 0.000162624754011631
Loss at iteration 1520 : 0.0018807470332831144
Loss at iteration 1530 : 0.0015366298612207174
Loss at iteration 1540 : 0.00010858948371605948
Loss at iteration 1550 : 0.00028035478317178786
Loss at iteration 1560 : 0.0004004812508355826
Loss at iteration 1570 : 0.0025069559924304485
Loss at iteration 1580 : 9.12292962311767e-05
Loss at iteration 1590 : 0.00022741188877262175
Loss at iteration 1600 : 0.00014333042781800032
Loss at iteration 1610 : 0.00012702232925221324
Loss at iteration 1620 : 0.000483123236335814
Loss at iteration 1630 : 0.0003062268951907754
Loss at iteration 1640 : 0.0011736078886315227
Loss at iteration 1650 : 0.004360852297395468
Loss at iteration 1660 : 0.00019742088625207543
Loss at iteration 1670 : 0.006003931630402803
Loss at iteration 1680 : 0.00013312259397935122
Loss at iteration 1690 : 0.001332863001152873
Loss at iteration 1700 : 0.0009146643569692969
Loss at iteration 1710 : 0.0001242937723873183
Loss at iteration 1720 : 0.0005066419253125787
Loss at iteration 1730 : 0.0007620962569490075
Loss at iteration 1740 : 0.0008227847865782678
Loss at iteration 1750 : 0.002072820207104087
The SSIM Value is: 0.9848526038787438
The PSNR Value is: 46.504637774917
the epoch is: 145
Loss at iteration 10 : 0.0004989575245417655
Loss at iteration 20 : 0.0003850095672532916
Loss at iteration 30 : 0.0008142737788148224
Loss at iteration 40 : 0.0001612992346053943
Loss at iteration 50 : 0.0002023524430114776
Loss at iteration 60 : 0.000296929880278185
Loss at iteration 70 : 0.0005377361667342484
Loss at iteration 80 : 0.00024640996707603335
Loss at iteration 90 : 0.0003859309945255518
Loss at iteration 100 : 0.0003053726104553789
Loss at iteration 110 : 0.0007954764296300709
Loss at iteration 120 : 0.002370279747992754
Loss at iteration 130 : 0.0004035716410726309
Loss at iteration 140 : 0.00030013651121407747
Loss at iteration 150 : 0.00025999793433584273
Loss at iteration 160 : 0.00041890284046530724
Loss at iteration 170 : 0.0004548284341581166
Loss at iteration 180 : 0.0003252153692301363
Loss at iteration 190 : 0.0028956022579222918
Loss at iteration 200 : 0.0010618044761940837
Loss at iteration 210 : 0.0019193531479686499
Loss at iteration 220 : 0.0005497030215337873
Loss at iteration 230 : 0.002538010710850358
Loss at iteration 240 : 0.00019102520309388638
Loss at iteration 250 : 0.0020379177294671535
Loss at iteration 260 : 0.000158345079398714
Loss at iteration 270 : 0.0002428973966743797
Loss at iteration 280 : 0.0026494888588786125
Loss at iteration 290 : 0.0017918411176651716
Loss at iteration 300 : 0.0030292985029518604
Loss at iteration 310 : 0.001185926841571927
Loss at iteration 320 : 0.00013453204883262515
Loss at iteration 330 : 0.00024533242685720325
Loss at iteration 340 : 0.0016499855555593967
Loss at iteration 350 : 0.00013559276703745127
Loss at iteration 360 : 0.0004487551632337272
Loss at iteration 370 : 0.0005043807905167341
Loss at iteration 380 : 0.0005292808637022972
Loss at iteration 390 : 5.832855822518468e-05
Loss at iteration 400 : 0.0004225748998578638
Loss at iteration 410 : 0.00034438498551025987
Loss at iteration 420 : 0.0008548418409191072
Loss at iteration 430 : 0.0011420686496421695
Loss at iteration 440 : 0.0005310416454449296
Loss at iteration 450 : 8.042632543947548e-05
Loss at iteration 460 : 0.0051189870573580265
Loss at iteration 470 : 0.001172926975414157
Loss at iteration 480 : 0.00010528587154112756
Loss at iteration 490 : 0.0030288766138255596
Loss at iteration 500 : 0.00040776137029752135
Loss at iteration 510 : 0.00010076713806483895
Loss at iteration 520 : 0.001757149351760745
Loss at iteration 530 : 0.0009405190357938409
Loss at iteration 540 : 0.00022519273625221103
Loss at iteration 550 : 0.0001771380048012361
Loss at iteration 560 : 0.0006289422744885087
Loss at iteration 570 : 7.32661719666794e-05
Loss at iteration 580 : 0.0002816375344991684
Loss at iteration 590 : 0.00015743235417176038
Loss at iteration 600 : 0.003324301680549979
Loss at iteration 610 : 7.167372677940875e-05
Loss at iteration 620 : 0.0004018896142952144
Loss at iteration 630 : 0.0007763250032439828
Loss at iteration 640 : 8.048725430853665e-05
Loss at iteration 650 : 0.00030074367532506585
Loss at iteration 660 : 0.0003342737618368119
Loss at iteration 670 : 0.00020583029254339635
Loss at iteration 680 : 0.0004506789264269173
Loss at iteration 690 : 0.0002800867659971118
Loss at iteration 700 : 0.00024408094759564847
Loss at iteration 710 : 0.0024640534538775682
Loss at iteration 720 : 0.00011284652282483876
Loss at iteration 730 : 0.0002611241361591965
Loss at iteration 740 : 0.00020597271213773638
Loss at iteration 750 : 0.0005593288224190474
Loss at iteration 760 : 0.0006362334825098515
Loss at iteration 770 : 0.0021983860060572624
Loss at iteration 780 : 5.212864198256284e-05
Loss at iteration 790 : 0.0033152408432215452
Loss at iteration 800 : 0.0027562095783650875
Loss at iteration 810 : 5.2115075959591195e-05
Loss at iteration 820 : 0.00021284123067744076
Loss at iteration 830 : 0.00014090465265326202
Loss at iteration 840 : 0.0001667602191446349
Loss at iteration 850 : 0.00027963859611190856
Loss at iteration 860 : 8.431270543951541e-05
Loss at iteration 870 : 0.0010691604111343622
Loss at iteration 880 : 0.0007873096619732678
Loss at iteration 890 : 0.000883038155734539
Loss at iteration 900 : 0.0002136116090696305
Loss at iteration 910 : 0.00014521570119541138
Loss at iteration 920 : 0.0005123154260218143
Loss at iteration 930 : 0.0005063817952759564
Loss at iteration 940 : 0.00035819486947730184
Loss at iteration 950 : 0.00036464835284277797
Loss at iteration 960 : 0.004347995389252901
Loss at iteration 970 : 0.0011861550156027079
Loss at iteration 980 : 0.00040178149356506765
Loss at iteration 990 : 0.0003399111737962812
Loss at iteration 1000 : 0.00046127219684422016
Loss at iteration 1010 : 0.0015203433576971292
Loss at iteration 1020 : 0.0012691507581621408
Loss at iteration 1030 : 0.00018291179731022567
Loss at iteration 1040 : 0.0009735342464409769
Loss at iteration 1050 : 0.000891914707608521
Loss at iteration 1060 : 0.00020220635633450001
Loss at iteration 1070 : 8.192828681785613e-05
Loss at iteration 1080 : 0.0006395389209501445
Loss at iteration 1090 : 0.0004549239529296756
Loss at iteration 1100 : 0.00011524336878210306
Loss at iteration 1110 : 0.0023834567982703447
Loss at iteration 1120 : 0.000432902539614588
Loss at iteration 1130 : 0.00015731569146737456
Loss at iteration 1140 : 9.426660108147189e-05
Loss at iteration 1150 : 0.0010364050976932049
Loss at iteration 1160 : 0.00012000745482509956
Loss at iteration 1170 : 0.0007228993345052004
Loss at iteration 1180 : 0.00017065378779079765
Loss at iteration 1190 : 0.003988160286098719
Loss at iteration 1200 : 0.0010316423140466213
Loss at iteration 1210 : 0.0014344893861562014
Loss at iteration 1220 : 0.00014092375931795686
Loss at iteration 1230 : 4.266799442120828e-05
Loss at iteration 1240 : 0.0020097787491977215
Loss at iteration 1250 : 0.0014417015481740236
Loss at iteration 1260 : 0.005422874353826046
Loss at iteration 1270 : 0.0002945464802905917
Loss at iteration 1280 : 0.00016157061327248812
Loss at iteration 1290 : 7.725289469817653e-05
Loss at iteration 1300 : 0.003136472776532173
Loss at iteration 1310 : 0.0001983018300961703
Loss at iteration 1320 : 7.536637713201344e-05
Loss at iteration 1330 : 0.0016572915483266115
Loss at iteration 1340 : 0.00401882641017437
Loss at iteration 1350 : 7.711006765021011e-05
Loss at iteration 1360 : 0.00010227671737084165
Loss at iteration 1370 : 0.0012325027491897345
Loss at iteration 1380 : 7.58069654693827e-05
Loss at iteration 1390 : 0.007585646118968725
Loss at iteration 1400 : 0.00018439453560858965
Loss at iteration 1410 : 3.11308067466598e-05
Loss at iteration 1420 : 0.00018119192100130022
Loss at iteration 1430 : 0.003001015866175294
Loss at iteration 1440 : 0.001564980368129909
Loss at iteration 1450 : 0.0024956318084150553
Loss at iteration 1460 : 0.0005237014847807586
Loss at iteration 1470 : 0.004571268800646067
Loss at iteration 1480 : 0.00021210078557487577
Loss at iteration 1490 : 0.00015045965847093612
Loss at iteration 1500 : 0.0005555740208365023
Loss at iteration 1510 : 0.0026934228371828794
Loss at iteration 1520 : 0.0001933104358613491
Loss at iteration 1530 : 0.00035145855508744717
Loss at iteration 1540 : 0.0023849764838814735
Loss at iteration 1550 : 0.004644267726689577
Loss at iteration 1560 : 0.0009582251077517867
Loss at iteration 1570 : 0.00014532473869621754
Loss at iteration 1580 : 0.00026218401035293937
Loss at iteration 1590 : 0.00013042593491263688
Loss at iteration 1600 : 0.00022755833924748003
Loss at iteration 1610 : 0.0001798735756892711
Loss at iteration 1620 : 0.00015009297931101173
Loss at iteration 1630 : 0.00018428987823426723
Loss at iteration 1640 : 0.0012314332416281104
Loss at iteration 1650 : 6.177744944579899e-05
Loss at iteration 1660 : 0.00028532868600450456
Loss at iteration 1670 : 0.0005741891218349338
Loss at iteration 1680 : 0.00016541041259188205
Loss at iteration 1690 : 0.00046466808998957276
Loss at iteration 1700 : 0.00013381069584283978
Loss at iteration 1710 : 0.008472654968500137
Loss at iteration 1720 : 0.00032339710742235184
Loss at iteration 1730 : 0.0006637836922891438
Loss at iteration 1740 : 0.00029628619085997343
Loss at iteration 1750 : 5.8494457334745675e-05
The SSIM Value is: 0.9877284879463885
The PSNR Value is: 46.345910631087385
the epoch is: 146
Loss at iteration 10 : 0.005246678367257118
Loss at iteration 20 : 0.0005906572914682329
Loss at iteration 30 : 0.00021878773986827582
Loss at iteration 40 : 0.0010125093394890428
Loss at iteration 50 : 0.00019557402993086725
Loss at iteration 60 : 0.000354616844560951
Loss at iteration 70 : 0.00017846058472059667
Loss at iteration 80 : 0.00023803253134246916
Loss at iteration 90 : 0.0006365324952639639
Loss at iteration 100 : 0.0001398256717948243
Loss at iteration 110 : 0.0009565269574522972
Loss at iteration 120 : 0.0015244991518557072
Loss at iteration 130 : 0.0006455716211348772
Loss at iteration 140 : 3.754604404093698e-05
Loss at iteration 150 : 0.00020932446932420135
Loss at iteration 160 : 0.00011863946565426886
Loss at iteration 170 : 0.0008863126276992261
Loss at iteration 180 : 0.00017592021322343498
Loss at iteration 190 : 0.00567751657217741
Loss at iteration 200 : 0.00011332812573527917
Loss at iteration 210 : 0.00013096691691316664
Loss at iteration 220 : 0.00846010260283947
Loss at iteration 230 : 0.0025428158696740866
Loss at iteration 240 : 0.000372678303392604
Loss at iteration 250 : 0.0027947905473411083
Loss at iteration 260 : 0.00014587916666641831
Loss at iteration 270 : 0.00023176410468295217
Loss at iteration 280 : 0.000450262421509251
Loss at iteration 290 : 8.309151598950848e-05
Loss at iteration 300 : 0.0012885548640042543
Loss at iteration 310 : 0.0007854643044993281
Loss at iteration 320 : 0.0004504977841861546
Loss at iteration 330 : 9.76216106209904e-05
Loss at iteration 340 : 8.65889887791127e-05
Loss at iteration 350 : 0.000484996271552518
Loss at iteration 360 : 0.0033660107292234898
Loss at iteration 370 : 6.853704690001905e-05
Loss at iteration 380 : 0.000660947582218796
Loss at iteration 390 : 0.0016807051142677665
Loss at iteration 400 : 0.00010246780584566295
Loss at iteration 410 : 0.0001766053756000474
Loss at iteration 420 : 0.00025687532615847886
Loss at iteration 430 : 0.004093945026397705
Loss at iteration 440 : 0.0015886095352470875
Loss at iteration 450 : 0.0025490056723356247
Loss at iteration 460 : 0.0003881554293911904
Loss at iteration 470 : 0.0009621371864341199
Loss at iteration 480 : 9.151306585408747e-05
Loss at iteration 490 : 0.00015554678975604475
Loss at iteration 500 : 0.001624695723876357
Loss at iteration 510 : 0.0001876596943475306
Loss at iteration 520 : 0.00030492193764075637
Loss at iteration 530 : 0.004087516106665134
Loss at iteration 540 : 0.00020203467283863574
Loss at iteration 550 : 0.0002259602042613551
Loss at iteration 560 : 0.0032683596946299076
Loss at iteration 570 : 7.985614502103999e-05
Loss at iteration 580 : 0.0009981895564123988
Loss at iteration 590 : 0.0001366368669550866
Loss at iteration 600 : 0.002944094128906727
Loss at iteration 610 : 0.00029184779850766063
Loss at iteration 620 : 0.0007143184775486588
Loss at iteration 630 : 0.00025075263692997396
Loss at iteration 640 : 0.00015718978829681873
Loss at iteration 650 : 0.0034112082794308662
Loss at iteration 660 : 0.00013664120342582464
Loss at iteration 670 : 0.001660156180150807
Loss at iteration 680 : 0.0006148491520434618
Loss at iteration 690 : 0.0008123519364744425
Loss at iteration 700 : 0.0005714360740967095
Loss at iteration 710 : 0.0005306467646732926
Loss at iteration 720 : 0.00026443664683029056
Loss at iteration 730 : 0.00046482484322041273
Loss at iteration 740 : 0.000278963620075956
Loss at iteration 750 : 0.0005289815017022192
Loss at iteration 760 : 0.00013597210636362433
Loss at iteration 770 : 6.518790905829519e-05
Loss at iteration 780 : 0.0003907250356860459
Loss at iteration 790 : 0.00017125604790635407
Loss at iteration 800 : 0.0002964311861433089
Loss at iteration 810 : 0.0014872836181893945
Loss at iteration 820 : 0.0023550400510430336
Loss at iteration 830 : 0.00022687946329824626
Loss at iteration 840 : 0.00032084094709716737
Loss at iteration 850 : 0.0005040753167122602
Loss at iteration 860 : 0.00030936591792851686
Loss at iteration 870 : 0.0001897397160064429
Loss at iteration 880 : 0.00025279392139054835
Loss at iteration 890 : 0.0003739140520337969
Loss at iteration 900 : 0.0003506361972540617
Loss at iteration 910 : 5.599701762548648e-05
Loss at iteration 920 : 8.308807446155697e-05
Loss at iteration 930 : 0.0005071335472166538
Loss at iteration 940 : 0.0018446182366460562
Loss at iteration 950 : 0.004322666209191084
Loss at iteration 960 : 0.0015503678005188704
Loss at iteration 970 : 0.00027567159850150347
Loss at iteration 980 : 9.276947821490467e-05
Loss at iteration 990 : 0.0001224387960974127
Loss at iteration 1000 : 9.628098632674664e-05
Loss at iteration 1010 : 0.0008590823272243142
Loss at iteration 1020 : 0.007794543169438839
Loss at iteration 1030 : 0.00231350539252162
Loss at iteration 1040 : 0.0016273766523227096
Loss at iteration 1050 : 0.0021043126471340656
Loss at iteration 1060 : 0.0001675718231126666
Loss at iteration 1070 : 0.00018489515059627593
Loss at iteration 1080 : 0.00044152000918984413
Loss at iteration 1090 : 0.0008569100755266845
Loss at iteration 1100 : 0.0038177822716534138
Loss at iteration 1110 : 6.207182013895363e-05
Loss at iteration 1120 : 0.001224191626533866
Loss at iteration 1130 : 0.0008778052870184183
Loss at iteration 1140 : 0.0009743198752403259
Loss at iteration 1150 : 0.0001510370202595368
Loss at iteration 1160 : 8.220568997785449e-05
Loss at iteration 1170 : 0.0036500603891909122
Loss at iteration 1180 : 0.0001742952154017985
Loss at iteration 1190 : 0.00020204263273626566
Loss at iteration 1200 : 0.00021704702521674335
Loss at iteration 1210 : 0.0002380531223025173
Loss at iteration 1220 : 0.00015999586321413517
Loss at iteration 1230 : 0.0026906561106443405
Loss at iteration 1240 : 0.0017665568739175797
Loss at iteration 1250 : 0.0003508823865558952
Loss at iteration 1260 : 0.0001479734928580001
Loss at iteration 1270 : 0.0036500352434813976
Loss at iteration 1280 : 0.002109590684995055
Loss at iteration 1290 : 0.0001321790332440287
Loss at iteration 1300 : 8.545565651729703e-05
Loss at iteration 1310 : 0.00020199644495733082
Loss at iteration 1320 : 0.00044716845150105655
Loss at iteration 1330 : 0.0005935092340223491
Loss at iteration 1340 : 0.00016070799028966576
Loss at iteration 1350 : 7.263297447934747e-05
Loss at iteration 1360 : 0.00024143225164152682
Loss at iteration 1370 : 7.313712558243424e-05
Loss at iteration 1380 : 0.00011766290117520839
Loss at iteration 1390 : 0.0003066043427679688
Loss at iteration 1400 : 0.0050699105486273766
Loss at iteration 1410 : 0.0006397399120032787
Loss at iteration 1420 : 0.000156159425387159
Loss at iteration 1430 : 0.0003998046740889549
Loss at iteration 1440 : 8.07336182333529e-05
Loss at iteration 1450 : 0.00045755968312732875
Loss at iteration 1460 : 0.00010037109313998371
Loss at iteration 1470 : 5.023006451665424e-05
Loss at iteration 1480 : 0.0006508124643005431
Loss at iteration 1490 : 0.0002373376046307385
Loss at iteration 1500 : 0.00014214779366739094
Loss at iteration 1510 : 0.0003341865085531026
Loss at iteration 1520 : 0.003892875276505947
Loss at iteration 1530 : 0.0019408034859225154
Loss at iteration 1540 : 0.0004302090674173087
Loss at iteration 1550 : 0.0004955392214469612
Loss at iteration 1560 : 0.00022165731934364885
Loss at iteration 1570 : 0.0006601156201213598
Loss at iteration 1580 : 0.001428178627975285
Loss at iteration 1590 : 0.00022359610011335462
Loss at iteration 1600 : 0.004111918620765209
Loss at iteration 1610 : 0.0015369709581136703
Loss at iteration 1620 : 0.00014693132834509015
Loss at iteration 1630 : 0.00023129716282710433
Loss at iteration 1640 : 0.00017716089496389031
Loss at iteration 1650 : 0.00024393326020799577
Loss at iteration 1660 : 0.0001144625130109489
Loss at iteration 1670 : 0.004938567988574505
Loss at iteration 1680 : 0.0001719930733088404
Loss at iteration 1690 : 0.0003890132065862417
Loss at iteration 1700 : 8.610679651610553e-05
Loss at iteration 1710 : 4.534332038019784e-05
Loss at iteration 1720 : 0.00010382031177869067
Loss at iteration 1730 : 0.003955932334065437
Loss at iteration 1740 : 0.00010400643077446148
Loss at iteration 1750 : 0.0029102205298841
The SSIM Value is: 0.9873913735282579
The PSNR Value is: 46.68962549638118
the epoch is: 147
Loss at iteration 10 : 0.0030212407000362873
Loss at iteration 20 : 0.001556619768962264
Loss at iteration 30 : 0.004790566861629486
Loss at iteration 40 : 0.00011929927131859586
Loss at iteration 50 : 0.00012038058048347011
Loss at iteration 60 : 0.0001279609277844429
Loss at iteration 70 : 0.00020509379100985825
Loss at iteration 80 : 0.0004079897189512849
Loss at iteration 90 : 0.00041424587834626436
Loss at iteration 100 : 0.00015863627777434886
Loss at iteration 110 : 0.0001779183221515268
Loss at iteration 120 : 0.0020528463646769524
Loss at iteration 130 : 0.00031871377723291516
Loss at iteration 140 : 5.041632539359853e-05
Loss at iteration 150 : 0.0001494893804192543
Loss at iteration 160 : 0.0011882730759680271
Loss at iteration 170 : 0.0011649684747681022
Loss at iteration 180 : 0.00022166161215864122
Loss at iteration 190 : 4.8824007535586134e-05
Loss at iteration 200 : 5.477648664964363e-05
Loss at iteration 210 : 0.0022572888992726803
Loss at iteration 220 : 0.001268182648345828
Loss at iteration 230 : 0.0006425337051041424
Loss at iteration 240 : 0.00022923460346646607
Loss at iteration 250 : 0.005910370498895645
Loss at iteration 260 : 0.00038379518082365394
Loss at iteration 270 : 0.00020880287047475576
Loss at iteration 280 : 0.00037247262662276626
Loss at iteration 290 : 0.0015396098606288433
Loss at iteration 300 : 0.005620430689305067
Loss at iteration 310 : 7.160277891671285e-05
Loss at iteration 320 : 0.0032340919133275747
Loss at iteration 330 : 0.002907718066126108
Loss at iteration 340 : 0.0003651617735158652
Loss at iteration 350 : 0.0002024353452725336
Loss at iteration 360 : 0.0001243943115696311
Loss at iteration 370 : 9.654110908741131e-05
Loss at iteration 380 : 8.66199261508882e-05
Loss at iteration 390 : 0.00027351098833605647
Loss at iteration 400 : 0.0017965884180739522
Loss at iteration 410 : 6.117860175436363e-05
Loss at iteration 420 : 0.002416461706161499
Loss at iteration 430 : 0.0022290130145847797
Loss at iteration 440 : 0.00010732809460023418
Loss at iteration 450 : 0.00019877473823726177
Loss at iteration 460 : 0.0017199103021994233
Loss at iteration 470 : 0.00034404871985316277
Loss at iteration 480 : 0.00011009730224031955
Loss at iteration 490 : 0.00016084223170764744
Loss at iteration 500 : 0.0009226534748449922
Loss at iteration 510 : 0.0001229176123160869
Loss at iteration 520 : 9.242875967174768e-05
Loss at iteration 530 : 0.00043057347647845745
Loss at iteration 540 : 0.0010419893078505993
Loss at iteration 550 : 0.00042126659536734223
Loss at iteration 560 : 0.0011633873218670487
Loss at iteration 570 : 0.0009853750234469771
Loss at iteration 580 : 9.659532952355221e-05
Loss at iteration 590 : 0.0011036461219191551
Loss at iteration 600 : 0.00024044292513281107
Loss at iteration 610 : 0.0015347461448982358
Loss at iteration 620 : 0.0009272461757063866
Loss at iteration 630 : 0.00028363021556288004
Loss at iteration 640 : 0.0002669592504389584
Loss at iteration 650 : 0.00015179566980805248
Loss at iteration 660 : 0.00022105615062173456
Loss at iteration 670 : 0.0006431800429709256
Loss at iteration 680 : 0.0001450294948881492
Loss at iteration 690 : 0.0003520556492730975
Loss at iteration 700 : 0.0009760155808180571
Loss at iteration 710 : 0.0005522787687368691
Loss at iteration 720 : 0.00018836701929103583
Loss at iteration 730 : 0.0003855935647152364
Loss at iteration 740 : 0.0009374910732731223
Loss at iteration 750 : 0.0001288415805902332
Loss at iteration 760 : 0.0004799723974429071
Loss at iteration 770 : 8.689284004503861e-05
Loss at iteration 780 : 0.000126059225294739
Loss at iteration 790 : 0.0007376116700470448
Loss at iteration 800 : 0.0011779870837926865
Loss at iteration 810 : 0.0010076694888994098
Loss at iteration 820 : 0.0002293276775162667
Loss at iteration 830 : 0.0014867925783619285
Loss at iteration 840 : 0.0009336243965663016
Loss at iteration 850 : 0.0021754871122539043
Loss at iteration 860 : 0.00026531709590926766
Loss at iteration 870 : 0.00029391387943178415
Loss at iteration 880 : 0.0003047911450266838
Loss at iteration 890 : 0.0005729015101678669
Loss at iteration 900 : 0.002903104992583394
Loss at iteration 910 : 0.0002864299458451569
Loss at iteration 920 : 0.00032922561513260007
Loss at iteration 930 : 0.0002769146813079715
Loss at iteration 940 : 0.00021421992278192192
Loss at iteration 950 : 0.0015640862984582782
Loss at iteration 960 : 0.0001078275527106598
Loss at iteration 970 : 0.0005478590028360486
Loss at iteration 980 : 0.00020115663937758654
Loss at iteration 990 : 3.441422086325474e-05
Loss at iteration 1000 : 0.0042687272652983665
Loss at iteration 1010 : 7.832440314814448e-05
Loss at iteration 1020 : 0.0002031177282333374
Loss at iteration 1030 : 0.003342519048601389
Loss at iteration 1040 : 0.00010626089351717383
Loss at iteration 1050 : 8.856930799083784e-05
Loss at iteration 1060 : 0.00013120265793986619
Loss at iteration 1070 : 0.000285594433080405
Loss at iteration 1080 : 0.0003661400987766683
Loss at iteration 1090 : 0.003925969358533621
Loss at iteration 1100 : 0.0001546461135149002
Loss at iteration 1110 : 0.0002758714836090803
Loss at iteration 1120 : 0.0001495707401772961
Loss at iteration 1130 : 9.175281593343243e-05
Loss at iteration 1140 : 0.0004256142710801214
Loss at iteration 1150 : 0.003490275703370571
Loss at iteration 1160 : 0.0001156917423941195
Loss at iteration 1170 : 0.0010763081954792142
Loss at iteration 1180 : 0.005061654839664698
Loss at iteration 1190 : 0.0013833603588864207
Loss at iteration 1200 : 0.0010025600204244256
Loss at iteration 1210 : 0.00015147934027481824
Loss at iteration 1220 : 0.00011401070514693856
Loss at iteration 1230 : 0.0003723410773091018
Loss at iteration 1240 : 0.0033066016621887684
Loss at iteration 1250 : 0.00039111709338612854
Loss at iteration 1260 : 0.0003699644294101745
Loss at iteration 1270 : 0.005295060109347105
Loss at iteration 1280 : 0.0003431962977629155
Loss at iteration 1290 : 0.00017021025996655226
Loss at iteration 1300 : 0.00021128548542037606
Loss at iteration 1310 : 0.0052408138290047646
Loss at iteration 1320 : 0.0001742672175168991
Loss at iteration 1330 : 0.0001780832390068099
Loss at iteration 1340 : 0.0002644854539539665
Loss at iteration 1350 : 0.00015595092554576695
Loss at iteration 1360 : 0.0001972253667190671
Loss at iteration 1370 : 0.0006065191701054573
Loss at iteration 1380 : 0.00013238342944532633
Loss at iteration 1390 : 0.00013979805225972086
Loss at iteration 1400 : 0.00010440414189361036
Loss at iteration 1410 : 0.000604888831730932
Loss at iteration 1420 : 0.0021603840868920088
Loss at iteration 1430 : 5.401673843152821e-05
Loss at iteration 1440 : 0.00029315747087821364
Loss at iteration 1450 : 0.0014612484956160188
Loss at iteration 1460 : 0.0002008798037422821
Loss at iteration 1470 : 0.00025485182413831353
Loss at iteration 1480 : 8.12140860944055e-05
Loss at iteration 1490 : 0.00010098677012138069
Loss at iteration 1500 : 0.00025139411445707083
Loss at iteration 1510 : 0.00020918971858918667
Loss at iteration 1520 : 0.0003018971183337271
Loss at iteration 1530 : 0.001717583043500781
Loss at iteration 1540 : 0.0021713809110224247
Loss at iteration 1550 : 0.0004530104051809758
Loss at iteration 1560 : 0.0008966008317656815
Loss at iteration 1570 : 0.0029598260298371315
Loss at iteration 1580 : 0.00011709897080436349
Loss at iteration 1590 : 0.00045596889685839415
Loss at iteration 1600 : 7.884670048952103e-05
Loss at iteration 1610 : 0.0008206955390051007
Loss at iteration 1620 : 0.00015687948325648904
Loss at iteration 1630 : 0.00018112205725628883
Loss at iteration 1640 : 0.004672078415751457
Loss at iteration 1650 : 0.0001781654718797654
Loss at iteration 1660 : 0.00025028278469108045
Loss at iteration 1670 : 0.0026257005520164967
Loss at iteration 1680 : 0.00035347818629816175
Loss at iteration 1690 : 9.089878585655242e-05
Loss at iteration 1700 : 0.00048359850188717246
Loss at iteration 1710 : 3.7264831917127594e-05
Loss at iteration 1720 : 0.00016545865219086409
Loss at iteration 1730 : 0.00023988763859961182
Loss at iteration 1740 : 0.002492403844371438
Loss at iteration 1750 : 0.0015662150690332055
The SSIM Value is: 0.9862865235837021
The PSNR Value is: 46.535875980024294
the epoch is: 148
Loss at iteration 10 : 0.00016344114555977285
Loss at iteration 20 : 6.347025919239968e-05
Loss at iteration 30 : 0.0008070188341662288
Loss at iteration 40 : 0.0012813287321478128
Loss at iteration 50 : 0.004362193867564201
Loss at iteration 60 : 0.00010248915350530297
Loss at iteration 70 : 0.0001160392930614762
Loss at iteration 80 : 0.00012483024329412729
Loss at iteration 90 : 0.00013254421355668455
Loss at iteration 100 : 0.0001211954586324282
Loss at iteration 110 : 0.006890440359711647
Loss at iteration 120 : 0.0009091707179322839
Loss at iteration 130 : 0.000375513598555699
Loss at iteration 140 : 0.001502577681094408
Loss at iteration 150 : 0.0041829487308859825
Loss at iteration 160 : 0.0021070886868983507
Loss at iteration 170 : 0.0037383269518613815
Loss at iteration 180 : 0.00010552901221672073
Loss at iteration 190 : 0.0010185115970671177
Loss at iteration 200 : 6.720989040331915e-05
Loss at iteration 210 : 0.00010486181417945772
Loss at iteration 220 : 0.00017051742179319263
Loss at iteration 230 : 0.004010221920907497
Loss at iteration 240 : 0.000843794085085392
Loss at iteration 250 : 0.0003743529669009149
Loss at iteration 260 : 0.0028313228394836187
Loss at iteration 270 : 0.0005549848428927362
Loss at iteration 280 : 0.002549927681684494
Loss at iteration 290 : 0.0024223688524216413
Loss at iteration 300 : 0.002655360382050276
Loss at iteration 310 : 0.00020180110004730523
Loss at iteration 320 : 0.00017443722754251212
Loss at iteration 330 : 0.0008927958551794291
Loss at iteration 340 : 0.0029263964388519526
Loss at iteration 350 : 0.00010647521412465721
Loss at iteration 360 : 0.0001670432393439114
Loss at iteration 370 : 0.0032463576644659042
Loss at iteration 380 : 0.00043858546996489167
Loss at iteration 390 : 0.0024984623305499554
Loss at iteration 400 : 0.0018980215536430478
Loss at iteration 410 : 0.0011189829092472792
Loss at iteration 420 : 0.0010530090657994151
Loss at iteration 430 : 0.0003450237272772938
Loss at iteration 440 : 0.0008346280083060265
Loss at iteration 450 : 0.0025496070738881826
Loss at iteration 460 : 0.002969643333926797
Loss at iteration 470 : 0.0002897268277592957
Loss at iteration 480 : 0.0006896017584949732
Loss at iteration 490 : 0.0007292742957361042
Loss at iteration 500 : 0.0001626773737370968
Loss at iteration 510 : 0.0001685266033746302
Loss at iteration 520 : 0.0005909537430852652
Loss at iteration 530 : 0.0002725103113334626
Loss at iteration 540 : 4.920296851196326e-05
Loss at iteration 550 : 0.0004007774987258017
Loss at iteration 560 : 7.86508244345896e-05
Loss at iteration 570 : 9.153022256214172e-05
Loss at iteration 580 : 4.48479077022057e-05
Loss at iteration 590 : 0.0004416775773279369
Loss at iteration 600 : 0.0029395113233476877
Loss at iteration 610 : 0.0008127627079375088
Loss at iteration 620 : 0.001078620902262628
Loss at iteration 630 : 0.0004935862962156534
Loss at iteration 640 : 0.0002985813480336219
Loss at iteration 650 : 0.0018180343322455883
Loss at iteration 660 : 0.00020506333385128528
Loss at iteration 670 : 0.00019428847008384764
Loss at iteration 680 : 0.0008942482527345419
Loss at iteration 690 : 0.00011027068103430793
Loss at iteration 700 : 0.002660140162333846
Loss at iteration 710 : 0.0015602572821080685
Loss at iteration 720 : 0.00024044881865847856
Loss at iteration 730 : 0.0030052964575588703
Loss at iteration 740 : 8.549388439860195e-05
Loss at iteration 750 : 0.0036150526721030474
Loss at iteration 760 : 7.503623783122748e-05
Loss at iteration 770 : 0.009570515714585781
Loss at iteration 780 : 0.002598279155790806
Loss at iteration 790 : 0.00019154621986672282
Loss at iteration 800 : 0.0010378004517406225
Loss at iteration 810 : 5.824835898238234e-05
Loss at iteration 820 : 7.635990186827257e-05
Loss at iteration 830 : 0.0002408503059996292
Loss at iteration 840 : 0.0003284616977907717
Loss at iteration 850 : 6.984428910072893e-05
Loss at iteration 860 : 0.00012496185081545264
Loss at iteration 870 : 0.0006144967628642917
Loss at iteration 880 : 0.0016471468843519688
Loss at iteration 890 : 0.00024731169105507433
Loss at iteration 900 : 0.0012105166679248214
Loss at iteration 910 : 0.00011196180275874212
Loss at iteration 920 : 0.000885560701135546
Loss at iteration 930 : 0.0009984413627535105
Loss at iteration 940 : 0.0005442594992928207
Loss at iteration 950 : 0.0001961599919013679
Loss at iteration 960 : 0.0002267839154228568
Loss at iteration 970 : 0.00010133597970707342
Loss at iteration 980 : 0.0010292958468198776
Loss at iteration 990 : 0.002857857383787632
Loss at iteration 1000 : 0.00015577067097183317
Loss at iteration 1010 : 8.220116433221847e-05
Loss at iteration 1020 : 0.0025602171663194895
Loss at iteration 1030 : 0.006293212063610554
Loss at iteration 1040 : 8.169707143679261e-05
Loss at iteration 1050 : 0.0006391530041582882
Loss at iteration 1060 : 0.0010755693074315786
Loss at iteration 1070 : 0.0032417448237538338
Loss at iteration 1080 : 0.0036896937526762486
Loss at iteration 1090 : 0.00010623862908687443
Loss at iteration 1100 : 0.000305673573166132
Loss at iteration 1110 : 0.00015650643035769463
Loss at iteration 1120 : 0.00018507518689148128
Loss at iteration 1130 : 0.005796355195343494
Loss at iteration 1140 : 6.793838110752404e-05
Loss at iteration 1150 : 0.0003602767828851938
Loss at iteration 1160 : 0.0038058049976825714
Loss at iteration 1170 : 0.0010480600176379085
Loss at iteration 1180 : 0.0005668086232617497
Loss at iteration 1190 : 8.625550981378183e-05
Loss at iteration 1200 : 0.00045853701885789633
Loss at iteration 1210 : 7.569501758553088e-05
Loss at iteration 1220 : 0.0009672123705968261
Loss at iteration 1230 : 0.002279259730130434
Loss at iteration 1240 : 0.003018587827682495
Loss at iteration 1250 : 0.00019162507669534534
Loss at iteration 1260 : 0.00033447114401496947
Loss at iteration 1270 : 0.0011090146144852042
Loss at iteration 1280 : 0.0001282084413105622
Loss at iteration 1290 : 0.00023317926388699561
Loss at iteration 1300 : 0.0023455782793462276
Loss at iteration 1310 : 0.00021050538634881377
Loss at iteration 1320 : 0.00029494910268113017
Loss at iteration 1330 : 0.0001349407684756443
Loss at iteration 1340 : 0.00041771569522097707
Loss at iteration 1350 : 0.0004637386300601065
Loss at iteration 1360 : 0.0002081215934595093
Loss at iteration 1370 : 0.0001057060289895162
Loss at iteration 1380 : 0.00011285397340543568
Loss at iteration 1390 : 0.00025932519929483533
Loss at iteration 1400 : 0.0003009996435139328
Loss at iteration 1410 : 0.00361206685192883
Loss at iteration 1420 : 0.005665854550898075
Loss at iteration 1430 : 0.00013821889297105372
Loss at iteration 1440 : 0.0007506276597268879
Loss at iteration 1450 : 0.0001708759373286739
Loss at iteration 1460 : 0.00017926447617355734
Loss at iteration 1470 : 0.0006771687767468393
Loss at iteration 1480 : 0.00435807928442955
Loss at iteration 1490 : 0.00012335721112322062
Loss at iteration 1500 : 0.00021661282517015934
Loss at iteration 1510 : 0.00030433956999331713
Loss at iteration 1520 : 9.266364941140637e-05
Loss at iteration 1530 : 0.00036205537617206573
Loss at iteration 1540 : 0.00010286794713465497
Loss at iteration 1550 : 0.0018230468267574906
Loss at iteration 1560 : 0.0023208509664982557
Loss at iteration 1570 : 9.774536738405004e-05
Loss at iteration 1580 : 0.0031880056485533714
Loss at iteration 1590 : 0.00012074143160134554
Loss at iteration 1600 : 0.0001368469966109842
Loss at iteration 1610 : 0.006603142246603966
Loss at iteration 1620 : 0.00013154218322597444
Loss at iteration 1630 : 0.0003818553523160517
Loss at iteration 1640 : 0.00010995203047059476
Loss at iteration 1650 : 0.00205207709223032
Loss at iteration 1660 : 7.146503048716113e-05
Loss at iteration 1670 : 0.00013003565254621208
Loss at iteration 1680 : 0.00012094421981601045
Loss at iteration 1690 : 0.0008239476010203362
Loss at iteration 1700 : 0.0037656831555068493
Loss at iteration 1710 : 0.00022311216162052006
Loss at iteration 1720 : 6.509314698632807e-05
Loss at iteration 1730 : 0.0008019427768886089
Loss at iteration 1740 : 0.004874418489634991
Loss at iteration 1750 : 0.00032025304972194135
The SSIM Value is: 0.9852364218182501
The PSNR Value is: 46.58862219192908
the epoch is: 149
Loss at iteration 10 : 0.001666070194914937
Loss at iteration 20 : 0.0004532489401753992
Loss at iteration 30 : 0.0003603028308134526
Loss at iteration 40 : 0.0003664928663056344
Loss at iteration 50 : 0.0004225635202601552
Loss at iteration 60 : 9.135397704085335e-05
Loss at iteration 70 : 0.0027523497119545937
Loss at iteration 80 : 0.000883523840457201
Loss at iteration 90 : 0.0001282878511119634
Loss at iteration 100 : 0.0011263012420386076
Loss at iteration 110 : 0.0035283793695271015
Loss at iteration 120 : 0.0002553054946474731
Loss at iteration 130 : 0.00020657878485508263
Loss at iteration 140 : 0.00010885827214224264
Loss at iteration 150 : 0.0023194109089672565
Loss at iteration 160 : 0.0019282151479274035
Loss at iteration 170 : 0.00021204768563620746
Loss at iteration 180 : 0.0005077304667793214
Loss at iteration 190 : 0.0015063865575939417
Loss at iteration 200 : 0.00020711059914901853
Loss at iteration 210 : 0.00012107213115086779
Loss at iteration 220 : 0.0005930300685577095
Loss at iteration 230 : 0.000910262344405055
Loss at iteration 240 : 5.422243702923879e-05
Loss at iteration 250 : 0.00011178105341969058
Loss at iteration 260 : 0.0003726574359461665
Loss at iteration 270 : 0.0001155274803750217
Loss at iteration 280 : 0.00014943868154659867
Loss at iteration 290 : 0.00021136360010132194
Loss at iteration 300 : 0.00022654392523691058
Loss at iteration 310 : 0.0016387652140110731
Loss at iteration 320 : 0.00019074295414611697
Loss at iteration 330 : 7.115596963558346e-05
Loss at iteration 340 : 0.00028378356364555657
Loss at iteration 350 : 0.002215051557868719
Loss at iteration 360 : 0.0019511788850650191
Loss at iteration 370 : 0.0020144919399172068
Loss at iteration 380 : 0.0005082057905383408
Loss at iteration 390 : 0.0006507335929200053
Loss at iteration 400 : 0.000336016237270087
Loss at iteration 410 : 0.00035947293508797884
Loss at iteration 420 : 0.000316050136461854
Loss at iteration 430 : 0.00014072902558837086
Loss at iteration 440 : 0.0004889040719717741
Loss at iteration 450 : 0.00019470119150355458
Loss at iteration 460 : 8.496759983245283e-05
Loss at iteration 470 : 0.001508258981630206
Loss at iteration 480 : 0.0009583183564245701
Loss at iteration 490 : 0.000673540576826781
Loss at iteration 500 : 0.0001485304528614506
Loss at iteration 510 : 0.00025426552747376263
Loss at iteration 520 : 7.496075704693794e-05
Loss at iteration 530 : 0.00042772514279931784
Loss at iteration 540 : 0.000444695760961622
Loss at iteration 550 : 0.00030114068067632616
Loss at iteration 560 : 0.00021027348702773452
Loss at iteration 570 : 0.0008939739782363176
Loss at iteration 580 : 0.00015325471758842468
Loss at iteration 590 : 0.001746086054481566
Loss at iteration 600 : 0.0001801400794647634
Loss at iteration 610 : 0.0007876676390878856
Loss at iteration 620 : 0.00018222632934339345
Loss at iteration 630 : 0.00013092547305859625
Loss at iteration 640 : 0.004812362603843212
Loss at iteration 650 : 5.234049604041502e-05
Loss at iteration 660 : 0.0001556108909426257
Loss at iteration 670 : 0.0005830518202856183
Loss at iteration 680 : 0.0025091832503676414
Loss at iteration 690 : 0.0001997032668441534
Loss at iteration 700 : 0.0004197719390504062
Loss at iteration 710 : 0.00021298820502124727
Loss at iteration 720 : 0.0008258934249170125
Loss at iteration 730 : 0.003341924399137497
Loss at iteration 740 : 0.0008155529503710568
Loss at iteration 750 : 0.00033216981682926416
Loss at iteration 760 : 0.0001768176443874836
Loss at iteration 770 : 8.792377775534987e-05
Loss at iteration 780 : 0.0011930731125175953
Loss at iteration 790 : 0.0006479846779257059
Loss at iteration 800 : 0.0005350797437131405
Loss at iteration 810 : 0.0007339033763855696
Loss at iteration 820 : 0.000382663361961022
Loss at iteration 830 : 0.00013265256711747497
Loss at iteration 840 : 0.0003107968077529222
Loss at iteration 850 : 0.001940363086760044
Loss at iteration 860 : 0.000385001563699916
Loss at iteration 870 : 0.003177257487550378
Loss at iteration 880 : 0.0001660539273871109
Loss at iteration 890 : 0.00021079627913422883
Loss at iteration 900 : 0.00012523066834546626
Loss at iteration 910 : 0.0016137186903506517
Loss at iteration 920 : 0.00034346748725511134
Loss at iteration 930 : 0.0013736756518483162
Loss at iteration 940 : 0.0009310381137765944
Loss at iteration 950 : 0.005447679199278355
Loss at iteration 960 : 0.004605510737746954
Loss at iteration 970 : 0.0007886122912168503
Loss at iteration 980 : 0.0001177554513560608
Loss at iteration 990 : 0.0027674678713083267
Loss at iteration 1000 : 0.0017296280711889267
Loss at iteration 1010 : 0.00015816475206520408
Loss at iteration 1020 : 0.0027119137812405825
Loss at iteration 1030 : 0.00034553048317320645
Loss at iteration 1040 : 0.0004647115711122751
Loss at iteration 1050 : 0.001281401258893311
Loss at iteration 1060 : 0.00033029585028998554
Loss at iteration 1070 : 0.0007055102032609284
Loss at iteration 1080 : 0.00013266394671518356
Loss at iteration 1090 : 0.00018880311108659953
Loss at iteration 1100 : 0.0017343716463074088
Loss at iteration 1110 : 0.0004227197205182165
Loss at iteration 1120 : 0.00022553294547833502
Loss at iteration 1130 : 0.000590722425840795
Loss at iteration 1140 : 0.001956421881914139
Loss at iteration 1150 : 0.00633613346144557
Loss at iteration 1160 : 0.00013897166354581714
Loss at iteration 1170 : 8.530594641342759e-05
Loss at iteration 1180 : 0.0010555335320532322
Loss at iteration 1190 : 0.0005502947606146336
Loss at iteration 1200 : 0.00041917417547665536
Loss at iteration 1210 : 7.720221765339375e-05
Loss at iteration 1220 : 8.919336687540635e-05
Loss at iteration 1230 : 0.0008560572750866413
Loss at iteration 1240 : 0.0015826543094590306
Loss at iteration 1250 : 0.00029632970108650625
Loss at iteration 1260 : 0.00011914207425434142
Loss at iteration 1270 : 5.401955786510371e-05
Loss at iteration 1280 : 0.0004623205168172717
Loss at iteration 1290 : 0.00044810347026214004
Loss at iteration 1300 : 0.0023294060956686735
Loss at iteration 1310 : 0.0005228893714956939
Loss at iteration 1320 : 0.0004615014186128974
Loss at iteration 1330 : 5.021162360208109e-05
Loss at iteration 1340 : 0.0002131408837158233
Loss at iteration 1350 : 0.00020197767298668623
Loss at iteration 1360 : 0.00029883114621043205
Loss at iteration 1370 : 0.00012773129856213927
Loss at iteration 1380 : 0.00015256176993716508
Loss at iteration 1390 : 0.002921860897913575
Loss at iteration 1400 : 0.0002668167289812118
Loss at iteration 1410 : 0.00011060849647037685
Loss at iteration 1420 : 6.747968291165307e-05
Loss at iteration 1430 : 0.0008195402915589511
Loss at iteration 1440 : 0.005320894066244364
Loss at iteration 1450 : 0.00014980605919845402
Loss at iteration 1460 : 0.0002254838473163545
Loss at iteration 1470 : 0.0001741659943945706
Loss at iteration 1480 : 5.9123362007085234e-05
Loss at iteration 1490 : 0.00036391548928804696
Loss at iteration 1500 : 0.0001159066814580001
Loss at iteration 1510 : 0.0005190491210669279
Loss at iteration 1520 : 9.634796879254282e-05
Loss at iteration 1530 : 0.00014822800585534424
Loss at iteration 1540 : 0.002419928088784218
Loss at iteration 1550 : 0.0022151318844407797
Loss at iteration 1560 : 0.0005505366716533899
Loss at iteration 1570 : 7.336791168199852e-05
Loss at iteration 1580 : 3.385804302524775e-05
Loss at iteration 1590 : 0.0002907240414060652
Loss at iteration 1600 : 5.3880572522757575e-05
Loss at iteration 1610 : 0.0034714906942099333
Loss at iteration 1620 : 0.00015521330351475626
Loss at iteration 1630 : 0.0002115036768373102
Loss at iteration 1640 : 0.00039844991988502443
Loss at iteration 1650 : 0.00014924310380592942
Loss at iteration 1660 : 0.0010486738756299019
Loss at iteration 1670 : 0.0002395397750660777
Loss at iteration 1680 : 0.002011899370700121
Loss at iteration 1690 : 0.00013411384134087712
Loss at iteration 1700 : 0.00020593256340362132
Loss at iteration 1710 : 0.00010948599083349109
Loss at iteration 1720 : 0.006360900588333607
Loss at iteration 1730 : 0.0007547113345935941
Loss at iteration 1740 : 0.004512770101428032
Loss at iteration 1750 : 0.00011406409612391144
The SSIM Value is: 0.9770590079382128
The PSNR Value is: 46.522922129357966
the epoch is: 150
Loss at iteration 10 : 7.547026325482875e-05
Loss at iteration 20 : 0.00032391282729804516
Loss at iteration 30 : 0.0007146124262362719
Loss at iteration 40 : 0.00020318961469456553
Loss at iteration 50 : 0.00021371175535023212
Loss at iteration 60 : 0.0002292647259309888
Loss at iteration 70 : 0.006454838439822197
Loss at iteration 80 : 0.00048611999955028296
Loss at iteration 90 : 0.0047842105850577354
Loss at iteration 100 : 0.0009911408415064216
Loss at iteration 110 : 0.00018351050675846636
Loss at iteration 120 : 0.0036951948422938585
Loss at iteration 130 : 0.0008216618443839252
Loss at iteration 140 : 0.0037865168415009975
Loss at iteration 150 : 0.002632217248901725
Loss at iteration 160 : 0.0008988311165012419
Loss at iteration 170 : 9.805010631680489e-05
Loss at iteration 180 : 6.11102586844936e-05
Loss at iteration 190 : 0.00019361873273737729
Loss at iteration 200 : 0.0008949667098931968
Loss at iteration 210 : 0.0005306340171955526
Loss at iteration 220 : 7.256836397573352e-05
Loss at iteration 230 : 0.008274308405816555
Loss at iteration 240 : 0.0004573518526740372
Loss at iteration 250 : 0.0014519901014864445
Loss at iteration 260 : 0.0001691529032541439
Loss at iteration 270 : 0.00016079570923466235
Loss at iteration 280 : 0.002482676412910223
Loss at iteration 290 : 0.0015548698138445616
Loss at iteration 300 : 0.00024921385920606554
Loss at iteration 310 : 0.00020212860545143485
Loss at iteration 320 : 0.0021578192245215178
Loss at iteration 330 : 0.00010586324060568586
Loss at iteration 340 : 0.00028849593945778906
Loss at iteration 350 : 0.00024678331101313233
Loss at iteration 360 : 0.0007405580254271626
Loss at iteration 370 : 0.0008014260674826801
Loss at iteration 380 : 0.002119116485118866
Loss at iteration 390 : 0.0001132164616137743
Loss at iteration 400 : 0.0008779914933256805
Loss at iteration 410 : 0.0004773757536895573
Loss at iteration 420 : 0.00011044239363400266
Loss at iteration 430 : 0.0001020866766339168
Loss at iteration 440 : 0.000520254485309124
Loss at iteration 450 : 0.0002839969238266349
Loss at iteration 460 : 0.0004895165329799056
Loss at iteration 470 : 0.00017376834875904024
Loss at iteration 480 : 0.00010724563617259264
Loss at iteration 490 : 0.0003902712487615645
Loss at iteration 500 : 0.00044910237193107605
Loss at iteration 510 : 0.001584989600814879
Loss at iteration 520 : 0.00011642173922155052
Loss at iteration 530 : 0.00010625705908751115
Loss at iteration 540 : 0.0004821217153221369
Loss at iteration 550 : 0.00011686493235174567
Loss at iteration 560 : 0.0003300547832623124
Loss at iteration 570 : 0.00018584982899483293
Loss at iteration 580 : 0.003158950014039874
Loss at iteration 590 : 0.0009626992978155613
Loss at iteration 600 : 0.0006146897212602198
Loss at iteration 610 : 0.0004435832961462438
Loss at iteration 620 : 0.0003364891745150089
Loss at iteration 630 : 0.003979133442044258
Loss at iteration 640 : 0.0003779797989409417
Loss at iteration 650 : 0.0009275211486965418
Loss at iteration 660 : 7.248482870636508e-05
Loss at iteration 670 : 0.0003621180949267
Loss at iteration 680 : 0.00015989074017852545
Loss at iteration 690 : 0.0002834986080415547
Loss at iteration 700 : 0.00011542655556695536
Loss at iteration 710 : 0.004726325627416372
Loss at iteration 720 : 0.00025373586686328053
Loss at iteration 730 : 0.0005606530467048287
Loss at iteration 740 : 0.00040959176840260625
Loss at iteration 750 : 0.00015987295773811638
Loss at iteration 760 : 7.423825445584953e-05
Loss at iteration 770 : 0.0033134273253381252
Loss at iteration 780 : 0.0025409827940165997
Loss at iteration 790 : 9.828375186771154e-05
Loss at iteration 800 : 0.005635463632643223
Loss at iteration 810 : 0.0010236004600301385
Loss at iteration 820 : 0.0014385734684765339
Loss at iteration 830 : 0.00038311409298330545
Loss at iteration 840 : 0.00010926568938884884
Loss at iteration 850 : 0.0029584509320557117
Loss at iteration 860 : 0.002041272819042206
Loss at iteration 870 : 0.0021933801472187042
Loss at iteration 880 : 0.00011435414489824325
Loss at iteration 890 : 7.656517846044153e-05
Loss at iteration 900 : 0.00014247657964006066
Loss at iteration 910 : 0.00021855048544239253
Loss at iteration 920 : 0.00019964214880019426
Loss at iteration 930 : 0.0005061868578195572
Loss at iteration 940 : 0.006081111263483763
Loss at iteration 950 : 0.0005214481498114765
Loss at iteration 960 : 0.000893069664016366
Loss at iteration 970 : 9.695337939774618e-05
Loss at iteration 980 : 0.0004998939693905413
Loss at iteration 990 : 0.0003616843605414033
Loss at iteration 1000 : 0.004460450261831284
Loss at iteration 1010 : 0.00031878973823040724
Loss at iteration 1020 : 0.006598391104489565
Loss at iteration 1030 : 0.00020113843493163586
Loss at iteration 1040 : 0.0002886013826355338
Loss at iteration 1050 : 0.000339050980983302
Loss at iteration 1060 : 0.001708952710032463
Loss at iteration 1070 : 0.0001916946202982217
Loss at iteration 1080 : 0.0016902153147384524
Loss at iteration 1090 : 0.0005719211185351014
Loss at iteration 1100 : 0.0007838966557756066
Loss at iteration 1110 : 0.00011360841745045036
Loss at iteration 1120 : 0.0018390328623354435
Loss at iteration 1130 : 0.000640099635347724
Loss at iteration 1140 : 0.005543092731386423
Loss at iteration 1150 : 0.00023350384435616434
Loss at iteration 1160 : 0.0003763588611036539
Loss at iteration 1170 : 0.004311655182391405
Loss at iteration 1180 : 0.002671930007636547
Loss at iteration 1190 : 0.0002116737305186689
Loss at iteration 1200 : 0.0009673393797129393
Loss at iteration 1210 : 7.406239456031471e-05
Loss at iteration 1220 : 0.0005207456997595727
Loss at iteration 1230 : 0.00040088818059302866
Loss at iteration 1240 : 0.00043041567550972104
Loss at iteration 1250 : 0.0025376093108206987
Loss at iteration 1260 : 0.0003171390271745622
Loss at iteration 1270 : 7.532850577263162e-05
Loss at iteration 1280 : 8.788971172180027e-05
Loss at iteration 1290 : 9.781774133443832e-05
Loss at iteration 1300 : 0.0002536368556320667
Loss at iteration 1310 : 0.004624667577445507
Loss at iteration 1320 : 0.0005619885050691664
Loss at iteration 1330 : 0.0001133043915615417
Loss at iteration 1340 : 0.0001789027010090649
Loss at iteration 1350 : 0.000493881874717772
Loss at iteration 1360 : 0.000317972939228639
Loss at iteration 1370 : 0.0007321701850742102
Loss at iteration 1380 : 0.0007375241257250309
Loss at iteration 1390 : 9.429211786482483e-05
Loss at iteration 1400 : 0.0009935015114024282
Loss at iteration 1410 : 0.0015384664293378592
Loss at iteration 1420 : 0.005535033997148275
Loss at iteration 1430 : 0.00024501659208908677
Loss at iteration 1440 : 0.00034421446616761386
Loss at iteration 1450 : 9.019712160807103e-05
Loss at iteration 1460 : 0.002547882031649351
Loss at iteration 1470 : 0.005536369979381561
Loss at iteration 1480 : 0.00531000318005681
Loss at iteration 1490 : 4.893497680313885e-05
Loss at iteration 1500 : 8.660102321300656e-05
Loss at iteration 1510 : 0.0009027853375300765
Loss at iteration 1520 : 0.0004030816489830613
Loss at iteration 1530 : 0.0007422663038596511
Loss at iteration 1540 : 0.0005803608219139278
Loss at iteration 1550 : 4.495708708418533e-05
Loss at iteration 1560 : 0.0005924341967329383
Loss at iteration 1570 : 4.737505514640361e-05
Loss at iteration 1580 : 9.545372449792922e-05
Loss at iteration 1590 : 6.257727363845333e-05
Loss at iteration 1600 : 0.00033375906059518456
Loss at iteration 1610 : 0.0034817613195627928
Loss at iteration 1620 : 0.0004703133599832654
Loss at iteration 1630 : 0.0006123181665316224
Loss at iteration 1640 : 0.0009176801540888846
Loss at iteration 1650 : 0.0005424903938546777
Loss at iteration 1660 : 0.00029403535882011056
Loss at iteration 1670 : 0.00017938086239155382
Loss at iteration 1680 : 0.0004070803988724947
Loss at iteration 1690 : 0.0021732766181230545
Loss at iteration 1700 : 0.005283535458147526
Loss at iteration 1710 : 0.001699282438494265
Loss at iteration 1720 : 0.0010818865848705173
Loss at iteration 1730 : 7.186624861788005e-05
Loss at iteration 1740 : 0.00010687379108276218
Loss at iteration 1750 : 0.00018449858180247247
The SSIM Value is: 0.9894223398311548
The PSNR Value is: 46.48250880850569
the epoch is: 151
Loss at iteration 10 : 0.00010533600288908929
Loss at iteration 20 : 0.002551977289840579
Loss at iteration 30 : 0.0038162008859217167
Loss at iteration 40 : 0.0005091005004942417
Loss at iteration 50 : 0.00017353125440422446
Loss at iteration 60 : 0.004053974524140358
Loss at iteration 70 : 0.0005760112544521689
Loss at iteration 80 : 0.0027737468481063843
Loss at iteration 90 : 9.945141209755093e-05
Loss at iteration 100 : 8.579070708947256e-05
Loss at iteration 110 : 0.0004089308204129338
Loss at iteration 120 : 0.00010621277760947123
Loss at iteration 130 : 0.0006281663663685322
Loss at iteration 140 : 0.00029417965561151505
Loss at iteration 150 : 8.544612501282245e-05
Loss at iteration 160 : 0.0005254473071545362
Loss at iteration 170 : 0.0003138780302833766
Loss at iteration 180 : 0.0038607236929237843
Loss at iteration 190 : 6.751320324838161e-05
Loss at iteration 200 : 0.0015257357154041529
Loss at iteration 210 : 6.115789437899366e-05
Loss at iteration 220 : 0.002129908185452223
Loss at iteration 230 : 7.16364083928056e-05
Loss at iteration 240 : 0.0005022777477279305
Loss at iteration 250 : 0.0013130108127370477
Loss at iteration 260 : 0.0023916340433061123
Loss at iteration 270 : 0.00028872338589280844
Loss at iteration 280 : 0.0038137920200824738
Loss at iteration 290 : 0.003968652803450823
Loss at iteration 300 : 0.00015055776748340577
Loss at iteration 310 : 0.0027589043602347374
Loss at iteration 320 : 0.0015204311348497868
Loss at iteration 330 : 0.00017985524027608335
Loss at iteration 340 : 0.0004573667247314006
Loss at iteration 350 : 0.0016631962498649955
Loss at iteration 360 : 0.001206261687912047
Loss at iteration 370 : 0.00015165343938861042
Loss at iteration 380 : 0.0006344607099890709
Loss at iteration 390 : 0.002702202182263136
Loss at iteration 400 : 0.00017182217561639845
Loss at iteration 410 : 0.00019096845062449574
Loss at iteration 420 : 0.004212856292724609
Loss at iteration 430 : 0.0003893257526215166
Loss at iteration 440 : 9.858524572337046e-05
Loss at iteration 450 : 0.001785017317160964
Loss at iteration 460 : 0.0003456877893768251
Loss at iteration 470 : 0.0032922346144914627
Loss at iteration 480 : 0.0021895298268646
Loss at iteration 490 : 8.385981345782056e-05
Loss at iteration 500 : 0.00013207734446041286
Loss at iteration 510 : 0.0032864180393517017
Loss at iteration 520 : 0.00026311460533179343
Loss at iteration 530 : 0.0001658175024203956
Loss at iteration 540 : 0.0004799699818249792
Loss at iteration 550 : 0.0003837315598502755
Loss at iteration 560 : 0.00391359394416213
Loss at iteration 570 : 0.00033017242094501853
Loss at iteration 580 : 0.0015256230253726244
Loss at iteration 590 : 0.0002578335115686059
Loss at iteration 600 : 0.00041731863166205585
Loss at iteration 610 : 0.0001385786454193294
Loss at iteration 620 : 0.0011968823382630944
Loss at iteration 630 : 9.155285806627944e-05
Loss at iteration 640 : 0.00034161846269853413
Loss at iteration 650 : 0.00017881403618957847
Loss at iteration 660 : 0.0002325738314539194
Loss at iteration 670 : 7.627360173501074e-05
Loss at iteration 680 : 0.0007495389436371624
Loss at iteration 690 : 0.00015230645658448339
Loss at iteration 700 : 0.004915054887533188
Loss at iteration 710 : 0.00038229324854910374
Loss at iteration 720 : 8.824434189591557e-05
Loss at iteration 730 : 0.0003169882402289659
Loss at iteration 740 : 0.00010781493620015681
Loss at iteration 750 : 9.795428195502609e-05
Loss at iteration 760 : 0.00018357450608164072
Loss at iteration 770 : 0.00013177708024159074
Loss at iteration 780 : 0.0003256805066484958
Loss at iteration 790 : 0.0003933513071388006
Loss at iteration 800 : 7.440336048603058e-05
Loss at iteration 810 : 0.00029310068930499256
Loss at iteration 820 : 0.0002807778073474765
Loss at iteration 830 : 7.83101495471783e-05
Loss at iteration 840 : 8.856520435074344e-05
Loss at iteration 850 : 0.002206929726526141
Loss at iteration 860 : 9.615947783458978e-05
Loss at iteration 870 : 0.00014021448441781104
Loss at iteration 880 : 0.0002364930260227993
Loss at iteration 890 : 0.00023059890372678638
Loss at iteration 900 : 0.0003316622751299292
Loss at iteration 910 : 0.0015504563925787807
Loss at iteration 920 : 0.003161011729389429
Loss at iteration 930 : 0.00011000283120665699
Loss at iteration 940 : 0.0008366262773051858
Loss at iteration 950 : 7.771866512484848e-05
Loss at iteration 960 : 0.005895527079701424
Loss at iteration 970 : 0.0003461823216639459
Loss at iteration 980 : 8.857302600517869e-05
Loss at iteration 990 : 0.0002369750291109085
Loss at iteration 1000 : 8.535844972357154e-05
Loss at iteration 1010 : 0.0006071317475289106
Loss at iteration 1020 : 0.00061414745869115
Loss at iteration 1030 : 0.000134331698063761
Loss at iteration 1040 : 0.0003625773824751377
Loss at iteration 1050 : 0.00041912359301932156
Loss at iteration 1060 : 0.001468317350372672
Loss at iteration 1070 : 7.64987853472121e-05
Loss at iteration 1080 : 0.002325402107089758
Loss at iteration 1090 : 0.0001311441883444786
Loss at iteration 1100 : 0.00014375618775375187
Loss at iteration 1110 : 0.0019077014876529574
Loss at iteration 1120 : 8.982750296127051e-05
Loss at iteration 1130 : 0.00016118772327899933
Loss at iteration 1140 : 9.43846971495077e-05
Loss at iteration 1150 : 0.0039969552308321
Loss at iteration 1160 : 0.00010053798905573785
Loss at iteration 1170 : 0.0003903810866177082
Loss at iteration 1180 : 0.0030686568934470415
Loss at iteration 1190 : 0.00012980718747712672
Loss at iteration 1200 : 0.00011678111332003027
Loss at iteration 1210 : 8.556999819120392e-05
Loss at iteration 1220 : 0.0027500702999532223
Loss at iteration 1230 : 0.00017574938829056919
Loss at iteration 1240 : 0.0004918895429000258
Loss at iteration 1250 : 0.001300864270888269
Loss at iteration 1260 : 0.004272244870662689
Loss at iteration 1270 : 0.0018654256127774715
Loss at iteration 1280 : 0.00029612434445880353
Loss at iteration 1290 : 0.00012795094517059624
Loss at iteration 1300 : 0.00019902510393876582
Loss at iteration 1310 : 0.00010761729208752513
Loss at iteration 1320 : 0.0004408932290971279
Loss at iteration 1330 : 0.00015844099107198417
Loss at iteration 1340 : 0.000259121268754825
Loss at iteration 1350 : 0.0005235861171968281
Loss at iteration 1360 : 0.00023864489048719406
Loss at iteration 1370 : 0.00012464144674595445
Loss at iteration 1380 : 0.0009042960009537637
Loss at iteration 1390 : 0.00015924549370538443
Loss at iteration 1400 : 0.0008695923606865108
Loss at iteration 1410 : 0.0035120639950037003
Loss at iteration 1420 : 0.0012568552047014236
Loss at iteration 1430 : 0.000238424792769365
Loss at iteration 1440 : 5.085561133455485e-05
Loss at iteration 1450 : 0.00046205049147829413
Loss at iteration 1460 : 5.943542782915756e-05
Loss at iteration 1470 : 0.003763731336221099
Loss at iteration 1480 : 0.00017198520072270185
Loss at iteration 1490 : 0.00020518236851785332
Loss at iteration 1500 : 0.000681787496432662
Loss at iteration 1510 : 0.002098588040098548
Loss at iteration 1520 : 0.0003443018067628145
Loss at iteration 1530 : 0.0001777689903974533
Loss at iteration 1540 : 0.003078482346609235
Loss at iteration 1550 : 0.00056427315576002
Loss at iteration 1560 : 0.0007395113352686167
Loss at iteration 1570 : 0.00025445298524573445
Loss at iteration 1580 : 6.284641131060198e-05
Loss at iteration 1590 : 0.0001701832516118884
Loss at iteration 1600 : 0.0009339276002719998
Loss at iteration 1610 : 0.00022978504421189427
Loss at iteration 1620 : 0.0003809262707363814
Loss at iteration 1630 : 0.0017612832598388195
Loss at iteration 1640 : 0.002771132392808795
Loss at iteration 1650 : 0.000218477682210505
Loss at iteration 1660 : 0.00018553021072875708
Loss at iteration 1670 : 0.0005168712232261896
Loss at iteration 1680 : 0.003984550479799509
Loss at iteration 1690 : 0.0005400546942837536
Loss at iteration 1700 : 0.0008972275536507368
Loss at iteration 1710 : 0.0003056032001040876
Loss at iteration 1720 : 0.00014250277308747172
Loss at iteration 1730 : 0.002469670958817005
Loss at iteration 1740 : 4.808479206985794e-05
Loss at iteration 1750 : 0.002907478017732501
The SSIM Value is: 0.9861332904137179
The PSNR Value is: 46.28298233049031
the epoch is: 152
Loss at iteration 10 : 0.00037568650441244245
Loss at iteration 20 : 0.0002755296300165355
Loss at iteration 30 : 0.0019556069746613503
Loss at iteration 40 : 6.866540934424847e-05
Loss at iteration 50 : 0.0005118113476783037
Loss at iteration 60 : 0.00014374118472915143
Loss at iteration 70 : 4.584439375321381e-05
Loss at iteration 80 : 0.0020202877931296825
Loss at iteration 90 : 6.44351021037437e-05
Loss at iteration 100 : 0.0022621212992817163
Loss at iteration 110 : 7.657696551177651e-05
Loss at iteration 120 : 0.001962560461834073
Loss at iteration 130 : 0.0009237070917151868
Loss at iteration 140 : 0.00020658221910707653
Loss at iteration 150 : 7.365136116277426e-05
Loss at iteration 160 : 0.003004434984177351
Loss at iteration 170 : 6.817410758230835e-05
Loss at iteration 180 : 0.005723536014556885
Loss at iteration 190 : 0.0006809613551013172
Loss at iteration 200 : 0.0020987526513636112
Loss at iteration 210 : 0.001787017099559307
Loss at iteration 220 : 0.0003618374466896057
Loss at iteration 230 : 0.0001493602030677721
Loss at iteration 240 : 0.00031204428523778915
Loss at iteration 250 : 0.002339820610359311
Loss at iteration 260 : 9.447847696719691e-05
Loss at iteration 270 : 0.0021327068097889423
Loss at iteration 280 : 0.0013842590851709247
Loss at iteration 290 : 0.0020265912171453238
Loss at iteration 300 : 6.938321166671813e-05
Loss at iteration 310 : 0.004229564685374498
Loss at iteration 320 : 8.09604607638903e-05
Loss at iteration 330 : 8.629477815702558e-05
Loss at iteration 340 : 9.415662498213351e-05
Loss at iteration 350 : 0.0009581396006979048
Loss at iteration 360 : 0.000947805936448276
Loss at iteration 370 : 0.00029166703461669385
Loss at iteration 380 : 7.02386605553329e-05
Loss at iteration 390 : 9.150541154667735e-05
Loss at iteration 400 : 0.0001669917837716639
Loss at iteration 410 : 0.0008019972592592239
Loss at iteration 420 : 0.0008000487578101456
Loss at iteration 430 : 0.00036043490399606526
Loss at iteration 440 : 0.0006183846853673458
Loss at iteration 450 : 0.000380673271138221
Loss at iteration 460 : 0.0002155294205294922
Loss at iteration 470 : 0.0002135943650500849
Loss at iteration 480 : 0.0029033010359853506
Loss at iteration 490 : 0.00020659762958530337
Loss at iteration 500 : 0.0007354592671617866
Loss at iteration 510 : 0.00013445323565974832
Loss at iteration 520 : 0.00033459728001616895
Loss at iteration 530 : 0.00033390201861038804
Loss at iteration 540 : 0.0008496004156768322
Loss at iteration 550 : 0.0004804374766536057
Loss at iteration 560 : 0.00017152410873677582
Loss at iteration 570 : 0.00030523270834237337
Loss at iteration 580 : 9.086266800295562e-05
Loss at iteration 590 : 0.0005080723203718662
Loss at iteration 600 : 0.003862174926325679
Loss at iteration 610 : 0.00029956395155750215
Loss at iteration 620 : 0.00019322699517942965
Loss at iteration 630 : 0.0002940943231806159
Loss at iteration 640 : 0.0027891923673450947
Loss at iteration 650 : 0.00020928154117427766
Loss at iteration 660 : 0.00010735630348790437
Loss at iteration 670 : 0.00042599369771778584
Loss at iteration 680 : 0.0021144230850040913
Loss at iteration 690 : 0.00030877726385369897
Loss at iteration 700 : 0.0010668281465768814
Loss at iteration 710 : 0.0008584370370954275
Loss at iteration 720 : 0.0002861308748833835
Loss at iteration 730 : 0.0010228255996480584
Loss at iteration 740 : 0.00039400492096319795
Loss at iteration 750 : 0.0003750278556253761
Loss at iteration 760 : 0.001503744162619114
Loss at iteration 770 : 6.821048737037927e-05
Loss at iteration 780 : 9.911147208185866e-05
Loss at iteration 790 : 0.006609569303691387
Loss at iteration 800 : 0.002041161060333252
Loss at iteration 810 : 0.0006153935100883245
Loss at iteration 820 : 0.0005546726752072573
Loss at iteration 830 : 0.00023125983716454357
Loss at iteration 840 : 0.0006240788497962058
Loss at iteration 850 : 0.0004039530176669359
Loss at iteration 860 : 0.00012406842142809182
Loss at iteration 870 : 0.00016127194976434112
Loss at iteration 880 : 0.00032795051811262965
Loss at iteration 890 : 0.0008727913373149931
Loss at iteration 900 : 0.0036123653408139944
Loss at iteration 910 : 0.0029538555536419153
Loss at iteration 920 : 0.00011959444964304566
Loss at iteration 930 : 0.0005408735596574843
Loss at iteration 940 : 0.0006892342935316265
Loss at iteration 950 : 0.00024709629360586405
Loss at iteration 960 : 0.0003977819869760424
Loss at iteration 970 : 0.0004206690064165741
Loss at iteration 980 : 6.610168202314526e-05
Loss at iteration 990 : 8.955056546255946e-05
Loss at iteration 1000 : 0.002469163155183196
Loss at iteration 1010 : 0.00014127441681921482
Loss at iteration 1020 : 0.0002469021419528872
Loss at iteration 1030 : 0.00014871591702103615
Loss at iteration 1040 : 0.0006264137336984277
Loss at iteration 1050 : 0.0004965693806298077
Loss at iteration 1060 : 0.0007595393108204007
Loss at iteration 1070 : 0.00323408842086792
Loss at iteration 1080 : 0.0040681324899196625
Loss at iteration 1090 : 0.00015896474360488355
Loss at iteration 1100 : 0.00016134769248310477
Loss at iteration 1110 : 7.66265657148324e-05
Loss at iteration 1120 : 0.0005695322761312127
Loss at iteration 1130 : 0.00015811513003427535
Loss at iteration 1140 : 0.0008277875022031367
Loss at iteration 1150 : 8.551488281227648e-05
Loss at iteration 1160 : 0.0011745524825528264
Loss at iteration 1170 : 0.0004540880327112973
Loss at iteration 1180 : 0.0002661847975105047
Loss at iteration 1190 : 0.0007629362517036498
Loss at iteration 1200 : 0.00045134377432987094
Loss at iteration 1210 : 0.00022071589773986489
Loss at iteration 1220 : 0.0017309703398495913
Loss at iteration 1230 : 0.002373696072027087
Loss at iteration 1240 : 0.004169181454926729
Loss at iteration 1250 : 0.002974895993247628
Loss at iteration 1260 : 8.439772500423715e-05
Loss at iteration 1270 : 0.004689167253673077
Loss at iteration 1280 : 0.0018731052987277508
Loss at iteration 1290 : 0.0004051348951179534
Loss at iteration 1300 : 0.0004508014244493097
Loss at iteration 1310 : 0.00011095670924987644
Loss at iteration 1320 : 0.0005806030239909887
Loss at iteration 1330 : 0.00028711860068142414
Loss at iteration 1340 : 0.00029218618874438107
Loss at iteration 1350 : 0.00013509803102351725
Loss at iteration 1360 : 0.00013377299183048308
Loss at iteration 1370 : 0.0014027126599103212
Loss at iteration 1380 : 0.0004351608222350478
Loss at iteration 1390 : 0.0026139658875763416
Loss at iteration 1400 : 0.00013829846284352243
Loss at iteration 1410 : 0.00010556346387602389
Loss at iteration 1420 : 3.463387838564813e-05
Loss at iteration 1430 : 0.00024282149388454854
Loss at iteration 1440 : 0.0007609486347064376
Loss at iteration 1450 : 0.0021675119642168283
Loss at iteration 1460 : 9.285104897571728e-05
Loss at iteration 1470 : 0.004627415910363197
Loss at iteration 1480 : 0.0001563855039421469
Loss at iteration 1490 : 7.900132914073765e-05
Loss at iteration 1500 : 0.00038008790579624474
Loss at iteration 1510 : 0.00010442425991641358
Loss at iteration 1520 : 0.0004720889846794307
Loss at iteration 1530 : 0.000261045090155676
Loss at iteration 1540 : 0.006700553931295872
Loss at iteration 1550 : 0.0005258615128695965
Loss at iteration 1560 : 0.00012070486991433427
Loss at iteration 1570 : 0.000624395499471575
Loss at iteration 1580 : 0.000418747280491516
Loss at iteration 1590 : 6.61034500808455e-05
Loss at iteration 1600 : 0.0029447833076119423
Loss at iteration 1610 : 0.0017236582934856415
Loss at iteration 1620 : 0.002911799121648073
Loss at iteration 1630 : 0.0008776398608461022
Loss at iteration 1640 : 0.00010063578520203009
Loss at iteration 1650 : 0.0004569869488477707
Loss at iteration 1660 : 0.00016329705249518156
Loss at iteration 1670 : 0.00016470739501528442
Loss at iteration 1680 : 0.001145202200859785
Loss at iteration 1690 : 0.00024615516304038465
Loss at iteration 1700 : 0.0031458858866244555
Loss at iteration 1710 : 0.0022842504549771547
Loss at iteration 1720 : 0.0008171843946911395
Loss at iteration 1730 : 0.00016579116345383227
Loss at iteration 1740 : 4.726598126580939e-05
Loss at iteration 1750 : 0.0023090869653970003
The SSIM Value is: 0.9873173982561423
The PSNR Value is: 46.74509948780883
the epoch is: 153
Loss at iteration 10 : 0.00011598519631661475
Loss at iteration 20 : 6.449921056628227e-05
Loss at iteration 30 : 0.00014711296535097063
Loss at iteration 40 : 0.0011687134392559528
Loss at iteration 50 : 0.0013977362541481853
Loss at iteration 60 : 0.0011900881072506309
Loss at iteration 70 : 0.00016060852794907987
Loss at iteration 80 : 0.0002634515112731606
Loss at iteration 90 : 8.94967743079178e-05
Loss at iteration 100 : 0.00448785163462162
Loss at iteration 110 : 0.0004461301723495126
Loss at iteration 120 : 0.000690629065502435
Loss at iteration 130 : 0.0001460705534555018
Loss at iteration 140 : 0.00019597462960518897
Loss at iteration 150 : 0.0009646216640248895
Loss at iteration 160 : 0.0014348475961014628
Loss at iteration 170 : 5.5035805416991934e-05
Loss at iteration 180 : 0.000645466148853302
Loss at iteration 190 : 0.00015532589168287814
Loss at iteration 200 : 0.01117063220590353
Loss at iteration 210 : 6.713867333019152e-05
Loss at iteration 220 : 0.0001598698436282575
Loss at iteration 230 : 0.0008001304813660681
Loss at iteration 240 : 0.0009762747795321047
Loss at iteration 250 : 0.0010904170339927077
Loss at iteration 260 : 0.00017466639110352844
Loss at iteration 270 : 0.00034460952156223357
Loss at iteration 280 : 8.684294152772054e-05
Loss at iteration 290 : 5.271458940114826e-05
Loss at iteration 300 : 8.896447252482176e-05
Loss at iteration 310 : 8.693365816725418e-05
Loss at iteration 320 : 0.0002475049113854766
Loss at iteration 330 : 0.0001068499987013638
Loss at iteration 340 : 0.0006370511837303638
Loss at iteration 350 : 0.00037205847911536694
Loss at iteration 360 : 0.0024431515485048294
Loss at iteration 370 : 0.003017081879079342
Loss at iteration 380 : 0.00014085571456234902
Loss at iteration 390 : 0.0016162387328222394
Loss at iteration 400 : 0.00012673684977926314
Loss at iteration 410 : 0.0001724679459584877
Loss at iteration 420 : 0.0035833236761391163
Loss at iteration 430 : 0.0001788994122762233
Loss at iteration 440 : 0.0002810987352859229
Loss at iteration 450 : 0.0005640111048705876
Loss at iteration 460 : 0.0002300440100952983
Loss at iteration 470 : 0.00012753892224282026
Loss at iteration 480 : 0.002004251116886735
Loss at iteration 490 : 0.00022282473219092935
Loss at iteration 500 : 0.00016266325837932527
Loss at iteration 510 : 0.00017008138820528984
Loss at iteration 520 : 0.006519435904920101
Loss at iteration 530 : 0.0022574574686586857
Loss at iteration 540 : 0.0001034232263918966
Loss at iteration 550 : 0.00035276482230983675
Loss at iteration 560 : 0.0009278933284804225
Loss at iteration 570 : 0.0001915503671625629
Loss at iteration 580 : 0.001529002794995904
Loss at iteration 590 : 5.301991768646985e-05
Loss at iteration 600 : 0.002096370328217745
Loss at iteration 610 : 5.239797246758826e-05
Loss at iteration 620 : 0.00020379254419822246
Loss at iteration 630 : 0.00015870302740950137
Loss at iteration 640 : 0.0006760380347259343
Loss at iteration 650 : 0.000100667544757016
Loss at iteration 660 : 0.001283095683902502
Loss at iteration 670 : 7.859186735004187e-05
Loss at iteration 680 : 0.0001216152886627242
Loss at iteration 690 : 0.00044080731458961964
Loss at iteration 700 : 0.0005379289505071938
Loss at iteration 710 : 0.00012420064012985677
Loss at iteration 720 : 0.00011854887998197228
Loss at iteration 730 : 0.0016002459451556206
Loss at iteration 740 : 0.00017883772670757025
Loss at iteration 750 : 0.00015005205932538956
Loss at iteration 760 : 0.0001385851064696908
Loss at iteration 770 : 0.0019494891166687012
Loss at iteration 780 : 0.00042750636930577457
Loss at iteration 790 : 7.417458982672542e-05
Loss at iteration 800 : 0.0018230639398097992
Loss at iteration 810 : 0.00017094706709031016
Loss at iteration 820 : 0.00020153629884589463
Loss at iteration 830 : 0.0011044254060834646
Loss at iteration 840 : 0.0004424959188327193
Loss at iteration 850 : 8.516438538208604e-05
Loss at iteration 860 : 0.0032619712874293327
Loss at iteration 870 : 0.00010533669410506263
Loss at iteration 880 : 0.0022606742568314075
Loss at iteration 890 : 0.005981476046144962
Loss at iteration 900 : 0.0002651237300597131
Loss at iteration 910 : 0.00018859126430470496
Loss at iteration 920 : 0.00013345610932447016
Loss at iteration 930 : 0.0013369256630539894
Loss at iteration 940 : 0.0014186161570250988
Loss at iteration 950 : 0.0011236517457291484
Loss at iteration 960 : 0.0019168194849044085
Loss at iteration 970 : 0.0006030153599567711
Loss at iteration 980 : 0.0017751147970557213
Loss at iteration 990 : 0.00039961340371519327
Loss at iteration 1000 : 0.0001137102663051337
Loss at iteration 1010 : 0.0029564129654318094
Loss at iteration 1020 : 0.0001137915241997689
Loss at iteration 1030 : 8.206465281546116e-05
Loss at iteration 1040 : 0.00013004701759200543
Loss at iteration 1050 : 0.0027383186388760805
Loss at iteration 1060 : 0.0001066249969881028
Loss at iteration 1070 : 0.00018925695621874183
Loss at iteration 1080 : 9.998319001169875e-05
Loss at iteration 1090 : 0.003372387494891882
Loss at iteration 1100 : 9.615431918064132e-05
Loss at iteration 1110 : 0.0005400276277214289
Loss at iteration 1120 : 0.004281135275959969
Loss at iteration 1130 : 0.0011858005309477448
Loss at iteration 1140 : 0.0002492482017260045
Loss at iteration 1150 : 0.00018142684712074697
Loss at iteration 1160 : 0.0002435857168165967
Loss at iteration 1170 : 0.0001680048299022019
Loss at iteration 1180 : 0.001173586817458272
Loss at iteration 1190 : 0.002666930668056011
Loss at iteration 1200 : 0.0003771371266338974
Loss at iteration 1210 : 0.0008671831456013024
Loss at iteration 1220 : 0.004611739423125982
Loss at iteration 1230 : 0.0001292830565944314
Loss at iteration 1240 : 0.0003117446613032371
Loss at iteration 1250 : 0.0007514485041610897
Loss at iteration 1260 : 0.0018775064963847399
Loss at iteration 1270 : 0.0007251665811054409
Loss at iteration 1280 : 0.0021512198727577925
Loss at iteration 1290 : 0.001826689695008099
Loss at iteration 1300 : 0.001627220306545496
Loss at iteration 1310 : 0.0004189889004919678
Loss at iteration 1320 : 0.00046883017057552934
Loss at iteration 1330 : 0.0007489349227398634
Loss at iteration 1340 : 0.00026786173111759126
Loss at iteration 1350 : 0.005013158544898033
Loss at iteration 1360 : 9.485717600909993e-05
Loss at iteration 1370 : 0.0001708890195004642
Loss at iteration 1380 : 0.004495417233556509
Loss at iteration 1390 : 0.0006950317765586078
Loss at iteration 1400 : 0.002490330021828413
Loss at iteration 1410 : 0.0002858848311007023
Loss at iteration 1420 : 0.00019906848319806159
Loss at iteration 1430 : 0.0003972527920268476
Loss at iteration 1440 : 0.0001912178995553404
Loss at iteration 1450 : 0.0005814684554934502
Loss at iteration 1460 : 0.0011147670447826385
Loss at iteration 1470 : 0.00013345923798624426
Loss at iteration 1480 : 0.00017281828331761062
Loss at iteration 1490 : 0.0003142247151117772
Loss at iteration 1500 : 0.0007027437095530331
Loss at iteration 1510 : 0.002465919591486454
Loss at iteration 1520 : 0.0001899302442325279
Loss at iteration 1530 : 0.0001651909260544926
Loss at iteration 1540 : 0.00024860870325937867
Loss at iteration 1550 : 0.0001349149679299444
Loss at iteration 1560 : 0.00014310887490864843
Loss at iteration 1570 : 0.002365402178838849
Loss at iteration 1580 : 0.0010322333546355367
Loss at iteration 1590 : 0.000997055321931839
Loss at iteration 1600 : 0.005483426619321108
Loss at iteration 1610 : 0.0002092403738060966
Loss at iteration 1620 : 0.0003359051188454032
Loss at iteration 1630 : 0.004145484883338213
Loss at iteration 1640 : 0.00016623706324025989
Loss at iteration 1650 : 0.0002096570678986609
Loss at iteration 1660 : 0.00020973679784219712
Loss at iteration 1670 : 5.3974115871824324e-05
Loss at iteration 1680 : 0.00023302693443838507
Loss at iteration 1690 : 3.808386099990457e-05
Loss at iteration 1700 : 0.0006569905090145767
Loss at iteration 1710 : 7.862216443754733e-05
Loss at iteration 1720 : 0.0005965870805084705
Loss at iteration 1730 : 6.160613702377304e-05
Loss at iteration 1740 : 0.00016630205209366977
Loss at iteration 1750 : 8.928040915634483e-05
The SSIM Value is: 0.984230906558982
The PSNR Value is: 46.44556891235486
the epoch is: 154
Loss at iteration 10 : 0.00038153381319716573
Loss at iteration 20 : 0.002213712316006422
Loss at iteration 30 : 5.7275192375527695e-05
Loss at iteration 40 : 0.0006420784629881382
Loss at iteration 50 : 0.003059940179809928
Loss at iteration 60 : 0.00027135739219374955
Loss at iteration 70 : 7.528050628025085e-05
Loss at iteration 80 : 0.00010162790567846969
Loss at iteration 90 : 0.00012320323730818927
Loss at iteration 100 : 0.000725981721188873
Loss at iteration 110 : 0.00012118002632632852
Loss at iteration 120 : 0.001618686132133007
Loss at iteration 130 : 7.838727469788864e-05
Loss at iteration 140 : 0.0019083336228504777
Loss at iteration 150 : 0.00011806149268522859
Loss at iteration 160 : 0.0002929221955128014
Loss at iteration 170 : 0.0005190535448491573
Loss at iteration 180 : 0.00011372558219591156
Loss at iteration 190 : 0.005243857391178608
Loss at iteration 200 : 0.00026627659099176526
Loss at iteration 210 : 0.0005052539054304361
Loss at iteration 220 : 0.00012193182192277163
Loss at iteration 230 : 0.0002845781564246863
Loss at iteration 240 : 9.698845678940415e-05
Loss at iteration 250 : 0.0006669026333838701
Loss at iteration 260 : 0.00027870648773387074
Loss at iteration 270 : 0.0028942993376404047
Loss at iteration 280 : 0.0007283531595021486
Loss at iteration 290 : 6.645463145105168e-05
Loss at iteration 300 : 0.0026879156939685345
Loss at iteration 310 : 0.0005798734491690993
Loss at iteration 320 : 0.0022873778361827135
Loss at iteration 330 : 0.0001670791971264407
Loss at iteration 340 : 0.00017859457875601947
Loss at iteration 350 : 0.00025792146334424615
Loss at iteration 360 : 0.0008637578575871885
Loss at iteration 370 : 0.0024832296185195446
Loss at iteration 380 : 0.002392901573330164
Loss at iteration 390 : 0.002504962030798197
Loss at iteration 400 : 6.203226803336293e-05
Loss at iteration 410 : 0.00010174170893151313
Loss at iteration 420 : 5.262477134237997e-05
Loss at iteration 430 : 0.00037879901356063783
Loss at iteration 440 : 0.0006925222696736455
Loss at iteration 450 : 0.0031096255406737328
Loss at iteration 460 : 0.0008321731584146619
Loss at iteration 470 : 0.000885171233676374
Loss at iteration 480 : 0.000531703932210803
Loss at iteration 490 : 0.00033128977520391345
Loss at iteration 500 : 0.00012167118984507397
Loss at iteration 510 : 0.003345596371218562
Loss at iteration 520 : 0.00016370606317650527
Loss at iteration 530 : 0.001983317546546459
Loss at iteration 540 : 0.0014637396670877934
Loss at iteration 550 : 7.200605614343658e-05
Loss at iteration 560 : 0.001340891933068633
Loss at iteration 570 : 0.000782828195951879
Loss at iteration 580 : 0.00021990499226376414
Loss at iteration 590 : 0.0002983507583849132
Loss at iteration 600 : 0.00018993006960954517
Loss at iteration 610 : 0.00062146334676072
Loss at iteration 620 : 0.00017337434110231698
Loss at iteration 630 : 0.0002142865996574983
Loss at iteration 640 : 0.001376740518026054
Loss at iteration 650 : 0.0011446091812103987
Loss at iteration 660 : 0.0002755852183327079
Loss at iteration 670 : 0.001759771490469575
Loss at iteration 680 : 0.00022733530204277486
Loss at iteration 690 : 0.002581213368102908
Loss at iteration 700 : 0.00022515833552461118
Loss at iteration 710 : 0.0002637420839164406
Loss at iteration 720 : 6.52190501568839e-05
Loss at iteration 730 : 0.0003484060289338231
Loss at iteration 740 : 0.000904023356270045
Loss at iteration 750 : 0.0001396682346239686
Loss at iteration 760 : 0.0022058961912989616
Loss at iteration 770 : 0.0004986950079910457
Loss at iteration 780 : 0.0008100882405415177
Loss at iteration 790 : 0.0005708709941245615
Loss at iteration 800 : 0.00010590955935185775
Loss at iteration 810 : 7.096774788806215e-05
Loss at iteration 820 : 0.0010366432834416628
Loss at iteration 830 : 0.005639318376779556
Loss at iteration 840 : 0.00021728946012444794
Loss at iteration 850 : 0.00013522771769203246
Loss at iteration 860 : 0.00011302015627734363
Loss at iteration 870 : 0.0003489168593659997
Loss at iteration 880 : 0.0002458880189806223
Loss at iteration 890 : 6.704812403768301e-05
Loss at iteration 900 : 0.0005087211611680686
Loss at iteration 910 : 0.0038315041456371546
Loss at iteration 920 : 0.0035967445001006126
Loss at iteration 930 : 0.0004590811440721154
Loss at iteration 940 : 0.0016652527265250683
Loss at iteration 950 : 0.001788969966582954
Loss at iteration 960 : 0.0003129323595203459
Loss at iteration 970 : 0.0002577345003373921
Loss at iteration 980 : 0.0005053570494055748
Loss at iteration 990 : 0.001946793869137764
Loss at iteration 1000 : 0.0028195360209792852
Loss at iteration 1010 : 0.002166006714105606
Loss at iteration 1020 : 9.729373414302245e-05
Loss at iteration 1030 : 0.0020790155977010727
Loss at iteration 1040 : 0.00037950719706714153
Loss at iteration 1050 : 0.00041193622746504843
Loss at iteration 1060 : 3.6632100091082975e-05
Loss at iteration 1070 : 0.0002861464163288474
Loss at iteration 1080 : 0.0006359300459735096
Loss at iteration 1090 : 0.004016607999801636
Loss at iteration 1100 : 8.3789651398547e-05
Loss at iteration 1110 : 0.00024966441560536623
Loss at iteration 1120 : 0.00471927085891366
Loss at iteration 1130 : 0.0002005162532441318
Loss at iteration 1140 : 0.00033137411810457706
Loss at iteration 1150 : 0.004508484620600939
Loss at iteration 1160 : 0.0006303004920482635
Loss at iteration 1170 : 9.66326188063249e-05
Loss at iteration 1180 : 0.0006128329550847411
Loss at iteration 1190 : 0.000171261650393717
Loss at iteration 1200 : 0.00010531449515838176
Loss at iteration 1210 : 9.575250442139804e-05
Loss at iteration 1220 : 0.001675126375630498
Loss at iteration 1230 : 0.0010314497631043196
Loss at iteration 1240 : 0.00019485462689772248
Loss at iteration 1250 : 0.0005566290928982198
Loss at iteration 1260 : 4.36057016486302e-05
Loss at iteration 1270 : 0.00021872457000426948
Loss at iteration 1280 : 0.00029504747362807393
Loss at iteration 1290 : 0.0009306257124990225
Loss at iteration 1300 : 0.0004534380859695375
Loss at iteration 1310 : 0.0004155047645326704
Loss at iteration 1320 : 0.00019895803416147828
Loss at iteration 1330 : 0.002337244339287281
Loss at iteration 1340 : 0.002185970079153776
Loss at iteration 1350 : 0.00025020618340931833
Loss at iteration 1360 : 0.00023845004034228623
Loss at iteration 1370 : 0.00010568510333541781
Loss at iteration 1380 : 0.00012105116911698133
Loss at iteration 1390 : 0.000422040990088135
Loss at iteration 1400 : 0.0001003466168185696
Loss at iteration 1410 : 0.00013731644139625132
Loss at iteration 1420 : 0.00011414203618187457
Loss at iteration 1430 : 0.00013153866166248918
Loss at iteration 1440 : 0.0020672795362770557
Loss at iteration 1450 : 0.00024127919459715486
Loss at iteration 1460 : 0.0005077593377791345
Loss at iteration 1470 : 0.00014901194663252681
Loss at iteration 1480 : 0.000692316796630621
Loss at iteration 1490 : 0.0008934013894759119
Loss at iteration 1500 : 0.0001434198347851634
Loss at iteration 1510 : 0.0018740282393991947
Loss at iteration 1520 : 0.00013460221816785634
Loss at iteration 1530 : 0.0033422873821109533
Loss at iteration 1540 : 6.890529039083049e-05
Loss at iteration 1550 : 0.0001713313249638304
Loss at iteration 1560 : 0.0002938215038739145
Loss at iteration 1570 : 0.0007235533557832241
Loss at iteration 1580 : 0.00015867565525695682
Loss at iteration 1590 : 0.0005044498248025775
Loss at iteration 1600 : 0.0034600968938320875
Loss at iteration 1610 : 0.00016771291848272085
Loss at iteration 1620 : 0.00167393172159791
Loss at iteration 1630 : 0.0012538076844066381
Loss at iteration 1640 : 0.00027441358543001115
Loss at iteration 1650 : 0.0029088256414979696
Loss at iteration 1660 : 0.00010580438538454473
Loss at iteration 1670 : 0.00022541469661518931
Loss at iteration 1680 : 0.00014981490676291287
Loss at iteration 1690 : 0.0031990166753530502
Loss at iteration 1700 : 9.345552825834602e-05
Loss at iteration 1710 : 0.0006407545879483223
Loss at iteration 1720 : 0.0005708873504772782
Loss at iteration 1730 : 0.000373085931641981
Loss at iteration 1740 : 0.0001380983303533867
Loss at iteration 1750 : 0.000321878440445289
The SSIM Value is: 0.9876593663829014
The PSNR Value is: 46.582377984135164
the epoch is: 155
Loss at iteration 10 : 0.0001227001048391685
Loss at iteration 20 : 3.9919679693412036e-05
Loss at iteration 30 : 0.0007283828454092145
Loss at iteration 40 : 0.0002052878262475133
Loss at iteration 50 : 0.00011827539128717035
Loss at iteration 60 : 0.005329003091901541
Loss at iteration 70 : 0.0005337990587577224
Loss at iteration 80 : 0.0003744764835573733
Loss at iteration 90 : 0.0021935380063951015
Loss at iteration 100 : 0.001781719853170216
Loss at iteration 110 : 0.00034603505628183484
Loss at iteration 120 : 0.0017928325105458498
Loss at iteration 130 : 0.0032334437128156424
Loss at iteration 140 : 0.0005073547945357859
Loss at iteration 150 : 0.0004222129937261343
Loss at iteration 160 : 0.0003201316576451063
Loss at iteration 170 : 0.00017573114018887281
Loss at iteration 180 : 7.158519292715937e-05
Loss at iteration 190 : 0.00013106019468978047
Loss at iteration 200 : 0.0016165530541911721
Loss at iteration 210 : 0.0021025706082582474
Loss at iteration 220 : 0.0012793057831004262
Loss at iteration 230 : 0.0001484000968048349
Loss at iteration 240 : 0.0002059452817775309
Loss at iteration 250 : 0.00012530178355518728
Loss at iteration 260 : 0.000585904170293361
Loss at iteration 270 : 0.00026630147476680577
Loss at iteration 280 : 0.00016525712271686643
Loss at iteration 290 : 0.0014279182069003582
Loss at iteration 300 : 0.0004999955417588353
Loss at iteration 310 : 0.00013361414312385023
Loss at iteration 320 : 0.0015487131895497441
Loss at iteration 330 : 8.865727431839332e-05
Loss at iteration 340 : 0.00012448508641682565
Loss at iteration 350 : 6.0105106967967004e-05
Loss at iteration 360 : 0.0006571218254975975
Loss at iteration 370 : 0.002394481562077999
Loss at iteration 380 : 0.0014707559021189809
Loss at iteration 390 : 0.0001256994582945481
Loss at iteration 400 : 0.00114866578951478
Loss at iteration 410 : 0.00020669979858212173
Loss at iteration 420 : 0.0001189972463180311
Loss at iteration 430 : 0.00024755962658673525
Loss at iteration 440 : 0.00015857024118304253
Loss at iteration 450 : 0.0014709453098475933
Loss at iteration 460 : 5.3455667512025684e-05
Loss at iteration 470 : 0.0003463459142949432
Loss at iteration 480 : 0.0024586552754044533
Loss at iteration 490 : 0.0002982456353493035
Loss at iteration 500 : 0.003250187961384654
Loss at iteration 510 : 0.00035963772097602487
Loss at iteration 520 : 0.00010396634752396494
Loss at iteration 530 : 0.0001567015133332461
Loss at iteration 540 : 0.0006846801261417568
Loss at iteration 550 : 0.00031791391666047275
Loss at iteration 560 : 0.0034379453863948584
Loss at iteration 570 : 0.00044204556616023183
Loss at iteration 580 : 0.0006292503676377237
Loss at iteration 590 : 9.552094707032666e-05
Loss at iteration 600 : 9.557232988299802e-05
Loss at iteration 610 : 0.0001894331508083269
Loss at iteration 620 : 0.0004165021819062531
Loss at iteration 630 : 0.00010196309449383989
Loss at iteration 640 : 0.00026510594761930406
Loss at iteration 650 : 0.0002469215833116323
Loss at iteration 660 : 0.00020009058061987162
Loss at iteration 670 : 0.0005772215081378818
Loss at iteration 680 : 0.0005206394707784057
Loss at iteration 690 : 0.0006228382117114961
Loss at iteration 700 : 0.005927638150751591
Loss at iteration 710 : 9.091315587284043e-05
Loss at iteration 720 : 0.0001338849833700806
Loss at iteration 730 : 0.0019380354788154364
Loss at iteration 740 : 0.0005913372151553631
Loss at iteration 750 : 0.00016005650104489177
Loss at iteration 760 : 0.0030644196085631847
Loss at iteration 770 : 0.00016286956088151783
Loss at iteration 780 : 0.0029194988310337067
Loss at iteration 790 : 0.0001172507181763649
Loss at iteration 800 : 0.0006239535287022591
Loss at iteration 810 : 0.0015601147897541523
Loss at iteration 820 : 0.0015792608028277755
Loss at iteration 830 : 0.00022373255342245102
Loss at iteration 840 : 0.0019214432686567307
Loss at iteration 850 : 0.00013035378651693463
Loss at iteration 860 : 0.0004717981209978461
Loss at iteration 870 : 0.0005950778140686452
Loss at iteration 880 : 0.00021478295093402267
Loss at iteration 890 : 0.00032881711376830935
Loss at iteration 900 : 0.0003604062949307263
Loss at iteration 910 : 8.557969704270363e-05
Loss at iteration 920 : 0.0023560894187539816
Loss at iteration 930 : 0.00027522019809111953
Loss at iteration 940 : 0.0007122180541045964
Loss at iteration 950 : 0.0002633600670378655
Loss at iteration 960 : 0.0031326685566455126
Loss at iteration 970 : 4.7441135393455625e-05
Loss at iteration 980 : 0.00022600116790272295
Loss at iteration 990 : 0.0005049555329605937
Loss at iteration 1000 : 0.00015774791245348752
Loss at iteration 1010 : 0.00014395792095456272
Loss at iteration 1020 : 0.0002634736883919686
Loss at iteration 1030 : 0.0001965010305866599
Loss at iteration 1040 : 0.0004058915073983371
Loss at iteration 1050 : 4.8548270569881424e-05
Loss at iteration 1060 : 0.0038275739643722773
Loss at iteration 1070 : 5.6867800594773144e-05
Loss at iteration 1080 : 0.00027179194148629904
Loss at iteration 1090 : 0.0005178971914574504
Loss at iteration 1100 : 0.00015033531235530972
Loss at iteration 1110 : 0.00010061401553684846
Loss at iteration 1120 : 0.0001343298063147813
Loss at iteration 1130 : 0.00014200806617736816
Loss at iteration 1140 : 0.00010754667164292186
Loss at iteration 1150 : 0.0006160452030599117
Loss at iteration 1160 : 0.0026586786843836308
Loss at iteration 1170 : 0.0003414769016671926
Loss at iteration 1180 : 0.00017546351591590792
Loss at iteration 1190 : 0.00023243206669576466
Loss at iteration 1200 : 0.000667500018607825
Loss at iteration 1210 : 7.258634286699817e-05
Loss at iteration 1220 : 0.0002411464520264417
Loss at iteration 1230 : 0.0003823090810328722
Loss at iteration 1240 : 0.00022457476006820798
Loss at iteration 1250 : 0.0021177411545068026
Loss at iteration 1260 : 0.00011109554179711267
Loss at iteration 1270 : 0.0002095955132972449
Loss at iteration 1280 : 0.0013712253421545029
Loss at iteration 1290 : 0.005168374627828598
Loss at iteration 1300 : 0.005241308361291885
Loss at iteration 1310 : 0.0002709974942263216
Loss at iteration 1320 : 0.00011817417544079944
Loss at iteration 1330 : 0.0003215756732970476
Loss at iteration 1340 : 0.002248098375275731
Loss at iteration 1350 : 7.19092640792951e-05
Loss at iteration 1360 : 0.002039666287600994
Loss at iteration 1370 : 4.701366196968593e-05
Loss at iteration 1380 : 0.00024983868934214115
Loss at iteration 1390 : 0.00010823694174177945
Loss at iteration 1400 : 5.591205263044685e-05
Loss at iteration 1410 : 0.00013003520143684
Loss at iteration 1420 : 0.005820279475301504
Loss at iteration 1430 : 5.1285827794345096e-05
Loss at iteration 1440 : 0.0007937790942378342
Loss at iteration 1450 : 0.0004046136455144733
Loss at iteration 1460 : 0.00021882141300011426
Loss at iteration 1470 : 0.00021937651035841554
Loss at iteration 1480 : 5.9390840760897845e-05
Loss at iteration 1490 : 0.0004351072129793465
Loss at iteration 1500 : 0.002067367546260357
Loss at iteration 1510 : 0.0006542968330904841
Loss at iteration 1520 : 0.00013710453640669584
Loss at iteration 1530 : 0.00026217481354251504
Loss at iteration 1540 : 0.00029980213730596006
Loss at iteration 1550 : 9.728898294270039e-05
Loss at iteration 1560 : 0.00017610265058465302
Loss at iteration 1570 : 0.0008150055073201656
Loss at iteration 1580 : 0.00019753174274228513
Loss at iteration 1590 : 0.00017129369371104985
Loss at iteration 1600 : 0.00025049466057680547
Loss at iteration 1610 : 6.280952948145568e-05
Loss at iteration 1620 : 0.001702223438769579
Loss at iteration 1630 : 0.0018102957401424646
Loss at iteration 1640 : 0.00018071159138344228
Loss at iteration 1650 : 0.00036323731183074415
Loss at iteration 1660 : 0.0011061008553951979
Loss at iteration 1670 : 0.000528650009073317
Loss at iteration 1680 : 0.0005631313542835414
Loss at iteration 1690 : 0.00019497238099575043
Loss at iteration 1700 : 0.00471870880573988
Loss at iteration 1710 : 0.0052612763829529285
Loss at iteration 1720 : 0.004944106563925743
Loss at iteration 1730 : 0.0002114855742547661
Loss at iteration 1740 : 0.00033051357604563236
Loss at iteration 1750 : 0.0002031883632298559
The SSIM Value is: 0.9892201508982066
The PSNR Value is: 46.75232788539668
the epoch is: 156
Loss at iteration 10 : 7.621461554663256e-05
Loss at iteration 20 : 8.184766193153337e-05
Loss at iteration 30 : 0.00013864177162759006
Loss at iteration 40 : 0.0019203416304662824
Loss at iteration 50 : 0.00028327220934443176
Loss at iteration 60 : 0.0017429596045985818
Loss at iteration 70 : 0.00017565702728461474
Loss at iteration 80 : 0.004924158100038767
Loss at iteration 90 : 0.002538838889449835
Loss at iteration 100 : 0.00021661838400177658
Loss at iteration 110 : 0.0031157617922872305
Loss at iteration 120 : 0.0003187118854839355
Loss at iteration 130 : 0.00014532874047290534
Loss at iteration 140 : 0.00013352406676858664
Loss at iteration 150 : 0.0003455073747318238
Loss at iteration 160 : 7.431181438732892e-05
Loss at iteration 170 : 0.00013664142170455307
Loss at iteration 180 : 0.00021024160378146917
Loss at iteration 190 : 0.001907121972180903
Loss at iteration 200 : 0.0005394652835093439
Loss at iteration 210 : 0.0005566597683355212
Loss at iteration 220 : 0.0002553024096414447
Loss at iteration 230 : 0.00017666385974735022
Loss at iteration 240 : 0.0006890394724905491
Loss at iteration 250 : 0.002672438742592931
Loss at iteration 260 : 0.0028340816497802734
Loss at iteration 270 : 0.00011123251169919968
Loss at iteration 280 : 0.0014062135014683008
Loss at iteration 290 : 0.0007710776990279555
Loss at iteration 300 : 0.00030461399001069367
Loss at iteration 310 : 0.002141390461474657
Loss at iteration 320 : 9.853513620328158e-05
Loss at iteration 330 : 0.000257030624197796
Loss at iteration 340 : 0.000122719444334507
Loss at iteration 350 : 0.0017811836441978812
Loss at iteration 360 : 0.00025203649420291185
Loss at iteration 370 : 0.0028530817944556475
Loss at iteration 380 : 0.00028785705217160285
Loss at iteration 390 : 0.0009906408376991749
Loss at iteration 400 : 0.0005308785475790501
Loss at iteration 410 : 0.0011747783282771707
Loss at iteration 420 : 0.00013661038246937096
Loss at iteration 430 : 8.275727304862812e-05
Loss at iteration 440 : 0.00012367758608888835
Loss at iteration 450 : 0.002019464736804366
Loss at iteration 460 : 0.0034822726156562567
Loss at iteration 470 : 0.00013509736163541675
Loss at iteration 480 : 0.00017635064432397485
Loss at iteration 490 : 0.00023532133491244167
Loss at iteration 500 : 0.005934382323175669
Loss at iteration 510 : 0.00025133031886070967
Loss at iteration 520 : 0.0006037216517142951
Loss at iteration 530 : 5.210178278503008e-05
Loss at iteration 540 : 0.0029594190418720245
Loss at iteration 550 : 0.0036490121856331825
Loss at iteration 560 : 0.00018296990310773253
Loss at iteration 570 : 0.000803247676230967
Loss at iteration 580 : 7.807356450939551e-05
Loss at iteration 590 : 0.0015417739050462842
Loss at iteration 600 : 0.0018952222308143973
Loss at iteration 610 : 9.365410369355232e-05
Loss at iteration 620 : 0.0032463613897562027
Loss at iteration 630 : 0.00010007424134528264
Loss at iteration 640 : 0.00010523434320930392
Loss at iteration 650 : 0.00011146296310471371
Loss at iteration 660 : 0.00017605228640604764
Loss at iteration 670 : 0.002111034234985709
Loss at iteration 680 : 0.0004886867245659232
Loss at iteration 690 : 8.72629025252536e-05
Loss at iteration 700 : 0.0002171076339436695
Loss at iteration 710 : 9.57033917075023e-05
Loss at iteration 720 : 8.348978008143604e-05
Loss at iteration 730 : 0.00025396610726602376
Loss at iteration 740 : 0.0038291309028863907
Loss at iteration 750 : 0.0036402957048267126
Loss at iteration 760 : 0.0004257239925209433
Loss at iteration 770 : 0.002141726203262806
Loss at iteration 780 : 0.00020186550682410598
Loss at iteration 790 : 0.00011418985377531499
Loss at iteration 800 : 0.0030680426862090826
Loss at iteration 810 : 0.00010746628686320037
Loss at iteration 820 : 0.0005199004663154483
Loss at iteration 830 : 0.0033603045158088207
Loss at iteration 840 : 0.0004027020186185837
Loss at iteration 850 : 0.0001763955078786239
Loss at iteration 860 : 0.0020889868028461933
Loss at iteration 870 : 0.00022932581487111747
Loss at iteration 880 : 0.001431226497516036
Loss at iteration 890 : 0.0004925566609017551
Loss at iteration 900 : 0.0002363259845878929
Loss at iteration 910 : 0.00010219048999715596
Loss at iteration 920 : 0.0006613983423449099
Loss at iteration 930 : 0.0012208556290715933
Loss at iteration 940 : 8.26688192319125e-05
Loss at iteration 950 : 0.0027764823753386736
Loss at iteration 960 : 9.958325972547755e-05
Loss at iteration 970 : 0.0007606901926919818
Loss at iteration 980 : 0.0010393860284239054
Loss at iteration 990 : 0.000872813630849123
Loss at iteration 1000 : 0.00010543798271100968
Loss at iteration 1010 : 0.00024775831843726337
Loss at iteration 1020 : 0.0028190596494823694
Loss at iteration 1030 : 0.004937552846968174
Loss at iteration 1040 : 0.00038776465225964785
Loss at iteration 1050 : 0.00012996423174627125
Loss at iteration 1060 : 0.0007171033066697419
Loss at iteration 1070 : 0.0002176624839194119
Loss at iteration 1080 : 0.0026229533832520247
Loss at iteration 1090 : 0.0008998312405310571
Loss at iteration 1100 : 0.003081990173086524
Loss at iteration 1110 : 0.0002381475642323494
Loss at iteration 1120 : 0.00017801107605919242
Loss at iteration 1130 : 0.0011335494928061962
Loss at iteration 1140 : 0.0001142694236477837
Loss at iteration 1150 : 0.0006528892554342747
Loss at iteration 1160 : 0.0001898652990348637
Loss at iteration 1170 : 0.0002696565061341971
Loss at iteration 1180 : 3.54616749973502e-05
Loss at iteration 1190 : 0.00016152020543813705
Loss at iteration 1200 : 0.00029139863909222186
Loss at iteration 1210 : 0.00018941040616482496
Loss at iteration 1220 : 0.0005929378676228225
Loss at iteration 1230 : 0.0003932179824914783
Loss at iteration 1240 : 0.0002955155214294791
Loss at iteration 1250 : 2.1115234630997293e-05
Loss at iteration 1260 : 0.0018599843606352806
Loss at iteration 1270 : 0.000667132786475122
Loss at iteration 1280 : 0.00016290450002998114
Loss at iteration 1290 : 0.0019465566147118807
Loss at iteration 1300 : 0.005197713151574135
Loss at iteration 1310 : 0.00095562037313357
Loss at iteration 1320 : 0.00025796968839131296
Loss at iteration 1330 : 0.00018654628365766257
Loss at iteration 1340 : 0.0021140282042324543
Loss at iteration 1350 : 0.00014972286589909345
Loss at iteration 1360 : 0.0003713258483912796
Loss at iteration 1370 : 4.4966764107812196e-05
Loss at iteration 1380 : 6.568451499333605e-05
Loss at iteration 1390 : 0.0002107216278091073
Loss at iteration 1400 : 0.0003622574149630964
Loss at iteration 1410 : 0.0002442917611915618
Loss at iteration 1420 : 6.086998473620042e-05
Loss at iteration 1430 : 0.0004168740415479988
Loss at iteration 1440 : 0.00011535041267052293
Loss at iteration 1450 : 0.0005520294071175158
Loss at iteration 1460 : 0.00030016229720786214
Loss at iteration 1470 : 0.006092632655054331
Loss at iteration 1480 : 0.0015013450756669044
Loss at iteration 1490 : 0.004115935415029526
Loss at iteration 1500 : 0.0036203910131007433
Loss at iteration 1510 : 0.007871575653553009
Loss at iteration 1520 : 0.0006490881787613034
Loss at iteration 1530 : 0.00021138037845958024
Loss at iteration 1540 : 0.0007100087241269648
Loss at iteration 1550 : 0.0004269201890565455
Loss at iteration 1560 : 0.00013046848471276462
Loss at iteration 1570 : 0.0014566169120371342
Loss at iteration 1580 : 0.0007655646186321974
Loss at iteration 1590 : 0.0002176411508116871
Loss at iteration 1600 : 0.004996215458959341
Loss at iteration 1610 : 0.00019400336896069348
Loss at iteration 1620 : 0.0015863071894273162
Loss at iteration 1630 : 0.00014553259825333953
Loss at iteration 1640 : 0.00278266123495996
Loss at iteration 1650 : 0.0018478333950042725
Loss at iteration 1660 : 0.0005839681252837181
Loss at iteration 1670 : 0.0025316597893834114
Loss at iteration 1680 : 0.0006120787584222853
Loss at iteration 1690 : 0.0002189613733207807
Loss at iteration 1700 : 0.0017590825445950031
Loss at iteration 1710 : 5.1269780669827014e-05
Loss at iteration 1720 : 0.0005414830520749092
Loss at iteration 1730 : 0.0013836086727678776
Loss at iteration 1740 : 8.448808512184769e-05
Loss at iteration 1750 : 0.000424681871663779
The SSIM Value is: 0.9848107597113706
The PSNR Value is: 46.32317346833351
the epoch is: 157
Loss at iteration 10 : 0.0007905524107627571
Loss at iteration 20 : 0.0001433867000741884
Loss at iteration 30 : 0.0004672195063903928
Loss at iteration 40 : 0.0015432463260367513
Loss at iteration 50 : 0.0005038660019636154
Loss at iteration 60 : 0.000439498049672693
Loss at iteration 70 : 0.0002452199987601489
Loss at iteration 80 : 0.004702980630099773
Loss at iteration 90 : 0.0010340965818613768
Loss at iteration 100 : 0.0007264465093612671
Loss at iteration 110 : 0.0009572501294314861
Loss at iteration 120 : 8.75464320415631e-05
Loss at iteration 130 : 0.0016686484450474381
Loss at iteration 140 : 0.0015443332958966494
Loss at iteration 150 : 0.0007463893271051347
Loss at iteration 160 : 0.0009680393268354237
Loss at iteration 170 : 0.0001762847532518208
Loss at iteration 180 : 0.0001943272800417617
Loss at iteration 190 : 0.0005329794366843998
Loss at iteration 200 : 7.763956091366708e-05
Loss at iteration 210 : 0.001159714418463409
Loss at iteration 220 : 0.00017536940868012607
Loss at iteration 230 : 0.002644533524289727
Loss at iteration 240 : 0.00871509499847889
Loss at iteration 250 : 0.0002382748934905976
Loss at iteration 260 : 0.00039181046304292977
Loss at iteration 270 : 0.00014323304640129209
Loss at iteration 280 : 0.00010788614599732682
Loss at iteration 290 : 0.0006611319840885699
Loss at iteration 300 : 0.0037305140867829323
Loss at iteration 310 : 0.0004303856985643506
Loss at iteration 320 : 0.00041415277519263327
Loss at iteration 330 : 0.0001733989192871377
Loss at iteration 340 : 0.0023267692886292934
Loss at iteration 350 : 0.00013996695633977652
Loss at iteration 360 : 7.714873208897188e-05
Loss at iteration 370 : 9.950055391527712e-05
Loss at iteration 380 : 0.0001493414893047884
Loss at iteration 390 : 0.002754395827651024
Loss at iteration 400 : 0.0024155157152563334
Loss at iteration 410 : 0.0003802970750257373
Loss at iteration 420 : 0.0011429894948378205
Loss at iteration 430 : 0.0001151312462752685
Loss at iteration 440 : 0.00020991035853512585
Loss at iteration 450 : 0.0004263485607225448
Loss at iteration 460 : 0.00021598610328510404
Loss at iteration 470 : 0.0013550447765737772
Loss at iteration 480 : 0.0006181187927722931
Loss at iteration 490 : 0.0028731082566082478
Loss at iteration 500 : 0.00039233837742358446
Loss at iteration 510 : 0.0002511924831196666
Loss at iteration 520 : 0.00020363755174912512
Loss at iteration 530 : 0.002650747075676918
Loss at iteration 540 : 0.004290634300559759
Loss at iteration 550 : 0.005567257758229971
Loss at iteration 560 : 0.00026790358242578804
Loss at iteration 570 : 0.0004316446138545871
Loss at iteration 580 : 0.0016052296850830317
Loss at iteration 590 : 0.0036512340884655714
Loss at iteration 600 : 0.0007708320626989007
Loss at iteration 610 : 0.0005568919004872441
Loss at iteration 620 : 0.00041384290670976043
Loss at iteration 630 : 0.00014138460392132401
Loss at iteration 640 : 0.00013309578935150057
Loss at iteration 650 : 0.0005109492340125144
Loss at iteration 660 : 0.0008568427292630076
Loss at iteration 670 : 0.00024803768610581756
Loss at iteration 680 : 0.0003562967758625746
Loss at iteration 690 : 0.0059636556543409824
Loss at iteration 700 : 0.0004805955686606467
Loss at iteration 710 : 0.000568556017242372
Loss at iteration 720 : 0.0003691047022584826
Loss at iteration 730 : 7.749101496301591e-05
Loss at iteration 740 : 0.00023378754849545658
Loss at iteration 750 : 0.0036705562379211187
Loss at iteration 760 : 5.655179120367393e-05
Loss at iteration 770 : 0.0012389315525069833
Loss at iteration 780 : 0.0002466151781845838
Loss at iteration 790 : 0.00023669989604968578
Loss at iteration 800 : 4.508179335971363e-05
Loss at iteration 810 : 0.001794641138985753
Loss at iteration 820 : 6.704658881062642e-05
Loss at iteration 830 : 0.00011481383262434974
Loss at iteration 840 : 0.0001884950906969607
Loss at iteration 850 : 0.0004237767425365746
Loss at iteration 860 : 0.006978335324674845
Loss at iteration 870 : 0.0034678324591368437
Loss at iteration 880 : 0.00023754900030326098
Loss at iteration 890 : 0.00029238846036605537
Loss at iteration 900 : 0.00013762156595475972
Loss at iteration 910 : 0.00015634814917575568
Loss at iteration 920 : 0.001125581213273108
Loss at iteration 930 : 0.0009429611964151263
Loss at iteration 940 : 0.0025419830344617367
Loss at iteration 950 : 0.00027440639678388834
Loss at iteration 960 : 0.0003119774628430605
Loss at iteration 970 : 0.0001726947957649827
Loss at iteration 980 : 0.00031381106236949563
Loss at iteration 990 : 5.649641389027238e-05
Loss at iteration 1000 : 0.00025670265313237906
Loss at iteration 1010 : 0.0005747376708313823
Loss at iteration 1020 : 0.004150642082095146
Loss at iteration 1030 : 0.00022586130944546312
Loss at iteration 1040 : 0.00016143196262419224
Loss at iteration 1050 : 0.0017065342981368303
Loss at iteration 1060 : 0.00021469916100613773
Loss at iteration 1070 : 0.0001962614041985944
Loss at iteration 1080 : 0.0004874299047514796
Loss at iteration 1090 : 0.0003796411619987339
Loss at iteration 1100 : 8.83858956512995e-05
Loss at iteration 1110 : 0.0045026992447674274
Loss at iteration 1120 : 0.0002118319971486926
Loss at iteration 1130 : 0.0010865589138120413
Loss at iteration 1140 : 0.005359326023608446
Loss at iteration 1150 : 0.0005024218116886914
Loss at iteration 1160 : 0.00015878910198807716
Loss at iteration 1170 : 0.0035956811625510454
Loss at iteration 1180 : 0.00017195426335092634
Loss at iteration 1190 : 0.00029962541884742677
Loss at iteration 1200 : 0.00040786489262245595
Loss at iteration 1210 : 0.0021304753609001637
Loss at iteration 1220 : 0.00023171346401795745
Loss at iteration 1230 : 0.002322566695511341
Loss at iteration 1240 : 0.0005062326090410352
Loss at iteration 1250 : 6.402689177775756e-05
Loss at iteration 1260 : 0.00018038811685983092
Loss at iteration 1270 : 0.0001413854624843225
Loss at iteration 1280 : 0.0022450843825936317
Loss at iteration 1290 : 0.0011069681495428085
Loss at iteration 1300 : 0.0012070640223100781
Loss at iteration 1310 : 0.00014614460815209895
Loss at iteration 1320 : 0.0012042702874168754
Loss at iteration 1330 : 0.00011761731730075553
Loss at iteration 1340 : 0.0013352870009839535
Loss at iteration 1350 : 0.0006747012957930565
Loss at iteration 1360 : 0.0006322849076241255
Loss at iteration 1370 : 0.001998694147914648
Loss at iteration 1380 : 0.0002801651135087013
Loss at iteration 1390 : 0.00013977679191157222
Loss at iteration 1400 : 0.0001469458657084033
Loss at iteration 1410 : 0.003488949267193675
Loss at iteration 1420 : 0.0001363004994345829
Loss at iteration 1430 : 0.00011900181561941281
Loss at iteration 1440 : 0.000806765106972307
Loss at iteration 1450 : 0.0012080809101462364
Loss at iteration 1460 : 0.00015888552297838032
Loss at iteration 1470 : 0.003913189750164747
Loss at iteration 1480 : 0.0002966805186588317
Loss at iteration 1490 : 0.0029989508911967278
Loss at iteration 1500 : 0.0002637034631334245
Loss at iteration 1510 : 0.0035694800317287445
Loss at iteration 1520 : 0.00039046272286213934
Loss at iteration 1530 : 0.00015055523545015603
Loss at iteration 1540 : 7.214715878944844e-05
Loss at iteration 1550 : 0.00024740645312704146
Loss at iteration 1560 : 0.0009190869168378413
Loss at iteration 1570 : 0.002667443361133337
Loss at iteration 1580 : 0.001136379549279809
Loss at iteration 1590 : 0.0030665062367916107
Loss at iteration 1600 : 0.0002610725350677967
Loss at iteration 1610 : 0.0009719489025883377
Loss at iteration 1620 : 0.0009963284246623516
Loss at iteration 1630 : 0.0003739428357221186
Loss at iteration 1640 : 0.00030998222064226866
Loss at iteration 1650 : 0.00011453146726125851
Loss at iteration 1660 : 0.003344097640365362
Loss at iteration 1670 : 0.0023621460422873497
Loss at iteration 1680 : 0.0005757196340709925
Loss at iteration 1690 : 0.00037324774893932045
Loss at iteration 1700 : 0.0001882167416624725
Loss at iteration 1710 : 0.005125673487782478
Loss at iteration 1720 : 0.0025597948115319014
Loss at iteration 1730 : 0.0035652366932481527
Loss at iteration 1740 : 0.00033688743133097887
Loss at iteration 1750 : 0.0003841145080514252
The SSIM Value is: 0.985812954965667
The PSNR Value is: 46.616458250037375
the epoch is: 158
Loss at iteration 10 : 0.0008224481716752052
Loss at iteration 20 : 0.0007106162956915796
Loss at iteration 30 : 0.0007275152020156384
Loss at iteration 40 : 0.00180545705370605
Loss at iteration 50 : 0.0013057606993243098
Loss at iteration 60 : 0.0007668199832551181
Loss at iteration 70 : 0.0001199581238324754
Loss at iteration 80 : 0.000891340896487236
Loss at iteration 90 : 0.0008728642715141177
Loss at iteration 100 : 0.00032918990473262966
Loss at iteration 110 : 0.0002034698991337791
Loss at iteration 120 : 0.0015613865107297897
Loss at iteration 130 : 0.000583409215323627
Loss at iteration 140 : 0.00012990903633181006
Loss at iteration 150 : 0.0008868271252140403
Loss at iteration 160 : 0.0010626912117004395
Loss at iteration 170 : 0.001424457412213087
Loss at iteration 180 : 0.0001266297185793519
Loss at iteration 190 : 0.00014348584227263927
Loss at iteration 200 : 0.0002272243145853281
Loss at iteration 210 : 0.00033614857238717377
Loss at iteration 220 : 0.001595580717548728
Loss at iteration 230 : 0.002702669007703662
Loss at iteration 240 : 0.0008666348294354975
Loss at iteration 250 : 0.0005663056508637965
Loss at iteration 260 : 0.001659636152908206
Loss at iteration 270 : 0.006614293437451124
Loss at iteration 280 : 0.0003524247440509498
Loss at iteration 290 : 0.003958520479500294
Loss at iteration 300 : 0.00027238650363869965
Loss at iteration 310 : 0.0006306733703240752
Loss at iteration 320 : 0.00040304585127159953
Loss at iteration 330 : 8.56816623127088e-05
Loss at iteration 340 : 0.00014797229960095137
Loss at iteration 350 : 0.0008705609943717718
Loss at iteration 360 : 0.00025258652749471366
Loss at iteration 370 : 0.00011175462714163586
Loss at iteration 380 : 0.00016153522301465273
Loss at iteration 390 : 0.002425022888928652
Loss at iteration 400 : 0.002706393599510193
Loss at iteration 410 : 0.0001367207005387172
Loss at iteration 420 : 0.0003591124841477722
Loss at iteration 430 : 0.0027091745287179947
Loss at iteration 440 : 0.000635606178548187
Loss at iteration 450 : 9.137669258052483e-05
Loss at iteration 460 : 0.0002638396981637925
Loss at iteration 470 : 0.00019001509645022452
Loss at iteration 480 : 0.0001431572891306132
Loss at iteration 490 : 0.00038324546767398715
Loss at iteration 500 : 0.003432838013395667
Loss at iteration 510 : 0.00012509820226114243
Loss at iteration 520 : 0.000711396976839751
Loss at iteration 530 : 0.002553129568696022
Loss at iteration 540 : 0.0036527332849800587
Loss at iteration 550 : 0.002847714349627495
Loss at iteration 560 : 0.0008359338971786201
Loss at iteration 570 : 0.00018740823725238442
Loss at iteration 580 : 0.0013981412630528212
Loss at iteration 590 : 0.0016997389029711485
Loss at iteration 600 : 0.001499480800703168
Loss at iteration 610 : 0.0015350303146988153
Loss at iteration 620 : 0.0005388095742091537
Loss at iteration 630 : 0.0002327670663362369
Loss at iteration 640 : 0.0003338565002195537
Loss at iteration 650 : 0.00019819334556814283
Loss at iteration 660 : 0.00011769779666792601
Loss at iteration 670 : 0.000119493153761141
Loss at iteration 680 : 0.00037784824962727726
Loss at iteration 690 : 0.00015872149378992617
Loss at iteration 700 : 0.0009729089215397835
Loss at iteration 710 : 0.00010002232738770545
Loss at iteration 720 : 0.0003658596833702177
Loss at iteration 730 : 0.00023271681857295334
Loss at iteration 740 : 0.00022457643353845924
Loss at iteration 750 : 0.0002281931519974023
Loss at iteration 760 : 0.0015939136501401663
Loss at iteration 770 : 0.00023306279035750777
Loss at iteration 780 : 0.0003478775033727288
Loss at iteration 790 : 0.002178093185648322
Loss at iteration 800 : 0.0005509146139957011
Loss at iteration 810 : 0.00019230323960073292
Loss at iteration 820 : 0.00016065224190242589
Loss at iteration 830 : 0.0001860790653154254
Loss at iteration 840 : 0.0015304541448131204
Loss at iteration 850 : 0.0004964331164956093
Loss at iteration 860 : 0.0002896019723266363
Loss at iteration 870 : 0.001658216118812561
Loss at iteration 880 : 0.00107182702049613
Loss at iteration 890 : 0.0006499040173366666
Loss at iteration 900 : 0.0009698108769953251
Loss at iteration 910 : 6.575956649612635e-05
Loss at iteration 920 : 0.00040804900345392525
Loss at iteration 930 : 0.00024939767899923027
Loss at iteration 940 : 0.00040623731911182404
Loss at iteration 950 : 0.00021017997642047703
Loss at iteration 960 : 0.0003931730752810836
Loss at iteration 970 : 0.0018358280649408698
Loss at iteration 980 : 5.508378671947867e-05
Loss at iteration 990 : 0.0002723166544456035
Loss at iteration 1000 : 0.0004897357430309057
Loss at iteration 1010 : 0.0003147331008221954
Loss at iteration 1020 : 0.0007182446424849331
Loss at iteration 1030 : 0.0009828555630519986
Loss at iteration 1040 : 0.0011318607721477747
Loss at iteration 1050 : 7.639163231942803e-05
Loss at iteration 1060 : 0.0005246828077360988
Loss at iteration 1070 : 0.00011010383605025709
Loss at iteration 1080 : 0.0013653187779709697
Loss at iteration 1090 : 0.001509028603322804
Loss at iteration 1100 : 0.0001619507238501683
Loss at iteration 1110 : 0.0004464306402951479
Loss at iteration 1120 : 0.004416265524923801
Loss at iteration 1130 : 0.00010452903370605782
Loss at iteration 1140 : 0.0015919499564915895
Loss at iteration 1150 : 0.000161275384016335
Loss at iteration 1160 : 0.0006960650789551437
Loss at iteration 1170 : 0.004674932453781366
Loss at iteration 1180 : 0.00015270595031324774
Loss at iteration 1190 : 0.0014878269284963608
Loss at iteration 1200 : 0.0007655183435417712
Loss at iteration 1210 : 0.0001417731400579214
Loss at iteration 1220 : 0.00031605485128238797
Loss at iteration 1230 : 0.0018122796900570393
Loss at iteration 1240 : 8.41280198073946e-05
Loss at iteration 1250 : 8.487117156619206e-05
Loss at iteration 1260 : 0.0001382476621074602
Loss at iteration 1270 : 0.0003243722894694656
Loss at iteration 1280 : 0.00028201821260154247
Loss at iteration 1290 : 0.00018917099805548787
Loss at iteration 1300 : 0.001110447570681572
Loss at iteration 1310 : 5.6187585869338363e-05
Loss at iteration 1320 : 0.0033281559590250254
Loss at iteration 1330 : 0.0017034906195476651
Loss at iteration 1340 : 0.00010404951899545267
Loss at iteration 1350 : 9.449342906009406e-05
Loss at iteration 1360 : 0.001397186191752553
Loss at iteration 1370 : 0.0005442204419523478
Loss at iteration 1380 : 0.0017015885096043348
Loss at iteration 1390 : 0.00033480324782431126
Loss at iteration 1400 : 0.00234533310867846
Loss at iteration 1410 : 9.581135236658156e-05
Loss at iteration 1420 : 0.0006822115974500775
Loss at iteration 1430 : 0.00033176690340042114
Loss at iteration 1440 : 0.0020715310238301754
Loss at iteration 1450 : 0.0002751248248387128
Loss at iteration 1460 : 0.0002966726606246084
Loss at iteration 1470 : 4.256232568877749e-05
Loss at iteration 1480 : 0.0004146378778386861
Loss at iteration 1490 : 0.0020207404159009457
Loss at iteration 1500 : 0.0005135093815624714
Loss at iteration 1510 : 0.0015875757671892643
Loss at iteration 1520 : 0.0009698030771687627
Loss at iteration 1530 : 0.0035451173316687346
Loss at iteration 1540 : 0.0005458522355183959
Loss at iteration 1550 : 0.00019509284175001085
Loss at iteration 1560 : 0.0005268260720185935
Loss at iteration 1570 : 0.00026384866214357316
Loss at iteration 1580 : 0.0006231024162843823
Loss at iteration 1590 : 0.0006280821980908513
Loss at iteration 1600 : 0.001620151218958199
Loss at iteration 1610 : 8.061174594331533e-05
Loss at iteration 1620 : 9.669193968875334e-05
Loss at iteration 1630 : 0.00018630667182151228
Loss at iteration 1640 : 0.00034686148865148425
Loss at iteration 1650 : 0.0002727425890043378
Loss at iteration 1660 : 0.0008800991345196962
Loss at iteration 1670 : 0.0020750858820974827
Loss at iteration 1680 : 0.0006487378850579262
Loss at iteration 1690 : 0.0019960859790444374
Loss at iteration 1700 : 0.0002924887521658093
Loss at iteration 1710 : 0.00014438900689128786
Loss at iteration 1720 : 0.00035891239531338215
Loss at iteration 1730 : 0.0007735844701528549
Loss at iteration 1740 : 0.000535688130185008
Loss at iteration 1750 : 0.0009221220389008522
The SSIM Value is: 0.9821338121192571
The PSNR Value is: 46.70446279290489
the epoch is: 159
Loss at iteration 10 : 0.0021434384398162365
Loss at iteration 20 : 0.00015318483929149806
Loss at iteration 30 : 0.0001080726069631055
Loss at iteration 40 : 0.0005135665414854884
Loss at iteration 50 : 0.0008181234588846564
Loss at iteration 60 : 0.00021640026534441859
Loss at iteration 70 : 0.0036913116928189993
Loss at iteration 80 : 0.00018221588106825948
Loss at iteration 90 : 0.002822005422785878
Loss at iteration 100 : 0.00043470802484080195
Loss at iteration 110 : 0.00023897315259091556
Loss at iteration 120 : 0.0006992381531745195
Loss at iteration 130 : 0.00012295406486373395
Loss at iteration 140 : 8.584438910475001e-05
Loss at iteration 150 : 0.00028813391691073775
Loss at iteration 160 : 0.00018734027980826795
Loss at iteration 170 : 0.00028982601361349225
Loss at iteration 180 : 0.00030332012102007866
Loss at iteration 190 : 0.00508628785610199
Loss at iteration 200 : 8.584186434745789e-05
Loss at iteration 210 : 0.004849543329328299
Loss at iteration 220 : 0.00022956711472943425
Loss at iteration 230 : 0.00036463496508076787
Loss at iteration 240 : 0.0009088440565392375
Loss at iteration 250 : 0.00020859972573816776
Loss at iteration 260 : 0.0003098017768934369
Loss at iteration 270 : 0.00011265421198913828
Loss at iteration 280 : 0.00018299490329809487
Loss at iteration 290 : 0.002794327214360237
Loss at iteration 300 : 0.00267518637701869
Loss at iteration 310 : 0.00022042352065909654
Loss at iteration 320 : 0.0002765448880381882
Loss at iteration 330 : 0.00021965343330521137
Loss at iteration 340 : 0.0002523575385566801
Loss at iteration 350 : 0.0011686573270708323
Loss at iteration 360 : 9.841559221968055e-05
Loss at iteration 370 : 0.0003119509492535144
Loss at iteration 380 : 0.00019450629770290107
Loss at iteration 390 : 4.8781286750454456e-05
Loss at iteration 400 : 0.0007510734722018242
Loss at iteration 410 : 0.00027128568035550416
Loss at iteration 420 : 0.00021648335678037256
Loss at iteration 430 : 0.0005492514465004206
Loss at iteration 440 : 0.0005252455011941493
Loss at iteration 450 : 0.0002295988379046321
Loss at iteration 460 : 0.0015627581160515547
Loss at iteration 470 : 0.00026576881646178663
Loss at iteration 480 : 0.00011043293488910422
Loss at iteration 490 : 0.00017551775090396404
Loss at iteration 500 : 0.00016480989870615304
Loss at iteration 510 : 4.166943472228013e-05
Loss at iteration 520 : 0.0005117345135658979
Loss at iteration 530 : 0.00010084473615279421
Loss at iteration 540 : 6.076866702642292e-05
Loss at iteration 550 : 0.0016100091161206365
Loss at iteration 560 : 0.00011085212463513017
Loss at iteration 570 : 0.00015443576558027416
Loss at iteration 580 : 0.0003368034085724503
Loss at iteration 590 : 0.0019485065713524818
Loss at iteration 600 : 0.0031543129589408636
Loss at iteration 610 : 0.0005803055828437209
Loss at iteration 620 : 0.0004981746897101402
Loss at iteration 630 : 0.0011081405682489276
Loss at iteration 640 : 0.00011279058526270092
Loss at iteration 650 : 0.0007529650465585291
Loss at iteration 660 : 0.00031406429479829967
Loss at iteration 670 : 8.995742246042937e-05
Loss at iteration 680 : 7.83156938268803e-05
Loss at iteration 690 : 0.00022313180670607835
Loss at iteration 700 : 4.2443709389772266e-05
Loss at iteration 710 : 0.0008903439156711102
Loss at iteration 720 : 0.0004636218072846532
Loss at iteration 730 : 6.919167208252475e-05
Loss at iteration 740 : 9.64610735536553e-05
Loss at iteration 750 : 0.00010942349763354287
Loss at iteration 760 : 0.00019004086789209396
Loss at iteration 770 : 0.00019720388809219003
Loss at iteration 780 : 0.0010283321607857943
Loss at iteration 790 : 0.0025116982869803905
Loss at iteration 800 : 9.490843513049185e-05
Loss at iteration 810 : 0.00020865732221864164
Loss at iteration 820 : 0.0033870022743940353
Loss at iteration 830 : 0.006470083259046078
Loss at iteration 840 : 0.00013458356261253357
Loss at iteration 850 : 0.00012424387387000024
Loss at iteration 860 : 6.951121031306684e-05
Loss at iteration 870 : 4.9025002226699144e-05
Loss at iteration 880 : 0.002492402447387576
Loss at iteration 890 : 0.00013063197548035532
Loss at iteration 900 : 0.0004199956019874662
Loss at iteration 910 : 0.00011266780347796157
Loss at iteration 920 : 0.0003305949503555894
Loss at iteration 930 : 0.002966676838696003
Loss at iteration 940 : 0.00046422536252066493
Loss at iteration 950 : 0.0012811339693143964
Loss at iteration 960 : 0.00039097663830034435
Loss at iteration 970 : 0.0025358619168400764
Loss at iteration 980 : 8.181072917068377e-05
Loss at iteration 990 : 0.0004190046456642449
Loss at iteration 1000 : 0.0001708797353785485
Loss at iteration 1010 : 0.004932246636599302
Loss at iteration 1020 : 0.00039741917862556875
Loss at iteration 1030 : 0.0002931788330897689
Loss at iteration 1040 : 0.00026762986090034246
Loss at iteration 1050 : 0.0002190562809119001
Loss at iteration 1060 : 0.0001380488829454407
Loss at iteration 1070 : 0.00013949927233625203
Loss at iteration 1080 : 0.00023506199067924172
Loss at iteration 1090 : 0.004475144669413567
Loss at iteration 1100 : 9.207546099787578e-05
Loss at iteration 1110 : 0.00023100811813492328
Loss at iteration 1120 : 7.397838635370135e-05
Loss at iteration 1130 : 0.0005503522697836161
Loss at iteration 1140 : 0.00012160915503045544
Loss at iteration 1150 : 0.00020202845917083323
Loss at iteration 1160 : 0.00019807260832749307
Loss at iteration 1170 : 0.002971032867208123
Loss at iteration 1180 : 0.00019675944349728525
Loss at iteration 1190 : 0.00032114519854076207
Loss at iteration 1200 : 0.00131690944544971
Loss at iteration 1210 : 0.000717230373993516
Loss at iteration 1220 : 0.0005312587600201368
Loss at iteration 1230 : 0.0035535877104848623
Loss at iteration 1240 : 6.853444210719317e-05
Loss at iteration 1250 : 0.0006305485730990767
Loss at iteration 1260 : 0.00239407061599195
Loss at iteration 1270 : 0.00024389271857216954
Loss at iteration 1280 : 0.004155504051595926
Loss at iteration 1290 : 0.00014594252570532262
Loss at iteration 1300 : 0.0004416507144924253
Loss at iteration 1310 : 0.00024721832596696913
Loss at iteration 1320 : 0.00020342519565019757
Loss at iteration 1330 : 0.001739366794936359
Loss at iteration 1340 : 0.00021805721917189658
Loss at iteration 1350 : 0.0008028770098462701
Loss at iteration 1360 : 0.0031223525293171406
Loss at iteration 1370 : 0.0005519657861441374
Loss at iteration 1380 : 9.185382805299014e-05
Loss at iteration 1390 : 0.0021573768462985754
Loss at iteration 1400 : 0.00033893875661306083
Loss at iteration 1410 : 0.0006324836285784841
Loss at iteration 1420 : 0.0003533153503667563
Loss at iteration 1430 : 0.004111316055059433
Loss at iteration 1440 : 0.0003807205648627132
Loss at iteration 1450 : 0.0021872548386454582
Loss at iteration 1460 : 0.00021360932441893965
Loss at iteration 1470 : 0.0005995536339469254
Loss at iteration 1480 : 5.906136357225478e-05
Loss at iteration 1490 : 0.001088387449271977
Loss at iteration 1500 : 0.00039132984238676727
Loss at iteration 1510 : 0.0006536501459777355
Loss at iteration 1520 : 0.0025883838534355164
Loss at iteration 1530 : 0.0010698878904804587
Loss at iteration 1540 : 0.00023427707492373884
Loss at iteration 1550 : 0.00042696140008047223
Loss at iteration 1560 : 8.617439743829891e-05
Loss at iteration 1570 : 0.00035029544960707426
Loss at iteration 1580 : 0.0001424560323357582
Loss at iteration 1590 : 0.00011310439731460065
Loss at iteration 1600 : 0.00043993344297632575
Loss at iteration 1610 : 0.00029510477907024324
Loss at iteration 1620 : 0.00010238598042633384
Loss at iteration 1630 : 0.0011532199569046497
Loss at iteration 1640 : 0.00048491990310139954
Loss at iteration 1650 : 0.0019371919333934784
Loss at iteration 1660 : 0.00021249470592010766
Loss at iteration 1670 : 0.0009624094236642122
Loss at iteration 1680 : 0.0009967614896595478
Loss at iteration 1690 : 8.976452954811975e-05
Loss at iteration 1700 : 0.00010556160123087466
Loss at iteration 1710 : 0.00769426953047514
Loss at iteration 1720 : 0.0010079076746478677
Loss at iteration 1730 : 0.0003234794130548835
Loss at iteration 1740 : 0.0006921726744621992
Loss at iteration 1750 : 0.0001235668023582548
The SSIM Value is: 0.9800851916164028
The PSNR Value is: 46.35108968129767
the epoch is: 160
Loss at iteration 10 : 0.003581350203603506
Loss at iteration 20 : 0.0004300471628084779
Loss at iteration 30 : 0.0011868616566061974
Loss at iteration 40 : 0.00024460829445160925
Loss at iteration 50 : 0.009426606819033623
Loss at iteration 60 : 0.002989802975207567
Loss at iteration 70 : 0.00046910528908483684
Loss at iteration 80 : 8.79581129993312e-05
Loss at iteration 90 : 0.0007654684595763683
Loss at iteration 100 : 0.000952853646595031
Loss at iteration 110 : 0.00039202492916956544
Loss at iteration 120 : 0.0007914855377748609
Loss at iteration 130 : 0.00016759400023147464
Loss at iteration 140 : 0.00026809057453647256
Loss at iteration 150 : 0.0002932026400230825
Loss at iteration 160 : 0.0004119783407077193
Loss at iteration 170 : 0.00016066961688920856
Loss at iteration 180 : 0.00010999060032190755
Loss at iteration 190 : 0.0001052901498042047
Loss at iteration 200 : 0.00013929378474131227
Loss at iteration 210 : 0.00011227792128920555
Loss at iteration 220 : 0.004088877700269222
Loss at iteration 230 : 0.0002466111327521503
Loss at iteration 240 : 0.0010481112403795123
Loss at iteration 250 : 0.0006496176938526332
Loss at iteration 260 : 0.0003115649160463363
Loss at iteration 270 : 0.0001245519088115543
Loss at iteration 280 : 0.003487947164103389
Loss at iteration 290 : 0.0018332432955503464
Loss at iteration 300 : 0.00034482270712032914
Loss at iteration 310 : 0.00011432858445914462
Loss at iteration 320 : 0.0007134376792237163
Loss at iteration 330 : 0.00026677356800064445
Loss at iteration 340 : 0.00010250411287415773
Loss at iteration 350 : 0.00031273235799744725
Loss at iteration 360 : 0.0024138358421623707
Loss at iteration 370 : 0.00030947959749028087
Loss at iteration 380 : 6.650835712207481e-05
Loss at iteration 390 : 0.0002090116176987067
Loss at iteration 400 : 0.00022500622435472906
Loss at iteration 410 : 0.00041612464701756835
Loss at iteration 420 : 0.00011285992513876408
Loss at iteration 430 : 0.0007604849524796009
Loss at iteration 440 : 0.00027353805489838123
Loss at iteration 450 : 0.0006247850251384079
Loss at iteration 460 : 0.004119211807847023
Loss at iteration 470 : 0.0011911321198567748
Loss at iteration 480 : 0.0001349548838334158
Loss at iteration 490 : 0.00022198024089448154
Loss at iteration 500 : 0.00016925562522374094
Loss at iteration 510 : 0.00016376176790799946
Loss at iteration 520 : 0.0002026701986324042
Loss at iteration 530 : 0.0002450989850331098
Loss at iteration 540 : 9.753248014021665e-05
Loss at iteration 550 : 0.00023441131634172052
Loss at iteration 560 : 0.0024037400726228952
Loss at iteration 570 : 0.00017883384134620428
Loss at iteration 580 : 0.0003248688008170575
Loss at iteration 590 : 0.0005046267178840935
Loss at iteration 600 : 0.00047260080464184284
Loss at iteration 610 : 0.0011090240441262722
Loss at iteration 620 : 0.0003156956227030605
Loss at iteration 630 : 6.309749733190984e-05
Loss at iteration 640 : 0.001156855490989983
Loss at iteration 650 : 0.0011208697687834501
Loss at iteration 660 : 0.0005563327576965094
Loss at iteration 670 : 0.00023035121557768434
Loss at iteration 680 : 0.0003896644338965416
Loss at iteration 690 : 0.0006713615730404854
Loss at iteration 700 : 0.00011629587243078277
Loss at iteration 710 : 0.0005953612271696329
Loss at iteration 720 : 8.409995643887669e-05
Loss at iteration 730 : 8.486284059472382e-05
Loss at iteration 740 : 4.5065462472848594e-05
Loss at iteration 750 : 0.0005448811571113765
Loss at iteration 760 : 0.0001296675472985953
Loss at iteration 770 : 0.00024668918922543526
Loss at iteration 780 : 0.0001229852787218988
Loss at iteration 790 : 0.0006434893002733588
Loss at iteration 800 : 0.0003921503375750035
Loss at iteration 810 : 0.003177172038704157
Loss at iteration 820 : 0.0002543949813116342
Loss at iteration 830 : 0.0003331485204398632
Loss at iteration 840 : 0.00010389454837422818
Loss at iteration 850 : 0.0008827945566736162
Loss at iteration 860 : 0.00010195790673606098
Loss at iteration 870 : 0.0009003112209029496
Loss at iteration 880 : 0.0026260262820869684
Loss at iteration 890 : 0.0029392759315669537
Loss at iteration 900 : 0.0019043207867071033
Loss at iteration 910 : 0.0003374381922185421
Loss at iteration 920 : 0.0005501762498170137
Loss at iteration 930 : 0.0005653327098116279
Loss at iteration 940 : 0.0026213014498353004
Loss at iteration 950 : 0.0001649338664719835
Loss at iteration 960 : 0.0021943231113255024
Loss at iteration 970 : 0.0023181517608463764
Loss at iteration 980 : 0.0004948874702677131
Loss at iteration 990 : 0.0026652333326637745
Loss at iteration 1000 : 0.0006602445500902832
Loss at iteration 1010 : 0.00020514216157607734
Loss at iteration 1020 : 0.00014254855341278017
Loss at iteration 1030 : 0.0003039131697732955
Loss at iteration 1040 : 0.00015957937284838408
Loss at iteration 1050 : 0.00015756385982967913
Loss at iteration 1060 : 0.0005284515209496021
Loss at iteration 1070 : 0.0007307176711037755
Loss at iteration 1080 : 0.0021008842159062624
Loss at iteration 1090 : 0.0014528760220855474
Loss at iteration 1100 : 0.0002490847837179899
Loss at iteration 1110 : 0.0004702587320934981
Loss at iteration 1120 : 0.0004171462496742606
Loss at iteration 1130 : 0.0014531841734424233
Loss at iteration 1140 : 0.00015038347919471562
Loss at iteration 1150 : 0.0001591286127222702
Loss at iteration 1160 : 0.00023319979663938284
Loss at iteration 1170 : 0.000218086366658099
Loss at iteration 1180 : 0.00028488447424024343
Loss at iteration 1190 : 0.00020532302733045071
Loss at iteration 1200 : 0.00028974260203540325
Loss at iteration 1210 : 0.0005170931108295918
Loss at iteration 1220 : 0.0011009520385414362
Loss at iteration 1230 : 0.0005391818704083562
Loss at iteration 1240 : 0.0016163615509867668
Loss at iteration 1250 : 0.00015218793123494834
Loss at iteration 1260 : 0.003352187108248472
Loss at iteration 1270 : 0.00011978118709521368
Loss at iteration 1280 : 0.0003056154237128794
Loss at iteration 1290 : 0.0010582251707091928
Loss at iteration 1300 : 0.0018947501666843891
Loss at iteration 1310 : 0.0003346748126205057
Loss at iteration 1320 : 0.0019223341951146722
Loss at iteration 1330 : 0.0047470638528466225
Loss at iteration 1340 : 0.0014261575415730476
Loss at iteration 1350 : 0.0002444534911774099
Loss at iteration 1360 : 0.00013787191710434854
Loss at iteration 1370 : 0.00017416730406694114
Loss at iteration 1380 : 0.00026453164173290133
Loss at iteration 1390 : 9.094559936784208e-05
Loss at iteration 1400 : 0.00040585611714050174
Loss at iteration 1410 : 0.0006326448637992144
Loss at iteration 1420 : 0.0028151259757578373
Loss at iteration 1430 : 4.6617755288025364e-05
Loss at iteration 1440 : 0.0019926410168409348
Loss at iteration 1450 : 0.00100405840203166
Loss at iteration 1460 : 7.618028757860884e-05
Loss at iteration 1470 : 0.00014217750867828727
Loss at iteration 1480 : 0.00011874276242451742
Loss at iteration 1490 : 0.0035252049565315247
Loss at iteration 1500 : 0.00021658220794051886
Loss at iteration 1510 : 0.0005640833987854421
Loss at iteration 1520 : 0.0014036420034244657
Loss at iteration 1530 : 0.00018871059000957757
Loss at iteration 1540 : 4.3727261072490364e-05
Loss at iteration 1550 : 0.0006493201944977045
Loss at iteration 1560 : 8.954266377259046e-05
Loss at iteration 1570 : 0.00021262653172016144
Loss at iteration 1580 : 0.0015011640498414636
Loss at iteration 1590 : 0.0006007066695019603
Loss at iteration 1600 : 0.00022565198014490306
Loss at iteration 1610 : 5.099908958072774e-05
Loss at iteration 1620 : 0.00031698314705863595
Loss at iteration 1630 : 0.0059956759214401245
Loss at iteration 1640 : 0.0005787816480733454
Loss at iteration 1650 : 0.0017965948209166527
Loss at iteration 1660 : 0.0017704394413158298
Loss at iteration 1670 : 8.062522829277441e-05
Loss at iteration 1680 : 0.00043177854968234897
Loss at iteration 1690 : 0.00010533521708566695
Loss at iteration 1700 : 0.0006050511146895587
Loss at iteration 1710 : 0.0010216637747362256
Loss at iteration 1720 : 0.0003500817692838609
Loss at iteration 1730 : 4.9909023800864816e-05
Loss at iteration 1740 : 0.0007547850254923105
Loss at iteration 1750 : 0.004353145603090525
The SSIM Value is: 0.9872004434400719
The PSNR Value is: 46.28066012512745
the epoch is: 161
Loss at iteration 10 : 0.0006390016642399132
Loss at iteration 20 : 6.350107287289575e-05
Loss at iteration 30 : 9.902757301460952e-05
Loss at iteration 40 : 0.0023917416110634804
Loss at iteration 50 : 0.0006027841009199619
Loss at iteration 60 : 0.001726960064843297
Loss at iteration 70 : 5.868070729775354e-05
Loss at iteration 80 : 0.00021615097648464143
Loss at iteration 90 : 0.00010483010555617511
Loss at iteration 100 : 8.648590301163495e-05
Loss at iteration 110 : 0.0002752572181634605
Loss at iteration 120 : 0.0005002932739444077
Loss at iteration 130 : 0.00013077331823296845
Loss at iteration 140 : 0.00020780279010068625
Loss at iteration 150 : 0.0006071128882467747
Loss at iteration 160 : 0.00039184975321404636
Loss at iteration 170 : 9.641181532060727e-05
Loss at iteration 180 : 0.00017691616085357964
Loss at iteration 190 : 0.000235591855016537
Loss at iteration 200 : 0.0006991276168264449
Loss at iteration 210 : 3.614828165154904e-05
Loss at iteration 220 : 0.0013158880174160004
Loss at iteration 230 : 0.00029757487936876714
Loss at iteration 240 : 0.0022266749292612076
Loss at iteration 250 : 0.00017021357780322433
Loss at iteration 260 : 0.00012349079770501703
Loss at iteration 270 : 0.000376366195268929
Loss at iteration 280 : 0.001891767606139183
Loss at iteration 290 : 0.000316431192914024
Loss at iteration 300 : 0.005947396159172058
Loss at iteration 310 : 0.00021534775441978127
Loss at iteration 320 : 0.00015401167911477387
Loss at iteration 330 : 0.0002933848008979112
Loss at iteration 340 : 0.0024768009316176176
Loss at iteration 350 : 0.0005630234954878688
Loss at iteration 360 : 0.00010189740714849904
Loss at iteration 370 : 0.00017054911586456
Loss at iteration 380 : 0.000784693518653512
Loss at iteration 390 : 0.00028378848219290376
Loss at iteration 400 : 0.0005587923224084079
Loss at iteration 410 : 0.0003162740613333881
Loss at iteration 420 : 0.0024435026571154594
Loss at iteration 430 : 0.00031242507975548506
Loss at iteration 440 : 6.556520384037867e-05
Loss at iteration 450 : 0.0008276687003672123
Loss at iteration 460 : 0.00026519966195337474
Loss at iteration 470 : 0.00024135864805430174
Loss at iteration 480 : 8.125752356136218e-05
Loss at iteration 490 : 0.00029387985705398023
Loss at iteration 500 : 0.00018399224791210145
Loss at iteration 510 : 0.00020523034618236125
Loss at iteration 520 : 0.00032526516588404775
Loss at iteration 530 : 0.0026355120353400707
Loss at iteration 540 : 0.003956628497689962
Loss at iteration 550 : 0.0038761848118156195
Loss at iteration 560 : 0.001326749799773097
Loss at iteration 570 : 0.00017777043103706092
Loss at iteration 580 : 0.0010997239733114839
Loss at iteration 590 : 8.155256364261732e-05
Loss at iteration 600 : 0.00026474962942302227
Loss at iteration 610 : 0.0002672912087291479
Loss at iteration 620 : 0.0007328909123316407
Loss at iteration 630 : 0.006611863151192665
Loss at iteration 640 : 0.0052969790995121
Loss at iteration 650 : 0.0023811243008822203
Loss at iteration 660 : 0.0002373642346356064
Loss at iteration 670 : 0.00297700148075819
Loss at iteration 680 : 0.004082859493792057
Loss at iteration 690 : 0.000936507829464972
Loss at iteration 700 : 0.0013797007268294692
Loss at iteration 710 : 0.0006560827605426311
Loss at iteration 720 : 0.001204772270284593
Loss at iteration 730 : 0.00011364406964275986
Loss at iteration 740 : 0.00011902194819413126
Loss at iteration 750 : 0.00041936832712963223
Loss at iteration 760 : 0.000266909395577386
Loss at iteration 770 : 0.0007889732369221747
Loss at iteration 780 : 0.0004973168834112585
Loss at iteration 790 : 0.0015253612073138356
Loss at iteration 800 : 0.0014270648825913668
Loss at iteration 810 : 0.00027861728449352086
Loss at iteration 820 : 0.005451620556414127
Loss at iteration 830 : 0.0005162032321095467
Loss at iteration 840 : 0.00017905945423990488
Loss at iteration 850 : 0.0010184785351157188
Loss at iteration 860 : 0.0022270153276622295
Loss at iteration 870 : 0.0010064111556857824
Loss at iteration 880 : 0.0006421083817258477
Loss at iteration 890 : 0.00021443380683194846
Loss at iteration 900 : 0.0011069069150835276
Loss at iteration 910 : 0.0026734215207397938
Loss at iteration 920 : 0.00017269485397264361
Loss at iteration 930 : 0.001090886304154992
Loss at iteration 940 : 0.0022031068801879883
Loss at iteration 950 : 0.00013804291666019708
Loss at iteration 960 : 0.0005947180325165391
Loss at iteration 970 : 0.0004282900190446526
Loss at iteration 980 : 0.000128336891066283
Loss at iteration 990 : 0.0004246371681801975
Loss at iteration 1000 : 0.0005220848834142089
Loss at iteration 1010 : 0.0002790342550724745
Loss at iteration 1020 : 0.0003029207873623818
Loss at iteration 1030 : 7.638799434062093e-05
Loss at iteration 1040 : 0.00016884903016034514
Loss at iteration 1050 : 0.000132990229758434
Loss at iteration 1060 : 8.260193862952292e-05
Loss at iteration 1070 : 0.0018925286130979657
Loss at iteration 1080 : 0.0008760192431509495
Loss at iteration 1090 : 0.0002312512369826436
Loss at iteration 1100 : 0.00027203495847061276
Loss at iteration 1110 : 0.0024978246074169874
Loss at iteration 1120 : 0.0003454286779742688
Loss at iteration 1130 : 0.0029092063196003437
Loss at iteration 1140 : 0.00030687986873090267
Loss at iteration 1150 : 0.00022177128994371742
Loss at iteration 1160 : 0.0002704752841964364
Loss at iteration 1170 : 0.00014775428280699998
Loss at iteration 1180 : 0.00015396221715491265
Loss at iteration 1190 : 0.0021550951059907675
Loss at iteration 1200 : 0.0007777323480695486
Loss at iteration 1210 : 0.0002700500772334635
Loss at iteration 1220 : 0.00042367164860479534
Loss at iteration 1230 : 0.00017145485617220402
Loss at iteration 1240 : 0.0010262770811095834
Loss at iteration 1250 : 0.00033324791002087295
Loss at iteration 1260 : 0.0021471641957759857
Loss at iteration 1270 : 3.761260086321272e-05
Loss at iteration 1280 : 0.002636437537148595
Loss at iteration 1290 : 5.1595427066786215e-05
Loss at iteration 1300 : 0.0003051870735362172
Loss at iteration 1310 : 0.0006142284837551415
Loss at iteration 1320 : 0.0007419282919727266
Loss at iteration 1330 : 0.0025730030611157417
Loss at iteration 1340 : 0.003116373671218753
Loss at iteration 1350 : 4.430369517649524e-05
Loss at iteration 1360 : 0.0008190216613002121
Loss at iteration 1370 : 0.0028888420201838017
Loss at iteration 1380 : 8.224934572353959e-05
Loss at iteration 1390 : 6.070359449950047e-05
Loss at iteration 1400 : 0.00015894341049715877
Loss at iteration 1410 : 0.0022389297373592854
Loss at iteration 1420 : 6.696279888274148e-05
Loss at iteration 1430 : 0.00017353598377667367
Loss at iteration 1440 : 5.36141888005659e-05
Loss at iteration 1450 : 0.0008467258303426206
Loss at iteration 1460 : 0.001173601602204144
Loss at iteration 1470 : 0.0001966391282621771
Loss at iteration 1480 : 0.0015426662284880877
Loss at iteration 1490 : 0.00011017635551979765
Loss at iteration 1500 : 0.0004385530191939324
Loss at iteration 1510 : 6.953618139959872e-05
Loss at iteration 1520 : 0.001699834130704403
Loss at iteration 1530 : 0.0008066793088801205
Loss at iteration 1540 : 0.00014946030569262803
Loss at iteration 1550 : 0.0003456496633589268
Loss at iteration 1560 : 0.0002877725928556174
Loss at iteration 1570 : 8.220141899073496e-05
Loss at iteration 1580 : 4.701919897343032e-05
Loss at iteration 1590 : 0.0038113996852189302
Loss at iteration 1600 : 0.00027662309003062546
Loss at iteration 1610 : 0.00010213926725555211
Loss at iteration 1620 : 0.0006615541060455143
Loss at iteration 1630 : 0.0009575501899234951
Loss at iteration 1640 : 0.00010362919420003891
Loss at iteration 1650 : 0.000691403984092176
Loss at iteration 1660 : 0.0003452706150710583
Loss at iteration 1670 : 0.00023358935141004622
Loss at iteration 1680 : 0.0016297550173476338
Loss at iteration 1690 : 0.00013230409240350127
Loss at iteration 1700 : 0.0008148315246216953
Loss at iteration 1710 : 0.0009821444982662797
Loss at iteration 1720 : 0.00015783826529514045
Loss at iteration 1730 : 0.0006598811014555395
Loss at iteration 1740 : 9.983931522583589e-05
Loss at iteration 1750 : 0.00025021357578225434
The SSIM Value is: 0.9861978579985413
The PSNR Value is: 46.620445793420735
the epoch is: 162
Loss at iteration 10 : 0.00014302277122624218
Loss at iteration 20 : 0.00023351242998614907
Loss at iteration 30 : 3.540605757734738e-05
Loss at iteration 40 : 6.182143988553435e-05
Loss at iteration 50 : 0.0003002238227054477
Loss at iteration 60 : 0.0037498190067708492
Loss at iteration 70 : 6.136153388069943e-05
Loss at iteration 80 : 0.002659865189343691
Loss at iteration 90 : 0.0002935128868557513
Loss at iteration 100 : 0.00042797360219992697
Loss at iteration 110 : 0.00029332886333577335
Loss at iteration 120 : 7.572719914605841e-05
Loss at iteration 130 : 9.131059778155759e-05
Loss at iteration 140 : 0.003142252564430237
Loss at iteration 150 : 0.00017157243564724922
Loss at iteration 160 : 0.0018904519965872169
Loss at iteration 170 : 0.0006302681285887957
Loss at iteration 180 : 0.00017772057617548853
Loss at iteration 190 : 0.0005409657023847103
Loss at iteration 200 : 0.0028996991459280252
Loss at iteration 210 : 6.0904116253368556e-05
Loss at iteration 220 : 0.00019172366592101753
Loss at iteration 230 : 0.00021882282453589141
Loss at iteration 240 : 0.00024904453312046826
Loss at iteration 250 : 0.00018136634025722742
Loss at iteration 260 : 0.003807131201028824
Loss at iteration 270 : 0.0026124618016183376
Loss at iteration 280 : 0.00041618323302827775
Loss at iteration 290 : 0.00015899581194389611
Loss at iteration 300 : 0.000172795495018363
Loss at iteration 310 : 0.00029353192076087
Loss at iteration 320 : 0.00032083207042887807
Loss at iteration 330 : 0.0002848429139703512
Loss at iteration 340 : 0.0019285471644252539
Loss at iteration 350 : 0.0011839666403830051
Loss at iteration 360 : 0.0026211098302155733
Loss at iteration 370 : 0.00010414375719847158
Loss at iteration 380 : 8.208477811422199e-05
Loss at iteration 390 : 0.00010138079233001918
Loss at iteration 400 : 0.0018094356637448072
Loss at iteration 410 : 0.0002253649872727692
Loss at iteration 420 : 0.00010903141810558736
Loss at iteration 430 : 0.002585521899163723
Loss at iteration 440 : 0.002196180634200573
Loss at iteration 450 : 0.00014805278624407947
Loss at iteration 460 : 0.00021957136050332338
Loss at iteration 470 : 0.002286770613864064
Loss at iteration 480 : 0.00015415941015817225
Loss at iteration 490 : 0.0006397493416443467
Loss at iteration 500 : 0.00181291822809726
Loss at iteration 510 : 0.00022339572024066
Loss at iteration 520 : 0.0022675401996821165
Loss at iteration 530 : 0.0010340622393414378
Loss at iteration 540 : 7.016697782091796e-05
Loss at iteration 550 : 0.000537436397280544
Loss at iteration 560 : 0.0005393559695221484
Loss at iteration 570 : 0.0002892096235882491
Loss at iteration 580 : 0.00016270027845166624
Loss at iteration 590 : 0.0003836634277831763
Loss at iteration 600 : 6.202323129400611e-05
Loss at iteration 610 : 0.004449759144335985
Loss at iteration 620 : 0.00011746148084057495
Loss at iteration 630 : 0.00017691391985863447
Loss at iteration 640 : 0.00018277281196787953
Loss at iteration 650 : 0.0005864760605618358
Loss at iteration 660 : 6.740784010617062e-05
Loss at iteration 670 : 0.0002457003283780068
Loss at iteration 680 : 0.00010920305794570595
Loss at iteration 690 : 0.00013306258188094944
Loss at iteration 700 : 0.0001451512216590345
Loss at iteration 710 : 0.0006066139321774244
Loss at iteration 720 : 0.00010386339999968186
Loss at iteration 730 : 0.00014634907711297274
Loss at iteration 740 : 0.00021134514827281237
Loss at iteration 750 : 0.00011899128003278747
Loss at iteration 760 : 8.849462028592825e-05
Loss at iteration 770 : 0.002651563147082925
Loss at iteration 780 : 0.00011420274677220732
Loss at iteration 790 : 0.0004809104430023581
Loss at iteration 800 : 9.744831186253577e-05
Loss at iteration 810 : 0.0009850228670984507
Loss at iteration 820 : 0.00037829120992682874
Loss at iteration 830 : 0.0009256009943783283
Loss at iteration 840 : 0.00017459876835346222
Loss at iteration 850 : 0.00028717800159938633
Loss at iteration 860 : 0.00018248820560984313
Loss at iteration 870 : 0.00013930750719737262
Loss at iteration 880 : 0.0025044367648661137
Loss at iteration 890 : 0.00025180744705721736
Loss at iteration 900 : 0.0002202414907515049
Loss at iteration 910 : 0.003999548964202404
Loss at iteration 920 : 9.562920604366809e-05
Loss at iteration 930 : 0.0001126969073084183
Loss at iteration 940 : 0.00014873643522150815
Loss at iteration 950 : 0.0001915145548991859
Loss at iteration 960 : 0.0012858445988968015
Loss at iteration 970 : 0.000288186565740034
Loss at iteration 980 : 0.004643043037503958
Loss at iteration 990 : 0.0013024843065068126
Loss at iteration 1000 : 0.0007974401814863086
Loss at iteration 1010 : 0.00049843784654513
Loss at iteration 1020 : 9.025470353662968e-05
Loss at iteration 1030 : 6.826263415860012e-05
Loss at iteration 1040 : 0.003713332349434495
Loss at iteration 1050 : 0.00020322462660260499
Loss at iteration 1060 : 0.00010476041643414646
Loss at iteration 1070 : 0.00046359741827473044
Loss at iteration 1080 : 0.00016059928748290986
Loss at iteration 1090 : 0.0008053401252254844
Loss at iteration 1100 : 0.0005736970342695713
Loss at iteration 1110 : 0.0015725699486210942
Loss at iteration 1120 : 0.001021689735352993
Loss at iteration 1130 : 0.0010414033895358443
Loss at iteration 1140 : 0.000352021015714854
Loss at iteration 1150 : 0.0005154813406988978
Loss at iteration 1160 : 0.0003595411835703999
Loss at iteration 1170 : 0.0006288045551627874
Loss at iteration 1180 : 0.00047082544188015163
Loss at iteration 1190 : 0.00016197533113881946
Loss at iteration 1200 : 0.00107504241168499
Loss at iteration 1210 : 0.0013176484499126673
Loss at iteration 1220 : 0.00043294575880281627
Loss at iteration 1230 : 0.0005745292291976511
Loss at iteration 1240 : 0.002867685863748193
Loss at iteration 1250 : 0.0008417965145781636
Loss at iteration 1260 : 0.0021557374857366085
Loss at iteration 1270 : 0.000141827404149808
Loss at iteration 1280 : 0.0001755996490828693
Loss at iteration 1290 : 0.00023332028649747372
Loss at iteration 1300 : 0.005734673701226711
Loss at iteration 1310 : 0.0003593570727389306
Loss at iteration 1320 : 0.0007361234165728092
Loss at iteration 1330 : 0.0002904204302467406
Loss at iteration 1340 : 0.002597056794911623
Loss at iteration 1350 : 0.0006818905239924788
Loss at iteration 1360 : 0.0005810225266031921
Loss at iteration 1370 : 0.0001713872916297987
Loss at iteration 1380 : 0.00027977192075923085
Loss at iteration 1390 : 0.00041482693632133305
Loss at iteration 1400 : 0.00014263195043895394
Loss at iteration 1410 : 0.002350116614252329
Loss at iteration 1420 : 0.0005479322862811387
Loss at iteration 1430 : 0.00019786119810305536
Loss at iteration 1440 : 0.001045295619405806
Loss at iteration 1450 : 5.941775452811271e-05
Loss at iteration 1460 : 0.001172125106677413
Loss at iteration 1470 : 0.00017149627092294395
Loss at iteration 1480 : 0.00018137713777832687
Loss at iteration 1490 : 0.004239412024617195
Loss at iteration 1500 : 0.0002139021671609953
Loss at iteration 1510 : 0.001379746594466269
Loss at iteration 1520 : 0.0002327123802388087
Loss at iteration 1530 : 0.00013742239389102906
Loss at iteration 1540 : 0.0022101844660937786
Loss at iteration 1550 : 8.219193841796368e-05
Loss at iteration 1560 : 0.00030603466439060867
Loss at iteration 1570 : 0.000566859554965049
Loss at iteration 1580 : 0.00016325703472830355
Loss at iteration 1590 : 0.0032510673627257347
Loss at iteration 1600 : 0.00021625796216540039
Loss at iteration 1610 : 0.0003652913437690586
Loss at iteration 1620 : 0.0004950551083311439
Loss at iteration 1630 : 0.0002444488927721977
Loss at iteration 1640 : 0.0024415538646280766
Loss at iteration 1650 : 0.0007865482475608587
Loss at iteration 1660 : 0.0008793173474259675
Loss at iteration 1670 : 8.369443094125018e-05
Loss at iteration 1680 : 0.0006073495605960488
Loss at iteration 1690 : 0.0004985772538930178
Loss at iteration 1700 : 0.00031749054323881865
Loss at iteration 1710 : 0.0002807843848131597
Loss at iteration 1720 : 0.00015274094766937196
Loss at iteration 1730 : 0.00017427491548005491
Loss at iteration 1740 : 0.0002776049659587443
Loss at iteration 1750 : 0.0006812477950006723
The SSIM Value is: 0.9870861029572424
The PSNR Value is: 46.62302031075902
the epoch is: 163
Loss at iteration 10 : 7.7479773608502e-05
Loss at iteration 20 : 0.0001322938478551805
Loss at iteration 30 : 0.00010493872832739726
Loss at iteration 40 : 0.0016698685940355062
Loss at iteration 50 : 0.00013006749213673174
Loss at iteration 60 : 0.00012995324505027384
Loss at iteration 70 : 0.00023216655245050788
Loss at iteration 80 : 0.0022425639908760786
Loss at iteration 90 : 0.0013388136867433786
Loss at iteration 100 : 0.00011272513074800372
Loss at iteration 110 : 0.0011298581957817078
Loss at iteration 120 : 0.00017188552010338753
Loss at iteration 130 : 0.0005057810340076685
Loss at iteration 140 : 9.409253107151017e-05
Loss at iteration 150 : 0.00015515898121520877
Loss at iteration 160 : 0.0001044762393576093
Loss at iteration 170 : 0.0014610416255891323
Loss at iteration 180 : 0.00011154449020978063
Loss at iteration 190 : 6.914294499438256e-05
Loss at iteration 200 : 0.00015461587463505566
Loss at iteration 210 : 0.0002503489959053695
Loss at iteration 220 : 0.00016521685756742954
Loss at iteration 230 : 0.0003219378995709121
Loss at iteration 240 : 0.0001801198668545112
Loss at iteration 250 : 0.0036125925835222006
Loss at iteration 260 : 0.0028142696246504784
Loss at iteration 270 : 0.0005628585931845009
Loss at iteration 280 : 0.0006469936342909932
Loss at iteration 290 : 0.001498440746217966
Loss at iteration 300 : 0.00010177065269090235
Loss at iteration 310 : 0.00023008885909803212
Loss at iteration 320 : 4.127729334868491e-05
Loss at iteration 330 : 0.0009329855674877763
Loss at iteration 340 : 0.00012296336353756487
Loss at iteration 350 : 0.0002557655971031636
Loss at iteration 360 : 0.000149165527545847
Loss at iteration 370 : 0.0018887447658926249
Loss at iteration 380 : 0.0006828121840953827
Loss at iteration 390 : 0.0006278858054429293
Loss at iteration 400 : 0.002002017106860876
Loss at iteration 410 : 0.00016329354548361152
Loss at iteration 420 : 0.00019081536447629333
Loss at iteration 430 : 0.0009506613714620471
Loss at iteration 440 : 0.0008412461029365659
Loss at iteration 450 : 0.001503304811194539
Loss at iteration 460 : 0.00010174730414291844
Loss at iteration 470 : 0.0001821952755562961
Loss at iteration 480 : 7.745619222987443e-05
Loss at iteration 490 : 0.0001900079078041017
Loss at iteration 500 : 0.0005026586586609483
Loss at iteration 510 : 5.084105214336887e-05
Loss at iteration 520 : 8.0662161053624e-05
Loss at iteration 530 : 0.0024662392679601908
Loss at iteration 540 : 0.004071041941642761
Loss at iteration 550 : 9.373229113407433e-05
Loss at iteration 560 : 0.00017463391122873873
Loss at iteration 570 : 0.0005522737046703696
Loss at iteration 580 : 3.1883730116533116e-05
Loss at iteration 590 : 0.00012812379281967878
Loss at iteration 600 : 0.00020724674686789513
Loss at iteration 610 : 0.0005304914666339755
Loss at iteration 620 : 3.474167169770226e-05
Loss at iteration 630 : 0.0017247082432731986
Loss at iteration 640 : 0.007187378127127886
Loss at iteration 650 : 0.00011647959763649851
Loss at iteration 660 : 0.0009245763649232686
Loss at iteration 670 : 0.00028433866100385785
Loss at iteration 680 : 0.0012132616247981787
Loss at iteration 690 : 0.0034469470847398043
Loss at iteration 700 : 0.0003355871303938329
Loss at iteration 710 : 0.0030428748577833176
Loss at iteration 720 : 0.00019502549548633397
Loss at iteration 730 : 0.0007010588888078928
Loss at iteration 740 : 0.000244678754825145
Loss at iteration 750 : 0.00016597029753029346
Loss at iteration 760 : 0.002804805990308523
Loss at iteration 770 : 0.0011307720560580492
Loss at iteration 780 : 0.00019699922995641828
Loss at iteration 790 : 0.00014872083556838334
Loss at iteration 800 : 0.0012506956700235605
Loss at iteration 810 : 0.00045642309123650193
Loss at iteration 820 : 0.001914773602038622
Loss at iteration 830 : 0.00018045585602521896
Loss at iteration 840 : 0.001195157179608941
Loss at iteration 850 : 0.00025325341266579926
Loss at iteration 860 : 0.000467604142613709
Loss at iteration 870 : 0.0002901760453823954
Loss at iteration 880 : 0.00019212545885238796
Loss at iteration 890 : 4.4301574234850705e-05
Loss at iteration 900 : 0.0014716777950525284
Loss at iteration 910 : 0.000483200914459303
Loss at iteration 920 : 0.00028041863697580993
Loss at iteration 930 : 0.00021756484056822956
Loss at iteration 940 : 0.00018374159117229283
Loss at iteration 950 : 0.000599381048232317
Loss at iteration 960 : 0.00020553218200802803
Loss at iteration 970 : 0.0020622448064386845
Loss at iteration 980 : 0.0005357569316402078
Loss at iteration 990 : 0.00037526292726397514
Loss at iteration 1000 : 0.006848990451544523
Loss at iteration 1010 : 0.00020899003720842302
Loss at iteration 1020 : 0.0005043708952143788
Loss at iteration 1030 : 0.00012265382974874228
Loss at iteration 1040 : 0.00027643583598546684
Loss at iteration 1050 : 0.00041102402610704303
Loss at iteration 1060 : 0.000529440410900861
Loss at iteration 1070 : 0.002692156471312046
Loss at iteration 1080 : 0.00165051338262856
Loss at iteration 1090 : 0.0020422544330358505
Loss at iteration 1100 : 3.0832336051389575e-05
Loss at iteration 1110 : 0.00034660089295357466
Loss at iteration 1120 : 0.0001797589211491868
Loss at iteration 1130 : 0.0010979947401210666
Loss at iteration 1140 : 0.0006699140649288893
Loss at iteration 1150 : 0.002778874011710286
Loss at iteration 1160 : 9.694779146229848e-05
Loss at iteration 1170 : 0.00015108694788068533
Loss at iteration 1180 : 0.0023337590973824263
Loss at iteration 1190 : 0.00036210636608302593
Loss at iteration 1200 : 0.0016172205796465278
Loss at iteration 1210 : 0.00027640434564091265
Loss at iteration 1220 : 0.0002991011133417487
Loss at iteration 1230 : 0.00030828139279037714
Loss at iteration 1240 : 5.811508890474215e-05
Loss at iteration 1250 : 0.0004102675593458116
Loss at iteration 1260 : 0.00010889630357269198
Loss at iteration 1270 : 0.00010220411058980972
Loss at iteration 1280 : 0.001349625177681446
Loss at iteration 1290 : 0.0003829758206848055
Loss at iteration 1300 : 0.003052518703043461
Loss at iteration 1310 : 0.0005442923284135759
Loss at iteration 1320 : 0.00011497739615151659
Loss at iteration 1330 : 0.00011851411545649171
Loss at iteration 1340 : 0.00033554149558767676
Loss at iteration 1350 : 0.00016994363977573812
Loss at iteration 1360 : 0.0002879745443351567
Loss at iteration 1370 : 0.0012371037155389786
Loss at iteration 1380 : 0.00016939172928687185
Loss at iteration 1390 : 0.0005719081382267177
Loss at iteration 1400 : 0.0006846499163657427
Loss at iteration 1410 : 0.00013463167124427855
Loss at iteration 1420 : 0.0009033057722263038
Loss at iteration 1430 : 0.0001109099030145444
Loss at iteration 1440 : 0.0003613161388784647
Loss at iteration 1450 : 0.003573697991669178
Loss at iteration 1460 : 0.00020533340284600854
Loss at iteration 1470 : 0.0001303832686971873
Loss at iteration 1480 : 0.00036291746073402464
Loss at iteration 1490 : 0.003442531917244196
Loss at iteration 1500 : 0.00049681740347296
Loss at iteration 1510 : 0.00010392329568276182
Loss at iteration 1520 : 0.00024182029301300645
Loss at iteration 1530 : 0.0023240947630256414
Loss at iteration 1540 : 0.00022135264589451253
Loss at iteration 1550 : 0.0001291457301704213
Loss at iteration 1560 : 0.0016425660578534007
Loss at iteration 1570 : 0.0002661783655639738
Loss at iteration 1580 : 0.00046228556311689317
Loss at iteration 1590 : 0.00027563367621041834
Loss at iteration 1600 : 0.00026004304527305067
Loss at iteration 1610 : 0.00018256543262396008
Loss at iteration 1620 : 0.0005881040706299245
Loss at iteration 1630 : 0.0003475038683973253
Loss at iteration 1640 : 0.0001163132837973535
Loss at iteration 1650 : 0.0018503390019759536
Loss at iteration 1660 : 0.0036817167419940233
Loss at iteration 1670 : 0.008391095325350761
Loss at iteration 1680 : 0.00010049639968201518
Loss at iteration 1690 : 0.001266677281819284
Loss at iteration 1700 : 0.00026739921304397285
Loss at iteration 1710 : 0.0001279139833059162
Loss at iteration 1720 : 5.897079245187342e-05
Loss at iteration 1730 : 0.0005504240980371833
Loss at iteration 1740 : 8.697046723682433e-05
Loss at iteration 1750 : 0.0001508906134404242
The SSIM Value is: 0.9858653530937984
The PSNR Value is: 46.719402918206434
the epoch is: 164
Loss at iteration 10 : 0.0006172907305881381
Loss at iteration 20 : 6.397216930054128e-05
Loss at iteration 30 : 0.0028317475225776434
Loss at iteration 40 : 0.00040217716014012694
Loss at iteration 50 : 0.00032646345789544284
Loss at iteration 60 : 0.0010432511335238814
Loss at iteration 70 : 0.0026528695598244667
Loss at iteration 80 : 0.0010145909618586302
Loss at iteration 90 : 0.0003919780137948692
Loss at iteration 100 : 0.002133001806214452
Loss at iteration 110 : 0.00019007902301382273
Loss at iteration 120 : 0.00026902195531874895
Loss at iteration 130 : 0.0009279850055463612
Loss at iteration 140 : 0.00039860967081040144
Loss at iteration 150 : 0.0002363239327678457
Loss at iteration 160 : 3.377685061423108e-05
Loss at iteration 170 : 0.00027075293473899364
Loss at iteration 180 : 8.926149894250557e-05
Loss at iteration 190 : 0.0006544969510287046
Loss at iteration 200 : 0.0003885519690811634
Loss at iteration 210 : 0.002484220080077648
Loss at iteration 220 : 0.00014578075206372887
Loss at iteration 230 : 0.0004205363802611828
Loss at iteration 240 : 0.0024713159073144197
Loss at iteration 250 : 0.0005084789590910077
Loss at iteration 260 : 0.0007577324868179858
Loss at iteration 270 : 0.0001723156456137076
Loss at iteration 280 : 0.002920100698247552
Loss at iteration 290 : 0.0002074026269838214
Loss at iteration 300 : 0.00020172735094092786
Loss at iteration 310 : 0.0019017597660422325
Loss at iteration 320 : 0.0003789587353821844
Loss at iteration 330 : 7.653162174392492e-05
Loss at iteration 340 : 0.00015980801254045218
Loss at iteration 350 : 0.00046488558291457593
Loss at iteration 360 : 0.00040801838622428477
Loss at iteration 370 : 0.0004591501201502979
Loss at iteration 380 : 0.0005289187538437545
Loss at iteration 390 : 0.000143607787322253
Loss at iteration 400 : 0.0005158019484952092
Loss at iteration 410 : 0.00013268375187180936
Loss at iteration 420 : 0.0008934960933402181
Loss at iteration 430 : 0.0009446870535612106
Loss at iteration 440 : 0.0005282765487208962
Loss at iteration 450 : 0.00020022643730044365
Loss at iteration 460 : 0.002478178823366761
Loss at iteration 470 : 0.0002196027198806405
Loss at iteration 480 : 0.0005432710750028491
Loss at iteration 490 : 0.001255205599591136
Loss at iteration 500 : 0.00275802006945014
Loss at iteration 510 : 0.0002706129162106663
Loss at iteration 520 : 0.0001398304884787649
Loss at iteration 530 : 0.00030286857509054244
Loss at iteration 540 : 0.003685268573462963
Loss at iteration 550 : 0.004592021461576223
Loss at iteration 560 : 0.00015684531535953283
Loss at iteration 570 : 0.0003767167218029499
Loss at iteration 580 : 0.0004445708473213017
Loss at iteration 590 : 0.002595974365249276
Loss at iteration 600 : 0.0004549693549051881
Loss at iteration 610 : 0.0005538760451599956
Loss at iteration 620 : 0.0017951632617041469
Loss at iteration 630 : 0.0004951022565364838
Loss at iteration 640 : 0.0004495361354202032
Loss at iteration 650 : 0.00010938935884041712
Loss at iteration 660 : 0.0005424342234618962
Loss at iteration 670 : 0.0036614704877138138
Loss at iteration 680 : 0.000126515471492894
Loss at iteration 690 : 0.0004223331925459206
Loss at iteration 700 : 8.760658238315955e-05
Loss at iteration 710 : 0.00023086860892362893
Loss at iteration 720 : 0.0001409758988302201
Loss at iteration 730 : 0.0005237282020971179
Loss at iteration 740 : 0.0031690283212810755
Loss at iteration 750 : 0.0034584254026412964
Loss at iteration 760 : 0.001590687781572342
Loss at iteration 770 : 0.00020944584684912115
Loss at iteration 780 : 0.0004433970316313207
Loss at iteration 790 : 0.00014142043073661625
Loss at iteration 800 : 0.0029687313362956047
Loss at iteration 810 : 0.0031471794936805964
Loss at iteration 820 : 0.007975174114108086
Loss at iteration 830 : 0.00218586646951735
Loss at iteration 840 : 0.0003075512358918786
Loss at iteration 850 : 0.00017878218204714358
Loss at iteration 860 : 0.003659431589767337
Loss at iteration 870 : 0.0007113227038644254
Loss at iteration 880 : 0.00017820573702920228
Loss at iteration 890 : 0.0001514088362455368
Loss at iteration 900 : 0.00015332820476032794
Loss at iteration 910 : 0.00023739502648822963
Loss at iteration 920 : 0.0009253998287022114
Loss at iteration 930 : 0.0005215549608692527
Loss at iteration 940 : 0.0012319375528022647
Loss at iteration 950 : 0.0034552160650491714
Loss at iteration 960 : 0.0006156578310765326
Loss at iteration 970 : 0.0029019052162766457
Loss at iteration 980 : 0.004395425785332918
Loss at iteration 990 : 6.943086918909103e-05
Loss at iteration 1000 : 0.0031311349011957645
Loss at iteration 1010 : 0.000783465919084847
Loss at iteration 1020 : 0.0005445320857688785
Loss at iteration 1030 : 0.003250738838687539
Loss at iteration 1040 : 8.467955194646493e-05
Loss at iteration 1050 : 0.005975883454084396
Loss at iteration 1060 : 0.0003742426633834839
Loss at iteration 1070 : 0.00014446764544118196
Loss at iteration 1080 : 0.00035009003477171063
Loss at iteration 1090 : 0.003363175317645073
Loss at iteration 1100 : 0.002255925675854087
Loss at iteration 1110 : 0.000244115391978994
Loss at iteration 1120 : 0.0006118461024016142
Loss at iteration 1130 : 0.0002447112638037652
Loss at iteration 1140 : 0.001258320757187903
Loss at iteration 1150 : 0.00015560291649308056
Loss at iteration 1160 : 5.9860991314053535e-05
Loss at iteration 1170 : 0.0019690757617354393
Loss at iteration 1180 : 0.0004905523383058608
Loss at iteration 1190 : 0.002555052749812603
Loss at iteration 1200 : 0.0003855476970784366
Loss at iteration 1210 : 8.582657028455287e-05
Loss at iteration 1220 : 6.044183828635141e-05
Loss at iteration 1230 : 0.00019208215235266834
Loss at iteration 1240 : 0.00037891388637945056
Loss at iteration 1250 : 0.0001523872051620856
Loss at iteration 1260 : 0.00013152464816812426
Loss at iteration 1270 : 0.00021881972497794777
Loss at iteration 1280 : 0.00029008850106038153
Loss at iteration 1290 : 0.0026973651256412268
Loss at iteration 1300 : 0.001422677538357675
Loss at iteration 1310 : 0.00015330611495301127
Loss at iteration 1320 : 0.00226408988237381
Loss at iteration 1330 : 0.00046830298379063606
Loss at iteration 1340 : 0.0006121466285549104
Loss at iteration 1350 : 0.000138489282107912
Loss at iteration 1360 : 0.0032615954987704754
Loss at iteration 1370 : 0.00016377083375118673
Loss at iteration 1380 : 0.001956081250682473
Loss at iteration 1390 : 0.00015720215742476285
Loss at iteration 1400 : 0.00011497757805045694
Loss at iteration 1410 : 0.00015513476682826877
Loss at iteration 1420 : 0.0007137123611755669
Loss at iteration 1430 : 0.00014035192725714296
Loss at iteration 1440 : 0.0005809636786580086
Loss at iteration 1450 : 0.0004763099132105708
Loss at iteration 1460 : 0.00016823215992189944
Loss at iteration 1470 : 0.0011175740510225296
Loss at iteration 1480 : 5.758153565693647e-05
Loss at iteration 1490 : 0.0005843716789968312
Loss at iteration 1500 : 0.00013094962923787534
Loss at iteration 1510 : 0.0027967984788119793
Loss at iteration 1520 : 6.493700493592769e-05
Loss at iteration 1530 : 0.0011925528524443507
Loss at iteration 1540 : 0.0005854627233929932
Loss at iteration 1550 : 7.718671986367553e-05
Loss at iteration 1560 : 0.0006172169232740998
Loss at iteration 1570 : 0.0005711521371267736
Loss at iteration 1580 : 0.0007852814742363989
Loss at iteration 1590 : 0.0011743943905457854
Loss at iteration 1600 : 0.0004617611994035542
Loss at iteration 1610 : 0.00019308176706545055
Loss at iteration 1620 : 0.00018072518287226558
Loss at iteration 1630 : 9.742181282490492e-05
Loss at iteration 1640 : 0.0011117388494312763
Loss at iteration 1650 : 0.0005923838471062481
Loss at iteration 1660 : 0.000293099059490487
Loss at iteration 1670 : 0.0017819993663579226
Loss at iteration 1680 : 0.00033014200744219124
Loss at iteration 1690 : 0.0002148546336684376
Loss at iteration 1700 : 0.0013748523779213428
Loss at iteration 1710 : 0.0010253355139866471
Loss at iteration 1720 : 0.003171842312440276
Loss at iteration 1730 : 0.0009230940486304462
Loss at iteration 1740 : 0.00014696836296934634
Loss at iteration 1750 : 0.00018420175183564425
The SSIM Value is: 0.986386367928089
The PSNR Value is: 46.1539725648149
the epoch is: 165
Loss at iteration 10 : 0.00011768592230509967
Loss at iteration 20 : 0.0009080732124857605
Loss at iteration 30 : 0.001377022359520197
Loss at iteration 40 : 0.0001278668496524915
Loss at iteration 50 : 0.000190197242773138
Loss at iteration 60 : 0.0006870853248983622
Loss at iteration 70 : 0.0022403995972126722
Loss at iteration 80 : 0.0004917201586067677
Loss at iteration 90 : 0.0029526017606258392
Loss at iteration 100 : 0.00015126512153074145
Loss at iteration 110 : 0.0038176672533154488
Loss at iteration 120 : 0.0001663853181526065
Loss at iteration 130 : 0.0013080437202006578
Loss at iteration 140 : 0.0003019805299118161
Loss at iteration 150 : 0.0007033002912066877
Loss at iteration 160 : 0.00021081036538816988
Loss at iteration 170 : 0.0004854051803704351
Loss at iteration 180 : 9.105475328397006e-05
Loss at iteration 190 : 0.0001267192856175825
Loss at iteration 200 : 0.0016710588242858648
Loss at iteration 210 : 0.00015624583465978503
Loss at iteration 220 : 0.00048100852291099727
Loss at iteration 230 : 8.859146328177303e-05
Loss at iteration 240 : 0.004615391604602337
Loss at iteration 250 : 6.20848368271254e-05
Loss at iteration 260 : 0.0006248315330594778
Loss at iteration 270 : 0.00014307667152024806
Loss at iteration 280 : 0.00032576252124272287
Loss at iteration 290 : 0.0037723758723586798
Loss at iteration 300 : 0.004415981005877256
Loss at iteration 310 : 0.00026476557832211256
Loss at iteration 320 : 0.00014423114771489054
Loss at iteration 330 : 0.004745989106595516
Loss at iteration 340 : 0.0035503506660461426
Loss at iteration 350 : 0.00022999854991212487
Loss at iteration 360 : 0.00093721819575876
Loss at iteration 370 : 0.003505528438836336
Loss at iteration 380 : 0.0027755764313042164
Loss at iteration 390 : 0.00015040468133520335
Loss at iteration 400 : 0.00025492729037068784
Loss at iteration 410 : 0.000481333932839334
Loss at iteration 420 : 0.00016402195615228266
Loss at iteration 430 : 0.0023786542005836964
Loss at iteration 440 : 0.003777412697672844
Loss at iteration 450 : 0.0008816842455416918
Loss at iteration 460 : 0.0025431588292121887
Loss at iteration 470 : 0.00024993933038786054
Loss at iteration 480 : 0.0011958492686972022
Loss at iteration 490 : 0.0016644098795950413
Loss at iteration 500 : 0.0005258730379864573
Loss at iteration 510 : 0.0015529580414295197
Loss at iteration 520 : 0.0001418952742824331
Loss at iteration 530 : 0.000523794093169272
Loss at iteration 540 : 0.002409919397905469
Loss at iteration 550 : 0.0005605843034572899
Loss at iteration 560 : 0.00029434787575155497
Loss at iteration 570 : 0.00013085344107821584
Loss at iteration 580 : 4.022453504148871e-05
Loss at iteration 590 : 0.0005007549189031124
Loss at iteration 600 : 0.0001115879204007797
Loss at iteration 610 : 0.0005216168938204646
Loss at iteration 620 : 0.0008048521704040468
Loss at iteration 630 : 0.002577349776402116
Loss at iteration 640 : 0.0012795423390343785
Loss at iteration 650 : 0.002759421244263649
Loss at iteration 660 : 5.8347450249129906e-05
Loss at iteration 670 : 5.993111335556023e-05
Loss at iteration 680 : 0.00019246392184868455
Loss at iteration 690 : 0.00022368754434864968
Loss at iteration 700 : 0.00037547911051660776
Loss at iteration 710 : 0.00026766463997773826
Loss at iteration 720 : 0.0029961648397147655
Loss at iteration 730 : 0.0003504499909467995
Loss at iteration 740 : 0.0003589347761590034
Loss at iteration 750 : 4.9084781494457275e-05
Loss at iteration 760 : 0.001348869758658111
Loss at iteration 770 : 0.00010957930498989299
Loss at iteration 780 : 9.756955114426091e-05
Loss at iteration 790 : 0.0018264245009049773
Loss at iteration 800 : 0.003416873048990965
Loss at iteration 810 : 0.0003285379789303988
Loss at iteration 820 : 0.0003764483262784779
Loss at iteration 830 : 0.0004822262853849679
Loss at iteration 840 : 0.0021032188087701797
Loss at iteration 850 : 0.00012856046669185162
Loss at iteration 860 : 0.0002499773108866066
Loss at iteration 870 : 0.00014613353414461017
Loss at iteration 880 : 0.0036563784815371037
Loss at iteration 890 : 0.0010769912041723728
Loss at iteration 900 : 0.0001348020159639418
Loss at iteration 910 : 0.0002909140894189477
Loss at iteration 920 : 0.0007464021327905357
Loss at iteration 930 : 0.00043144120718352497
Loss at iteration 940 : 0.00016451340343337506
Loss at iteration 950 : 0.0004594159545376897
Loss at iteration 960 : 0.00010378666047472507
Loss at iteration 970 : 0.0004331419477239251
Loss at iteration 980 : 0.00017091113841161132
Loss at iteration 990 : 0.0009445351315662265
Loss at iteration 1000 : 0.00039148490759544075
Loss at iteration 1010 : 0.00015549510135315359
Loss at iteration 1020 : 9.905472688842565e-05
Loss at iteration 1030 : 0.0001097653730539605
Loss at iteration 1040 : 0.00011210022057639435
Loss at iteration 1050 : 7.892150460975245e-05
Loss at iteration 1060 : 0.0003792570496443659
Loss at iteration 1070 : 0.00024690540158189833
Loss at iteration 1080 : 0.0008872856851667166
Loss at iteration 1090 : 0.003795870114117861
Loss at iteration 1100 : 0.00020227005006745458
Loss at iteration 1110 : 7.861125777708367e-05
Loss at iteration 1120 : 0.0005740353371948004
Loss at iteration 1130 : 0.00020826524996664375
Loss at iteration 1140 : 0.0005854384507983923
Loss at iteration 1150 : 0.00014295848086476326
Loss at iteration 1160 : 0.00012206701649120077
Loss at iteration 1170 : 0.0004076358745805919
Loss at iteration 1180 : 0.0012462240410968661
Loss at iteration 1190 : 0.00019160816736984998
Loss at iteration 1200 : 0.00023417314514517784
Loss at iteration 1210 : 0.00040053785778582096
Loss at iteration 1220 : 0.0008240627939812839
Loss at iteration 1230 : 0.006801816634833813
Loss at iteration 1240 : 0.000237653250223957
Loss at iteration 1250 : 0.0026702159084379673
Loss at iteration 1260 : 0.00022660536342300475
Loss at iteration 1270 : 8.260067988885567e-05
Loss at iteration 1280 : 0.000183847252628766
Loss at iteration 1290 : 0.00016089311975520104
Loss at iteration 1300 : 0.0006029704818502069
Loss at iteration 1310 : 0.0031775906682014465
Loss at iteration 1320 : 0.002378738485276699
Loss at iteration 1330 : 0.0009797965176403522
Loss at iteration 1340 : 0.00013423209020402282
Loss at iteration 1350 : 0.00028971489518880844
Loss at iteration 1360 : 0.0005915454239584506
Loss at iteration 1370 : 0.00018167692178394645
Loss at iteration 1380 : 0.0005575604736804962
Loss at iteration 1390 : 0.0036933720111846924
Loss at iteration 1400 : 0.000437066046288237
Loss at iteration 1410 : 8.238464215537533e-05
Loss at iteration 1420 : 0.00018190097762271762
Loss at iteration 1430 : 0.004732488188892603
Loss at iteration 1440 : 0.0002696048468351364
Loss at iteration 1450 : 0.0016001173062250018
Loss at iteration 1460 : 0.0020221462473273277
Loss at iteration 1470 : 0.0003906131023541093
Loss at iteration 1480 : 0.00016943522496148944
Loss at iteration 1490 : 0.00039913112414069474
Loss at iteration 1500 : 0.00014417135389521718
Loss at iteration 1510 : 0.00015294042532332242
Loss at iteration 1520 : 0.00032547919545322657
Loss at iteration 1530 : 7.772877142997459e-05
Loss at iteration 1540 : 0.00011064373393310234
Loss at iteration 1550 : 0.0008703265921212733
Loss at iteration 1560 : 0.0004215712542645633
Loss at iteration 1570 : 0.001488041365519166
Loss at iteration 1580 : 0.0002932671632152051
Loss at iteration 1590 : 0.0002445196150802076
Loss at iteration 1600 : 4.561706737149507e-05
Loss at iteration 1610 : 0.0008833360043354332
Loss at iteration 1620 : 0.0007466187234967947
Loss at iteration 1630 : 0.00018065472249872983
Loss at iteration 1640 : 0.006158778443932533
Loss at iteration 1650 : 6.547740485984832e-05
Loss at iteration 1660 : 0.0011178924469277263
Loss at iteration 1670 : 0.0017466649878770113
Loss at iteration 1680 : 0.001738445134833455
Loss at iteration 1690 : 0.00022243727289605886
Loss at iteration 1700 : 0.0001020324561977759
Loss at iteration 1710 : 0.00027753779431805015
Loss at iteration 1720 : 0.0002598360297270119
Loss at iteration 1730 : 0.0005391961894929409
Loss at iteration 1740 : 7.758621359243989e-05
Loss at iteration 1750 : 0.0016936520114541054
The SSIM Value is: 0.9863365321432441
The PSNR Value is: 46.04667382303314
the epoch is: 166
Loss at iteration 10 : 5.704208888346329e-05
Loss at iteration 20 : 9.831565694184974e-05
Loss at iteration 30 : 0.0005020084790885448
Loss at iteration 40 : 0.007274989038705826
Loss at iteration 50 : 0.00029783148784190416
Loss at iteration 60 : 0.00048184223123826087
Loss at iteration 70 : 0.0009615659946575761
Loss at iteration 80 : 0.000271912693278864
Loss at iteration 90 : 0.0017736093141138554
Loss at iteration 100 : 0.00015152433479670435
Loss at iteration 110 : 0.0011146583128720522
Loss at iteration 120 : 0.002935274038463831
Loss at iteration 130 : 0.00046379698324017227
Loss at iteration 140 : 0.0008011576719582081
Loss at iteration 150 : 3.956699219997972e-05
Loss at iteration 160 : 0.00020075286738574505
Loss at iteration 170 : 0.00014794175513088703
Loss at iteration 180 : 0.001148213050328195
Loss at iteration 190 : 0.00045576176489703357
Loss at iteration 200 : 0.0011829774593934417
Loss at iteration 210 : 0.00044563907431438565
Loss at iteration 220 : 0.002270694589242339
Loss at iteration 230 : 0.00014764079242013395
Loss at iteration 240 : 3.3449316106271e-05
Loss at iteration 250 : 5.599346695817076e-05
Loss at iteration 260 : 0.000665496860165149
Loss at iteration 270 : 0.0009755886858329177
Loss at iteration 280 : 7.216711674118415e-05
Loss at iteration 290 : 0.000165200064657256
Loss at iteration 300 : 6.975439464440569e-05
Loss at iteration 310 : 0.0006342799169942737
Loss at iteration 320 : 0.00037941610207781196
Loss at iteration 330 : 0.00010427090455777943
Loss at iteration 340 : 0.001709774136543274
Loss at iteration 350 : 0.0012535307323560119
Loss at iteration 360 : 0.0008471768815070391
Loss at iteration 370 : 8.290132973343134e-05
Loss at iteration 380 : 0.00017296031001023948
Loss at iteration 390 : 0.0004123257240280509
Loss at iteration 400 : 0.0014340028865262866
Loss at iteration 410 : 0.0009485076298005879
Loss at iteration 420 : 0.00011113886284874752
Loss at iteration 430 : 0.0010798691073432565
Loss at iteration 440 : 0.00032348756212741137
Loss at iteration 450 : 0.0005863979458808899
Loss at iteration 460 : 0.00010562349780229852
Loss at iteration 470 : 0.0003045716439373791
Loss at iteration 480 : 0.0019914512522518635
Loss at iteration 490 : 0.0002989817294292152
Loss at iteration 500 : 0.0031795483082532883
Loss at iteration 510 : 4.000819899374619e-05
Loss at iteration 520 : 0.004378494340926409
Loss at iteration 530 : 4.890384661848657e-05
Loss at iteration 540 : 0.00018205490778200328
Loss at iteration 550 : 0.0002709264517761767
Loss at iteration 560 : 0.0001906849502120167
Loss at iteration 570 : 0.00012672666343860328
Loss at iteration 580 : 0.0006407404434867203
Loss at iteration 590 : 5.844271800015122e-05
Loss at iteration 600 : 0.0003050609666388482
Loss at iteration 610 : 0.00014293898129835725
Loss at iteration 620 : 0.00016960970242507756
Loss at iteration 630 : 0.00029405413079075515
Loss at iteration 640 : 0.00019019393948838115
Loss at iteration 650 : 0.00045108923222869635
Loss at iteration 660 : 0.0036922511644661427
Loss at iteration 670 : 0.00039099136483855546
Loss at iteration 680 : 0.00031518470495939255
Loss at iteration 690 : 0.0003206905093975365
Loss at iteration 700 : 0.007062737364321947
Loss at iteration 710 : 9.219718049280345e-05
Loss at iteration 720 : 0.00017951984773389995
Loss at iteration 730 : 0.00020561672863550484
Loss at iteration 740 : 0.0018748812144622207
Loss at iteration 750 : 0.0007488314295187593
Loss at iteration 760 : 0.00474499212577939
Loss at iteration 770 : 0.0001647107710596174
Loss at iteration 780 : 0.00040524324867874384
Loss at iteration 790 : 8.375794277526438e-05
Loss at iteration 800 : 0.0020937416702508926
Loss at iteration 810 : 0.0028944388031959534
Loss at iteration 820 : 0.0004934631870128214
Loss at iteration 830 : 0.003027245867997408
Loss at iteration 840 : 0.003409553784877062
Loss at iteration 850 : 0.0016581580275669694
Loss at iteration 860 : 0.0004932922311127186
Loss at iteration 870 : 0.0001507676497567445
Loss at iteration 880 : 0.0035033170133829117
Loss at iteration 890 : 0.0004369604866951704
Loss at iteration 900 : 0.0003976993029937148
Loss at iteration 910 : 7.505518442485482e-05
Loss at iteration 920 : 0.006788484286516905
Loss at iteration 930 : 0.00017921207472682
Loss at iteration 940 : 0.00014034072228241712
Loss at iteration 950 : 0.0026640859432518482
Loss at iteration 960 : 0.0020629339851439
Loss at iteration 970 : 0.00042957995901815593
Loss at iteration 980 : 0.0001326810452155769
Loss at iteration 990 : 0.00010670234769349918
Loss at iteration 1000 : 0.0002124821621691808
Loss at iteration 1010 : 0.0011575648095458746
Loss at iteration 1020 : 0.00018404224829282612
Loss at iteration 1030 : 0.0009789088508114219
Loss at iteration 1040 : 0.004620643332600594
Loss at iteration 1050 : 0.0003426730399951339
Loss at iteration 1060 : 0.0011471051257103682
Loss at iteration 1070 : 0.0017914262134581804
Loss at iteration 1080 : 0.00013867950474377722
Loss at iteration 1090 : 0.00027056841645389795
Loss at iteration 1100 : 0.0026858472265303135
Loss at iteration 1110 : 0.0003480314917396754
Loss at iteration 1120 : 0.0004717738484032452
Loss at iteration 1130 : 0.0001663372095208615
Loss at iteration 1140 : 7.564187399111688e-05
Loss at iteration 1150 : 0.005456342361867428
Loss at iteration 1160 : 0.0006647114641964436
Loss at iteration 1170 : 0.00030546440393663943
Loss at iteration 1180 : 0.002521728863939643
Loss at iteration 1190 : 0.0012209811247885227
Loss at iteration 1200 : 0.001391605706885457
Loss at iteration 1210 : 0.00319902366027236
Loss at iteration 1220 : 0.0004548956057988107
Loss at iteration 1230 : 0.002813065890222788
Loss at iteration 1240 : 0.0002785528195090592
Loss at iteration 1250 : 0.003651363542303443
Loss at iteration 1260 : 0.000347465364029631
Loss at iteration 1270 : 0.0004946752451360226
Loss at iteration 1280 : 0.003224496729671955
Loss at iteration 1290 : 0.0005439376691356301
Loss at iteration 1300 : 0.0006523663178086281
Loss at iteration 1310 : 0.00400932040065527
Loss at iteration 1320 : 3.4586715628392994e-05
Loss at iteration 1330 : 6.976324948482215e-05
Loss at iteration 1340 : 0.0005999029381200671
Loss at iteration 1350 : 0.003434233134612441
Loss at iteration 1360 : 0.0023341234773397446
Loss at iteration 1370 : 0.00032485328847542405
Loss at iteration 1380 : 0.0025224434211850166
Loss at iteration 1390 : 0.00016680500993970782
Loss at iteration 1400 : 0.0001251113135367632
Loss at iteration 1410 : 0.0009516654536128044
Loss at iteration 1420 : 0.0001284755126107484
Loss at iteration 1430 : 0.00018665437528397888
Loss at iteration 1440 : 0.0006696071359328926
Loss at iteration 1450 : 5.1164755859645084e-05
Loss at iteration 1460 : 0.006364215165376663
Loss at iteration 1470 : 0.003266603220254183
Loss at iteration 1480 : 0.0035617786925286055
Loss at iteration 1490 : 0.00036579888546839356
Loss at iteration 1500 : 0.00032520038075745106
Loss at iteration 1510 : 0.0034415596164762974
Loss at iteration 1520 : 0.0014623564202338457
Loss at iteration 1530 : 0.001770328264683485
Loss at iteration 1540 : 7.476592145394534e-05
Loss at iteration 1550 : 0.00025401770835742354
Loss at iteration 1560 : 0.0003692040336318314
Loss at iteration 1570 : 0.004690694622695446
Loss at iteration 1580 : 0.0030309390276670456
Loss at iteration 1590 : 0.0037794243544340134
Loss at iteration 1600 : 0.00020534798386506736
Loss at iteration 1610 : 0.008394397795200348
Loss at iteration 1620 : 0.00011308742978144437
Loss at iteration 1630 : 0.00019529620476532727
Loss at iteration 1640 : 0.00249399128369987
Loss at iteration 1650 : 0.002199904527515173
Loss at iteration 1660 : 0.00022110127611085773
Loss at iteration 1670 : 0.00030385644640773535
Loss at iteration 1680 : 0.0005805178079754114
Loss at iteration 1690 : 0.0001280357246287167
Loss at iteration 1700 : 0.00010470259439898655
Loss at iteration 1710 : 8.113918011076748e-05
Loss at iteration 1720 : 0.0004128347209189087
Loss at iteration 1730 : 0.0013642613776028156
Loss at iteration 1740 : 0.00038892729207873344
Loss at iteration 1750 : 0.0010652091586962342
The SSIM Value is: 0.9858384499990993
The PSNR Value is: 46.62984951162128
the epoch is: 167
Loss at iteration 10 : 0.0029418824706226587
Loss at iteration 20 : 0.00023923072149045765
Loss at iteration 30 : 0.00021026484319008887
Loss at iteration 40 : 0.00031007215147837996
Loss at iteration 50 : 0.003086607903242111
Loss at iteration 60 : 0.000153683839016594
Loss at iteration 70 : 0.00015583954518660903
Loss at iteration 80 : 0.00021376567019615322
Loss at iteration 90 : 0.00032146240118891
Loss at iteration 100 : 0.00010922325600404292
Loss at iteration 110 : 0.0009922967292368412
Loss at iteration 120 : 0.0017258520238101482
Loss at iteration 130 : 0.00012182841601315886
Loss at iteration 140 : 9.152865095529705e-05
Loss at iteration 150 : 0.0001608745806152001
Loss at iteration 160 : 0.0002502051938790828
Loss at iteration 170 : 0.0019884291104972363
Loss at iteration 180 : 0.00023284589406102896
Loss at iteration 190 : 0.0006661080988124013
Loss at iteration 200 : 0.0010534697212278843
Loss at iteration 210 : 0.0001872373977676034
Loss at iteration 220 : 0.003041197545826435
Loss at iteration 230 : 0.0002267309173475951
Loss at iteration 240 : 6.198663322720677e-05
Loss at iteration 250 : 0.00047114217886701226
Loss at iteration 260 : 0.00018985482165589929
Loss at iteration 270 : 0.0018913482781499624
Loss at iteration 280 : 0.0002149080828530714
Loss at iteration 290 : 0.00012781780969817191
Loss at iteration 300 : 0.0018430986674502492
Loss at iteration 310 : 0.0002340586797799915
Loss at iteration 320 : 0.0005602948367595673
Loss at iteration 330 : 0.00022218329831957817
Loss at iteration 340 : 0.00498936977237463
Loss at iteration 350 : 0.002765169832855463
Loss at iteration 360 : 0.000595393474213779
Loss at iteration 370 : 0.000317275378620252
Loss at iteration 380 : 0.000342210492817685
Loss at iteration 390 : 0.0021631396375596523
Loss at iteration 400 : 0.003171135438606143
Loss at iteration 410 : 0.002185405930504203
Loss at iteration 420 : 0.00013940472854301333
Loss at iteration 430 : 0.0010697750840336084
Loss at iteration 440 : 0.00026012194575741887
Loss at iteration 450 : 8.910661563277245e-05
Loss at iteration 460 : 6.623157969443128e-05
Loss at iteration 470 : 0.000995255308225751
Loss at iteration 480 : 0.0002962294383905828
Loss at iteration 490 : 0.0002331978757865727
Loss at iteration 500 : 0.0004904930246993899
Loss at iteration 510 : 0.0019840209279209375
Loss at iteration 520 : 0.00013844498607795686
Loss at iteration 530 : 8.605709444964305e-05
Loss at iteration 540 : 0.0008832520106807351
Loss at iteration 550 : 0.00038515354390256107
Loss at iteration 560 : 0.0012214318849146366
Loss at iteration 570 : 0.001289533218368888
Loss at iteration 580 : 5.784493623650633e-05
Loss at iteration 590 : 0.0025463204365223646
Loss at iteration 600 : 0.00041664045420475304
Loss at iteration 610 : 0.00023808951664250344
Loss at iteration 620 : 0.00028527434915304184
Loss at iteration 630 : 0.00037770456401631236
Loss at iteration 640 : 0.00036864043795503676
Loss at iteration 650 : 0.0005339833442121744
Loss at iteration 660 : 0.00011812759476015344
Loss at iteration 670 : 0.0002300131309311837
Loss at iteration 680 : 0.000261036359006539
Loss at iteration 690 : 0.003347688354551792
Loss at iteration 700 : 0.00028858002042397857
Loss at iteration 710 : 0.00018420613196212798
Loss at iteration 720 : 0.006058191880583763
Loss at iteration 730 : 0.0003722934052348137
Loss at iteration 740 : 0.0014500748366117477
Loss at iteration 750 : 0.00034061234327964485
Loss at iteration 760 : 0.0006695581250824034
Loss at iteration 770 : 0.0026770879048854113
Loss at iteration 780 : 0.00014736612502019852
Loss at iteration 790 : 0.00014540732081513852
Loss at iteration 800 : 0.0027208980172872543
Loss at iteration 810 : 0.0004909925046376884
Loss at iteration 820 : 6.978412420721725e-05
Loss at iteration 830 : 0.0004673312068916857
Loss at iteration 840 : 0.002551751211285591
Loss at iteration 850 : 0.0014212925452739
Loss at iteration 860 : 0.00021333625772967935
Loss at iteration 870 : 5.96593672526069e-05
Loss at iteration 880 : 0.00027330860029906034
Loss at iteration 890 : 8.227249782066792e-05
Loss at iteration 900 : 0.0020474488846957684
Loss at iteration 910 : 0.00021704938262701035
Loss at iteration 920 : 0.00268371868878603
Loss at iteration 930 : 0.00014546493184752762
Loss at iteration 940 : 0.00038365821819752455
Loss at iteration 950 : 0.0001829350076150149
Loss at iteration 960 : 0.002872163662686944
Loss at iteration 970 : 6.678663339698687e-05
Loss at iteration 980 : 0.00011399248614907265
Loss at iteration 990 : 0.0025950747076421976
Loss at iteration 1000 : 6.0884718550369143e-05
Loss at iteration 1010 : 0.00518829608336091
Loss at iteration 1020 : 0.0002885024296119809
Loss at iteration 1030 : 0.0031808363273739815
Loss at iteration 1040 : 0.0013852294068783522
Loss at iteration 1050 : 8.48824274726212e-05
Loss at iteration 1060 : 0.005298702046275139
Loss at iteration 1070 : 0.000600201659835875
Loss at iteration 1080 : 0.006979777477681637
Loss at iteration 1090 : 0.002119870623573661
Loss at iteration 1100 : 0.00011565030581550673
Loss at iteration 1110 : 0.00025751424254849553
Loss at iteration 1120 : 0.0005570741486735642
Loss at iteration 1130 : 0.00013794527330901474
Loss at iteration 1140 : 0.0020509378518909216
Loss at iteration 1150 : 0.0025484487414360046
Loss at iteration 1160 : 0.002098929602652788
Loss at iteration 1170 : 0.0005732326535508037
Loss at iteration 1180 : 0.005051081534475088
Loss at iteration 1190 : 0.00037517352029681206
Loss at iteration 1200 : 0.0010182458208873868
Loss at iteration 1210 : 0.0006635962054133415
Loss at iteration 1220 : 6.340505206026137e-05
Loss at iteration 1230 : 0.0010757842101156712
Loss at iteration 1240 : 0.0013743167510256171
Loss at iteration 1250 : 5.4726206144550815e-05
Loss at iteration 1260 : 0.0028782549779862165
Loss at iteration 1270 : 0.0004734111134894192
Loss at iteration 1280 : 0.0002714067231863737
Loss at iteration 1290 : 0.00047371978871524334
Loss at iteration 1300 : 0.0008793867309577763
Loss at iteration 1310 : 8.90231822268106e-05
Loss at iteration 1320 : 0.005047048907727003
Loss at iteration 1330 : 0.000134411413455382
Loss at iteration 1340 : 0.0021468973718583584
Loss at iteration 1350 : 0.0033811694011092186
Loss at iteration 1360 : 0.00012471583613660187
Loss at iteration 1370 : 0.0024905859027057886
Loss at iteration 1380 : 0.0016039483016356826
Loss at iteration 1390 : 0.0006658645579591393
Loss at iteration 1400 : 0.0002721932251006365
Loss at iteration 1410 : 0.00012421439168974757
Loss at iteration 1420 : 0.00041772297117859125
Loss at iteration 1430 : 0.00533095421269536
Loss at iteration 1440 : 0.00046098598977550864
Loss at iteration 1450 : 0.00015066223568283021
Loss at iteration 1460 : 0.0007792526739649475
Loss at iteration 1470 : 0.00023235398111864924
Loss at iteration 1480 : 0.00015892929513938725
Loss at iteration 1490 : 0.0003020102740265429
Loss at iteration 1500 : 0.0013685720041394234
Loss at iteration 1510 : 0.00041468016570433974
Loss at iteration 1520 : 0.00039293861482292414
Loss at iteration 1530 : 0.003337376518175006
Loss at iteration 1540 : 0.0009597759344615042
Loss at iteration 1550 : 0.0003248218563385308
Loss at iteration 1560 : 0.00039433169877156615
Loss at iteration 1570 : 0.0028358055278658867
Loss at iteration 1580 : 0.00020459317602217197
Loss at iteration 1590 : 9.881783626042306e-05
Loss at iteration 1600 : 0.000780188012868166
Loss at iteration 1610 : 0.002626276109367609
Loss at iteration 1620 : 0.00013378961011767387
Loss at iteration 1630 : 5.458433588501066e-05
Loss at iteration 1640 : 0.00014089627075009048
Loss at iteration 1650 : 0.0016237108502537012
Loss at iteration 1660 : 0.0007008932298049331
Loss at iteration 1670 : 0.00036553118843585253
Loss at iteration 1680 : 0.001615811139345169
Loss at iteration 1690 : 0.0015512984246015549
Loss at iteration 1700 : 5.261901605990715e-05
Loss at iteration 1710 : 0.0001783264015102759
Loss at iteration 1720 : 0.00032178786932490766
Loss at iteration 1730 : 0.00017166562611237168
Loss at iteration 1740 : 0.0003482884494587779
Loss at iteration 1750 : 0.0004684177692979574
The SSIM Value is: 0.9874163452486635
The PSNR Value is: 46.43120461938665
the epoch is: 168
Loss at iteration 10 : 0.00035335501888766885
Loss at iteration 20 : 0.00030116213019937277
Loss at iteration 30 : 0.0005464064888656139
Loss at iteration 40 : 0.0033932016231119633
Loss at iteration 50 : 0.00011235004785703495
Loss at iteration 60 : 0.0012649717973545194
Loss at iteration 70 : 0.0003124121285509318
Loss at iteration 80 : 0.00011257146979914978
Loss at iteration 90 : 8.442356192972511e-05
Loss at iteration 100 : 0.000302880653180182
Loss at iteration 110 : 0.00023873147438280284
Loss at iteration 120 : 0.00015742612595204264
Loss at iteration 130 : 0.0025649419985711575
Loss at iteration 140 : 0.0003333288477733731
Loss at iteration 150 : 0.0016759479185566306
Loss at iteration 160 : 0.0002660149475559592
Loss at iteration 170 : 0.00049546331865713
Loss at iteration 180 : 0.00020206601766403764
Loss at iteration 190 : 0.00027832144405692816
Loss at iteration 200 : 0.0002548091870266944
Loss at iteration 210 : 0.002476988360285759
Loss at iteration 220 : 0.0011975921224802732
Loss at iteration 230 : 6.389048940036446e-05
Loss at iteration 240 : 0.0007576724165119231
Loss at iteration 250 : 0.00014685798669233918
Loss at iteration 260 : 0.0007007070817053318
Loss at iteration 270 : 0.0002983096637763083
Loss at iteration 280 : 4.998468648409471e-05
Loss at iteration 290 : 0.0006881564622744918
Loss at iteration 300 : 0.0002772442239802331
Loss at iteration 310 : 0.0018383136484771967
Loss at iteration 320 : 6.283993570832536e-05
Loss at iteration 330 : 0.0002703091886360198
Loss at iteration 340 : 0.00022395978157874197
Loss at iteration 350 : 0.0014491986948996782
Loss at iteration 360 : 0.0003693913749884814
Loss at iteration 370 : 0.000955578638240695
Loss at iteration 380 : 0.00037731925840489566
Loss at iteration 390 : 0.0014188727363944054
Loss at iteration 400 : 0.0005094000371173024
Loss at iteration 410 : 0.0002700023469515145
Loss at iteration 420 : 6.521488103317097e-05
Loss at iteration 430 : 0.00041022972436621785
Loss at iteration 440 : 0.0005336602916941047
Loss at iteration 450 : 0.0009963175980374217
Loss at iteration 460 : 9.870697977021337e-05
Loss at iteration 470 : 8.680818427819759e-05
Loss at iteration 480 : 9.969033271772787e-05
Loss at iteration 490 : 0.00047050754074007273
Loss at iteration 500 : 0.000408442021580413
Loss at iteration 510 : 0.00031503476202487946
Loss at iteration 520 : 0.00025104882661253214
Loss at iteration 530 : 0.00037927532684989274
Loss at iteration 540 : 0.00017573588411323726
Loss at iteration 550 : 0.000647433684207499
Loss at iteration 560 : 0.00010049207048723474
Loss at iteration 570 : 0.0004290431970730424
Loss at iteration 580 : 0.0008442850084975362
Loss at iteration 590 : 0.00043764966540038586
Loss at iteration 600 : 9.9483564554248e-05
Loss at iteration 610 : 0.000195773143786937
Loss at iteration 620 : 9.609714470570907e-05
Loss at iteration 630 : 0.0002043077547568828
Loss at iteration 640 : 0.0024231800343841314
Loss at iteration 650 : 0.004175467416644096
Loss at iteration 660 : 7.525555702159181e-05
Loss at iteration 670 : 0.0009249162394553423
Loss at iteration 680 : 0.0002252906415378675
Loss at iteration 690 : 0.00013221352128311992
Loss at iteration 700 : 0.0032934295013546944
Loss at iteration 710 : 0.00013490216224454343
Loss at iteration 720 : 0.00023260086891241372
Loss at iteration 730 : 0.002330162562429905
Loss at iteration 740 : 0.0007466569077223539
Loss at iteration 750 : 3.4237011277582496e-05
Loss at iteration 760 : 7.67581514082849e-05
Loss at iteration 770 : 0.0001381141773890704
Loss at iteration 780 : 0.0006138556636869907
Loss at iteration 790 : 0.00022048086975701153
Loss at iteration 800 : 5.722338755731471e-05
Loss at iteration 810 : 0.00010084829409606755
Loss at iteration 820 : 0.0019125320250168443
Loss at iteration 830 : 0.0004720407596323639
Loss at iteration 840 : 8.028713637031615e-05
Loss at iteration 850 : 8.63898458192125e-05
Loss at iteration 860 : 0.00012251596490386873
Loss at iteration 870 : 0.00036444130819290876
Loss at iteration 880 : 0.0003262686950620264
Loss at iteration 890 : 0.00034527218667790294
Loss at iteration 900 : 0.0003342389245517552
Loss at iteration 910 : 3.376549284439534e-05
Loss at iteration 920 : 0.0007539528887718916
Loss at iteration 930 : 0.004819296300411224
Loss at iteration 940 : 0.0006490093655884266
Loss at iteration 950 : 0.0007889770204201341
Loss at iteration 960 : 6.750793545506895e-05
Loss at iteration 970 : 0.0005654852138832211
Loss at iteration 980 : 0.0002205634955316782
Loss at iteration 990 : 0.001754644326865673
Loss at iteration 1000 : 0.00015576518489979208
Loss at iteration 1010 : 0.0007383382180705667
Loss at iteration 1020 : 9.42660917644389e-05
Loss at iteration 1030 : 0.0002726845850702375
Loss at iteration 1040 : 0.00040505031938664615
Loss at iteration 1050 : 0.00019504713418427855
Loss at iteration 1060 : 9.096196299651638e-05
Loss at iteration 1070 : 0.0017408981220796704
Loss at iteration 1080 : 0.00010488461703062057
Loss at iteration 1090 : 4.76288259960711e-05
Loss at iteration 1100 : 0.00028970095445401967
Loss at iteration 1110 : 0.0005449259770102799
Loss at iteration 1120 : 0.0030561015009880066
Loss at iteration 1130 : 0.00045763253001496196
Loss at iteration 1140 : 0.0020088092423975468
Loss at iteration 1150 : 0.0022660039830952883
Loss at iteration 1160 : 0.0026747414376586676
Loss at iteration 1170 : 0.0008730688132345676
Loss at iteration 1180 : 0.0023970562033355236
Loss at iteration 1190 : 0.00011538040416780859
Loss at iteration 1200 : 8.511610212735832e-05
Loss at iteration 1210 : 0.0007712826482020319
Loss at iteration 1220 : 0.00016506074462085962
Loss at iteration 1230 : 0.0004034732119180262
Loss at iteration 1240 : 8.58072453411296e-05
Loss at iteration 1250 : 0.0008858420769684017
Loss at iteration 1260 : 5.684611460310407e-05
Loss at iteration 1270 : 0.00018876341346185654
Loss at iteration 1280 : 0.0006166179664433002
Loss at iteration 1290 : 0.0005002974066883326
Loss at iteration 1300 : 0.003832933958619833
Loss at iteration 1310 : 0.00017198664136230946
Loss at iteration 1320 : 0.00017841547378338873
Loss at iteration 1330 : 0.0007743232999928296
Loss at iteration 1340 : 0.00013396775466389954
Loss at iteration 1350 : 0.00032406096579506993
Loss at iteration 1360 : 0.0010518368799239397
Loss at iteration 1370 : 0.00041510004666633904
Loss at iteration 1380 : 0.00031474471325054765
Loss at iteration 1390 : 0.004040637984871864
Loss at iteration 1400 : 0.0004378451267257333
Loss at iteration 1410 : 0.0005812994204461575
Loss at iteration 1420 : 7.584811828564852e-05
Loss at iteration 1430 : 0.0002638873120304197
Loss at iteration 1440 : 9.203528315993026e-05
Loss at iteration 1450 : 7.222143904073164e-05
Loss at iteration 1460 : 0.00012080821761628613
Loss at iteration 1470 : 0.00041998218512162566
Loss at iteration 1480 : 0.0014609831850975752
Loss at iteration 1490 : 0.0006905199261382222
Loss at iteration 1500 : 0.0045126196928322315
Loss at iteration 1510 : 9.823290019994602e-05
Loss at iteration 1520 : 0.003996669314801693
Loss at iteration 1530 : 0.004341719672083855
Loss at iteration 1540 : 0.00015758372319396585
Loss at iteration 1550 : 0.004127336200326681
Loss at iteration 1560 : 0.00037713831989094615
Loss at iteration 1570 : 0.0001027562830131501
Loss at iteration 1580 : 0.0004905823734588921
Loss at iteration 1590 : 7.375998393399641e-05
Loss at iteration 1600 : 0.0002627774083521217
Loss at iteration 1610 : 0.0003757160156965256
Loss at iteration 1620 : 0.000699003110639751
Loss at iteration 1630 : 0.0007884996011853218
Loss at iteration 1640 : 0.0001393501297570765
Loss at iteration 1650 : 8.414737385464832e-05
Loss at iteration 1660 : 4.433120557223447e-05
Loss at iteration 1670 : 0.00015439221169799566
Loss at iteration 1680 : 0.00033398219966329634
Loss at iteration 1690 : 0.0009233254240825772
Loss at iteration 1700 : 0.0011032258626073599
Loss at iteration 1710 : 0.0006249547586776316
Loss at iteration 1720 : 9.727127326186746e-05
Loss at iteration 1730 : 0.0018338905647397041
Loss at iteration 1740 : 0.00011851689487230033
Loss at iteration 1750 : 0.0001140815656981431
The SSIM Value is: 0.9847705475821894
The PSNR Value is: 46.233358534422216
the epoch is: 169
Loss at iteration 10 : 0.0007564808474853635
Loss at iteration 20 : 0.00014060996181797236
Loss at iteration 30 : 0.0005133785307407379
Loss at iteration 40 : 0.002799580805003643
Loss at iteration 50 : 0.0003631542786024511
Loss at iteration 60 : 0.00011576643737498671
Loss at iteration 70 : 0.00028777396073564887
Loss at iteration 80 : 0.0030839084647595882
Loss at iteration 90 : 5.881379183847457e-05
Loss at iteration 100 : 7.17675793566741e-05
Loss at iteration 110 : 0.00018768897280097008
Loss at iteration 120 : 0.0006552364211529493
Loss at iteration 130 : 0.0001307549246121198
Loss at iteration 140 : 0.0036111781373620033
Loss at iteration 150 : 0.0003678593202494085
Loss at iteration 160 : 0.00043946271762251854
Loss at iteration 170 : 0.003842653939500451
Loss at iteration 180 : 0.0002443094563204795
Loss at iteration 190 : 0.00022085501404944807
Loss at iteration 200 : 0.0001845513324951753
Loss at iteration 210 : 0.002211194019764662
Loss at iteration 220 : 0.0005494430661201477
Loss at iteration 230 : 0.0006836273241788149
Loss at iteration 240 : 0.0008145975298248231
Loss at iteration 250 : 0.0002688706445042044
Loss at iteration 260 : 0.0005360021023079753
Loss at iteration 270 : 0.00021241296781226993
Loss at iteration 280 : 0.0004901314969174564
Loss at iteration 290 : 0.0001760340528562665
Loss at iteration 300 : 0.0004795262066181749
Loss at iteration 310 : 0.002673342125490308
Loss at iteration 320 : 0.00013062347716186196
Loss at iteration 330 : 0.0005596033879555762
Loss at iteration 340 : 0.002651248127222061
Loss at iteration 350 : 0.0003142722125630826
Loss at iteration 360 : 0.005606085527688265
Loss at iteration 370 : 0.0002903167041949928
Loss at iteration 380 : 0.00142172712367028
Loss at iteration 390 : 0.00012933817924931645
Loss at iteration 400 : 0.0034041879698634148
Loss at iteration 410 : 0.00015213614096865058
Loss at iteration 420 : 8.065018482739106e-05
Loss at iteration 430 : 0.0020359689369797707
Loss at iteration 440 : 0.0013820112217217684
Loss at iteration 450 : 0.00038384925574064255
Loss at iteration 460 : 0.0001444143708795309
Loss at iteration 470 : 0.0008053184719756246
Loss at iteration 480 : 8.979876292869449e-05
Loss at iteration 490 : 0.00025412626564502716
Loss at iteration 500 : 9.69119428191334e-05
Loss at iteration 510 : 0.00011706633813446388
Loss at iteration 520 : 0.0035655382089316845
Loss at iteration 530 : 0.0002549695782363415
Loss at iteration 540 : 0.0009266925044357777
Loss at iteration 550 : 0.00018768552399706095
Loss at iteration 560 : 0.0029459025245159864
Loss at iteration 570 : 0.00015779957175254822
Loss at iteration 580 : 0.00015378504758700728
Loss at iteration 590 : 0.00024001108249649405
Loss at iteration 600 : 0.0007881348137743771
Loss at iteration 610 : 0.0017864262918010354
Loss at iteration 620 : 0.00022030035324860364
Loss at iteration 630 : 0.0013816935243085027
Loss at iteration 640 : 0.00042490236228331923
Loss at iteration 650 : 0.00016610872989986092
Loss at iteration 660 : 0.0008946212474256754
Loss at iteration 670 : 0.00020876259077340364
Loss at iteration 680 : 0.00014253689732868224
Loss at iteration 690 : 0.0008791979635134339
Loss at iteration 700 : 0.00011209011427126825
Loss at iteration 710 : 0.00014076719526201487
Loss at iteration 720 : 0.0024690707214176655
Loss at iteration 730 : 0.00028972659492865205
Loss at iteration 740 : 0.004881850443780422
Loss at iteration 750 : 0.00012979464372619987
Loss at iteration 760 : 0.00021024906891398132
Loss at iteration 770 : 0.001008137478493154
Loss at iteration 780 : 0.00015796648222021759
Loss at iteration 790 : 0.000452247477369383
Loss at iteration 800 : 0.00035346290678717196
Loss at iteration 810 : 0.00018495164113119245
Loss at iteration 820 : 0.00018857618852052838
Loss at iteration 830 : 0.002155416179448366
Loss at iteration 840 : 0.0007900833734311163
Loss at iteration 850 : 0.0005485577275976539
Loss at iteration 860 : 0.0004470772692002356
Loss at iteration 870 : 0.0008456779760308564
Loss at iteration 880 : 0.00016989518189802766
Loss at iteration 890 : 0.00015790229372214526
Loss at iteration 900 : 0.00023542532289866358
Loss at iteration 910 : 0.00010692646173993126
Loss at iteration 920 : 0.0009964504279196262
Loss at iteration 930 : 0.00011314440780552104
Loss at iteration 940 : 0.0017361886566504836
Loss at iteration 950 : 0.0027972604148089886
Loss at iteration 960 : 6.886111805215478e-05
Loss at iteration 970 : 0.00017332688730675727
Loss at iteration 980 : 0.0020406502299010754
Loss at iteration 990 : 0.00022877345327287912
Loss at iteration 1000 : 0.0001924714888446033
Loss at iteration 1010 : 0.000301807071082294
Loss at iteration 1020 : 0.002443468663841486
Loss at iteration 1030 : 0.00025461622863076627
Loss at iteration 1040 : 0.00027473861700855196
Loss at iteration 1050 : 0.0001185963410534896
Loss at iteration 1060 : 0.0001879597402876243
Loss at iteration 1070 : 7.33169072191231e-05
Loss at iteration 1080 : 0.00020210599177516997
Loss at iteration 1090 : 0.0018560069147497416
Loss at iteration 1100 : 0.00012148732639616355
Loss at iteration 1110 : 0.0001413314457749948
Loss at iteration 1120 : 9.5613460871391e-05
Loss at iteration 1130 : 0.0005997713888064027
Loss at iteration 1140 : 0.0004265644238330424
Loss at iteration 1150 : 0.00047838722821325064
Loss at iteration 1160 : 0.00418285233899951
Loss at iteration 1170 : 0.00030268667615018785
Loss at iteration 1180 : 0.0007515598554164171
Loss at iteration 1190 : 9.16749777388759e-05
Loss at iteration 1200 : 0.0010639890097081661
Loss at iteration 1210 : 0.0008203639881685376
Loss at iteration 1220 : 0.00648615974932909
Loss at iteration 1230 : 5.8332829212304205e-05
Loss at iteration 1240 : 0.0018310083542019129
Loss at iteration 1250 : 0.001015535555779934
Loss at iteration 1260 : 0.003211679169908166
Loss at iteration 1270 : 0.00023713108384981751
Loss at iteration 1280 : 0.000420716853113845
Loss at iteration 1290 : 0.004406704567372799
Loss at iteration 1300 : 0.0018378871027380228
Loss at iteration 1310 : 0.0002193564869230613
Loss at iteration 1320 : 0.0003762250707950443
Loss at iteration 1330 : 0.001315172528848052
Loss at iteration 1340 : 0.0004580172535497695
Loss at iteration 1350 : 8.99334263522178e-05
Loss at iteration 1360 : 0.00033897539833560586
Loss at iteration 1370 : 0.00012746715219691396
Loss at iteration 1380 : 7.402935443678871e-05
Loss at iteration 1390 : 0.0001048536942107603
Loss at iteration 1400 : 8.179742872016504e-05
Loss at iteration 1410 : 0.0002976477553602308
Loss at iteration 1420 : 0.0012951088137924671
Loss at iteration 1430 : 0.0006740066455677152
Loss at iteration 1440 : 0.0006765870493836701
Loss at iteration 1450 : 0.00011036729847546667
Loss at iteration 1460 : 9.630506247049198e-05
Loss at iteration 1470 : 0.00028697578818537295
Loss at iteration 1480 : 0.00023814811720512807
Loss at iteration 1490 : 0.004690825007855892
Loss at iteration 1500 : 0.0011870557209476829
Loss at iteration 1510 : 0.004124438855797052
Loss at iteration 1520 : 0.0014763819053769112
Loss at iteration 1530 : 0.0008646086207590997
Loss at iteration 1540 : 0.00034982082433998585
Loss at iteration 1550 : 0.00028702730196528137
Loss at iteration 1560 : 0.0004702256992459297
Loss at iteration 1570 : 0.0006501434836536646
Loss at iteration 1580 : 0.005483334884047508
Loss at iteration 1590 : 0.0003722560068126768
Loss at iteration 1600 : 0.0002427431318210438
Loss at iteration 1610 : 0.00040119580808095634
Loss at iteration 1620 : 0.000801368965767324
Loss at iteration 1630 : 0.0005482119740918279
Loss at iteration 1640 : 0.00022439795429818332
Loss at iteration 1650 : 0.00016695047088433057
Loss at iteration 1660 : 0.0018974010599777102
Loss at iteration 1670 : 0.00022475655714515597
Loss at iteration 1680 : 0.0008538427646271884
Loss at iteration 1690 : 5.5555115977767855e-05
Loss at iteration 1700 : 0.0002454563800711185
Loss at iteration 1710 : 8.913589408621192e-05
Loss at iteration 1720 : 0.00037558915209956467
Loss at iteration 1730 : 9.898199641611427e-05
Loss at iteration 1740 : 0.0002050405746558681
Loss at iteration 1750 : 8.132777293212712e-05
The SSIM Value is: 0.9843241389233636
The PSNR Value is: 46.5924890892096
the epoch is: 170
Loss at iteration 10 : 0.0007276523392647505
Loss at iteration 20 : 0.00026555644581094384
Loss at iteration 30 : 0.0002237912267446518
Loss at iteration 40 : 5.3293922974262387e-05
Loss at iteration 50 : 0.000227771102800034
Loss at iteration 60 : 0.00028212121105752885
Loss at iteration 70 : 0.0001931040605995804
Loss at iteration 80 : 0.0003007207124028355
Loss at iteration 90 : 0.00023556742235086858
Loss at iteration 100 : 0.0019996529445052147
Loss at iteration 110 : 0.0002354333410039544
Loss at iteration 120 : 0.0001449900446459651
Loss at iteration 130 : 0.00015101073950063437
Loss at iteration 140 : 0.003660720307379961
Loss at iteration 150 : 0.00013180880341678858
Loss at iteration 160 : 0.0014232726534828544
Loss at iteration 170 : 0.00010152427421417087
Loss at iteration 180 : 0.000269722833763808
Loss at iteration 190 : 9.025390318129212e-05
Loss at iteration 200 : 9.809873881749809e-05
Loss at iteration 210 : 0.00012764884741045535
Loss at iteration 220 : 8.463055564789101e-05
Loss at iteration 230 : 0.0014876362401992083
Loss at iteration 240 : 0.0009086376521736383
Loss at iteration 250 : 0.0034599844366312027
Loss at iteration 260 : 0.000508552067913115
Loss at iteration 270 : 0.004395665135234594
Loss at iteration 280 : 0.00014362168440129608
Loss at iteration 290 : 0.00011006545537384227
Loss at iteration 300 : 0.0020842431113123894
Loss at iteration 310 : 0.0006885575130581856
Loss at iteration 320 : 0.0013210942270234227
Loss at iteration 330 : 0.00034099898766726255
Loss at iteration 340 : 0.0002620155573822558
Loss at iteration 350 : 0.00037767310277558863
Loss at iteration 360 : 0.002463722601532936
Loss at iteration 370 : 0.00046364805893972516
Loss at iteration 380 : 0.0005909937317483127
Loss at iteration 390 : 0.00024273572489619255
Loss at iteration 400 : 0.0003399567794986069
Loss at iteration 410 : 0.0001755150151439011
Loss at iteration 420 : 0.002699133474379778
Loss at iteration 430 : 0.00031930115073919296
Loss at iteration 440 : 0.0001784013002179563
Loss at iteration 450 : 0.00033496314426884055
Loss at iteration 460 : 5.799384962301701e-05
Loss at iteration 470 : 6.440218567149714e-05
Loss at iteration 480 : 0.0012104525230824947
Loss at iteration 490 : 0.00011404942051740363
Loss at iteration 500 : 0.00013789325021207333
Loss at iteration 510 : 0.0001318689319305122
Loss at iteration 520 : 0.00023298068845178932
Loss at iteration 530 : 0.0003930268867406994
Loss at iteration 540 : 0.002709073480218649
Loss at iteration 550 : 0.0002771932049654424
Loss at iteration 560 : 6.196970207383856e-05
Loss at iteration 570 : 0.002677860204130411
Loss at iteration 580 : 0.0002236677973996848
Loss at iteration 590 : 0.0018815012881532311
Loss at iteration 600 : 0.00013671130000147969
Loss at iteration 610 : 0.00014690274838358164
Loss at iteration 620 : 0.00032817202736623585
Loss at iteration 630 : 0.00041620380943641067
Loss at iteration 640 : 0.0004274711827747524
Loss at iteration 650 : 0.0008398147183470428
Loss at iteration 660 : 0.0021837486419826746
Loss at iteration 670 : 0.000621522543951869
Loss at iteration 680 : 0.00012904635514132679
Loss at iteration 690 : 6.41266378806904e-05
Loss at iteration 700 : 0.000143428856972605
Loss at iteration 710 : 0.0010876312153413892
Loss at iteration 720 : 7.857584569137543e-05
Loss at iteration 730 : 0.0013575213961303234
Loss at iteration 740 : 0.00012820963456761092
Loss at iteration 750 : 0.0038290699012577534
Loss at iteration 760 : 8.892767073120922e-05
Loss at iteration 770 : 0.002859449712559581
Loss at iteration 780 : 0.0005060774274170399
Loss at iteration 790 : 0.00010870202822843567
Loss at iteration 800 : 0.0006121943588368595
Loss at iteration 810 : 0.0004269326163921505
Loss at iteration 820 : 0.0007156222127377987
Loss at iteration 830 : 0.00013951973232906312
Loss at iteration 840 : 0.00028612377354875207
Loss at iteration 850 : 0.0006255238549783826
Loss at iteration 860 : 0.0008042494300752878
Loss at iteration 870 : 0.00027928780764341354
Loss at iteration 880 : 0.0001672126236371696
Loss at iteration 890 : 0.002801388269290328
Loss at iteration 900 : 0.00015351345064118505
Loss at iteration 910 : 0.0026533983182162046
Loss at iteration 920 : 0.0010076283942908049
Loss at iteration 930 : 0.0006047231145203114
Loss at iteration 940 : 0.0029269063379615545
Loss at iteration 950 : 7.382786134257913e-05
Loss at iteration 960 : 0.006461475044488907
Loss at iteration 970 : 6.638505874434486e-05
Loss at iteration 980 : 0.00013008694804739207
Loss at iteration 990 : 0.0002461025433149189
Loss at iteration 1000 : 0.00019764431635849178
Loss at iteration 1010 : 8.620878361398354e-05
Loss at iteration 1020 : 0.00032712743268348277
Loss at iteration 1030 : 0.002058859448879957
Loss at iteration 1040 : 0.0006843750015832484
Loss at iteration 1050 : 0.0003982025955338031
Loss at iteration 1060 : 0.0006934832781553268
Loss at iteration 1070 : 0.0001225861778948456
Loss at iteration 1080 : 0.00029434330645017326
Loss at iteration 1090 : 0.0001471411087550223
Loss at iteration 1100 : 0.0002865307906176895
Loss at iteration 1110 : 0.005019939038902521
Loss at iteration 1120 : 0.00025822105817496777
Loss at iteration 1130 : 0.0006537499139085412
Loss at iteration 1140 : 0.0011235291603952646
Loss at iteration 1150 : 0.0013099083444103599
Loss at iteration 1160 : 0.0010155420750379562
Loss at iteration 1170 : 0.00010328064672648907
Loss at iteration 1180 : 8.28695556265302e-05
Loss at iteration 1190 : 0.0016754905227571726
Loss at iteration 1200 : 0.0010703371372073889
Loss at iteration 1210 : 0.00012448015331756324
Loss at iteration 1220 : 0.002038590842857957
Loss at iteration 1230 : 0.000628344074357301
Loss at iteration 1240 : 0.00043992558494210243
Loss at iteration 1250 : 0.000320328283123672
Loss at iteration 1260 : 0.00022567766427528113
Loss at iteration 1270 : 0.0033373788464814425
Loss at iteration 1280 : 0.0006362437270581722
Loss at iteration 1290 : 0.0003295448259450495
Loss at iteration 1300 : 0.0010222832206636667
Loss at iteration 1310 : 0.00140514993108809
Loss at iteration 1320 : 0.003985822666436434
Loss at iteration 1330 : 0.0002455899375490844
Loss at iteration 1340 : 0.004622037056833506
Loss at iteration 1350 : 0.00016837232396937907
Loss at iteration 1360 : 0.0028819735161960125
Loss at iteration 1370 : 0.00058182911016047
Loss at iteration 1380 : 0.0001255410024896264
Loss at iteration 1390 : 0.00018348016601521522
Loss at iteration 1400 : 0.0007566610001958907
Loss at iteration 1410 : 0.0009695984190329909
Loss at iteration 1420 : 0.004261627793312073
Loss at iteration 1430 : 0.00043429603101685643
Loss at iteration 1440 : 0.0003143014037050307
Loss at iteration 1450 : 0.004019072744995356
Loss at iteration 1460 : 0.0021197544410824776
Loss at iteration 1470 : 0.00012851486098952591
Loss at iteration 1480 : 0.0025961301289498806
Loss at iteration 1490 : 0.0008117292309179902
Loss at iteration 1500 : 0.00014980351261328906
Loss at iteration 1510 : 0.00045886007137596607
Loss at iteration 1520 : 0.0002838010259438306
Loss at iteration 1530 : 0.00015256402548402548
Loss at iteration 1540 : 0.0019823494367301464
Loss at iteration 1550 : 0.0005764705128967762
Loss at iteration 1560 : 0.0003302402619738132
Loss at iteration 1570 : 5.51592638657894e-05
Loss at iteration 1580 : 0.000765137083362788
Loss at iteration 1590 : 0.0005168889183551073
Loss at iteration 1600 : 0.0015320025850087404
Loss at iteration 1610 : 8.4862214862369e-05
Loss at iteration 1620 : 0.00029805966187268496
Loss at iteration 1630 : 0.0012016035616397858
Loss at iteration 1640 : 0.00011257285950705409
Loss at iteration 1650 : 0.00024497907725162804
Loss at iteration 1660 : 0.00019031224655918777
Loss at iteration 1670 : 0.001766718807630241
Loss at iteration 1680 : 4.384426574688405e-05
Loss at iteration 1690 : 0.0006791454507037997
Loss at iteration 1700 : 0.0021833747159689665
Loss at iteration 1710 : 0.00043447676580399275
Loss at iteration 1720 : 0.00013567015412263572
Loss at iteration 1730 : 0.0008868504082784057
Loss at iteration 1740 : 0.00017691359971649945
Loss at iteration 1750 : 0.005004724022001028
The SSIM Value is: 0.9875215482344186
The PSNR Value is: 46.46820096717532
the epoch is: 171
Loss at iteration 10 : 0.00018245665705762804
Loss at iteration 20 : 0.000964469276368618
Loss at iteration 30 : 6.49283902021125e-05
Loss at iteration 40 : 0.0002312721189809963
Loss at iteration 50 : 0.005240913946181536
Loss at iteration 60 : 0.00014371087308973074
Loss at iteration 70 : 0.00017896686040330678
Loss at iteration 80 : 0.0005331352003850043
Loss at iteration 90 : 0.0002362622763030231
Loss at iteration 100 : 0.00027565922937355936
Loss at iteration 110 : 0.00028029922395944595
Loss at iteration 120 : 0.000272753881290555
Loss at iteration 130 : 0.0036426454316824675
Loss at iteration 140 : 0.000697447219863534
Loss at iteration 150 : 0.00010902598296524957
Loss at iteration 160 : 0.0017667582724243402
Loss at iteration 170 : 0.005787384696304798
Loss at iteration 180 : 0.004371696151793003
Loss at iteration 190 : 0.0004981243400834501
Loss at iteration 200 : 0.0018208450637757778
Loss at iteration 210 : 0.00022815777629148215
Loss at iteration 220 : 0.0023594002705067396
Loss at iteration 230 : 0.0008734890725463629
Loss at iteration 240 : 0.0032396968454122543
Loss at iteration 250 : 0.0002449963940307498
Loss at iteration 260 : 0.00019706832244992256
Loss at iteration 270 : 0.0010085898684337735
Loss at iteration 280 : 0.0011789498385041952
Loss at iteration 290 : 7.576085772598162e-05
Loss at iteration 300 : 0.00028867507353425026
Loss at iteration 310 : 0.0001658156543271616
Loss at iteration 320 : 0.00022224968415684998
Loss at iteration 330 : 0.0002823319227900356
Loss at iteration 340 : 0.0001573497720528394
Loss at iteration 350 : 0.0001480317150708288
Loss at iteration 360 : 0.002961014397442341
Loss at iteration 370 : 0.0031680017709732056
Loss at iteration 380 : 0.003149026073515415
Loss at iteration 390 : 0.0001812607079045847
Loss at iteration 400 : 4.342212196206674e-05
Loss at iteration 410 : 0.00010229296458419412
Loss at iteration 420 : 0.00048564240569248796
Loss at iteration 430 : 0.0001267898769583553
Loss at iteration 440 : 0.00010357499559177086
Loss at iteration 450 : 0.0007194934878498316
Loss at iteration 460 : 0.0028096733149141073
Loss at iteration 470 : 0.0001988523144973442
Loss at iteration 480 : 0.00027289974968880415
Loss at iteration 490 : 0.0018202918581664562
Loss at iteration 500 : 0.0007302086451090872
Loss at iteration 510 : 0.000170660117873922
Loss at iteration 520 : 9.532018884783611e-05
Loss at iteration 530 : 0.0013154885964468122
Loss at iteration 540 : 0.003333435393869877
Loss at iteration 550 : 0.0010173583868891
Loss at iteration 560 : 0.0005898681120015681
Loss at iteration 570 : 0.00036385536077432334
Loss at iteration 580 : 0.00017101883713621646
Loss at iteration 590 : 0.0027443738654255867
Loss at iteration 600 : 0.00011960745905525982
Loss at iteration 610 : 0.003111152211204171
Loss at iteration 620 : 0.0025802156887948513
Loss at iteration 630 : 0.0028730989433825016
Loss at iteration 640 : 0.0005561384023167193
Loss at iteration 650 : 8.595574763603508e-05
Loss at iteration 660 : 0.0034042224287986755
Loss at iteration 670 : 0.00030006279121153057
Loss at iteration 680 : 0.0011764540104195476
Loss at iteration 690 : 0.0011903793783858418
Loss at iteration 700 : 0.0005314687732607126
Loss at iteration 710 : 8.326514216605574e-05
Loss at iteration 720 : 0.000426317797973752
Loss at iteration 730 : 0.0002109617053065449
Loss at iteration 740 : 6.813555955886841e-05
Loss at iteration 750 : 0.0014098617248237133
Loss at iteration 760 : 0.00010642810957506299
Loss at iteration 770 : 0.00023843128292355686
Loss at iteration 780 : 0.00015442262520082295
Loss at iteration 790 : 7.011865091044456e-05
Loss at iteration 800 : 0.000805967953056097
Loss at iteration 810 : 0.0001809242821764201
Loss at iteration 820 : 0.0003860095457639545
Loss at iteration 830 : 9.738428343553096e-05
Loss at iteration 840 : 0.00021348008885979652
Loss at iteration 850 : 0.00012918449647258967
Loss at iteration 860 : 0.0002992856316268444
Loss at iteration 870 : 0.00011816681217169389
Loss at iteration 880 : 0.00018760503735393286
Loss at iteration 890 : 0.00012301169044803828
Loss at iteration 900 : 0.004264119081199169
Loss at iteration 910 : 8.916033402783796e-05
Loss at iteration 920 : 0.00021542076137848198
Loss at iteration 930 : 0.002311079064384103
Loss at iteration 940 : 0.001613769680261612
Loss at iteration 950 : 0.0014412597520276904
Loss at iteration 960 : 0.00010437649325467646
Loss at iteration 970 : 0.002704116515815258
Loss at iteration 980 : 0.0004050979623571038
Loss at iteration 990 : 0.0009776465594768524
Loss at iteration 1000 : 0.0026113626081496477
Loss at iteration 1010 : 0.00021875598758924752
Loss at iteration 1020 : 0.0008173949318006635
Loss at iteration 1030 : 0.0001405999209964648
Loss at iteration 1040 : 0.00014724872016813606
Loss at iteration 1050 : 0.002077095676213503
Loss at iteration 1060 : 0.00018303105025552213
Loss at iteration 1070 : 0.00037411769153550267
Loss at iteration 1080 : 0.00012929612421430647
Loss at iteration 1090 : 0.00023138540564104915
Loss at iteration 1100 : 0.0026446133852005005
Loss at iteration 1110 : 0.0016743345186114311
Loss at iteration 1120 : 0.0003983012866228819
Loss at iteration 1130 : 0.0001284949976252392
Loss at iteration 1140 : 0.00459584966301918
Loss at iteration 1150 : 0.0019057734170928597
Loss at iteration 1160 : 0.0010594534687697887
Loss at iteration 1170 : 0.0010339317377656698
Loss at iteration 1180 : 0.00024281776859425008
Loss at iteration 1190 : 0.0028351652435958385
Loss at iteration 1200 : 0.00017111608758568764
Loss at iteration 1210 : 0.0009327284642495215
Loss at iteration 1220 : 0.00018524508050177246
Loss at iteration 1230 : 0.0005444786511361599
Loss at iteration 1240 : 0.0007927701808512211
Loss at iteration 1250 : 0.00013215116632636636
Loss at iteration 1260 : 0.00010572897008387372
Loss at iteration 1270 : 0.00020625223987735808
Loss at iteration 1280 : 0.00020128110190853477
Loss at iteration 1290 : 0.0004020193009637296
Loss at iteration 1300 : 0.0001190476177725941
Loss at iteration 1310 : 9.749753371579573e-05
Loss at iteration 1320 : 0.004520452581346035
Loss at iteration 1330 : 0.0028175837360322475
Loss at iteration 1340 : 0.002627304755151272
Loss at iteration 1350 : 0.0004708539927378297
Loss at iteration 1360 : 0.00013720866991207004
Loss at iteration 1370 : 0.001628900645300746
Loss at iteration 1380 : 8.896896906662732e-05
Loss at iteration 1390 : 5.4392978199757636e-05
Loss at iteration 1400 : 0.00029694446129724383
Loss at iteration 1410 : 0.00020224088802933693
Loss at iteration 1420 : 7.830105460016057e-05
Loss at iteration 1430 : 0.0002711750566959381
Loss at iteration 1440 : 0.0015190514968708158
Loss at iteration 1450 : 0.00012249524297658354
Loss at iteration 1460 : 0.00034768489422276616
Loss at iteration 1470 : 0.0005837369244545698
Loss at iteration 1480 : 0.002059925114735961
Loss at iteration 1490 : 0.004361360799521208
Loss at iteration 1500 : 0.0003839174169115722
Loss at iteration 1510 : 0.00016732783115003258
Loss at iteration 1520 : 0.0012272733729332685
Loss at iteration 1530 : 0.00021626334637403488
Loss at iteration 1540 : 0.00012456855620257556
Loss at iteration 1550 : 4.2934378143399954e-05
Loss at iteration 1560 : 0.005064771044999361
Loss at iteration 1570 : 0.0005102275172248483
Loss at iteration 1580 : 0.0003354028449393809
Loss at iteration 1590 : 0.0004708513733930886
Loss at iteration 1600 : 0.00015723941032774746
Loss at iteration 1610 : 0.000586327922064811
Loss at iteration 1620 : 3.1779531127540395e-05
Loss at iteration 1630 : 0.0009332287590950727
Loss at iteration 1640 : 0.0009389362530782819
Loss at iteration 1650 : 0.00020951955229975283
Loss at iteration 1660 : 0.001483915257267654
Loss at iteration 1670 : 0.0003190044080838561
Loss at iteration 1680 : 0.0001978650107048452
Loss at iteration 1690 : 0.000233991930144839
Loss at iteration 1700 : 0.0002332328585907817
Loss at iteration 1710 : 0.0004936457262374461
Loss at iteration 1720 : 0.00011381521471776068
Loss at iteration 1730 : 0.0001239422708749771
Loss at iteration 1740 : 0.00013759748253505677
Loss at iteration 1750 : 0.002282473724335432
The SSIM Value is: 0.9835134316646055
The PSNR Value is: 46.6397241264713
the epoch is: 172
Loss at iteration 10 : 0.00012685084948316216
Loss at iteration 20 : 0.00035247186315245926
Loss at iteration 30 : 0.00010523072705836967
Loss at iteration 40 : 0.00037887736107222736
Loss at iteration 50 : 0.0008191609522327781
Loss at iteration 60 : 0.006398052908480167
Loss at iteration 70 : 0.0021922311279922724
Loss at iteration 80 : 7.296199328266084e-05
Loss at iteration 90 : 0.002257691230624914
Loss at iteration 100 : 0.00018057557463180274
Loss at iteration 110 : 4.137128053116612e-05
Loss at iteration 120 : 0.00012426865578163415
Loss at iteration 130 : 0.0002517917309887707
Loss at iteration 140 : 0.0002797104825731367
Loss at iteration 150 : 0.0030996103305369616
Loss at iteration 160 : 0.00012534414418041706
Loss at iteration 170 : 9.641934593673795e-05
Loss at iteration 180 : 0.00021171843400225043
Loss at iteration 190 : 6.733697955496609e-05
Loss at iteration 200 : 0.001070539467036724
Loss at iteration 210 : 0.00014185010513756424
Loss at iteration 220 : 0.0003279635275248438
Loss at iteration 230 : 0.0008138328557834029
Loss at iteration 240 : 0.004208758007735014
Loss at iteration 250 : 0.0002754183078650385
Loss at iteration 260 : 0.0005595660768449306
Loss at iteration 270 : 0.005855092778801918
Loss at iteration 280 : 0.00033174033160321414
Loss at iteration 290 : 8.861620153766125e-05
Loss at iteration 300 : 0.00010137330536963418
Loss at iteration 310 : 0.0002944091975223273
Loss at iteration 320 : 8.756073657423258e-05
Loss at iteration 330 : 0.00026072573382407427
Loss at iteration 340 : 7.50765684642829e-05
Loss at iteration 350 : 3.407976691960357e-05
Loss at iteration 360 : 9.324285201728344e-05
Loss at iteration 370 : 0.00012514882837422192
Loss at iteration 380 : 0.0014757398748770356
Loss at iteration 390 : 0.0014250872191041708
Loss at iteration 400 : 0.00023906215210445225
Loss at iteration 410 : 0.00025809649378061295
Loss at iteration 420 : 0.0020296829752624035
Loss at iteration 430 : 0.00042994043906219304
Loss at iteration 440 : 0.0010876985033974051
Loss at iteration 450 : 0.00015106401406228542
Loss at iteration 460 : 0.0006857581902295351
Loss at iteration 470 : 0.001251440029591322
Loss at iteration 480 : 8.545014861738309e-05
Loss at iteration 490 : 0.0009875679388642311
Loss at iteration 500 : 0.005353473126888275
Loss at iteration 510 : 0.0003206856199540198
Loss at iteration 520 : 0.00012363080168142915
Loss at iteration 530 : 8.526442252332345e-05
Loss at iteration 540 : 6.75981500535272e-05
Loss at iteration 550 : 0.0028701203409582376
Loss at iteration 560 : 4.28965940955095e-05
Loss at iteration 570 : 0.00023221726587507874
Loss at iteration 580 : 0.00040558120235800743
Loss at iteration 590 : 0.0006969105452299118
Loss at iteration 600 : 6.999758625170216e-05
Loss at iteration 610 : 0.00016160740051418543
Loss at iteration 620 : 0.0008894078782759607
Loss at iteration 630 : 0.00022686617739964277
Loss at iteration 640 : 0.0001040347051457502
Loss at iteration 650 : 0.0002855610509868711
Loss at iteration 660 : 0.00025151699082925916
Loss at iteration 670 : 0.0016780518926680088
Loss at iteration 680 : 0.0012437701225280762
Loss at iteration 690 : 0.00014918751548975706
Loss at iteration 700 : 6.541514449054375e-05
Loss at iteration 710 : 5.19928835274186e-05
Loss at iteration 720 : 5.8155237638857216e-05
Loss at iteration 730 : 0.0003328649909235537
Loss at iteration 740 : 0.0002555855899117887
Loss at iteration 750 : 0.0019710087217390537
Loss at iteration 760 : 0.0006148278480395675
Loss at iteration 770 : 0.002445709425956011
Loss at iteration 780 : 0.003375778906047344
Loss at iteration 790 : 0.00026376612368039787
Loss at iteration 800 : 0.00032085771090351045
Loss at iteration 810 : 0.00034751463681459427
Loss at iteration 820 : 0.0003483196487650275
Loss at iteration 830 : 0.00018605637887958437
Loss at iteration 840 : 0.00020876310009043664
Loss at iteration 850 : 0.00012065710325259715
Loss at iteration 860 : 0.0036299547646194696
Loss at iteration 870 : 0.0008273799321614206
Loss at iteration 880 : 0.009718261659145355
Loss at iteration 890 : 0.00012196158058941364
Loss at iteration 900 : 0.0004729446955025196
Loss at iteration 910 : 3.781474515562877e-05
Loss at iteration 920 : 0.005467983894050121
Loss at iteration 930 : 0.0001942007802426815
Loss at iteration 940 : 5.85370471526403e-05
Loss at iteration 950 : 0.00014212816313374788
Loss at iteration 960 : 7.08690204191953e-05
Loss at iteration 970 : 0.0002496456727385521
Loss at iteration 980 : 0.002013890305534005
Loss at iteration 990 : 0.00028733877115882933
Loss at iteration 1000 : 7.757900311844423e-05
Loss at iteration 1010 : 0.00016282559954561293
Loss at iteration 1020 : 0.0009148003882728517
Loss at iteration 1030 : 0.00027937800041399896
Loss at iteration 1040 : 0.00022050677216611803
Loss at iteration 1050 : 0.00023523079289589077
Loss at iteration 1060 : 0.001739627681672573
Loss at iteration 1070 : 0.0006458080024458468
Loss at iteration 1080 : 0.00018208156689070165
Loss at iteration 1090 : 0.007014602888375521
Loss at iteration 1100 : 0.0030770874582231045
Loss at iteration 1110 : 0.0001305317273363471
Loss at iteration 1120 : 0.0005552662187255919
Loss at iteration 1130 : 0.00015147373778745532
Loss at iteration 1140 : 0.00022198162332642823
Loss at iteration 1150 : 0.00036388495936989784
Loss at iteration 1160 : 0.00010472966823726892
Loss at iteration 1170 : 8.92532552825287e-05
Loss at iteration 1180 : 0.00027129409136250615
Loss at iteration 1190 : 0.00026270735543221235
Loss at iteration 1200 : 0.00010111361916642636
Loss at iteration 1210 : 0.0022877282463014126
Loss at iteration 1220 : 0.0001976292987819761
Loss at iteration 1230 : 0.0011915317736566067
Loss at iteration 1240 : 0.002431281842291355
Loss at iteration 1250 : 0.00010331269004382193
Loss at iteration 1260 : 0.00010802621545735747
Loss at iteration 1270 : 0.00016715402307454497
Loss at iteration 1280 : 0.0005016748327761889
Loss at iteration 1290 : 0.0026550395414233208
Loss at iteration 1300 : 0.0027424648869782686
Loss at iteration 1310 : 0.0003332743654027581
Loss at iteration 1320 : 0.0005422959802672267
Loss at iteration 1330 : 4.204464130452834e-05
Loss at iteration 1340 : 0.003758328501135111
Loss at iteration 1350 : 0.00040350048220716417
Loss at iteration 1360 : 0.00030190421966835856
Loss at iteration 1370 : 0.00043532688869163394
Loss at iteration 1380 : 0.00012175156734883785
Loss at iteration 1390 : 0.0031695524230599403
Loss at iteration 1400 : 0.004058242309838533
Loss at iteration 1410 : 0.0001211141498060897
Loss at iteration 1420 : 0.002204053569585085
Loss at iteration 1430 : 0.0006839246489107609
Loss at iteration 1440 : 0.0001652034989092499
Loss at iteration 1450 : 0.0005210059462115169
Loss at iteration 1460 : 0.0003368909819982946
Loss at iteration 1470 : 0.0037103178910911083
Loss at iteration 1480 : 8.663796324981377e-05
Loss at iteration 1490 : 0.00039565982297062874
Loss at iteration 1500 : 0.0012184666702523828
Loss at iteration 1510 : 0.0027692040894180536
Loss at iteration 1520 : 0.0009196989121846855
Loss at iteration 1530 : 0.00028404995100572705
Loss at iteration 1540 : 0.0002728654071688652
Loss at iteration 1550 : 0.00040190195431932807
Loss at iteration 1560 : 0.0006241101073101163
Loss at iteration 1570 : 0.0013774081598967314
Loss at iteration 1580 : 0.00013410020619630814
Loss at iteration 1590 : 0.0002231583057437092
Loss at iteration 1600 : 0.0024429811164736748
Loss at iteration 1610 : 0.00017264521738979965
Loss at iteration 1620 : 0.00039929160266183317
Loss at iteration 1630 : 0.00012240925570949912
Loss at iteration 1640 : 0.002844305941835046
Loss at iteration 1650 : 0.0005470903124660254
Loss at iteration 1660 : 0.0001647033786866814
Loss at iteration 1670 : 0.0002860163222067058
Loss at iteration 1680 : 0.00015934515977278352
Loss at iteration 1690 : 0.000641464430373162
Loss at iteration 1700 : 0.0043035526759922504
Loss at iteration 1710 : 9.16301942197606e-05
Loss at iteration 1720 : 0.0004425123333930969
Loss at iteration 1730 : 0.00015914921823423356
Loss at iteration 1740 : 0.0004884146037511528
Loss at iteration 1750 : 0.00024415901862084866
The SSIM Value is: 0.9881928473842302
The PSNR Value is: 46.55233619916807
the epoch is: 173
Loss at iteration 10 : 8.697483281139284e-05
Loss at iteration 20 : 0.00020970232435502112
Loss at iteration 30 : 0.00012742583930958062
Loss at iteration 40 : 0.0007555081392638385
Loss at iteration 50 : 0.00033419113606214523
Loss at iteration 60 : 0.0014508954482153058
Loss at iteration 70 : 0.00013504990783985704
Loss at iteration 80 : 0.0019885809160768986
Loss at iteration 90 : 0.0031907723750919104
Loss at iteration 100 : 0.0012258619535714388
Loss at iteration 110 : 0.00028877725708298385
Loss at iteration 120 : 0.0004434538714122027
Loss at iteration 130 : 0.00011458823428256437
Loss at iteration 140 : 0.00022567146515939385
Loss at iteration 150 : 0.00013880871119908988
Loss at iteration 160 : 0.00011548273323569447
Loss at iteration 170 : 0.00015223670925479382
Loss at iteration 180 : 0.00019770636572502553
Loss at iteration 190 : 0.0014693420380353928
Loss at iteration 200 : 0.002749253995716572
Loss at iteration 210 : 0.00041969920857809484
Loss at iteration 220 : 0.00015627994434908032
Loss at iteration 230 : 0.0001234622613992542
Loss at iteration 240 : 0.00023373874137178063
Loss at iteration 250 : 0.003023292403668165
Loss at iteration 260 : 8.396826160605997e-05
Loss at iteration 270 : 0.0008955757366493344
Loss at iteration 280 : 0.001732901786454022
Loss at iteration 290 : 0.0013852599076926708
Loss at iteration 300 : 0.000261772598605603
Loss at iteration 310 : 0.0005246751243248582
Loss at iteration 320 : 8.666110807098448e-05
Loss at iteration 330 : 0.00013220228720456362
Loss at iteration 340 : 0.0011790652060881257
Loss at iteration 350 : 0.00015347814769484103
Loss at iteration 360 : 0.0008888700976967812
Loss at iteration 370 : 0.0006481213495135307
Loss at iteration 380 : 0.000142545803100802
Loss at iteration 390 : 0.0006304202252067626
Loss at iteration 400 : 0.0004538548528216779
Loss at iteration 410 : 0.00012619345216080546
Loss at iteration 420 : 0.00023889563453849405
Loss at iteration 430 : 0.0005946350865997374
Loss at iteration 440 : 0.0007842241320759058
Loss at iteration 450 : 0.00014935905346646905
Loss at iteration 460 : 0.0005233351257629693
Loss at iteration 470 : 0.0015599534381181002
Loss at iteration 480 : 0.0005384385003708303
Loss at iteration 490 : 0.004537232220172882
Loss at iteration 500 : 0.0001046474717441015
Loss at iteration 510 : 0.00015569187235087156
Loss at iteration 520 : 0.0015902214217931032
Loss at iteration 530 : 0.0009067500941455364
Loss at iteration 540 : 0.0028549504932016134
Loss at iteration 550 : 0.0001497334596933797
Loss at iteration 560 : 0.0001713536330498755
Loss at iteration 570 : 0.00015092699322849512
Loss at iteration 580 : 0.0024340564850717783
Loss at iteration 590 : 0.000618502963334322
Loss at iteration 600 : 0.00030863232677802444
Loss at iteration 610 : 0.00037458440056070685
Loss at iteration 620 : 0.005364824086427689
Loss at iteration 630 : 0.00014041454414837062
Loss at iteration 640 : 0.0026807133108377457
Loss at iteration 650 : 0.00011182609159732237
Loss at iteration 660 : 0.0006475918926298618
Loss at iteration 670 : 0.00012826612510252744
Loss at iteration 680 : 0.0006463402532972395
Loss at iteration 690 : 0.0005282635102048516
Loss at iteration 700 : 0.0003571390698198229
Loss at iteration 710 : 0.0023903672117739916
Loss at iteration 720 : 0.00016063849034253508
Loss at iteration 730 : 0.004441828932613134
Loss at iteration 740 : 0.0002752787549979985
Loss at iteration 750 : 0.0028976676985621452
Loss at iteration 760 : 0.0007280686986632645
Loss at iteration 770 : 0.0005894066416658461
Loss at iteration 780 : 0.0056797717697918415
Loss at iteration 790 : 0.0001497241173638031
Loss at iteration 800 : 0.0006528034573420882
Loss at iteration 810 : 7.776348502375185e-05
Loss at iteration 820 : 0.0029671876691281796
Loss at iteration 830 : 0.0001828990352805704
Loss at iteration 840 : 0.00043757696403190494
Loss at iteration 850 : 0.00029805710073560476
Loss at iteration 860 : 0.0002998972777277231
Loss at iteration 870 : 0.0004885721718892455
Loss at iteration 880 : 0.0001492504816269502
Loss at iteration 890 : 0.002548245945945382
Loss at iteration 900 : 0.0003310820320621133
Loss at iteration 910 : 0.0003292975598014891
Loss at iteration 920 : 0.00020540393597912043
Loss at iteration 930 : 0.0005431178142316639
Loss at iteration 940 : 0.00035119600943289697
Loss at iteration 950 : 0.0005751567077822983
Loss at iteration 960 : 0.003386600874364376
Loss at iteration 970 : 0.0030135076958686113
Loss at iteration 980 : 7.602006371598691e-05
Loss at iteration 990 : 0.00014190463116392493
Loss at iteration 1000 : 0.006307555362582207
Loss at iteration 1010 : 0.002913042437285185
Loss at iteration 1020 : 0.0003507027286104858
Loss at iteration 1030 : 0.00015725546109024435
Loss at iteration 1040 : 0.0004116540658287704
Loss at iteration 1050 : 0.00011501752305775881
Loss at iteration 1060 : 0.002068618079647422
Loss at iteration 1070 : 0.0023480721283704042
Loss at iteration 1080 : 0.0001620847178855911
Loss at iteration 1090 : 0.000804944837000221
Loss at iteration 1100 : 0.002179894130676985
Loss at iteration 1110 : 0.0006720352103002369
Loss at iteration 1120 : 0.001075491774827242
Loss at iteration 1130 : 0.00028443473274819553
Loss at iteration 1140 : 0.0002656213764566928
Loss at iteration 1150 : 7.985784759512171e-05
Loss at iteration 1160 : 0.0028704151045531034
Loss at iteration 1170 : 0.000646385713480413
Loss at iteration 1180 : 0.0007205434958450496
Loss at iteration 1190 : 0.0008681875187903643
Loss at iteration 1200 : 0.000588750874157995
Loss at iteration 1210 : 0.00037036449066363275
Loss at iteration 1220 : 0.00011085715232184157
Loss at iteration 1230 : 0.00016681166016496718
Loss at iteration 1240 : 0.00035693583777174354
Loss at iteration 1250 : 0.00015805060684215277
Loss at iteration 1260 : 0.00013386439241003245
Loss at iteration 1270 : 0.000593172328080982
Loss at iteration 1280 : 0.00022534986783284694
Loss at iteration 1290 : 0.0005077596870251
Loss at iteration 1300 : 0.004428650718182325
Loss at iteration 1310 : 0.00022571433510165662
Loss at iteration 1320 : 0.00017271154501941055
Loss at iteration 1330 : 0.00016206744476221502
Loss at iteration 1340 : 0.00013655508519150317
Loss at iteration 1350 : 0.00018267838458996266
Loss at iteration 1360 : 0.0001901411742437631
Loss at iteration 1370 : 0.00400517787784338
Loss at iteration 1380 : 0.00017924164421856403
Loss at iteration 1390 : 0.0008480824180878699
Loss at iteration 1400 : 0.003912758082151413
Loss at iteration 1410 : 0.00012635374150704592
Loss at iteration 1420 : 0.0001606835867278278
Loss at iteration 1430 : 0.00018037435074802488
Loss at iteration 1440 : 0.0001655722880968824
Loss at iteration 1450 : 0.003038925351575017
Loss at iteration 1460 : 0.0006888264906592667
Loss at iteration 1470 : 0.0006588929682038724
Loss at iteration 1480 : 0.00012282506213523448
Loss at iteration 1490 : 0.0003630482533480972
Loss at iteration 1500 : 0.0021369019523262978
Loss at iteration 1510 : 0.000344548694556579
Loss at iteration 1520 : 0.0010255323722958565
Loss at iteration 1530 : 0.00012786511797457933
Loss at iteration 1540 : 0.00022300347336567938
Loss at iteration 1550 : 0.0007569327717646956
Loss at iteration 1560 : 0.00023817873443476856
Loss at iteration 1570 : 8.638931467430666e-05
Loss at iteration 1580 : 0.0002818350913003087
Loss at iteration 1590 : 0.0001218558318214491
Loss at iteration 1600 : 0.00022509250266011804
Loss at iteration 1610 : 7.661482959520072e-05
Loss at iteration 1620 : 0.00012547991354949772
Loss at iteration 1630 : 9.710119047667831e-05
Loss at iteration 1640 : 0.0002560318971518427
Loss at iteration 1650 : 0.00037784059531986713
Loss at iteration 1660 : 4.394655843498185e-05
Loss at iteration 1670 : 0.0019437309820204973
Loss at iteration 1680 : 0.0049153040163218975
Loss at iteration 1690 : 0.0002797081251628697
Loss at iteration 1700 : 0.00305618392303586
Loss at iteration 1710 : 0.00041767911170609295
Loss at iteration 1720 : 0.0007139639928936958
Loss at iteration 1730 : 0.00013173834304325283
Loss at iteration 1740 : 0.003981542307883501
Loss at iteration 1750 : 0.0005161167937330902
The SSIM Value is: 0.9873600910676208
The PSNR Value is: 46.48000825134143
the epoch is: 174
Loss at iteration 10 : 0.003852756228297949
Loss at iteration 20 : 0.0031962248031049967
Loss at iteration 30 : 0.00015034351963549852
Loss at iteration 40 : 0.0001680714194662869
Loss at iteration 50 : 3.895104964612983e-05
Loss at iteration 60 : 0.0002093483490170911
Loss at iteration 70 : 0.0008948113536462188
Loss at iteration 80 : 0.00021111802197992802
Loss at iteration 90 : 0.00011388253187760711
Loss at iteration 100 : 0.0005227741785347462
Loss at iteration 110 : 0.0003170106210745871
Loss at iteration 120 : 0.00022236339282244444
Loss at iteration 130 : 0.0003712234611157328
Loss at iteration 140 : 0.00012402873835526407
Loss at iteration 150 : 0.006584770046174526
Loss at iteration 160 : 0.00014159921556711197
Loss at iteration 170 : 0.00014277794980444014
Loss at iteration 180 : 0.0018769620219245553
Loss at iteration 190 : 0.0002652685798238963
Loss at iteration 200 : 0.0017264923080801964
Loss at iteration 210 : 0.001035301829688251
Loss at iteration 220 : 0.0015265741385519505
Loss at iteration 230 : 0.0008312196587212384
Loss at iteration 240 : 0.0006873711827211082
Loss at iteration 250 : 0.0003053097752854228
Loss at iteration 260 : 8.610836084699258e-05
Loss at iteration 270 : 0.0012257815105840564
Loss at iteration 280 : 0.00020799330377485603
Loss at iteration 290 : 0.00013960228534415364
Loss at iteration 300 : 0.00030804198468104005
Loss at iteration 310 : 0.00012698966020252556
Loss at iteration 320 : 0.0001207776294904761
Loss at iteration 330 : 0.00024382355331908911
Loss at iteration 340 : 4.09631356887985e-05
Loss at iteration 350 : 0.00020329027029220015
Loss at iteration 360 : 0.00012515633716247976
Loss at iteration 370 : 9.509571827948093e-05
Loss at iteration 380 : 0.001093485625460744
Loss at iteration 390 : 0.00012590427650138736
Loss at iteration 400 : 0.0005179875297471881
Loss at iteration 410 : 0.001747489208355546
Loss at iteration 420 : 0.00135262671392411
Loss at iteration 430 : 0.0003353769425302744
Loss at iteration 440 : 7.078837370499969e-05
Loss at iteration 450 : 0.00032442505471408367
Loss at iteration 460 : 0.0005886054132133722
Loss at iteration 470 : 0.0002961517311632633
Loss at iteration 480 : 0.0013413954293355346
Loss at iteration 490 : 0.00422340864315629
Loss at iteration 500 : 5.76293641643133e-05
Loss at iteration 510 : 6.987652159295976e-05
Loss at iteration 520 : 0.00016919177141971886
Loss at iteration 530 : 0.0005322915967553854
Loss at iteration 540 : 0.00044169259490445256
Loss at iteration 550 : 0.0007995169144123793
Loss at iteration 560 : 0.00028388691134750843
Loss at iteration 570 : 0.0021649152040481567
Loss at iteration 580 : 0.001882955664768815
Loss at iteration 590 : 0.0006545533542521298
Loss at iteration 600 : 0.00021891934738960117
Loss at iteration 610 : 0.00012143472849857062
Loss at iteration 620 : 0.00013887829845771194
Loss at iteration 630 : 0.001338055357336998
Loss at iteration 640 : 0.0005275909788906574
Loss at iteration 650 : 0.0001324790355283767
Loss at iteration 660 : 0.00028104489319957793
Loss at iteration 670 : 0.001501936581917107
Loss at iteration 680 : 0.0005916052614338696
Loss at iteration 690 : 0.00029882334638386965
Loss at iteration 700 : 0.00010278331319568679
Loss at iteration 710 : 0.0001035437744576484
Loss at iteration 720 : 0.00023442080419044942
Loss at iteration 730 : 0.001455785008147359
Loss at iteration 740 : 0.0013910403940826654
Loss at iteration 750 : 0.00015605802764184773
Loss at iteration 760 : 0.0023535420186817646
Loss at iteration 770 : 0.0008296355954371393
Loss at iteration 780 : 0.0001296175323659554
Loss at iteration 790 : 0.0009477965068072081
Loss at iteration 800 : 0.0033003499265760183
Loss at iteration 810 : 0.00031042160117067397
Loss at iteration 820 : 5.016183422412723e-05
Loss at iteration 830 : 0.0001969331206055358
Loss at iteration 840 : 0.00014558409748133272
Loss at iteration 850 : 0.0008076796075329185
Loss at iteration 860 : 5.231628892943263e-05
Loss at iteration 870 : 0.00044092704774811864
Loss at iteration 880 : 0.0005708595854230225
Loss at iteration 890 : 0.00022271135821938515
Loss at iteration 900 : 0.00015619771147612482
Loss at iteration 910 : 0.00015617730969097465
Loss at iteration 920 : 3.7222514947643504e-05
Loss at iteration 930 : 0.005089641083031893
Loss at iteration 940 : 0.0006531317485496402
Loss at iteration 950 : 0.00022304212325252593
Loss at iteration 960 : 0.0016786330379545689
Loss at iteration 970 : 7.284124149009585e-05
Loss at iteration 980 : 0.0005209632799960673
Loss at iteration 990 : 0.0002436141367070377
Loss at iteration 1000 : 9.944742487277836e-05
Loss at iteration 1010 : 0.00014435646880883723
Loss at iteration 1020 : 0.00046819617273285985
Loss at iteration 1030 : 0.0002238887536805123
Loss at iteration 1040 : 0.0008306565578095615
Loss at iteration 1050 : 0.0006283824914135039
Loss at iteration 1060 : 0.0005975967505946755
Loss at iteration 1070 : 0.0008148258202709258
Loss at iteration 1080 : 0.0001128786097979173
Loss at iteration 1090 : 0.00044400792103260756
Loss at iteration 1100 : 0.0011967135360464454
Loss at iteration 1110 : 0.0002916751545853913
Loss at iteration 1120 : 0.0012954509584233165
Loss at iteration 1130 : 0.0013520573265850544
Loss at iteration 1140 : 0.00025999933131970465
Loss at iteration 1150 : 0.00034633686300367117
Loss at iteration 1160 : 0.004447796382009983
Loss at iteration 1170 : 0.003747532144188881
Loss at iteration 1180 : 0.00029128979076631367
Loss at iteration 1190 : 0.0001822053745854646
Loss at iteration 1200 : 9.904408943839371e-05
Loss at iteration 1210 : 4.3095529690617695e-05
Loss at iteration 1220 : 0.0002022597473114729
Loss at iteration 1230 : 0.00012095377314835787
Loss at iteration 1240 : 9.361545380670577e-05
Loss at iteration 1250 : 0.00032453943276777864
Loss at iteration 1260 : 0.00017058482626453042
Loss at iteration 1270 : 0.00026223715394735336
Loss at iteration 1280 : 0.00011007164721377194
Loss at iteration 1290 : 0.00018467156041879207
Loss at iteration 1300 : 0.0008534269873052835
Loss at iteration 1310 : 0.0002339142229175195
Loss at iteration 1320 : 0.0018779574893414974
Loss at iteration 1330 : 9.693227184470743e-05
Loss at iteration 1340 : 0.0003150975680910051
Loss at iteration 1350 : 0.00018620460468810052
Loss at iteration 1360 : 0.0001407030940754339
Loss at iteration 1370 : 0.00013955611211713403
Loss at iteration 1380 : 0.002881185384467244
Loss at iteration 1390 : 0.000199529982637614
Loss at iteration 1400 : 0.000263552472461015
Loss at iteration 1410 : 0.0040670763701200485
Loss at iteration 1420 : 0.001777207711711526
Loss at iteration 1430 : 0.0003938499721698463
Loss at iteration 1440 : 0.0010871868580579758
Loss at iteration 1450 : 0.00010634375939844176
Loss at iteration 1460 : 0.00012216411414556205
Loss at iteration 1470 : 0.0005673429695889354
Loss at iteration 1480 : 0.00046824681339785457
Loss at iteration 1490 : 0.002469537314027548
Loss at iteration 1500 : 0.00039846604340709746
Loss at iteration 1510 : 0.0006038984865881503
Loss at iteration 1520 : 0.0012091196840628982
Loss at iteration 1530 : 5.246810178505257e-05
Loss at iteration 1540 : 0.00015843973960727453
Loss at iteration 1550 : 0.00013367805513553321
Loss at iteration 1560 : 0.00018300433293916285
Loss at iteration 1570 : 0.0002925017033703625
Loss at iteration 1580 : 5.530190537683666e-05
Loss at iteration 1590 : 0.0038556659128516912
Loss at iteration 1600 : 0.0028172163292765617
Loss at iteration 1610 : 9.018983837449923e-05
Loss at iteration 1620 : 0.0020144281443208456
Loss at iteration 1630 : 0.00045622611651197076
Loss at iteration 1640 : 0.0002580268192104995
Loss at iteration 1650 : 0.0002441502292640507
Loss at iteration 1660 : 8.274395077023655e-05
Loss at iteration 1670 : 0.00017774786101654172
Loss at iteration 1680 : 0.003960363566875458
Loss at iteration 1690 : 0.0007868496468290687
Loss at iteration 1700 : 0.0021688437554985285
Loss at iteration 1710 : 0.0006665384862571955
Loss at iteration 1720 : 0.00011906149302376434
Loss at iteration 1730 : 0.004130186978727579
Loss at iteration 1740 : 0.00014527482562698424
Loss at iteration 1750 : 0.00010400312021374702
The SSIM Value is: 0.9854468287087748
The PSNR Value is: 46.47376765238556
the epoch is: 175
Loss at iteration 10 : 0.00029450791771523654
Loss at iteration 20 : 0.00025493052089586854
Loss at iteration 30 : 0.0014375894097611308
Loss at iteration 40 : 0.0004264681483618915
Loss at iteration 50 : 0.00017142236174549907
Loss at iteration 60 : 0.00023161023273132741
Loss at iteration 70 : 0.0037580630742013454
Loss at iteration 80 : 9.920336015056819e-05
Loss at iteration 90 : 7.916447793832049e-05
Loss at iteration 100 : 0.005235661286860704
Loss at iteration 110 : 0.0028276173397898674
Loss at iteration 120 : 0.002420509932562709
Loss at iteration 130 : 0.002347933128476143
Loss at iteration 140 : 0.0002909395843744278
Loss at iteration 150 : 0.00027738549397327006
Loss at iteration 160 : 0.00139385717920959
Loss at iteration 170 : 0.00018714999896474183
Loss at iteration 180 : 0.00015951867680996656
Loss at iteration 190 : 7.282051956281066e-05
Loss at iteration 200 : 0.0002526738098822534
Loss at iteration 210 : 0.004533255472779274
Loss at iteration 220 : 0.002901260508224368
Loss at iteration 230 : 0.0003483286709524691
Loss at iteration 240 : 0.0005309728439897299
Loss at iteration 250 : 8.259608875960112e-05
Loss at iteration 260 : 0.0002268131065648049
Loss at iteration 270 : 8.028954471228644e-05
Loss at iteration 280 : 7.175648352131248e-05
Loss at iteration 290 : 0.0002298335894010961
Loss at iteration 300 : 0.00021360619575716555
Loss at iteration 310 : 0.0003709575976245105
Loss at iteration 320 : 0.00012265464465599507
Loss at iteration 330 : 0.00027660891646519303
Loss at iteration 340 : 0.00031517076422460377
Loss at iteration 350 : 0.0031257309019565582
Loss at iteration 360 : 0.0011730320984497666
Loss at iteration 370 : 0.0018406506860628724
Loss at iteration 380 : 0.0002478048554621637
Loss at iteration 390 : 0.00010472589201526716
Loss at iteration 400 : 0.0014224236365407705
Loss at iteration 410 : 0.0009930366650223732
Loss at iteration 420 : 0.001558616990223527
Loss at iteration 430 : 0.003850130829960108
Loss at iteration 440 : 0.00583953782916069
Loss at iteration 450 : 0.00233066501095891
Loss at iteration 460 : 0.00046822658623568714
Loss at iteration 470 : 0.0004463357327040285
Loss at iteration 480 : 0.00028413732070475817
Loss at iteration 490 : 0.0007356851128861308
Loss at iteration 500 : 0.00034920329926535487
Loss at iteration 510 : 0.00032849516719579697
Loss at iteration 520 : 0.0007489617564715445
Loss at iteration 530 : 0.00044115097261965275
Loss at iteration 540 : 0.0007169721066020429
Loss at iteration 550 : 0.00017156936519313604
Loss at iteration 560 : 0.001859015435911715
Loss at iteration 570 : 0.0005203247419558465
Loss at iteration 580 : 0.00015666930994484574
Loss at iteration 590 : 0.0001082201924873516
Loss at iteration 600 : 0.0004168976447544992
Loss at iteration 610 : 0.004576477222144604
Loss at iteration 620 : 0.00028498805477283895
Loss at iteration 630 : 5.7824836403597146e-05
Loss at iteration 640 : 0.0012496226700022817
Loss at iteration 650 : 7.957954949233681e-05
Loss at iteration 660 : 9.545739158056676e-05
Loss at iteration 670 : 0.00011081190314143896
Loss at iteration 680 : 0.00296685635112226
Loss at iteration 690 : 0.00015934428665786982
Loss at iteration 700 : 0.00010805611236719415
Loss at iteration 710 : 0.00017489019955974072
Loss at iteration 720 : 0.0002236482541775331
Loss at iteration 730 : 0.0032595135271549225
Loss at iteration 740 : 0.0004084919346496463
Loss at iteration 750 : 0.0003321085823699832
Loss at iteration 760 : 0.0005913461209274828
Loss at iteration 770 : 0.00015384098514914513
Loss at iteration 780 : 0.00037922197952866554
Loss at iteration 790 : 0.00012314524792600423
Loss at iteration 800 : 0.0006125123472884297
Loss at iteration 810 : 0.00010461134661454707
Loss at iteration 820 : 9.544598287902772e-05
Loss at iteration 830 : 0.0008755583548918366
Loss at iteration 840 : 0.0009424843010492623
Loss at iteration 850 : 0.00026601931313052773
Loss at iteration 860 : 0.0002864644047804177
Loss at iteration 870 : 0.0005447668954730034
Loss at iteration 880 : 0.0014986657770350575
Loss at iteration 890 : 5.172599048819393e-05
Loss at iteration 900 : 0.0034290063194930553
Loss at iteration 910 : 0.00021161844779271632
Loss at iteration 920 : 0.004019069019705057
Loss at iteration 930 : 0.0011043943231925368
Loss at iteration 940 : 9.096587746171281e-05
Loss at iteration 950 : 0.002922405954450369
Loss at iteration 960 : 0.0002891411422751844
Loss at iteration 970 : 1.8949083823827095e-05
Loss at iteration 980 : 0.00012777690426446497
Loss at iteration 990 : 0.0002596802660264075
Loss at iteration 1000 : 0.0011441037058830261
Loss at iteration 1010 : 0.0005327998078428209
Loss at iteration 1020 : 0.0027055470272898674
Loss at iteration 1030 : 0.00342412362806499
Loss at iteration 1040 : 0.0006698377546854317
Loss at iteration 1050 : 0.00018829081091098487
Loss at iteration 1060 : 0.0002104508166667074
Loss at iteration 1070 : 0.0001588061568327248
Loss at iteration 1080 : 0.004017437808215618
Loss at iteration 1090 : 0.0002822941751219332
Loss at iteration 1100 : 0.00011539141269167885
Loss at iteration 1110 : 0.0010373647091910243
Loss at iteration 1120 : 0.00013895971642341465
Loss at iteration 1130 : 0.00012985279317945242
Loss at iteration 1140 : 0.00021131712128408253
Loss at iteration 1150 : 0.0002663376508280635
Loss at iteration 1160 : 0.002514595165848732
Loss at iteration 1170 : 0.0011712070554494858
Loss at iteration 1180 : 0.00029488923610188067
Loss at iteration 1190 : 0.0033695725724101067
Loss at iteration 1200 : 6.540962203871459e-05
Loss at iteration 1210 : 0.0002557649277150631
Loss at iteration 1220 : 0.0013508265838027
Loss at iteration 1230 : 8.005183917703107e-05
Loss at iteration 1240 : 0.00010716664837673306
Loss at iteration 1250 : 0.00183303898666054
Loss at iteration 1260 : 0.0006886218907311559
Loss at iteration 1270 : 0.0002494603395462036
Loss at iteration 1280 : 0.00027714745374396443
Loss at iteration 1290 : 0.001239837845787406
Loss at iteration 1300 : 0.0010035772575065494
Loss at iteration 1310 : 0.00040181601070798934
Loss at iteration 1320 : 7.7665681601502e-05
Loss at iteration 1330 : 0.0001589379389770329
Loss at iteration 1340 : 0.00012732154573313892
Loss at iteration 1350 : 0.0013479167828336358
Loss at iteration 1360 : 0.0003030625230167061
Loss at iteration 1370 : 0.0006214026361703873
Loss at iteration 1380 : 0.0009310704190284014
Loss at iteration 1390 : 0.0032250983640551567
Loss at iteration 1400 : 0.0002721234632190317
Loss at iteration 1410 : 0.00042266861419193447
Loss at iteration 1420 : 0.0006623546360060573
Loss at iteration 1430 : 0.0004828210221603513
Loss at iteration 1440 : 0.0006031788070686162
Loss at iteration 1450 : 0.00012748573499266058
Loss at iteration 1460 : 0.0009573755087330937
Loss at iteration 1470 : 0.00027561758179217577
Loss at iteration 1480 : 0.0005414375336840749
Loss at iteration 1490 : 0.00036597944563254714
Loss at iteration 1500 : 0.0002826654235832393
Loss at iteration 1510 : 0.0019518263870850205
Loss at iteration 1520 : 0.0026983441784977913
Loss at iteration 1530 : 0.0028026301879435778
Loss at iteration 1540 : 0.0021991278044879436
Loss at iteration 1550 : 0.0001326122583122924
Loss at iteration 1560 : 9.300759120378643e-05
Loss at iteration 1570 : 0.00016550802683923393
Loss at iteration 1580 : 6.298562220763415e-05
Loss at iteration 1590 : 4.5521654101321474e-05
Loss at iteration 1600 : 0.0029594730585813522
Loss at iteration 1610 : 0.001554597751237452
Loss at iteration 1620 : 0.0028035794384777546
Loss at iteration 1630 : 0.00038404378574341536
Loss at iteration 1640 : 0.0003545941144693643
Loss at iteration 1650 : 0.00029855070170015097
Loss at iteration 1660 : 0.005838453769683838
Loss at iteration 1670 : 0.0059196846559643745
Loss at iteration 1680 : 5.513975702342577e-05
Loss at iteration 1690 : 0.001371936989016831
Loss at iteration 1700 : 3.7879712181165814e-05
Loss at iteration 1710 : 0.0004036433529108763
Loss at iteration 1720 : 6.005304749123752e-05
Loss at iteration 1730 : 0.0007157039362937212
Loss at iteration 1740 : 0.0002858164953067899
Loss at iteration 1750 : 0.0025151362642645836
The SSIM Value is: 0.9850533806805043
The PSNR Value is: 46.48768751001568
the epoch is: 176
Loss at iteration 10 : 0.005409243982285261
Loss at iteration 20 : 4.701982834376395e-05
Loss at iteration 30 : 0.0006766424048691988
Loss at iteration 40 : 0.002066163346171379
Loss at iteration 50 : 0.00016185615095309913
Loss at iteration 60 : 0.0002920202095992863
Loss at iteration 70 : 0.0005570340435951948
Loss at iteration 80 : 0.00010644816211424768
Loss at iteration 90 : 0.0003094779094681144
Loss at iteration 100 : 9.230259456671774e-05
Loss at iteration 110 : 0.00015172205166891217
Loss at iteration 120 : 0.0014944493304938078
Loss at iteration 130 : 0.0004943968378938735
Loss at iteration 140 : 0.0003299603995401412
Loss at iteration 150 : 0.00040838957647792995
Loss at iteration 160 : 0.00013795882114209235
Loss at iteration 170 : 0.0003528935194481164
Loss at iteration 180 : 0.0032250762451440096
Loss at iteration 190 : 0.0029962179251015186
Loss at iteration 200 : 0.00043146032840013504
Loss at iteration 210 : 0.005602746270596981
Loss at iteration 220 : 0.0005411530146375299
Loss at iteration 230 : 0.00033072929363697767
Loss at iteration 240 : 0.0017124487785622478
Loss at iteration 250 : 0.0003012449305970222
Loss at iteration 260 : 0.00025824792101047933
Loss at iteration 270 : 0.0026704459451138973
Loss at iteration 280 : 0.0001648653851589188
Loss at iteration 290 : 9.775977378012612e-05
Loss at iteration 300 : 0.00010734572424553335
Loss at iteration 310 : 0.00020418534404598176
Loss at iteration 320 : 0.002701530698686838
Loss at iteration 330 : 8.870677993400022e-05
Loss at iteration 340 : 0.00090222735889256
Loss at iteration 350 : 0.003803595434874296
Loss at iteration 360 : 0.0001949569268617779
Loss at iteration 370 : 0.00038124859565868974
Loss at iteration 380 : 0.001941027119755745
Loss at iteration 390 : 0.00015726813580840826
Loss at iteration 400 : 0.0006565754301846027
Loss at iteration 410 : 0.00012859808339271694
Loss at iteration 420 : 0.000156630456331186
Loss at iteration 430 : 0.0019982291851192713
Loss at iteration 440 : 6.716630014125258e-05
Loss at iteration 450 : 0.00046498977462761104
Loss at iteration 460 : 8.855709893396124e-05
Loss at iteration 470 : 0.000309138122247532
Loss at iteration 480 : 0.00029184267623350024
Loss at iteration 490 : 0.0004237228131387383
Loss at iteration 500 : 8.44261739985086e-05
Loss at iteration 510 : 0.00016804138431325555
Loss at iteration 520 : 0.00015574856661260128
Loss at iteration 530 : 0.00023633911041542888
Loss at iteration 540 : 6.377018871717155e-05
Loss at iteration 550 : 4.280470238882117e-05
Loss at iteration 560 : 0.0001292895758524537
Loss at iteration 570 : 0.0019396403804421425
Loss at iteration 580 : 0.00030463660368695855
Loss at iteration 590 : 0.00019232269551139325
Loss at iteration 600 : 0.0008339035557582974
Loss at iteration 610 : 0.0027651304844766855
Loss at iteration 620 : 0.00012552598491311073
Loss at iteration 630 : 6.537653098348528e-05
Loss at iteration 640 : 0.0032486324198544025
Loss at iteration 650 : 0.0008098774706013501
Loss at iteration 660 : 0.0002083401777781546
Loss at iteration 670 : 0.0008159679127857089
Loss at iteration 680 : 0.00019682604761328548
Loss at iteration 690 : 0.0002525935124140233
Loss at iteration 700 : 0.00039928528713062406
Loss at iteration 710 : 0.0002929435868281871
Loss at iteration 720 : 0.002225889591500163
Loss at iteration 730 : 6.987860251683742e-05
Loss at iteration 740 : 0.0004479926428757608
Loss at iteration 750 : 0.0006163992802612484
Loss at iteration 760 : 0.0011485443683341146
Loss at iteration 770 : 0.002403733553364873
Loss at iteration 780 : 0.0003796470700763166
Loss at iteration 790 : 0.008816125802695751
Loss at iteration 800 : 0.0012741641839966178
Loss at iteration 810 : 0.001589193008840084
Loss at iteration 820 : 0.0002744218800216913
Loss at iteration 830 : 0.00010729725909186527
Loss at iteration 840 : 7.947614358272403e-05
Loss at iteration 850 : 0.006459814961999655
Loss at iteration 860 : 0.0011948369210585952
Loss at iteration 870 : 0.006279787980020046
Loss at iteration 880 : 0.0028805371839553118
Loss at iteration 890 : 0.00042608162038959563
Loss at iteration 900 : 0.0005090992781333625
Loss at iteration 910 : 5.394048639573157e-05
Loss at iteration 920 : 0.0005725477822124958
Loss at iteration 930 : 0.0001008786930469796
Loss at iteration 940 : 0.0005258977180346847
Loss at iteration 950 : 0.001157473656348884
Loss at iteration 960 : 0.0017081359401345253
Loss at iteration 970 : 0.0002050241455435753
Loss at iteration 980 : 0.0003401926951482892
Loss at iteration 990 : 0.0001177698140963912
Loss at iteration 1000 : 0.0004669192712754011
Loss at iteration 1010 : 0.00016769352077972144
Loss at iteration 1020 : 0.00018057962006423622
Loss at iteration 1030 : 0.0007495360914617777
Loss at iteration 1040 : 0.0005230748793110251
Loss at iteration 1050 : 0.003811393165960908
Loss at iteration 1060 : 0.00017621475853957236
Loss at iteration 1070 : 5.7493511121720076e-05
Loss at iteration 1080 : 0.0002162084711017087
Loss at iteration 1090 : 0.00011062994599342346
Loss at iteration 1100 : 0.005665041506290436
Loss at iteration 1110 : 0.0032145637087523937
Loss at iteration 1120 : 0.0004984408733434975
Loss at iteration 1130 : 0.0006991614354774356
Loss at iteration 1140 : 0.00017248853691853583
Loss at iteration 1150 : 0.0031568659469485283
Loss at iteration 1160 : 0.0005069947801530361
Loss at iteration 1170 : 0.004746380262076855
Loss at iteration 1180 : 0.0014810366556048393
Loss at iteration 1190 : 0.0010391174582764506
Loss at iteration 1200 : 0.0003078114823438227
Loss at iteration 1210 : 0.0026051965542137623
Loss at iteration 1220 : 0.000457528920378536
Loss at iteration 1230 : 0.005447433330118656
Loss at iteration 1240 : 0.0014507935848087072
Loss at iteration 1250 : 0.003777134697884321
Loss at iteration 1260 : 0.00027321936795488
Loss at iteration 1270 : 0.00015739433001726866
Loss at iteration 1280 : 0.0014326497912406921
Loss at iteration 1290 : 0.00023509588208980858
Loss at iteration 1300 : 0.0002231558901257813
Loss at iteration 1310 : 5.233139017946087e-05
Loss at iteration 1320 : 0.0007131875026971102
Loss at iteration 1330 : 0.0011416435008868575
Loss at iteration 1340 : 0.002928751055151224
Loss at iteration 1350 : 0.0002464516437612474
Loss at iteration 1360 : 0.0009477334097027779
Loss at iteration 1370 : 0.0005255108117125928
Loss at iteration 1380 : 0.0012707177083939314
Loss at iteration 1390 : 0.006130698136985302
Loss at iteration 1400 : 0.00022758418344892561
Loss at iteration 1410 : 7.150445890147239e-05
Loss at iteration 1420 : 0.00012342278205323964
Loss at iteration 1430 : 0.0011090573389083147
Loss at iteration 1440 : 0.0037972931750118732
Loss at iteration 1450 : 8.681149483891204e-05
Loss at iteration 1460 : 0.0019725789315998554
Loss at iteration 1470 : 0.00017506795120425522
Loss at iteration 1480 : 0.000308390794089064
Loss at iteration 1490 : 0.003663816023617983
Loss at iteration 1500 : 0.00010650590411387384
Loss at iteration 1510 : 0.002995613031089306
Loss at iteration 1520 : 0.00019475040608085692
Loss at iteration 1530 : 0.002662379527464509
Loss at iteration 1540 : 0.0009545477805659175
Loss at iteration 1550 : 0.00013328393106348813
Loss at iteration 1560 : 0.0001958728244062513
Loss at iteration 1570 : 0.0020557628013193607
Loss at iteration 1580 : 0.00015369114407803863
Loss at iteration 1590 : 0.00562608428299427
Loss at iteration 1600 : 0.0003355828521307558
Loss at iteration 1610 : 0.004404006525874138
Loss at iteration 1620 : 0.00010934461170108989
Loss at iteration 1630 : 0.00018790029571391642
Loss at iteration 1640 : 0.0001735919067868963
Loss at iteration 1650 : 0.004192790016531944
Loss at iteration 1660 : 0.00031097265309654176
Loss at iteration 1670 : 0.001822170102968812
Loss at iteration 1680 : 0.00021823735733050853
Loss at iteration 1690 : 0.00022494287986773998
Loss at iteration 1700 : 0.0005414281040430069
Loss at iteration 1710 : 8.861404785420746e-05
Loss at iteration 1720 : 0.0006707665743306279
Loss at iteration 1730 : 0.0012366145383566618
Loss at iteration 1740 : 0.0001901542564155534
Loss at iteration 1750 : 6.971499533392489e-05
The SSIM Value is: 0.9846628578748997
The PSNR Value is: 46.503331530986905
the epoch is: 177
Loss at iteration 10 : 0.000611658557318151
Loss at iteration 20 : 0.0003379914560355246
Loss at iteration 30 : 0.00020003196550533175
Loss at iteration 40 : 0.004451800603419542
Loss at iteration 50 : 0.00012158670142525807
Loss at iteration 60 : 0.004808250814676285
Loss at iteration 70 : 0.00015905496547929943
Loss at iteration 80 : 0.0004969925503246486
Loss at iteration 90 : 0.00011443133553257212
Loss at iteration 100 : 0.0005712651181966066
Loss at iteration 110 : 0.0025372705422341824
Loss at iteration 120 : 0.0007491479627788067
Loss at iteration 130 : 0.00024199225299526006
Loss at iteration 140 : 0.0001729596988297999
Loss at iteration 150 : 0.0002803413080982864
Loss at iteration 160 : 0.0033455181401222944
Loss at iteration 170 : 0.0004097463679499924
Loss at iteration 180 : 0.0036255917511880398
Loss at iteration 190 : 0.00039572492823936045
Loss at iteration 200 : 7.590655150124803e-05
Loss at iteration 210 : 0.001966649666428566
Loss at iteration 220 : 0.0003772873315028846
Loss at iteration 230 : 0.001055979635566473
Loss at iteration 240 : 9.426182805327699e-05
Loss at iteration 250 : 0.00014197133714333177
Loss at iteration 260 : 0.0002696154988370836
Loss at iteration 270 : 0.0028656190261244774
Loss at iteration 280 : 0.0024270976427942514
Loss at iteration 290 : 0.0011275657452642918
Loss at iteration 300 : 0.00011060053657274693
Loss at iteration 310 : 0.0011018175864592195
Loss at iteration 320 : 0.0013006890658289194
Loss at iteration 330 : 0.0007533842581324279
Loss at iteration 340 : 0.00025788709172047675
Loss at iteration 350 : 0.0005166091141290963
Loss at iteration 360 : 0.00025162057136185467
Loss at iteration 370 : 9.442307782592252e-05
Loss at iteration 380 : 0.0008917615050449967
Loss at iteration 390 : 0.0031558454502373934
Loss at iteration 400 : 0.0032506089191883802
Loss at iteration 410 : 7.858607568778098e-05
Loss at iteration 420 : 0.0012139971368014812
Loss at iteration 430 : 0.0002742065698839724
Loss at iteration 440 : 0.0021155611611902714
Loss at iteration 450 : 0.00045527261681854725
Loss at iteration 460 : 0.0009256763150915504
Loss at iteration 470 : 0.00011229186202399433
Loss at iteration 480 : 0.00013036940072197467
Loss at iteration 490 : 0.00020834716269746423
Loss at iteration 500 : 0.00030182889895513654
Loss at iteration 510 : 0.000461623421870172
Loss at iteration 520 : 0.0003386051976121962
Loss at iteration 530 : 0.0003645113902166486
Loss at iteration 540 : 0.0020561381243169308
Loss at iteration 550 : 0.0005171953816898167
Loss at iteration 560 : 5.712782876798883e-05
Loss at iteration 570 : 0.00017327784735243767
Loss at iteration 580 : 6.545540963998064e-05
Loss at iteration 590 : 0.001160096493549645
Loss at iteration 600 : 0.0002664441999513656
Loss at iteration 610 : 0.0011588239576667547
Loss at iteration 620 : 0.00286220945417881
Loss at iteration 630 : 0.0005086697638034821
Loss at iteration 640 : 0.0008750406559556723
Loss at iteration 650 : 0.0011299166362732649
Loss at iteration 660 : 0.00012267920828890055
Loss at iteration 670 : 0.0003915283887181431
Loss at iteration 680 : 0.00014252145774662495
Loss at iteration 690 : 0.003031362546607852
Loss at iteration 700 : 0.0016828736988827586
Loss at iteration 710 : 0.0003073406987823546
Loss at iteration 720 : 8.25145179987885e-05
Loss at iteration 730 : 0.000634365133009851
Loss at iteration 740 : 0.0007079275092110038
Loss at iteration 750 : 0.00033933797385543585
Loss at iteration 760 : 0.00011854867625515908
Loss at iteration 770 : 0.002851014258340001
Loss at iteration 780 : 0.0019542821682989597
Loss at iteration 790 : 0.000639694684650749
Loss at iteration 800 : 0.00032690251828171313
Loss at iteration 810 : 0.002345859073102474
Loss at iteration 820 : 0.00038000018685124815
Loss at iteration 830 : 0.0001357261644443497
Loss at iteration 840 : 0.0006083135376684368
Loss at iteration 850 : 0.0017746646190062165
Loss at iteration 860 : 0.00017311850388068706
Loss at iteration 870 : 0.00027033532387576997
Loss at iteration 880 : 0.00017044166452251375
Loss at iteration 890 : 0.0007830662652850151
Loss at iteration 900 : 0.0004883779911324382
Loss at iteration 910 : 0.0002361559309065342
Loss at iteration 920 : 0.0003834486997220665
Loss at iteration 930 : 0.00034909709938801825
Loss at iteration 940 : 0.0008877413347363472
Loss at iteration 950 : 0.0029018507339060307
Loss at iteration 960 : 0.0003837888943962753
Loss at iteration 970 : 0.004202291835099459
Loss at iteration 980 : 0.00011487533629406244
Loss at iteration 990 : 0.00012495103874243796
Loss at iteration 1000 : 0.003601613687351346
Loss at iteration 1010 : 0.001434367150068283
Loss at iteration 1020 : 0.0022808213252574205
Loss at iteration 1030 : 5.227840301813558e-05
Loss at iteration 1040 : 0.0008861407404765487
Loss at iteration 1050 : 0.00020008767023682594
Loss at iteration 1060 : 0.00016884114302229136
Loss at iteration 1070 : 0.00022844104387331754
Loss at iteration 1080 : 0.0008386106346733868
Loss at iteration 1090 : 0.00040314870420843363
Loss at iteration 1100 : 0.00010999933147104457
Loss at iteration 1110 : 0.0002764031523838639
Loss at iteration 1120 : 0.0043664174154400826
Loss at iteration 1130 : 0.0002728670078795403
Loss at iteration 1140 : 0.00035086271236650646
Loss at iteration 1150 : 0.003520275466144085
Loss at iteration 1160 : 0.0005091384518891573
Loss at iteration 1170 : 9.728188888402656e-05
Loss at iteration 1180 : 0.00042031711200252175
Loss at iteration 1190 : 0.00044223220902495086
Loss at iteration 1200 : 0.00039388923323713243
Loss at iteration 1210 : 0.0006628095870837569
Loss at iteration 1220 : 0.00017344392836093903
Loss at iteration 1230 : 9.020537981996313e-05
Loss at iteration 1240 : 0.0004005739465355873
Loss at iteration 1250 : 0.0013313319068402052
Loss at iteration 1260 : 0.0005122621660120785
Loss at iteration 1270 : 0.0026028139982372522
Loss at iteration 1280 : 0.0007317181443795562
Loss at iteration 1290 : 5.184052133699879e-05
Loss at iteration 1300 : 0.0003093776758760214
Loss at iteration 1310 : 0.003138028085231781
Loss at iteration 1320 : 0.0003162049106322229
Loss at iteration 1330 : 0.0004669093177653849
Loss at iteration 1340 : 0.002571837743744254
Loss at iteration 1350 : 0.00041878788033500314
Loss at iteration 1360 : 0.0005465468857437372
Loss at iteration 1370 : 0.0006108818342909217
Loss at iteration 1380 : 0.0019885851070284843
Loss at iteration 1390 : 0.00015179658657871187
Loss at iteration 1400 : 0.0007160886307246983
Loss at iteration 1410 : 0.00010821869364008307
Loss at iteration 1420 : 7.575242489110678e-05
Loss at iteration 1430 : 7.68290992709808e-05
Loss at iteration 1440 : 0.00020264055638108402
Loss at iteration 1450 : 0.00021793044288642704
Loss at iteration 1460 : 0.0002230530371889472
Loss at iteration 1470 : 0.00041351531399413943
Loss at iteration 1480 : 0.002361238468438387
Loss at iteration 1490 : 0.000429236504714936
Loss at iteration 1500 : 6.953286356292665e-05
Loss at iteration 1510 : 0.00028570438735187054
Loss at iteration 1520 : 0.003177086589857936
Loss at iteration 1530 : 0.0022389383520931005
Loss at iteration 1540 : 7.2752773121465e-05
Loss at iteration 1550 : 0.0022142543457448483
Loss at iteration 1560 : 0.0006144921062514186
Loss at iteration 1570 : 0.0005295387818478048
Loss at iteration 1580 : 7.684964657528326e-05
Loss at iteration 1590 : 0.0006869101780466735
Loss at iteration 1600 : 0.0007606493309140205
Loss at iteration 1610 : 0.000161134812515229
Loss at iteration 1620 : 0.0018692619632929564
Loss at iteration 1630 : 0.004512450657784939
Loss at iteration 1640 : 0.0006688578869216144
Loss at iteration 1650 : 9.127723751589656e-05
Loss at iteration 1660 : 0.0025909182149916887
Loss at iteration 1670 : 0.0002537262043915689
Loss at iteration 1680 : 0.0005680241156369448
Loss at iteration 1690 : 0.0033789470326155424
Loss at iteration 1700 : 8.288091339636594e-05
Loss at iteration 1710 : 0.001247592270374298
Loss at iteration 1720 : 4.508494748733938e-05
Loss at iteration 1730 : 0.00025028028176166117
Loss at iteration 1740 : 0.0020894180051982403
Loss at iteration 1750 : 0.0009269028669223189
The SSIM Value is: 0.9869337618876134
The PSNR Value is: 46.675864362506616
the epoch is: 178
Loss at iteration 10 : 0.00012478622375056148
Loss at iteration 20 : 0.00026997760869562626
Loss at iteration 30 : 0.004000414628535509
Loss at iteration 40 : 0.005096209701150656
Loss at iteration 50 : 0.0003084740601480007
Loss at iteration 60 : 0.0002309847332071513
Loss at iteration 70 : 0.0001433886936865747
Loss at iteration 80 : 0.00017702819604892284
Loss at iteration 90 : 0.0004843656497541815
Loss at iteration 100 : 0.00024374861095566303
Loss at iteration 110 : 8.07594187790528e-05
Loss at iteration 120 : 0.00010845149517990649
Loss at iteration 130 : 9.412747749593109e-05
Loss at iteration 140 : 0.0007472423603758216
Loss at iteration 150 : 0.0073492079973220825
Loss at iteration 160 : 5.370825601858087e-05
Loss at iteration 170 : 0.00035070814192295074
Loss at iteration 180 : 0.00016558697097934783
Loss at iteration 190 : 0.0002743309596553445
Loss at iteration 200 : 0.00011667663784464821
Loss at iteration 210 : 0.00018031586660072207
Loss at iteration 220 : 0.00027294590836390853
Loss at iteration 230 : 0.0009114426211453974
Loss at iteration 240 : 0.0009566597873345017
Loss at iteration 250 : 0.00018544602789916098
Loss at iteration 260 : 0.0002074170479318127
Loss at iteration 270 : 0.0003007118939422071
Loss at iteration 280 : 0.0005302704521454871
Loss at iteration 290 : 0.00018445702153258026
Loss at iteration 300 : 0.00034017759026028216
Loss at iteration 310 : 0.003034002613276243
Loss at iteration 320 : 0.00010356842540204525
Loss at iteration 330 : 0.0001903484226204455
Loss at iteration 340 : 0.0014664898626506329
Loss at iteration 350 : 0.0011508086463436484
Loss at iteration 360 : 0.00024349044542759657
Loss at iteration 370 : 0.0025314646773040295
Loss at iteration 380 : 0.00036239862674847245
Loss at iteration 390 : 0.0018384952563792467
Loss at iteration 400 : 0.004229976795613766
Loss at iteration 410 : 0.004730566870421171
Loss at iteration 420 : 6.634174496866763e-05
Loss at iteration 430 : 0.00026563508436083794
Loss at iteration 440 : 0.0008496457012370229
Loss at iteration 450 : 0.00010891545389313251
Loss at iteration 460 : 0.00011999807611573488
Loss at iteration 470 : 0.002182531636208296
Loss at iteration 480 : 0.0026580914855003357
Loss at iteration 490 : 0.00024316052440553904
Loss at iteration 500 : 0.0008667117799632251
Loss at iteration 510 : 0.0005892143817618489
Loss at iteration 520 : 0.0021321435924619436
Loss at iteration 530 : 0.0015584819484502077
Loss at iteration 540 : 0.00022365432232618332
Loss at iteration 550 : 0.00010246571764582768
Loss at iteration 560 : 0.0004897938342764974
Loss at iteration 570 : 0.0005467164446599782
Loss at iteration 580 : 0.0005898983799852431
Loss at iteration 590 : 0.00010181858669966459
Loss at iteration 600 : 0.00018299026123713702
Loss at iteration 610 : 0.00024069678329396993
Loss at iteration 620 : 0.0023731887340545654
Loss at iteration 630 : 0.0018551333341747522
Loss at iteration 640 : 0.00011574813106562942
Loss at iteration 650 : 0.0005503107095137239
Loss at iteration 660 : 0.00035459527862258255
Loss at iteration 670 : 0.003245973028242588
Loss at iteration 680 : 6.819984264438972e-05
Loss at iteration 690 : 0.0007466488750651479
Loss at iteration 700 : 9.549563401378691e-05
Loss at iteration 710 : 0.00014906912110745907
Loss at iteration 720 : 0.00019507293472997844
Loss at iteration 730 : 0.0011735463049262762
Loss at iteration 740 : 0.00021221028873696923
Loss at iteration 750 : 8.489064202876762e-05
Loss at iteration 760 : 0.0003807497560046613
Loss at iteration 770 : 0.0002649788511916995
Loss at iteration 780 : 0.000651567941531539
Loss at iteration 790 : 0.00046075423597358167
Loss at iteration 800 : 9.757976658875123e-05
Loss at iteration 810 : 0.0004920006613247097
Loss at iteration 820 : 0.00014206767082214355
Loss at iteration 830 : 0.003894839668646455
Loss at iteration 840 : 0.0030449300538748503
Loss at iteration 850 : 0.00014027065481059253
Loss at iteration 860 : 0.0001973911130335182
Loss at iteration 870 : 0.00011916205403394997
Loss at iteration 880 : 0.0005405031843110919
Loss at iteration 890 : 0.006620415486395359
Loss at iteration 900 : 0.0006718352669849992
Loss at iteration 910 : 0.0006844857125543058
Loss at iteration 920 : 0.0028385657351464033
Loss at iteration 930 : 0.00016051028796937317
Loss at iteration 940 : 0.0007392939296551049
Loss at iteration 950 : 0.00037804312887601554
Loss at iteration 960 : 6.148990360088646e-05
Loss at iteration 970 : 0.0004948665155097842
Loss at iteration 980 : 0.0009399409173056483
Loss at iteration 990 : 0.00012388326285872608
Loss at iteration 1000 : 0.0005451773176901042
Loss at iteration 1010 : 0.00459572859108448
Loss at iteration 1020 : 0.0006388159235939384
Loss at iteration 1030 : 0.00013124261749908328
Loss at iteration 1040 : 8.54295794852078e-05
Loss at iteration 1050 : 0.00019441796757746488
Loss at iteration 1060 : 0.0005550122587010264
Loss at iteration 1070 : 0.00016500975470989943
Loss at iteration 1080 : 0.00010600660607451573
Loss at iteration 1090 : 0.0014228001236915588
Loss at iteration 1100 : 0.0001498511846875772
Loss at iteration 1110 : 0.003049273509532213
Loss at iteration 1120 : 0.0023012717720121145
Loss at iteration 1130 : 0.0009061905439011753
Loss at iteration 1140 : 0.00015646134852431715
Loss at iteration 1150 : 0.00017102093261200935
Loss at iteration 1160 : 0.00019150294247083366
Loss at iteration 1170 : 0.0025683632120490074
Loss at iteration 1180 : 0.0009957000147551298
Loss at iteration 1190 : 0.00010363453475292772
Loss at iteration 1200 : 0.0002747480175457895
Loss at iteration 1210 : 0.0025811551604419947
Loss at iteration 1220 : 0.00037823704769834876
Loss at iteration 1230 : 0.0007512071169912815
Loss at iteration 1240 : 0.001422679633833468
Loss at iteration 1250 : 0.0005520127597264946
Loss at iteration 1260 : 0.001321337535046041
Loss at iteration 1270 : 0.00012452104419935495
Loss at iteration 1280 : 5.746015449403785e-05
Loss at iteration 1290 : 0.004775987938046455
Loss at iteration 1300 : 0.0030257340986281633
Loss at iteration 1310 : 0.002919817576184869
Loss at iteration 1320 : 0.0014856394845992327
Loss at iteration 1330 : 0.00018180815095547587
Loss at iteration 1340 : 0.0011425197590142488
Loss at iteration 1350 : 0.00012288405559957027
Loss at iteration 1360 : 0.0005931351333856583
Loss at iteration 1370 : 0.00013164349365979433
Loss at iteration 1380 : 0.0001243178267031908
Loss at iteration 1390 : 0.003558855503797531
Loss at iteration 1400 : 0.0018179100006818771
Loss at iteration 1410 : 0.0004824214265681803
Loss at iteration 1420 : 0.00014282898337114602
Loss at iteration 1430 : 0.0004724175960291177
Loss at iteration 1440 : 0.0003952258266508579
Loss at iteration 1450 : 0.00023781356867402792
Loss at iteration 1460 : 0.0020475536584854126
Loss at iteration 1470 : 0.00031016915454529226
Loss at iteration 1480 : 0.0044059157371521
Loss at iteration 1490 : 0.0002651191607583314
Loss at iteration 1500 : 0.0012550344690680504
Loss at iteration 1510 : 0.0017976876115426421
Loss at iteration 1520 : 4.4657368562184274e-05
Loss at iteration 1530 : 8.408295980188996e-05
Loss at iteration 1540 : 5.923529533902183e-05
Loss at iteration 1550 : 0.00010001642658608034
Loss at iteration 1560 : 0.0003480456362012774
Loss at iteration 1570 : 0.00010697231482481584
Loss at iteration 1580 : 0.0026673737447708845
Loss at iteration 1590 : 0.0008720207260921597
Loss at iteration 1600 : 0.00013000969192944467
Loss at iteration 1610 : 0.0002459192764945328
Loss at iteration 1620 : 0.0005463084089569747
Loss at iteration 1630 : 0.00019449929823167622
Loss at iteration 1640 : 9.049993968801573e-05
Loss at iteration 1650 : 0.00021805637516081333
Loss at iteration 1660 : 0.003501027589663863
Loss at iteration 1670 : 0.0016298486152663827
Loss at iteration 1680 : 0.00015812733909115195
Loss at iteration 1690 : 0.0006190381827764213
Loss at iteration 1700 : 0.00016419182065874338
Loss at iteration 1710 : 0.00012024958414258435
Loss at iteration 1720 : 7.265142630785704e-05
Loss at iteration 1730 : 0.00027295920881442726
Loss at iteration 1740 : 0.005563151556998491
Loss at iteration 1750 : 9.031195077113807e-05
The SSIM Value is: 0.9846506021621468
The PSNR Value is: 46.16547263351306
the epoch is: 179
Loss at iteration 10 : 0.001351107726804912
Loss at iteration 20 : 0.004938970319926739
Loss at iteration 30 : 0.0003460384323261678
Loss at iteration 40 : 0.00048181333113461733
Loss at iteration 50 : 9.782912093214691e-05
Loss at iteration 60 : 0.00100229203235358
Loss at iteration 70 : 0.0019480632618069649
Loss at iteration 80 : 9.421160939382389e-05
Loss at iteration 90 : 6.983272760407999e-05
Loss at iteration 100 : 0.0032373066060245037
Loss at iteration 110 : 0.00014491993351839483
Loss at iteration 120 : 0.00019455039000604302
Loss at iteration 130 : 0.0016217438969761133
Loss at iteration 140 : 0.006521038711071014
Loss at iteration 150 : 0.0002411490713711828
Loss at iteration 160 : 0.002770027844235301
Loss at iteration 170 : 0.0001668742042966187
Loss at iteration 180 : 5.338697155821137e-05
Loss at iteration 190 : 0.0005839493242092431
Loss at iteration 200 : 0.0027347521390765905
Loss at iteration 210 : 0.003026156686246395
Loss at iteration 220 : 0.00045509522897191346
Loss at iteration 230 : 0.0005590674700215459
Loss at iteration 240 : 0.0002519036061130464
Loss at iteration 250 : 0.00011468712909845635
Loss at iteration 260 : 0.005185462534427643
Loss at iteration 270 : 0.0001707837509457022
Loss at iteration 280 : 0.00010994619515258819
Loss at iteration 290 : 0.00020138733088970184
Loss at iteration 300 : 0.00048384006367996335
Loss at iteration 310 : 0.000551022298168391
Loss at iteration 320 : 0.00019600705127231777
Loss at iteration 330 : 0.0013852810952812433
Loss at iteration 340 : 0.00039423545240424573
Loss at iteration 350 : 0.0002131376531906426
Loss at iteration 360 : 0.00038848904659971595
Loss at iteration 370 : 5.6726246839389205e-05
Loss at iteration 380 : 0.0002039097889792174
Loss at iteration 390 : 4.77852372569032e-05
Loss at iteration 400 : 0.00019675868679769337
Loss at iteration 410 : 0.0002623648033477366
Loss at iteration 420 : 0.00014030186866875738
Loss at iteration 430 : 0.000721209857147187
Loss at iteration 440 : 0.0005221053725108504
Loss at iteration 450 : 0.00030315713956952095
Loss at iteration 460 : 8.784059900790453e-05
Loss at iteration 470 : 0.00023664894979447126
Loss at iteration 480 : 3.8166519516380504e-05
Loss at iteration 490 : 7.475473103113472e-05
Loss at iteration 500 : 0.00016836318536661565
Loss at iteration 510 : 0.0007273153751157224
Loss at iteration 520 : 7.35128705855459e-05
Loss at iteration 530 : 0.00016487870016135275
Loss at iteration 540 : 0.0003199501661583781
Loss at iteration 550 : 0.0009949529776349664
Loss at iteration 560 : 0.00013550309813581407
Loss at iteration 570 : 4.779100709129125e-05
Loss at iteration 580 : 0.00018906840705312788
Loss at iteration 590 : 0.0019284109584987164
Loss at iteration 600 : 0.0005126253236085176
Loss at iteration 610 : 0.0001600396353751421
Loss at iteration 620 : 0.0011765473755076528
Loss at iteration 630 : 0.003436994506046176
Loss at iteration 640 : 0.0001798890734789893
Loss at iteration 650 : 0.0007122629322111607
Loss at iteration 660 : 0.0035614357329905033
Loss at iteration 670 : 0.00024087211932055652
Loss at iteration 680 : 9.14333068067208e-05
Loss at iteration 690 : 8.842514944262803e-05
Loss at iteration 700 : 0.00012381889973767102
Loss at iteration 710 : 0.0004317079146858305
Loss at iteration 720 : 8.381712541449815e-05
Loss at iteration 730 : 0.00014093215577304363
Loss at iteration 740 : 0.004308408126235008
Loss at iteration 750 : 0.0013784728944301605
Loss at iteration 760 : 0.0012897660490125418
Loss at iteration 770 : 6.620074418606237e-05
Loss at iteration 780 : 8.379555947612971e-05
Loss at iteration 790 : 0.0005266412044875324
Loss at iteration 800 : 0.0021463679149746895
Loss at iteration 810 : 0.00011803991947090253
Loss at iteration 820 : 0.0010645235888659954
Loss at iteration 830 : 7.146702409954742e-05
Loss at iteration 840 : 0.0017514412757009268
Loss at iteration 850 : 0.0023025653790682554
Loss at iteration 860 : 0.0027462122961878777
Loss at iteration 870 : 9.952102846000344e-05
Loss at iteration 880 : 0.00012571299157571048
Loss at iteration 890 : 0.0011786583345383406
Loss at iteration 900 : 0.00020239187870174646
Loss at iteration 910 : 0.0006390167400240898
Loss at iteration 920 : 0.0007674676016904414
Loss at iteration 930 : 0.0014582416042685509
Loss at iteration 940 : 0.0009859905112534761
Loss at iteration 950 : 0.0017423673998564482
Loss at iteration 960 : 0.00021869110059924424
Loss at iteration 970 : 0.0006023200112394989
Loss at iteration 980 : 0.00021624204237014055
Loss at iteration 990 : 0.0002042965788859874
Loss at iteration 1000 : 0.00014194767572917044
Loss at iteration 1010 : 0.00017714968998916447
Loss at iteration 1020 : 0.0004545720003079623
Loss at iteration 1030 : 0.00028938468312844634
Loss at iteration 1040 : 0.00011279399041086435
Loss at iteration 1050 : 0.00019512182916514575
Loss at iteration 1060 : 0.0008359417552128434
Loss at iteration 1070 : 0.0039390502497553825
Loss at iteration 1080 : 6.30493595963344e-05
Loss at iteration 1090 : 5.584524114965461e-05
Loss at iteration 1100 : 0.00039760349318385124
Loss at iteration 1110 : 0.0011030150344595313
Loss at iteration 1120 : 0.0001533263421151787
Loss at iteration 1130 : 7.682923751417547e-05
Loss at iteration 1140 : 0.0012561245821416378
Loss at iteration 1150 : 0.00038703237078152597
Loss at iteration 1160 : 0.00046390597708523273
Loss at iteration 1170 : 0.0016427729278802872
Loss at iteration 1180 : 0.0009086965583264828
Loss at iteration 1190 : 0.0020950110629200935
Loss at iteration 1200 : 0.003948617726564407
Loss at iteration 1210 : 0.00012462452286854386
Loss at iteration 1220 : 0.0006763845449313521
Loss at iteration 1230 : 0.0024614951107650995
Loss at iteration 1240 : 0.00022724168957211077
Loss at iteration 1250 : 0.0003954456769861281
Loss at iteration 1260 : 6.976012809900567e-05
Loss at iteration 1270 : 0.0003133898717351258
Loss at iteration 1280 : 0.006853526458144188
Loss at iteration 1290 : 0.0028166850097477436
Loss at iteration 1300 : 9.06596687855199e-05
Loss at iteration 1310 : 0.0001932995073730126
Loss at iteration 1320 : 0.001891757478006184
Loss at iteration 1330 : 0.00031481232144869864
Loss at iteration 1340 : 0.00032101862598210573
Loss at iteration 1350 : 0.006678020115941763
Loss at iteration 1360 : 0.0031841518357396126
Loss at iteration 1370 : 0.0002230611426057294
Loss at iteration 1380 : 0.00029902675305493176
Loss at iteration 1390 : 0.002870403928682208
Loss at iteration 1400 : 0.0005519713158719242
Loss at iteration 1410 : 0.00015903121675364673
Loss at iteration 1420 : 0.0013634779024869204
Loss at iteration 1430 : 0.00012035883264616132
Loss at iteration 1440 : 0.0006489891093224287
Loss at iteration 1450 : 0.000263626134255901
Loss at iteration 1460 : 0.00016439514001831412
Loss at iteration 1470 : 0.0003323714481666684
Loss at iteration 1480 : 0.00045487278839573264
Loss at iteration 1490 : 0.00011914505739696324
Loss at iteration 1500 : 0.000140591204399243
Loss at iteration 1510 : 0.00016656488878652453
Loss at iteration 1520 : 8.721354242879897e-05
Loss at iteration 1530 : 0.00028338778065517545
Loss at iteration 1540 : 0.0001403569767717272
Loss at iteration 1550 : 0.00026526430156081915
Loss at iteration 1560 : 0.00014095427468419075
Loss at iteration 1570 : 0.00032865643152035773
Loss at iteration 1580 : 0.0004678203258663416
Loss at iteration 1590 : 7.921150972833857e-05
Loss at iteration 1600 : 0.0002773250453174114
Loss at iteration 1610 : 0.0003608269616961479
Loss at iteration 1620 : 0.0004841965273953974
Loss at iteration 1630 : 0.0035230042412877083
Loss at iteration 1640 : 0.00021101771562825888
Loss at iteration 1650 : 6.285563722485676e-05
Loss at iteration 1660 : 4.2086605390068144e-05
Loss at iteration 1670 : 0.00020781323837582022
Loss at iteration 1680 : 0.0020975025836378336
Loss at iteration 1690 : 0.00012563465861603618
Loss at iteration 1700 : 0.00013665464939549565
Loss at iteration 1710 : 0.005513608455657959
Loss at iteration 1720 : 0.0008487700251862407
Loss at iteration 1730 : 0.0009186338866129518
Loss at iteration 1740 : 0.0006728791049681604
Loss at iteration 1750 : 0.00024387647863477468
The SSIM Value is: 0.9799597161588165
The PSNR Value is: 46.767715187324825
the epoch is: 180
Loss at iteration 10 : 0.004119072575122118
Loss at iteration 20 : 0.00014493979688268155
Loss at iteration 30 : 0.0003654675674624741
Loss at iteration 40 : 0.00013932277215644717
Loss at iteration 50 : 5.023387348046526e-05
Loss at iteration 60 : 0.00045029143802821636
Loss at iteration 70 : 0.00011361198994563892
Loss at iteration 80 : 7.712409569649026e-05
Loss at iteration 90 : 0.00020086295262444764
Loss at iteration 100 : 0.000377470045350492
Loss at iteration 110 : 0.0012389153707772493
Loss at iteration 120 : 0.0003626908001024276
Loss at iteration 130 : 0.0024674225132912397
Loss at iteration 140 : 0.000571018026676029
Loss at iteration 150 : 0.0005052410997450352
Loss at iteration 160 : 0.0005590805085375905
Loss at iteration 170 : 0.003557471791282296
Loss at iteration 180 : 0.0005756576429121196
Loss at iteration 190 : 0.005694977007806301
Loss at iteration 200 : 0.00020506115106400102
Loss at iteration 210 : 0.00030124231125228107
Loss at iteration 220 : 0.0016186395660042763
Loss at iteration 230 : 0.00010805617057485506
Loss at iteration 240 : 0.000371603382518515
Loss at iteration 250 : 0.0002738420735113323
Loss at iteration 260 : 0.0001446244859835133
Loss at iteration 270 : 0.000566153263207525
Loss at iteration 280 : 0.00010480146738700569
Loss at iteration 290 : 0.00026102393167093396
Loss at iteration 300 : 0.0006683469982817769
Loss at iteration 310 : 0.003424138994887471
Loss at iteration 320 : 0.0004501508083194494
Loss at iteration 330 : 0.0009526833309791982
Loss at iteration 340 : 0.0020918939262628555
Loss at iteration 350 : 0.003637636313214898
Loss at iteration 360 : 0.00017616816330701113
Loss at iteration 370 : 0.00033026712480932474
Loss at iteration 380 : 0.004892207216471434
Loss at iteration 390 : 0.0001712667290121317
Loss at iteration 400 : 0.00013897306052967906
Loss at iteration 410 : 0.0035423384979367256
Loss at iteration 420 : 0.00020032812608405948
Loss at iteration 430 : 9.646314720157534e-05
Loss at iteration 440 : 0.0006134554278105497
Loss at iteration 450 : 0.0042250631377100945
Loss at iteration 460 : 0.00026163519942201674
Loss at iteration 470 : 0.003314379835501313
Loss at iteration 480 : 0.0004902587388642132
Loss at iteration 490 : 0.0004684113373514265
Loss at iteration 500 : 6.777323869755492e-05
Loss at iteration 510 : 0.0006951584364287555
Loss at iteration 520 : 4.536742562777363e-05
Loss at iteration 530 : 0.0012632054276764393
Loss at iteration 540 : 0.00022451189579442143
Loss at iteration 550 : 0.00016487270477227867
Loss at iteration 560 : 0.00011260480823693797
Loss at iteration 570 : 0.0005850224988535047
Loss at iteration 580 : 0.00013531066360883415
Loss at iteration 590 : 0.0010469802655279636
Loss at iteration 600 : 0.0003102208429481834
Loss at iteration 610 : 0.0001018477778416127
Loss at iteration 620 : 0.0007420858601108193
Loss at iteration 630 : 0.00011560382699826732
Loss at iteration 640 : 0.00011147093027830124
Loss at iteration 650 : 0.003202897496521473
Loss at iteration 660 : 0.0004774431581608951
Loss at iteration 670 : 0.0021183574572205544
Loss at iteration 680 : 0.00019878175226040184
Loss at iteration 690 : 5.579391654464416e-05
Loss at iteration 700 : 0.0007797637954354286
Loss at iteration 710 : 0.0001055554166669026
Loss at iteration 720 : 0.0001224375591846183
Loss at iteration 730 : 0.0019250580808147788
Loss at iteration 740 : 0.000828990712761879
Loss at iteration 750 : 6.196583854034543e-05
Loss at iteration 760 : 0.00016751505609136075
Loss at iteration 770 : 0.00017623862368054688
Loss at iteration 780 : 0.00013879494508728385
Loss at iteration 790 : 0.0009292238391935825
Loss at iteration 800 : 0.0005775343161076307
Loss at iteration 810 : 3.3008291211444885e-05
Loss at iteration 820 : 0.0002805501571856439
Loss at iteration 830 : 0.00013564898108597845
Loss at iteration 840 : 0.00028272473718971014
Loss at iteration 850 : 0.0011639866279438138
Loss at iteration 860 : 0.0012915446422994137
Loss at iteration 870 : 0.00014772493159398437
Loss at iteration 880 : 0.0003895628033205867
Loss at iteration 890 : 0.00015620249905623496
Loss at iteration 900 : 0.00024300528457388282
Loss at iteration 910 : 0.0002323438529856503
Loss at iteration 920 : 0.0008486885344609618
Loss at iteration 930 : 6.278036744333804e-05
Loss at iteration 940 : 5.80152845941484e-05
Loss at iteration 950 : 0.0038521720562130213
Loss at iteration 960 : 0.00021002836001571268
Loss at iteration 970 : 0.00013711312203668058
Loss at iteration 980 : 0.002628290094435215
Loss at iteration 990 : 0.0038204158190637827
Loss at iteration 1000 : 0.00016613896877970546
Loss at iteration 1010 : 0.00012921883899252862
Loss at iteration 1020 : 0.0002840789675246924
Loss at iteration 1030 : 0.0016673728823661804
Loss at iteration 1040 : 0.0001434516452718526
Loss at iteration 1050 : 0.00010247689351672307
Loss at iteration 1060 : 0.0025868183001875877
Loss at iteration 1070 : 0.0007263381266966462
Loss at iteration 1080 : 0.00039839764940552413
Loss at iteration 1090 : 0.00010782004392240196
Loss at iteration 1100 : 0.00012608013639692217
Loss at iteration 1110 : 0.0011271222028881311
Loss at iteration 1120 : 0.00022984019597060978
Loss at iteration 1130 : 0.0001575655915075913
Loss at iteration 1140 : 0.00021803884010296315
Loss at iteration 1150 : 0.0003047335194423795
Loss at iteration 1160 : 7.32850021449849e-05
Loss at iteration 1170 : 7.25060235708952e-05
Loss at iteration 1180 : 0.0006817701505497098
Loss at iteration 1190 : 0.002990385051816702
Loss at iteration 1200 : 0.00018108267977368087
Loss at iteration 1210 : 0.0027979412116110325
Loss at iteration 1220 : 9.865846368484199e-05
Loss at iteration 1230 : 5.924385186517611e-05
Loss at iteration 1240 : 0.0004047923721373081
Loss at iteration 1250 : 5.202053944231011e-05
Loss at iteration 1260 : 0.0016636814689263701
Loss at iteration 1270 : 0.0002457276568748057
Loss at iteration 1280 : 0.0003007011255249381
Loss at iteration 1290 : 0.0003283426340203732
Loss at iteration 1300 : 9.288723231293261e-05
Loss at iteration 1310 : 0.0002833024482242763
Loss at iteration 1320 : 0.0004181956755928695
Loss at iteration 1330 : 5.447224248200655e-05
Loss at iteration 1340 : 0.0002595950209069997
Loss at iteration 1350 : 0.0005972263752482831
Loss at iteration 1360 : 4.478159098653123e-05
Loss at iteration 1370 : 0.0007479515043087304
Loss at iteration 1380 : 0.00023557257372885942
Loss at iteration 1390 : 0.0003413109516259283
Loss at iteration 1400 : 0.00015276607882697135
Loss at iteration 1410 : 0.0024069303181022406
Loss at iteration 1420 : 0.00021829004981555045
Loss at iteration 1430 : 0.00025865412317216396
Loss at iteration 1440 : 0.0003427281917538494
Loss at iteration 1450 : 0.004142237827181816
Loss at iteration 1460 : 0.0001106105773942545
Loss at iteration 1470 : 0.0003633997985161841
Loss at iteration 1480 : 0.0002607129281386733
Loss at iteration 1490 : 9.608988330001011e-05
Loss at iteration 1500 : 0.0003085977805312723
Loss at iteration 1510 : 0.0002686095249373466
Loss at iteration 1520 : 0.004036463797092438
Loss at iteration 1530 : 0.002167313825339079
Loss at iteration 1540 : 8.38755804579705e-05
Loss at iteration 1550 : 9.395098459208384e-05
Loss at iteration 1560 : 0.00107945769559592
Loss at iteration 1570 : 0.0001676726242294535
Loss at iteration 1580 : 0.00016957419575192034
Loss at iteration 1590 : 0.0001498626807006076
Loss at iteration 1600 : 0.0032579265534877777
Loss at iteration 1610 : 0.0009018215350806713
Loss at iteration 1620 : 0.00011981620627921075
Loss at iteration 1630 : 0.00020674844563473016
Loss at iteration 1640 : 0.00013281199790071696
Loss at iteration 1650 : 0.00010815517453011125
Loss at iteration 1660 : 0.0005884191486984491
Loss at iteration 1670 : 5.2775012591155246e-05
Loss at iteration 1680 : 0.0002112264046445489
Loss at iteration 1690 : 0.0007418356835842133
Loss at iteration 1700 : 0.0003935275599360466
Loss at iteration 1710 : 0.004210749175399542
Loss at iteration 1720 : 8.872901526046917e-05
Loss at iteration 1730 : 0.00014909282617736608
Loss at iteration 1740 : 0.0002988638589158654
Loss at iteration 1750 : 0.0008236792637035251
The SSIM Value is: 0.9868673518103125
The PSNR Value is: 46.69480008700871
the epoch is: 181
Loss at iteration 10 : 0.001593605149537325
Loss at iteration 20 : 3.419502536416985e-05
Loss at iteration 30 : 0.00019294850062578917
Loss at iteration 40 : 0.0030838658567517996
Loss at iteration 50 : 0.0016743639716878533
Loss at iteration 60 : 0.00045748590491712093
Loss at iteration 70 : 0.0010632466292008758
Loss at iteration 80 : 0.00030457015964202583
Loss at iteration 90 : 0.0003443749446887523
Loss at iteration 100 : 0.000575035170186311
Loss at iteration 110 : 0.0036217947490513325
Loss at iteration 120 : 0.0009433188242837787
Loss at iteration 130 : 0.0006272293394431472
Loss at iteration 140 : 0.0001881029165815562
Loss at iteration 150 : 0.00019433586567174643
Loss at iteration 160 : 0.0008693326963111758
Loss at iteration 170 : 0.00015972483379300684
Loss at iteration 180 : 0.001289993291720748
Loss at iteration 190 : 0.00018383402493782341
Loss at iteration 200 : 7.761271990602836e-05
Loss at iteration 210 : 0.00023742017219774425
Loss at iteration 220 : 0.00036832221667282283
Loss at iteration 230 : 0.0006028318894095719
Loss at iteration 240 : 0.0007045239908620715
Loss at iteration 250 : 0.0004088609421160072
Loss at iteration 260 : 6.939344893908128e-05
Loss at iteration 270 : 9.753489575814456e-05
Loss at iteration 280 : 0.00028588908025994897
Loss at iteration 290 : 0.00017874814511742443
Loss at iteration 300 : 7.795335841365159e-05
Loss at iteration 310 : 0.001423168694600463
Loss at iteration 320 : 3.3147891372209415e-05
Loss at iteration 330 : 0.0001912668376462534
Loss at iteration 340 : 6.54810864944011e-05
Loss at iteration 350 : 0.00020049797603860497
Loss at iteration 360 : 0.00014814248424954712
Loss at iteration 370 : 0.0009376144735142589
Loss at iteration 380 : 0.00011817373160738498
Loss at iteration 390 : 9.055206464836374e-05
Loss at iteration 400 : 0.005280346143990755
Loss at iteration 410 : 7.572797767352313e-05
Loss at iteration 420 : 0.00033466811873950064
Loss at iteration 430 : 0.001681122463196516
Loss at iteration 440 : 0.0006430514622479677
Loss at iteration 450 : 0.0003506357315927744
Loss at iteration 460 : 9.326281724497676e-05
Loss at iteration 470 : 0.0008395204204134643
Loss at iteration 480 : 0.00027113547548651695
Loss at iteration 490 : 0.0005026825820095837
Loss at iteration 500 : 0.00016325594333466142
Loss at iteration 510 : 0.00029106769943609834
Loss at iteration 520 : 0.002019414911046624
Loss at iteration 530 : 0.003276971634477377
Loss at iteration 540 : 0.00020805056556127965
Loss at iteration 550 : 0.00014270150859374553
Loss at iteration 560 : 0.00010398344602435827
Loss at iteration 570 : 0.0004286118783056736
Loss at iteration 580 : 0.0008567971526645124
Loss at iteration 590 : 0.00015440184506587684
Loss at iteration 600 : 0.002190332394093275
Loss at iteration 610 : 0.0009060119045898318
Loss at iteration 620 : 7.65788063290529e-05
Loss at iteration 630 : 0.0008437429205514491
Loss at iteration 640 : 0.0013586361892521381
Loss at iteration 650 : 0.0008617674466222525
Loss at iteration 660 : 0.00019428702944424003
Loss at iteration 670 : 0.00025624525733292103
Loss at iteration 680 : 0.0002314223238499835
Loss at iteration 690 : 0.0018645712407305837
Loss at iteration 700 : 0.0002512125647626817
Loss at iteration 710 : 0.00029534759232774377
Loss at iteration 720 : 0.0036211032420396805
Loss at iteration 730 : 0.0015070396475493908
Loss at iteration 740 : 0.0039773667231202126
Loss at iteration 750 : 6.266070704441518e-05
Loss at iteration 760 : 0.0002165384212275967
Loss at iteration 770 : 0.00044488435378298163
Loss at iteration 780 : 0.00021484552416950464
Loss at iteration 790 : 0.00045709143159911036
Loss at iteration 800 : 0.0001668579934630543
Loss at iteration 810 : 0.002343069529160857
Loss at iteration 820 : 0.00016344602045137435
Loss at iteration 830 : 5.530931957764551e-05
Loss at iteration 840 : 0.0012090241070836782
Loss at iteration 850 : 6.568036042153835e-05
Loss at iteration 860 : 0.001123866648413241
Loss at iteration 870 : 0.0071539971977472305
Loss at iteration 880 : 0.0009386814199388027
Loss at iteration 890 : 0.0001029969280352816
Loss at iteration 900 : 0.0002370100119151175
Loss at iteration 910 : 0.00013815431157127023
Loss at iteration 920 : 0.0036666146479547024
Loss at iteration 930 : 0.00038325993227772415
Loss at iteration 940 : 0.0019099456258118153
Loss at iteration 950 : 0.00013658487296197563
Loss at iteration 960 : 0.00024405492877122015
Loss at iteration 970 : 0.0006386797176674008
Loss at iteration 980 : 0.00021664406813215464
Loss at iteration 990 : 0.0004168101295363158
Loss at iteration 1000 : 0.00019928588881157339
Loss at iteration 1010 : 0.004228594247251749
Loss at iteration 1020 : 0.0019457798916846514
Loss at iteration 1030 : 0.00035992945777252316
Loss at iteration 1040 : 0.00019155567861162126
Loss at iteration 1050 : 0.0005121227586641908
Loss at iteration 1060 : 0.0001285524049308151
Loss at iteration 1070 : 0.00036096025723963976
Loss at iteration 1080 : 0.0001922415103763342
Loss at iteration 1090 : 9.562964260112494e-05
Loss at iteration 1100 : 0.00020822350052185357
Loss at iteration 1110 : 0.0008136368705891073
Loss at iteration 1120 : 0.00021962402388453484
Loss at iteration 1130 : 0.0006947244983166456
Loss at iteration 1140 : 0.0010390767129138112
Loss at iteration 1150 : 9.18868463486433e-05
Loss at iteration 1160 : 0.00022457196610048413
Loss at iteration 1170 : 0.0003059990704059601
Loss at iteration 1180 : 0.00012730664457194507
Loss at iteration 1190 : 0.0009802107233554125
Loss at iteration 1200 : 0.0006778460228815675
Loss at iteration 1210 : 0.006394648924469948
Loss at iteration 1220 : 0.00019173829059582204
Loss at iteration 1230 : 0.0004308837524149567
Loss at iteration 1240 : 0.006839368492364883
Loss at iteration 1250 : 8.385816181544214e-05
Loss at iteration 1260 : 0.00013510150893125683
Loss at iteration 1270 : 0.0009119913447648287
Loss at iteration 1280 : 0.0012578143505379558
Loss at iteration 1290 : 0.0001587069418746978
Loss at iteration 1300 : 8.891162724466994e-05
Loss at iteration 1310 : 0.008701853454113007
Loss at iteration 1320 : 0.0009335184586234391
Loss at iteration 1330 : 0.0026243021711707115
Loss at iteration 1340 : 0.0005498707760125399
Loss at iteration 1350 : 0.00022185280977282673
Loss at iteration 1360 : 0.001894863205961883
Loss at iteration 1370 : 0.002667992142960429
Loss at iteration 1380 : 0.00014967704191803932
Loss at iteration 1390 : 0.0005461181281134486
Loss at iteration 1400 : 0.0008371758740395308
Loss at iteration 1410 : 0.0001480718783568591
Loss at iteration 1420 : 8.862558752298355e-05
Loss at iteration 1430 : 0.004567947704344988
Loss at iteration 1440 : 0.0005849773297086358
Loss at iteration 1450 : 9.973401029128581e-05
Loss at iteration 1460 : 0.00017868177383206785
Loss at iteration 1470 : 0.0001502364466432482
Loss at iteration 1480 : 0.0037545845843851566
Loss at iteration 1490 : 0.0002615153498481959
Loss at iteration 1500 : 0.002708363113924861
Loss at iteration 1510 : 0.00027297012275084853
Loss at iteration 1520 : 0.00025570610887371004
Loss at iteration 1530 : 0.0027932790108025074
Loss at iteration 1540 : 0.0038351675029844046
Loss at iteration 1550 : 0.0027274666354060173
Loss at iteration 1560 : 0.00035330161335878074
Loss at iteration 1570 : 0.0020000808872282505
Loss at iteration 1580 : 6.175817543407902e-05
Loss at iteration 1590 : 0.0007299719145521522
Loss at iteration 1600 : 0.0016004445496946573
Loss at iteration 1610 : 0.0005587735795415938
Loss at iteration 1620 : 0.002321419073268771
Loss at iteration 1630 : 0.0007716320687904954
Loss at iteration 1640 : 8.661820902489126e-05
Loss at iteration 1650 : 0.002253294689580798
Loss at iteration 1660 : 0.00035204051528126
Loss at iteration 1670 : 0.0014242687029764056
Loss at iteration 1680 : 5.794688331661746e-05
Loss at iteration 1690 : 0.00016751557996030897
Loss at iteration 1700 : 9.744834096636623e-05
Loss at iteration 1710 : 0.00371262663975358
Loss at iteration 1720 : 0.00045357298222370446
Loss at iteration 1730 : 0.00036747692502103746
Loss at iteration 1740 : 0.00015850269119255245
Loss at iteration 1750 : 0.0005444271955639124
The SSIM Value is: 0.9856038243234946
The PSNR Value is: 46.18263931106366
the epoch is: 182
Loss at iteration 10 : 0.00033975750557146966
Loss at iteration 20 : 0.002042289124801755
Loss at iteration 30 : 6.847004260635003e-05
Loss at iteration 40 : 0.00029540646937675774
Loss at iteration 50 : 0.00012920089648105204
Loss at iteration 60 : 0.00032972413464449346
Loss at iteration 70 : 0.0006379337282851338
Loss at iteration 80 : 0.0010914006270468235
Loss at iteration 90 : 0.00034865664201788604
Loss at iteration 100 : 0.0021072786767035723
Loss at iteration 110 : 0.00033460906706750393
Loss at iteration 120 : 0.0001832323323469609
Loss at iteration 130 : 0.0006396009121090174
Loss at iteration 140 : 0.00014668366929981858
Loss at iteration 150 : 0.0001789834932424128
Loss at iteration 160 : 0.00011666725913528353
Loss at iteration 170 : 0.00010939099593088031
Loss at iteration 180 : 0.000317622150760144
Loss at iteration 190 : 0.000321917817927897
Loss at iteration 200 : 0.0011773980222642422
Loss at iteration 210 : 0.0006956961588002741
Loss at iteration 220 : 0.000474403117550537
Loss at iteration 230 : 0.00025524268858134747
Loss at iteration 240 : 0.0005444204434752464
Loss at iteration 250 : 0.0002267271192977205
Loss at iteration 260 : 0.00227843364700675
Loss at iteration 270 : 0.0005077322130091488
Loss at iteration 280 : 0.0023955367505550385
Loss at iteration 290 : 0.00017521163681522012
Loss at iteration 300 : 0.0004162203404121101
Loss at iteration 310 : 0.003289609681814909
Loss at iteration 320 : 0.00016802582831587642
Loss at iteration 330 : 0.0002121231082128361
Loss at iteration 340 : 0.00011573594383662567
Loss at iteration 350 : 0.0014956356026232243
Loss at iteration 360 : 0.0007582672405987978
Loss at iteration 370 : 0.002606873167678714
Loss at iteration 380 : 0.004817128647118807
Loss at iteration 390 : 0.0006393783260136843
Loss at iteration 400 : 0.00025310329510830343
Loss at iteration 410 : 0.00030572270043194294
Loss at iteration 420 : 0.0009558711899444461
Loss at iteration 430 : 0.002522677183151245
Loss at iteration 440 : 0.0024749741423875093
Loss at iteration 450 : 0.0005348765989765525
Loss at iteration 460 : 7.821977487765253e-05
Loss at iteration 470 : 7.944794924696907e-05
Loss at iteration 480 : 9.160432819044217e-05
Loss at iteration 490 : 0.0006236145854927599
Loss at iteration 500 : 0.0013067515101283789
Loss at iteration 510 : 0.0004276652471162379
Loss at iteration 520 : 0.0009979888563975692
Loss at iteration 530 : 0.001038533402606845
Loss at iteration 540 : 0.0006654574535787106
Loss at iteration 550 : 0.001108977710828185
Loss at iteration 560 : 0.00032496763742528856
Loss at iteration 570 : 0.000302665401250124
Loss at iteration 580 : 0.001092425431124866
Loss at iteration 590 : 0.0011185789480805397
Loss at iteration 600 : 0.00013451292761601508
Loss at iteration 610 : 0.0005046185106039047
Loss at iteration 620 : 0.00034555376623757184
Loss at iteration 630 : 0.0013135102344676852
Loss at iteration 640 : 0.0003950920654460788
Loss at iteration 650 : 0.00010122687672264874
Loss at iteration 660 : 0.006119985599070787
Loss at iteration 670 : 0.00012767623411491513
Loss at iteration 680 : 0.0025853081606328487
Loss at iteration 690 : 0.0001769513764884323
Loss at iteration 700 : 0.0004219832189846784
Loss at iteration 710 : 0.00032153830397874117
Loss at iteration 720 : 0.00043452699901536107
Loss at iteration 730 : 0.00024599762400612235
Loss at iteration 740 : 0.0002308122639078647
Loss at iteration 750 : 0.00027329105068929493
Loss at iteration 760 : 0.003656543791294098
Loss at iteration 770 : 0.0003506829380057752
Loss at iteration 780 : 0.00023318240710068494
Loss at iteration 790 : 0.0007012175628915429
Loss at iteration 800 : 0.0016533315647393465
Loss at iteration 810 : 0.00017788252444006503
Loss at iteration 820 : 0.00020143689471296966
Loss at iteration 830 : 0.0012568003730848432
Loss at iteration 840 : 0.00016825206694193184
Loss at iteration 850 : 0.002433351008221507
Loss at iteration 860 : 0.0001887143444037065
Loss at iteration 870 : 0.0007347166538238525
Loss at iteration 880 : 7.610672037117183e-05
Loss at iteration 890 : 0.0005325257079675794
Loss at iteration 900 : 0.00012113470438634977
Loss at iteration 910 : 0.00027364000561647117
Loss at iteration 920 : 0.001170346513390541
Loss at iteration 930 : 0.00016093601880129427
Loss at iteration 940 : 9.164470975520089e-05
Loss at iteration 950 : 0.00023993992363102734
Loss at iteration 960 : 0.00018882332369685173
Loss at iteration 970 : 0.0031084809452295303
Loss at iteration 980 : 0.00014768398250453174
Loss at iteration 990 : 0.0002606402267701924
Loss at iteration 1000 : 0.0006297278450801969
Loss at iteration 1010 : 0.00040696034557186067
Loss at iteration 1020 : 0.0002154381072614342
Loss at iteration 1030 : 0.0005022919503971934
Loss at iteration 1040 : 0.0008802132215350866
Loss at iteration 1050 : 0.0011018505319952965
Loss at iteration 1060 : 0.0006124648498371243
Loss at iteration 1070 : 0.00119867199100554
Loss at iteration 1080 : 0.00012700459046754986
Loss at iteration 1090 : 0.0031124402303248644
Loss at iteration 1100 : 0.00021024048328399658
Loss at iteration 1110 : 0.0008310245466418564
Loss at iteration 1120 : 7.886523962952197e-05
Loss at iteration 1130 : 0.0004891418502666056
Loss at iteration 1140 : 6.181720527820289e-05
Loss at iteration 1150 : 0.003178040962666273
Loss at iteration 1160 : 0.0001034355373121798
Loss at iteration 1170 : 0.0009914444526657462
Loss at iteration 1180 : 5.656807479681447e-05
Loss at iteration 1190 : 0.00029235967667773366
Loss at iteration 1200 : 0.0001623709249543026
Loss at iteration 1210 : 0.0036746831610798836
Loss at iteration 1220 : 0.0001479881175328046
Loss at iteration 1230 : 0.0007642739219591022
Loss at iteration 1240 : 0.00042721626232378185
Loss at iteration 1250 : 0.004016458056867123
Loss at iteration 1260 : 0.005141678266227245
Loss at iteration 1270 : 3.423929956625216e-05
Loss at iteration 1280 : 0.0021458591800183058
Loss at iteration 1290 : 0.00013752555241808295
Loss at iteration 1300 : 0.00012508896179497242
Loss at iteration 1310 : 0.0021580089814960957
Loss at iteration 1320 : 0.00016239288379438221
Loss at iteration 1330 : 0.0008795356843620539
Loss at iteration 1340 : 0.0008002858376130462
Loss at iteration 1350 : 0.00021197546448092908
Loss at iteration 1360 : 0.0006754901260137558
Loss at iteration 1370 : 0.0004896763130091131
Loss at iteration 1380 : 0.0013763329479843378
Loss at iteration 1390 : 0.0001512767339590937
Loss at iteration 1400 : 0.0006161631317809224
Loss at iteration 1410 : 9.816764941206202e-05
Loss at iteration 1420 : 0.00023605419846717268
Loss at iteration 1430 : 0.00023835417232476175
Loss at iteration 1440 : 0.00011344890663167462
Loss at iteration 1450 : 0.0029539705719798803
Loss at iteration 1460 : 0.0002210883831139654
Loss at iteration 1470 : 0.00040548405377194285
Loss at iteration 1480 : 0.00019460354815237224
Loss at iteration 1490 : 0.0009216659818775952
Loss at iteration 1500 : 0.0003239148063585162
Loss at iteration 1510 : 0.00019041199993807822
Loss at iteration 1520 : 0.0022919911425560713
Loss at iteration 1530 : 0.0020132092759013176
Loss at iteration 1540 : 0.00044159230310469866
Loss at iteration 1550 : 0.00014913953782524914
Loss at iteration 1560 : 7.463716610800475e-05
Loss at iteration 1570 : 0.00016097993648145348
Loss at iteration 1580 : 0.0016922354698181152
Loss at iteration 1590 : 0.0003844686143565923
Loss at iteration 1600 : 0.0003066192730329931
Loss at iteration 1610 : 9.898337884806097e-05
Loss at iteration 1620 : 0.0003024860634468496
Loss at iteration 1630 : 0.00015891375369392335
Loss at iteration 1640 : 0.00016145275731105357
Loss at iteration 1650 : 0.0021155818831175566
Loss at iteration 1660 : 0.00031347424373961985
Loss at iteration 1670 : 0.0006367717287503183
Loss at iteration 1680 : 0.0030026622116565704
Loss at iteration 1690 : 0.00018533648108132184
Loss at iteration 1700 : 0.0015610468108206987
Loss at iteration 1710 : 7.390109385596588e-05
Loss at iteration 1720 : 0.0007127111312001944
Loss at iteration 1730 : 0.0001616712543182075
Loss at iteration 1740 : 0.00038499844959005713
Loss at iteration 1750 : 8.331918070325628e-05
The SSIM Value is: 0.9848788828314139
The PSNR Value is: 46.5209468282792
the epoch is: 183
Loss at iteration 10 : 9.36837459448725e-05
Loss at iteration 20 : 0.0011411861050873995
Loss at iteration 30 : 0.00010135090997209772
Loss at iteration 40 : 0.002734447829425335
Loss at iteration 50 : 0.0022757563274353743
Loss at iteration 60 : 0.0006427131011150777
Loss at iteration 70 : 0.0010407562367618084
Loss at iteration 80 : 0.000215101899811998
Loss at iteration 90 : 0.0008334918529726565
Loss at iteration 100 : 0.0020053922198712826
Loss at iteration 110 : 0.0013882513158023357
Loss at iteration 120 : 6.916841812198982e-05
Loss at iteration 130 : 0.00044620598782785237
Loss at iteration 140 : 0.0003564565849956125
Loss at iteration 150 : 0.0005281225312501192
Loss at iteration 160 : 0.00036090670619159937
Loss at iteration 170 : 6.018408384989016e-05
Loss at iteration 180 : 0.0002687966334633529
Loss at iteration 190 : 0.0034504015929996967
Loss at iteration 200 : 0.00015226764662656933
Loss at iteration 210 : 0.001351582002826035
Loss at iteration 220 : 0.0023267779033631086
Loss at iteration 230 : 0.0002297868486493826
Loss at iteration 240 : 1.997633808059618e-05
Loss at iteration 250 : 0.00351184350438416
Loss at iteration 260 : 7.837355951778591e-05
Loss at iteration 270 : 9.492706885794178e-05
Loss at iteration 280 : 4.202001582598314e-05
Loss at iteration 290 : 0.00013744592433795333
Loss at iteration 300 : 0.0003644742537289858
Loss at iteration 310 : 0.00048752358998171985
Loss at iteration 320 : 0.0001310910884058103
Loss at iteration 330 : 0.00199002749286592
Loss at iteration 340 : 0.00022466914379037917
Loss at iteration 350 : 0.00020132854115217924
Loss at iteration 360 : 0.0003668937715701759
Loss at iteration 370 : 0.0030697137117385864
Loss at iteration 380 : 0.0002114906528731808
Loss at iteration 390 : 0.0004396605654619634
Loss at iteration 400 : 5.9731497458415106e-05
Loss at iteration 410 : 0.003429412841796875
Loss at iteration 420 : 0.0008080864208750427
Loss at iteration 430 : 0.00018527981592342257
Loss at iteration 440 : 8.503886783728376e-05
Loss at iteration 450 : 0.0025913515128195286
Loss at iteration 460 : 0.0012489201035350561
Loss at iteration 470 : 0.00014728163660038263
Loss at iteration 480 : 0.00017638101417105645
Loss at iteration 490 : 9.171096462523565e-05
Loss at iteration 500 : 0.00010720345744630322
Loss at iteration 510 : 0.00032567529706284404
Loss at iteration 520 : 0.002828051336109638
Loss at iteration 530 : 0.00027476975810714066
Loss at iteration 540 : 0.0002803293173201382
Loss at iteration 550 : 0.0004106179694645107
Loss at iteration 560 : 0.000189562066225335
Loss at iteration 570 : 0.0002918361278716475
Loss at iteration 580 : 0.0009101490722969174
Loss at iteration 590 : 8.222928590839729e-05
Loss at iteration 600 : 0.0001966064010048285
Loss at iteration 610 : 7.430960977217183e-05
Loss at iteration 620 : 0.0005482073174789548
Loss at iteration 630 : 0.0007211272604763508
Loss at iteration 640 : 0.003093078965321183
Loss at iteration 650 : 0.0031540184281766415
Loss at iteration 660 : 0.003036065027117729
Loss at iteration 670 : 0.00045182942994870245
Loss at iteration 680 : 0.0038809548132121563
Loss at iteration 690 : 0.001174240023829043
Loss at iteration 700 : 0.0003596153692342341
Loss at iteration 710 : 0.00014931797340977937
Loss at iteration 720 : 0.0009852191433310509
Loss at iteration 730 : 0.0002669655659701675
Loss at iteration 740 : 0.00013128187856636941
Loss at iteration 750 : 0.0013710143975913525
Loss at iteration 760 : 0.00027548670186661184
Loss at iteration 770 : 0.0011240406893193722
Loss at iteration 780 : 0.0011282078921794891
Loss at iteration 790 : 0.004902302287518978
Loss at iteration 800 : 0.0008068176684901118
Loss at iteration 810 : 0.000603415654040873
Loss at iteration 820 : 0.001635136315599084
Loss at iteration 830 : 3.5506316635292023e-05
Loss at iteration 840 : 0.0025241696275770664
Loss at iteration 850 : 0.0018552171532064676
Loss at iteration 860 : 0.0023461629170924425
Loss at iteration 870 : 0.005200501065701246
Loss at iteration 880 : 0.00014434994955081493
Loss at iteration 890 : 0.00015539459127467126
Loss at iteration 900 : 7.057531183818355e-05
Loss at iteration 910 : 0.0014128433540463448
Loss at iteration 920 : 0.00015123230696190149
Loss at iteration 930 : 0.00023068762675393373
Loss at iteration 940 : 0.00774047477170825
Loss at iteration 950 : 8.837688073981553e-05
Loss at iteration 960 : 0.002292782999575138
Loss at iteration 970 : 0.00210288492962718
Loss at iteration 980 : 5.115658859722316e-05
Loss at iteration 990 : 6.983066850807518e-05
Loss at iteration 1000 : 0.0021003957372158766
Loss at iteration 1010 : 0.00033484757295809686
Loss at iteration 1020 : 0.0001302924210904166
Loss at iteration 1030 : 0.0001748394570313394
Loss at iteration 1040 : 0.0023507606238126755
Loss at iteration 1050 : 9.074868285097182e-05
Loss at iteration 1060 : 0.00012833281653001904
Loss at iteration 1070 : 0.0006989340763539076
Loss at iteration 1080 : 0.0037370959762483835
Loss at iteration 1090 : 0.004325277172029018
Loss at iteration 1100 : 0.0006727055879309773
Loss at iteration 1110 : 0.00010812886466737837
Loss at iteration 1120 : 0.005583936348557472
Loss at iteration 1130 : 9.76991286734119e-05
Loss at iteration 1140 : 6.651005969615653e-05
Loss at iteration 1150 : 0.00018943716713692993
Loss at iteration 1160 : 0.0001810252433642745
Loss at iteration 1170 : 0.001846545492298901
Loss at iteration 1180 : 0.00013945761020295322
Loss at iteration 1190 : 0.002997463569045067
Loss at iteration 1200 : 0.0023260782472789288
Loss at iteration 1210 : 0.00020177432452328503
Loss at iteration 1220 : 8.30211429274641e-05
Loss at iteration 1230 : 0.00016016907466109842
Loss at iteration 1240 : 0.0011461256071925163
Loss at iteration 1250 : 0.0010900491615757346
Loss at iteration 1260 : 0.0006402122089639306
Loss at iteration 1270 : 0.00013970283907838166
Loss at iteration 1280 : 0.0003467065398581326
Loss at iteration 1290 : 0.0012512868270277977
Loss at iteration 1300 : 0.0050098528154194355
Loss at iteration 1310 : 6.485475023509935e-05
Loss at iteration 1320 : 0.001269856235012412
Loss at iteration 1330 : 0.00017491063044872135
Loss at iteration 1340 : 0.000618903839495033
Loss at iteration 1350 : 0.0006474939873442054
Loss at iteration 1360 : 0.003019949421286583
Loss at iteration 1370 : 0.00016963202506303787
Loss at iteration 1380 : 0.00017750993720255792
Loss at iteration 1390 : 0.0009704824769869447
Loss at iteration 1400 : 0.00019440255709923804
Loss at iteration 1410 : 7.501968502765521e-05
Loss at iteration 1420 : 0.002982119331136346
Loss at iteration 1430 : 0.002638267818838358
Loss at iteration 1440 : 0.00040241528768092394
Loss at iteration 1450 : 7.387797813862562e-05
Loss at iteration 1460 : 0.00019352618255652487
Loss at iteration 1470 : 0.003956268075853586
Loss at iteration 1480 : 0.0016043060459196568
Loss at iteration 1490 : 0.0006751202745363116
Loss at iteration 1500 : 0.000371229718439281
Loss at iteration 1510 : 0.00013789448712486774
Loss at iteration 1520 : 0.0034817990381270647
Loss at iteration 1530 : 0.00027993720141239464
Loss at iteration 1540 : 0.005502333864569664
Loss at iteration 1550 : 0.0002572335652075708
Loss at iteration 1560 : 0.0005254396237432957
Loss at iteration 1570 : 0.00020423279784154147
Loss at iteration 1580 : 0.0001677510008448735
Loss at iteration 1590 : 0.0001560496020829305
Loss at iteration 1600 : 0.003436411265283823
Loss at iteration 1610 : 0.00043896184070035815
Loss at iteration 1620 : 0.0009884120663627982
Loss at iteration 1630 : 0.0002179017465095967
Loss at iteration 1640 : 0.00031108467373996973
Loss at iteration 1650 : 0.00026272484683431685
Loss at iteration 1660 : 6.841410504421219e-05
Loss at iteration 1670 : 0.00013568898430094123
Loss at iteration 1680 : 0.000198498455574736
Loss at iteration 1690 : 0.00010506655962672085
Loss at iteration 1700 : 9.909019718179479e-05
Loss at iteration 1710 : 0.00012294918997213244
Loss at iteration 1720 : 0.0002946247404906899
Loss at iteration 1730 : 0.0003674026229418814
Loss at iteration 1740 : 0.0001062661103787832
Loss at iteration 1750 : 0.0016971139702945948
The SSIM Value is: 0.9864010033628489
The PSNR Value is: 46.814523621277665
the epoch is: 184
Loss at iteration 10 : 0.0014467518776655197
Loss at iteration 20 : 0.00012846918252762407
Loss at iteration 30 : 8.706182416062802e-05
Loss at iteration 40 : 0.0012915426632389426
Loss at iteration 50 : 0.0002141385048162192
Loss at iteration 60 : 0.00014120318519417197
Loss at iteration 70 : 5.2289913583081216e-05
Loss at iteration 80 : 0.00010406947694718838
Loss at iteration 90 : 0.004844175651669502
Loss at iteration 100 : 9.418628906132653e-05
Loss at iteration 110 : 0.000261790759395808
Loss at iteration 120 : 0.00010339560685679317
Loss at iteration 130 : 0.0006271853344514966
Loss at iteration 140 : 0.00013110772124491632
Loss at iteration 150 : 0.0020208011846989393
Loss at iteration 160 : 0.003516780212521553
Loss at iteration 170 : 0.00016851539839990437
Loss at iteration 180 : 0.0011288404930382967
Loss at iteration 190 : 0.0004954287433065474
Loss at iteration 200 : 0.00016836856957525015
Loss at iteration 210 : 9.896131814457476e-05
Loss at iteration 220 : 6.463011959567666e-05
Loss at iteration 230 : 0.00200044852681458
Loss at iteration 240 : 0.0009594122529961169
Loss at iteration 250 : 0.0002865470014512539
Loss at iteration 260 : 0.0006260725203901529
Loss at iteration 270 : 6.0881990066263825e-05
Loss at iteration 280 : 0.0001683875743765384
Loss at iteration 290 : 9.290129673900083e-05
Loss at iteration 300 : 0.001812991569750011
Loss at iteration 310 : 0.002520727226510644
Loss at iteration 320 : 0.0004000578774139285
Loss at iteration 330 : 0.0006846345495432615
Loss at iteration 340 : 0.0001340263115707785
Loss at iteration 350 : 0.0034777368418872356
Loss at iteration 360 : 5.538050027098507e-05
Loss at iteration 370 : 0.001482648542150855
Loss at iteration 380 : 0.001961813075467944
Loss at iteration 390 : 0.000551901466678828
Loss at iteration 400 : 4.7832716518314555e-05
Loss at iteration 410 : 0.0005852526519447565
Loss at iteration 420 : 0.0002220995374955237
Loss at iteration 430 : 0.0013238133396953344
Loss at iteration 440 : 0.0017124796286225319
Loss at iteration 450 : 1.5982601325958967e-05
Loss at iteration 460 : 0.001193802454508841
Loss at iteration 470 : 0.0027626552619040012
Loss at iteration 480 : 4.854168219026178e-05
Loss at iteration 490 : 0.0002253320999443531
Loss at iteration 500 : 0.00022369010548572987
Loss at iteration 510 : 0.00022890768013894558
Loss at iteration 520 : 0.0028663286939263344
Loss at iteration 530 : 0.0004872198333032429
Loss at iteration 540 : 0.004020671360194683
Loss at iteration 550 : 0.0004297205596230924
Loss at iteration 560 : 0.000336363329552114
Loss at iteration 570 : 0.0011380934156477451
Loss at iteration 580 : 0.00038243469316512346
Loss at iteration 590 : 0.004845636896789074
Loss at iteration 600 : 0.0021615992300212383
Loss at iteration 610 : 0.00034694772330112755
Loss at iteration 620 : 0.0013347057392820716
Loss at iteration 630 : 0.0008375338511541486
Loss at iteration 640 : 0.0007346925558522344
Loss at iteration 650 : 8.786280523054302e-05
Loss at iteration 660 : 0.00010670912161003798
Loss at iteration 670 : 0.0030773982871323824
Loss at iteration 680 : 0.00017197839042637497
Loss at iteration 690 : 0.00012796928058378398
Loss at iteration 700 : 6.307061994448304e-05
Loss at iteration 710 : 0.000240680092247203
Loss at iteration 720 : 3.633149026427418e-05
Loss at iteration 730 : 0.0006899746949784458
Loss at iteration 740 : 0.000663840037304908
Loss at iteration 750 : 0.00041888371924869716
Loss at iteration 760 : 0.005913559813052416
Loss at iteration 770 : 0.00013114309695083648
Loss at iteration 780 : 0.00030863884603604674
Loss at iteration 790 : 0.0026240921579301357
Loss at iteration 800 : 0.00046448269858956337
Loss at iteration 810 : 9.812515781959519e-05
Loss at iteration 820 : 0.0002105528983520344
Loss at iteration 830 : 0.0004590621974784881
Loss at iteration 840 : 8.87075875652954e-05
Loss at iteration 850 : 8.472645276924595e-05
Loss at iteration 860 : 0.00041003531077876687
Loss at iteration 870 : 9.241747466148809e-05
Loss at iteration 880 : 0.0006209785933606327
Loss at iteration 890 : 8.595868712291121e-05
Loss at iteration 900 : 0.0004608651506714523
Loss at iteration 910 : 0.003085747128352523
Loss at iteration 920 : 0.00015481084119528532
Loss at iteration 930 : 0.0009639815543778241
Loss at iteration 940 : 0.00024651671992614865
Loss at iteration 950 : 0.00022344468743540347
Loss at iteration 960 : 0.00011696033470798284
Loss at iteration 970 : 0.00021420340635813773
Loss at iteration 980 : 0.0008668744703754783
Loss at iteration 990 : 0.0018484822940081358
Loss at iteration 1000 : 0.0001530661538708955
Loss at iteration 1010 : 0.000304181594401598
Loss at iteration 1020 : 0.0002527019823901355
Loss at iteration 1030 : 0.001021609641611576
Loss at iteration 1040 : 0.0005069455364719033
Loss at iteration 1050 : 0.0008319598855450749
Loss at iteration 1060 : 0.00014522606215905398
Loss at iteration 1070 : 0.00012419889390002936
Loss at iteration 1080 : 0.0004512507584877312
Loss at iteration 1090 : 0.0009456147672608495
Loss at iteration 1100 : 0.00014376486069522798
Loss at iteration 1110 : 9.505593334324658e-05
Loss at iteration 1120 : 5.707770833396353e-05
Loss at iteration 1130 : 0.0033542097080498934
Loss at iteration 1140 : 0.0001409136166330427
Loss at iteration 1150 : 0.0002766576944850385
Loss at iteration 1160 : 9.902589226840064e-05
Loss at iteration 1170 : 9.854527161223814e-05
Loss at iteration 1180 : 0.0002505848533473909
Loss at iteration 1190 : 5.4548905609408394e-05
Loss at iteration 1200 : 0.0012559543829411268
Loss at iteration 1210 : 0.00019806489581242204
Loss at iteration 1220 : 0.0015321606770157814
Loss at iteration 1230 : 0.00014816864859312773
Loss at iteration 1240 : 0.000222393951844424
Loss at iteration 1250 : 3.8302001485135406e-05
Loss at iteration 1260 : 0.0071984389796853065
Loss at iteration 1270 : 0.0016103871166706085
Loss at iteration 1280 : 0.0013543486129492521
Loss at iteration 1290 : 0.00021828286116942763
Loss at iteration 1300 : 0.0006097506848163903
Loss at iteration 1310 : 8.930719923228025e-05
Loss at iteration 1320 : 4.4948788854526356e-05
Loss at iteration 1330 : 9.045138722285628e-05
Loss at iteration 1340 : 0.00018238386837765574
Loss at iteration 1350 : 0.0024924033787101507
Loss at iteration 1360 : 0.001989145064726472
Loss at iteration 1370 : 0.00013093536836095154
Loss at iteration 1380 : 0.00033088395139202476
Loss at iteration 1390 : 0.0001803541963454336
Loss at iteration 1400 : 0.004374376963824034
Loss at iteration 1410 : 0.0026868386194109917
Loss at iteration 1420 : 0.00198163790628314
Loss at iteration 1430 : 0.0020686560310423374
Loss at iteration 1440 : 8.202462777262554e-05
Loss at iteration 1450 : 0.0018708809511736035
Loss at iteration 1460 : 0.001606089062988758
Loss at iteration 1470 : 0.0004821198817808181
Loss at iteration 1480 : 0.0008717280579730868
Loss at iteration 1490 : 0.0001607129815965891
Loss at iteration 1500 : 0.000129546329844743
Loss at iteration 1510 : 0.003175936406478286
Loss at iteration 1520 : 0.00032508716685697436
Loss at iteration 1530 : 0.0008251729886978865
Loss at iteration 1540 : 0.0031910990364849567
Loss at iteration 1550 : 0.0006350946496240795
Loss at iteration 1560 : 8.42533481772989e-05
Loss at iteration 1570 : 3.453392127994448e-05
Loss at iteration 1580 : 0.0003313050256110728
Loss at iteration 1590 : 0.0005611469969153404
Loss at iteration 1600 : 0.0004122456884942949
Loss at iteration 1610 : 0.00035233504604548216
Loss at iteration 1620 : 0.002417298499494791
Loss at iteration 1630 : 8.969353802967817e-05
Loss at iteration 1640 : 0.003346749348565936
Loss at iteration 1650 : 7.542221283074468e-05
Loss at iteration 1660 : 0.0029540432151407003
Loss at iteration 1670 : 0.00015693639579694718
Loss at iteration 1680 : 0.0015166820958256721
Loss at iteration 1690 : 0.0007214680081233382
Loss at iteration 1700 : 0.002430867636576295
Loss at iteration 1710 : 0.00047184404684230685
Loss at iteration 1720 : 0.0021932695526629686
Loss at iteration 1730 : 0.0002499003894627094
Loss at iteration 1740 : 0.00029897678177803755
Loss at iteration 1750 : 0.00026156677631661296
The SSIM Value is: 0.9874506671523208
The PSNR Value is: 46.26262045536797
the epoch is: 185
Loss at iteration 10 : 0.0004442596109583974
Loss at iteration 20 : 0.00016853763372637331
Loss at iteration 30 : 3.674581239465624e-05
Loss at iteration 40 : 0.00024105835473164916
Loss at iteration 50 : 0.0045592705719172955
Loss at iteration 60 : 0.00015277572674676776
Loss at iteration 70 : 0.00028323038714006543
Loss at iteration 80 : 0.00012945482740178704
Loss at iteration 90 : 0.00036766508128494024
Loss at iteration 100 : 0.0011119344271719456
Loss at iteration 110 : 0.00015064651961438358
Loss at iteration 120 : 0.0007812949479557574
Loss at iteration 130 : 5.4371463193092495e-05
Loss at iteration 140 : 0.0005556225660257041
Loss at iteration 150 : 0.0008106331806629896
Loss at iteration 160 : 0.00016152896569110453
Loss at iteration 170 : 0.00047369831008836627
Loss at iteration 180 : 0.0005771007854491472
Loss at iteration 190 : 0.0002272627898491919
Loss at iteration 200 : 0.00018229300621896982
Loss at iteration 210 : 0.00038841681089252234
Loss at iteration 220 : 0.0011965916492044926
Loss at iteration 230 : 6.986640073591843e-05
Loss at iteration 240 : 0.001487760804593563
Loss at iteration 250 : 0.004513557534664869
Loss at iteration 260 : 5.426517964224331e-05
Loss at iteration 270 : 0.003725153859704733
Loss at iteration 280 : 0.0002827694406732917
Loss at iteration 290 : 0.00022111815633252263
Loss at iteration 300 : 0.00019092309230472893
Loss at iteration 310 : 0.0004041095671709627
Loss at iteration 320 : 0.0002287701645400375
Loss at iteration 330 : 0.00010971515439450741
Loss at iteration 340 : 0.0001224988664034754
Loss at iteration 350 : 0.00029429729329422116
Loss at iteration 360 : 0.00010321933223167434
Loss at iteration 370 : 0.0001041817813529633
Loss at iteration 380 : 0.0017907969886437058
Loss at iteration 390 : 0.00024069756909739226
Loss at iteration 400 : 8.201640594052151e-05
Loss at iteration 410 : 0.0005817395867779851
Loss at iteration 420 : 0.00021900612046010792
Loss at iteration 430 : 0.0014078859239816666
Loss at iteration 440 : 0.00032357449526898563
Loss at iteration 450 : 0.00016256567323580384
Loss at iteration 460 : 0.00012024477473460138
Loss at iteration 470 : 0.0003033284447155893
Loss at iteration 480 : 0.0005210667150095105
Loss at iteration 490 : 0.0010296632535755634
Loss at iteration 500 : 0.0001298859715461731
Loss at iteration 510 : 0.00029120894032530487
Loss at iteration 520 : 4.6959063183749095e-05
Loss at iteration 530 : 0.00018946375348605216
Loss at iteration 540 : 0.00022431302932091057
Loss at iteration 550 : 0.00017947590094991028
Loss at iteration 560 : 6.417078111553565e-05
Loss at iteration 570 : 0.0015315298223868012
Loss at iteration 580 : 0.0002610684314277023
Loss at iteration 590 : 0.0008636874845251441
Loss at iteration 600 : 0.0017639431171119213
Loss at iteration 610 : 0.0007390379905700684
Loss at iteration 620 : 0.0026014582253992558
Loss at iteration 630 : 0.00035853724693879485
Loss at iteration 640 : 0.0001368900266243145
Loss at iteration 650 : 0.00033300244831480086
Loss at iteration 660 : 0.00013150880113244057
Loss at iteration 670 : 0.0003922481555491686
Loss at iteration 680 : 6.198038317961618e-05
Loss at iteration 690 : 0.002937357872724533
Loss at iteration 700 : 0.00023252020764630288
Loss at iteration 710 : 0.00016962994413916022
Loss at iteration 720 : 0.0006069815717637539
Loss at iteration 730 : 0.005537046119570732
Loss at iteration 740 : 0.0005140964640304446
Loss at iteration 750 : 0.0023625092580914497
Loss at iteration 760 : 0.00014431914314627647
Loss at iteration 770 : 0.0003932469990104437
Loss at iteration 780 : 0.004698628559708595
Loss at iteration 790 : 0.0005504321306943893
Loss at iteration 800 : 0.00029533394263125956
Loss at iteration 810 : 0.00018205546075478196
Loss at iteration 820 : 4.565889685181901e-05
Loss at iteration 830 : 0.0013971112202852964
Loss at iteration 840 : 0.00010286943143000826
Loss at iteration 850 : 0.0019915776792913675
Loss at iteration 860 : 0.00015429386985488236
Loss at iteration 870 : 0.00024972413666546345
Loss at iteration 880 : 0.0001878395996754989
Loss at iteration 890 : 0.0001319900038652122
Loss at iteration 900 : 0.00012424244778230786
Loss at iteration 910 : 0.00014800546341575682
Loss at iteration 920 : 0.0019338370766490698
Loss at iteration 930 : 0.000697250769007951
Loss at iteration 940 : 0.0004348727234173566
Loss at iteration 950 : 0.0022875650320202112
Loss at iteration 960 : 0.001593321212567389
Loss at iteration 970 : 0.000187270634341985
Loss at iteration 980 : 0.0003183313529007137
Loss at iteration 990 : 0.00022196941426955163
Loss at iteration 1000 : 0.00015598293975926936
Loss at iteration 1010 : 0.00019252813945058733
Loss at iteration 1020 : 0.0004862602800130844
Loss at iteration 1030 : 0.0002462036209180951
Loss at iteration 1040 : 0.0016449438408017159
Loss at iteration 1050 : 0.0020621090661734343
Loss at iteration 1060 : 0.0004093410971108824
Loss at iteration 1070 : 0.00012035432882839814
Loss at iteration 1080 : 0.0013571525923907757
Loss at iteration 1090 : 6.13485390204005e-05
Loss at iteration 1100 : 6.73057948006317e-05
Loss at iteration 1110 : 0.002786375815048814
Loss at iteration 1120 : 0.0006583078647963703
Loss at iteration 1130 : 0.00013186260184738785
Loss at iteration 1140 : 0.00015719421207904816
Loss at iteration 1150 : 0.0003743173147086054
Loss at iteration 1160 : 0.00016903792857192457
Loss at iteration 1170 : 0.00012995742144994438
Loss at iteration 1180 : 0.003219924634322524
Loss at iteration 1190 : 0.0001349667873000726
Loss at iteration 1200 : 0.004857989493757486
Loss at iteration 1210 : 0.0006256148335523903
Loss at iteration 1220 : 0.0001283362798858434
Loss at iteration 1230 : 0.00021612779528368264
Loss at iteration 1240 : 0.0004438101896084845
Loss at iteration 1250 : 0.00027129496447741985
Loss at iteration 1260 : 0.00023476632486563176
Loss at iteration 1270 : 0.00021806725999340415
Loss at iteration 1280 : 0.0005814936012029648
Loss at iteration 1290 : 0.00011201966844964772
Loss at iteration 1300 : 7.163747795857489e-05
Loss at iteration 1310 : 7.479246414732188e-05
Loss at iteration 1320 : 0.0003418688429519534
Loss at iteration 1330 : 0.00012773620255757123
Loss at iteration 1340 : 6.924841727595776e-05
Loss at iteration 1350 : 6.937221041880548e-05
Loss at iteration 1360 : 0.0025886651128530502
Loss at iteration 1370 : 0.0007219433900900185
Loss at iteration 1380 : 0.0007654158398509026
Loss at iteration 1390 : 0.0018288370920345187
Loss at iteration 1400 : 0.00016210615285672247
Loss at iteration 1410 : 0.0048511759378015995
Loss at iteration 1420 : 0.00011816241749329492
Loss at iteration 1430 : 0.00014156878751236945
Loss at iteration 1440 : 5.0715640099952e-05
Loss at iteration 1450 : 0.0004366383654996753
Loss at iteration 1460 : 0.005261356942355633
Loss at iteration 1470 : 0.00014593832020182163
Loss at iteration 1480 : 0.0016686837188899517
Loss at iteration 1490 : 0.002149017294868827
Loss at iteration 1500 : 0.00019985312246717513
Loss at iteration 1510 : 0.0004308682691771537
Loss at iteration 1520 : 0.0005527809262275696
Loss at iteration 1530 : 6.995078729232773e-05
Loss at iteration 1540 : 0.0013824229827150702
Loss at iteration 1550 : 0.00037208746653050184
Loss at iteration 1560 : 0.00014977969112806022
Loss at iteration 1570 : 0.00018180356710217893
Loss at iteration 1580 : 0.000374543946236372
Loss at iteration 1590 : 0.0003941582690458745
Loss at iteration 1600 : 0.0002207374491263181
Loss at iteration 1610 : 9.440006397198886e-05
Loss at iteration 1620 : 0.0005668348749168217
Loss at iteration 1630 : 0.00024335537455044687
Loss at iteration 1640 : 0.0005463130655698478
Loss at iteration 1650 : 0.0010338713182136416
Loss at iteration 1660 : 0.00010544066753936931
Loss at iteration 1670 : 0.005424577742815018
Loss at iteration 1680 : 0.0034454739652574062
Loss at iteration 1690 : 7.402589108096436e-05
Loss at iteration 1700 : 0.0015461877919733524
Loss at iteration 1710 : 0.0002744944067671895
Loss at iteration 1720 : 0.0005010582390241325
Loss at iteration 1730 : 0.0002995550457853824
Loss at iteration 1740 : 0.0029727439396083355
Loss at iteration 1750 : 5.664115451509133e-05
The SSIM Value is: 0.9847036200998113
The PSNR Value is: 46.65757797258016
the epoch is: 186
Loss at iteration 10 : 0.0013946411199867725
Loss at iteration 20 : 0.00019377024727873504
Loss at iteration 30 : 0.0014587226323783398
Loss at iteration 40 : 0.0004587309085763991
Loss at iteration 50 : 0.00018711111624725163
Loss at iteration 60 : 0.00032886891858652234
Loss at iteration 70 : 0.00018970364180859178
Loss at iteration 80 : 0.003975607454776764
Loss at iteration 90 : 0.0010171954054385424
Loss at iteration 100 : 0.00025984743842855096
Loss at iteration 110 : 8.857213833834976e-05
Loss at iteration 120 : 0.0001512226153863594
Loss at iteration 130 : 0.0016351828817278147
Loss at iteration 140 : 0.0002179202565457672
Loss at iteration 150 : 0.008112368173897266
Loss at iteration 160 : 0.00041143031558021903
Loss at iteration 170 : 0.00017640338046476245
Loss at iteration 180 : 0.0004487745463848114
Loss at iteration 190 : 0.00042094034142792225
Loss at iteration 200 : 8.11536519904621e-05
Loss at iteration 210 : 0.004030910786241293
Loss at iteration 220 : 8.545599121134728e-05
Loss at iteration 230 : 0.00013008719542995095
Loss at iteration 240 : 8.976308163255453e-05
Loss at iteration 250 : 0.0019736704416573048
Loss at iteration 260 : 0.0004582058172672987
Loss at iteration 270 : 0.00014373098383657634
Loss at iteration 280 : 0.00043367757461965084
Loss at iteration 290 : 0.0005155513645149767
Loss at iteration 300 : 0.00013679932453669608
Loss at iteration 310 : 0.0005623519537039101
Loss at iteration 320 : 0.00013638842210639268
Loss at iteration 330 : 0.00019949347188230604
Loss at iteration 340 : 0.000412758527090773
Loss at iteration 350 : 0.0010742072481662035
Loss at iteration 360 : 0.00011959021503571421
Loss at iteration 370 : 0.00040980451740324497
Loss at iteration 380 : 0.003533279290422797
Loss at iteration 390 : 0.005220919847488403
Loss at iteration 400 : 4.3795185774797574e-05
Loss at iteration 410 : 0.005519362166523933
Loss at iteration 420 : 0.00023421089281328022
Loss at iteration 430 : 0.0015449672937393188
Loss at iteration 440 : 0.00020957486412953585
Loss at iteration 450 : 0.0002987187181133777
Loss at iteration 460 : 0.001458877930417657
Loss at iteration 470 : 0.00015757211076561362
Loss at iteration 480 : 0.0022329192142933607
Loss at iteration 490 : 0.0002804239629767835
Loss at iteration 500 : 0.00026358553441241384
Loss at iteration 510 : 0.005573226138949394
Loss at iteration 520 : 0.0002726503589656204
Loss at iteration 530 : 7.484631350962445e-05
Loss at iteration 540 : 0.0001991767785511911
Loss at iteration 550 : 0.0004786438075825572
Loss at iteration 560 : 0.0009666277328506112
Loss at iteration 570 : 0.00020457390928640962
Loss at iteration 580 : 0.0034910389222204685
Loss at iteration 590 : 4.845265721087344e-05
Loss at iteration 600 : 0.005095609463751316
Loss at iteration 610 : 0.00495315482839942
Loss at iteration 620 : 0.00012728257570415735
Loss at iteration 630 : 0.0022863810881972313
Loss at iteration 640 : 0.0008098020916804671
Loss at iteration 650 : 0.0001476610341342166
Loss at iteration 660 : 8.177290146704763e-05
Loss at iteration 670 : 0.004011211916804314
Loss at iteration 680 : 0.00010512662265682593
Loss at iteration 690 : 0.001104211201891303
Loss at iteration 700 : 0.001985211856663227
Loss at iteration 710 : 0.0006336471415124834
Loss at iteration 720 : 0.00010042155190603808
Loss at iteration 730 : 0.0005561900325119495
Loss at iteration 740 : 0.0005331665743142366
Loss at iteration 750 : 0.0004708062333520502
Loss at iteration 760 : 0.0001378233137074858
Loss at iteration 770 : 0.0003844287130050361
Loss at iteration 780 : 0.0010469916742295027
Loss at iteration 790 : 0.0007486356771551073
Loss at iteration 800 : 0.00020244441111572087
Loss at iteration 810 : 0.00027772653265856206
Loss at iteration 820 : 0.007150897290557623
Loss at iteration 830 : 0.0016079879133030772
Loss at iteration 840 : 8.147500921040773e-05
Loss at iteration 850 : 0.003043630626052618
Loss at iteration 860 : 0.0001000505726551637
Loss at iteration 870 : 0.00026993732899427414
Loss at iteration 880 : 0.0002797311171889305
Loss at iteration 890 : 0.00012535933637991548
Loss at iteration 900 : 6.55321273370646e-05
Loss at iteration 910 : 0.003105830168351531
Loss at iteration 920 : 0.001976006431505084
Loss at iteration 930 : 0.00024990839301608503
Loss at iteration 940 : 8.26551258796826e-05
Loss at iteration 950 : 0.0010765762999653816
Loss at iteration 960 : 0.0002798073401208967
Loss at iteration 970 : 0.00011622844613157213
Loss at iteration 980 : 8.301383059006184e-05
Loss at iteration 990 : 0.0014248209772631526
Loss at iteration 1000 : 0.0005195144331082702
Loss at iteration 1010 : 0.00043204438406974077
Loss at iteration 1020 : 0.001761960913427174
Loss at iteration 1030 : 0.0002038370439549908
Loss at iteration 1040 : 0.0006315583596006036
Loss at iteration 1050 : 0.004078758880496025
Loss at iteration 1060 : 8.968164911493659e-05
Loss at iteration 1070 : 0.0011309654219076037
Loss at iteration 1080 : 0.0006519239977933466
Loss at iteration 1090 : 0.0002504108415450901
Loss at iteration 1100 : 0.0002604115870781243
Loss at iteration 1110 : 0.00015103741316124797
Loss at iteration 1120 : 0.00016514360322616994
Loss at iteration 1130 : 0.0001426989329047501
Loss at iteration 1140 : 0.00030699861235916615
Loss at iteration 1150 : 0.0008669458911754191
Loss at iteration 1160 : 0.00034832011442631483
Loss at iteration 1170 : 0.0014635056722909212
Loss at iteration 1180 : 0.000288319744868204
Loss at iteration 1190 : 0.000215261839912273
Loss at iteration 1200 : 0.00030020391568541527
Loss at iteration 1210 : 4.968708162778057e-05
Loss at iteration 1220 : 0.00018045953765977174
Loss at iteration 1230 : 7.337332499446347e-05
Loss at iteration 1240 : 0.0019859138410538435
Loss at iteration 1250 : 0.00042272318387404084
Loss at iteration 1260 : 0.0002639848680701107
Loss at iteration 1270 : 0.0002584284811746329
Loss at iteration 1280 : 0.00014789175475016236
Loss at iteration 1290 : 0.0030216900631785393
Loss at iteration 1300 : 0.0001816552394302562
Loss at iteration 1310 : 0.0033853710629045963
Loss at iteration 1320 : 0.00011473022459540516
Loss at iteration 1330 : 0.0017075493233278394
Loss at iteration 1340 : 0.001330165658146143
Loss at iteration 1350 : 0.003209567628800869
Loss at iteration 1360 : 0.0008488526218570769
Loss at iteration 1370 : 0.0007951180450618267
Loss at iteration 1380 : 0.00037955876905471087
Loss at iteration 1390 : 0.001666038646362722
Loss at iteration 1400 : 0.00011515946971485391
Loss at iteration 1410 : 0.00016024378419388086
Loss at iteration 1420 : 0.000956692558247596
Loss at iteration 1430 : 0.00018102434114553034
Loss at iteration 1440 : 0.00023579035769216716
Loss at iteration 1450 : 0.00019982765661552548
Loss at iteration 1460 : 0.0007953084423206747
Loss at iteration 1470 : 9.308075823355466e-05
Loss at iteration 1480 : 0.0003647753910627216
Loss at iteration 1490 : 0.00016141682863235474
Loss at iteration 1500 : 0.00014887687575537711
Loss at iteration 1510 : 0.00027674547163769603
Loss at iteration 1520 : 0.00020209050853736699
Loss at iteration 1530 : 0.0022930214181542397
Loss at iteration 1540 : 0.00037391134537756443
Loss at iteration 1550 : 4.744855687022209e-05
Loss at iteration 1560 : 0.00023117446107789874
Loss at iteration 1570 : 8.985855674836785e-05
Loss at iteration 1580 : 0.0004240329726599157
Loss at iteration 1590 : 0.0019468606915324926
Loss at iteration 1600 : 0.0002089517074637115
Loss at iteration 1610 : 0.002030892763286829
Loss at iteration 1620 : 0.00010291719809174538
Loss at iteration 1630 : 2.7202275305171497e-05
Loss at iteration 1640 : 0.0009739643428474665
Loss at iteration 1650 : 0.001207956811413169
Loss at iteration 1660 : 0.0022475901059806347
Loss at iteration 1670 : 5.136723484611139e-05
Loss at iteration 1680 : 0.0002497940440662205
Loss at iteration 1690 : 0.0005027942825108767
Loss at iteration 1700 : 8.73790995683521e-05
Loss at iteration 1710 : 0.0007202145061455667
Loss at iteration 1720 : 0.0019489452242851257
Loss at iteration 1730 : 0.0005981795256957412
Loss at iteration 1740 : 6.943281914573163e-05
Loss at iteration 1750 : 0.0033517528790980577
The SSIM Value is: 0.9884154401424172
The PSNR Value is: 46.532685172715375
the epoch is: 187
Loss at iteration 10 : 0.005921666510403156
Loss at iteration 20 : 8.06231691967696e-05
Loss at iteration 30 : 0.0003496585413813591
Loss at iteration 40 : 0.007430288940668106
Loss at iteration 50 : 0.0008523346041329205
Loss at iteration 60 : 0.0001831858535297215
Loss at iteration 70 : 0.0006118695018813014
Loss at iteration 80 : 0.0002493505598977208
Loss at iteration 90 : 0.003213928546756506
Loss at iteration 100 : 0.0036862134002149105
Loss at iteration 110 : 0.0016593786422163248
Loss at iteration 120 : 0.003329616039991379
Loss at iteration 130 : 0.004860211163759232
Loss at iteration 140 : 0.0027025912422686815
Loss at iteration 150 : 0.0011409467551857233
Loss at iteration 160 : 0.004077821038663387
Loss at iteration 170 : 0.00016103967209346592
Loss at iteration 180 : 0.0006249163998290896
Loss at iteration 190 : 0.0020313281565904617
Loss at iteration 200 : 7.425565854646266e-05
Loss at iteration 210 : 8.856799831846729e-05
Loss at iteration 220 : 0.00016040880291257054
Loss at iteration 230 : 0.00033767111017368734
Loss at iteration 240 : 5.139009590493515e-05
Loss at iteration 250 : 3.596211536205374e-05
Loss at iteration 260 : 0.00012466340558603406
Loss at iteration 270 : 0.002718166681006551
Loss at iteration 280 : 0.00016060589405242354
Loss at iteration 290 : 0.00037204890395514667
Loss at iteration 300 : 0.0007485182723030448
Loss at iteration 310 : 0.00011360142525518313
Loss at iteration 320 : 0.0003022715973202139
Loss at iteration 330 : 0.0004595617647282779
Loss at iteration 340 : 0.0008381722145713866
Loss at iteration 350 : 0.0004165627178736031
Loss at iteration 360 : 0.0013489190023392439
Loss at iteration 370 : 8.955246448749676e-05
Loss at iteration 380 : 0.0002582632005214691
Loss at iteration 390 : 0.00014772826398257166
Loss at iteration 400 : 7.66672455938533e-05
Loss at iteration 410 : 0.00043412475497461855
Loss at iteration 420 : 0.0002512322389520705
Loss at iteration 430 : 0.0003058953443542123
Loss at iteration 440 : 0.00016426609363406897
Loss at iteration 450 : 0.00023496319772675633
Loss at iteration 460 : 0.0002079436817439273
Loss at iteration 470 : 0.00020057542133145034
Loss at iteration 480 : 0.0002760007046163082
Loss at iteration 490 : 0.0023148092441260815
Loss at iteration 500 : 7.47750309528783e-05
Loss at iteration 510 : 0.00020434145699255168
Loss at iteration 520 : 0.00010639601532602683
Loss at iteration 530 : 0.00022412104590330273
Loss at iteration 540 : 0.00027366107678972185
Loss at iteration 550 : 0.00010964850662276149
Loss at iteration 560 : 9.51412512222305e-05
Loss at iteration 570 : 0.0004161821270827204
Loss at iteration 580 : 4.105610787519254e-05
Loss at iteration 590 : 0.0001664110750425607
Loss at iteration 600 : 0.0002709019463509321
Loss at iteration 610 : 0.0004999525262974203
Loss at iteration 620 : 0.0011050363536924124
Loss at iteration 630 : 0.00047047980478964746
Loss at iteration 640 : 0.0007980747614055872
Loss at iteration 650 : 0.0001884470839286223
Loss at iteration 660 : 0.00025060345069505274
Loss at iteration 670 : 0.0001132012257585302
Loss at iteration 680 : 0.00046965095680207014
Loss at iteration 690 : 0.0002607652568258345
Loss at iteration 700 : 0.001183259766548872
Loss at iteration 710 : 5.413654071162455e-05
Loss at iteration 720 : 0.00028779765125364065
Loss at iteration 730 : 0.0009126000804826617
Loss at iteration 740 : 0.000562532339245081
Loss at iteration 750 : 0.0017034774646162987
Loss at iteration 760 : 0.00040100738988257945
Loss at iteration 770 : 0.0016215154901146889
Loss at iteration 780 : 0.0004460455966182053
Loss at iteration 790 : 0.00031916124862618744
Loss at iteration 800 : 0.0022384198382496834
Loss at iteration 810 : 0.0026734971906989813
Loss at iteration 820 : 0.00042748948908410966
Loss at iteration 830 : 0.00013798935106024146
Loss at iteration 840 : 0.0039793322794139385
Loss at iteration 850 : 0.0004673933726735413
Loss at iteration 860 : 0.00039881563861854374
Loss at iteration 870 : 0.0001664871524553746
Loss at iteration 880 : 0.002139454009011388
Loss at iteration 890 : 0.00014647025091107935
Loss at iteration 900 : 0.0005363054806366563
Loss at iteration 910 : 0.0026967297308146954
Loss at iteration 920 : 0.0009177234605886042
Loss at iteration 930 : 0.0002836353378370404
Loss at iteration 940 : 0.0007316371775232255
Loss at iteration 950 : 0.00035291456151753664
Loss at iteration 960 : 0.0013112816959619522
Loss at iteration 970 : 0.00042603586916811764
Loss at iteration 980 : 0.0006836988613940775
Loss at iteration 990 : 9.917128045344725e-05
Loss at iteration 1000 : 7.589649612782523e-05
Loss at iteration 1010 : 0.00030444515869021416
Loss at iteration 1020 : 0.0032095296774059534
Loss at iteration 1030 : 4.146597711951472e-05
Loss at iteration 1040 : 0.002778923837468028
Loss at iteration 1050 : 0.0007630973705090582
Loss at iteration 1060 : 0.0005359470378607512
Loss at iteration 1070 : 0.0004858935426454991
Loss at iteration 1080 : 6.383017898770049e-05
Loss at iteration 1090 : 0.000332363648340106
Loss at iteration 1100 : 0.00025853817351162434
Loss at iteration 1110 : 0.0003233115712646395
Loss at iteration 1120 : 0.00010324794129701331
Loss at iteration 1130 : 0.00045963175944052637
Loss at iteration 1140 : 0.00010390706302132457
Loss at iteration 1150 : 0.0005195798585191369
Loss at iteration 1160 : 0.0010416556615382433
Loss at iteration 1170 : 0.0008695589494891465
Loss at iteration 1180 : 0.0003711090248543769
Loss at iteration 1190 : 0.00040990274283103645
Loss at iteration 1200 : 7.670037302887067e-05
Loss at iteration 1210 : 0.001632703235372901
Loss at iteration 1220 : 0.00045765077811665833
Loss at iteration 1230 : 0.0013920904602855444
Loss at iteration 1240 : 0.00024247007968369871
Loss at iteration 1250 : 0.00022226710279937834
Loss at iteration 1260 : 0.0018169113900512457
Loss at iteration 1270 : 0.0004395615542307496
Loss at iteration 1280 : 0.0008423595572821796
Loss at iteration 1290 : 5.339080962585285e-05
Loss at iteration 1300 : 0.00020403781672939658
Loss at iteration 1310 : 0.00026278989389538765
Loss at iteration 1320 : 8.935093501349911e-05
Loss at iteration 1330 : 0.0022355634719133377
Loss at iteration 1340 : 0.0024994593113660812
Loss at iteration 1350 : 8.620844164397568e-05
Loss at iteration 1360 : 0.0006490926607511938
Loss at iteration 1370 : 0.00023102050181478262
Loss at iteration 1380 : 0.0018466539913788438
Loss at iteration 1390 : 0.00010772344830911607
Loss at iteration 1400 : 0.0036034639924764633
Loss at iteration 1410 : 3.381983333383687e-05
Loss at iteration 1420 : 0.001717883162200451
Loss at iteration 1430 : 0.0020216847769916058
Loss at iteration 1440 : 0.0001438692124793306
Loss at iteration 1450 : 0.002142711076885462
Loss at iteration 1460 : 0.0030661271885037422
Loss at iteration 1470 : 0.0007844148203730583
Loss at iteration 1480 : 0.0002856913488358259
Loss at iteration 1490 : 0.00020338557078503072
Loss at iteration 1500 : 0.001477506011724472
Loss at iteration 1510 : 0.00019118207274004817
Loss at iteration 1520 : 0.00046390225179493427
Loss at iteration 1530 : 0.003140043467283249
Loss at iteration 1540 : 0.00020331196719780564
Loss at iteration 1550 : 0.0023390869610011578
Loss at iteration 1560 : 0.0020292920526117086
Loss at iteration 1570 : 0.0045082224532961845
Loss at iteration 1580 : 0.0005791311850771308
Loss at iteration 1590 : 0.00011204426118638366
Loss at iteration 1600 : 0.00045917945681139827
Loss at iteration 1610 : 0.0016070797573775053
Loss at iteration 1620 : 0.0005576138501055539
Loss at iteration 1630 : 0.0006702253594994545
Loss at iteration 1640 : 0.00012494181282818317
Loss at iteration 1650 : 0.0017306990921497345
Loss at iteration 1660 : 0.0001748923968989402
Loss at iteration 1670 : 0.001532255788333714
Loss at iteration 1680 : 0.00012851893552578986
Loss at iteration 1690 : 0.00037946412339806557
Loss at iteration 1700 : 0.0003466118942014873
Loss at iteration 1710 : 0.002712081652134657
Loss at iteration 1720 : 0.00046437332639470696
Loss at iteration 1730 : 0.0002673528506420553
Loss at iteration 1740 : 0.0017236876301467419
Loss at iteration 1750 : 0.00036492705112323165
The SSIM Value is: 0.9877435424516905
The PSNR Value is: 46.54415287950491
the epoch is: 188
Loss at iteration 10 : 0.003720593871548772
Loss at iteration 20 : 0.00034548447001725435
Loss at iteration 30 : 0.002860603854060173
Loss at iteration 40 : 0.00019862150656990707
Loss at iteration 50 : 0.000260813016211614
Loss at iteration 60 : 0.0035788253881037235
Loss at iteration 70 : 0.00026908633299171925
Loss at iteration 80 : 4.274211823940277e-05
Loss at iteration 90 : 0.00392790837213397
Loss at iteration 100 : 0.00021677561744581908
Loss at iteration 110 : 0.0029296856373548508
Loss at iteration 120 : 0.0032972272019833326
Loss at iteration 130 : 0.0006678738864138722
Loss at iteration 140 : 0.0012359415413811803
Loss at iteration 150 : 0.00026883959071710706
Loss at iteration 160 : 0.0006932095857337117
Loss at iteration 170 : 0.003252612892538309
Loss at iteration 180 : 0.0002871062606573105
Loss at iteration 190 : 9.818252874538302e-05
Loss at iteration 200 : 0.0007673671934753656
Loss at iteration 210 : 0.0003817667602561414
Loss at iteration 220 : 0.0004063234955538064
Loss at iteration 230 : 0.006696705706417561
Loss at iteration 240 : 0.00015742910909466445
Loss at iteration 250 : 0.006564447656273842
Loss at iteration 260 : 0.0026038973592221737
Loss at iteration 270 : 0.0026566090527921915
Loss at iteration 280 : 0.00012437219265848398
Loss at iteration 290 : 0.0006038057617843151
Loss at iteration 300 : 0.00011618471035035327
Loss at iteration 310 : 0.0003833056543953717
Loss at iteration 320 : 0.00696827657520771
Loss at iteration 330 : 0.0002613296383060515
Loss at iteration 340 : 0.0002083237050101161
Loss at iteration 350 : 0.00024471545475535095
Loss at iteration 360 : 0.001747778384014964
Loss at iteration 370 : 0.0002536670654080808
Loss at iteration 380 : 0.00047869861009530723
Loss at iteration 390 : 0.00017286518414039165
Loss at iteration 400 : 0.0006848316988907754
Loss at iteration 410 : 0.000755131128244102
Loss at iteration 420 : 5.57277089683339e-05
Loss at iteration 430 : 8.932449418352917e-05
Loss at iteration 440 : 8.791781147010624e-05
Loss at iteration 450 : 0.0015290987212210894
Loss at iteration 460 : 9.88450410659425e-05
Loss at iteration 470 : 0.001814093324355781
Loss at iteration 480 : 0.00011290379916317761
Loss at iteration 490 : 0.0018714218167588115
Loss at iteration 500 : 0.004784564021974802
Loss at iteration 510 : 0.0012035943800583482
Loss at iteration 520 : 0.00043360417475923896
Loss at iteration 530 : 0.00019706913735717535
Loss at iteration 540 : 0.0006378613179549575
Loss at iteration 550 : 0.00034158615744672716
Loss at iteration 560 : 0.0021983408369123936
Loss at iteration 570 : 0.0003454499819781631
Loss at iteration 580 : 0.0004662013379856944
Loss at iteration 590 : 0.00045552541268989444
Loss at iteration 600 : 0.003185092005878687
Loss at iteration 610 : 0.0004127004649490118
Loss at iteration 620 : 0.00010829238453879952
Loss at iteration 630 : 0.0035598832182586193
Loss at iteration 640 : 0.0006460546283051372
Loss at iteration 650 : 0.002202319446951151
Loss at iteration 660 : 0.00037375048850663006
Loss at iteration 670 : 5.59705076739192e-05
Loss at iteration 680 : 7.143866241676733e-05
Loss at iteration 690 : 0.00016266685270238668
Loss at iteration 700 : 0.0022827782668173313
Loss at iteration 710 : 0.00011673241533571854
Loss at iteration 720 : 0.0004778014263138175
Loss at iteration 730 : 0.00035413019941188395
Loss at iteration 740 : 0.0019233101047575474
Loss at iteration 750 : 0.0004489659913815558
Loss at iteration 760 : 0.0026336212176829576
Loss at iteration 770 : 0.0007260451675392687
Loss at iteration 780 : 0.00021969502267893404
Loss at iteration 790 : 0.0006930447416380048
Loss at iteration 800 : 0.00023034527839627117
Loss at iteration 810 : 0.004499880131334066
Loss at iteration 820 : 0.00012502059689722955
Loss at iteration 830 : 0.00044839875772595406
Loss at iteration 840 : 0.0005857963697053492
Loss at iteration 850 : 0.00019051134586334229
Loss at iteration 860 : 0.0001462369255023077
Loss at iteration 870 : 0.0008781505166552961
Loss at iteration 880 : 0.00021516661217901856
Loss at iteration 890 : 0.0001443329092580825
Loss at iteration 900 : 6.715593917760998e-05
Loss at iteration 910 : 0.004518428817391396
Loss at iteration 920 : 0.00013476786261890084
Loss at iteration 930 : 0.00016928627155721188
Loss at iteration 940 : 0.00017630938964430243
Loss at iteration 950 : 0.0016019754111766815
Loss at iteration 960 : 0.00031318774563260376
Loss at iteration 970 : 0.0002358127967454493
Loss at iteration 980 : 0.0002656966680660844
Loss at iteration 990 : 0.0002905738656409085
Loss at iteration 1000 : 0.0003362522693350911
Loss at iteration 1010 : 0.000692869012709707
Loss at iteration 1020 : 0.0007473013829439878
Loss at iteration 1030 : 0.0006807544850744307
Loss at iteration 1040 : 0.00012355143553577363
Loss at iteration 1050 : 5.151233199285343e-05
Loss at iteration 1060 : 0.00031663625850342214
Loss at iteration 1070 : 0.00012994759890716523
Loss at iteration 1080 : 0.00014538236428052187
Loss at iteration 1090 : 0.0006579466862604022
Loss at iteration 1100 : 3.9109610952436924e-05
Loss at iteration 1110 : 0.0022646139841526747
Loss at iteration 1120 : 0.0014849472790956497
Loss at iteration 1130 : 6.611474964302033e-05
Loss at iteration 1140 : 0.00013315968681126833
Loss at iteration 1150 : 0.0002578841813374311
Loss at iteration 1160 : 0.002176211681216955
Loss at iteration 1170 : 0.00025518902111798525
Loss at iteration 1180 : 0.0011190535733476281
Loss at iteration 1190 : 0.0003284864651504904
Loss at iteration 1200 : 6.025414040777832e-05
Loss at iteration 1210 : 9.807368041947484e-05
Loss at iteration 1220 : 5.7132863730657846e-05
Loss at iteration 1230 : 8.896602230379358e-05
Loss at iteration 1240 : 0.0027462232392281294
Loss at iteration 1250 : 0.00026372261345386505
Loss at iteration 1260 : 0.0007871309062466025
Loss at iteration 1270 : 0.0003035730915144086
Loss at iteration 1280 : 0.0003040385199710727
Loss at iteration 1290 : 0.0026362226344645023
Loss at iteration 1300 : 0.00015761013492010534
Loss at iteration 1310 : 8.908229938242584e-05
Loss at iteration 1320 : 0.004214238375425339
Loss at iteration 1330 : 0.00017945189028978348
Loss at iteration 1340 : 0.00041128494194708765
Loss at iteration 1350 : 0.0001923984964378178
Loss at iteration 1360 : 0.00011714366701198742
Loss at iteration 1370 : 0.0001509031862951815
Loss at iteration 1380 : 0.000208190584089607
Loss at iteration 1390 : 0.00011954057845287025
Loss at iteration 1400 : 4.265444295015186e-05
Loss at iteration 1410 : 0.00016610378224868327
Loss at iteration 1420 : 0.00010435684816911817
Loss at iteration 1430 : 0.0002104977611452341
Loss at iteration 1440 : 0.00018459012790117413
Loss at iteration 1450 : 0.00047149567399173975
Loss at iteration 1460 : 0.00012571626575663686
Loss at iteration 1470 : 0.00014225578343030065
Loss at iteration 1480 : 0.0025183898396790028
Loss at iteration 1490 : 0.0002818850625772029
Loss at iteration 1500 : 0.00023581412096973509
Loss at iteration 1510 : 0.005342765711247921
Loss at iteration 1520 : 0.0026135595981031656
Loss at iteration 1530 : 0.0002949222398456186
Loss at iteration 1540 : 0.00021772951004095376
Loss at iteration 1550 : 0.0021034919191151857
Loss at iteration 1560 : 0.0016643614508211613
Loss at iteration 1570 : 0.00019724445883184671
Loss at iteration 1580 : 0.0030392901971936226
Loss at iteration 1590 : 0.000512154190801084
Loss at iteration 1600 : 0.00019011899712495506
Loss at iteration 1610 : 0.0006575486622750759
Loss at iteration 1620 : 4.97867695230525e-05
Loss at iteration 1630 : 0.0029198918491601944
Loss at iteration 1640 : 9.485585178481415e-05
Loss at iteration 1650 : 0.00014405176625587046
Loss at iteration 1660 : 0.00011451230238890275
Loss at iteration 1670 : 0.0002243207854917273
Loss at iteration 1680 : 0.00030270725255832076
Loss at iteration 1690 : 0.0006397442193701863
Loss at iteration 1700 : 0.0015320783713832498
Loss at iteration 1710 : 5.406734999269247e-05
Loss at iteration 1720 : 0.0005732913268730044
Loss at iteration 1730 : 0.0005150495562702417
Loss at iteration 1740 : 0.00029061269015073776
Loss at iteration 1750 : 0.0006569562829099596
The SSIM Value is: 0.9883635821321463
The PSNR Value is: 46.29443166539532
the epoch is: 189
Loss at iteration 10 : 0.0011216179700568318
Loss at iteration 20 : 0.000113830974441953
Loss at iteration 30 : 0.0003573954163584858
Loss at iteration 40 : 0.0031135552562773228
Loss at iteration 50 : 0.00011241225729463622
Loss at iteration 60 : 0.0002998726849909872
Loss at iteration 70 : 0.00015136013098526746
Loss at iteration 80 : 0.00023259961744770408
Loss at iteration 90 : 0.0005957689718343318
Loss at iteration 100 : 0.00020033956388942897
Loss at iteration 110 : 0.00024067939375527203
Loss at iteration 120 : 0.0001485602551838383
Loss at iteration 130 : 9.092477557715029e-05
Loss at iteration 140 : 0.00015431010979227722
Loss at iteration 150 : 0.004088454879820347
Loss at iteration 160 : 0.0006584125803783536
Loss at iteration 170 : 0.00014451750030275434
Loss at iteration 180 : 5.546783722820692e-05
Loss at iteration 190 : 0.0001273925881832838
Loss at iteration 200 : 0.0024296881165355444
Loss at iteration 210 : 0.0009702420211397111
Loss at iteration 220 : 7.889943663030863e-05
Loss at iteration 230 : 0.0014224359765648842
Loss at iteration 240 : 0.006026886403560638
Loss at iteration 250 : 0.0002382999809924513
Loss at iteration 260 : 0.0017307798843830824
Loss at iteration 270 : 0.00041562458500266075
Loss at iteration 280 : 0.0009296654025092721
Loss at iteration 290 : 0.001672289683483541
Loss at iteration 300 : 0.0005423558177426457
Loss at iteration 310 : 9.388743637828156e-05
Loss at iteration 320 : 0.000714949332177639
Loss at iteration 330 : 0.0004538825014606118
Loss at iteration 340 : 0.0024659426417201757
Loss at iteration 350 : 0.00018787177396006882
Loss at iteration 360 : 0.003856639377772808
Loss at iteration 370 : 0.00110594742000103
Loss at iteration 380 : 0.0003958775196224451
Loss at iteration 390 : 9.091683750739321e-05
Loss at iteration 400 : 0.0011717319721356034
Loss at iteration 410 : 8.565786993131042e-05
Loss at iteration 420 : 0.00013954074529465288
Loss at iteration 430 : 0.00749673368409276
Loss at iteration 440 : 0.0008870508172549307
Loss at iteration 450 : 6.200472125783563e-05
Loss at iteration 460 : 0.0002056145458482206
Loss at iteration 470 : 0.0028845062479376793
Loss at iteration 480 : 0.0006091592367738485
Loss at iteration 490 : 9.718404180603102e-05
Loss at iteration 500 : 5.3857569582760334e-05
Loss at iteration 510 : 6.323748675640672e-05
Loss at iteration 520 : 0.00024806003784760833
Loss at iteration 530 : 0.0008552702493034303
Loss at iteration 540 : 9.923303150571883e-05
Loss at iteration 550 : 7.387531513813883e-05
Loss at iteration 560 : 0.003940812312066555
Loss at iteration 570 : 9.227124246535823e-05
Loss at iteration 580 : 0.0002885743451770395
Loss at iteration 590 : 0.0002744830562733114
Loss at iteration 600 : 0.00048172561218962073
Loss at iteration 610 : 0.00030940017313696444
Loss at iteration 620 : 0.0026213908568024635
Loss at iteration 630 : 0.0015320179518312216
Loss at iteration 640 : 0.00014711036055814475
Loss at iteration 650 : 0.0001584819401614368
Loss at iteration 660 : 0.0011485391296446323
Loss at iteration 670 : 0.00018148588424082845
Loss at iteration 680 : 8.577146945754066e-05
Loss at iteration 690 : 0.00013475914602167904
Loss at iteration 700 : 0.0028216128703206778
Loss at iteration 710 : 0.000137460432597436
Loss at iteration 720 : 0.00010742688027676195
Loss at iteration 730 : 8.87169735506177e-05
Loss at iteration 740 : 0.00016528068226762116
Loss at iteration 750 : 0.003868635045364499
Loss at iteration 760 : 0.0026088294107466936
Loss at iteration 770 : 0.0026235883124172688
Loss at iteration 780 : 0.0018673357553780079
Loss at iteration 790 : 0.00012239204079378396
Loss at iteration 800 : 4.185382567811757e-05
Loss at iteration 810 : 0.0030939485877752304
Loss at iteration 820 : 0.0003701182431541383
Loss at iteration 830 : 0.00518031045794487
Loss at iteration 840 : 0.0019701016135513783
Loss at iteration 850 : 0.0002471295010764152
Loss at iteration 860 : 6.011317600496113e-05
Loss at iteration 870 : 0.0004001423658337444
Loss at iteration 880 : 0.0007500917417928576
Loss at iteration 890 : 0.0026282386388629675
Loss at iteration 900 : 0.0010000728070735931
Loss at iteration 910 : 0.0011365556856617332
Loss at iteration 920 : 0.0002584826434031129
Loss at iteration 930 : 0.003753497265279293
Loss at iteration 940 : 4.149668166064657e-05
Loss at iteration 950 : 0.0019481393974274397
Loss at iteration 960 : 0.0014886939898133278
Loss at iteration 970 : 0.0006676095072180033
Loss at iteration 980 : 0.002345080254599452
Loss at iteration 990 : 9.978736488847062e-05
Loss at iteration 1000 : 0.00045901830890215933
Loss at iteration 1010 : 0.0022332745138555765
Loss at iteration 1020 : 0.004326843656599522
Loss at iteration 1030 : 0.00015970105596352369
Loss at iteration 1040 : 0.000265576847596094
Loss at iteration 1050 : 0.0006037380662746727
Loss at iteration 1060 : 0.001234741765074432
Loss at iteration 1070 : 0.0019402641337364912
Loss at iteration 1080 : 0.0007848286186344922
Loss at iteration 1090 : 0.0006434376118704677
Loss at iteration 1100 : 0.00015486529446206987
Loss at iteration 1110 : 0.0015249383868649602
Loss at iteration 1120 : 0.00044922996312379837
Loss at iteration 1130 : 0.00023890062584541738
Loss at iteration 1140 : 0.0004730585787910968
Loss at iteration 1150 : 8.78050850587897e-05
Loss at iteration 1160 : 0.0008835068438202143
Loss at iteration 1170 : 0.0014304157812148333
Loss at iteration 1180 : 0.0005441734101623297
Loss at iteration 1190 : 0.00021705348626710474
Loss at iteration 1200 : 0.0002490360348019749
Loss at iteration 1210 : 7.498326158383861e-05
Loss at iteration 1220 : 0.002641004044562578
Loss at iteration 1230 : 4.9410889914724976e-05
Loss at iteration 1240 : 0.00035367158125154674
Loss at iteration 1250 : 0.0035630303900688887
Loss at iteration 1260 : 0.0003066259087063372
Loss at iteration 1270 : 0.0008878849330358207
Loss at iteration 1280 : 0.0009768164018169045
Loss at iteration 1290 : 0.0005875404458492994
Loss at iteration 1300 : 7.088891288731247e-05
Loss at iteration 1310 : 0.0004501118091866374
Loss at iteration 1320 : 0.002392215421423316
Loss at iteration 1330 : 0.0001293491804972291
Loss at iteration 1340 : 0.00035934330662712455
Loss at iteration 1350 : 0.0006045325426384807
Loss at iteration 1360 : 0.0021894476376473904
Loss at iteration 1370 : 0.0017044448759406805
Loss at iteration 1380 : 0.0015554219717159867
Loss at iteration 1390 : 0.001044982811436057
Loss at iteration 1400 : 9.008400957100093e-05
Loss at iteration 1410 : 0.00014433838077820837
Loss at iteration 1420 : 0.0004976028576493263
Loss at iteration 1430 : 0.0003843723388854414
Loss at iteration 1440 : 4.4990607420913875e-05
Loss at iteration 1450 : 0.0005245509091764688
Loss at iteration 1460 : 0.00010148446745006368
Loss at iteration 1470 : 0.00021175594883970916
Loss at iteration 1480 : 0.0020220051519572735
Loss at iteration 1490 : 0.0007340145530179143
Loss at iteration 1500 : 0.00020299416792113334
Loss at iteration 1510 : 0.000958758988417685
Loss at iteration 1520 : 0.00421187374740839
Loss at iteration 1530 : 0.0001949704746948555
Loss at iteration 1540 : 0.0003589628613553941
Loss at iteration 1550 : 0.00029843219090253115
Loss at iteration 1560 : 0.000615739612840116
Loss at iteration 1570 : 0.001989449840039015
Loss at iteration 1580 : 0.00038831448182463646
Loss at iteration 1590 : 0.00033655198058113456
Loss at iteration 1600 : 0.000667305663228035
Loss at iteration 1610 : 9.396873065270483e-05
Loss at iteration 1620 : 0.00012770926696248353
Loss at iteration 1630 : 0.0025014556013047695
Loss at iteration 1640 : 0.004020838066935539
Loss at iteration 1650 : 0.002373059978708625
Loss at iteration 1660 : 0.00019470225379336625
Loss at iteration 1670 : 0.00024017761461436749
Loss at iteration 1680 : 0.003102446673437953
Loss at iteration 1690 : 0.0007315389229916036
Loss at iteration 1700 : 0.0008234578417614102
Loss at iteration 1710 : 0.0002452154294587672
Loss at iteration 1720 : 0.00014663305773865432
Loss at iteration 1730 : 0.004831006750464439
Loss at iteration 1740 : 5.0749105866998434e-05
Loss at iteration 1750 : 0.0009081345633603632
The SSIM Value is: 0.9848291902815193
The PSNR Value is: 46.635641226159315
the epoch is: 190
Loss at iteration 10 : 0.0003035449772141874
Loss at iteration 20 : 0.0011303689097985625
Loss at iteration 30 : 0.0005275635048747063
Loss at iteration 40 : 0.001212646602652967
Loss at iteration 50 : 0.0005055830115452409
Loss at iteration 60 : 0.0006850252393633127
Loss at iteration 70 : 0.00016538132331334054
Loss at iteration 80 : 0.0001829637767514214
Loss at iteration 90 : 0.000460115319583565
Loss at iteration 100 : 0.0010795376729220152
Loss at iteration 110 : 0.00012779331882484257
Loss at iteration 120 : 0.00035084644332528114
Loss at iteration 130 : 0.00012479702127166092
Loss at iteration 140 : 0.0016781578306108713
Loss at iteration 150 : 0.00010992558236466721
Loss at iteration 160 : 0.00027448899345472455
Loss at iteration 170 : 0.0004158171359449625
Loss at iteration 180 : 0.002744091209024191
Loss at iteration 190 : 0.002031202893704176
Loss at iteration 200 : 0.0013485754607245326
Loss at iteration 210 : 0.00030568314832635224
Loss at iteration 220 : 0.00019106752006337047
Loss at iteration 230 : 0.0004519862122833729
Loss at iteration 240 : 0.0026392010040581226
Loss at iteration 250 : 0.00012250531290192157
Loss at iteration 260 : 0.0002959678531624377
Loss at iteration 270 : 0.0020821953658014536
Loss at iteration 280 : 0.00010094448953168467
Loss at iteration 290 : 0.0017671450041234493
Loss at iteration 300 : 0.00019303671433590353
Loss at iteration 310 : 0.002623847918584943
Loss at iteration 320 : 0.003763376735150814
Loss at iteration 330 : 4.923633605358191e-05
Loss at iteration 340 : 0.001967123942449689
Loss at iteration 350 : 0.00528543908149004
Loss at iteration 360 : 7.070647552609444e-05
Loss at iteration 370 : 0.0011047916486859322
Loss at iteration 380 : 0.0020028965082019567
Loss at iteration 390 : 0.00026437497581355274
Loss at iteration 400 : 0.0018191857961937785
Loss at iteration 410 : 0.00014695010031573474
Loss at iteration 420 : 0.004964669235050678
Loss at iteration 430 : 0.0001542339741718024
Loss at iteration 440 : 9.414247324457392e-05
Loss at iteration 450 : 0.001991125289350748
Loss at iteration 460 : 0.0035775688011199236
Loss at iteration 470 : 0.003184838918969035
Loss at iteration 480 : 0.00017072397167794406
Loss at iteration 490 : 0.0022379078436642885
Loss at iteration 500 : 0.00023502175463363528
Loss at iteration 510 : 0.00237087020650506
Loss at iteration 520 : 0.0021056155674159527
Loss at iteration 530 : 0.0002912716008722782
Loss at iteration 540 : 0.00019255734514445066
Loss at iteration 550 : 0.00011767071555368602
Loss at iteration 560 : 6.07372639933601e-05
Loss at iteration 570 : 0.00022033159621059895
Loss at iteration 580 : 9.157630847766995e-05
Loss at iteration 590 : 0.0003236154152546078
Loss at iteration 600 : 0.00034420020529069006
Loss at iteration 610 : 0.0002475533401593566
Loss at iteration 620 : 0.002081474522128701
Loss at iteration 630 : 0.00026556526427157223
Loss at iteration 640 : 0.000514865037985146
Loss at iteration 650 : 0.00019938484183512628
Loss at iteration 660 : 0.0002106777101289481
Loss at iteration 670 : 0.0013232348719611764
Loss at iteration 680 : 0.00014150729111861438
Loss at iteration 690 : 0.0027202353812754154
Loss at iteration 700 : 0.0004610529576893896
Loss at iteration 710 : 0.0002499923575669527
Loss at iteration 720 : 0.0012450359063223004
Loss at iteration 730 : 0.00010760366421891376
Loss at iteration 740 : 0.0003832189831882715
Loss at iteration 750 : 0.00549109373241663
Loss at iteration 760 : 0.0017891393508762121
Loss at iteration 770 : 0.00032061932142823935
Loss at iteration 780 : 0.0003035903791896999
Loss at iteration 790 : 0.00028934303554706275
Loss at iteration 800 : 0.00011334606824675575
Loss at iteration 810 : 7.673022628296167e-05
Loss at iteration 820 : 0.00392115069553256
Loss at iteration 830 : 0.0005394840845838189
Loss at iteration 840 : 0.00013071921421214938
Loss at iteration 850 : 0.00014173802628647536
Loss at iteration 860 : 0.0003026619669981301
Loss at iteration 870 : 0.001947788754478097
Loss at iteration 880 : 0.0008464942802675068
Loss at iteration 890 : 0.00013430412218440324
Loss at iteration 900 : 0.0016703498549759388
Loss at iteration 910 : 0.00029849642305634916
Loss at iteration 920 : 0.0006396218668669462
Loss at iteration 930 : 0.00019362465536687523
Loss at iteration 940 : 0.0004274571256246418
Loss at iteration 950 : 0.0004978521028533578
Loss at iteration 960 : 0.0007904528174549341
Loss at iteration 970 : 0.0031153210438787937
Loss at iteration 980 : 0.0036853605415672064
Loss at iteration 990 : 0.00018051642109639943
Loss at iteration 1000 : 0.0006521031027659774
Loss at iteration 1010 : 4.9649286665953696e-05
Loss at iteration 1020 : 0.00028934661531820893
Loss at iteration 1030 : 0.00020437540661077946
Loss at iteration 1040 : 6.813471554778516e-05
Loss at iteration 1050 : 0.0012816449161618948
Loss at iteration 1060 : 0.00029271128005348146
Loss at iteration 1070 : 0.000985371763817966
Loss at iteration 1080 : 0.00011693008127622306
Loss at iteration 1090 : 0.00019632453040685505
Loss at iteration 1100 : 0.00015393912326544523
Loss at iteration 1110 : 0.0013677296228706837
Loss at iteration 1120 : 0.0002581232984084636
Loss at iteration 1130 : 0.004362810868769884
Loss at iteration 1140 : 0.0003632442094385624
Loss at iteration 1150 : 4.9926475185202435e-05
Loss at iteration 1160 : 0.00022618882940150797
Loss at iteration 1170 : 8.298175089294091e-05
Loss at iteration 1180 : 0.002468729391694069
Loss at iteration 1190 : 0.00010051704157376662
Loss at iteration 1200 : 0.00019656548101920635
Loss at iteration 1210 : 0.00011666359205264598
Loss at iteration 1220 : 0.0028339277487248182
Loss at iteration 1230 : 0.000706644612364471
Loss at iteration 1240 : 0.0018026818288490176
Loss at iteration 1250 : 0.00029321457259356976
Loss at iteration 1260 : 0.0034852558746933937
Loss at iteration 1270 : 0.00018416876264382154
Loss at iteration 1280 : 5.389834404923022e-05
Loss at iteration 1290 : 0.0007314456161111593
Loss at iteration 1300 : 0.0001942262169905007
Loss at iteration 1310 : 0.0002945016312878579
Loss at iteration 1320 : 0.004714643117040396
Loss at iteration 1330 : 0.005867180414497852
Loss at iteration 1340 : 0.0018137333681806922
Loss at iteration 1350 : 0.0029465914703905582
Loss at iteration 1360 : 0.0003406554751563817
Loss at iteration 1370 : 5.6779997976263985e-05
Loss at iteration 1380 : 0.00038765219505876303
Loss at iteration 1390 : 0.0002118138363584876
Loss at iteration 1400 : 3.8983893318800256e-05
Loss at iteration 1410 : 0.00023339406470768154
Loss at iteration 1420 : 0.005358964670449495
Loss at iteration 1430 : 0.00093812495470047
Loss at iteration 1440 : 0.00012276889174245298
Loss at iteration 1450 : 0.000297592137940228
Loss at iteration 1460 : 0.0005462035187520087
Loss at iteration 1470 : 0.001242801663465798
Loss at iteration 1480 : 8.768121188040823e-05
Loss at iteration 1490 : 0.00040771922795102
Loss at iteration 1500 : 0.005693776998668909
Loss at iteration 1510 : 0.00017548380128573626
Loss at iteration 1520 : 0.0001186865265481174
Loss at iteration 1530 : 0.0012924849288538098
Loss at iteration 1540 : 5.07150252815336e-05
Loss at iteration 1550 : 0.000250951386988163
Loss at iteration 1560 : 0.0003648333949968219
Loss at iteration 1570 : 0.0016476927557960153
Loss at iteration 1580 : 0.0007005197694525123
Loss at iteration 1590 : 0.00293797068297863
Loss at iteration 1600 : 0.0002643697371240705
Loss at iteration 1610 : 0.0003173232253175229
Loss at iteration 1620 : 0.0006937893922440708
Loss at iteration 1630 : 0.0009399211849085987
Loss at iteration 1640 : 0.00035756590659730136
Loss at iteration 1650 : 0.00025224804994650185
Loss at iteration 1660 : 0.0028274469077587128
Loss at iteration 1670 : 0.0006528807571157813
Loss at iteration 1680 : 7.369398372247815e-05
Loss at iteration 1690 : 3.279779775766656e-05
Loss at iteration 1700 : 0.0026708515360951424
Loss at iteration 1710 : 0.00037722475826740265
Loss at iteration 1720 : 0.00010132927855011076
Loss at iteration 1730 : 0.0002810990554280579
Loss at iteration 1740 : 0.00023502230760641396
Loss at iteration 1750 : 0.0008428199216723442
The SSIM Value is: 0.9887832399244351
The PSNR Value is: 46.5020655409355
the epoch is: 191
Loss at iteration 10 : 3.788937101489864e-05
Loss at iteration 20 : 0.00024244295491371304
Loss at iteration 30 : 0.0008747709798626602
Loss at iteration 40 : 0.0002622532192617655
Loss at iteration 50 : 0.000566556234844029
Loss at iteration 60 : 0.00016055451123975217
Loss at iteration 70 : 0.005866250488907099
Loss at iteration 80 : 0.001036374713294208
Loss at iteration 90 : 0.00112345430534333
Loss at iteration 100 : 0.0007065011886879802
Loss at iteration 110 : 0.0003533210256136954
Loss at iteration 120 : 0.00022221295512281358
Loss at iteration 130 : 0.0040036765858531
Loss at iteration 140 : 0.00108993798494339
Loss at iteration 150 : 0.0001466012909077108
Loss at iteration 160 : 0.00020213439711369574
Loss at iteration 170 : 0.0011667752405628562
Loss at iteration 180 : 0.0006379433907568455
Loss at iteration 190 : 0.0003083699266426265
Loss at iteration 200 : 0.0024176216684281826
Loss at iteration 210 : 0.00016200283425860107
Loss at iteration 220 : 0.0003842020523734391
Loss at iteration 230 : 0.000493373372592032
Loss at iteration 240 : 0.001270414562895894
Loss at iteration 250 : 0.0005146805779077113
Loss at iteration 260 : 0.00033102717134170234
Loss at iteration 270 : 0.0012167843524366617
Loss at iteration 280 : 0.0002375234616920352
Loss at iteration 290 : 5.255036739981733e-05
Loss at iteration 300 : 0.0020394474267959595
Loss at iteration 310 : 6.205522367963567e-05
Loss at iteration 320 : 7.410364196402952e-05
Loss at iteration 330 : 0.00044624938163906336
Loss at iteration 340 : 7.998473301995546e-05
Loss at iteration 350 : 0.001164293265901506
Loss at iteration 360 : 0.00016508338740095496
Loss at iteration 370 : 0.00013080390635877848
Loss at iteration 380 : 0.0003000386932399124
Loss at iteration 390 : 0.002955653239041567
Loss at iteration 400 : 0.00025358665152452886
Loss at iteration 410 : 0.0001231847854796797
Loss at iteration 420 : 0.004513566382229328
Loss at iteration 430 : 0.0006097098812460899
Loss at iteration 440 : 0.00045546097680926323
Loss at iteration 450 : 0.0001324882759945467
Loss at iteration 460 : 0.00035402661887928843
Loss at iteration 470 : 0.00030289622372947633
Loss at iteration 480 : 0.0001871407584985718
Loss at iteration 490 : 0.000364459294360131
Loss at iteration 500 : 0.0008393982425332069
Loss at iteration 510 : 0.0004818699089810252
Loss at iteration 520 : 0.00374915380962193
Loss at iteration 530 : 0.0002742281649261713
Loss at iteration 540 : 0.00020733344717882574
Loss at iteration 550 : 0.0010949958814308047
Loss at iteration 560 : 0.00020937994122505188
Loss at iteration 570 : 0.00032136228401213884
Loss at iteration 580 : 0.006011042278259993
Loss at iteration 590 : 0.0014109367039054632
Loss at iteration 600 : 0.0035811439156532288
Loss at iteration 610 : 0.0010345703922212124
Loss at iteration 620 : 0.00013002337072975934
Loss at iteration 630 : 6.735261558787897e-05
Loss at iteration 640 : 0.002442625118419528
Loss at iteration 650 : 0.00038573474739678204
Loss at iteration 660 : 0.0024454998783767223
Loss at iteration 670 : 0.00015851500211283565
Loss at iteration 680 : 0.0032725806813687086
Loss at iteration 690 : 0.005989782977849245
Loss at iteration 700 : 0.000377506366930902
Loss at iteration 710 : 4.571340105030686e-05
Loss at iteration 720 : 0.0003473981923889369
Loss at iteration 730 : 8.716043521417305e-05
Loss at iteration 740 : 5.567756306845695e-05
Loss at iteration 750 : 0.001539657125249505
Loss at iteration 760 : 6.038415085640736e-05
Loss at iteration 770 : 0.00014746497618034482
Loss at iteration 780 : 0.00212484085932374
Loss at iteration 790 : 0.00011945130972890183
Loss at iteration 800 : 0.000747163372579962
Loss at iteration 810 : 0.000477572379168123
Loss at iteration 820 : 5.657539441017434e-05
Loss at iteration 830 : 0.0018176879966631532
Loss at iteration 840 : 9.353691712021828e-05
Loss at iteration 850 : 4.077525591128506e-05
Loss at iteration 860 : 0.0006661111256107688
Loss at iteration 870 : 0.0005254843272268772
Loss at iteration 880 : 0.00019130062719341367
Loss at iteration 890 : 0.0008328933035954833
Loss at iteration 900 : 0.003556216834113002
Loss at iteration 910 : 0.00015446767793036997
Loss at iteration 920 : 0.0005146871553733945
Loss at iteration 930 : 9.427512850379571e-05
Loss at iteration 940 : 0.000911916489712894
Loss at iteration 950 : 8.505953883286566e-05
Loss at iteration 960 : 0.0002582075248938054
Loss at iteration 970 : 0.00030874955700710416
Loss at iteration 980 : 0.0029230162035673857
Loss at iteration 990 : 0.0037008682265877724
Loss at iteration 1000 : 0.0013160696253180504
Loss at iteration 1010 : 0.0002743589866440743
Loss at iteration 1020 : 0.0007464969530701637
Loss at iteration 1030 : 0.00017144267621915787
Loss at iteration 1040 : 0.000701002893038094
Loss at iteration 1050 : 0.0001694693200988695
Loss at iteration 1060 : 0.0002673253184184432
Loss at iteration 1070 : 0.003748765680938959
Loss at iteration 1080 : 0.005025061778724194
Loss at iteration 1090 : 0.0003765322035178542
Loss at iteration 1100 : 0.0002619055157992989
Loss at iteration 1110 : 0.0032235593535006046
Loss at iteration 1120 : 0.0003828855406027287
Loss at iteration 1130 : 9.68964013736695e-05
Loss at iteration 1140 : 0.000799134373664856
Loss at iteration 1150 : 0.0008903729030862451
Loss at iteration 1160 : 0.00010896113963099197
Loss at iteration 1170 : 0.0003966387012042105
Loss at iteration 1180 : 0.00020334521832410246
Loss at iteration 1190 : 0.0028300494886934757
Loss at iteration 1200 : 0.0008052600896917284
Loss at iteration 1210 : 0.0004256340325810015
Loss at iteration 1220 : 0.0006107988301664591
Loss at iteration 1230 : 5.934693035669625e-05
Loss at iteration 1240 : 8.32937948871404e-05
Loss at iteration 1250 : 0.004625900648534298
Loss at iteration 1260 : 0.0005737888277508318
Loss at iteration 1270 : 0.00019288560724817216
Loss at iteration 1280 : 8.459074888378382e-05
Loss at iteration 1290 : 4.4867207179777324e-05
Loss at iteration 1300 : 0.0001648730831220746
Loss at iteration 1310 : 0.000286722817691043
Loss at iteration 1320 : 0.0001365692587569356
Loss at iteration 1330 : 0.00032496172934770584
Loss at iteration 1340 : 6.528002268169075e-05
Loss at iteration 1350 : 0.003751157084479928
Loss at iteration 1360 : 0.00010115504846908152
Loss at iteration 1370 : 9.498245344730094e-05
Loss at iteration 1380 : 9.0093381004408e-05
Loss at iteration 1390 : 7.065371028147638e-05
Loss at iteration 1400 : 7.892143912613392e-05
Loss at iteration 1410 : 7.168205047491938e-05
Loss at iteration 1420 : 0.00030068663181737065
Loss at iteration 1430 : 6.487270729849115e-05
Loss at iteration 1440 : 0.0027330343145877123
Loss at iteration 1450 : 0.0009769430616870522
Loss at iteration 1460 : 0.00021742987155448645
Loss at iteration 1470 : 9.056513226823881e-05
Loss at iteration 1480 : 0.004061265382915735
Loss at iteration 1490 : 0.003649114863947034
Loss at iteration 1500 : 0.0027301411610096693
Loss at iteration 1510 : 7.644851575605571e-05
Loss at iteration 1520 : 4.956153134116903e-05
Loss at iteration 1530 : 8.425740816164762e-05
Loss at iteration 1540 : 0.00012108076771255583
Loss at iteration 1550 : 0.000317518541123718
Loss at iteration 1560 : 0.0001474776945542544
Loss at iteration 1570 : 0.0002155667170882225
Loss at iteration 1580 : 0.0014861715026199818
Loss at iteration 1590 : 0.0009970127139240503
Loss at iteration 1600 : 0.0011347302934154868
Loss at iteration 1610 : 0.0018827926833182573
Loss at iteration 1620 : 0.0001581800024723634
Loss at iteration 1630 : 0.00022524368250742555
Loss at iteration 1640 : 0.002026764675974846
Loss at iteration 1650 : 0.0001085089024854824
Loss at iteration 1660 : 0.002560518914833665
Loss at iteration 1670 : 0.00014884700067341328
Loss at iteration 1680 : 9.814037912292406e-05
Loss at iteration 1690 : 0.0031701386906206608
Loss at iteration 1700 : 0.0006104974308982491
Loss at iteration 1710 : 0.0011435507331043482
Loss at iteration 1720 : 0.0004735466209240258
Loss at iteration 1730 : 6.424218736356124e-05
Loss at iteration 1740 : 5.84127010370139e-05
Loss at iteration 1750 : 0.000656982883810997
The SSIM Value is: 0.9885134803303538
The PSNR Value is: 46.71711687474524
the epoch is: 192
Loss at iteration 10 : 0.00022219252423383296
Loss at iteration 20 : 0.00332250096835196
Loss at iteration 30 : 0.0006234409520402551
Loss at iteration 40 : 0.001133238198235631
Loss at iteration 50 : 5.870404129382223e-05
Loss at iteration 60 : 8.14337472547777e-05
Loss at iteration 70 : 0.0002097227261401713
Loss at iteration 80 : 0.0002993924426846206
Loss at iteration 90 : 0.0002978138218168169
Loss at iteration 100 : 9.053901885636151e-05
Loss at iteration 110 : 0.0018169452669098973
Loss at iteration 120 : 0.007595749106258154
Loss at iteration 130 : 0.00021134442067705095
Loss at iteration 140 : 0.0033276586327701807
Loss at iteration 150 : 7.44598510209471e-05
Loss at iteration 160 : 0.00019906785746570677
Loss at iteration 170 : 0.0003087673394475132
Loss at iteration 180 : 0.0005988893681205809
Loss at iteration 190 : 0.0024738663341850042
Loss at iteration 200 : 0.001135445199906826
Loss at iteration 210 : 0.0001029453196679242
Loss at iteration 220 : 0.0005132608348503709
Loss at iteration 230 : 0.0013515029568225145
Loss at iteration 240 : 0.0014370096614584327
Loss at iteration 250 : 0.00031048597884364426
Loss at iteration 260 : 0.0006429839413613081
Loss at iteration 270 : 0.0015064836479723454
Loss at iteration 280 : 0.0002867103321477771
Loss at iteration 290 : 0.0007108559366315603
Loss at iteration 300 : 0.0007780842715874314
Loss at iteration 310 : 0.00010845973156392574
Loss at iteration 320 : 8.650281961308792e-05
Loss at iteration 330 : 0.00030451445491053164
Loss at iteration 340 : 0.00011997141700703651
Loss at iteration 350 : 0.000336694298312068
Loss at iteration 360 : 0.00039436391671188176
Loss at iteration 370 : 0.00029582061688415706
Loss at iteration 380 : 0.00012086619972251356
Loss at iteration 390 : 0.00012025822070427239
Loss at iteration 400 : 0.00016379024600610137
Loss at iteration 410 : 0.0004899844061583281
Loss at iteration 420 : 0.0006381566636264324
Loss at iteration 430 : 0.00011792717123171315
Loss at iteration 440 : 0.0004746773629449308
Loss at iteration 450 : 0.0001319836446782574
Loss at iteration 460 : 0.00019732286455109715
Loss at iteration 470 : 8.828590216580778e-05
Loss at iteration 480 : 0.0004385743523016572
Loss at iteration 490 : 0.00011769018601626158
Loss at iteration 500 : 0.003121558576822281
Loss at iteration 510 : 8.624931797385216e-05
Loss at iteration 520 : 0.0010883554350584745
Loss at iteration 530 : 0.0015272083692252636
Loss at iteration 540 : 0.00018578339950181544
Loss at iteration 550 : 0.0002171928936149925
Loss at iteration 560 : 8.43418383738026e-05
Loss at iteration 570 : 0.00014221145829651505
Loss at iteration 580 : 0.00014284747885540128
Loss at iteration 590 : 0.00018340436508879066
Loss at iteration 600 : 0.00034973438596352935
Loss at iteration 610 : 0.0004547866410575807
Loss at iteration 620 : 0.0027465152088552713
Loss at iteration 630 : 0.0002538414264563471
Loss at iteration 640 : 0.0002944648149423301
Loss at iteration 650 : 0.004153681918978691
Loss at iteration 660 : 0.0016757266130298376
Loss at iteration 670 : 0.0001680771674728021
Loss at iteration 680 : 0.002115625888109207
Loss at iteration 690 : 0.000861684326082468
Loss at iteration 700 : 0.00280847679823637
Loss at iteration 710 : 0.00016239275282714516
Loss at iteration 720 : 0.0003265469567850232
Loss at iteration 730 : 4.387749868328683e-05
Loss at iteration 740 : 0.00010581836977507919
Loss at iteration 750 : 3.921001189155504e-05
Loss at iteration 760 : 0.00019524320669006556
Loss at iteration 770 : 0.00032492843456566334
Loss at iteration 780 : 0.0005689132958650589
Loss at iteration 790 : 0.0001486097025917843
Loss at iteration 800 : 0.0015866277972236276
Loss at iteration 810 : 0.004976833239197731
Loss at iteration 820 : 0.00037548670661635697
Loss at iteration 830 : 0.00017113369540311396
Loss at iteration 840 : 0.0024656776804476976
Loss at iteration 850 : 0.00035061489325016737
Loss at iteration 860 : 0.0028798875864595175
Loss at iteration 870 : 0.00023618766863364726
Loss at iteration 880 : 0.004345584660768509
Loss at iteration 890 : 0.003057922003790736
Loss at iteration 900 : 0.001624656142666936
Loss at iteration 910 : 0.0011693798005580902
Loss at iteration 920 : 9.193870209855959e-05
Loss at iteration 930 : 0.00027663196669891477
Loss at iteration 940 : 0.0003455963160376996
Loss at iteration 950 : 0.00021748460130766034
Loss at iteration 960 : 0.003895488800480962
Loss at iteration 970 : 0.0001845513324951753
Loss at iteration 980 : 0.0002621477178763598
Loss at iteration 990 : 0.0012569342507049441
Loss at iteration 1000 : 5.237528239376843e-05
Loss at iteration 1010 : 0.0011819645296782255
Loss at iteration 1020 : 0.00018566186190582812
Loss at iteration 1030 : 4.863231151830405e-05
Loss at iteration 1040 : 0.0007218333194032311
Loss at iteration 1050 : 0.00022002510377205908
Loss at iteration 1060 : 0.003660026006400585
Loss at iteration 1070 : 0.003065172117203474
Loss at iteration 1080 : 0.00021397304954007268
Loss at iteration 1090 : 8.073753269854933e-05
Loss at iteration 1100 : 0.0013082517543807626
Loss at iteration 1110 : 0.0016591256717219949
Loss at iteration 1120 : 0.004387822933495045
Loss at iteration 1130 : 0.00012156621232861653
Loss at iteration 1140 : 0.002945168409496546
Loss at iteration 1150 : 0.0007476439932361245
Loss at iteration 1160 : 0.0014636557316407561
Loss at iteration 1170 : 0.00033147691283375025
Loss at iteration 1180 : 0.0009637161856517196
Loss at iteration 1190 : 0.004414507653564215
Loss at iteration 1200 : 9.024408791447058e-05
Loss at iteration 1210 : 0.0006548729725182056
Loss at iteration 1220 : 0.00021562838810496032
Loss at iteration 1230 : 0.006549237761646509
Loss at iteration 1240 : 0.00010926911636488512
Loss at iteration 1250 : 0.00012231046275701374
Loss at iteration 1260 : 0.0019934859592467546
Loss at iteration 1270 : 0.00013728644989896566
Loss at iteration 1280 : 0.004380291793495417
Loss at iteration 1290 : 0.0015199386980384588
Loss at iteration 1300 : 0.0008208671351894736
Loss at iteration 1310 : 7.299903518287465e-05
Loss at iteration 1320 : 0.00042214090353809297
Loss at iteration 1330 : 0.0023664592299610376
Loss at iteration 1340 : 0.0001555033668410033
Loss at iteration 1350 : 0.0032735068816691637
Loss at iteration 1360 : 0.00031393079552799463
Loss at iteration 1370 : 0.0006874268292449415
Loss at iteration 1380 : 6.144113285699859e-05
Loss at iteration 1390 : 0.0011018043151125312
Loss at iteration 1400 : 0.0001978388463612646
Loss at iteration 1410 : 9.746724390424788e-05
Loss at iteration 1420 : 0.002747292397543788
Loss at iteration 1430 : 0.00013505335664376616
Loss at iteration 1440 : 0.0018640419002622366
Loss at iteration 1450 : 0.0007815773133188486
Loss at iteration 1460 : 5.5313466873485595e-05
Loss at iteration 1470 : 0.0011963134165853262
Loss at iteration 1480 : 0.0001306210324401036
Loss at iteration 1490 : 0.0038501424714922905
Loss at iteration 1500 : 0.0033797002397477627
Loss at iteration 1510 : 8.708654786460102e-05
Loss at iteration 1520 : 0.00023268949007615447
Loss at iteration 1530 : 0.00011219771113246679
Loss at iteration 1540 : 0.00073932611849159
Loss at iteration 1550 : 0.0009247846901416779
Loss at iteration 1560 : 0.0003271136956755072
Loss at iteration 1570 : 0.00021388183813542128
Loss at iteration 1580 : 5.987135227769613e-05
Loss at iteration 1590 : 0.00013036471500527114
Loss at iteration 1600 : 0.0003760320832952857
Loss at iteration 1610 : 0.0011081683915108442
Loss at iteration 1620 : 0.00024258358462247998
Loss at iteration 1630 : 0.0002858936204575002
Loss at iteration 1640 : 0.0020543872378766537
Loss at iteration 1650 : 0.0002891625335905701
Loss at iteration 1660 : 0.00011850317241623998
Loss at iteration 1670 : 0.00033380225067958236
Loss at iteration 1680 : 0.00014907112927176058
Loss at iteration 1690 : 0.0005812780000269413
Loss at iteration 1700 : 0.0017679290613159537
Loss at iteration 1710 : 0.0002694842405617237
Loss at iteration 1720 : 0.0033930535428225994
Loss at iteration 1730 : 0.002928143134340644
Loss at iteration 1740 : 0.006411732640117407
Loss at iteration 1750 : 0.00011974952940363437
The SSIM Value is: 0.9864770692613156
The PSNR Value is: 46.38033123898611
the epoch is: 193
Loss at iteration 10 : 0.00030100130243226886
Loss at iteration 20 : 8.082035492407158e-05
Loss at iteration 30 : 0.0001495882897870615
Loss at iteration 40 : 0.00012073041580151767
Loss at iteration 50 : 0.0002350607537664473
Loss at iteration 60 : 0.00025786246987991035
Loss at iteration 70 : 0.0007009180262684822
Loss at iteration 80 : 0.0018787767039611936
Loss at iteration 90 : 0.0007601515972055495
Loss at iteration 100 : 0.005453324876725674
Loss at iteration 110 : 0.0006192784640006721
Loss at iteration 120 : 0.0004218392423354089
Loss at iteration 130 : 0.0001880767522379756
Loss at iteration 140 : 0.0024032373912632465
Loss at iteration 150 : 0.0027253192383795977
Loss at iteration 160 : 0.0005740615306422114
Loss at iteration 170 : 0.0001395465078530833
Loss at iteration 180 : 0.0022905878722667694
Loss at iteration 190 : 0.0007959039066918194
Loss at iteration 200 : 0.00034156389301642776
Loss at iteration 210 : 0.00016860496543813497
Loss at iteration 220 : 0.00015888514462858438
Loss at iteration 230 : 0.00011461033136583865
Loss at iteration 240 : 0.00046887746430002153
Loss at iteration 250 : 0.00029603936127386987
Loss at iteration 260 : 0.004464967176318169
Loss at iteration 270 : 0.00036668824031949043
Loss at iteration 280 : 0.00023627025075256824
Loss at iteration 290 : 0.0025850858073681593
Loss at iteration 300 : 0.0022122689988464117
Loss at iteration 310 : 0.00011123150761704892
Loss at iteration 320 : 0.00045325749670155346
Loss at iteration 330 : 0.00012202211655676365
Loss at iteration 340 : 9.443226008443162e-05
Loss at iteration 350 : 9.020746074384078e-05
Loss at iteration 360 : 0.005044694058597088
Loss at iteration 370 : 6.582641071872786e-05
Loss at iteration 380 : 0.0009759696549735963
Loss at iteration 390 : 6.226011464605108e-05
Loss at iteration 400 : 0.00151012372225523
Loss at iteration 410 : 6.575299630640075e-05
Loss at iteration 420 : 0.00023639985010959208
Loss at iteration 430 : 0.00013863005733583122
Loss at iteration 440 : 0.003038002410903573
Loss at iteration 450 : 0.001981720793992281
Loss at iteration 460 : 7.231662311824039e-05
Loss at iteration 470 : 0.0028673072811216116
Loss at iteration 480 : 0.0001768909569364041
Loss at iteration 490 : 8.570306818000972e-05
Loss at iteration 500 : 0.000227762691793032
Loss at iteration 510 : 0.00048195733688771725
Loss at iteration 520 : 6.714540359098464e-05
Loss at iteration 530 : 0.001013214117847383
Loss at iteration 540 : 0.00040257812361232936
Loss at iteration 550 : 0.000418804120272398
Loss at iteration 560 : 0.0006250925362110138
Loss at iteration 570 : 0.003737374674528837
Loss at iteration 580 : 0.0005082091083750129
Loss at iteration 590 : 9.523685730528086e-05
Loss at iteration 600 : 0.0005587773630395532
Loss at iteration 610 : 0.0007811365649104118
Loss at iteration 620 : 0.0001161319378297776
Loss at iteration 630 : 0.00013291432696860284
Loss at iteration 640 : 0.000244818686041981
Loss at iteration 650 : 0.0001295300608035177
Loss at iteration 660 : 0.00021491097868420184
Loss at iteration 670 : 0.0005200633895583451
Loss at iteration 680 : 0.0001712293887976557
Loss at iteration 690 : 0.001161431660875678
Loss at iteration 700 : 0.0001137258077505976
Loss at iteration 710 : 0.0021925370674580336
Loss at iteration 720 : 4.808617813978344e-05
Loss at iteration 730 : 0.00017250484961550683
Loss at iteration 740 : 0.0003691943420562893
Loss at iteration 750 : 0.000985065009444952
Loss at iteration 760 : 0.0017558583058416843
Loss at iteration 770 : 0.00020428583957254887
Loss at iteration 780 : 0.008435141295194626
Loss at iteration 790 : 0.00031604667310602963
Loss at iteration 800 : 9.716123167891055e-05
Loss at iteration 810 : 0.00013289407070260495
Loss at iteration 820 : 0.0003282518300693482
Loss at iteration 830 : 0.003984008450061083
Loss at iteration 840 : 0.00012825221347156912
Loss at iteration 850 : 5.63405774300918e-05
Loss at iteration 860 : 0.0023098355159163475
Loss at iteration 870 : 0.0003266924759373069
Loss at iteration 880 : 0.00022075859305914491
Loss at iteration 890 : 0.0025077166501432657
Loss at iteration 900 : 0.0003556406300049275
Loss at iteration 910 : 0.00014361520879901946
Loss at iteration 920 : 0.00029313017148524523
Loss at iteration 930 : 0.00011647911742329597
Loss at iteration 940 : 0.0012474977411329746
Loss at iteration 950 : 0.000726384692825377
Loss at iteration 960 : 0.0029457879718393087
Loss at iteration 970 : 0.0018256778130307794
Loss at iteration 980 : 0.000215516600292176
Loss at iteration 990 : 6.64420222165063e-05
Loss at iteration 1000 : 0.0005591316148638725
Loss at iteration 1010 : 0.0005323830991983414
Loss at iteration 1020 : 0.0001255853712791577
Loss at iteration 1030 : 0.0004260264977347106
Loss at iteration 1040 : 0.0028079464100301266
Loss at iteration 1050 : 0.00020938992383889854
Loss at iteration 1060 : 6.319519161479548e-05
Loss at iteration 1070 : 0.0006741133984178305
Loss at iteration 1080 : 0.0006118599558249116
Loss at iteration 1090 : 0.0005924734869040549
Loss at iteration 1100 : 0.00013141357339918613
Loss at iteration 1110 : 0.00026607722975313663
Loss at iteration 1120 : 0.0023757154121994972
Loss at iteration 1130 : 5.696135121979751e-05
Loss at iteration 1140 : 0.0020735147409141064
Loss at iteration 1150 : 0.004417354706674814
Loss at iteration 1160 : 0.0001825644139898941
Loss at iteration 1170 : 0.002738806651905179
Loss at iteration 1180 : 0.00013668449537362903
Loss at iteration 1190 : 0.00012407361646182835
Loss at iteration 1200 : 0.00011913215712411329
Loss at iteration 1210 : 0.00010393372940598056
Loss at iteration 1220 : 0.0010148620931431651
Loss at iteration 1230 : 0.0002221523754997179
Loss at iteration 1240 : 0.00011582274601096287
Loss at iteration 1250 : 0.0031331884674727917
Loss at iteration 1260 : 8.624247857369483e-05
Loss at iteration 1270 : 0.0003255860647186637
Loss at iteration 1280 : 0.004521460272371769
Loss at iteration 1290 : 0.0016866505611687899
Loss at iteration 1300 : 0.0005823835963383317
Loss at iteration 1310 : 0.00040870680822990835
Loss at iteration 1320 : 0.00012006614997517318
Loss at iteration 1330 : 0.00018182962958235294
Loss at iteration 1340 : 0.00016147013229783624
Loss at iteration 1350 : 0.0002001660323003307
Loss at iteration 1360 : 0.00035878430935554206
Loss at iteration 1370 : 5.773640441475436e-05
Loss at iteration 1380 : 0.0001267271290998906
Loss at iteration 1390 : 0.00017321361519861966
Loss at iteration 1400 : 0.0002812146267388016
Loss at iteration 1410 : 0.00015193826402537525
Loss at iteration 1420 : 0.00021975339041091502
Loss at iteration 1430 : 0.0018713836325332522
Loss at iteration 1440 : 0.002865501446649432
Loss at iteration 1450 : 0.000249999575316906
Loss at iteration 1460 : 0.0005591277731582522
Loss at iteration 1470 : 0.0014705682406201959
Loss at iteration 1480 : 0.000244400289375335
Loss at iteration 1490 : 0.00015291701129171997
Loss at iteration 1500 : 0.0007025589002296329
Loss at iteration 1510 : 0.00018957426073029637
Loss at iteration 1520 : 0.00010464587830938399
Loss at iteration 1530 : 0.0005197442369535565
Loss at iteration 1540 : 5.426067946245894e-05
Loss at iteration 1550 : 8.694871212355793e-05
Loss at iteration 1560 : 0.0001332542160525918
Loss at iteration 1570 : 0.00025177153293043375
Loss at iteration 1580 : 0.00040778343100100756
Loss at iteration 1590 : 0.000601080188062042
Loss at iteration 1600 : 0.0040318770334124565
Loss at iteration 1610 : 0.003460996551439166
Loss at iteration 1620 : 0.0023264901246875525
Loss at iteration 1630 : 0.00023546972079202533
Loss at iteration 1640 : 0.0020006161648780107
Loss at iteration 1650 : 0.0007931124418973923
Loss at iteration 1660 : 0.0029582593124359846
Loss at iteration 1670 : 0.00012475322000682354
Loss at iteration 1680 : 0.0014109264593571424
Loss at iteration 1690 : 6.0160480643389747e-05
Loss at iteration 1700 : 0.0002417431678622961
Loss at iteration 1710 : 0.001774239121004939
Loss at iteration 1720 : 0.0005917097441852093
Loss at iteration 1730 : 0.0026752834673970938
Loss at iteration 1740 : 0.0029719341546297073
Loss at iteration 1750 : 0.00020371470600366592
The SSIM Value is: 0.9880086876747367
The PSNR Value is: 46.449244671456086
the epoch is: 194
Loss at iteration 10 : 0.00025534856831654906
Loss at iteration 20 : 0.003060831455513835
Loss at iteration 30 : 0.0011334691662341356
Loss at iteration 40 : 0.00019537581829354167
Loss at iteration 50 : 0.002612665994092822
Loss at iteration 60 : 0.0002532131620682776
Loss at iteration 70 : 0.00014274276327341795
Loss at iteration 80 : 0.0026481347158551216
Loss at iteration 90 : 0.00038725408376194537
Loss at iteration 100 : 0.00016770328511483967
Loss at iteration 110 : 0.0022519328631460667
Loss at iteration 120 : 6.715122435707599e-05
Loss at iteration 130 : 0.0010814288398250937
Loss at iteration 140 : 0.0005790168652310967
Loss at iteration 150 : 0.00029108888702467084
Loss at iteration 160 : 0.00010858122550416738
Loss at iteration 170 : 0.00044280634028837085
Loss at iteration 180 : 0.0003262694808654487
Loss at iteration 190 : 0.00038554187631234527
Loss at iteration 200 : 0.002546208444982767
Loss at iteration 210 : 0.0032221865840256214
Loss at iteration 220 : 0.00012118456652387977
Loss at iteration 230 : 0.0007313585374504328
Loss at iteration 240 : 0.0006040483713150024
Loss at iteration 250 : 0.00047269227798096836
Loss at iteration 260 : 9.236067853635177e-05
Loss at iteration 270 : 0.00022833733237348497
Loss at iteration 280 : 0.000768830650486052
Loss at iteration 290 : 0.00030802280525676906
Loss at iteration 300 : 0.00013328553177416325
Loss at iteration 310 : 0.0004018923791591078
Loss at iteration 320 : 0.0015832853969186544
Loss at iteration 330 : 0.00013022150960750878
Loss at iteration 340 : 0.00010579957597656175
Loss at iteration 350 : 0.0004871130222454667
Loss at iteration 360 : 0.0010048584081232548
Loss at iteration 370 : 8.628968498669565e-05
Loss at iteration 380 : 0.0003387048200238496
Loss at iteration 390 : 0.0002889696042984724
Loss at iteration 400 : 9.038164716912434e-05
Loss at iteration 410 : 0.00021259146160446107
Loss at iteration 420 : 0.0037174851167947054
Loss at iteration 430 : 0.0002515506057534367
Loss at iteration 440 : 0.0013059705961495638
Loss at iteration 450 : 0.0037256956566125154
Loss at iteration 460 : 0.0001248204061994329
Loss at iteration 470 : 0.0002579581632744521
Loss at iteration 480 : 0.00011405065743019804
Loss at iteration 490 : 0.00013456199667416513
Loss at iteration 500 : 0.0019695041701197624
Loss at iteration 510 : 0.0030416816007345915
Loss at iteration 520 : 0.00032552500488236547
Loss at iteration 530 : 0.0007000720943324268
Loss at iteration 540 : 0.0005441302200779319
Loss at iteration 550 : 0.0002243285853182897
Loss at iteration 560 : 0.0017763411160558462
Loss at iteration 570 : 0.00017072344780899584
Loss at iteration 580 : 0.0015742307296022773
Loss at iteration 590 : 5.327230246621184e-05
Loss at iteration 600 : 0.00023670477094128728
Loss at iteration 610 : 0.0006190339336171746
Loss at iteration 620 : 0.0020259562879800797
Loss at iteration 630 : 0.00015084765618667006
Loss at iteration 640 : 0.00031941113411448896
Loss at iteration 650 : 0.00012698944192379713
Loss at iteration 660 : 0.0001980180968530476
Loss at iteration 670 : 0.0005595459369942546
Loss at iteration 680 : 0.0006054023979231715
Loss at iteration 690 : 0.0044574555940926075
Loss at iteration 700 : 0.0004579249653033912
Loss at iteration 710 : 0.002063758671283722
Loss at iteration 720 : 0.0003743822453543544
Loss at iteration 730 : 0.00010340820881538093
Loss at iteration 740 : 0.00013295233657117933
Loss at iteration 750 : 0.0015742856776341796
Loss at iteration 760 : 0.0007325303740799427
Loss at iteration 770 : 5.412693280959502e-05
Loss at iteration 780 : 0.0010675294324755669
Loss at iteration 790 : 0.00010696253593778238
Loss at iteration 800 : 0.001996598904952407
Loss at iteration 810 : 0.0009762404952198267
Loss at iteration 820 : 0.0018707045819610357
Loss at iteration 830 : 0.00014140164421405643
Loss at iteration 840 : 0.0025894979480654
Loss at iteration 850 : 0.0013141928939148784
Loss at iteration 860 : 6.653081072727218e-05
Loss at iteration 870 : 9.186012903228402e-05
Loss at iteration 880 : 0.0010568829020485282
Loss at iteration 890 : 0.00018971887766383588
Loss at iteration 900 : 0.0003883415483869612
Loss at iteration 910 : 0.0023982226848602295
Loss at iteration 920 : 0.00013830710668116808
Loss at iteration 930 : 0.00011004037514794618
Loss at iteration 940 : 0.008402802050113678
Loss at iteration 950 : 0.0014841180527582765
Loss at iteration 960 : 0.00019129965221509337
Loss at iteration 970 : 0.0001128336152760312
Loss at iteration 980 : 0.0005382281960919499
Loss at iteration 990 : 0.002046923153102398
Loss at iteration 1000 : 0.0003071517567150295
Loss at iteration 1010 : 0.0005943372962065041
Loss at iteration 1020 : 0.00016999198123812675
Loss at iteration 1030 : 0.0001236734533449635
Loss at iteration 1040 : 0.00016138068167492747
Loss at iteration 1050 : 0.0043948013335466385
Loss at iteration 1060 : 0.00012843887088820338
Loss at iteration 1070 : 0.000117981675430201
Loss at iteration 1080 : 0.0014958251267671585
Loss at iteration 1090 : 0.0011616385309025645
Loss at iteration 1100 : 0.0014939963584765792
Loss at iteration 1110 : 0.00014371368160936981
Loss at iteration 1120 : 0.0006840022397227585
Loss at iteration 1130 : 0.002042141743004322
Loss at iteration 1140 : 5.395709376898594e-05
Loss at iteration 1150 : 0.0013140866067260504
Loss at iteration 1160 : 9.687086276244372e-05
Loss at iteration 1170 : 7.8740187746007e-05
Loss at iteration 1180 : 0.00016099763161037117
Loss at iteration 1190 : 0.0014880921225994825
Loss at iteration 1200 : 6.844518065918237e-05
Loss at iteration 1210 : 0.00010605120041873306
Loss at iteration 1220 : 8.155839168466628e-05
Loss at iteration 1230 : 0.0003014990652445704
Loss at iteration 1240 : 0.0002090008492814377
Loss at iteration 1250 : 8.22289875941351e-05
Loss at iteration 1260 : 0.001900500850751996
Loss at iteration 1270 : 6.615050369873643e-05
Loss at iteration 1280 : 0.0003003909660037607
Loss at iteration 1290 : 0.0002508283359929919
Loss at iteration 1300 : 0.0008641930762678385
Loss at iteration 1310 : 0.0001363855553790927
Loss at iteration 1320 : 0.0020019973162561655
Loss at iteration 1330 : 0.00022052580607123673
Loss at iteration 1340 : 0.002066089538857341
Loss at iteration 1350 : 0.000503295159433037
Loss at iteration 1360 : 9.75501025095582e-05
Loss at iteration 1370 : 0.0006316214567050338
Loss at iteration 1380 : 0.0001338170695817098
Loss at iteration 1390 : 0.0004457320610526949
Loss at iteration 1400 : 0.00014166644541546702
Loss at iteration 1410 : 0.00014152670337352902
Loss at iteration 1420 : 0.00010240176197839901
Loss at iteration 1430 : 0.0001879107439890504
Loss at iteration 1440 : 0.0022313985973596573
Loss at iteration 1450 : 0.0001735213299980387
Loss at iteration 1460 : 8.367552072741091e-05
Loss at iteration 1470 : 0.0002485186269041151
Loss at iteration 1480 : 0.00020140624837949872
Loss at iteration 1490 : 9.351863991469145e-05
Loss at iteration 1500 : 6.299875531112775e-05
Loss at iteration 1510 : 0.005744555499404669
Loss at iteration 1520 : 5.336593312676996e-05
Loss at iteration 1530 : 0.00010515391477383673
Loss at iteration 1540 : 5.4284624638967216e-05
Loss at iteration 1550 : 0.00030484976014122367
Loss at iteration 1560 : 0.00033032160717993975
Loss at iteration 1570 : 0.00040549231925979257
Loss at iteration 1580 : 8.602882007835433e-05
Loss at iteration 1590 : 0.0008810299914330244
Loss at iteration 1600 : 0.0005449102609418333
Loss at iteration 1610 : 0.00027399498503655195
Loss at iteration 1620 : 0.00010071216092910618
Loss at iteration 1630 : 0.000188456877367571
Loss at iteration 1640 : 0.0008927539456635714
Loss at iteration 1650 : 0.0001787797809811309
Loss at iteration 1660 : 0.0006927357171662152
Loss at iteration 1670 : 0.00010470665438333526
Loss at iteration 1680 : 0.00024583342019468546
Loss at iteration 1690 : 0.00015347350563388318
Loss at iteration 1700 : 0.0012546692742034793
Loss at iteration 1710 : 0.00029772636480629444
Loss at iteration 1720 : 0.00017978902906179428
Loss at iteration 1730 : 0.00029860634822398424
Loss at iteration 1740 : 0.00033869611797854304
Loss at iteration 1750 : 0.00012410317140165716
The SSIM Value is: 0.9890875704750616
The PSNR Value is: 46.69946130256821
the epoch is: 195
Loss at iteration 10 : 0.0003620777861215174
Loss at iteration 20 : 0.0025051075499504805
Loss at iteration 30 : 0.00015602185158059
Loss at iteration 40 : 0.0001400705659762025
Loss at iteration 50 : 9.669374412624165e-05
Loss at iteration 60 : 0.00044256472028791904
Loss at iteration 70 : 0.005982085131108761
Loss at iteration 80 : 0.00011719018220901489
Loss at iteration 90 : 0.0007396218134090304
Loss at iteration 100 : 0.0003518870216794312
Loss at iteration 110 : 0.0002157590351998806
Loss at iteration 120 : 0.00016893036081455648
Loss at iteration 130 : 0.0010602017864584923
Loss at iteration 140 : 0.002566809533163905
Loss at iteration 150 : 0.0003476009296718985
Loss at iteration 160 : 0.00020748827955685556
Loss at iteration 170 : 0.0006394152296707034
Loss at iteration 180 : 0.0011257301084697247
Loss at iteration 190 : 0.0002587433555163443
Loss at iteration 200 : 0.004452782683074474
Loss at iteration 210 : 0.000824635149911046
Loss at iteration 220 : 0.0004519288195297122
Loss at iteration 230 : 4.881650966126472e-05
Loss at iteration 240 : 0.003506495151668787
Loss at iteration 250 : 4.9620030040387064e-05
Loss at iteration 260 : 0.003440328873693943
Loss at iteration 270 : 0.00015083314792718738
Loss at iteration 280 : 9.249438880942762e-05
Loss at iteration 290 : 0.00014193910465110093
Loss at iteration 300 : 0.006110476329922676
Loss at iteration 310 : 0.0034808251075446606
Loss at iteration 320 : 9.483726171310991e-05
Loss at iteration 330 : 0.0001444858789909631
Loss at iteration 340 : 0.0001259046111954376
Loss at iteration 350 : 9.43528430070728e-05
Loss at iteration 360 : 0.0006234392640180886
Loss at iteration 370 : 0.0020775017328560352
Loss at iteration 380 : 0.00024019484408199787
Loss at iteration 390 : 0.0003390170750208199
Loss at iteration 400 : 0.0007138419896364212
Loss at iteration 410 : 0.0004187997546978295
Loss at iteration 420 : 0.0002175662957597524
Loss at iteration 430 : 9.715223131934181e-05
Loss at iteration 440 : 0.0020417990162968636
Loss at iteration 450 : 0.00032844545785337687
Loss at iteration 460 : 0.00021563254995271564
Loss at iteration 470 : 0.001405414892360568
Loss at iteration 480 : 8.632979006506503e-05
Loss at iteration 490 : 0.00011883927072631195
Loss at iteration 500 : 0.00043129880214110017
Loss at iteration 510 : 0.00013665537699125707
Loss at iteration 520 : 0.0001725705515127629
Loss at iteration 530 : 0.0003925839555449784
Loss at iteration 540 : 9.497837163507938e-05
Loss at iteration 550 : 0.00011804550013039261
Loss at iteration 560 : 0.0014014745829626918
Loss at iteration 570 : 0.0012496626004576683
Loss at iteration 580 : 0.00028384753386490047
Loss at iteration 590 : 0.0036092239897698164
Loss at iteration 600 : 0.0010140433441847563
Loss at iteration 610 : 0.00016121880616992712
Loss at iteration 620 : 7.548296707682312e-05
Loss at iteration 630 : 0.0002888537128455937
Loss at iteration 640 : 0.0003973686834797263
Loss at iteration 650 : 0.00028218154329806566
Loss at iteration 660 : 0.00030882444116286933
Loss at iteration 670 : 0.001707048388198018
Loss at iteration 680 : 0.0003061576862819493
Loss at iteration 690 : 5.311767745297402e-05
Loss at iteration 700 : 0.0028215080965310335
Loss at iteration 710 : 0.0003930522652808577
Loss at iteration 720 : 8.40968859847635e-05
Loss at iteration 730 : 0.00012636437895707786
Loss at iteration 740 : 0.000996605958789587
Loss at iteration 750 : 0.00034123752266168594
Loss at iteration 760 : 0.00019490061094984412
Loss at iteration 770 : 0.0002134105598088354
Loss at iteration 780 : 0.00044610287295654416
Loss at iteration 790 : 0.0009741997346282005
Loss at iteration 800 : 0.0002949153131339699
Loss at iteration 810 : 9.291178866988048e-05
Loss at iteration 820 : 0.00230961455963552
Loss at iteration 830 : 0.00017838019994087517
Loss at iteration 840 : 0.0033819961827248335
Loss at iteration 850 : 0.006083646789193153
Loss at iteration 860 : 0.00029470230219885707
Loss at iteration 870 : 0.0012124371714890003
Loss at iteration 880 : 0.0006703254184685647
Loss at iteration 890 : 0.0014167536282911897
Loss at iteration 900 : 0.00012678072380367666
Loss at iteration 910 : 9.908503125188872e-05
Loss at iteration 920 : 0.0002234322892036289
Loss at iteration 930 : 0.00011092062050011009
Loss at iteration 940 : 0.000320951163303107
Loss at iteration 950 : 0.00031978299375623465
Loss at iteration 960 : 0.0004148061852902174
Loss at iteration 970 : 0.0009773687925189734
Loss at iteration 980 : 0.0007404444040730596
Loss at iteration 990 : 0.0027804491110146046
Loss at iteration 1000 : 0.00021695315081160516
Loss at iteration 1010 : 0.0056595150381326675
Loss at iteration 1020 : 0.0008264782372862101
Loss at iteration 1030 : 9.319451783085242e-05
Loss at iteration 1040 : 8.52677330840379e-05
Loss at iteration 1050 : 0.00043391063809394836
Loss at iteration 1060 : 0.002945952583104372
Loss at iteration 1070 : 0.004728460218757391
Loss at iteration 1080 : 0.000456717680208385
Loss at iteration 1090 : 7.774518599035218e-05
Loss at iteration 1100 : 0.0002647775399964303
Loss at iteration 1110 : 0.0003178828628733754
Loss at iteration 1120 : 9.349569154437631e-05
Loss at iteration 1130 : 0.004774780943989754
Loss at iteration 1140 : 0.00010891709825955331
Loss at iteration 1150 : 0.00023024329857435077
Loss at iteration 1160 : 0.00048627087380737066
Loss at iteration 1170 : 0.00018205653759650886
Loss at iteration 1180 : 0.0020376925822347403
Loss at iteration 1190 : 0.00046588864643126726
Loss at iteration 1200 : 0.0030823221895843744
Loss at iteration 1210 : 0.0002099020202877
Loss at iteration 1220 : 0.00026999731198884547
Loss at iteration 1230 : 0.00017398709314875305
Loss at iteration 1240 : 0.00010155519703403115
Loss at iteration 1250 : 0.00039637667941860855
Loss at iteration 1260 : 0.0007356780115514994
Loss at iteration 1270 : 0.003111189231276512
Loss at iteration 1280 : 0.00020260158635210246
Loss at iteration 1290 : 0.0005373142776079476
Loss at iteration 1300 : 0.00035666878102347255
Loss at iteration 1310 : 0.0012012685183435678
Loss at iteration 1320 : 0.00015642082144040614
Loss at iteration 1330 : 0.000544851238373667
Loss at iteration 1340 : 0.00012784759746864438
Loss at iteration 1350 : 0.00023487440194003284
Loss at iteration 1360 : 0.00016511678404640406
Loss at iteration 1370 : 0.000808548997156322
Loss at iteration 1380 : 0.00012156757293269038
Loss at iteration 1390 : 9.47995504247956e-05
Loss at iteration 1400 : 0.00015484707546420395
Loss at iteration 1410 : 0.0019015856087207794
Loss at iteration 1420 : 0.0004994790069758892
Loss at iteration 1430 : 0.00048086096649058163
Loss at iteration 1440 : 0.00010108541755471379
Loss at iteration 1450 : 0.00023872074962127954
Loss at iteration 1460 : 0.001804842846468091
Loss at iteration 1470 : 0.000310549046844244
Loss at iteration 1480 : 8.114840602502227e-05
Loss at iteration 1490 : 0.003896727692335844
Loss at iteration 1500 : 0.0017468617297708988
Loss at iteration 1510 : 0.0006874360842630267
Loss at iteration 1520 : 0.0026082568801939487
Loss at iteration 1530 : 0.0001218613178934902
Loss at iteration 1540 : 0.0006093581323511899
Loss at iteration 1550 : 9.689731814432889e-05
Loss at iteration 1560 : 0.0013144472613930702
Loss at iteration 1570 : 0.0032825996167957783
Loss at iteration 1580 : 0.0009028983185999095
Loss at iteration 1590 : 9.591747220838442e-05
Loss at iteration 1600 : 0.0001272867521038279
Loss at iteration 1610 : 0.00120094686280936
Loss at iteration 1620 : 7.935865869512782e-05
Loss at iteration 1630 : 0.00022451323457062244
Loss at iteration 1640 : 0.00045832351315766573
Loss at iteration 1650 : 0.00015088965301401913
Loss at iteration 1660 : 0.001985881244763732
Loss at iteration 1670 : 0.0001683002192294225
Loss at iteration 1680 : 0.0002761614741757512
Loss at iteration 1690 : 0.00036333914613351226
Loss at iteration 1700 : 0.0006017612759023905
Loss at iteration 1710 : 0.00023418816272169352
Loss at iteration 1720 : 0.00016897697059903294
Loss at iteration 1730 : 8.798267663223669e-05
Loss at iteration 1740 : 7.674283551750705e-05
Loss at iteration 1750 : 0.0006289623561315238
The SSIM Value is: 0.9885500999011657
The PSNR Value is: 46.61557678189047
the epoch is: 196
Loss at iteration 10 : 0.0016919493209570646
Loss at iteration 20 : 0.0001647850585868582
Loss at iteration 30 : 6.642450898652896e-05
Loss at iteration 40 : 0.0003712028847075999
Loss at iteration 50 : 0.0007051244610920548
Loss at iteration 60 : 0.00010067259427160025
Loss at iteration 70 : 0.0004767424543388188
Loss at iteration 80 : 0.00019689442706294358
Loss at iteration 90 : 0.0004674600495491177
Loss at iteration 100 : 0.00018353984341956675
Loss at iteration 110 : 0.00023604478337801993
Loss at iteration 120 : 0.004294432234019041
Loss at iteration 130 : 0.0018622418865561485
Loss at iteration 140 : 0.0005060090916231275
Loss at iteration 150 : 7.281798752956092e-05
Loss at iteration 160 : 0.0004142594407312572
Loss at iteration 170 : 0.0007317987619899213
Loss at iteration 180 : 0.00026093923952430487
Loss at iteration 190 : 0.00015355233335867524
Loss at iteration 200 : 0.0013564454857259989
Loss at iteration 210 : 0.00010034583101514727
Loss at iteration 220 : 0.0023009597789496183
Loss at iteration 230 : 0.0003348885802552104
Loss at iteration 240 : 0.00010237917740596458
Loss at iteration 250 : 0.0002682260819710791
Loss at iteration 260 : 0.0033677679020911455
Loss at iteration 270 : 0.00021077663404867053
Loss at iteration 280 : 0.0017246954375877976
Loss at iteration 290 : 0.006929207593202591
Loss at iteration 300 : 7.138507498893887e-05
Loss at iteration 310 : 0.0004976626951247454
Loss at iteration 320 : 0.00011213654215680435
Loss at iteration 330 : 0.001265841186977923
Loss at iteration 340 : 0.002876612590625882
Loss at iteration 350 : 0.0039050737395882607
Loss at iteration 360 : 0.00998198427259922
Loss at iteration 370 : 0.0017118535470217466
Loss at iteration 380 : 5.089943442726508e-05
Loss at iteration 390 : 0.0016092481091618538
Loss at iteration 400 : 0.0021357680670917034
Loss at iteration 410 : 0.0017298217862844467
Loss at iteration 420 : 0.0022439996246248484
Loss at iteration 430 : 0.0007864615763537586
Loss at iteration 440 : 0.001987829338759184
Loss at iteration 450 : 0.0022275156807154417
Loss at iteration 460 : 0.0002501984126865864
Loss at iteration 470 : 7.755535625619814e-05
Loss at iteration 480 : 0.005385507829487324
Loss at iteration 490 : 0.0020571909844875336
Loss at iteration 500 : 0.0013003344647586346
Loss at iteration 510 : 0.000164972196216695
Loss at iteration 520 : 0.0006557265296578407
Loss at iteration 530 : 0.001384242088533938
Loss at iteration 540 : 0.00018247071420773864
Loss at iteration 550 : 0.0005274817231111228
Loss at iteration 560 : 0.00024622579803690314
Loss at iteration 570 : 6.026702612871304e-05
Loss at iteration 580 : 5.7224457123083994e-05
Loss at iteration 590 : 0.0007581283571198583
Loss at iteration 600 : 0.00010488940461073071
Loss at iteration 610 : 0.0009104229393415153
Loss at iteration 620 : 4.2949573980877176e-05
Loss at iteration 630 : 0.0018301961245015264
Loss at iteration 640 : 0.0004528179415501654
Loss at iteration 650 : 0.0006080078310333192
Loss at iteration 660 : 0.0007629048777744174
Loss at iteration 670 : 0.00025544525124132633
Loss at iteration 680 : 0.00045679163304157555
Loss at iteration 690 : 0.0007605791324749589
Loss at iteration 700 : 0.0006719517987221479
Loss at iteration 710 : 0.00014727056259289384
Loss at iteration 720 : 0.0002095847885357216
Loss at iteration 730 : 0.00022957749024499208
Loss at iteration 740 : 0.001311981352046132
Loss at iteration 750 : 0.0015230122953653336
Loss at iteration 760 : 8.402427920373157e-05
Loss at iteration 770 : 0.0005439146189019084
Loss at iteration 780 : 0.00010020071204053238
Loss at iteration 790 : 0.0005417225183919072
Loss at iteration 800 : 0.0025695597287267447
Loss at iteration 810 : 0.00021671102149412036
Loss at iteration 820 : 0.0001046018151100725
Loss at iteration 830 : 0.0005126247415319085
Loss at iteration 840 : 0.005162532441318035
Loss at iteration 850 : 0.000418408919358626
Loss at iteration 860 : 0.0006296299980022013
Loss at iteration 870 : 6.474196561612189e-05
Loss at iteration 880 : 0.0008182741003111005
Loss at iteration 890 : 0.0004026032402180135
Loss at iteration 900 : 0.0005182352033443749
Loss at iteration 910 : 0.00022627809084951878
Loss at iteration 920 : 0.0013961736112833023
Loss at iteration 930 : 0.003482833504676819
Loss at iteration 940 : 0.002701306017115712
Loss at iteration 950 : 0.00021121218742337078
Loss at iteration 960 : 0.0011458081426098943
Loss at iteration 970 : 0.0006023106398060918
Loss at iteration 980 : 0.00032189313787966967
Loss at iteration 990 : 0.00016447159578092396
Loss at iteration 1000 : 9.815995872486383e-05
Loss at iteration 1010 : 5.040946780354716e-05
Loss at iteration 1020 : 0.0019359798170626163
Loss at iteration 1030 : 0.0001327100326307118
Loss at iteration 1040 : 0.00047943921526893973
Loss at iteration 1050 : 0.0013106621336191893
Loss at iteration 1060 : 0.00132467458024621
Loss at iteration 1070 : 0.0026535673532634974
Loss at iteration 1080 : 0.0005783537635579705
Loss at iteration 1090 : 0.0032302956096827984
Loss at iteration 1100 : 0.002973834052681923
Loss at iteration 1110 : 0.0009503795299679041
Loss at iteration 1120 : 7.902226207079366e-05
Loss at iteration 1130 : 0.00013574020704254508
Loss at iteration 1140 : 0.00012665432586800307
Loss at iteration 1150 : 0.0001336258283117786
Loss at iteration 1160 : 0.0015077318530529737
Loss at iteration 1170 : 0.0002864445559680462
Loss at iteration 1180 : 0.00040599124622531235
Loss at iteration 1190 : 6.564466457348317e-05
Loss at iteration 1200 : 0.0031505990773439407
Loss at iteration 1210 : 0.002286438597366214
Loss at iteration 1220 : 0.00310614169575274
Loss at iteration 1230 : 0.000534989929292351
Loss at iteration 1240 : 0.0005546910688281059
Loss at iteration 1250 : 4.414031718624756e-05
Loss at iteration 1260 : 0.0001657357788644731
Loss at iteration 1270 : 0.00020373630104586482
Loss at iteration 1280 : 0.00025851858663372695
Loss at iteration 1290 : 0.00039649539394304156
Loss at iteration 1300 : 0.0002870005846489221
Loss at iteration 1310 : 0.0016526540275663137
Loss at iteration 1320 : 0.0002421467797830701
Loss at iteration 1330 : 0.0005819794023409486
Loss at iteration 1340 : 0.0001706411421764642
Loss at iteration 1350 : 0.00038160395342856646
Loss at iteration 1360 : 0.0005248520756140351
Loss at iteration 1370 : 0.0004307771450839937
Loss at iteration 1380 : 0.0013409554958343506
Loss at iteration 1390 : 0.00010486314567970112
Loss at iteration 1400 : 9.557573503116146e-05
Loss at iteration 1410 : 0.0011644356418401003
Loss at iteration 1420 : 9.417843830306083e-05
Loss at iteration 1430 : 0.00034699481329880655
Loss at iteration 1440 : 0.0034140832722187042
Loss at iteration 1450 : 0.0004268712655175477
Loss at iteration 1460 : 7.532440213253722e-05
Loss at iteration 1470 : 0.00029292784165591
Loss at iteration 1480 : 0.00024485483299940825
Loss at iteration 1490 : 0.0005121091962791979
Loss at iteration 1500 : 7.788212678860873e-05
Loss at iteration 1510 : 6.213902088347822e-05
Loss at iteration 1520 : 0.00022558795171789825
Loss at iteration 1530 : 0.0004101174417883158
Loss at iteration 1540 : 5.738243635278195e-05
Loss at iteration 1550 : 0.00017710818792693317
Loss at iteration 1560 : 0.0001714546378934756
Loss at iteration 1570 : 0.00014109068433754146
Loss at iteration 1580 : 0.00014401786029338837
Loss at iteration 1590 : 0.0024450626224279404
Loss at iteration 1600 : 0.0017276317812502384
Loss at iteration 1610 : 0.0016943817026913166
Loss at iteration 1620 : 0.0025759669952094555
Loss at iteration 1630 : 6.632273289142177e-05
Loss at iteration 1640 : 0.0001565352431498468
Loss at iteration 1650 : 0.0001252583460882306
Loss at iteration 1660 : 3.84072627639398e-05
Loss at iteration 1670 : 0.00033873971551656723
Loss at iteration 1680 : 0.0002020888205152005
Loss at iteration 1690 : 0.00013000309991184622
Loss at iteration 1700 : 0.001148839364759624
Loss at iteration 1710 : 0.001631696242839098
Loss at iteration 1720 : 0.003260444151237607
Loss at iteration 1730 : 0.00044242129661142826
Loss at iteration 1740 : 0.003395410254597664
Loss at iteration 1750 : 0.0006082022446207702
The SSIM Value is: 0.9832379728686967
The PSNR Value is: 46.419537804725415
the epoch is: 197
Loss at iteration 10 : 0.0021145297214388847
Loss at iteration 20 : 0.0007778244907967746
Loss at iteration 30 : 0.00020929703896399587
Loss at iteration 40 : 0.0005524939624592662
Loss at iteration 50 : 0.0025696312077343464
Loss at iteration 60 : 0.0003120331675745547
Loss at iteration 70 : 0.000390229863114655
Loss at iteration 80 : 0.0001515120529802516
Loss at iteration 90 : 0.00022146737319417298
Loss at iteration 100 : 0.00011680524767143652
Loss at iteration 110 : 0.0002201029856223613
Loss at iteration 120 : 0.0008559589623473585
Loss at iteration 130 : 0.0037388349883258343
Loss at iteration 140 : 9.502020839136094e-05
Loss at iteration 150 : 0.0008703573839738965
Loss at iteration 160 : 0.0007184023852460086
Loss at iteration 170 : 0.0002803708193823695
Loss at iteration 180 : 0.00014519426622428
Loss at iteration 190 : 0.0002317578619113192
Loss at iteration 200 : 0.00042809726437553763
Loss at iteration 210 : 0.00017835560720413923
Loss at iteration 220 : 9.494474943494424e-05
Loss at iteration 230 : 0.0018787410808727145
Loss at iteration 240 : 0.000311291660182178
Loss at iteration 250 : 0.0001822689373511821
Loss at iteration 260 : 0.00029384109075181186
Loss at iteration 270 : 0.0004108553403057158
Loss at iteration 280 : 0.0004545833799056709
Loss at iteration 290 : 0.0002988154592458159
Loss at iteration 300 : 0.0003147872048430145
Loss at iteration 310 : 0.0010558132780715823
Loss at iteration 320 : 0.00034261555992998183
Loss at iteration 330 : 0.00022835636627860367
Loss at iteration 340 : 0.00014851178275421262
Loss at iteration 350 : 0.006895618513226509
Loss at iteration 360 : 0.0006336838123388588
Loss at iteration 370 : 0.0006196730537340045
Loss at iteration 380 : 0.00016775316908024251
Loss at iteration 390 : 0.0001071310616680421
Loss at iteration 400 : 0.00011728178651537746
Loss at iteration 410 : 9.540819883113727e-05
Loss at iteration 420 : 0.0001931057486217469
Loss at iteration 430 : 0.0005769366398453712
Loss at iteration 440 : 0.00027435607626102865
Loss at iteration 450 : 0.00026586532476358116
Loss at iteration 460 : 7.07001963746734e-05
Loss at iteration 470 : 0.00046890327939763665
Loss at iteration 480 : 0.00012902560411021113
Loss at iteration 490 : 0.0007065098616294563
Loss at iteration 500 : 0.00033429788891226053
Loss at iteration 510 : 7.831142283976078e-05
Loss at iteration 520 : 0.003236746182665229
Loss at iteration 530 : 0.0001685150491539389
Loss at iteration 540 : 0.00016552413580939174
Loss at iteration 550 : 0.0019531222060322762
Loss at iteration 560 : 0.0026370275299996138
Loss at iteration 570 : 0.00024161041073966771
Loss at iteration 580 : 0.0002242550253868103
Loss at iteration 590 : 0.0005472301854752004
Loss at iteration 600 : 0.0003053710388485342
Loss at iteration 610 : 0.0005272596026770771
Loss at iteration 620 : 0.00017585375462658703
Loss at iteration 630 : 0.0003152351710014045
Loss at iteration 640 : 0.00048128486378118396
Loss at iteration 650 : 0.0001168241651612334
Loss at iteration 660 : 0.0004068789421580732
Loss at iteration 670 : 0.0003454224788583815
Loss at iteration 680 : 0.0003351250197738409
Loss at iteration 690 : 0.0002571251825429499
Loss at iteration 700 : 0.002225835109129548
Loss at iteration 710 : 0.00012450400390662253
Loss at iteration 720 : 0.0015056950505822897
Loss at iteration 730 : 0.0005514667136594653
Loss at iteration 740 : 0.00047365311183966696
Loss at iteration 750 : 0.00017169545753858984
Loss at iteration 760 : 6.645679968642071e-05
Loss at iteration 770 : 0.0035500177182257175
Loss at iteration 780 : 7.653168722754344e-05
Loss at iteration 790 : 0.0010138389188796282
Loss at iteration 800 : 0.00038063505780883133
Loss at iteration 810 : 0.00118491449393332
Loss at iteration 820 : 0.0003579320327844471
Loss at iteration 830 : 6.0983536968706176e-05
Loss at iteration 840 : 0.00017206513439305127
Loss at iteration 850 : 0.00016250298358500004
Loss at iteration 860 : 0.00023697402502875775
Loss at iteration 870 : 8.568908378947526e-05
Loss at iteration 880 : 0.0011759381741285324
Loss at iteration 890 : 0.00012057274580001831
Loss at iteration 900 : 0.0006264872499741614
Loss at iteration 910 : 0.0075306762009859085
Loss at iteration 920 : 0.0003205974935553968
Loss at iteration 930 : 0.00040119848563335836
Loss at iteration 940 : 0.0002481863193679601
Loss at iteration 950 : 0.009330645203590393
Loss at iteration 960 : 0.00011548749898793176
Loss at iteration 970 : 0.00025680960970930755
Loss at iteration 980 : 0.0002687650849111378
Loss at iteration 990 : 8.363035158254206e-05
Loss at iteration 1000 : 0.00015755272761452943
Loss at iteration 1010 : 0.00021842657588422298
Loss at iteration 1020 : 0.003995933569967747
Loss at iteration 1030 : 0.00019901161431334913
Loss at iteration 1040 : 0.00021311512682586908
Loss at iteration 1050 : 0.00014341945643536747
Loss at iteration 1060 : 0.00023033973411656916
Loss at iteration 1070 : 0.0017065771389752626
Loss at iteration 1080 : 0.0002495332737453282
Loss at iteration 1090 : 0.0004196868685539812
Loss at iteration 1100 : 0.0010414501884952188
Loss at iteration 1110 : 0.0001864491932792589
Loss at iteration 1120 : 9.453413804294541e-05
Loss at iteration 1130 : 0.004186676815152168
Loss at iteration 1140 : 0.000266374961938709
Loss at iteration 1150 : 0.004320213571190834
Loss at iteration 1160 : 9.26081120269373e-05
Loss at iteration 1170 : 0.00031427928479388356
Loss at iteration 1180 : 0.0011630997760221362
Loss at iteration 1190 : 0.00012706225970759988
Loss at iteration 1200 : 0.00034393338137306273
Loss at iteration 1210 : 6.519372982438654e-05
Loss at iteration 1220 : 0.000733720778953284
Loss at iteration 1230 : 0.00016646928270347416
Loss at iteration 1240 : 0.0003255173796787858
Loss at iteration 1250 : 0.00028238436789251864
Loss at iteration 1260 : 0.00025126608670689166
Loss at iteration 1270 : 9.592666174285114e-05
Loss at iteration 1280 : 0.0032481164671480656
Loss at iteration 1290 : 0.0002866910654120147
Loss at iteration 1300 : 0.001407358911819756
Loss at iteration 1310 : 0.001121696550399065
Loss at iteration 1320 : 5.944236181676388e-05
Loss at iteration 1330 : 9.207295079249889e-05
Loss at iteration 1340 : 4.5556640543509275e-05
Loss at iteration 1350 : 0.00011978014663327485
Loss at iteration 1360 : 7.252726936712861e-05
Loss at iteration 1370 : 0.0002180495939683169
Loss at iteration 1380 : 0.00036994408583268523
Loss at iteration 1390 : 0.002880471060052514
Loss at iteration 1400 : 9.047722414834425e-05
Loss at iteration 1410 : 0.011032252572476864
Loss at iteration 1420 : 0.0024019370321184397
Loss at iteration 1430 : 0.0006272016325965524
Loss at iteration 1440 : 0.00013662801939062774
Loss at iteration 1450 : 0.002803790383040905
Loss at iteration 1460 : 7.398298475891352e-05
Loss at iteration 1470 : 0.0001509322173660621
Loss at iteration 1480 : 0.0007376102730631828
Loss at iteration 1490 : 0.0006832375074736774
Loss at iteration 1500 : 0.0002903086133301258
Loss at iteration 1510 : 0.0023943823762238026
Loss at iteration 1520 : 0.00014832431043032557
Loss at iteration 1530 : 0.00010931818542303517
Loss at iteration 1540 : 0.00010383562766946852
Loss at iteration 1550 : 0.00031449817470274866
Loss at iteration 1560 : 0.0017943725688382983
Loss at iteration 1570 : 0.0009146732045337558
Loss at iteration 1580 : 0.002562575275078416
Loss at iteration 1590 : 0.003693629987537861
Loss at iteration 1600 : 0.00028328318148851395
Loss at iteration 1610 : 0.00014523888239637017
Loss at iteration 1620 : 0.008607029914855957
Loss at iteration 1630 : 0.0005223647458478808
Loss at iteration 1640 : 0.0018674959428608418
Loss at iteration 1650 : 0.0005537217948585749
Loss at iteration 1660 : 0.0004658928082790226
Loss at iteration 1670 : 0.000453486863989383
Loss at iteration 1680 : 4.645794615498744e-05
Loss at iteration 1690 : 5.03521368955262e-05
Loss at iteration 1700 : 0.00014983551227487624
Loss at iteration 1710 : 0.0005173527169972658
Loss at iteration 1720 : 0.00024441038840450346
Loss at iteration 1730 : 5.911499829380773e-05
Loss at iteration 1740 : 0.000200681941350922
Loss at iteration 1750 : 0.00013182447582948953
The SSIM Value is: 0.9873865489655129
The PSNR Value is: 46.76289290793667
the epoch is: 198
Loss at iteration 10 : 0.0007730084471404552
Loss at iteration 20 : 0.0010947496630251408
Loss at iteration 30 : 0.00026091578183695674
Loss at iteration 40 : 8.321202039951459e-05
Loss at iteration 50 : 0.003017464652657509
Loss at iteration 60 : 0.00311946589499712
Loss at iteration 70 : 0.00012353465717751533
Loss at iteration 80 : 0.0010462719947099686
Loss at iteration 90 : 0.00011329280823701993
Loss at iteration 100 : 0.0001911805011332035
Loss at iteration 110 : 0.00027471117209643126
Loss at iteration 120 : 0.002177879214286804
Loss at iteration 130 : 0.0030781347304582596
Loss at iteration 140 : 0.0001123475594795309
Loss at iteration 150 : 0.0004016592283733189
Loss at iteration 160 : 0.00034891642280854285
Loss at iteration 170 : 0.00020017130009364337
Loss at iteration 180 : 0.0018872693181037903
Loss at iteration 190 : 9.004526509670541e-05
Loss at iteration 200 : 0.00016826085629872978
Loss at iteration 210 : 0.0002215102140326053
Loss at iteration 220 : 0.0004249997728038579
Loss at iteration 230 : 0.0007403315976262093
Loss at iteration 240 : 0.00030252907890826464
Loss at iteration 250 : 0.0003636133624240756
Loss at iteration 260 : 0.00238503678701818
Loss at iteration 270 : 0.00011075306974817067
Loss at iteration 280 : 0.0001180302060674876
Loss at iteration 290 : 0.00019124368554912508
Loss at iteration 300 : 7.76923552621156e-05
Loss at iteration 310 : 8.512732165399939e-05
Loss at iteration 320 : 0.00048282399075105786
Loss at iteration 330 : 0.00023960565158631653
Loss at iteration 340 : 0.0032780796755105257
Loss at iteration 350 : 0.0003863641759380698
Loss at iteration 360 : 0.0026987968012690544
Loss at iteration 370 : 0.00010809377999976277
Loss at iteration 380 : 9.281562233809382e-05
Loss at iteration 390 : 0.00017166427278425545
Loss at iteration 400 : 0.0004022151115350425
Loss at iteration 410 : 0.0007404890493489802
Loss at iteration 420 : 0.00032939884113147855
Loss at iteration 430 : 0.0010589787270873785
Loss at iteration 440 : 0.00213899789378047
Loss at iteration 450 : 0.00032167285098694265
Loss at iteration 460 : 0.00014623832248616964
Loss at iteration 470 : 0.0005835549090988934
Loss at iteration 480 : 0.0020837420597672462
Loss at iteration 490 : 0.0009581646299920976
Loss at iteration 500 : 0.00010143736290046945
Loss at iteration 510 : 0.009081410244107246
Loss at iteration 520 : 0.0004436139133758843
Loss at iteration 530 : 0.0003630939463619143
Loss at iteration 540 : 0.0003451954107731581
Loss at iteration 550 : 4.6675635530846193e-05
Loss at iteration 560 : 0.006959505379199982
Loss at iteration 570 : 0.0031095650047063828
Loss at iteration 580 : 0.0009314335184171796
Loss at iteration 590 : 0.0028847199864685535
Loss at iteration 600 : 0.0017002765089273453
Loss at iteration 610 : 0.00011558417463675141
Loss at iteration 620 : 0.0027853797655552626
Loss at iteration 630 : 0.0009898795979097486
Loss at iteration 640 : 0.0004948338028043509
Loss at iteration 650 : 0.001968890894204378
Loss at iteration 660 : 0.00043278306839056313
Loss at iteration 670 : 0.0007852134294807911
Loss at iteration 680 : 0.00015563702618237585
Loss at iteration 690 : 0.0006102615734562278
Loss at iteration 700 : 0.00011310661648167297
Loss at iteration 710 : 0.00023017752391751856
Loss at iteration 720 : 0.0007753099780529737
Loss at iteration 730 : 0.0008521434501744807
Loss at iteration 740 : 0.00018285134865436703
Loss at iteration 750 : 0.00014492680202238262
Loss at iteration 760 : 0.0005238598678261042
Loss at iteration 770 : 0.0010537151247262955
Loss at iteration 780 : 0.0002488323953002691
Loss at iteration 790 : 0.0011710918042808771
Loss at iteration 800 : 0.00013167380529921502
Loss at iteration 810 : 0.0002460363321006298
Loss at iteration 820 : 0.0003539564204402268
Loss at iteration 830 : 0.0035548219457268715
Loss at iteration 840 : 0.0030022962018847466
Loss at iteration 850 : 0.0016855760477483273
Loss at iteration 860 : 0.003552317153662443
Loss at iteration 870 : 0.00027183088241145015
Loss at iteration 880 : 0.00014206366904545575
Loss at iteration 890 : 0.0019052017014473677
Loss at iteration 900 : 0.0004989707958884537
Loss at iteration 910 : 0.001946220058016479
Loss at iteration 920 : 0.0013561730738729239
Loss at iteration 930 : 0.0040341634303331375
Loss at iteration 940 : 0.0042419759556651115
Loss at iteration 950 : 0.0005605481564998627
Loss at iteration 960 : 0.001436496851965785
Loss at iteration 970 : 0.0001415103324688971
Loss at iteration 980 : 0.0026318083982914686
Loss at iteration 990 : 0.0021889498457312584
Loss at iteration 1000 : 0.00013042768114246428
Loss at iteration 1010 : 0.0005584739265032113
Loss at iteration 1020 : 0.00012835283996537328
Loss at iteration 1030 : 0.003107732627540827
Loss at iteration 1040 : 0.000416459864936769
Loss at iteration 1050 : 4.992906906409189e-05
Loss at iteration 1060 : 0.0022285052109509706
Loss at iteration 1070 : 0.00014759191253688186
Loss at iteration 1080 : 0.00020960649999324232
Loss at iteration 1090 : 0.0033297576010227203
Loss at iteration 1100 : 0.0012267578858882189
Loss at iteration 1110 : 0.0040733786299824715
Loss at iteration 1120 : 0.0009428049670532346
Loss at iteration 1130 : 0.0003000549040734768
Loss at iteration 1140 : 0.001540939905680716
Loss at iteration 1150 : 0.0007633373606950045
Loss at iteration 1160 : 0.00011407235433580354
Loss at iteration 1170 : 0.007666594814509153
Loss at iteration 1180 : 0.0007030048873275518
Loss at iteration 1190 : 7.703189476160333e-05
Loss at iteration 1200 : 0.0006389985792338848
Loss at iteration 1210 : 0.0002841547247953713
Loss at iteration 1220 : 0.0033443188294768333
Loss at iteration 1230 : 0.0007482412038370967
Loss at iteration 1240 : 0.0007289809873327613
Loss at iteration 1250 : 0.0002627623325679451
Loss at iteration 1260 : 0.001956269145011902
Loss at iteration 1270 : 0.00015739524678792804
Loss at iteration 1280 : 0.0018154671415686607
Loss at iteration 1290 : 0.00044448644621297717
Loss at iteration 1300 : 0.003196634817868471
Loss at iteration 1310 : 0.00037186621921136975
Loss at iteration 1320 : 0.0037694924976676702
Loss at iteration 1330 : 8.740808698348701e-05
Loss at iteration 1340 : 0.00043692748295143247
Loss at iteration 1350 : 0.00035309744998812675
Loss at iteration 1360 : 0.0009049073560163379
Loss at iteration 1370 : 0.00017049687448889017
Loss at iteration 1380 : 0.0031632347963750362
Loss at iteration 1390 : 7.536424527643248e-05
Loss at iteration 1400 : 0.0002138266572728753
Loss at iteration 1410 : 0.0003057483700104058
Loss at iteration 1420 : 0.0006036998238414526
Loss at iteration 1430 : 0.00026391667779535055
Loss at iteration 1440 : 0.00015743906260468066
Loss at iteration 1450 : 0.0004715707909781486
Loss at iteration 1460 : 0.0041877818293869495
Loss at iteration 1470 : 0.0002372375747654587
Loss at iteration 1480 : 0.00023602056899107993
Loss at iteration 1490 : 0.0014925170689821243
Loss at iteration 1500 : 0.00037262935074977577
Loss at iteration 1510 : 0.0008336409227922559
Loss at iteration 1520 : 0.00019563303794711828
Loss at iteration 1530 : 0.002841627923771739
Loss at iteration 1540 : 0.0003873440145980567
Loss at iteration 1550 : 0.0010313406819477677
Loss at iteration 1560 : 0.0008789162384346128
Loss at iteration 1570 : 0.00023096738732419908
Loss at iteration 1580 : 0.00029828137485310435
Loss at iteration 1590 : 5.0788432417903095e-05
Loss at iteration 1600 : 0.00017874625336844474
Loss at iteration 1610 : 0.0060552433133125305
Loss at iteration 1620 : 0.00016096622857730836
Loss at iteration 1630 : 0.00021557961008511484
Loss at iteration 1640 : 0.0020890990272164345
Loss at iteration 1650 : 0.0021867789328098297
Loss at iteration 1660 : 0.0002078684192383662
Loss at iteration 1670 : 0.0030122585594654083
Loss at iteration 1680 : 0.00040693263872526586
Loss at iteration 1690 : 0.0001265925238840282
Loss at iteration 1700 : 0.00011003440886270255
Loss at iteration 1710 : 0.00011121110583189875
Loss at iteration 1720 : 0.00013976905029267073
Loss at iteration 1730 : 0.0021049720235168934
Loss at iteration 1740 : 0.001634026411920786
Loss at iteration 1750 : 3.2500251109013334e-05
The SSIM Value is: 0.9845700458282941
The PSNR Value is: 46.55399248568497
the epoch is: 199
Loss at iteration 10 : 7.258219557115808e-05
Loss at iteration 20 : 0.00015458745474461466
Loss at iteration 30 : 0.001751570263877511
Loss at iteration 40 : 0.0001657234679441899
Loss at iteration 50 : 8.974930824479088e-05
Loss at iteration 60 : 0.002502871910110116
Loss at iteration 70 : 0.0023862163070589304
Loss at iteration 80 : 0.0008305734372697771
Loss at iteration 90 : 0.00015912094386294484
Loss at iteration 100 : 0.0001128474686993286
Loss at iteration 110 : 0.00012199846969451755
Loss at iteration 120 : 0.0001596277579665184
Loss at iteration 130 : 0.0008909442112781107
Loss at iteration 140 : 0.00032408611150458455
Loss at iteration 150 : 0.00021050713257864118
Loss at iteration 160 : 0.0003622707154136151
Loss at iteration 170 : 0.0025994540192186832
Loss at iteration 180 : 0.0002069626352749765
Loss at iteration 190 : 0.0018952891696244478
Loss at iteration 200 : 0.0003008883213624358
Loss at iteration 210 : 0.0013831639662384987
Loss at iteration 220 : 0.0002928539179265499
Loss at iteration 230 : 0.0019091495778411627
Loss at iteration 240 : 0.00017200413276441395
Loss at iteration 250 : 0.001555057941004634
Loss at iteration 260 : 0.003923260606825352
Loss at iteration 270 : 0.0027466677129268646
Loss at iteration 280 : 0.0002344556851312518
Loss at iteration 290 : 0.0001679171109572053
Loss at iteration 300 : 0.00012991011317353696
Loss at iteration 310 : 9.493943798588589e-05
Loss at iteration 320 : 0.004288697149604559
Loss at iteration 330 : 0.00033805970451794565
Loss at iteration 340 : 8.414691546931863e-05
Loss at iteration 350 : 0.0013799500884488225
Loss at iteration 360 : 4.772660759044811e-05
Loss at iteration 370 : 0.0001337009307462722
Loss at iteration 380 : 0.00013306869368534535
Loss at iteration 390 : 0.0018228229600936174
Loss at iteration 400 : 0.0013027982786297798
Loss at iteration 410 : 0.008276794105768204
Loss at iteration 420 : 0.00011007830471498892
Loss at iteration 430 : 0.0006994814611971378
Loss at iteration 440 : 0.003355553839355707
Loss at iteration 450 : 9.521865285933018e-05
Loss at iteration 460 : 0.00016778908320702612
Loss at iteration 470 : 0.00014890854072291404
Loss at iteration 480 : 0.0004904572851955891
Loss at iteration 490 : 0.0002927258610725403
Loss at iteration 500 : 0.00027441856218501925
Loss at iteration 510 : 0.00016571491141803563
Loss at iteration 520 : 0.00019813385733868927
Loss at iteration 530 : 0.00013177227810956538
Loss at iteration 540 : 7.929217099444941e-05
Loss at iteration 550 : 0.004608985502272844
Loss at iteration 560 : 0.00044484902173280716
Loss at iteration 570 : 7.975890184752643e-05
Loss at iteration 580 : 0.00483814999461174
Loss at iteration 590 : 0.008342979475855827
Loss at iteration 600 : 0.00025665643624961376
Loss at iteration 610 : 0.00014177484263200313
Loss at iteration 620 : 0.002170872874557972
Loss at iteration 630 : 0.0016066448297351599
Loss at iteration 640 : 0.0006677680066786706
Loss at iteration 650 : 7.492867734981701e-05
Loss at iteration 660 : 0.00015750713646411896
Loss at iteration 670 : 0.00010960397776216269
Loss at iteration 680 : 0.00038644991582259536
Loss at iteration 690 : 0.0031479294411838055
Loss at iteration 700 : 0.00044757494470104575
Loss at iteration 710 : 3.373594518052414e-05
Loss at iteration 720 : 5.3543793910648674e-05
Loss at iteration 730 : 0.0013956623151898384
Loss at iteration 740 : 0.0018674781313166022
Loss at iteration 750 : 0.0018235903698951006
Loss at iteration 760 : 0.0004604024870786816
Loss at iteration 770 : 7.398878369713202e-05
Loss at iteration 780 : 0.0005797011544927955
Loss at iteration 790 : 0.00012703804532065988
Loss at iteration 800 : 0.00046781435958109796
Loss at iteration 810 : 0.00047249416820704937
Loss at iteration 820 : 0.00523543544113636
Loss at iteration 830 : 0.000301913358271122
Loss at iteration 840 : 0.0007090781582519412
Loss at iteration 850 : 0.0008637059945613146
Loss at iteration 860 : 5.945508382865228e-05
Loss at iteration 870 : 0.000340586673701182
Loss at iteration 880 : 0.00010969706636387855
Loss at iteration 890 : 0.00015665558748878539
Loss at iteration 900 : 0.0007587280124425888
Loss at iteration 910 : 0.0002414920600131154
Loss at iteration 920 : 5.0751470553223044e-05
Loss at iteration 930 : 0.0002658849989529699
Loss at iteration 940 : 0.0006652059382759035
Loss at iteration 950 : 0.0001661452406551689
Loss at iteration 960 : 0.004699687007814646
Loss at iteration 970 : 0.0011701275361701846
Loss at iteration 980 : 0.0005802467931061983
Loss at iteration 990 : 0.0006381115526892245
Loss at iteration 1000 : 0.0002350262220716104
Loss at iteration 1010 : 0.0002451667678542435
Loss at iteration 1020 : 3.755598663701676e-05
Loss at iteration 1030 : 0.00011704200733220205
Loss at iteration 1040 : 5.491263800649904e-05
Loss at iteration 1050 : 0.000901485385838896
Loss at iteration 1060 : 0.00019389655790291727
Loss at iteration 1070 : 0.002120407996699214
Loss at iteration 1080 : 0.0003362108545843512
Loss at iteration 1090 : 0.000835938029922545
Loss at iteration 1100 : 0.0002429524902254343
Loss at iteration 1110 : 0.0008196912240236998
Loss at iteration 1120 : 0.0023027388378977776
Loss at iteration 1130 : 0.002460464369505644
Loss at iteration 1140 : 0.0020946762524545193
Loss at iteration 1150 : 0.000299483333947137
Loss at iteration 1160 : 0.003174321725964546
Loss at iteration 1170 : 0.00013759947614744306
Loss at iteration 1180 : 0.0006376912351697683
Loss at iteration 1190 : 0.003692818805575371
Loss at iteration 1200 : 0.0009796556551009417
Loss at iteration 1210 : 0.0007864354411140084
Loss at iteration 1220 : 0.000491368817165494
Loss at iteration 1230 : 0.0034615593031048775
Loss at iteration 1240 : 0.0029575065709650517
Loss at iteration 1250 : 0.00020645430777221918
Loss at iteration 1260 : 0.0002501492854207754
Loss at iteration 1270 : 0.0003743756387848407
Loss at iteration 1280 : 0.00042303410009481013
Loss at iteration 1290 : 0.00187356723472476
Loss at iteration 1300 : 0.0001379884488414973
Loss at iteration 1310 : 0.0018370574107393622
Loss at iteration 1320 : 0.0038155061192810535
Loss at iteration 1330 : 0.00019244456780143082
Loss at iteration 1340 : 0.0024683536030352116
Loss at iteration 1350 : 0.00015440376591868699
Loss at iteration 1360 : 0.001954467035830021
Loss at iteration 1370 : 0.0046983882784843445
Loss at iteration 1380 : 0.00017446131096221507
Loss at iteration 1390 : 0.000386113824788481
Loss at iteration 1400 : 0.0004186565929558128
Loss at iteration 1410 : 0.00026836636243388057
Loss at iteration 1420 : 0.00017740574548952281
Loss at iteration 1430 : 0.002013192744925618
Loss at iteration 1440 : 0.00026096339570358396
Loss at iteration 1450 : 0.00041527533903717995
Loss at iteration 1460 : 0.0005183677421882749
Loss at iteration 1470 : 0.002489052712917328
Loss at iteration 1480 : 0.00011788526171585545
Loss at iteration 1490 : 0.0016123868990689516
Loss at iteration 1500 : 0.0010405931388959289
Loss at iteration 1510 : 4.963132232660428e-05
Loss at iteration 1520 : 0.0018002070719376206
Loss at iteration 1530 : 0.00045292708091437817
Loss at iteration 1540 : 0.00012398039689287543
Loss at iteration 1550 : 5.007045911042951e-05
Loss at iteration 1560 : 0.00011557829566299915
Loss at iteration 1570 : 0.0029168345499783754
Loss at iteration 1580 : 0.000334314740030095
Loss at iteration 1590 : 0.002021078485995531
Loss at iteration 1600 : 0.0015718264039605856
Loss at iteration 1610 : 0.00041695774416439235
Loss at iteration 1620 : 0.000443560624262318
Loss at iteration 1630 : 9.833781223278493e-05
Loss at iteration 1640 : 0.00017141099669970572
Loss at iteration 1650 : 0.00036101535079069436
Loss at iteration 1660 : 0.0009133221465162933
Loss at iteration 1670 : 0.000671366520691663
Loss at iteration 1680 : 0.0001704421010799706
Loss at iteration 1690 : 0.002705243183299899
Loss at iteration 1700 : 0.0005363349337130785
Loss at iteration 1710 : 0.0012181797064840794
Loss at iteration 1720 : 0.00030673248693346977
Loss at iteration 1730 : 0.0005122324218973517
Loss at iteration 1740 : 0.00031225476413965225
Loss at iteration 1750 : 5.594638059847057e-05
The SSIM Value is: 0.9855907892865756
The PSNR Value is: 46.66709256697331
the epoch is: 200
Loss at iteration 10 : 6.164829392218962e-05
Loss at iteration 20 : 0.00041271315421909094
Loss at iteration 30 : 0.00010275559179717675
Loss at iteration 40 : 0.0018408936448395252
Loss at iteration 50 : 0.002653198316693306
Loss at iteration 60 : 0.001096575753763318
Loss at iteration 70 : 0.0006226060795597732
Loss at iteration 80 : 0.0005985828465782106
Loss at iteration 90 : 0.000805134535767138
Loss at iteration 100 : 8.212188549805433e-05
Loss at iteration 110 : 0.0002920880215242505
Loss at iteration 120 : 0.0006199644412845373
Loss at iteration 130 : 0.0003432758676353842
Loss at iteration 140 : 0.0006164266378618777
Loss at iteration 150 : 0.00014370898134075105
Loss at iteration 160 : 0.000364383653504774
Loss at iteration 170 : 0.00011281576007604599
Loss at iteration 180 : 0.0023555683437734842
Loss at iteration 190 : 0.00044884817907586694
Loss at iteration 200 : 0.0007187458104453981
Loss at iteration 210 : 0.004855882842093706
Loss at iteration 220 : 0.00017465927521698177
Loss at iteration 230 : 0.003414550796151161
Loss at iteration 240 : 0.00013876435696147382
Loss at iteration 250 : 0.00016024048090912402
Loss at iteration 260 : 0.00040313773206435144
Loss at iteration 270 : 0.0005360491340979934
Loss at iteration 280 : 0.005031878594309092
Loss at iteration 290 : 4.266271571395919e-05
Loss at iteration 300 : 0.0021807048469781876
Loss at iteration 310 : 9.95737427729182e-05
Loss at iteration 320 : 0.0007576870266348124
Loss at iteration 330 : 0.000737262424081564
Loss at iteration 340 : 0.0008323709480464458
Loss at iteration 350 : 0.0032529360614717007
Loss at iteration 360 : 0.0003916617715731263
Loss at iteration 370 : 0.003122839378193021
Loss at iteration 380 : 0.00012490017979871482
Loss at iteration 390 : 0.00011706566147040576
Loss at iteration 400 : 0.00043034745613113046
Loss at iteration 410 : 0.00013842721818946302
Loss at iteration 420 : 0.0002251323458040133
Loss at iteration 430 : 0.00011262336192885414
Loss at iteration 440 : 0.0002476050576660782
Loss at iteration 450 : 0.004411623347550631
Loss at iteration 460 : 0.002769009442999959
Loss at iteration 470 : 6.715019844705239e-05
Loss at iteration 480 : 0.002384306164458394
Loss at iteration 490 : 0.0003836160176433623
Loss at iteration 500 : 0.00016544632671866566
Loss at iteration 510 : 0.0006608688272535801
Loss at iteration 520 : 0.00028937007300555706
Loss at iteration 530 : 0.00042731582652777433
Loss at iteration 540 : 0.00035849539563059807
Loss at iteration 550 : 0.0010007114615291357
Loss at iteration 560 : 0.0008788724662736058
Loss at iteration 570 : 0.0019764797762036324
Loss at iteration 580 : 0.0007878840551711619
Loss at iteration 590 : 0.00017869095609057695
Loss at iteration 600 : 0.0006025682669132948
Loss at iteration 610 : 0.00021035506506450474
Loss at iteration 620 : 0.0007090512663125992
Loss at iteration 630 : 0.0005061880801804364
Loss at iteration 640 : 0.00040846248157322407
Loss at iteration 650 : 0.00017402223602402955
Loss at iteration 660 : 0.0032221460714936256
Loss at iteration 670 : 0.00016108847921714187
Loss at iteration 680 : 0.0015253424644470215
Loss at iteration 690 : 0.0002003931294893846
Loss at iteration 700 : 6.571416452061385e-05
Loss at iteration 710 : 0.002663204213604331
Loss at iteration 720 : 0.0005794364842586219
Loss at iteration 730 : 0.00016158308426383883
Loss at iteration 740 : 0.0006521950126625597
Loss at iteration 750 : 0.0032411343418061733
Loss at iteration 760 : 0.000309454946545884
Loss at iteration 770 : 6.050793672329746e-05
Loss at iteration 780 : 0.0004756110138259828
Loss at iteration 790 : 0.00010283563460689038
Loss at iteration 800 : 0.00022247526794672012
Loss at iteration 810 : 0.0005464689456857741
Loss at iteration 820 : 0.0006325156427919865
Loss at iteration 830 : 0.0001165715220849961
Loss at iteration 840 : 0.0010946022812277079
Loss at iteration 850 : 0.0005192238604649901
Loss at iteration 860 : 0.00011410031584091485
Loss at iteration 870 : 0.0030485927127301693
Loss at iteration 880 : 0.0006601748173125088
Loss at iteration 890 : 0.0004504393436945975
Loss at iteration 900 : 0.0001381736365146935
Loss at iteration 910 : 0.00020782486535608768
Loss at iteration 920 : 0.00013274131924845278
Loss at iteration 930 : 0.0002555830869823694
Loss at iteration 940 : 0.0003896041598636657
Loss at iteration 950 : 0.002392557682469487
Loss at iteration 960 : 0.0009797813836485147
Loss at iteration 970 : 0.00016445000073872507
Loss at iteration 980 : 0.002448256593197584
Loss at iteration 990 : 0.005365549586713314
Loss at iteration 1000 : 0.00027103041065856814
Loss at iteration 1010 : 0.0001816000003600493
Loss at iteration 1020 : 0.0028092660941183567
Loss at iteration 1030 : 0.0009322294499725103
Loss at iteration 1040 : 0.0032344372011721134
Loss at iteration 1050 : 0.0005656710127368569
Loss at iteration 1060 : 0.00023476679052691907
Loss at iteration 1070 : 0.00028858165023848414
Loss at iteration 1080 : 0.0005282651982270181
Loss at iteration 1090 : 0.0002873209596145898
Loss at iteration 1100 : 0.00023912207689136267
Loss at iteration 1110 : 0.00030589630478061736
Loss at iteration 1120 : 0.0029545496217906475
Loss at iteration 1130 : 0.0001769666123436764
Loss at iteration 1140 : 0.0008747676038183272
Loss at iteration 1150 : 5.926092489971779e-05
Loss at iteration 1160 : 0.0007299873395822942
Loss at iteration 1170 : 0.0022623969707638025
Loss at iteration 1180 : 0.0012662754161283374
Loss at iteration 1190 : 3.617376205511391e-05
Loss at iteration 1200 : 0.0009642690420150757
Loss at iteration 1210 : 0.00011688626545947045
Loss at iteration 1220 : 0.0004873542347922921
Loss at iteration 1230 : 0.005701836664229631
Loss at iteration 1240 : 0.0002675516880117357
Loss at iteration 1250 : 0.0002593858225736767
Loss at iteration 1260 : 0.0002051411720458418
Loss at iteration 1270 : 0.00014329617260955274
Loss at iteration 1280 : 0.003690481185913086
Loss at iteration 1290 : 0.0005482084234245121
Loss at iteration 1300 : 0.00016839288582559675
Loss at iteration 1310 : 0.0006298986845649779
Loss at iteration 1320 : 0.003045913763344288
Loss at iteration 1330 : 0.00023326976224780083
Loss at iteration 1340 : 0.0001183914573630318
Loss at iteration 1350 : 5.2407638577278703e-05
Loss at iteration 1360 : 0.0005614092806354165
Loss at iteration 1370 : 0.0006371103227138519
Loss at iteration 1380 : 0.0004392516566440463
Loss at iteration 1390 : 0.0004956218181177974
Loss at iteration 1400 : 0.0001353779953205958
Loss at iteration 1410 : 0.00037648173747584224
Loss at iteration 1420 : 7.621119584655389e-05
Loss at iteration 1430 : 9.098432929022238e-05
Loss at iteration 1440 : 0.00011538804392330348
Loss at iteration 1450 : 0.00013469831901602447
Loss at iteration 1460 : 0.00016157033678609878
Loss at iteration 1470 : 0.0005875771748833358
Loss at iteration 1480 : 0.0010419038590043783
Loss at iteration 1490 : 0.0071762981824576855
Loss at iteration 1500 : 0.00012175351730547845
Loss at iteration 1510 : 0.00012061337474733591
Loss at iteration 1520 : 0.0008091966155916452
Loss at iteration 1530 : 0.000892851734533906
Loss at iteration 1540 : 0.0002426179125905037
Loss at iteration 1550 : 6.65928891976364e-05
Loss at iteration 1560 : 0.0010807040380313993
Loss at iteration 1570 : 0.000742301344871521
Loss at iteration 1580 : 8.95966513780877e-05
Loss at iteration 1590 : 0.001174355624243617
Loss at iteration 1600 : 0.0003422738518565893
Loss at iteration 1610 : 0.0032328644301742315
Loss at iteration 1620 : 0.0003833989321719855
Loss at iteration 1630 : 0.0006487801438197494
Loss at iteration 1640 : 0.00040143169462680817
Loss at iteration 1650 : 0.001134699210524559
Loss at iteration 1660 : 0.0031249530147761106
Loss at iteration 1670 : 0.000262921821558848
Loss at iteration 1680 : 0.0002805449767038226
Loss at iteration 1690 : 0.0001527270069345832
Loss at iteration 1700 : 0.0011124167358502746
Loss at iteration 1710 : 0.0007471749559044838
Loss at iteration 1720 : 0.00265682814642787
Loss at iteration 1730 : 0.0003823647857643664
Loss at iteration 1740 : 0.003990629687905312
Loss at iteration 1750 : 0.0005892517510801554
The SSIM Value is: 0.9860645758422986
The PSNR Value is: 46.43762387263092
the epoch is: 201
Loss at iteration 10 : 0.0004545921110548079
Loss at iteration 20 : 0.0037142494693398476
Loss at iteration 30 : 0.0026850199792534113
Loss at iteration 40 : 0.0024872159119695425
Loss at iteration 50 : 0.002822315087541938
Loss at iteration 60 : 0.00022670536418445408
Loss at iteration 70 : 0.00013176562788430601
Loss at iteration 80 : 0.00021606162772513926
Loss at iteration 90 : 0.0008829811122268438
Loss at iteration 100 : 0.0017202718881890178
Loss at iteration 110 : 0.0002656269061844796
Loss at iteration 120 : 0.00014612273662351072
Loss at iteration 130 : 0.000143909128382802
Loss at iteration 140 : 0.00027124464395456016
Loss at iteration 150 : 5.0408732931828126e-05
Loss at iteration 160 : 4.799854650627822e-05
Loss at iteration 170 : 0.0005506975576281548
Loss at iteration 180 : 0.000576711434405297
Loss at iteration 190 : 0.0005194075056351721
Loss at iteration 200 : 0.0006317703519016504
Loss at iteration 210 : 0.0006079942104406655
Loss at iteration 220 : 0.002791773760691285
Loss at iteration 230 : 7.785340130794793e-05
Loss at iteration 240 : 0.0022926474921405315
Loss at iteration 250 : 0.0006252985331229866
Loss at iteration 260 : 0.001177966594696045
Loss at iteration 270 : 0.00048263330245390534
Loss at iteration 280 : 0.0001711360819172114
Loss at iteration 290 : 0.00048135087126865983
Loss at iteration 300 : 0.0007347564678639174
Loss at iteration 310 : 0.0002473251079209149
Loss at iteration 320 : 0.001474794582463801
Loss at iteration 330 : 0.0025112242437899113
Loss at iteration 340 : 0.0005750386626459658
Loss at iteration 350 : 7.799370359862223e-05
Loss at iteration 360 : 0.00024868693435564637
Loss at iteration 370 : 0.0005001501995138824
Loss at iteration 380 : 0.002064687665551901
Loss at iteration 390 : 0.002630108967423439
Loss at iteration 400 : 0.0007414191495627165
Loss at iteration 410 : 0.00013950075663160533
Loss at iteration 420 : 0.0007976987399160862
Loss at iteration 430 : 0.004322873428463936
Loss at iteration 440 : 0.0006260117515921593
Loss at iteration 450 : 0.0002940812846645713
Loss at iteration 460 : 0.0010927955154329538
Loss at iteration 470 : 0.00021756246860604733
Loss at iteration 480 : 0.0002760459028650075
Loss at iteration 490 : 0.00030689092818647623
Loss at iteration 500 : 0.0012805000878870487
Loss at iteration 510 : 0.000787392957136035
Loss at iteration 520 : 5.174347825231962e-05
Loss at iteration 530 : 0.0011647932697087526
Loss at iteration 540 : 0.0003468317736405879
Loss at iteration 550 : 0.001175489742308855
Loss at iteration 560 : 0.0014020341914147139
Loss at iteration 570 : 7.856050797272474e-05
Loss at iteration 580 : 0.0003549549728631973
Loss at iteration 590 : 0.0027067738119512796
Loss at iteration 600 : 0.0017898362129926682
Loss at iteration 610 : 8.316470484714955e-05
Loss at iteration 620 : 0.000142927368870005
Loss at iteration 630 : 0.0002995699178427458
Loss at iteration 640 : 0.0002087944303639233
Loss at iteration 650 : 0.00020960342953912914
Loss at iteration 660 : 0.0008558171102777123
Loss at iteration 670 : 0.00039420899702236056
Loss at iteration 680 : 0.00018227979307994246
Loss at iteration 690 : 0.00012666784459725022
Loss at iteration 700 : 0.002482643350958824
Loss at iteration 710 : 4.963648461853154e-05
Loss at iteration 720 : 0.00034120428608730435
Loss at iteration 730 : 0.0015557208098471165
Loss at iteration 740 : 0.0002636487188283354
Loss at iteration 750 : 6.868856871733442e-05
Loss at iteration 760 : 0.002286297734826803
Loss at iteration 770 : 0.003972677513957024
Loss at iteration 780 : 0.0003574694273993373
Loss at iteration 790 : 0.00011223365436308086
Loss at iteration 800 : 0.00021518400171771646
Loss at iteration 810 : 0.0002152168017346412
Loss at iteration 820 : 0.00015970240929163992
Loss at iteration 830 : 8.796684414846823e-05
Loss at iteration 840 : 0.00030887959292158484
Loss at iteration 850 : 0.0002581427397672087
Loss at iteration 860 : 0.0004452633438631892
Loss at iteration 870 : 0.00320690986700356
Loss at iteration 880 : 0.00012588001845870167
Loss at iteration 890 : 0.008780166506767273
Loss at iteration 900 : 0.0002079857949865982
Loss at iteration 910 : 5.55088663531933e-05
Loss at iteration 920 : 0.0029102060943841934
Loss at iteration 930 : 0.0026510274037718773
Loss at iteration 940 : 0.001186861889436841
Loss at iteration 950 : 0.003640520153567195
Loss at iteration 960 : 0.00028220858075655997
Loss at iteration 970 : 0.0009355726651847363
Loss at iteration 980 : 0.00015948846703395247
Loss at iteration 990 : 0.00020654192485380918
Loss at iteration 1000 : 0.0001539646473247558
Loss at iteration 1010 : 0.00026729784440249205
Loss at iteration 1020 : 0.0002334427263122052
Loss at iteration 1030 : 0.0022553512826561928
Loss at iteration 1040 : 0.0004439554177224636
Loss at iteration 1050 : 0.000435116293374449
Loss at iteration 1060 : 0.0023702490143477917
Loss at iteration 1070 : 0.000668330816552043
Loss at iteration 1080 : 0.00015799074026290327
Loss at iteration 1090 : 0.00037153108860366046
Loss at iteration 1100 : 9.956757276086137e-05
Loss at iteration 1110 : 0.00011700199684128165
Loss at iteration 1120 : 0.003170813899487257
Loss at iteration 1130 : 0.00020454180776141584
Loss at iteration 1140 : 0.0002069877227768302
Loss at iteration 1150 : 0.00040295414510183036
Loss at iteration 1160 : 8.687932859174907e-05
Loss at iteration 1170 : 0.00016925418458413333
Loss at iteration 1180 : 0.00260655558668077
Loss at iteration 1190 : 0.0019078959012404084
Loss at iteration 1200 : 0.0006464970065280795
Loss at iteration 1210 : 0.003507229732349515
Loss at iteration 1220 : 0.0002943381841760129
Loss at iteration 1230 : 0.00026696239365264773
Loss at iteration 1240 : 0.0005404794355854392
Loss at iteration 1250 : 0.003004786092787981
Loss at iteration 1260 : 0.0013891984708607197
Loss at iteration 1270 : 0.0003030880761798471
Loss at iteration 1280 : 0.000249648408498615
Loss at iteration 1290 : 0.00010850215039681643
Loss at iteration 1300 : 0.0003638541675172746
Loss at iteration 1310 : 0.0004385259817354381
Loss at iteration 1320 : 0.00040497444570064545
Loss at iteration 1330 : 0.00023989549663383514
Loss at iteration 1340 : 0.0002963690785691142
Loss at iteration 1350 : 0.00012428683112375438
Loss at iteration 1360 : 0.004461499396711588
Loss at iteration 1370 : 0.00016148758004419506
Loss at iteration 1380 : 0.0010281297145411372
Loss at iteration 1390 : 0.0014511281624436378
Loss at iteration 1400 : 0.0003739225212484598
Loss at iteration 1410 : 0.000205440039280802
Loss at iteration 1420 : 0.00021548420772887766
Loss at iteration 1430 : 8.723554492462426e-05
Loss at iteration 1440 : 0.00028134509921073914
Loss at iteration 1450 : 0.005848485976457596
Loss at iteration 1460 : 0.0001426899980287999
Loss at iteration 1470 : 0.0005981230642646551
Loss at iteration 1480 : 0.00017622284940443933
Loss at iteration 1490 : 0.00042796003981493413
Loss at iteration 1500 : 0.0020043011754751205
Loss at iteration 1510 : 0.00018072866078000516
Loss at iteration 1520 : 0.0002753153385128826
Loss at iteration 1530 : 0.0003839593264274299
Loss at iteration 1540 : 7.308886415557936e-05
Loss at iteration 1550 : 0.00035019591450691223
Loss at iteration 1560 : 0.0024076788686215878
Loss at iteration 1570 : 0.00019617742509581149
Loss at iteration 1580 : 0.00015812406491022557
Loss at iteration 1590 : 0.0009179794578813016
Loss at iteration 1600 : 0.0007470886339433491
Loss at iteration 1610 : 0.0014155569951981306
Loss at iteration 1620 : 0.00015430642815772444
Loss at iteration 1630 : 0.00021821362315677106
Loss at iteration 1640 : 0.000270461430773139
Loss at iteration 1650 : 0.00016637977387290448
Loss at iteration 1660 : 0.003001453587785363
Loss at iteration 1670 : 0.000228953649639152
Loss at iteration 1680 : 0.0026190762873739004
Loss at iteration 1690 : 0.003879316383972764
Loss at iteration 1700 : 0.002013917313888669
Loss at iteration 1710 : 0.00044908170821145177
Loss at iteration 1720 : 0.0007485653040930629
Loss at iteration 1730 : 0.003610301064327359
Loss at iteration 1740 : 0.006065220572054386
Loss at iteration 1750 : 0.00023473786131944507
The SSIM Value is: 0.9836999986665365
The PSNR Value is: 46.19689467719998
the epoch is: 202
Loss at iteration 10 : 0.0001751440140651539
Loss at iteration 20 : 0.00025049649411812425
Loss at iteration 30 : 0.004076406359672546
Loss at iteration 40 : 0.0001465286040911451
Loss at iteration 50 : 0.00024537506396882236
Loss at iteration 60 : 0.0004898793995380402
Loss at iteration 70 : 0.00019548789714463055
Loss at iteration 80 : 0.004403943661600351
Loss at iteration 90 : 0.001401746179908514
Loss at iteration 100 : 0.0005535327945835888
Loss at iteration 110 : 0.002867208095267415
Loss at iteration 120 : 0.0014712319243699312
Loss at iteration 130 : 0.0002921142731793225
Loss at iteration 140 : 0.00039182318141683936
Loss at iteration 150 : 0.0005978328408673406
Loss at iteration 160 : 0.003403660375624895
Loss at iteration 170 : 0.0006007381598465145
Loss at iteration 180 : 0.00011051414185203612
Loss at iteration 190 : 0.0015609599649906158
Loss at iteration 200 : 0.00013659361866302788
Loss at iteration 210 : 6.538041634485126e-05
Loss at iteration 220 : 0.0006008078344166279
Loss at iteration 230 : 0.00018066023767460138
Loss at iteration 240 : 5.21406254847534e-05
Loss at iteration 250 : 9.334579954156652e-05
Loss at iteration 260 : 0.0011538512771949172
Loss at iteration 270 : 0.00016078510088846087
Loss at iteration 280 : 0.0006500415620394051
Loss at iteration 290 : 0.0002692544076126069
Loss at iteration 300 : 0.0002649085072334856
Loss at iteration 310 : 0.00037439254811033607
Loss at iteration 320 : 0.00015003251610323787
Loss at iteration 330 : 0.00028582208324223757
Loss at iteration 340 : 0.001090510399080813
Loss at iteration 350 : 0.0002950877242255956
Loss at iteration 360 : 0.00022379145957529545
Loss at iteration 370 : 0.002162940800189972
Loss at iteration 380 : 0.00016116492042783648
Loss at iteration 390 : 0.00042393291369080544
Loss at iteration 400 : 0.000616298639215529
Loss at iteration 410 : 0.003433658042922616
Loss at iteration 420 : 6.483643664978445e-05
Loss at iteration 430 : 0.00019385013729333878
Loss at iteration 440 : 3.9466329326387495e-05
Loss at iteration 450 : 0.0014207909116521478
Loss at iteration 460 : 0.00020544447761494666
Loss at iteration 470 : 0.0003633950836956501
Loss at iteration 480 : 0.0001485020329710096
Loss at iteration 490 : 0.0020328741520643234
Loss at iteration 500 : 0.00015391374472528696
Loss at iteration 510 : 0.0029585130978375673
Loss at iteration 520 : 0.0027602200862020254
Loss at iteration 530 : 0.00017214438412338495
Loss at iteration 540 : 0.0034584272652864456
Loss at iteration 550 : 0.003918861970305443
Loss at iteration 560 : 0.00023052503820508718
Loss at iteration 570 : 0.000191428218386136
Loss at iteration 580 : 0.00035176900564692914
Loss at iteration 590 : 0.00014987558824941516
Loss at iteration 600 : 0.0002363439416512847
Loss at iteration 610 : 0.0005642977776005864
Loss at iteration 620 : 0.0028099720366299152
Loss at iteration 630 : 0.0003669235447887331
Loss at iteration 640 : 0.00011955032096011564
Loss at iteration 650 : 0.002576212864369154
Loss at iteration 660 : 0.0014602580340579152
Loss at iteration 670 : 0.0011190399527549744
Loss at iteration 680 : 0.004504098556935787
Loss at iteration 690 : 7.46064106351696e-05
Loss at iteration 700 : 0.00048510037595406175
Loss at iteration 710 : 3.1459941965295e-05
Loss at iteration 720 : 0.0013854706194251776
Loss at iteration 730 : 0.0001107284115278162
Loss at iteration 740 : 0.0005487874150276184
Loss at iteration 750 : 8.784820965956897e-05
Loss at iteration 760 : 0.004000019282102585
Loss at iteration 770 : 0.0003550370456650853
Loss at iteration 780 : 0.0010353843681514263
Loss at iteration 790 : 0.001668586628511548
Loss at iteration 800 : 6.945675704628229e-05
Loss at iteration 810 : 0.004898423328995705
Loss at iteration 820 : 0.00017737376037985086
Loss at iteration 830 : 9.13046023924835e-05
Loss at iteration 840 : 0.0008962643332779408
Loss at iteration 850 : 5.858176155015826e-05
Loss at iteration 860 : 6.658087659161538e-05
Loss at iteration 870 : 0.0028080870397388935
Loss at iteration 880 : 0.0003032919194083661
Loss at iteration 890 : 0.0002445465070195496
Loss at iteration 900 : 0.000139833617140539
Loss at iteration 910 : 0.0021330630406737328
Loss at iteration 920 : 0.0002603376342449337
Loss at iteration 930 : 0.0006742008263245225
Loss at iteration 940 : 0.0002790103026200086
Loss at iteration 950 : 0.0016059210756793618
Loss at iteration 960 : 0.000196721768588759
Loss at iteration 970 : 0.001276363618671894
Loss at iteration 980 : 0.00019831130339298397
Loss at iteration 990 : 0.0013337956042960286
Loss at iteration 1000 : 0.0003064312331844121
Loss at iteration 1010 : 0.0006353555945679545
Loss at iteration 1020 : 0.0037656761705875397
Loss at iteration 1030 : 8.266598160844296e-05
Loss at iteration 1040 : 0.0001459956110920757
Loss at iteration 1050 : 0.00012364691065158695
Loss at iteration 1060 : 0.00016068699187599123
Loss at iteration 1070 : 0.0008303135982714593
Loss at iteration 1080 : 0.0033243964426219463
Loss at iteration 1090 : 0.00011973304208368063
Loss at iteration 1100 : 0.0006928418879397213
Loss at iteration 1110 : 0.0002665181818883866
Loss at iteration 1120 : 0.0001221606944454834
Loss at iteration 1130 : 0.00023893800971563905
Loss at iteration 1140 : 0.0005292839487083256
Loss at iteration 1150 : 0.0002938471734523773
Loss at iteration 1160 : 0.004084967542439699
Loss at iteration 1170 : 0.002300833584740758
Loss at iteration 1180 : 0.0018151482800021768
Loss at iteration 1190 : 0.00027130654780194163
Loss at iteration 1200 : 6.359265535138547e-05
Loss at iteration 1210 : 0.001573343062773347
Loss at iteration 1220 : 5.077644163975492e-05
Loss at iteration 1230 : 8.526144665665925e-05
Loss at iteration 1240 : 6.062100874260068e-05
Loss at iteration 1250 : 0.0001832446432672441
Loss at iteration 1260 : 0.0005780175561085343
Loss at iteration 1270 : 0.002054258482530713
Loss at iteration 1280 : 0.000589798204600811
Loss at iteration 1290 : 9.411772043677047e-05
Loss at iteration 1300 : 0.00296309357509017
Loss at iteration 1310 : 0.00028072696295566857
Loss at iteration 1320 : 0.00024315982591360807
Loss at iteration 1330 : 0.0011950416956096888
Loss at iteration 1340 : 0.0026145316660404205
Loss at iteration 1350 : 0.0038591434713453054
Loss at iteration 1360 : 0.00011027703294530511
Loss at iteration 1370 : 0.0006966170622035861
Loss at iteration 1380 : 0.002400596858933568
Loss at iteration 1390 : 0.00020105144358240068
Loss at iteration 1400 : 0.004795679356902838
Loss at iteration 1410 : 0.0017133001238107681
Loss at iteration 1420 : 0.000518067623488605
Loss at iteration 1430 : 0.00021036624093540013
Loss at iteration 1440 : 0.0004042935324832797
Loss at iteration 1450 : 0.00014647177886217833
Loss at iteration 1460 : 0.0005656177527271211
Loss at iteration 1470 : 5.841528400196694e-05
Loss at iteration 1480 : 0.00035755481803789735
Loss at iteration 1490 : 0.0005696131847798824
Loss at iteration 1500 : 0.00020447923452593386
Loss at iteration 1510 : 0.0003047723148483783
Loss at iteration 1520 : 0.0037777586840093136
Loss at iteration 1530 : 0.006531251594424248
Loss at iteration 1540 : 0.00018659848137758672
Loss at iteration 1550 : 0.000831223267596215
Loss at iteration 1560 : 0.00014491035835817456
Loss at iteration 1570 : 0.0029958761297166348
Loss at iteration 1580 : 0.0002586901537142694
Loss at iteration 1590 : 0.0004484580713324249
Loss at iteration 1600 : 0.004194437991827726
Loss at iteration 1610 : 0.0004871920682489872
Loss at iteration 1620 : 0.0002509392215870321
Loss at iteration 1630 : 0.001959463581442833
Loss at iteration 1640 : 0.00017515559738967568
Loss at iteration 1650 : 0.00033243943471461535
Loss at iteration 1660 : 0.0008365954272449017
Loss at iteration 1670 : 0.0002551260113250464
Loss at iteration 1680 : 0.0013116541085764766
Loss at iteration 1690 : 0.0006869370699860156
Loss at iteration 1700 : 4.9363643483957276e-05
Loss at iteration 1710 : 0.0001959750079549849
Loss at iteration 1720 : 0.0001859768817666918
Loss at iteration 1730 : 9.3178401584737e-05
Loss at iteration 1740 : 0.0001170704053947702
Loss at iteration 1750 : 0.00012207972758915275
The SSIM Value is: 0.989181612819302
The PSNR Value is: 46.73576363382885
the epoch is: 203
Loss at iteration 10 : 0.001217818120494485
Loss at iteration 20 : 0.0004439194453880191
Loss at iteration 30 : 0.00012811394117306918
Loss at iteration 40 : 0.00015020809951238334
Loss at iteration 50 : 0.00018909764185082167
Loss at iteration 60 : 0.00012947525829076767
Loss at iteration 70 : 0.0035074520856142044
Loss at iteration 80 : 0.00036153814289718866
Loss at iteration 90 : 0.001750516821630299
Loss at iteration 100 : 0.0002568505296949297
Loss at iteration 110 : 0.0023829105775803328
Loss at iteration 120 : 0.0010655808728188276
Loss at iteration 130 : 0.00010596222273306921
Loss at iteration 140 : 0.000139712356030941
Loss at iteration 150 : 0.00024919616407714784
Loss at iteration 160 : 0.001605624333024025
Loss at iteration 170 : 2.878119448723737e-05
Loss at iteration 180 : 0.00035251647932454944
Loss at iteration 190 : 0.00015204609371721745
Loss at iteration 200 : 0.00010282366565661505
Loss at iteration 210 : 0.00020693388069048524
Loss at iteration 220 : 0.00010521639342186972
Loss at iteration 230 : 0.00019561445515137166
Loss at iteration 240 : 0.0010920378845185041
Loss at iteration 250 : 9.792732453206554e-05
Loss at iteration 260 : 4.743312456412241e-05
Loss at iteration 270 : 0.00021739344811066985
Loss at iteration 280 : 7.202131382655352e-05
Loss at iteration 290 : 0.0008086813031695783
Loss at iteration 300 : 0.00012149559915997088
Loss at iteration 310 : 0.0003387170727364719
Loss at iteration 320 : 0.0008618272840976715
Loss at iteration 330 : 0.0015476623084396124
Loss at iteration 340 : 0.0016882336931303144
Loss at iteration 350 : 0.00028286041924729943
Loss at iteration 360 : 0.0035758763551712036
Loss at iteration 370 : 0.00027739969664253294
Loss at iteration 380 : 0.00034034959389828146
Loss at iteration 390 : 0.00971479807049036
Loss at iteration 400 : 0.0001618754758965224
Loss at iteration 410 : 0.00010469212429597974
Loss at iteration 420 : 0.0007116557681001723
Loss at iteration 430 : 0.00025338889099657536
Loss at iteration 440 : 0.000370878231478855
Loss at iteration 450 : 0.00012402288848534226
Loss at iteration 460 : 6.868713535368443e-05
Loss at iteration 470 : 0.00032380118500441313
Loss at iteration 480 : 0.0025106058456003666
Loss at iteration 490 : 0.0005721010384149849
Loss at iteration 500 : 4.2375060729682446e-05
Loss at iteration 510 : 0.002477895235642791
Loss at iteration 520 : 0.0014233819674700499
Loss at iteration 530 : 0.0004518188361544162
Loss at iteration 540 : 0.00012236980546731502
Loss at iteration 550 : 0.0027949947398155928
Loss at iteration 560 : 0.0027198551688343287
Loss at iteration 570 : 7.735002873232588e-05
Loss at iteration 580 : 0.001039633178152144
Loss at iteration 590 : 0.0001183781714644283
Loss at iteration 600 : 0.0027563474141061306
Loss at iteration 610 : 0.0005357027985155582
Loss at iteration 620 : 5.5397966207237914e-05
Loss at iteration 630 : 0.0005935600493103266
Loss at iteration 640 : 0.0030386694706976414
Loss at iteration 650 : 0.00010714166273828596
Loss at iteration 660 : 0.00010444074723636732
Loss at iteration 670 : 0.0002905268338508904
Loss at iteration 680 : 0.00030560241430066526
Loss at iteration 690 : 0.00017935429059434682
Loss at iteration 700 : 5.2887608035234734e-05
Loss at iteration 710 : 0.0010248246835544705
Loss at iteration 720 : 0.000877326587215066
Loss at iteration 730 : 0.000147734084748663
Loss at iteration 740 : 6.906838098075241e-05
Loss at iteration 750 : 0.0002632022078614682
Loss at iteration 760 : 0.00013102793309371918
Loss at iteration 770 : 0.00022154039470478892
Loss at iteration 780 : 0.002268860349431634
Loss at iteration 790 : 0.00036803263355977833
Loss at iteration 800 : 8.003885886864737e-05
Loss at iteration 810 : 0.0009701291564851999
Loss at iteration 820 : 0.00045899651013314724
Loss at iteration 830 : 0.00019552990852389485
Loss at iteration 840 : 0.0002503975701984018
Loss at iteration 850 : 0.00014956784434616566
Loss at iteration 860 : 0.0012087097857147455
Loss at iteration 870 : 5.0971277232747525e-05
Loss at iteration 880 : 0.00015084241749718785
Loss at iteration 890 : 0.00010995115735568106
Loss at iteration 900 : 0.00021625313092954457
Loss at iteration 910 : 0.0021561288740485907
Loss at iteration 920 : 9.147982927970588e-05
Loss at iteration 930 : 0.00029908507713116705
Loss at iteration 940 : 0.00017250035307370126
Loss at iteration 950 : 0.00041755661368370056
Loss at iteration 960 : 0.0012162862112745643
Loss at iteration 970 : 0.00013148842845112085
Loss at iteration 980 : 0.0001280213618883863
Loss at iteration 990 : 0.00037900099414400756
Loss at iteration 1000 : 0.0001281508302781731
Loss at iteration 1010 : 7.343987817876041e-05
Loss at iteration 1020 : 0.013851499184966087
Loss at iteration 1030 : 0.0002606934285722673
Loss at iteration 1040 : 0.00016525540559086949
Loss at iteration 1050 : 0.0004441605706233531
Loss at iteration 1060 : 0.0002510877966415137
Loss at iteration 1070 : 8.551442442694679e-05
Loss at iteration 1080 : 0.00016500128549523652
Loss at iteration 1090 : 0.00209358474239707
Loss at iteration 1100 : 8.677242294652387e-05
Loss at iteration 1110 : 0.0007765537593513727
Loss at iteration 1120 : 0.00014228498912416399
Loss at iteration 1130 : 0.002870489377528429
Loss at iteration 1140 : 0.002486584009602666
Loss at iteration 1150 : 0.0026991302147507668
Loss at iteration 1160 : 0.0008558722911402583
Loss at iteration 1170 : 6.564694922417402e-05
Loss at iteration 1180 : 0.00484067015349865
Loss at iteration 1190 : 0.0002131726942025125
Loss at iteration 1200 : 0.0002888835733756423
Loss at iteration 1210 : 0.0037046100478619337
Loss at iteration 1220 : 0.0026416347827762365
Loss at iteration 1230 : 0.00042077607940882444
Loss at iteration 1240 : 4.4129312300356105e-05
Loss at iteration 1250 : 0.0015288625145331025
Loss at iteration 1260 : 0.00020120585395488888
Loss at iteration 1270 : 0.003007303923368454
Loss at iteration 1280 : 0.0006795847439207137
Loss at iteration 1290 : 0.00010858230234589428
Loss at iteration 1300 : 0.001152699813246727
Loss at iteration 1310 : 0.0003026994818355888
Loss at iteration 1320 : 0.0006327908486127853
Loss at iteration 1330 : 0.004229356534779072
Loss at iteration 1340 : 0.00016527954721823335
Loss at iteration 1350 : 0.0005692109698429704
Loss at iteration 1360 : 6.945166387595236e-05
Loss at iteration 1370 : 0.0022802904713898897
Loss at iteration 1380 : 0.0003604524245020002
Loss at iteration 1390 : 0.0007954636821523309
Loss at iteration 1400 : 0.0030265934765338898
Loss at iteration 1410 : 0.0008389854338020086
Loss at iteration 1420 : 0.00015295537014026195
Loss at iteration 1430 : 9.750520257512107e-05
Loss at iteration 1440 : 0.0025850986130535603
Loss at iteration 1450 : 0.0006256275810301304
Loss at iteration 1460 : 0.0018299191724509
Loss at iteration 1470 : 0.0002270698023494333
Loss at iteration 1480 : 0.00017295603174716234
Loss at iteration 1490 : 0.0002150873770006001
Loss at iteration 1500 : 0.0007096052286215127
Loss at iteration 1510 : 0.004136081784963608
Loss at iteration 1520 : 0.0004977165954187512
Loss at iteration 1530 : 0.00245479098521173
Loss at iteration 1540 : 0.00048249136307276785
Loss at iteration 1550 : 0.0026625520549714565
Loss at iteration 1560 : 0.0002500857808627188
Loss at iteration 1570 : 0.00040448736399412155
Loss at iteration 1580 : 0.001679877983406186
Loss at iteration 1590 : 0.002299802377820015
Loss at iteration 1600 : 0.0006916034035384655
Loss at iteration 1610 : 0.00034758233232423663
Loss at iteration 1620 : 9.815586963668466e-05
Loss at iteration 1630 : 0.00092931097606197
Loss at iteration 1640 : 0.00011495046055642888
Loss at iteration 1650 : 0.002376872580498457
Loss at iteration 1660 : 0.00010300095891579986
Loss at iteration 1670 : 0.00028248963644728065
Loss at iteration 1680 : 7.881080091465265e-05
Loss at iteration 1690 : 0.001503001432865858
Loss at iteration 1700 : 0.0014040404930710793
Loss at iteration 1710 : 0.0018163489876314998
Loss at iteration 1720 : 0.0039373114705085754
Loss at iteration 1730 : 0.006921697407960892
Loss at iteration 1740 : 5.356821202440187e-05
Loss at iteration 1750 : 9.241494990419596e-05
The SSIM Value is: 0.9824034404912184
The PSNR Value is: 46.54424906617219
the epoch is: 204
Loss at iteration 10 : 0.0002767621772363782
Loss at iteration 20 : 0.0002281533379573375
Loss at iteration 30 : 0.000477138499263674
Loss at iteration 40 : 0.0009144959039986134
Loss at iteration 50 : 0.0016720836283639073
Loss at iteration 60 : 0.00155905622523278
Loss at iteration 70 : 0.00012051115481881425
Loss at iteration 80 : 0.0024064115714281797
Loss at iteration 90 : 0.0001136349601438269
Loss at iteration 100 : 0.0005054069915786386
Loss at iteration 110 : 0.0061469548381865025
Loss at iteration 120 : 0.0002308360708411783
Loss at iteration 130 : 0.00039720005588606
Loss at iteration 140 : 7.197854574769735e-05
Loss at iteration 150 : 0.0021541710011661053
Loss at iteration 160 : 0.0007410268299281597
Loss at iteration 170 : 8.512182103004307e-05
Loss at iteration 180 : 0.0011935889488086104
Loss at iteration 190 : 0.001940967165865004
Loss at iteration 200 : 0.0004816463915631175
Loss at iteration 210 : 0.0003682085080072284
Loss at iteration 220 : 0.002643789164721966
Loss at iteration 230 : 0.00408900436013937
Loss at iteration 240 : 0.00037255213828757405
Loss at iteration 250 : 0.00011686865764204413
Loss at iteration 260 : 0.00011605049803620204
Loss at iteration 270 : 0.0005464011337608099
Loss at iteration 280 : 0.0005036763031966984
Loss at iteration 290 : 0.004997265990823507
Loss at iteration 300 : 7.782407919876277e-05
Loss at iteration 310 : 0.000977545976638794
Loss at iteration 320 : 0.003164430847391486
Loss at iteration 330 : 0.0005300898337736726
Loss at iteration 340 : 0.0031869506929069757
Loss at iteration 350 : 0.0006956831202842295
Loss at iteration 360 : 0.00026967472513206303
Loss at iteration 370 : 0.00010188876331085339
Loss at iteration 380 : 6.777404632885009e-05
Loss at iteration 390 : 0.0017785722156986594
Loss at iteration 400 : 0.0010643985588103533
Loss at iteration 410 : 0.0005668072262778878
Loss at iteration 420 : 0.00022098956105764955
Loss at iteration 430 : 6.465093611041084e-05
Loss at iteration 440 : 0.00017436896450817585
Loss at iteration 450 : 0.004428423009812832
Loss at iteration 460 : 0.00014769905828870833
Loss at iteration 470 : 5.063826029072516e-05
Loss at iteration 480 : 0.002984450664371252
Loss at iteration 490 : 9.586433588992804e-05
Loss at iteration 500 : 0.0007463977672159672
Loss at iteration 510 : 0.00020965171279385686
Loss at iteration 520 : 0.0013986144913360476
Loss at iteration 530 : 0.00019536956096999347
Loss at iteration 540 : 0.000543943140655756
Loss at iteration 550 : 0.00015766122669447213
Loss at iteration 560 : 0.0011538092512637377
Loss at iteration 570 : 0.00015731787425465882
Loss at iteration 580 : 0.0011310166446492076
Loss at iteration 590 : 0.0004607365117408335
Loss at iteration 600 : 0.00011319668556097895
Loss at iteration 610 : 0.0027278196066617966
Loss at iteration 620 : 7.676208770135418e-05
Loss at iteration 630 : 0.00033359177177771926
Loss at iteration 640 : 0.0001611545740161091
Loss at iteration 650 : 9.899430733639747e-05
Loss at iteration 660 : 0.00392596609890461
Loss at iteration 670 : 6.358118116622791e-05
Loss at iteration 680 : 0.0024154179263859987
Loss at iteration 690 : 0.00029951136093586683
Loss at iteration 700 : 0.0001238058030139655
Loss at iteration 710 : 6.162537465570495e-05
Loss at iteration 720 : 6.558138557011262e-05
Loss at iteration 730 : 0.0010122020030394197
Loss at iteration 740 : 0.000573491386603564
Loss at iteration 750 : 0.0003779870457947254
Loss at iteration 760 : 0.0006060410523787141
Loss at iteration 770 : 0.0003627125406637788
Loss at iteration 780 : 0.00015682885714340955
Loss at iteration 790 : 0.0016261995770037174
Loss at iteration 800 : 0.0004588745068758726
Loss at iteration 810 : 8.486747537972406e-05
Loss at iteration 820 : 0.00028282543644309044
Loss at iteration 830 : 0.003929291386157274
Loss at iteration 840 : 0.003251926740631461
Loss at iteration 850 : 0.00010464982915436849
Loss at iteration 860 : 0.0003128614625893533
Loss at iteration 870 : 0.0005084668518975377
Loss at iteration 880 : 0.0015411388594657183
Loss at iteration 890 : 0.00019374040130060166
Loss at iteration 900 : 0.00026895286282524467
Loss at iteration 910 : 0.0009747738367877901
Loss at iteration 920 : 0.0001449750125175342
Loss at iteration 930 : 0.00010848880629055202
Loss at iteration 940 : 0.0036113224923610687
Loss at iteration 950 : 0.00028928020037710667
Loss at iteration 960 : 0.003983958624303341
Loss at iteration 970 : 0.006742060650140047
Loss at iteration 980 : 0.0012358049862086773
Loss at iteration 990 : 0.001350840087980032
Loss at iteration 1000 : 0.0022392827086150646
Loss at iteration 1010 : 0.00015961543249431998
Loss at iteration 1020 : 0.0006548495148308575
Loss at iteration 1030 : 0.0031413286924362183
Loss at iteration 1040 : 0.00029340689070522785
Loss at iteration 1050 : 0.0001952554885065183
Loss at iteration 1060 : 0.0022934875451028347
Loss at iteration 1070 : 0.0002565732866059989
Loss at iteration 1080 : 2.9848313715774566e-05
Loss at iteration 1090 : 0.0004374176205601543
Loss at iteration 1100 : 0.00032906976412050426
Loss at iteration 1110 : 0.0026771919801831245
Loss at iteration 1120 : 0.00048494659131392837
Loss at iteration 1130 : 0.0043746368028223515
Loss at iteration 1140 : 0.0014357606414705515
Loss at iteration 1150 : 0.00024234817828983068
Loss at iteration 1160 : 0.0004124632687307894
Loss at iteration 1170 : 0.0022583864629268646
Loss at iteration 1180 : 0.0019121449440717697
Loss at iteration 1190 : 9.189095726469532e-05
Loss at iteration 1200 : 0.00017548896721564233
Loss at iteration 1210 : 0.00010845517681445926
Loss at iteration 1220 : 0.0019682145211845636
Loss at iteration 1230 : 0.0012585099320858717
Loss at iteration 1240 : 0.00022391781385522336
Loss at iteration 1250 : 0.002955860923975706
Loss at iteration 1260 : 0.0005174947436898947
Loss at iteration 1270 : 0.0006584493676200509
Loss at iteration 1280 : 0.00046542962081730366
Loss at iteration 1290 : 0.003907667472958565
Loss at iteration 1300 : 0.00038679438875988126
Loss at iteration 1310 : 0.0004761188756674528
Loss at iteration 1320 : 7.333060057135299e-05
Loss at iteration 1330 : 0.0005981530994176865
Loss at iteration 1340 : 0.00017918209778144956
Loss at iteration 1350 : 0.00027430005138739944
Loss at iteration 1360 : 0.00026191899087280035
Loss at iteration 1370 : 0.0003731464094016701
Loss at iteration 1380 : 0.0005002521211281419
Loss at iteration 1390 : 0.0006338694947771728
Loss at iteration 1400 : 0.0007236303063109517
Loss at iteration 1410 : 0.0005043884739279747
Loss at iteration 1420 : 0.0021883402951061726
Loss at iteration 1430 : 0.0007700656424276531
Loss at iteration 1440 : 0.0003207037225365639
Loss at iteration 1450 : 0.0002654464915394783
Loss at iteration 1460 : 0.0023481936659663916
Loss at iteration 1470 : 0.00016865688667166978
Loss at iteration 1480 : 0.0004964461550116539
Loss at iteration 1490 : 0.0001970218145288527
Loss at iteration 1500 : 0.0026099977549165487
Loss at iteration 1510 : 0.0014590019127354026
Loss at iteration 1520 : 8.860713569447398e-05
Loss at iteration 1530 : 0.00018348016601521522
Loss at iteration 1540 : 0.00012985419016331434
Loss at iteration 1550 : 0.004469397012144327
Loss at iteration 1560 : 5.166474147699773e-05
Loss at iteration 1570 : 0.0001505845575593412
Loss at iteration 1580 : 0.000580494524911046
Loss at iteration 1590 : 0.00012923833855893463
Loss at iteration 1600 : 9.112816042033955e-05
Loss at iteration 1610 : 0.0003810086636804044
Loss at iteration 1620 : 0.00029859645292162895
Loss at iteration 1630 : 0.0006298437947407365
Loss at iteration 1640 : 7.91129787103273e-05
Loss at iteration 1650 : 0.00016634770145174116
Loss at iteration 1660 : 0.002292850986123085
Loss at iteration 1670 : 0.003919100388884544
Loss at iteration 1680 : 8.438411168754101e-05
Loss at iteration 1690 : 0.002222777809947729
Loss at iteration 1700 : 0.000310710136545822
Loss at iteration 1710 : 0.00039196768193505704
Loss at iteration 1720 : 0.00012139344471506774
Loss at iteration 1730 : 0.0014775199815630913
Loss at iteration 1740 : 0.0004954429459758103
Loss at iteration 1750 : 0.0003370825434103608
The SSIM Value is: 0.9871914508846888
The PSNR Value is: 46.48827193171967
the epoch is: 205
Loss at iteration 10 : 0.00020508014131337404
Loss at iteration 20 : 0.0007728028576821089
Loss at iteration 30 : 0.00018593244021758437
Loss at iteration 40 : 0.000206121287192218
Loss at iteration 50 : 0.0007449840777553618
Loss at iteration 60 : 0.0031947947572916746
Loss at iteration 70 : 0.005436251871287823
Loss at iteration 80 : 0.0020544608123600483
Loss at iteration 90 : 0.0014541368000209332
Loss at iteration 100 : 0.00012117160076741129
Loss at iteration 110 : 0.00024654355365782976
Loss at iteration 120 : 0.0004967783461324871
Loss at iteration 130 : 0.0019770325161516666
Loss at iteration 140 : 0.0005325269885361195
Loss at iteration 150 : 0.0022002661135047674
Loss at iteration 160 : 0.0021172810811549425
Loss at iteration 170 : 0.0002788082347251475
Loss at iteration 180 : 0.00018203539366368204
Loss at iteration 190 : 0.0002304905792698264
Loss at iteration 200 : 0.00014897676010150462
Loss at iteration 210 : 0.0024235243909060955
Loss at iteration 220 : 0.0027353374753147364
Loss at iteration 230 : 0.00023880982189439237
Traceback (most recent call last):
  File "/home/wsz/workspace/Illumination-Adaptive-Transformer/IAT_enhance/train_lol_v1_whole_MIRNet_pretrain.py", line 105, in <module>
    for iteration, imgs in enumerate(train_loader):
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 634, in __next__
    data = self._next_data()
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1346, in _next_data
    return self._process_data(data)
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torch/utils/data/dataloader.py", line 1372, in _process_data
    data.reraise()
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
OSError: Caught OSError in DataLoader worker process 6.
Original Traceback (most recent call last):
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/home/wsz/workspace/Illumination-Adaptive-Transformer/IAT_enhance/data_loaders/lol_v1_whole.py", line 40, in __getitem__
    data_lowlight = Image.open(data_lowlight_path).convert('RGB')
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/PIL/Image.py", line 901, in convert
    self.load()
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/PIL/ImageFile.py", line 276, in load
    raise_oserror(err_code)
  File "/home/wsz/anaconda3/envs/kang/lib/python3.9/site-packages/PIL/ImageFile.py", line 71, in raise_oserror
    raise OSError(message + " when reading image file")
OSError: unrecognized data stream contents when reading image file

